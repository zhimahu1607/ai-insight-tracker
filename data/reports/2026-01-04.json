{
  "date": "2026-01-04",
  "summary": "今日AI领域聚焦于生成模型的高效化与精细化。技术前沿上，扩散模型在跨模态生成和推理加速方面成果突出，如微信利用vLLM实现扩散语言模型的高效部署。研究方向集中在对3D场景、动态视频的可控生成与编辑，以及针对RAG的上下文优化。行业层面，中美AI发展差距持续受到关注。",
  "all_papers": [
    {
      "id": "2512.25075",
      "title": "SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time",
      "authors": [
        "Zhening Huang",
        "Hyeonho Jeong",
        "Xuelin Chen",
        "Yulia Gryaditskaya",
        "Tuanfeng Y. Wang",
        "Joan Lasenby",
        "Chun-Hao Huang"
      ],
      "abstract": "We present SpaceTimePilot, a video diffusion model that disentangles space and time for controllable generative rendering. Given a monocular video, SpaceTimePilot can independently alter the camera viewpoint and the motion sequence within the generative process, re-rendering the scene for continuous and arbitrary exploration across space and time. To achieve this, we introduce an effective animation time-embedding mechanism in the diffusion process, allowing explicit control of the output video's motion sequence with respect to that of the source video. As no datasets provide paired videos of the same dynamic scene with continuous temporal variations, we propose a simple yet effective temporal-warping training scheme that repurposes existing multi-view datasets to mimic temporal differences. This strategy effectively supervises the model to learn temporal control and achieve robust space-time disentanglement. To further enhance the precision of dual control, we introduce two additional components: an improved camera-conditioning mechanism that allows altering the camera from the first frame, and CamxTime, the first synthetic space-and-time full-coverage rendering dataset that provides fully free space-time video trajectories within a scene. Joint training on the temporal-warping scheme and the CamxTime dataset yields more precise temporal control. We evaluate SpaceTimePilot on both real-world and synthetic data, demonstrating clear space-time disentanglement and strong results compared to prior work. Project page: https://zheninghuang.github.io/Space-Time-Pilot/ Code: https://github.com/ZheningHuang/spacetimepilot",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25075.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25075",
      "published": "2025-12-31T18:59:57Z",
      "updated": "2025-12-31T18:59:57Z",
      "comment": "Project page: https://zheninghuang.github.io/Space-Time-Pilot/ Code: https://github.com/ZheningHuang/spacetimepilot",
      "light_analysis": {
        "overview": "提出SpaceTimePilot视频扩散模型，实现动态场景在空间和时间上的可控生成渲染。",
        "motivation": "解决动态场景生成中空间和时间控制分离的问题，以允许连续和任意探索场景。",
        "method": "采用视频扩散模型，引入动画时间嵌入机制、时间扭曲训练方案、改进相机条件机制和CamxTime合成数据集。",
        "result": "在真实和合成数据评估中，模型显示清晰的空间-时间分离，性能优于先前工作。",
        "conclusion": "贡献包括模型、训练策略和数据集，实现了精确的空间和时间双重控制，推进生成渲染技术。",
        "tags": [
          "Video Diffusion Model",
          "Temporal Control",
          "Space-Time Disentanglement",
          "Camera Conditioning",
          "Synthetic Dataset"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:19.926790Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25073",
      "title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
      "authors": [
        "Yi-Chuan Huang",
        "Hao-Jen Chien",
        "Chin-Yang Lin",
        "Ying-Huan Chen",
        "Yu-Lun Liu"
      ],
      "abstract": "Recent advances in 3D reconstruction have achieved remarkable progress in high-quality scene capture from dense multi-view imagery, yet struggle when input views are limited. Various approaches, including regularization techniques, semantic priors, and geometric constraints, have been implemented to address this challenge. Latest diffusion-based methods have demonstrated substantial improvements by generating novel views from new camera poses to augment training data, surpassing earlier regularization and prior-based techniques. Despite this progress, we identify three critical limitations in these state-of-the-art approaches: inadequate coverage beyond known view peripheries, geometric inconsistencies across generated views, and computationally expensive pipelines. We introduce GaMO (Geometry-aware Multi-view Outpainter), a framework that reformulates sparse-view reconstruction through multi-view outpainting. Instead of generating new viewpoints, GaMO expands the field of view from existing camera poses, which inherently preserves geometric consistency while providing broader scene coverage. Our approach employs multi-view conditioning and geometry-aware denoising strategies in a zero-shot manner without training. Extensive experiments on Replica and ScanNet++ demonstrate state-of-the-art reconstruction quality across 3, 6, and 9 input views, outperforming prior methods in PSNR and LPIPS, while achieving a $25\\times$ speedup over SOTA diffusion-based methods with processing time under 10 minutes. Project page: https://yichuanh.github.io/GaMO/",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25073.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25073",
      "published": "2025-12-31T18:59:55Z",
      "updated": "2025-12-31T18:59:55Z",
      "comment": "Project page: https://yichuanh.github.io/GaMO/",
      "light_analysis": {
        "overview": "提出GaMO框架，通过几何感知多视图外绘实现稀疏视图3D重建，保持几何一致性并提升效率。",
        "motivation": "稀疏视图3D重建中，现有方法覆盖不足、几何不一致且计算昂贵，需要改进以应对输入视图有限的挑战。",
        "method": "采用多视图外绘框架，从已知相机姿态扩展视野，结合多视图条件化和几何感知去噪策略，实现零样本无需训练。",
        "result": "在Replica和ScanNet++数据集上，3/6/9输入视图下PSNR和LPIPS优于先前方法，速度提升25倍，处理时间低于10分钟。",
        "conclusion": "GaMO框架有效解决稀疏视图重建的几何不一致和计算效率问题，推进了高质量快速3D重建的发展。",
        "tags": [
          "Diffusion Models",
          "Multi-view Outpainting",
          "Geometry-aware Denoising",
          "Zero-shot Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:49.351145Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25071",
      "title": "Edit3r: Instant 3D Scene Editing from Sparse Unposed Images",
      "authors": [
        "Jiageng Liu",
        "Weijie Lyu",
        "Xueting Li",
        "Yejie Guo",
        "Ming-Hsuan Yang"
      ],
      "abstract": "We present Edit3r, a feed-forward framework that reconstructs and edits 3D scenes in a single pass from unposed, view-inconsistent, instruction-edited images. Unlike prior methods requiring per-scene optimization, Edit3r directly predicts instruction-aligned 3D edits, enabling fast and photorealistic rendering without optimization or pose estimation. A key challenge in training such a model lies in the absence of multi-view consistent edited images for supervision. We address this with (i) a SAM2-based recoloring strategy that generates reliable, cross-view-consistent supervision, and (ii) an asymmetric input strategy that pairs a recolored reference view with raw auxiliary views, encouraging the network to fuse and align disparate observations. At inference, our model effectively handles images edited by 2D methods such as InstructPix2Pix, despite not being exposed to such edits during training. For large-scale quantitative evaluation, we introduce DL3DV-Edit-Bench, a benchmark built on the DL3DV test split, featuring 20 diverse scenes, 4 edit types and 100 edits in total. Comprehensive quantitative and qualitative results show that Edit3r achieves superior semantic alignment and enhanced 3D consistency compared to recent baselines, while operating at significantly higher inference speed, making it promising for real-time 3D editing applications.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25071.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25071",
      "published": "2025-12-31T18:59:53Z",
      "updated": "2025-12-31T18:59:53Z",
      "comment": "Project page: https://edit3r.github.io/edit3r/",
      "light_analysis": {
        "overview": "Edit3r提出前馈框架，从稀疏无姿态图像中单次重建和编辑3D场景。",
        "motivation": "解决传统方法需要每场景优化的问题，实现快速、无需姿态估计的3D场景编辑。",
        "method": "采用基于SAM2的重新着色策略生成跨视图一致监督，结合不对称输入策略融合图像。",
        "result": "在DL3DV-Edit-Bench基准上，Edit3r在语义对齐和3D一致性上优于基线，推理速度显著提高。",
        "conclusion": "Edit3r贡献了高效3D编辑方法，无需优化，速度快且逼真，适用于实时应用。",
        "tags": [
          "3D Scene Editing",
          "Feed-forward Framework",
          "SAM2",
          "Asymmetric Input",
          "Multi-view Consistency"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:51:14.410732Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25070",
      "title": "Scaling Open-Ended Reasoning to Predict the Future",
      "authors": [
        "Nikhil Chandak",
        "Shashwat Goel",
        "Ameya Prabhu",
        "Moritz Hardt",
        "Jonas Geiping"
      ],
      "abstract": "High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.25070.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25070",
      "published": "2025-12-31T18:59:51Z",
      "updated": "2025-12-31T18:59:51Z",
      "comment": "45 pages",
      "light_analysis": {
        "overview": "训练语言模型进行开放式未来预测，通过自动化数据合成和改进强化学习提升性能。",
        "motivation": "解决高风险决策中需要基于不确定性的未来推理问题，提升预测能力。",
        "method": "从新闻自动合成预测问题训练Qwen3模型，结合检索和改进的强化学习奖励函数。",
        "result": "OpenForecaster 8B模型匹配更大专有模型，提高准确性、校准和一致性，校准改进泛化。",
        "conclusion": "开源系统促进语言模型预测研究，展示训练对预测性能的改进和泛化效果。",
        "tags": [
          "Large Language Model",
          "Reinforcement Learning",
          "Retrieval",
          "Forecasting",
          "Data Synthesis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:26.414647Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25067",
      "title": "FineTec: Fine-Grained Action Recognition Under Temporal Corruption via Skeleton Decomposition and Sequence Completion",
      "authors": [
        "Dian Shao",
        "Mingfei Shi",
        "Like Liu"
      ],
      "abstract": "Recognizing fine-grained actions from temporally corrupted skeleton sequences remains a significant challenge, particularly in real-world scenarios where online pose estimation often yields substantial missing data. Existing methods often struggle to accurately recover temporal dynamics and fine-grained spatial structures, resulting in the loss of subtle motion cues crucial for distinguishing similar actions. To address this, we propose FineTec, a unified framework for Fine-grained action recognition under Temporal Corruption. FineTec first restores a base skeleton sequence from corrupted input using context-aware completion with diverse temporal masking. Next, a skeleton-based spatial decomposition module partitions the skeleton into five semantic regions, further divides them into dynamic and static subgroups based on motion variance, and generates two augmented skeleton sequences via targeted perturbation. These, along with the base sequence, are then processed by a physics-driven estimation module, which utilizes Lagrangian dynamics to estimate joint accelerations. Finally, both the fused skeleton position sequence and the fused acceleration sequence are jointly fed into a GCN-based action recognition head. Extensive experiments on both coarse-grained (NTU-60, NTU-120) and fine-grained (Gym99, Gym288) benchmarks show that FineTec significantly outperforms previous methods under various levels of temporal corruption. Specifically, FineTec achieves top-1 accuracies of 89.1% and 78.1% on the challenging Gym99-severe and Gym288-severe settings, respectively, demonstrating its robustness and generalizability. Code and datasets could be found at https://smartdianlab.github.io/projects-FineTec/.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25067.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25067",
      "published": "2025-12-31T18:59:12Z",
      "updated": "2025-12-31T18:59:12Z",
      "comment": "Accepted by AAAI 2026",
      "light_analysis": {
        "overview": "提出 FineTec 框架，通过骨骼分解和序列完成，解决时间损坏下的细粒度动作识别问题。",
        "motivation": "解决真实场景中时间损坏骨骼序列的细粒度动作识别挑战，现有方法难以恢复时间动态和空间结构。",
        "method": "采用上下文感知序列完成、骨骼空间分解、物理驱动加速度估计和基于 GCN 的识别头进行动作识别。",
        "result": "在 Gym99-severe 和 Gym288-severe 基准上分别达到 89.1% 和 78.1% 的 top-1 准确率，显著优于先前方法。",
        "conclusion": "FineTec 框架有效处理时间损坏，提升了细粒度动作识别的鲁棒性和泛化性。",
        "tags": [
          "Fine-Grained Action Recognition",
          "Skeleton Decomposition",
          "Temporal Sequence Completion",
          "Lagrangian Dynamics",
          "Graph Convolutional Network"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:02.349540Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25066",
      "title": "From Inpainting to Editing: A Self-Bootstrapping Framework for Context-Rich Visual Dubbing",
      "authors": [
        "Xu He",
        "Haoxian Zhang",
        "Hejia Chen",
        "Changyuan Zheng",
        "Liyang Chen",
        "Songlin Tang",
        "Jiehui Huang",
        "Xiaoqiang Liu",
        "Pengfei Wan",
        "Zhiyong Wu"
      ],
      "abstract": "Audio-driven visual dubbing aims to synchronize a video's lip movements with new speech, but is fundamentally challenged by the lack of ideal training data: paired videos where only a subject's lip movements differ while all other visual conditions are identical. Existing methods circumvent this with a mask-based inpainting paradigm, where an incomplete visual conditioning forces models to simultaneously hallucinate missing content and sync lips, leading to visual artifacts, identity drift, and poor synchronization. In this work, we propose a novel self-bootstrapping framework that reframes visual dubbing from an ill-posed inpainting task into a well-conditioned video-to-video editing problem. Our approach employs a Diffusion Transformer, first as a data generator, to synthesize ideal training data: a lip-altered companion video for each real sample, forming visually aligned video pairs. A DiT-based audio-driven editor is then trained on these pairs end-to-end, leveraging the complete and aligned input video frames to focus solely on precise, audio-driven lip modifications. This complete, frame-aligned input conditioning forms a rich visual context for the editor, providing it with complete identity cues, scene interactions, and continuous spatiotemporal dynamics. Leveraging this rich context fundamentally enables our method to achieve highly accurate lip sync, faithful identity preservation, and exceptional robustness against challenging in-the-wild scenarios. We further introduce a timestep-adaptive multi-phase learning strategy as a necessary component to disentangle conflicting editing objectives across diffusion timesteps, thereby facilitating stable training and yielding enhanced lip synchronization and visual fidelity. Additionally, we propose ContextDubBench, a comprehensive benchmark dataset for robust evaluation in diverse and challenging practical application scenarios.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25066.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25066",
      "published": "2025-12-31T18:58:30Z",
      "updated": "2025-12-31T18:58:30Z",
      "comment": "Project Page https://hjrphoebus.github.io/X-Dub",
      "light_analysis": {
        "overview": "提出自举框架将视觉配音从修复任务转为视频编辑，解决训练数据问题。",
        "motivation": "现有方法因缺乏理想训练数据（仅唇部不同的配对视频）导致伪影、身份漂移与同步不佳。",
        "method": "用Diffusion Transformer生成理想配对数据，然后训练DiT音频驱动编辑器进行端到端学习，并引入时间步自适应多阶段学习策略。",
        "result": "实现了高度准确的唇部同步、忠实身份保持，并对野外挑战性场景具有出色鲁棒性。",
        "conclusion": "提出了新框架和ContextDubBench基准，提升了视觉配音的准确性与鲁棒性，推动了该领域发展。",
        "tags": [
          "Diffusion Transformer",
          "Audio-driven Video Editing",
          "Self-Bootstrapping",
          "Multi-phase Learning",
          "Benchmark Dataset"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:28.911146Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25063",
      "title": "Many Minds from One Model: Bayesian Transformers for Population Intelligence",
      "authors": [
        "Diji Yang",
        "Yi Zhang"
      ],
      "abstract": "Despite their scale and success, modern transformers are almost universally trained as single-minded systems: optimization produces one deterministic set of parameters, representing a single functional hypothesis about the data. Motivated by the idea that intelligence emerge from many minds, we propose Population Bayesian Transformers (B-Trans), which transform a standard Large Language Model into a Bayesian Transformer model to supports sampling diverse yet coherent model instances from a single set of pre-trained weights.   B-Trans introduces a Bayesian-motivated posterior proxy by treating the bias-like offsets in normalization layers as stochastic variables with a Gaussian variational approximation, inducing a distribution over model behavior without the cost of training full Bayesian neural networks. Sampling from this proxy yields a set of model instances with diverse behaviors while maintaining general competence. To preserve coherence within each generation, we freeze the sampled noise at the sequence level, enforcing temporal consistency across tokens. B-Trans allows for population-level decision-making, where aggregating predictions across sampled individuals significantly enhances exploration. Experiments across zero-shot generation, Reinforcement Learning with Verifiable Rewards (RLVR), and RL without explicit labels demonstrate that B-Trans effectively leverage the wisdom of crowds, yielding superior semantic diversity while achieving better task performance compared to deterministic baselines.",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.25063.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25063",
      "published": "2025-12-31T18:56:02Z",
      "updated": "2025-12-31T18:56:02Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出贝叶斯Transformer(B-Trans)，能从单一预训练权重中采样多样化模型实例，实现群体智能决策。",
        "motivation": "解决现代Transformer作为单一确定性系统的问题，探索智能源于多样化心智的理念。",
        "method": "将归一化层的偏置偏移视为随机变量，使用高斯变分近似构建后验代理，并在序列级冻结噪声以保证一致性。",
        "result": "在零样本生成和强化学习任务中，相比确定性基线，实现了更优的语义多样性和任务性能。",
        "conclusion": "B-Trans能以低成本实现模型行为分布，有效利用群体智慧，提升探索能力和决策质量。",
        "tags": [
          "Large Language Model",
          "Bayesian Inference",
          "Variational Approximation",
          "Reinforcement Learning",
          "Zero-shot Generation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:25.106480Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25060",
      "title": "On the geometry and topology of representations: the manifolds of modular addition",
      "authors": [
        "Gabriela Moisescu-Pareja",
        "Gavin McCracken",
        "Harley Wiltzer",
        "Vincent Létourneau",
        "Colin Daniels",
        "Doina Precup",
        "Jonathan Love"
      ],
      "abstract": "The Clock and Pizza interpretations, associated with architectures differing in either uniform or learnable attention, were introduced to argue that different architectural designs can yield distinct circuits for modular addition. In this work, we show that this is not the case, and that both uniform attention and trainable attention architectures implement the same algorithm via topologically and geometrically equivalent representations. Our methodology goes beyond the interpretation of individual neurons and weights. Instead, we identify all of the neurons corresponding to each learned representation and then study the collective group of neurons as one entity. This method reveals that each learned representation is a manifold that we can study utilizing tools from topology. Based on this insight, we can statistically analyze the learned representations across hundreds of circuits to demonstrate the similarity between learned modular addition circuits that arise naturally from common deep learning paradigms.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.25060.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25060",
      "published": "2025-12-31T18:53:19Z",
      "updated": "2025-12-31T18:53:19Z",
      "comment": null,
      "light_analysis": {
        "overview": "论文证明不同注意力架构在模块加法中实现相同算法，通过拓扑分析揭示表示等价性。",
        "motivation": "解决Clock和Pizza解释的争议，验证架构差异是否导致不同模块加法电路。",
        "method": "将学习表示视为流形，使用拓扑工具分析神经元群体作为整体。",
        "result": "发现统一注意力和可训练注意力架构的表示在拓扑和几何上等价。",
        "conclusion": "提出基于拓扑的表示分析方法，展示深度学习范式下模块加法电路的相似性。",
        "tags": [
          "Attention Mechanisms",
          "Representation Learning",
          "Topological Analysis",
          "Neural Networks",
          "Modular Addition"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:20.564234Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25052",
      "title": "AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG",
      "authors": [
        "Chao Peng",
        "Bin Wang",
        "Zhilei Long",
        "Jinfang Sheng"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is highly sensitive to the quality of selected context, yet standard top-k retrieval often returns redundant or near-duplicate chunks that waste token budget and degrade downstream generation. We present AdaGReS, a redundancy-aware context selection framework for token-budgeted RAG that optimizes a set-level objective combining query-chunk relevance and intra-set redundancy penalties. AdaGReS performs greedy selection under a token-budget constraint using marginal gains derived from the objective, and introduces a closed-form, instance-adaptive calibration of the relevance-redundancy trade-off parameter to eliminate manual tuning and adapt to candidate-pool statistics and budget limits. We further provide a theoretical analysis showing that the proposed objective exhibits epsilon-approximate submodularity under practical embedding similarity conditions, yielding near-optimality guarantees for greedy selection. Experiments on open-domain question answering (Natural Questions) and a high-redundancy biomedical (drug) corpus demonstrate consistent improvements in redundancy control and context quality, translating to better end-to-end answer quality and robustness across settings.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.25052.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25052",
      "published": "2025-12-31T18:48:07Z",
      "updated": "2025-12-31T18:48:07Z",
      "comment": "Preprint. Under review",
      "light_analysis": {
        "overview": "提出AdaGReS框架，通过冗余感知评分和自适应贪心选择，优化RAG在token预算下的上下文选择质量。",
        "motivation": "标准的Top-k检索常返回冗余或近似的文本块，浪费token预算并降低下游生成的性能。",
        "method": "提出了一个结合查询相关性和集内冗余惩罚的集合级目标函数，在token约束下进行贪心选择，并引入了自适应的相关性与冗余权衡参数校准。",
        "result": "在开放域问答和生物医学语料上的实验表明，该方法能持续改进冗余控制和上下文质量，从而提升端到端答案质量和鲁棒性。",
        "conclusion": "该工作为预算受限的RAG系统提供了一种理论保证的自适应选择框架，有效提升检索效率和生成质量。",
        "tags": [
          "Retrieval-Augmented Generation",
          "Redundancy-Aware Selection",
          "Greedy Selection",
          "Submodular Optimization",
          "Adaptive Parameter Tuning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:33.005617Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25034",
      "title": "Generative Classifiers Avoid Shortcut Solutions",
      "authors": [
        "Alexander C. Li",
        "Ananya Kumar",
        "Deepak Pathak"
      ],
      "abstract": "Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.25034.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25034",
      "published": "2025-12-31T18:31:46Z",
      "updated": "2025-12-31T18:31:46Z",
      "comment": "ICLR 2025. Code: https://github.com/alexlioralexli/generative-classifiers",
      "light_analysis": {
        "overview": "生成式分类器通过建模所有特征避免判别式分类器的捷径学习问题，在分布偏移下达到最先进性能。",
        "motivation": "判别式分类器在分布偏移下常因学习虚假相关性而失败，研究旨在探索生成式分类器以避免此问题。",
        "method": "采用生成式分类器，使用类条件生成模型如扩散模型和自回归模型，训练简单无需额外调整。",
        "result": "在五个图像和文本分布偏移基准测试中取得最先进性能，减少医疗和卫星数据集中的虚假相关性影响。",
        "conclusion": "生成式分类器有效提升模型鲁棒性，避免捷径学习，并通过分析揭示其优势条件和数据属性。",
        "tags": [
          "Generative Classifiers",
          "Diffusion Models",
          "Autoregressive Models",
          "Distribution Shift",
          "Spurious Correlations"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:10.207881Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25026",
      "title": "Modeling Language as a Sequence of Thoughts",
      "authors": [
        "Nasim Borazjanizadeh",
        "James McClelland"
      ],
      "abstract": "Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim form is short-lived. Motivated by this view, we introduce Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels of abstraction - tokens and sentence-level \"thought\" states. TG generates the tokens of one sentence at a time while cross-attending to a memory of prior sentence representations. In TG, token and sentence representations are generated using the same set of model parameters and trained with a single objective, the next-token cross-entropy: by retaining the computation graph of sentence representations written to memory, gradients from future token losses flow backward through cross-attention to optimize the parameters generating earlier sentence vectors. In scaling experiments, TG consistently improves efficiency over matched GPT-2 runs, among other baselines, with scaling fits indicating GPT-2 requires ~5-8% more data and ~33-42% more parameters to match TG's loss. TG also reduces errors on relational direction generalization on a father-son reversal curse probe.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.25026.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25026",
      "published": "2025-12-31T18:24:57Z",
      "updated": "2025-12-31T18:24:57Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了Thought Gestalt模型，通过建模句子级思想状态来改进语言模型的全局一致性和效率。",
        "motivation": "解决Transformer语言模型因依赖表面统计而缺乏全局一致表示，导致关系方向脆弱性和数据效率低的问题，受人类认知中事件样表示启发。",
        "method": "引入循环Transformer TG，在标记和句子级两个抽象层次建模语言，使用交叉关注到先前句子表示的内存，并以单一的下一个标记交叉熵目标统一训练。",
        "result": "在扩展实验中，TG比匹配的GPT-2运行更高效，GPT-2需要额外~5-8%的数据和~33-42%的参数来匹配损失，并减少关系方向泛化错误。",
        "conclusion": "TG模型通过多级抽象和内存机制，提升了语言建模的效率和泛化能力，是改进现有Transformer架构的重要贡献。",
        "tags": [
          "Transformer",
          "Recurrent Transformer",
          "Cross-Attention",
          "Language Modeling",
          "Sentence Representation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:45.873463Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25023",
      "title": "ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning",
      "authors": [
        "Timo Kaufmann",
        "Yannick Metz",
        "Daniel Keim",
        "Eyke Hüllermeier"
      ],
      "abstract": "Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.25023.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25023",
      "published": "2025-12-31T18:21:52Z",
      "updated": "2025-12-31T18:21:52Z",
      "comment": "NeurIPS 2025",
      "light_analysis": {
        "overview": "提出ResponseRank方法，通过偏好强度学习实现数据高效奖励建模。",
        "motivation": "传统RLHF的二元选择仅反映偏好方向，缺乏强度信息，而强度对决策和模型泛化至关重要，但难以可靠测量。",
        "method": "提出ResponseRank方法，利用响应时间等代理信号的相对差异，在局部构建的层内比较，鲁棒学习偏好强度，最小化对强度信号的假设。",
        "result": "在合成偏好学习、语言建模和RL控制任务中，实证显示提高了样本效率和鲁棒性，并引入了Pearson距离相关性(PDC)度量。",
        "conclusion": "贡献包括ResponseRank方法、跨任务实证证据和PDC度量，推动了偏好强度学习的研究。",
        "tags": [
          "Reinforcement Learning from Human Feedback",
          "Preference Strength Learning",
          "Reward Modeling",
          "Data Efficiency",
          "Pearson Distance Correlation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:59.323523Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25015",
      "title": "MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes",
      "authors": [
        "Siddhant Agarwal",
        "Adya Dhuler",
        "Polly Ruhnke",
        "Melvin Speisman",
        "Md Shad Akhtar",
        "Shweta Yadav"
      ],
      "abstract": "Over the past years, memes have evolved from being exclusively a medium of humorous exchanges to one that allows users to express a range of emotions freely and easily. With the ever-growing utilization of memes in expressing depressive sentiments, we conduct a study on identifying depressive symptoms exhibited by memes shared by users of online social media platforms. We introduce RESTOREx as a vital resource for detecting depressive symptoms in memes on social media through the Large Language Model (LLM) generated and human-annotated explanations. We introduce MAMAMemeia, a collaborative multi-agent multi-aspect discussion framework grounded in the clinical psychology method of Cognitive Analytic Therapy (CAT) Competencies. MAMAMemeia improves upon the current state-of-the-art by 7.55% in macro-F1 and is established as the new benchmark compared to over 30 methods.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.25015.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25015",
      "published": "2025-12-31T18:06:21Z",
      "updated": "2025-12-31T18:06:21Z",
      "comment": "Accepted by AAAI 2026",
      "light_analysis": {
        "overview": "提出MAMAMemeia框架用于表情包抑郁症状识别，并创建了RESTOREx数据集。",
        "motivation": "识别社交媒体用户通过表情包表达的抑郁症状，以进行心理健康监测。",
        "method": "提出基于认知分析疗法能力的多智能体多方面的协作讨论框架，并创建了大语言模型辅助标注的数据集。",
        "result": "方法在宏平均F1分数上比当前最优方法提升7.55%，在与30多种方法的比较中成为新基准。",
        "conclusion": "提出的框架在抑郁症状识别任务上性能显著提升，为后续研究提供了新方法和数据集。",
        "tags": [
          "Large Language Model",
          "Multi-Agent Collaboration",
          "Depressive Symptoms Identification",
          "Cognitive Analytic Therapy"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:56.053161Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25014",
      "title": "Diffusion Language Models are Provably Optimal Parallel Samplers",
      "authors": [
        "Haozhe Jiang",
        "Nika Haghtalab",
        "Lijie Chen"
      ],
      "abstract": "Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.",
      "categories": [
        "cs.LG",
        "cs.CC"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.25014.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25014",
      "published": "2025-12-31T18:03:05Z",
      "updated": "2025-12-31T18:03:05Z",
      "comment": null,
      "light_analysis": {
        "overview": "证明了扩散语言模型结合链式思维和修订功能是理论上最优的并行采样器，优化步骤和空间复杂度。",
        "motivation": "为扩散语言模型在并行令牌生成中的效率优势提供严格的理论基础，并解决其空间复杂度限制问题。",
        "method": "形式化并行采样模型，分析扩散语言模型增强多项式长度链式思维的能力，并引入修订或重掩码功能。",
        "result": "证明扩散语言模型结合链式思维能以最优步数模拟任何并行采样算法；启用修订或重掩码后，能以最优空间复杂度模拟；并建立严格的表达性差距。",
        "conclusion": "结果为扩散语言模型作为最有效并行采样器的承诺提供了理论依据，并倡导启用修订功能。",
        "tags": [
          "Diffusion Language Models",
          "Parallel Sampling",
          "Chain-of-Thought",
          "Remasking",
          "Revision"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:10.655757Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25008",
      "title": "FoundationSLAM: Unleashing the Power of Depth Foundation Models for End-to-End Dense Visual SLAM",
      "authors": [
        "Yuchen Wu",
        "Jiahe Li",
        "Fabio Tosi",
        "Matteo Poggi",
        "Jin Zheng",
        "Xiao Bai"
      ],
      "abstract": "We present FoundationSLAM, a learning-based monocular dense SLAM system that addresses the absence of geometric consistency in previous flow-based approaches for accurate and robust tracking and mapping. Our core idea is to bridge flow estimation with geometric reasoning by leveraging the guidance from foundation depth models. To this end, we first develop a Hybrid Flow Network that produces geometry-aware correspondences, enabling consistent depth and pose inference across diverse keyframes. To enforce global consistency, we propose a Bi-Consistent Bundle Adjustment Layer that jointly optimizes keyframe pose and depth under multi-view constraints. Furthermore, we introduce a Reliability-Aware Refinement mechanism that dynamically adapts the flow update process by distinguishing between reliable and uncertain regions, forming a closed feedback loop between matching and optimization. Extensive experiments demonstrate that FoundationSLAM achieves superior trajectory accuracy and dense reconstruction quality across multiple challenging datasets, while running in real-time at 18 FPS, demonstrating strong generalization to various scenarios and practical applicability of our method.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25008.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25008",
      "published": "2025-12-31T17:57:45Z",
      "updated": "2025-12-31T17:57:45Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出FoundationSLAM，利用深度基础模型实现几何一致的端到端密集单目视觉SLAM。",
        "motivation": "解决以往基于光流的方法因缺乏几何一致性而难以实现准确、鲁棒跟踪与建图的问题。",
        "method": "开发几何感知的混合光流网络、双向一致集束调整层与可靠性感知细化机制，将光流与几何推理结合。",
        "result": "在多个数据集上达到优越轨迹精度与密集重建质量，并能以18 FPS实时运行，展现强泛化能力。",
        "conclusion": "通过深度基础模型引导的几何一致学习框架，提升了密集视觉SLAM的精度、效率与实用性。",
        "tags": [
          "Visual SLAM",
          "Depth Estimation",
          "Optical Flow",
          "End-to-End Learning",
          "Foundation Models"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:00.377102Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25000",
      "title": "Bi-C2R: Bidirectional Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification",
      "authors": [
        "Zhenyu Cui",
        "Jiahuan Zhou",
        "Yuxin Peng"
      ],
      "abstract": "Lifelong person Re-IDentification (L-ReID) exploits sequentially collected data to continuously train and update a ReID model, focusing on the overall performance of all data. Its main challenge is to avoid the catastrophic forgetting problem of old knowledge while training on new data. Existing L-ReID methods typically re-extract new features for all historical gallery images for inference after each update, known as \"re-indexing\". However, historical gallery data typically suffers from direct saving due to the data privacy issue and the high re-indexing costs for large-scale gallery images. As a result, it inevitably leads to incompatible retrieval between query features extracted by the updated model and gallery features extracted by those before the update, greatly impairing the re-identification performance. To tackle the above issue, this paper focuses on a new task called Re-index Free Lifelong person Re-IDentification (RFL-ReID), which requires performing lifelong person re-identification without re-indexing historical gallery images. Therefore, RFL-ReID is more challenging than L-ReID, requiring continuous learning and balancing new and old knowledge in diverse streaming data, and making the features output by the new and old models compatible with each other. To this end, we propose a Bidirectional Continuous Compatible Representation (Bi-C2R) framework to continuously update the gallery features extracted by the old model to perform efficient L-ReID in a compatible manner. We verify our proposed Bi-C2R method through theoretical analysis and extensive experiments on multiple benchmarks, which demonstrate that the proposed method can achieve leading performance on both the introduced RFL-ReID task and the traditional L-ReID task.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.25000.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25000",
      "published": "2025-12-31T17:50:05Z",
      "updated": "2025-12-31T17:50:05Z",
      "comment": null,
      "light_analysis": {
        "overview": "针对终身行人重识别中免重新索引的挑战，提出了双向持续兼容表示（Bi-C2R）框架。",
        "motivation": "现有终身ReID方法需对历史图库图像重新索引，面临数据隐私和高昂成本问题，导致新旧模型特征不兼容，性能受损。",
        "method": "提出双向持续兼容表示（Bi-C2R）框架，通过持续更新旧模型提取的图库特征，实现新旧模型特征的兼容。",
        "result": "在多个基准测试中验证，在RFL-ReID和传统L-ReID任务上均取得了领先性能。",
        "conclusion": "提出了更实际的免重新索引终身ReID新任务及有效的Bi-C2R解决方案，实现了高性能的兼容性终身学习。",
        "tags": [
          "Continual Learning",
          "Person Re-identification",
          "Feature Compatibility",
          "Compatible Representation Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:24.371288Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24991",
      "title": "Efficiently Estimating Data Efficiency for Language Model Fine-tuning",
      "authors": [
        "Gyung Hyun Je",
        "Colin Raffel"
      ],
      "abstract": "While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task's data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task's data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24991.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24991",
      "published": "2025-12-31T17:37:29Z",
      "updated": "2025-12-31T17:37:29Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于梯度余弦相似度预测语言模型微调数据效率的方法，以减少注释成本。",
        "motivation": "解决大语言模型微调时数据效率未知导致的增量注释和重新训练成本问题。",
        "method": "定义数据效率指标，使用低置信度示例的梯度余弦相似度基于少量标记样本预测数据效率。",
        "result": "在多样化任务集上验证，预测误差为8.6%，消除每个任务数百个不必要的注释。",
        "conclusion": "贡献是提供高效预测数据效率的方法，降低微调所需的注释工作量。",
        "tags": [
          "Large Language Model",
          "Fine-tuning",
          "Gradient Cosine Similarity",
          "Data Efficiency"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:39.875361Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24985",
      "title": "DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments",
      "authors": [
        "Yohan Park",
        "Hyunwoo Ha",
        "Wonjun Jo",
        "Tae-Hyun Oh"
      ],
      "abstract": "Vision Language Models (VLMs) are increasingly adopted as central reasoning modules for embodied agents. Existing benchmarks evaluate their capabilities under ideal, well-lit conditions, yet robust 24/7 operation demands performance under a wide range of visual degradations, including low-light conditions at night or in dark environments--a core necessity that has been largely overlooked. To address this underexplored challenge, we present DarkEQA, an open-source benchmark for evaluating EQA-relevant perceptual primitives under multi-level low-light conditions. DarkEQA isolates the perception bottleneck by evaluating question answering from egocentric observations under controlled degradations, enabling attributable robustness analysis. A key design feature of DarkEQA is its physical fidelity: visual degradations are modeled in linear RAW space, simulating physics-based illumination drop and sensor noise followed by an ISP-inspired rendering pipeline. We demonstrate the utility of DarkEQA by evaluating a wide range of state-of-the-art VLMs and Low-Light Image Enhancement (LLIE) models. Our analysis systematically reveals VLMs' limitations when operating under these challenging visual conditions. Our code and benchmark dataset will be released upon acceptance.",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24985.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24985",
      "published": "2025-12-31T17:31:29Z",
      "updated": "2025-12-31T17:31:29Z",
      "comment": "Submitted to IEEE Robotics and Automation Letters (RA-L)",
      "light_analysis": {
        "overview": "提出了DarkEQA基准，用于评测视觉语言模型在低光环境下的具身问答性能。",
        "motivation": "现有基准仅在理想光照下评估视觉语言模型，而实际具身代理需24/7运行，低光条件是一个被忽视的核心挑战。",
        "method": "设计物理保真度高的低光模拟方法，在原始RAW空间建模光照下降和传感器噪声，通过ISP渲染管道生成图像，评估问答能力。",
        "result": "评估多种先进视觉语言模型和低光图像增强模型，系统揭示了模型在低光条件下的显著局限性。",
        "conclusion": "贡献了一个开源基准，系统分析了视觉语言模型在低光下的弱点，促进鲁棒性研究。",
        "tags": [
          "Vision-Language Model",
          "Embodied Question Answering",
          "Low-Light Image Enhancement",
          "Benchmark Dataset",
          "Image Signal Processing"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:38.496485Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24971",
      "title": "Evaluating the Impact of Compression Techniques on the Robustness of CNNs under Natural Corruptions",
      "authors": [
        "Itallo Patrick Castro Alves Da Silva",
        "Emanuel Adler Medeiros Pereira",
        "Erick de Andrade Barboza",
        "Baldoino Fonseca dos Santos Neto",
        "Marcio de Medeiros Ribeiro"
      ],
      "abstract": "Compressed deep learning models are crucial for deploying computer vision systems on resource-constrained devices. However, model compression may affect robustness, especially under natural corruption. Therefore, it is important to consider robustness evaluation while validating computer vision systems. This paper presents a comprehensive evaluation of compression techniques - quantization, pruning, and weight clustering applied individually and in combination to convolutional neural networks (ResNet-50, VGG-19, and MobileNetV2). Using the CIFAR-10-C and CIFAR 100-C datasets, we analyze the trade-offs between robustness, accuracy, and compression ratio. Our results show that certain compression strategies not only preserve but can also improve robustness, particularly on networks with more complex architectures. Utilizing multiobjective assessment, we determine the best configurations, showing that customized technique combinations produce beneficial multi-objective results. This study provides insights into selecting compression methods for robust and efficient deployment of models in corrupted real-world environments.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24971.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24971",
      "published": "2025-12-31T17:00:01Z",
      "updated": "2025-12-31T17:00:01Z",
      "comment": "Accepted for publication at the 2025 International Conference on Machine Learning and Applications (ICMLA). IEEE Catalog Number: CFP25592-ART",
      "light_analysis": {
        "overview": "评估CNN压缩对自然损坏鲁棒性的影响，发现特定策略能提升鲁棒性。",
        "motivation": "研究模型压缩技术在应用于资源受限设备时，是否会影响CNN在自然损坏环境下的鲁棒性。",
        "method": "对ResNet-50等多种CNN应用量化、剪枝和权重聚类等压缩技术，并在CIFAR-10-C等损坏数据集上进行评估。",
        "result": "某些压缩策略不仅能保持还能提升鲁棒性，特别是在复杂架构网络上，通过多目标评估找到了最佳配置。",
        "conclusion": "为在现实损坏环境中实现鲁棒高效的模型部署提供了压缩方法选择和组合的依据。",
        "tags": [
          "Model Compression",
          "Convolutional Neural Network",
          "Quantization",
          "Pruning",
          "Robustness Evaluation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:59.774866Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24959",
      "title": "Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning",
      "authors": [
        "András Antos",
        "András Millinghoffer",
        "Péter Antal"
      ],
      "abstract": "Many modern AI and ML problems require evaluating partners' contributions through shared yet asymmetric, computationally intensive processes and the simultaneous selection of the most beneficial candidates. Sequential approaches to these problems can be unified under a new framework, Sequential Support Network Learning (SSNL), in which the goal is to select the most beneficial candidate set of partners for all participants using trials; that is, to learn a directed graph that represents the highest-performing contributions. We demonstrate that a new pure-exploration model, the semi-overlapping multi-(multi-armed) bandit (SOMMAB), in which a single evaluation provides distinct feedback to multiple bandits due to structural overlap among their arms, can be used to learn a support network from sparse candidate lists efficiently.   We develop a generalized GapE algorithm for SOMMABs and derive new exponential error bounds that improve the best known constant in the exponent for multi-bandit best-arm identification. The bounds scale linearly with the degree of overlap, revealing significant sample-complexity gains arising from shared evaluations.   From an application point of view, this work provides a theoretical foundation and improved performance guarantees for sequential learning tools for identifying support networks from sparse candidates in multiple learning problems, such as in multi-task learning (MTL), auxiliary task learning (ATL), federated learning (FL), and in multi-agent systems (MAS).",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24959.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24959",
      "published": "2025-12-31T16:42:00Z",
      "updated": "2025-12-31T16:42:00Z",
      "comment": "29 pages, 2 figures",
      "light_analysis": {
        "overview": "提出了半重叠多老虎机模型（SOMMAB）和广义GapE算法，用于高效学习支持网络。",
        "motivation": "解决现代AI/ML中评估合作伙伴贡献、同时选择最优候选集合的复杂序贯决策问题。",
        "method": "提出半重叠多老虎机（SOMMAB）模型，并为其开发了广义GapE算法用于最优臂识别。",
        "result": "推导出指数误差界，改进了已知常数；样本复杂度随臂的重叠度线性增长，显著降低。",
        "conclusion": "为从稀疏候选者中学习支持网络提供了理论基础和性能更强的序贯学习工具。",
        "tags": [
          "Multi-armed Bandit",
          "Best Arm Identification",
          "Multi-task Learning",
          "Federated Learning",
          "Multi-agent Systems"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:40.735882Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24957",
      "title": "AMAP Agentic Planning Technical Report",
      "authors": [
        "Yulan Hu",
        "Xiangwen Zhang",
        "Sheng Ouyang",
        "Hao Yi",
        "Lu Xu",
        "Qinglin Lang",
        "Lide Tan",
        "Xiang Cheng",
        "Tianchen Ye",
        "Zhicong Li",
        "Ge Chen",
        "Wenjin Yang",
        "Zheng Pan",
        "Shaopan Xiong",
        "Siran Yang",
        "Ju Huang",
        "Yan Zhang",
        "Jiamang Wang",
        "Yong Liu",
        "Yinfeng Huang",
        "Tucheng Lin",
        "Xin Li",
        "Ning Guo"
      ],
      "abstract": "We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24957.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24957",
      "published": "2025-12-31T16:39:09Z",
      "updated": "2025-12-31T16:39:09Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了STAgent代理大型语言模型，通过工具环境、数据策展和级联训练解决时空理解任务。",
        "motivation": "为了解决约束下的兴趣点发现和行程规划等复杂时空任务，需要具备时空理解和工具使用能力的代理模型。",
        "method": "采用稳定的工具环境、分层数据策展框架和级联训练方法（种子SFT、高确定性SFT和RL阶段）增强模型能力。",
        "result": "STAgent在TravelBench上表现良好，同时保持了在广泛通用基准测试中的一般能力。",
        "conclusion": "证明了STAgent在时空任务上的有效性，同时不牺牲一般能力，为代理模型开发提供了新方法。",
        "tags": [
          "Large Language Model",
          "Spatio-Temporal Understanding",
          "Reinforcement Learning",
          "Supervised Fine-Tuning",
          "Tool Use"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:38.796851Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24955",
      "title": "MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control",
      "authors": [
        "Yongwei Zhang",
        "Yuanzhe Xing",
        "Quan Quan",
        "Zhikun She"
      ],
      "abstract": "Achieving provable stability in model-free reinforcement learning (RL) remains a challenge, particularly in balancing exploration with rigorous safety. This article introduces MSACL, a framework that integrates exponential stability theory with maximum entropy RL through multi-step Lyapunov certificate learning. Unlike methods relying on complex reward engineering, MSACL utilizes off-policy multi-step data to learn Lyapunov certificates satisfying theoretical stability conditions. By introducing Exponential Stability Labels (ESL) and a $λ$-weighted aggregation mechanism, the framework effectively balances the bias-variance trade-off in multi-step learning. Policy optimization is guided by a stability-aware advantage function, ensuring the learned policy promotes rapid Lyapunov descent. We evaluate MSACL across six benchmarks, including stabilization and nonlinear tracking tasks, demonstrating its superiority over state-of-the-art Lyapunov-based RL algorithms. MSACL achieves exponential stability and rapid convergence under simple rewards, while exhibiting significant robustness to uncertainties and generalization to unseen trajectories. Sensitivity analysis establishes the multi-step horizon $n=20$ as a robust default across diverse systems. By linking Lyapunov theory with off-policy actor-critic frameworks, MSACL provides a foundation for verifiably safe learning-based control. Source code and benchmark environments will be made publicly available.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24955.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24955",
      "published": "2025-12-31T16:36:44Z",
      "updated": "2025-12-31T16:36:44Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出MSACL框架，通过多步李雅普诺夫证书学习，结合稳定性理论与强化学习，实现可验证的稳定控制。",
        "motivation": "解决无模型强化学习中实现可证明稳定性，以及平衡探索与安全性的挑战。",
        "method": "提出MSACL框架，整合指数稳定性理论与最大熵RL，通过离策略多步学习李雅普诺夫证书，并引入指数稳定性标签和λ加权聚合机制。",
        "result": "在六个基准测试中优于现有基于李雅普诺夫的RL算法，实现了指数稳定性、快速收敛，并对不确定性和新轨迹表现出鲁棒性和泛化能力。",
        "conclusion": "为可验证的安全学习控制奠定了基础，通过链接李雅普诺夫理论与离策略演员-评论家框架，提供了一种新方法。",
        "tags": [
          "Reinforcement Learning",
          "Lyapunov Stability",
          "Actor-Critic Methods",
          "Off-Policy Learning",
          "Control Theory"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:41.997695Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24940",
      "title": "Iterative Deployment Improves Planning Skills in LLMs",
      "authors": [
        "Augusto B. Corrêa",
        "Yoav Gelberg",
        "Luckeciano C. Melo",
        "Ilia Shumailov",
        "André G. Pereira",
        "Yarin Gal"
      ],
      "abstract": "We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24940.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24940",
      "published": "2025-12-31T16:03:14Z",
      "updated": "2025-12-31T16:03:14Z",
      "comment": null,
      "light_analysis": {
        "overview": "研究发现迭代部署与基于用户筛选数据的微调能显著提升大语言模型的规划能力。",
        "motivation": "探索迭代部署如何改变大语言模型的性质，并理解其对特定能力（如规划）的影响。",
        "method": "采用迭代部署框架，每轮基于用户从前一轮部署中筛选的数据对LLM进行微调，理论分析其与强化学习的联系。",
        "result": "在多个规划领域，后续模型的规划技能显著提升，能生成长度远超初始模型的计划，表现出涌现的泛化能力。",
        "conclusion": "揭示了迭代部署等效于外层循环的隐式奖励强化学习，对AI安全有影响，并提供了替代显式RL的训练方案。",
        "tags": [
          "Large Language Model",
          "Reinforcement Learning",
          "Fine-tuning",
          "Iterative Deployment",
          "Planning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:26.712834Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24933",
      "title": "Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline",
      "authors": [
        "Minjun Zhao",
        "Xinyu Zhang",
        "Shuai Zhang",
        "Deyang Li",
        "Ruifeng Shi"
      ],
      "abstract": "Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter-step dependencies. Existing end-to-end prompt optimization methods struggle under these conditions and often yield suboptimal or unstable updates. We propose ADOPT, an Adaptive Dependency-aware Prompt Optimization framework for multi-step LLM pipelines. ADOPT explicitly models the dependency between each LLM step and the final task outcome, enabling precise text-gradient estimation analogous to computing analytical derivatives. It decouples textual gradient estimation from gradient updates, reducing multi-prompt optimization to flexible single-prompt optimization steps, and employs a Shapley-based mechanism to adaptively allocate optimization resources. Experiments on real-world datasets and diverse pipeline structures show that ADOPT is effective and robust, consistently outperforming state-of-the-art prompt optimization baselines.",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24933.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24933",
      "published": "2025-12-31T15:46:37Z",
      "updated": "2025-12-31T15:46:37Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了ADOPT框架，通过依赖感知的梯度估计解决多步骤LLM管道提示联合优化难题。",
        "motivation": "多步骤LLM管道性能依赖各步提示，但联合优化面临缺乏步骤监督和步骤间依赖的挑战，现有方法效果不佳。",
        "method": "ADOPT框架显式建模步骤与结果的依赖关系以估计文本梯度，将梯度估计与更新解耦，并使用Shapley机制自适应分配优化资源。",
        "result": "在真实数据集和多种管道结构上的实验表明，ADOPT有效且稳健，性能持续优于最先进的提示优化基线方法。",
        "conclusion": "ADOPT为多步骤LLM管道提供了一种有效、稳健的提示优化方法，解决了现有端到端优化方法的局限性。",
        "tags": [
          "Prompt Optimization",
          "Multi-Step LLM Pipeline",
          "Text-Gradient Estimation",
          "Shapley Value",
          "Dependency Modeling"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:27.585230Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24922",
      "title": "Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection",
      "authors": [
        "Bartłomiej Olber",
        "Jakub Winter",
        "Paweł Wawrzyński",
        "Andrii Gamalii",
        "Daniel Górniak",
        "Marcin Łojek",
        "Robert Nowak",
        "Krystian Radlak"
      ],
      "abstract": "3D object detectors are fundamental components of perception systems in autonomous vehicles. While these detectors achieve remarkable performance on standard autonomous driving benchmarks, they often struggle to generalize across different domains - for instance, a model trained in the U.S. may perform poorly in regions like Asia or Europe. This paper presents a novel lidar domain adaptation method based on neuron activation patterns, demonstrating that state-of-the-art performance can be achieved by annotating only a small, representative, and diverse subset of samples from the target domain if they are correctly selected. The proposed approach requires very small annotation budget and, when combined with post-training techniques inspired by continual learning prevent weight drift from the original model. Empirical evaluation shows that the proposed domain adaptation approach outperforms both linear probing and state-of-the-art domain adaptation techniques.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24922.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24922",
      "published": "2025-12-31T15:26:09Z",
      "updated": "2025-12-31T15:26:09Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种高效半监督激光雷达域适应方法，仅需标注少量目标域样本即可提升3D物体检测的跨域性能。",
        "motivation": "现有3D物体检测模型在自动驾驶中存在跨域（如不同国家或地区）泛化能力差的问题。",
        "method": "提出基于神经元激活模式的域适应方法，结合后训练技术，选择有代表性且多样化的目标域样本子集进行标注。",
        "result": "未明确说明具体数据，但声称优于线性探测和最先进的域适应技术。",
        "conclusion": "主要贡献是提出了一种高精度且标注成本低的域适应方法，以解决3D检测模型在新场景下的性能下降问题。",
        "tags": [
          "Domain Adaptation",
          "3D Object Detection",
          "Lidar",
          "Semi-Supervised Learning",
          "Continual Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:15.511015Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24917",
      "title": "Frequent subgraph-based persistent homology for graph classification",
      "authors": [
        "Xinyang Chen",
        "Amaël Broustet",
        "Guoting Chen"
      ],
      "abstract": "Persistent homology (PH) has recently emerged as a powerful tool for extracting topological features. Integrating PH into machine learning and deep learning models enhances topology awareness and interpretability. However, most PH methods on graphs rely on a limited set of filtrations, such as degree-based or weight-based filtrations, which overlook richer features like recurring information across the dataset and thus restrict expressive power. In this work, we propose a novel graph filtration called Frequent Subgraph Filtration (FSF), which is derived from frequent subgraphs and produces stable and information-rich frequency-based persistent homology (FPH) features. We study the theoretical properties of FSF and provide both proofs and experimental validation. Beyond persistent homology itself, we introduce two approaches for graph classification: an FPH-based machine learning model (FPH-ML) and a hybrid framework that integrates FPH with graph neural networks (FPH-GNNs) to enhance topology-aware graph representation learning. Our frameworks bridge frequent subgraph mining and topological data analysis, offering a new perspective on topology-aware feature extraction. Experimental results show that FPH-ML achieves competitive or superior accuracy compared with kernel-based and degree-based filtration methods. When integrated into graph neural networks, FPH yields relative performance gains ranging from 0.4 to 21 percent, with improvements of up to 8.2 percentage points over GCN and GIN backbones across benchmarks.",
      "categories": [
        "cs.LG",
        "math.AT"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24917.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24917",
      "published": "2025-12-31T15:21:15Z",
      "updated": "2025-12-31T15:21:15Z",
      "comment": "Preprint. 18 pages, 10 figures",
      "light_analysis": {
        "overview": "提出基于频繁子图的持久同调滤波方法，用于增强图分类的拓扑感知和表达能力。",
        "motivation": "现有图持久同调方法依赖有限滤波（如基于度或权重），忽略数据集中的重复信息，限制了特征表达能力。",
        "method": "引入频繁子图滤波（FSF）产生频率基持久同调特征，并开发FPH-ML和FPH-GNNs框架进行图分类。",
        "result": "FPH-ML达到竞争性或更优准确性；集成到GNNs带来0.4%至21%的相对性能提升，最高提升8.2个百分点。",
        "conclusion": "桥接了频繁子图挖掘与拓扑数据分析，为拓扑感知特征提取提供了新视角。",
        "tags": [
          "Persistent Homology",
          "Frequent Subgraph Mining",
          "Graph Neural Networks",
          "Graph Classification",
          "Topological Data Analysis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:18.137678Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24885",
      "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
      "authors": [
        "Hengli Li",
        "Zhaoxin Yu",
        "Qi Shen",
        "Chenxi Li",
        "Mengmeng Wang",
        "Tinglang Wu",
        "Yipeng Kang",
        "Yuxuan Wang",
        "Song-Chun Zhu",
        "Zixia Jia",
        "Zilong Zheng"
      ],
      "abstract": "Strategic dialogue requires agents to execute distinct dialogue acts, for which belief estimation is essential. While prior work often estimates beliefs accurately, it lacks a principled mechanism to use those beliefs during generation. We bridge this gap by first formalizing two core acts Adversarial and Alignment, and by operationalizing them via probabilistic constraints on what an agent may generate. We instantiate this idea in BEDA, a framework that consists of the world set, the belief estimator for belief estimation, and the conditional generator that selects acts and realizes utterances consistent with the inferred beliefs. Across three settings, Conditional Keeper Burglar (CKBG, adversarial), Mutual Friends (MF, cooperative), and CaSiNo (negotiation), BEDA consistently outperforms strong baselines: on CKBG it improves success rate by at least 5.0 points across backbones and by 20.6 points with GPT-4.1-nano; on Mutual Friends it achieves an average improvement of 9.3 points; and on CaSiNo it achieves the optimal deal relative to all baselines. These results indicate that casting belief estimation as constraints provides a simple, general mechanism for reliable strategic dialogue.",
      "categories": [
        "cs.CL",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24885.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24885",
      "published": "2025-12-31T14:26:55Z",
      "updated": "2025-12-31T14:26:55Z",
      "comment": "Accepted by AAMAS 2026",
      "light_analysis": {
        "overview": "提出了BEDA框架，通过将信念估计作为概率约束来执行战略对话行为。",
        "motivation": "先前工作虽能准确估计信念，但缺乏在对话生成中使用信念的原则性机制，旨在弥补这一差距。",
        "method": "形式化对抗和校准对话行为，提出BEDA框架，包括世界集、信念估计器和条件生成器，通过概率约束生成话语。",
        "result": "在CKBG、MF和CaSiNo任务中优于基线，成功率提升最高达20.6点，并达到最优交易。",
        "conclusion": "将信念估计作为概率约束为战略对话提供了简单通用的可靠机制。",
        "tags": [
          "Belief Estimation",
          "Probabilistic Constraints",
          "Strategic Dialogue",
          "Conditional Generation",
          "Large Language Model"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:17.750862Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24873",
      "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem",
      "authors": [
        "Weixun Wang",
        "XiaoXiao Xu",
        "Wanhe An",
        "Fangwen Dai",
        "Wei Gao",
        "Yancheng He",
        "Ju Huang",
        "Qiang Ji",
        "Hanqi Jin",
        "Xiaoyang Li",
        "Yang Li",
        "Zhongwen Li",
        "Shirong Lin",
        "Jiashun Liu",
        "Zenan Liu",
        "Tao Luo",
        "Dilxat Muhtar",
        "Yuanbin Qu",
        "Jiaqiang Shi",
        "Qinghui Sun",
        "Yingshui Tan",
        "Hao Tang",
        "Runze Wang",
        "Yi Wang",
        "Zhaoguo Wang",
        "Yanan Wu",
        "Shaopan Xiong",
        "Binchen Xu",
        "Xander Xu",
        "Yuchi Xu",
        "Qipeng Zhang",
        "Xixia Zhang",
        "Haizhou Zhao",
        "Jie Zhao",
        "Shuaibing Zhao",
        "Baihui Zheng",
        "Jianhui Zheng",
        "Suhang Zheng",
        "Yanni Zhu",
        "Mengze Cai",
        "Kerui Cao",
        "Xitong Chen",
        "Yue Dai",
        "Lifan Du",
        "Tao Feng",
        "Tao He",
        "Jin Hu",
        "Yijie Hu",
        "Ziyu Jiang",
        "Cheng Li",
        "Xiang Li",
        "Jing Liang",
        "Chonghuan Liu",
        "ZhenDong Liu",
        "Haodong Mi",
        "Yanhu Mo",
        "Junjia Ni",
        "Shixin Pei",
        "Jingyu Shen",
        "XiaoShuai Song",
        "Cecilia Wang",
        "Chaofan Wang",
        "Kangyu Wang",
        "Pei Wang",
        "Tao Wang",
        "Wei Wang",
        "Ke Xiao",
        "Mingyu Xu",
        "Tiange Xu",
        "Nan Ya",
        "Siran Yang",
        "Jianan Ye",
        "Yaxing Zang",
        "Duo Zhang",
        "Junbo Zhang",
        "Boren Zheng",
        "Wanxi Deng",
        "Ling Pan",
        "Lin Qu",
        "Wenbo Su",
        "Jiamang Wang",
        "Wei Wang",
        "Hu Wei",
        "Minggang Wu",
        "Cheng Yu",
        "Bing Zhao",
        "Zhicheng Zheng",
        "Bo Zheng"
      ],
      "abstract": "Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24873.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24873",
      "published": "2025-12-31T14:03:39Z",
      "updated": "2025-12-31T14:03:39Z",
      "comment": "36 pages, 15 figures",
      "light_analysis": {
        "overview": "提出了一个端到端的智能体学习生态系统（ALE），并基于此开发了开源的智能体模型ROME。",
        "motivation": "开源社区缺乏一个系统性的、端到端的生态来简化和优化智能体大语言模型的开发流程。",
        "method": "设计了ALE生态系统，包含ROLL权重优化框架、ROCK轨迹生成环境和iFlow CLI上下文工程工具，并提出了用于长程训练的IPA策略优化算法。",
        "result": "发布的ROME模型在SWE-bench Verified和自研的Terminal Bench Pro等多个基准测试中表现出强大性能。",
        "conclusion": "ALE基础设施有效，所开发的ROME模型验证了其在构建高性能智能体方面的能力。",
        "tags": [
          "Large Language Model",
          "Agentic AI",
          "Policy Optimization",
          "Benchmarking",
          "Open Source Ecosystem"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:46.690294Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24867",
      "title": "Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements",
      "authors": [
        "Yiming Liang",
        "Yizhi Li",
        "Yantao Du",
        "Ge Zhang",
        "Jiayi Zhou",
        "Yuchen Wu",
        "Yinzhu Piao",
        "Denghui Cao",
        "Tong Sun",
        "Ziniu Li",
        "Li Du",
        "Bo Lei",
        "Jiaheng Liu",
        "Chenghua Lin",
        "Zhaoxiang Zhang",
        "Wenhao Huang",
        "Jiajun Zhang"
      ],
      "abstract": "Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contamination, restriction to single-knowledge-point assessment, and reliance on costly domain expert annotation. We propose Encyclo-K, a statement-based benchmark that rethinks benchmark construction from the ground up. Our key insight is that knowledge statements, not questions, can serve as the unit of curation, and questions can then be constructed from them. We extract standalone knowledge statements from authoritative textbooks and dynamically compose them into evaluation questions through random sampling at test time. This design directly addresses all three limitations: the combinatorial space is too vast to memorize, and model rankings remain stable across dynamically generated question sets, enabling reliable periodic dataset refresh; each question aggregates 8-10 statements for comprehensive multi-knowledge assessment; annotators only verify formatting compliance without requiring domain expertise, substantially reducing annotation costs. Experiments on over 50 LLMs demonstrate that Encyclo-K poses substantial challenges with strong discriminative power. Even the top-performing OpenAI-GPT-5.1 achieves only 62.07% accuracy, and model performance displays a clear gradient distribution--reasoning models span from 16.04% to 62.07%, while chat models range from 9.71% to 50.40%. These results validate the challenges introduced by dynamic evaluation and multi-statement comprehensive understanding. These findings establish Encyclo-K as a scalable framework for dynamic evaluation of LLMs' comprehensive understanding over multiple fine-grained disciplinary knowledge statements.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24867.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24867",
      "published": "2025-12-31T13:55:54Z",
      "updated": "2025-12-31T13:55:54Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出 Encyclo-K 基准，通过动态组合知识语句来评估大语言模型的综合理解能力。",
        "motivation": "解决现有基准测试的局限性：易数据污染、单知识评估、高成本专家注释。",
        "method": "从权威教材提取知识语句，在测试时动态随机组合成评估问题，降低记忆可能并聚合多语句。",
        "result": "对 50 多个 LLMs 的实验显示，精度最高仅 62.07%，模型性能呈梯度分布，验证了基准的挑战性和区分力。",
        "conclusion": "Encyclo-K 作为可扩展的动态评估框架，能可靠评估 LLMs 对多细粒度知识语句的综合理解。",
        "tags": [
          "Large Language Model",
          "Benchmark",
          "Dynamic Evaluation",
          "Knowledge Statement",
          "Multi-Knowledge Assessment"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:16.159751Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24866",
      "title": "Characterization of Transfer Using Multi-task Learning Curves",
      "authors": [
        "András Millinghoffer",
        "Bence Bolgár",
        "Péter Antal"
      ],
      "abstract": "Transfer effects manifest themselves both during training using a fixed data set and in inductive inference using accumulating data. We hypothesize that perturbing the data set by including more samples, instead of perturbing the model by gradient updates, provides a complementary and more fundamental characterization of transfer effects. To capture this phenomenon, we quantitatively model transfer effects using multi-task learning curves approximating the inductive performance over varying sample sizes. We describe an efficient method to approximate multi-task learning curves analogous to the Task Affinity Grouping method applied during training. We compare the statistical and computational approaches to transfer, which indicates considerably higher compute costs for the previous but better power and broader applicability. Evaluations are performed using a benchmark drug-target interaction data set. Our results show that learning curves can better capture the effects of multi-task learning and their multi-task extensions can delineate pairwise and contextual transfer effects in foundation models.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24866.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24866",
      "published": "2025-12-31T13:55:18Z",
      "updated": "2025-12-31T13:55:18Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出使用多任务学习曲线表征迁移效应的方法，并验证其在基准数据集上的有效性。",
        "motivation": "传统方法通过梯度更新扰动模型来表征迁移效应，但假设通过增加数据样本扰动数据集能提供更本质的表征。",
        "method": "定量建模多任务学习曲线以捕捉迁移效应，并开发了高效近似方法，类似Task Affinity Grouping。",
        "result": "在药物-靶点交互数据集上评估，显示学习曲线能更好捕捉多任务学习效果，扩展能描述成对和上下文迁移。",
        "conclusion": "多任务学习曲线作为迁移效应表征的新工具，为理解基础模型中的迁移提供更优方法。",
        "tags": [
          "Multi-task Learning",
          "Learning Curves",
          "Transfer Learning",
          "Task Affinity Grouping",
          "Foundation Models"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:38.669847Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24861",
      "title": "OFL-SAM2: Prompt SAM2 with Online Few-shot Learner for Efficient Medical Image Segmentation",
      "authors": [
        "Meng Lan",
        "Lefei Zhang",
        "Xiaomeng Li"
      ],
      "abstract": "The Segment Anything Model 2 (SAM2) has demonstrated remarkable promptable visual segmentation capabilities in video data, showing potential for extension to medical image segmentation (MIS) tasks involving 3D volumes and temporally correlated 2D image sequences. However, adapting SAM2 to MIS presents several challenges, including the need for extensive annotated medical data for fine-tuning and high-quality manual prompts, which are both labor-intensive and require intervention from medical experts. To address these challenges, we introduce OFL-SAM2, a prompt-free SAM2 framework for label-efficient MIS. Our core idea is to leverage limited annotated samples to train a lightweight mapping network that captures medical knowledge and transforms generic image features into target features, thereby providing additional discriminative target representations for each frame and eliminating the need for manual prompts. Crucially, the mapping network supports online parameter update during inference, enhancing the model's generalization across test sequences. Technically, we introduce two key components: (1) an online few-shot learner that trains the mapping network to generate target features using limited data, and (2) an adaptive fusion module that dynamically integrates the target features with the memory-attention features generated by frozen SAM2, leading to accurate and robust target representation. Extensive experiments on three diverse MIS datasets demonstrate that OFL-SAM2 achieves state-of-the-art performance with limited training data.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24861.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24861",
      "published": "2025-12-31T13:41:16Z",
      "updated": "2025-12-31T13:41:16Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出OFL-SAM2框架，通过在线少样本学习实现无提示的医疗图像分割，提高效率和泛化能力。",
        "motivation": "适应SAM2到医疗图像分割需要大量标注数据和手动提示，这劳动密集且依赖专家干预，因此寻求更高效方法。",
        "method": "采用在线少样本学习器训练轻量映射网络生成目标特征，并结合自适应融合模块动态集成特征，无需手动提示。",
        "result": "在三个医疗图像分割数据集上进行广泛实验，使用有限训练数据实现了最先进的性能。",
        "conclusion": "OFL-SAM2框架能高效适应SAM2到医疗图像分割，消除手动提示需求，并通过在线更新增强跨序列泛化。",
        "tags": [
          "Segment Anything Model 2",
          "Few-shot Learning",
          "Online Learning",
          "Adaptive Fusion"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:14.014992Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24851",
      "title": "VLN-MME: Diagnosing MLLMs as Language-guided Visual Navigation agents",
      "authors": [
        "Xunyi Zhao",
        "Gengze Zhou",
        "Qi Wu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across a wide range of vision-language tasks. However, their performance as embodied agents, which requires multi-round dialogue spatial reasoning and sequential action prediction, needs further exploration. Our work investigates this potential in the context of Vision-and-Language Navigation (VLN) by introducing a unified and extensible evaluation framework to probe MLLMs as zero-shot agents by bridging traditional navigation datasets into a standardized benchmark, named VLN-MME. We simplify the evaluation with a highly modular and accessible design. This flexibility streamlines experiments, enabling structured comparisons and component-level ablations across diverse MLLM architectures, agent designs, and navigation tasks. Crucially, enabled by our framework, we observe that enhancing our baseline agent with Chain-of-Thought (CoT) reasoning and self-reflection leads to an unexpected performance decrease. This suggests MLLMs exhibit poor context awareness in embodied navigation tasks; although they can follow instructions and structure their output, their 3D spatial reasoning fidelity is low. VLN-MME lays the groundwork for systematic evaluation of general-purpose MLLMs in embodied navigation settings and reveals limitations in their sequential decision-making capabilities. We believe these findings offer crucial guidance for MLLM post-training as embodied agents.",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24851.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24851",
      "published": "2025-12-31T13:21:21Z",
      "updated": "2025-12-31T13:21:21Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出统一的评估框架VLN-MME，用于系统评测多模态大模型在具身导航任务中的零样本能力。",
        "motivation": "探索多模态大模型作为具身智能体的潜力，其多轮对话与空间推理能力仍需深入研究。",
        "method": "构建高度模块化的评估框架VLN-MME，桥接传统数据集，支持跨模型、智能体设计和任务的标准化测试。",
        "result": "发现增强思维链推理和自反思反而降低性能，揭示了模型在3D空间推理与上下文感知上的重大缺陷。",
        "conclusion": "为MLLM的具身导航系统评测奠定基础，其揭示的决策局限为模型后训练提供了关键指引。",
        "tags": [
          "Multimodal Large Language Model",
          "Vision-and-Language Navigation",
          "Chain-of-Thought",
          "Embodied AI",
          "Spatial Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:20.582599Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24842",
      "title": "Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability",
      "authors": [
        "Yanan Long"
      ],
      "abstract": "Multilingual language models achieve strong aggregate performance yet often behave unpredictably across languages, scripts, and cultures. We argue that mechanistic explanations for such models should satisfy a \\emph{causal} standard: claims must survive causal interventions and must \\emph{cross-reference} across environments that perturb surface form while preserving meaning. We formalize \\emph{reference families} as predicate-preserving variants and introduce \\emph{triangulation}, an acceptance rule requiring necessity (ablating the circuit degrades the target behavior), sufficiency (patching activations transfers the behavior), and invariance (both effects remain directionally stable and of sufficient magnitude across the reference family). To supply candidate subgraphs, we adopt automatic circuit discovery and \\emph{accept or reject} those candidates by triangulation. We ground triangulation in causal abstraction by casting it as an approximate transformation score over a distribution of interchange interventions, connect it to the pragmatic interpretability agenda, and present a comparative experimental protocol across multiple model families, language pairs, and tasks. Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance.",
      "categories": [
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24842.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24842",
      "published": "2025-12-31T13:03:34Z",
      "updated": "2025-12-31T13:03:34Z",
      "comment": "NeurIPS 2025 Workshop Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling",
      "light_analysis": {
        "overview": "论文提出三角剖分规则，用于验证多语言语言模型机制解释的因果可靠性。",
        "motivation": "多语言语言模型行为在不同语言中不可预测，需基于因果干预的机制解释标准来确保跨语言稳定性。",
        "method": "形式化参考家族，引入三角剖分规则（必要性、充分性、不变性），结合自动电路发现和因果抽象框架进行验证。",
        "result": "三角剖分能过滤在单一环境中通过但跨语言失败的虚假电路，提供可证伪的机制解释标准。",
        "conclusion": "三角剖分作为接受规则，增强了多语言机制解释的可靠性和可证伪性，为因果解释奠定基础。",
        "tags": [
          "Multilingual Language Models",
          "Mechanistic Interpretability",
          "Causal Intervention",
          "Automatic Circuit Discovery",
          "Invariance Testing"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:41.913984Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24834",
      "title": "GenZ: Foundational models as latent variable generators within traditional statistical models",
      "authors": [
        "Marko Jojic",
        "Nebojsa Jojic"
      ],
      "abstract": "We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24834.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24834",
      "published": "2025-12-31T12:56:01Z",
      "updated": "2025-12-31T12:56:01Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出GenZ混合模型，桥接基础模型与统计建模，通过语义特征提升预测性能。",
        "motivation": "基础模型虽具广泛知识，但难以捕捉数据集特定模式，影响预测任务准确性，需开发结合两者优势的方法。",
        "method": "使用广义EM算法迭代发现语义特征，将基础模型分类作为潜在变量噪声观测，优化统计模型参数。",
        "result": "房价预测误差12%优于GPT-5的38%；电影推荐相似度0.59，匹配传统方法需4000评分的性能。",
        "conclusion": "GenZ模型有效结合基础模型与统计建模，提高预测准确性并发现数据特定模式，增强可解释性。",
        "tags": [
          "Foundational Models",
          "Statistical Modeling",
          "Generalized EM Algorithm",
          "Semantic Features",
          "Collaborative Filtering"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:02.283943Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24827",
      "title": "Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics",
      "authors": [
        "Raul D. Steleac",
        "Mohan Sridharan",
        "David Abel"
      ],
      "abstract": "Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviours. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the \\textit{Fermat} state, and use it to define a measure of \\textit{spreadness}, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24827.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24827",
      "published": "2025-12-31T12:39:22Z",
      "updated": "2025-12-31T12:39:22Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种基于智能体间相对动力学的新方法，用于发现协调的多智能体选项（option）。",
        "motivation": "解决多智能体选项发现中因状态空间指数增长导致的协调性不足问题，现有方法往往牺牲协调。",
        "method": "构建压缩的联合状态抽象，基于状态同步归纳偏置，引入Fermat状态和分散度度量，并使用神经网络拉普拉斯估计器提取选项。",
        "result": "在多个多智能体领域和场景中评估，所发现的选项比替代方法产生了更强的下游协调能力。",
        "conclusion": "提供了一种有效发现协调多智能体选项的新方法，提升了多智能体系统中的协调规划能力。",
        "tags": [
          "Multi-Agent Reinforcement Learning",
          "Option Discovery",
          "State Abstraction",
          "Neural Graph Laplacian",
          "Coordination"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:00.556373Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24818",
      "title": "Unregularized Linear Convergence in Zero-Sum Game from Preference Feedback",
      "authors": [
        "Shulun Chen",
        "Runlong Zhou",
        "Zihan Zhang",
        "Maryam Fazel",
        "Simon S. Du"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences has proven effective for enhancing model capabilities, yet standard preference modeling using the Bradley-Terry model assumes transitivity, overlooking the inherent complexity of human population preferences. Nash learning from human feedback (NLHF) addresses this by framing non-transitive preferences as a two-player zero-sum game, where alignment reduces to finding the Nash equilibrium (NE). However, existing algorithms typically rely on regularization, incurring unavoidable bias when computing the duality gap in the original game. In this work, we provide the first convergence guarantee for Optimistic Multiplicative Weights Update ($\\mathtt{OMWU}$) in NLHF, showing that it achieves last-iterate linear convergence after a burn-in phase whenever an NE with full support exists, with an instance-dependent linear convergence rate to the original NE, measured by duality gaps. Compared to prior results in Wei et al. (2020), we do not require the assumption of NE uniqueness. Our analysis identifies a novel marginal convergence behavior, where the probability of rarely played actions grows exponentially from exponentially small values, enabling exponentially better dependence on instance-dependent constants than prior results. Experiments corroborate the theoretical strengths of $\\mathtt{OMWU}$ in both tabular and neural policy classes, demonstrating its potential for LLM applications.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24818.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24818",
      "published": "2025-12-31T12:08:29Z",
      "updated": "2025-12-31T12:08:29Z",
      "comment": "28 pages",
      "light_analysis": {
        "overview": "首次为NLHF中的乐观乘性权重更新算法提供了线性收敛性保证，无需纳什均衡唯一性假设。",
        "motivation": "现有基于正则化的NLHF算法在计算对偶间隙时会产生偏差，且依赖纳什均衡唯一的强假设。",
        "method": "采用乐观乘性权重更新算法，并对其在零和博弈框架下的收敛性进行理论分析。",
        "result": "证明OMWU在burn-in后能以实例依赖的速率线性收敛至纳什均衡，并发现边际收敛行为，实验验证其优势。",
        "conclusion": "为NLHF提供了更优的无正则化算法理论保证，提升了LLM对齐的潜力。",
        "tags": [
          "Nash Learning from Human Feedback",
          "Zero-Sum Game",
          "Optimistic Multiplicative Weights Update",
          "Duality Gap",
          "Last-iterate Convergence"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:23.280241Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24810",
      "title": "DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes",
      "authors": [
        "Bence Bolgár",
        "András Millinghoffer",
        "Péter Antal"
      ],
      "abstract": "Precise probabilistic information about drug-target interaction (DTI) predictions is vital for understanding limitations and boosting predictive performance. Gaussian processes (GP) offer a scalable framework to integrate state-of-the-art DTI representations and Bayesian inference, enabling novel operations, such as Bayesian classification with rejection, top-$K$ selection, and ranking. We propose a deep kernel learning-based GP architecture (DTI-GP), which incorporates a combined neural embedding module for chemical compounds and protein targets, and a GP module. The workflow continues with sampling from the predictive distribution to estimate a Bayesian precedence matrix, which is used in fast and accurate selection and ranking operations. DTI-GP outperforms state-of-the-art solutions, and it allows (1) the construction of a Bayesian accuracy-confidence enrichment score, (2) rejection schemes for improved enrichment, and (3) estimation and search for top-$K$ selections and ranking with high expected utility.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24810.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24810",
      "published": "2025-12-31T11:55:09Z",
      "updated": "2025-12-31T11:55:09Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于深度核高斯过程的DTI-GP模型，用于贝叶斯药物-靶点相互作用预测和操作。",
        "motivation": "解决药物-靶点相互作用预测中概率信息不精确的问题，以提升预测性能和理解局限性。",
        "method": "采用深度核学习的高斯过程架构，结合神经嵌入模块表示化合物和蛋白质，以及GP模块进行贝叶斯推断。",
        "result": "模型性能优于现有方法，支持贝叶斯精度-置信度富集评分、拒绝方案和高效的top-K选择与排名。",
        "conclusion": "贡献在于提供一个可扩展的贝叶斯框架，实现准确的DTI预测并支持多种贝叶斯操作。",
        "tags": [
          "Deep Kernel Learning",
          "Gaussian Processes",
          "Neural Embeddings",
          "Bayesian Inference",
          "Drug-Target Interaction"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:00.991294Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24794",
      "title": "Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training",
      "authors": [
        "Andrew Tinits",
        "Stephen Mann"
      ],
      "abstract": "The Noise2Noise method allows for training machine learning-based denoisers with pairs of input and target images where both the input and target can be noisy. This removes the need for training with clean target images, which can be difficult to obtain. However, Noise2Noise training has a major limitation: nonlinear functions applied to the noisy targets will skew the results. This bias occurs because the nonlinearity makes the expected value of the noisy targets different from the clean target image. Since nonlinear functions are common in image processing, avoiding them limits the types of preprocessing that can be performed on the noisy targets. Our main insight is that certain nonlinear functions can be applied to the noisy targets without adding significant bias to the results. We develop a theoretical framework for analyzing the effects of these nonlinearities, and describe a class of nonlinear functions with minimal bias.   We demonstrate our method on the denoising of high dynamic range (HDR) images produced by Monte Carlo rendering. Noise2Noise training can have trouble with HDR images, where the training process is overwhelmed by outliers and performs poorly. We consider a commonly used method of addressing these training issues: applying a nonlinear tone mapping function to the model output and target images to reduce their dynamic range. This method was previously thought to be incompatible with Noise2Noise training because of the nonlinearities involved. We show that certain combinations of loss functions and tone mapping functions can reduce the effect of outliers while introducing minimal bias. We apply our method to an existing machine learning-based Monte Carlo denoiser, where the original implementation was trained with high-sample count reference images. Our results approach those of the original implementation, but are produced using only noisy training data.",
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24794.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24794",
      "published": "2025-12-31T11:30:38Z",
      "updated": "2025-12-31T11:30:38Z",
      "comment": "15 pages, 7 figures, 2 tables",
      "light_analysis": {
        "overview": "提出非线性 Noise2Noise 方法，允许在去噪器训练中使用特定非线性函数以减少偏差并处理 HDR 图像问题。",
        "motivation": "Noise2Noise 训练中非线性函数会导致偏差，限制了预处理选项；HDR 图像去噪中离群值影响训练效果，需解决此兼容性问题。",
        "method": "开发理论框架分析非线性函数影响，识别偏差最小的非线性函数类，结合损失函数和色调映射函数减少离群值影响。",
        "result": "应用于现有蒙特卡洛去噪器，使用仅噪声训练数据，结果接近使用高样本参考图像的原始实现。",
        "conclusion": "扩展了 Noise2Noise 方法的适用性，允许使用非线性预处理，特别适用于 HDR 图像去噪，减少训练偏差。",
        "tags": [
          "Noise2Noise",
          "Monte Carlo Denoising",
          "HDR Imaging",
          "Tone Mapping",
          "Loss Functions"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:20.913631Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24793",
      "title": "Self-Supervised Neural Architecture Search for Multimodal Deep Neural Networks",
      "authors": [
        "Shota Suzuki",
        "Satoshi Ono"
      ],
      "abstract": "Neural architecture search (NAS), which automates the architectural design process of deep neural networks (DNN), has attracted increasing attention. Multimodal DNNs that necessitate feature fusion from multiple modalities benefit from NAS due to their structural complexity; however, constructing an architecture for multimodal DNNs through NAS requires a substantial amount of labeled training data. Thus, this paper proposes a self-supervised learning (SSL) method for architecture search of multimodal DNNs. The proposed method applies SSL comprehensively for both the architecture search and model pretraining processes. Experimental results demonstrated that the proposed method successfully designed architectures for DNNs from unlabeled training data.",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24793.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24793",
      "published": "2025-12-31T11:30:28Z",
      "updated": "2025-12-31T11:30:28Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一种结合自监督学习的多模态神经网络架构搜索方法，降低了对标注数据的依赖。",
        "motivation": "解决多模态DNN架构搜索需要大量标注数据的问题，从而利用其结构复杂性优势。",
        "method": "提出一种自监督学习（SSL）方法，将其全面应用于神经架构搜索（NAS）和模型预训练过程。",
        "result": "实验表明，该方法能够仅使用未标注的训练数据成功设计出深度神经网络架构。",
        "conclusion": "将SSL与NAS结合，为多模态DNN的自动化架构设计提供了一种不依赖大量标注数据的解决方案。",
        "tags": [
          "Neural Architecture Search",
          "Multimodal Learning",
          "Self-Supervised Learning",
          "Deep Neural Networks"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:53.531809Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24792",
      "title": "Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation",
      "authors": [
        "Takeru Kusakabe",
        "Yudai Hirose",
        "Mashiho Mukaida",
        "Satoshi Ono"
      ],
      "abstract": "Deep neural networks (DNNs) remain vulnerable to adversarial attacks that cause misclassification when specific perturbations are added to input images. This vulnerability also threatens the reliability of DNN-based monocular depth estimation (MDE) models, making robustness enhancement a critical need in practical applications. To validate the vulnerability of DNN-based MDE models, this study proposes a projection-based adversarial attack method that projects perturbation light onto a target object. The proposed method employs physics-in-the-loop (PITL) optimization -- evaluating candidate solutions in actual environments to account for device specifications and disturbances -- and utilizes a distributed covariance matrix adaptation evolution strategy. Experiments confirmed that the proposed method successfully created adversarial examples that lead to depth misestimations, resulting in parts of objects disappearing from the target scene.",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24792.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24792",
      "published": "2025-12-31T11:30:03Z",
      "updated": "2025-12-31T11:30:03Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一种利用物理在环优化的投影式对抗攻击方法，以验证单目深度估计模型的脆弱性。",
        "motivation": "DNNs易受对抗攻击，这威胁到基于DNN的单目深度估计模型的可靠性，增强其鲁棒性具有迫切需求。",
        "method": "提出投影式对抗攻击方法，将扰动光投射到目标物体上，并采用物理在环优化与分布式协方差矩阵适应进化策略。",
        "result": "实验证实，该方法成功生成了导致深度估计错误的对抗样本，使得场景中目标物体的部分消失。",
        "conclusion": "该研究提供了一种在物理世界中验证MDE模型漏洞的新攻击方法。",
        "tags": [
          "Adversarial Attack",
          "Monocular Depth Estimation",
          "Physics-in-the-Loop Optimization",
          "CMA-ES"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:15.057544Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24780",
      "title": "Gradient Descent as Implicit EM in Distance-Based Neural Models",
      "authors": [
        "Alan Oursland"
      ],
      "abstract": "Neural networks trained with standard objectives exhibit behaviors characteristic of probabilistic inference: soft clustering, prototype specialization, and Bayesian uncertainty tracking. These phenomena appear across architectures -- in attention mechanisms, classification heads, and energy-based models -- yet existing explanations rely on loose analogies to mixture models or post-hoc architectural interpretation. We provide a direct derivation. For any objective with log-sum-exp structure over distances or energies, the gradient with respect to each distance is exactly the negative posterior responsibility of the corresponding component: $\\partial L / \\partial d_j = -r_j$. This is an algebraic identity, not an approximation. The immediate consequence is that gradient descent on such objectives performs expectation-maximization implicitly -- responsibilities are not auxiliary variables to be computed but gradients to be applied. No explicit inference algorithm is required because inference is embedded in optimization. This result unifies three regimes of learning under a single mechanism: unsupervised mixture modeling, where responsibilities are fully latent; attention, where responsibilities are conditioned on queries; and cross-entropy classification, where supervision clamps responsibilities to targets. The Bayesian structure recently observed in trained transformers is not an emergent property but a necessary consequence of the objective geometry. Optimization and inference are the same process.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24780.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24780",
      "published": "2025-12-31T10:56:43Z",
      "updated": "2025-12-31T10:56:43Z",
      "comment": "15 pages",
      "light_analysis": {
        "overview": "证明了基于距离的神经网络中梯度下降隐式执行期望最大化算法，统一了多种学习机制。",
        "motivation": "现有理论对神经网络表现出概率推断行为的解释依赖模糊类比，需直接推导以统一理解。",
        "method": "通过代数恒等式证明，具有log-sum-exp结构的目标函数的梯度等于负后验责任，从而将梯度下降解释为隐式EM。",
        "result": "发现梯度下降在特定目标函数下自动执行推断，无需显式推理算法，统一了无监督学习、注意力和分类学习。",
        "conclusion": "揭示了优化与推断在几何上的同一性，Transformer中的贝叶斯结构是其目标函数形式的必然结果。",
        "tags": [
          "Gradient Descent",
          "Expectation-Maximization",
          "Log-Sum-Exp",
          "Neural Networks",
          "Bayesian Inference"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:16.529895Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24776",
      "title": "Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models",
      "authors": [
        "Ákos Prucs",
        "Márton Csutora",
        "Mátyás Antal",
        "Márk Marosi"
      ],
      "abstract": "Large Language Models (LLMs) are demonstrating rapid improvements on complex reasoning benchmarks, particularly when allowed to utilize intermediate reasoning steps before converging on a final solution. However, current literature often overlooks the significant computational burden associated with generating long reasoning sequences. For industrial applications, model selection depends not only on raw accuracy but also on resource constraints and inference costs. In this work, we conduct a test-time-compute aware evaluation of both contemporary and older open-source LLMs, mapping their Pareto frontiers across math- and reasoning-intensive benchmarks. Our findings identify the Mixture of Experts (MoE) architecture as a strong candidate to balance performance and efficiency in our evaluation setting. Furthermore, we trace the trajectory of Pareto efficiency over time to derive an emergent trend regarding accuracy gain per unit of compute. Finally, we demonstrate that there is a saturation point for inference-time compute. Beyond a certain threshold, accuracy gains diminish, indicating that while extended reasoning capabilities are beneficial, they cannot overcome intrinsic model limitations regarding specific complexities.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24776.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24776",
      "published": "2025-12-31T10:51:32Z",
      "updated": "2025-12-31T10:51:32Z",
      "comment": null,
      "light_analysis": {
        "overview": "论文评估开源大语言模型的计算-精度Pareto前沿，发现混合专家架构在性能与效率间表现最佳，并识别推理计算的饱和点。",
        "motivation": "解决大语言模型推理时计算成本高的问题，为工业应用提供模型选择依据，平衡精度与效率。",
        "method": "采用计算感知评估方法，绘制开源大语言模型在数学和推理基准上的Pareto前沿，并追踪效率随时间的变化趋势。",
        "result": "发现混合专家架构在平衡性能与效率方面优越，推导出单位计算的精度增益趋势，并识别推理计算的饱和阈值。",
        "conclusion": "研究为工业应用中的LLM选择提供了计算-精度权衡的见解，强调了效率优化和模型内在能力极限。",
        "tags": [
          "Large Language Model",
          "Mixture of Experts",
          "Pareto Frontier",
          "Reasoning Benchmark",
          "Compute Efficiency"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:57.324749Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24742",
      "title": "Splatwizard: A Benchmark Toolkit for 3D Gaussian Splatting Compression",
      "authors": [
        "Xiang Liu",
        "Yimin Zhou",
        "Jinxiang Wang",
        "Yujun Huang",
        "Shuzhao Xie",
        "Shiyu Qin",
        "Mingyao Hong",
        "Jiawei Li",
        "Yaowei Wang",
        "Zhi Wang",
        "Shu-Tao Xia",
        "Bin Chen"
      ],
      "abstract": "The recent advent of 3D Gaussian Splatting (3DGS) has marked a significant breakthrough in real-time novel view synthesis. However, the rapid proliferation of 3DGS-based algorithms has created a pressing need for standardized and comprehensive evaluation tools, especially for compression task. Existing benchmarks often lack the specific metrics necessary to holistically assess the unique characteristics of different methods, such as rendering speed, rate distortion trade-offs memory efficiency, and geometric accuracy. To address this gap, we introduce Splatwizard, a unified benchmark toolkit designed specifically for benchmarking 3DGS compression models. Splatwizard provides an easy-to-use framework to implement new 3DGS compression model and utilize state-of-the-art techniques proposed by previous work. Besides, an integrated pipeline that automates the calculation of key performance indicators, including image-based quality metrics, chamfer distance of reconstruct mesh, rendering frame rates, and computational resource consumption is included in the framework as well. Code is available at https://github.com/splatwizard/splatwizard",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24742.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24742",
      "published": "2025-12-31T09:26:04Z",
      "updated": "2025-12-31T09:26:04Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出 Splatwizard，一个专为 3D 高斯泼溅压缩设计的统一基准工具包。",
        "motivation": "现有基准缺乏标准化和全面的评估工具，无法有效评估 3D 高斯泼溅压缩方法的性能。",
        "method": "开发了 Splatwizard 工具包，提供易于使用的框架和自动化计算关键性能指标的集成管道。",
        "result": "未明确说明",
        "conclusion": "该工具包通过标准化评估指标，推动 3D 高斯泼溅压缩技术的发展与比较。",
        "tags": [
          "3D Gaussian Splatting",
          "Compression Benchmark",
          "Rendering Speed",
          "Chamfer Distance",
          "Computational Resource Consumption"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:33.225263Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24731",
      "title": "EchoFoley: Event-Centric Hierarchical Control for Video Grounded Creative Sound Generation",
      "authors": [
        "Bingxuan Li",
        "Yiming Cui",
        "Yicheng He",
        "Yiwei Wang",
        "Shu Zhang",
        "Longyin Wen",
        "Yulei Niu"
      ],
      "abstract": "Sound effects build an essential layer of multimodal storytelling, shaping the emotional atmosphere and the narrative semantics of videos. Despite recent advancement in video-text-to-audio (VT2A), the current formulation faces three key limitations: First, an imbalance between visual and textual conditioning that leads to visual dominance; Second, the absence of a concrete definition for fine-grained controllable generation; Third, weak instruction understanding and following, as existing datasets rely on brief categorical tags. To address these limitations, we introduce EchoFoley, a new task designed for video-grounded sound generation with both event level local control and hierarchical semantic control. Our symbolic representation for sounding events specifies when, what, and how each sound is produced within a video or instruction, enabling fine-grained controls like sound generation, insertion, and editing. To support this task, we construct EchoFoley-6k, a large-scale, expert-curated benchmark containing over 6,000 video-instruction-annotation triplets. Building upon this foundation, we propose EchoVidia a sounding-event-centric agentic generation framework with slow-fast thinking strategy. Experiments show that EchoVidia surpasses recent VT2A models by 40.7% in controllability and 12.5% in perceptual quality.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24731.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24731",
      "published": "2025-12-31T08:58:30Z",
      "updated": "2025-12-31T08:58:30Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出EchoFoley新任务与EchoVidia框架，实现细粒度可控的视频音效生成。",
        "motivation": "解决当前视频-文本-音频生成中视觉主导、缺乏细粒度控制定义和指令理解弱的问题。",
        "method": "提出以声音事件为中心的符号化表示法，构建大规模数据集EchoFoley-6k，并设计了采用慢-快思考策略的EchoVidia代理框架。",
        "result": "EchoVidia在可控性上超越现有VT2A模型40.7%，感知质量提升12.5%。",
        "conclusion": "定义了视频配音新任务，提供了标注数据与生成框架，显著提升了生成的可控性与质量。",
        "tags": [
          "Video-to-Audio Generation",
          "Controllable Generation",
          "Instruction Following",
          "Multimodal Learning",
          "Benchmark Dataset"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:33.671618Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24724",
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "authors": [
        "Jibin Song",
        "Mingi Kwon",
        "Jaeseok Jeong",
        "Youngjung Uh"
      ],
      "abstract": "In this work, we show that the impact of model capacity varies across timesteps: it is crucial for the early and late stages but largely negligible during the intermediate stage. Accordingly, we propose FlowBlending, a stage-aware multi-model sampling strategy that employs a large model and a small model at capacity-sensitive stages and intermediate stages, respectively. We further introduce simple criteria to choose stage boundaries and provide a velocity-divergence analysis as an effective proxy for identifying capacity-sensitive regions. Across LTX-Video (2B/13B) and WAN 2.1 (1.3B/14B), FlowBlending achieves up to 1.65x faster inference with 57.35% fewer FLOPs, while maintaining the visual fidelity, temporal coherence, and semantic alignment of the large models. FlowBlending is also compatible with existing sampling-acceleration techniques, enabling up to 2x additional speedup. Project page is available at: https://jibin86.github.io/flowblending_project_page.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24724.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24724",
      "published": "2025-12-31T08:41:27Z",
      "updated": "2025-12-31T08:41:27Z",
      "comment": "Project page: https://jibin86.github.io/flowblending_project_page",
      "light_analysis": {
        "overview": "提出FlowBlending策略，通过阶段感知多模型采样加速视频生成推理，同时保持高保真度。",
        "motivation": "模型容量在视频生成的不同时间步影响不均：早期和晚期阶段敏感，中间阶段影响小，导致计算冗余和效率低下。",
        "method": "采用阶段感知多模型采样策略，大模型用于容量敏感阶段，小模型用于中间阶段，引入阶段边界选择和速度散度分析作为代理。",
        "result": "在LTX-Video和WAN 2.1模型上实现高达1.65倍推理加速、减少57.35% FLOPs，保持视觉保真度，兼容现有技术额外加速2倍。",
        "conclusion": "FlowBlending有效提升视频生成效率而不牺牲质量，为高效采样提供了新方法。",
        "tags": [
          "Video Generation",
          "Multi-Model Sampling",
          "Stage-Aware Sampling",
          "Velocity-Divergence Analysis",
          "Model Capacity Analysis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:12.045332Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24713",
      "title": "FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference",
      "authors": [
        "Fen-Yu Hsieh",
        "Yun-Chang Teng",
        "Ding-Yong Hong",
        "Jan-Jan Wu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To address this challenge, this work introduces an automation framework that leverages weight pruning and low-bit quantization, and presents a hardware-software co-design method that generates accelerators on the Field-Programmable Gate Array (FPGA) platform. In particular, we implement a unified pipeline that applies N:M structured pruning and 4-bit integer quantization to reduce the memory footprint, followed by optimized dequantization and matrix multiplication to enhance LLM inference on several hardware platforms, including CPUs, NVIDIA GPUs with Dense and 2:4 Sparse Tensor Cores, and a custom systolic-array-based FPGA accelerator. Utilizing 2:4 sparsity combined with quantization on $4096 \\times 4096$ matrices, our approach achieves a reduction of up to $4\\times$ in weight storage and a $1.71\\times$ speedup in matrix multiplication, yielding a $1.29\\times$ end-to-end latency reduction compared to dense GPU baselines. Scaling analysis on the LLaMA-7B model further shows that structured sparsity enhances the throughput per token by $1.36\\times$. These results demonstrate the synergy of fine-grained N:M sparsity and quantization for enabling efficient and deployable LLM inference, while the proposed FPGA accelerator offers a flexible architectural path for supporting a broader class of sparsity patterns beyond the fixed 2:4 hardware constraints.",
      "categories": [
        "cs.LG",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24713.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24713",
      "published": "2025-12-31T08:27:40Z",
      "updated": "2025-12-31T08:27:40Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一个结合N:M稀疏化和低比特量化的大语言模型推理加速框架，并设计了基于FPGA的硬件-软件协同加速器。",
        "motivation": "大语言模型的计算和内存需求巨大，阻碍了其在资源受限环境中的部署。",
        "method": "采用N:M结构化剪枝和4位整数量化降低内存占用，并设计了优化的反量化和矩阵乘法流程，在包括FPGA在内的多种硬件上实现。",
        "result": "在4096x4096矩阵上，存储减少4倍，矩阵乘加速1.71倍，端到端延迟降低1.29倍，LLaMA-7B模型吞吐量提升1.36倍。",
        "conclusion": "证明了细粒度稀疏化与量化协同作用能实现高效的LLM推理，FPGA加速器为支持更广泛的稀疏模式提供了灵活路径。",
        "tags": [
          "Large Language Model",
          "Model Compression",
          "FPGA Acceleration",
          "Structured Pruning",
          "Quantization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:01.666558Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24708",
      "title": "BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework",
      "authors": [
        "András Millinghoffer",
        "András Formanek",
        "András Antos",
        "Péter Antal"
      ],
      "abstract": "The challenge of effectively transferring knowledge across multiple tasks is of critical importance and is also present in downstream tasks with foundation models. However, the nature of transfer, its transitive-intransitive nature, is still an open problem, and negative transfer remains a significant obstacle. Selection of beneficial auxiliary task sets in multi-task learning is frequently hindered by the high computational cost of their evaluation, the high number of plausible candidate auxiliary sets, and the varying complexity of selection across target tasks.   To address these constraints, we introduce BandiK, a novel three-stage multi-task auxiliary task subset selection method using multi-bandits, where each arm pull evaluates candidate auxiliary sets by training and testing a multiple output neural network on a single random train-test dataset split. Firstly, BandiK estimates the pairwise transfers between tasks, which helps in identifying which tasks are likely to benefit from joint learning. In the second stage, it constructs a linear number of candidate sets of auxiliary tasks (in the number of all tasks) for each target task based on the initial estimations, significantly reducing the exponential number of potential auxiliary task sets. Thirdly, it employs a Multi-Armed Bandit (MAB) framework for each task, where the arms correspond to the performance of candidate auxiliary sets realized as multiple output neural networks over train-test data set splits. To enhance efficiency, BandiK integrates these individual task-specific MABs into a multi-bandit structure. The proposed multi-bandit solution exploits that the same neural network realizes multiple arms of different individual bandits corresponding to a given candidate set. This semi-overlapping arm property defines a novel multi-bandit cost/reward structure utilized in BandiK.",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24708.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24708",
      "published": "2025-12-31T08:25:15Z",
      "updated": "2025-12-31T08:25:15Z",
      "comment": "8 pages, 14 figures",
      "light_analysis": {
        "overview": "提出了BandiK框架，利用三阶段多臂老虎机方法高效选择多任务学习中的辅助任务子集。",
        "motivation": "解决多任务学习中辅助任务选择面临的计算成本高、候选集数量爆炸及负迁移等挑战。",
        "method": "采用三阶段方法：估计任务间迁移、构建线性候选集、使用多臂老虎机框架评估，并利用半重叠臂特性整合为多老虎机。",
        "result": "能够高效地识别出对目标任务有益的辅助任务集合，显著提升了辅助任务选择的效率。",
        "conclusion": "提出了一种新颖的多老虎机框架，有效解决了多任务学习中辅助任务选择的关键问题。",
        "tags": [
          "Multi-Task Learning",
          "Multi-Armed Bandit",
          "Negative Transfer",
          "Auxiliary Task Selection",
          "Knowledge Transfer"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:51:07.702760Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24702",
      "title": "Evolving, Not Training: Zero-Shot Reasoning Segmentation via Evolutionary Prompting",
      "authors": [
        "Kai Ye",
        "Xiaotong You",
        "Jianghang Lin",
        "Jiayi Ji",
        "Pingyang Dai",
        "Liujuan Cao"
      ],
      "abstract": "Reasoning Segmentation requires models to interpret complex, context-dependent linguistic queries to achieve pixel-level localization. Current dominant approaches rely heavily on Supervised Fine-Tuning (SFT) or Reinforcement Learning (RL). However, SFT suffers from catastrophic forgetting and domain dependency, while RL is often hindered by training instability and rigid reliance on predefined reward functions. Although recent training-free methods circumvent these training burdens, they are fundamentally limited by a static inference paradigm. These methods typically rely on a single-pass \"generate-then-segment\" chain, which suffers from insufficient reasoning depth and lacks the capability to self-correct linguistic hallucinations or spatial misinterpretations. In this paper, we challenge these limitations and propose EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. Instead of relying on a fixed prompt, EVOL-SAM3 maintains a population of prompt hypotheses and iteratively refines them through a \"Generate-Evaluate-Evolve\" loop. We introduce a Visual Arena to assess prompt fitness via reference-free pairwise tournaments, and a Semantic Mutation operator to inject diversity and correct semantic errors. Furthermore, a Heterogeneous Arena module integrates geometric priors with semantic reasoning to ensure robust final selection. Extensive experiments demonstrate that EVOL-SAM3 not only substantially outperforms static baselines but also significantly surpasses fully supervised state-of-the-art methods on the challenging ReasonSeg benchmark in a zero-shot setting. The code is available at https://github.com/AHideoKuzeA/Evol-SAM3.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24702.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24702",
      "published": "2025-12-31T08:10:03Z",
      "updated": "2025-12-31T08:10:03Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出EVOL-SAM3，一种将推理分割建模为进化搜索的零样本框架，无需训练即可实现更准确的分割。",
        "motivation": "现有方法（有监督微调/强化学习）存在遗忘、不稳定等问题，而无训练方法受限于静态推理，缺乏深度和自校正能力。",
        "method": "提出EVOL-SAM3框架，通过“生成-评估-进化”循环，利用视觉竞技场和语义突变算子动态进化提示，并整合几何先验进行最终选择。",
        "result": "在ReasonSeg基准测试中，零样本性能显著超越静态基线，并大幅优于全监督的最先进方法。",
        "conclusion": "EVOL-SAM3革新了推理分割的范式，通过动态进化提示提升了模型的推理和自校正能力，展现了进化算法在视觉语言模型中的潜力。",
        "tags": [
          "Zero-Shot Learning",
          "Reasoning Segmentation",
          "Evolutionary Algorithm",
          "Prompt Engineering",
          "Visual-Language Models"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:33.741836Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24695",
      "title": "Nested Learning: The Illusion of Deep Learning Architectures",
      "authors": [
        "Ali Behrouz",
        "Meisam Razaviyayn",
        "Peilin Zhong",
        "Vahab Mirrokni"
      ],
      "abstract": "Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24695.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24695",
      "published": "2025-12-31T07:59:43Z",
      "updated": "2025-12-31T07:59:43Z",
      "comment": "A version of this work is published at Neural Information Processing Systems (NeurIPS) 2025",
      "light_analysis": {
        "overview": "提出了Nested Learning新学习范式及三个核心组件，为设计更强大的学习算法提供新思路。",
        "motivation": "解决现有大型模型在持续学习、自我改进和寻找有效解决方案方面的根本挑战与未解问题。",
        "method": "提出Nested Learning（NL）范式，并基于此设计了更强大的优化器、自修改学习模块及连续内存系统。",
        "result": "结合自修改序列模型与连续内存系统构建的Hope模块，在语言建模、持续学习等任务上显示出有希望的结果。",
        "conclusion": "NL范式提供了设计更具表达力算法的哲学框架，其具体实现有望解锁高阶上下文学习和有效的持续学习能力。",
        "tags": [
          "Nested Learning",
          "In-context Learning",
          "Continual Learning",
          "Memory Systems",
          "Optimization Algorithms"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:25.669229Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24694",
      "title": "Mobility-Assisted Decentralized Federated Learning: Convergence Analysis and A Data-Driven Approach",
      "authors": [
        "Reza Jahani",
        "Md Farhamdur Reza",
        "Richeng Jin",
        "Huaiyu Dai"
      ],
      "abstract": "Decentralized Federated Learning (DFL) has emerged as a privacy-preserving machine learning paradigm that enables collaborative training among users without relying on a central server. However, its performance often degrades significantly due to limited connectivity and data heterogeneity. As we move toward the next generation of wireless networks, mobility is increasingly embedded in many real-world applications. The user mobility, either natural or induced, enables clients to act as relays or bridges, thus enhancing information flow in sparse networks; however, its impact on DFL has been largely overlooked despite its potential. In this work, we systematically investigate the role of mobility in improving DFL performance. We first establish the convergence of DFL in sparse networks under user mobility and theoretically demonstrate that even random movement of a fraction of users can significantly boost performance. Building upon this insight, we propose a DFL framework that utilizes mobile users with induced mobility patterns, allowing them to exploit the knowledge of data distribution to determine their trajectories to enhance information propagation through the network. Through extensive experiments, we empirically confirm our theoretical findings, validate the superiority of our approach over baselines, and provide a comprehensive analysis of how various network parameters influence DFL performance in mobile networks.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24694.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24694",
      "published": "2025-12-31T07:59:29Z",
      "updated": "2025-12-31T07:59:29Z",
      "comment": "Under review for potential publication in IEEE Transactions on Cognitive Communications and Networking",
      "light_analysis": {
        "overview": "提出了利用用户移动性增强去中心化联邦学习性能的理论框架与数据驱动方法。",
        "motivation": "去中心化联邦学习在稀疏网络和数据异构下性能下降，而普遍存在的用户移动性未被系统研究其对性能的潜在提升作用。",
        "method": "首先理论分析了移动性对稀疏网络下DFL收敛性的正面影响，进而提出一种利用用户诱导移动模式的数据驱动框架来优化信息传播。",
        "result": "理论证明即使随机移动也能提升性能，实验验证了所提方法优于基线，并全面分析了网络参数在移动网络中的影响。",
        "conclusion": "系统性研究揭示了移动性对提升去中心化联邦学习的重要价值，提出的框架能有效利用移动性优化学习过程。",
        "tags": [
          "Decentralized Federated Learning",
          "Mobility",
          "Convergence Analysis",
          "Data-Driven Optimization",
          "Network Sparsity"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:46.600981Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24693",
      "title": "MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models",
      "authors": [
        "Wenzhe Li",
        "Shujian Zhang",
        "Wenxuan Zhou",
        "John Lambert",
        "Chi Jin",
        "Andrew Hard",
        "Rajiv Mathews",
        "Lun Wang"
      ],
      "abstract": "Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \\textit{training} techniques, effective automated \\textit{evaluation} specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \\textit{multiple} turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \\textbf{MU}lti-\\textbf{S}tep \\textbf{I}nstruction \\textbf{C}ontrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24693.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24693",
      "published": "2025-12-31T07:54:30Z",
      "updated": "2025-12-31T07:54:30Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了 MUSIC 无监督数据增强策略，用于提升多轮奖励模型的评估性能。",
        "motivation": "多轮对话评估成本高且自动评估不足，标准偏好数据集无法有效捕获多轮交互细微差别。",
        "method": "采用 MUSIC 无监督数据增强策略，合成跨多个轮次的对比对话对来训练多轮奖励模型。",
        "result": "MUSIC 增强的奖励模型在 Skywork 数据集上优于基线，与先进 LLM 判断对齐更好，且不影响单轮基准。",
        "conclusion": "MUSIC 能有效构建健壮的多轮奖励模型，提升多轮对话评估的自动化水平。",
        "tags": [
          "Large Language Model",
          "Reward Model",
          "Unsupervised Data Augmentation",
          "Contrastive Learning",
          "Multi-Turn Conversation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:08.898268Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24665",
      "title": "HeteroHBA: A Generative Structure-Manipulating Backdoor Attack on Heterogeneous Graphs",
      "authors": [
        "Honglin Gao",
        "Lan Zhao",
        "Junhao Ren",
        "Xiang Li",
        "Gaoxi Xiao"
      ],
      "abstract": "Heterogeneous graph neural networks (HGNNs) have achieved strong performance in many real-world applications, yet targeted backdoor poisoning on heterogeneous graphs remains less studied. We consider backdoor attacks for heterogeneous node classification, where an adversary injects a small set of trigger nodes and connections during training to force specific victim nodes to be misclassified into an attacker-chosen label at test time while preserving clean performance. We propose HeteroHBA, a generative backdoor framework that selects influential auxiliary neighbors for trigger attachment via saliency-based screening and synthesizes diverse trigger features and connection patterns to better match the local heterogeneous context. To improve stealthiness, we combine Adaptive Instance Normalization (AdaIN) with a Maximum Mean Discrepancy (MMD) loss to align the trigger feature distribution with benign statistics, thereby reducing detectability, and we optimize the attack with a bilevel objective that jointly promotes attack success and maintains clean accuracy. Experiments on multiple real-world heterogeneous graphs with representative HGNN architectures show that HeteroHBA consistently achieves higher attack success than prior backdoor baselines with comparable or smaller impact on clean accuracy; moreover, the attack remains effective under our heterogeneity-aware structural defense, CSD. These results highlight practical backdoor risks in heterogeneous graph learning and motivate the development of stronger defenses.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24665.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24665",
      "published": "2025-12-31T06:38:53Z",
      "updated": "2025-12-31T06:38:53Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出 HeteroHBA，一个针对异构图的生成性后门攻击框架，提高攻击成功率并保持隐蔽性。",
        "motivation": "异构图神经网络应用广泛，但针对异构图的针对性后门攻击研究不足，需要揭示其安全风险。",
        "method": "提出 HeteroHBA 框架，通过显著性筛选选择触发节点，合成多样特征和连接，使用 AdaIN 和 MMD 损失提高隐蔽性，并用双层目标优化。",
        "result": "实验显示 HeteroHBA 攻击成功率高于基线，对干净准确性影响小，且在异构感知防御 CSD 下仍有效。",
        "conclusion": "贡献了高效后门攻击方法，强调了异构图学习中的实际风险，推动了更强防御研究。",
        "tags": [
          "Heterogeneous Graph Neural Networks",
          "Backdoor Attack",
          "Generative Framework",
          "Adaptive Instance Normalization",
          "Maximum Mean Discrepancy"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:44.740241Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24663",
      "title": "Renormalization Group Guided Tensor Network Structure Search",
      "authors": [
        "Maolin Wang",
        "Bowen Yu",
        "Sheng Zhang",
        "Linjie Mi",
        "Wanyu Wang",
        "Yiqi Wang",
        "Pengyue Jia",
        "Xuetao Wei",
        "Zenglin Xu",
        "Ruocheng Guo",
        "Xiangyu Zhao"
      ],
      "abstract": "Tensor network structure search (TN-SS) aims to automatically discover optimal network topologies and rank configurations for efficient tensor decomposition in high-dimensional data representation. Despite recent advances, existing TN-SS methods face significant limitations in computational tractability, structure adaptivity, and optimization robustness across diverse tensor characteristics. They struggle with three key challenges: single-scale optimization missing multi-scale structures, discrete search spaces hindering smooth structure evolution, and separated structure-parameter optimization causing computational inefficiency. We propose RGTN (Renormalization Group guided Tensor Network search), a physics-inspired framework transforming TN-SS via multi-scale renormalization group flows. Unlike fixed-scale discrete search methods, RGTN uses dynamic scale-transformation for continuous structure evolution across resolutions. Its core innovation includes learnable edge gates for optimization-stage topology modification and intelligent proposals based on physical quantities like node tension measuring local stress and edge information flow quantifying connectivity importance. Starting from low-complexity coarse scales and refining to finer ones, RGTN finds compact structures while escaping local minima via scale-induced perturbations. Extensive experiments on light field data, high-order synthetic tensors, and video completion tasks show RGTN achieves state-of-the-art compression ratios and runs 4-600$\\times$ faster than existing methods, validating the effectiveness of our physics-inspired approach.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24663.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24663",
      "published": "2025-12-31T06:31:43Z",
      "updated": "2025-12-31T06:31:43Z",
      "comment": "Accepted to AAAI 2026",
      "light_analysis": {
        "overview": "提出基于重正化群指导的张量网络结构搜索框架 RGTN，实现多尺度连续结构优化以提升张量分解效率。",
        "motivation": "解决现有张量网络结构搜索方法在计算可处理性、结构适应性和优化鲁棒性方面的不足，克服单尺度优化、离散搜索空间和分离优化等挑战。",
        "method": "采用 RGTN 框架，利用重正化群流进行多尺度搜索，包括动态尺度变换、可学习边门和基于节点张力、边信息流等物理量的智能提议。",
        "result": "在光场数据、高阶合成张量和视频完成任务上实现最先进压缩比，运行速度比现有方法快 4-600 倍。",
        "conclusion": "RGTN 框架有效解决了张量网络结构搜索的关键问题，验证了物理启发多尺度方法的有效性，为高效张量分解提供新途径。",
        "tags": [
          "Tensor Network",
          "Renormalization Group",
          "Multi-scale Optimization",
          "Dynamic Scale Transformation",
          "Edge Gates"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:28.696397Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24661",
      "title": "Do Large Language Models Know What They Are Capable Of?",
      "authors": [
        "Casey O. Barkan",
        "Sid Black",
        "Oliver Sourbut"
      ],
      "abstract": "We investigate whether large language models (LLMs) can predict whether they will succeed on a given task and whether their predictions improve as they progress through multi-step tasks. We also investigate whether LLMs can learn from in-context experiences to make better decisions about whether to pursue a task in scenarios where failure is costly. All LLMs we tested are overconfident, but most predict their success with better-than-random discriminatory power. We find that newer and larger LLMs generally do not have greater discriminatory power, though Claude models do show such a trend. On multi-step agentic tasks, the overconfidence of several frontier LLMs worsens as they progress through the tasks, and reasoning LLMs perform comparably to or worse than non-reasoning LLMs. With in-context experiences of failure, some but not all LLMs reduce their overconfidence leading to significantly improved decision making, while others do not. Interestingly, all LLMs' decisions are approximately rational given their estimated probabilities of success, yet their overly-optimistic estimates result in poor decision making. These results suggest that current LLM agents are hindered by their lack of awareness of their own capabilities. We discuss the implications of LLMs' awareness of their capabilities for AI misuse and misalignment risks.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24661.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24661",
      "published": "2025-12-31T06:14:46Z",
      "updated": "2025-12-31T06:14:46Z",
      "comment": "23 pages, 8 figures",
      "light_analysis": {
        "overview": "本研究揭示大语言模型普遍过度自信，缺乏自我能力意识，影响任务决策质量。",
        "motivation": "探究大语言模型是否能准确预测自身在任务中的成功，以优化在失败代价高昂场景中的决策。",
        "method": "通过实验测试多个LLMs在单步和多步任务中的成功预测能力，并引入上下文失败经验观察其学习效果。",
        "result": "LLMs普遍过度自信，预测能力随任务进展恶化，部分模型能从经验中学习改进决策，但整体决策仍因乐观估计受损。",
        "conclusion": "LLMs缺乏自我能力意识，导致决策不良，这对AI应用的安全性和可靠性构成风险，需关注滥用和失准问题。",
        "tags": [
          "Large Language Model",
          "Capability Assessment",
          "Overconfidence",
          "In-Context Learning",
          "Decision Making"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:46.403355Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24639",
      "title": "From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation",
      "authors": [
        "Siyang Wang",
        "Hanting Li",
        "Wei Li",
        "Jie Hu",
        "Xinghao Chen",
        "Feng Zhao"
      ],
      "abstract": "Inspired by the remarkable success of autoregressive models in language modeling, this paradigm has been widely adopted in visual generation. However, the sequential token-by-token decoding mechanism inherent in traditional autoregressive models leads to low inference efficiency.In this paper, we propose RadAR, an efficient and parallelizable framework designed to accelerate autoregressive visual generation while preserving its representational capacity. Our approach is motivated by the observation that visual tokens exhibit strong local dependencies and spatial correlations with their neighbors--a property not fully exploited in standard raster-scan decoding orders. Specifically, we organize the generation process around a radial topology: an initial token is selected as the starting point, and all other tokens are systematically grouped into multiple concentric rings according to their spatial distances from this center. Generation then proceeds in a ring-wise manner, from inner to outer regions, enabling the parallel prediction of all tokens within the same ring. This design not only preserves the structural locality and spatial coherence of visual scenes but also substantially increases parallelization. Furthermore, to address the risk of inconsistent predictions arising from simultaneous token generation with limited context, we introduce a nested attention mechanism. This mechanism dynamically refines implausible outputs during the forward pass, thereby mitigating error accumulation and preventing model collapse. By integrating radial parallel prediction with dynamic output correction, RadAR significantly improves generation efficiency.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24639.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24639",
      "published": "2025-12-31T05:24:07Z",
      "updated": "2025-12-31T05:24:07Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出RadAR框架，通过径向拓扑和嵌套注意力机制实现高效并行的自回归视觉生成。",
        "motivation": "传统自回归模型的顺序解码机制在视觉生成中效率低，且未充分利用视觉令牌的局部空间相关性。",
        "method": "采用径向拓扑将令牌按空间距离分组为同心环，实现环内并行生成，并引入嵌套注意力机制动态修正输出。",
        "result": "显著提高了视觉生成效率，但具体数据未在摘要中说明。",
        "conclusion": "RadAR框架结合径向并行预测和动态输出修正，在保持表示能力的同时提升了生成效率。",
        "tags": [
          "Autoregressive Models",
          "Visual Generation",
          "Parallel Decoding",
          "Spatial Topology",
          "Nested Attention"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:28.325153Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24625",
      "title": "AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt",
      "authors": [
        "Zijian Zhao",
        "Yitong Shang",
        "Sen Li"
      ],
      "abstract": "Accurate traffic prediction is essential for Intelligent Transportation Systems, including ride-hailing, urban road planning, and vehicle fleet management. However, due to significant privacy concerns surrounding traffic data, most existing methods rely on local training, resulting in data silos and limited knowledge sharing. Federated Learning (FL) offers an efficient solution through privacy-preserving collaborative training; however, standard FL struggles with the non-independent and identically distributed (non-IID) problem among clients. This challenge has led to the emergence of Personalized Federated Learning (PFL) as a promising paradigm. Nevertheless, current PFL frameworks require further adaptation for traffic prediction tasks, such as specialized graph feature engineering, data processing, and network architecture design. A notable limitation of many prior studies is their reliance on hyper-parameter optimization across datasets-information that is often unavailable in real-world scenarios-thus impeding practical deployment. To address this challenge, we propose AutoFed, a novel PFL framework for traffic prediction that eliminates the need for manual hyper-parameter tuning. Inspired by prompt learning, AutoFed introduces a federated representor that employs a client-aligned adapter to distill local data into a compact, globally shared prompt matrix. This prompt then conditions a personalized predictor, allowing each client to benefit from cross-client knowledge while maintaining local specificity. Extensive experiments on real-world datasets demonstrate that AutoFed consistently achieves superior performance across diverse scenarios. The code of this paper is provided at https://github.com/RS2002/AutoFed .",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24625.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24625",
      "published": "2025-12-31T04:52:19Z",
      "updated": "2025-12-31T04:52:19Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了AutoFed，一个无需手动超参数调优的个性化联邦学习框架，用于交通预测。",
        "motivation": "解决个性化联邦学习在交通预测中依赖手动超参数调优的问题，以促进实际部署。",
        "method": "基于提示学习，引入联邦表示器，通过客户端对齐适配器提取本地数据为全局共享提示矩阵，并条件化个性化预测器。",
        "result": "在真实世界数据集上的实验表明，AutoFed在各种场景下 consistently 取得优异性能。",
        "conclusion": "主要贡献是AutoFed框架，通过消除手动超参数调优，实现了高效的个性化交通预测。",
        "tags": [
          "Federated Learning",
          "Personalized Federated Learning",
          "Prompt Learning",
          "Traffic Prediction"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:56.620920Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24620",
      "title": "LLHA-Net: A Hierarchical Attention Network for Two-View Correspondence Learning",
      "authors": [
        "Shuyuan Lin",
        "Yu Guo",
        "Xiao Chen",
        "Yanjie Liang",
        "Guobao Xiao",
        "Feiran Huang"
      ],
      "abstract": "Establishing the correct correspondence of feature points is a fundamental task in computer vision. However, the presence of numerous outliers among the feature points can significantly affect the matching results, reducing the accuracy and robustness of the process. Furthermore, a challenge arises when dealing with a large proportion of outliers: how to ensure the extraction of high-quality information while reducing errors caused by negative samples. To address these issues, in this paper, we propose a novel method called Layer-by-Layer Hierarchical Attention Network, which enhances the precision of feature point matching in computer vision by addressing the issue of outliers. Our method incorporates stage fusion, hierarchical extraction, and an attention mechanism to improve the network's representation capability by emphasizing the rich semantic information of feature points. Specifically, we introduce a layer-by-layer channel fusion module, which preserves the feature semantic information from each stage and achieves overall fusion, thereby enhancing the representation capability of the feature points. Additionally, we design a hierarchical attention module that adaptively captures and fuses global perception and structural semantic information using an attention mechanism. Finally, we propose two architectures to extract and integrate features, thereby improving the adaptability of our network. We conduct experiments on two public datasets, namely YFCC100M and SUN3D, and the results demonstrate that our proposed method outperforms several state-of-the-art techniques in both outlier removal and camera pose estimation. Source code is available at http://www.linshuyuan.com.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24620.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24620",
      "published": "2025-12-31T04:25:53Z",
      "updated": "2025-12-31T04:25:53Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出LLHA-Net分层注意力网络，通过处理异常值提升两视图特征点匹配精度。",
        "motivation": "解决特征点匹配中异常值过多导致的精度下降和鲁棒性问题，应对高异常值比例下的信息提取挑战。",
        "method": "采用分层注意力网络，集成阶段融合、层间通道融合模块和分层注意力机制，增强特征语义表示。",
        "result": "在YFCC100M和SUN3D数据集上，方法在异常值去除和相机姿态估计方面优于多种最先进技术。",
        "conclusion": "提出的网络架构有效处理异常值，提升特征匹配精度和适应性，对计算机视觉任务有积极意义。",
        "tags": [
          "Hierarchical Attention",
          "Attention Mechanism",
          "Feature Fusion",
          "Outlier Removal",
          "Correspondence Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:42.377306Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24618",
      "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
      "authors": [
        "Junru Lu",
        "Jiarui Qin",
        "Lingfeng Qiao",
        "Yinghui Li",
        "Xinyi Dai",
        "Bo Ke",
        "Jianfeng He",
        "Ruizhi Qiao",
        "Di Yin",
        "Xing Sun",
        "Yunsheng Wu",
        "Yinsong Liu",
        "Shuangyin Liu",
        "Mingkong Tang",
        "Haodong Lin",
        "Jiayi Kuang",
        "Fanxu Meng",
        "Xiaojuan Tang",
        "Yunjia Xi",
        "Junjie Huang",
        "Haotong Yang",
        "Zhenyi Shen",
        "Yangning Li",
        "Qianwen Zhang",
        "Yifei Yu",
        "Siyu An",
        "Junnan Dong",
        "Qiufeng Wang",
        "Jie Wang",
        "Keyu Chen",
        "Wei Wen",
        "Taian Guo",
        "Zhifeng Shen",
        "Daohai Yu",
        "Jiahao Li",
        "Ke Li",
        "Zongyi Li",
        "Xiaoyu Tan"
      ],
      "abstract": "We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities. The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window. This design enables robust long-context reasoning and state tracking within a minimal memory footprint, making it ideal for long-horizon agent and reasoning tasks. (2) Principled \"Commonsense-STEM-Agent\" Curriculum: We curated a massive corpus of approximately 11T tokens and implemented a multi-stage training strategy. By progressively shifting the pre-training data distribution from general commonsense to complex STEM and agentic tasks, we ensure the model acquires deep cognitive abilities rather than superficial alignment. (3) Scalable Agentic Mid-training: Specifically for the agentic mid-training, we employ diverse data construction schemes to synthesize rich and varied trajectories across math, coding, and tool-use domains. This high-quality data enables the model to internalize planning and reflection behaviors effectively. Extensive evaluations show that Youtu-LLM sets a new state-of-the-art for sub-2B LLMs. On general benchmarks, it achieves competitive performance against larger models, while on agent-specific tasks, it significantly surpasses existing SOTA baselines, demonstrating that lightweight models can possess strong intrinsic agentic capabilities.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24618.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24618",
      "published": "2025-12-31T04:25:11Z",
      "updated": "2025-12-31T04:25:11Z",
      "comment": "57 pages, 26 figures",
      "light_analysis": {
        "overview": "提出轻量级Youtu-LLM模型，结合高效计算与原生代理智能，在推理和规划任务中表现优异。",
        "motivation": "解决轻量级LLM依赖蒸馏、缺乏内在代理能力的问题，旨在直接从预训练中培养推理和规划能力。",
        "method": "采用密集多潜在注意力架构和STEM词汇表构建紧凑模型；实施多阶段训练课程，从常识到代理任务；使用合成数据增强代理能力。",
        "result": "在轻量级模型中达到最先进水平，通用任务表现竞争性，代理任务显著优于现有基线。",
        "conclusion": "证明了轻量级LLM通过从头预训练和结构化课程可以获得强代理能力，为高效AI代理开发提供新途径。",
        "tags": [
          "Large Language Model",
          "Multi-Latent Attention",
          "Curriculum Learning",
          "Agentic Intelligence"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:33.756358Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24617",
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "authors": [
        "Xingwei Qu",
        "Shaowen Wang",
        "Zihao Huang",
        "Kai Hua",
        "Fan Yin",
        "Rui-Jie Zhu",
        "Jundong Zhou",
        "Qiyang Min",
        "Zihao Wang",
        "Yizhi Li",
        "Tianyu Zhang",
        "He Xing",
        "Zheng Zhang",
        "Yuxuan Song",
        "Tianyu Zheng",
        "Zhiyuan Zeng",
        "Chenghua Lin",
        "Ge Zhang",
        "Wenhao Huang"
      ],
      "abstract": "Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\\textbf{decoupled $μ$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\\textbf{+2.69$\\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24617.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24617",
      "published": "2025-12-31T04:19:33Z",
      "updated": "2025-12-31T04:19:33Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了动态大型概念模型（DLCM），通过压缩标记到概念空间优化大语言模型的计算效率。",
        "motivation": "解决大语言模型对所有标记进行统一计算的问题，因语言信息密度不均匀导致计算分配不当和效率低下。",
        "method": "采用分层语言建模框架学习语义边界，将计算转移到压缩概念空间；引入压缩感知缩放定律和解耦μP参数化进行稳定训练。",
        "result": "在R=4设定下，重新分配约三分之一推理计算，在12个零样本基准测试中平均提升2.69%。",
        "conclusion": "贡献了DLCM框架和压缩感知缩放定律，优化计算分配并提高了推理性能。",
        "tags": [
          "Large Language Model",
          "Hierarchical Language Modeling",
          "Compression-aware Scaling",
          "μP Parametrization",
          "Latent Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:29.096544Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24615",
      "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
      "authors": [
        "Yuchen Shi",
        "Yuzheng Cai",
        "Siqi Cai",
        "Zihan Xu",
        "Lichao Chen",
        "Yulei Qin",
        "Zhijian Zhou",
        "Xiang Fei",
        "Chaofan Qiu",
        "Xiaoyu Tan",
        "Gang Li",
        "Zongyi Li",
        "Haojia Lin",
        "Guocan Cai",
        "Yong Mao",
        "Yunsheng Wu",
        "Ke Li",
        "Xing Sun"
      ],
      "abstract": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \\textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \\textbf{Workflow} mode for standard tasks and a \\textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \\textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \\textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\\%) and GAIA (72.8\\%) using open-weight models. Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively. Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24615.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24615",
      "published": "2025-12-31T04:17:36Z",
      "updated": "2025-12-31T04:17:36Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出Youtu-Agent框架，通过自动生成和混合策略优化实现LLM代理的持续进化与生产力提升。",
        "motivation": "解决现有LLM代理框架配置成本高、能力静态，无法适应动态环境且需要大量人工努力的问题。",
        "method": "提出模块化框架，包含结构化配置系统、两种自动生成范式以及由Agent Practice和Agent RL组成的混合策略优化系统。",
        "result": "在多个基准上达到SOTA性能，自动生成成功率超81%，策略优化模块带来显著性能提升，RL训练实现40%加速。",
        "conclusion": "Youtu-Agent框架显著降低了LLM代理的构建成本，并实现了其能力的自动化生成与持续优化。",
        "tags": [
          "Large Language Model Agents",
          "Automated Generation",
          "Reinforcement Learning",
          "Hybrid Policy Optimization",
          "Tool Synthesis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:36.012912Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24613",
      "title": "Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning",
      "authors": [
        "Zheyu Shi",
        "Dong Qiu",
        "Shanlong Yu"
      ],
      "abstract": "This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24613.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24613",
      "published": "2025-12-31T04:10:57Z",
      "updated": "2025-12-31T04:10:57Z",
      "comment": "Accepted by IEEE ITCA 2025",
      "light_analysis": {
        "overview": "提出了面向群体审议的多智能体对话模型，显著提升复杂推理任务的准确性和一致性。",
        "motivation": "解决单一大型语言模型在复杂推理任务中的局限性，提升推理能力。",
        "method": "采用三层角色分工架构，结合自我博弈机制和检索增强，使用复合奖励函数和改进近端策略优化进行协同训练。",
        "result": "在HotpotQA、2WikiMultihopQA和MeetingBank数据集上，多跳推理准确率分别提升16.8%、14.3%和19.2%，一致性提升21.5%。",
        "conclusion": "模型比主流多智能体方法更高效，为复杂推理任务提供了有效且稳定的解决方案。",
        "tags": [
          "Multi-Agent System",
          "Large Language Model",
          "Reinforcement Learning",
          "Retrieval-Augmented Generation",
          "Complex Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:06.949303Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24609",
      "title": "Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization",
      "authors": [
        "Dong Qiu",
        "Duo Xu",
        "Limengxi Yue"
      ],
      "abstract": "Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24609.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24609",
      "published": "2025-12-31T03:59:18Z",
      "updated": "2025-12-31T03:59:18Z",
      "comment": "Accepted by IEEE ICFTIC 2025",
      "light_analysis": {
        "overview": "提出强化学习增强的LLM多智能体框架，用于优化协作决策与全局性能。",
        "motivation": "解决大语言模型在多智能体环境中缺乏协作意识、难以优化全局性能的问题。",
        "method": "提出基于Dec-POMDP和CTDE的强化学习框架，引入GRPO算法与平衡任务质量、速度和协调成本的联合奖励。",
        "result": "在协作写作与编码任务中，处理速度提升3倍，写作一致性达98.7%，编码测试通过率达74.6%。",
        "conclusion": "该框架显著优于现有多智能体LLM基线，为复杂工作流中的可靠协作提供了实用路径。",
        "tags": [
          "Large Language Model",
          "Reinforcement Learning",
          "Multi-Agent Systems",
          "Dec-POMDP",
          "CTDE"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:02.515919Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24605",
      "title": "MoniRefer: A Real-world Large-scale Multi-modal Dataset based on Roadside Infrastructure for 3D Visual Grounding",
      "authors": [
        "Panquan Yang",
        "Junfei Huang",
        "Zongzhangbao Yin",
        "Yingsong Hu",
        "Anni Xu",
        "Xinyi Luo",
        "Xueqi Sun",
        "Hai Wu",
        "Sheng Ao",
        "Zhaoxing Zhu",
        "Chenglu Wen",
        "Cheng Wang"
      ],
      "abstract": "3D visual grounding aims to localize the object in 3D point cloud scenes that semantically corresponds to given natural language sentences. It is very critical for roadside infrastructure system to interpret natural languages and localize relevant target objects in complex traffic environments. However, most existing datasets and approaches for 3D visual grounding focus on the indoor and outdoor driving scenes, outdoor monitoring scenarios remain unexplored due to scarcity of paired point cloud-text data captured by roadside infrastructure sensors. In this paper, we introduce a novel task of 3D Visual Grounding for Outdoor Monitoring Scenarios, which enables infrastructure-level understanding of traffic scenes beyond the ego-vehicle perspective. To support this task, we construct MoniRefer, the first real-world large-scale multi-modal dataset for roadside-level 3D visual grounding. The dataset consists of about 136,018 objects with 411,128 natural language expressions collected from multiple complex traffic intersections in the real-world environments. To ensure the quality and accuracy of the dataset, we manually verified all linguistic descriptions and 3D labels for objects. Additionally, we also propose a new end-to-end method, named Moni3DVG, which utilizes the rich appearance information provided by images and geometry and optical information from point cloud for multi-modal feature learning and 3D object localization. Extensive experiments and ablation studies on the proposed benchmarks demonstrate the superiority and effectiveness of our method. Our dataset and code will be released.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24605.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24605",
      "published": "2025-12-31T03:56:28Z",
      "updated": "2025-12-31T03:56:28Z",
      "comment": "14 pages",
      "light_analysis": {
        "overview": "本文构建首个真实世界大规模多模态数据集MoniRefer并提出Moni3DVG方法，用于户外监控场景的3D视觉接地。",
        "motivation": "现有3D视觉接地数据集和方法主要关注室内和驾驶场景，缺乏户外监控场景的配对点云-文本数据，本研究旨在填补此空白。",
        "method": "提出端到端方法Moni3DVG，融合图像的外观信息和点云的几何光学信息，进行多模态特征学习和3D对象定位。",
        "result": "在构建的数据集上进行了广泛实验和消融研究，证明了所提方法的优越性和有效性。",
        "conclusion": "主要贡献包括引入户外监控场景的3D视觉接地任务、构建大规模数据集MoniRefer和提出有效方法Moni3DVG。",
        "tags": [
          "3D Visual Grounding",
          "Multi-modal Dataset",
          "Point Cloud Processing",
          "Natural Language Understanding",
          "Computer Vision"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:43.126650Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24603",
      "title": "Collaborative Low-Rank Adaptation for Pre-Trained Vision Transformers",
      "authors": [
        "Zheng Liu",
        "Jinchao Zhu",
        "Gao Huang"
      ],
      "abstract": "Low-rank adaptation (LoRA) has achieved remarkable success in fine-tuning pre-trained vision transformers for various downstream tasks. Existing studies mainly focus on exploring more parameter-efficient strategies or more effective representation learning schemes. However, these methods either sacrifice fine-tuning performance or introduce excessive trainable parameters, failing to strike a balance between learning performance and parameter efficiency. To address this problem, we propose a novel tuning method named collaborative low-rank adaptation (CLoRA) in this paper. CLoRA consists of base-space sharing and sample-agnostic diversity enhancement (SADE) components. To maintain parameter efficiency while expanding the learning capacity of low-rank modules (LRMs), base-space sharing allows all LRMs to share a set of down/up-projection spaces. In CLoRA, the low-rank matrices obtained from the shared spaces collaboratively construct each LRM. Since the representations extracted by these matrices may contain redundant information, SADE is employed to regularize the similarities among them to encourage diverse representations in the training process. We conduct extensive experiments on widely used image and point cloud datasets to evaluate the performance of CLoRA. Experimental results demonstrate that CLoRA strikes a better balance between learning performance and parameter efficiency, while requiring the fewest GFLOPs for point cloud analysis, compared with the state-of-the-art methods.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24603.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24603",
      "published": "2025-12-31T03:46:49Z",
      "updated": "2025-12-31T03:46:49Z",
      "comment": "13 tables, 3 figures",
      "light_analysis": {
        "overview": "提出CLoRA方法，用于微调视觉Transformer，以更好地平衡学习性能与参数效率。",
        "motivation": "现有低秩适应方法难以在微调性能与参数效率之间取得良好平衡。",
        "method": "提出协作低秩适应（CLoRA），包含基础空间共享组件和样本无关多样性增强（SADE）正则化组件。",
        "result": "在图像与点云数据集上的实验表明，CLoRA取得了更好的性能-效率平衡，且在点云分析中计算量最小。",
        "conclusion": "CLoRA是一种参数高效且性能优异的微调方法，为平衡学习性能与参数效率提供了新方案。",
        "tags": [
          "Low-rank Adaptation",
          "Vision Transformer",
          "Parameter-efficient Fine-tuning",
          "Contrastive Learning",
          "Point Cloud Analysis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:59.242964Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24601",
      "title": "Recursive Language Models",
      "authors": [
        "Alex L. Zhang",
        "Tim Kraska",
        "Omar Khattab"
      ],
      "abstract": "We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24601.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24601",
      "published": "2025-12-31T03:43:41Z",
      "updated": "2025-12-31T03:43:41Z",
      "comment": "9 pages, 33 with Appendix",
      "light_analysis": {
        "overview": "提出递归语言模型方法，使大语言模型能够处理远超其上下文窗口的任意长文本。",
        "motivation": "解决大语言模型受固定上下文窗口限制，无法处理任意长提示的问题。",
        "method": "提出递归语言模型推理策略，允许模型程序化地检查、分解长提示，并递归调用自身处理片段。",
        "result": "成功处理比上下文窗口长两个数量级的输入，在多个长上下文任务中性能显著优于基准模型。",
        "conclusion": "提供了一种高效扩展大语言模型上下文处理能力的通用推理框架。",
        "tags": [
          "Large Language Model",
          "Recursive Inference",
          "Context Window Extension",
          "Long-Context Processing",
          "Inference-Time Scaling"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:27.822528Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24592",
      "title": "SliceLens: Fine-Grained and Grounded Error Slice Discovery for Multi-Instance Vision Tasks",
      "authors": [
        "Wei Zhang",
        "Chaoqun Wang",
        "Zixuan Guan",
        "Sam Kao",
        "Pengfei Zhao",
        "Peng Wu",
        "Sifeng He"
      ],
      "abstract": "Systematic failures of computer vision models on subsets with coherent visual patterns, known as error slices, pose a critical challenge for robust model evaluation. Existing slice discovery methods are primarily developed for image classification, limiting their applicability to multi-instance tasks such as detection, segmentation, and pose estimation. In real-world scenarios, error slices often arise from corner cases involving complex visual relationships, where existing instance-level approaches lacking fine-grained reasoning struggle to yield meaningful insights. Moreover, current benchmarks are typically tailored to specific algorithms or biased toward image classification, with artificial ground truth that fails to reflect real model failures. To address these limitations, we propose SliceLens, a hypothesis-driven framework that leverages LLMs and VLMs to generate and verify diverse failure hypotheses through grounded visual reasoning, enabling reliable identification of fine-grained and interpretable error slices. We further introduce FeSD (Fine-grained Slice Discovery), the first benchmark specifically designed for evaluating fine-grained error slice discovery across instance-level vision tasks, featuring expert-annotated and carefully refined ground-truth slices with precise grounding to local error regions. Extensive experiments on both existing benchmarks and FeSD demonstrate that SliceLens achieves state-of-the-art performance, improving Precision@10 by 0.42 (0.73 vs. 0.31) on FeSD, and identifies interpretable slices that facilitate actionable model improvements, as validated through model repair experiments.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24592.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24592",
      "published": "2025-12-31T03:28:41Z",
      "updated": "2025-12-31T03:28:41Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了SliceLens框架和FeSD基准，用于多实例视觉任务的细粒度错误切片发现。",
        "motivation": "解决现有错误切片发现方法对多实例视觉任务不适用、缺乏细粒度推理，以及基准测试不足的问题。",
        "method": "提出SliceLens，一个基于假设的框架，利用大型语言模型和视觉语言模型通过基于视觉的推理生成和验证失败假设。",
        "result": "在FeSD基准上，Precision@10提高了0.42（从0.31到0.73），达到state-of-the-art，并通过模型修复实验验证了可操作改进。",
        "conclusion": "SliceLens能可靠识别细粒度和可解释的错误切片，促进模型改进，具有实际应用价值。",
        "tags": [
          "Large Language Model",
          "Visual Language Model",
          "Error Slice Discovery",
          "Fine-Grained Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:18.524374Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24591",
      "title": "Improving Few-Shot Change Detection Visual Question Answering via Decision-Ambiguity-guided Reinforcement Fine-Tuning",
      "authors": [
        "Fuyu Dong",
        "Ke Li",
        "Di Wang",
        "Nan Luo",
        "Yiming Zhang",
        "Kaiyu Li",
        "Jianfei Yang",
        "Quan Wang"
      ],
      "abstract": "Change detection visual question answering (CDVQA) requires answering text queries by reasoning about semantic changes in bi-temporal remote sensing images. A straightforward approach is to boost CDVQA performance with generic vision-language models via supervised fine-tuning (SFT). Despite recent progress, we observe that a significant portion of failures do not stem from clearly incorrect predictions, but from decision ambiguity, where the model assigns similar confidence to the correct answer and strong distractors. To formalize this challenge, we define Decision-Ambiguous Samples (DAS) as instances with a small probability margin between the ground-truth answer and the most competitive alternative. We argue that explicitly optimizing DAS is crucial for improving the discriminability and robustness of CDVQA models. To this end, we propose DARFT, a Decision-Ambiguity-guided Reinforcement Fine-Tuning framework that first mines DAS using an SFT-trained reference policy and then applies group-relative policy optimization on the mined subset. By leveraging multi-sample decoding and intra-group relative advantages, DARFT suppresses strong distractors and sharpens decision boundaries without additional supervision. Extensive experiments demonstrate consistent gains over SFT baselines, particularly under few-shot settings.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24591.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24591",
      "published": "2025-12-31T03:28:17Z",
      "updated": "2025-12-31T03:28:17Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出DARFT框架，通过决策模糊性指导的强化微调解决少样本CDVQA的判别力不足问题。",
        "motivation": "传统监督微调（SFT）后的模型常在决策模糊样本上失败，即对正确答案与强干扰项置信度相近，阻碍性能提升。",
        "method": "提出DARFT框架：先用SFT策略挖掘决策模糊样本，然后基于组内相对优势进行策略优化，以抑制干扰项、锐化决策边界。",
        "result": "在广泛实验中，DARFT相比SFT基线取得一致性能提升，尤其在少样本设置下效果显著。",
        "conclusion": "通过针对性地优化决策模糊样本，能有效提升CDVQA模型的判别力和鲁棒性，而无需额外监督信号。",
        "tags": [
          "Change Detection VQA",
          "Reinforcement Learning Fine-Tuning",
          "Few-Shot Learning",
          "Decision Ambiguity",
          "Policy Optimization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:21.915116Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24574",
      "title": "Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time",
      "authors": [
        "Zhenyu Zhang",
        "Xiaoxia Wu",
        "Zhongzhu Zhou",
        "Qingyang Wu",
        "Yineng Zhang",
        "Pragaash Ponnusamy",
        "Harikaran Subbaraj",
        "Jue Wang",
        "Shuaiwen Leon Song",
        "Ben Athiwaratkun"
      ],
      "abstract": "Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct cognitive behaviors such as verification and backtracking. By lightly intervening on these heads at inference time, we can steer the model away from inefficient modes. Building on this insight, we propose CREST, a training-free method for Cognitive REasoning Steering at Test-time. CREST has two components: (1) an offline calibration step that identifies cognitive heads and derives head-specific steering vectors, and (2) an inference-time procedure that rotates hidden representations to suppress components along those vectors. CREST adaptively suppresses unproductive reasoning behaviors, yielding both higher accuracy and lower computational cost. Across diverse reasoning benchmarks and models, CREST improves accuracy by up to 17.5% while reducing token usage by 37.6%, offering a simple and effective pathway to faster, more reliable LLM reasoning.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24574.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24574",
      "published": "2025-12-31T02:46:04Z",
      "updated": "2025-12-31T02:46:04Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出无需训练的测试时推理引导方法CREST，通过干预注意力头提升大语言模型推理效率与准确率。",
        "motivation": "大语言模型的链式思考推理常效率低下，导致高延迟和不稳定（如思考过浅或冗长）。",
        "method": "提出了CREST方法，先离线识别与特定认知行为相关的注意力头并计算干预向量，然后在推理时旋转隐藏表示以抑制低效行为。",
        "result": "在多个基准测试中，准确率最高提升17.5%，同时Token使用量减少37.6%。",
        "conclusion": "CREST为提升大语言模型推理速度与可靠性提供了一种简单有效的免训练路径。",
        "tags": [
          "Large Language Model",
          "Chain-of-Thought reasoning",
          "Attention Heads",
          "Test-time intervention"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:59.472834Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24565",
      "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use",
      "authors": [
        "Wenrui Liu",
        "Zixiang Liu",
        "Elsie Dai",
        "Wenhan Yu",
        "Lei Yu",
        "Tong Yang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24565.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24565",
      "published": "2025-12-31T02:09:48Z",
      "updated": "2025-12-31T02:09:48Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一个评估LLM智能体MCP工具使用能力的真实世界任务基准MCPAgentBench。",
        "motivation": "解决现有MCP评估集依赖外部服务、缺乏难度感知的问题。",
        "method": "构建了包含真实任务和模拟工具的数据集，采用带干扰项的动态沙盒环境和综合指标进行评估。",
        "result": "实验揭示了不同主流LLM在处理复杂多步骤工具调用时存在显著性能差异，所有代码已开源。",
        "conclusion": "贡献了一个基于真实MCP定义的基准，能更好地评估智能体工具选择与使用能力。",
        "tags": [
          "Large Language Model",
          "LLM Agent",
          "Tool Use",
          "Model Context Protocol",
          "Benchmark Evaluation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:28.965505Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24564",
      "title": "CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts",
      "authors": [
        "Shunbo Jia",
        "Caizhi Liao"
      ],
      "abstract": "Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24564.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24564",
      "published": "2025-12-31T02:08:34Z",
      "updated": "2025-12-31T02:08:34Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出 CPR 方法，通过因果解缠学习鲁棒 ECG 表示，以应对分布偏移下的对抗性攻击。",
        "motivation": "ECG 深度学习模型对对抗性扰动脆弱，现有防御方法计算负担重或延迟高，不适合实时临床监测。",
        "method": "CPR 在因果解缠框架中融入生理结构先验，通过结构因果模型建模 ECG 生成，分离病理特征。",
        "result": "在 PTB-XL 数据集上，CPR 在 SAP 攻击下 F1 分数 0.632，优于基线，同时保持高效推理。",
        "conclusion": "CPR 在鲁棒性、效率和临床可解释性间提供优越权衡，为实时 ECG 分析提供实用解决方案。",
        "tags": [
          "Causal Representation Learning",
          "Adversarial Robustness",
          "Structural Causal Model",
          "ECG Analysis",
          "Disentanglement"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:09.681345Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24562",
      "title": "HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering",
      "authors": [
        "Chaodong Tong",
        "Qi Zhang",
        "Jiayang Gao",
        "Lei Jiang",
        "Yanbing Liu",
        "Nannan Sun"
      ],
      "abstract": "Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods often aim to accurately capture a single type of uncertainty while overlooking the complementarity among different sources, particularly between token-level probability uncertainty and the uncertainty conveyed by internal semantic representations, which provide complementary views on model reliability. We present \\textbf{HaluNet}, a lightweight and trainable neural framework that integrates multi granular token level uncertainties by combining semantic embeddings with probabilistic confidence and distributional uncertainty. Its multi branch architecture adaptively fuses what the model knows with the uncertainty expressed in its outputs, enabling efficient one pass hallucination detection. Experiments on SQuAD, TriviaQA, and Natural Questions show that HaluNet delivers strong detection performance and favorable computational efficiency, with or without access to context, highlighting its potential for real time hallucination detection in LLM based QA systems.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24562.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24562",
      "published": "2025-12-31T02:03:10Z",
      "updated": "2025-12-31T02:03:10Z",
      "comment": "13 pages, 5 figures",
      "light_analysis": {
        "overview": "提出HaluNet，一个集成多粒度不确定性建模的轻量级框架，用于LLM问答中的高效幻觉检测。",
        "motivation": "现有方法常忽略不同不确定性来源（如概率和语义）的互补性，限制了基于内部信号的幻觉检测效果。",
        "method": "提出HaluNet，通过多分支架构融合语义嵌入与概率置信度及分布不确定性，实现一次性幻觉检测。",
        "result": "在SQuAD等数据集上，无论能否访问上下文，均展现出强大的检测性能和良好的计算效率。",
        "conclusion": "该轻量级可训练框架有效整合多粒度不确定性，为LLM问答系统实现实时幻觉检测提供了潜力。",
        "tags": [
          "Hallucination Detection",
          "Uncertainty Quantification",
          "Large Language Model",
          "Question Answering",
          "Semantic Embedding"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:50.342974Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24561",
      "title": "RGBT-Ground Benchmark: Visual Grounding Beyond RGB in Complex Real-World Scenarios",
      "authors": [
        "Tianyi Zhao",
        "Jiawen Xi",
        "Linhui Xiao",
        "Junnan Li",
        "Xue Yang",
        "Maoxun Yuan",
        "Xingxing Wei"
      ],
      "abstract": "Visual Grounding (VG) aims to localize specific objects in an image according to natural language expressions, serving as a fundamental task in vision-language understanding. However, existing VG benchmarks are mostly derived from datasets collected under clean environments, such as COCO, where scene diversity is limited. Consequently, they fail to reflect the complexity of real-world conditions, such as changes in illumination, weather, etc., that are critical to evaluating model robustness and generalization in safety-critical applications. To address these limitations, we present RGBT-Ground, the first large-scale visual grounding benchmark built for complex real-world scenarios. It consists of spatially aligned RGB and Thermal infrared (TIR) image pairs with high-quality referring expressions, corresponding object bounding boxes, and fine-grained annotations at the scene, environment, and object levels. This benchmark enables comprehensive evaluation and facilitates the study of robust grounding under diverse and challenging conditions. Furthermore, we establish a unified visual grounding framework that supports both uni-modal (RGB or TIR) and multi-modal (RGB-TIR) visual inputs. Based on it, we propose RGBT-VGNet, a simple yet effective baseline for fusing complementary visual modalities to achieve robust grounding. We conduct extensive adaptations to the existing methods on RGBT-Ground. Experimental results show that our proposed RGBT-VGNet significantly outperforms these adapted methods, particularly in nighttime and long-distance scenarios. All resources will be publicly released to promote future research on robust visual grounding in complex real-world environments.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24561.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24561",
      "published": "2025-12-31T02:01:02Z",
      "updated": "2025-12-31T02:01:02Z",
      "comment": "27pages, 9figures",
      "light_analysis": {
        "overview": "提出首个用于复杂真实世界场景的 RGB-TIR 视觉接地基准和一个有效的多模态融合基线模型。",
        "motivation": "现有视觉接地基准缺乏真实世界复杂性（如光照、天气变化），无法评估模型鲁棒性，因此需要新基准。",
        "method": "创建 RGBT-Ground 基准，包含空间对齐的 RGB 和热红外图像对；建立统一框架支持单模态和多模态输入，并提出 RGBT-VGNet 模型进行多模态融合。",
        "result": "RGBT-VGNet 在 RGBT-Ground 上显著优于其他适应方法，尤其在夜间和远距离场景中表现突出。",
        "conclusion": "主要贡献是推出新基准和基线模型，促进复杂真实世界环境中鲁棒视觉接地的未来研究。",
        "tags": [
          "Visual Grounding",
          "Benchmark",
          "Multi-modal Fusion",
          "Thermal Infrared",
          "Robustness"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:01.678630Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24556",
      "title": "Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs",
      "authors": [
        "Muhammad Abdullahi Said",
        "Muhammad Sammani Sani"
      ],
      "abstract": "As Large Language Models (LLMs) integrate into critical global infrastructure, the assumption that safety alignment transfers zero-shot from English to other languages remains a dangerous blind spot. This study presents a systematic audit of three state of the art models (GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus) using HausaSafety, a novel adversarial dataset grounded in West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). Employing a 2 x 4 factorial design across 1,440 evaluations, we tested the non-linear interaction between language (English vs. Hausa) and temporal framing. Our results challenge the prevailing multilingual safety gap narrative. Instead of a simple degradation in low-resource settings, we identified a mechanism of Complex Interference where safety is determined by the intersection of variables. While models exhibited a Reverse Linguistic with Claude 4.5 Opus proving significantly safer in Hausa (45.0%) than in English (36.7%) due to uncertainty-driven refusal they suffered catastrophic failures in temporal reasoning. We report a profound Temporal Asymmetry, where past-tense framing bypassed defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). The magnitude of this volatility is illustrated by a 9.2x disparity between the safest and most vulnerable configurations, proving that safety is not a fixed property but a context-dependent state. We conclude that current models rely on superficial heuristics rather than robust semantic understanding, creating Safety Pockets that leave Global South users exposed to localized harms. We propose Invariant Alignment as a necessary paradigm shift to ensure safety stability across linguistic and temporal shifts.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24556.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24556",
      "published": "2025-12-31T01:40:07Z",
      "updated": "2025-12-31T01:40:07Z",
      "comment": null,
      "light_analysis": {
        "overview": "本文系统审计LLMs在多语言和时态下的安全性漏洞，揭示安全是上下文依赖的，并提出不变对齐新范式。",
        "motivation": "解决LLMs安全对齐零-shot从英语转移到低资源语言的盲点问题，评估其在全球南方用户中的本地化危害风险。",
        "method": "使用新颖对抗数据集HausaSafety，对三个先进LLMs进行2x4因子设计审计，测试语言（英语vs豪萨语）与时态的交互作用。",
        "result": "发现复杂干扰机制，模型在豪萨语中可能更安全但时态推理失败；过去时绕过防御（15.6%安全），未来时触发过度拒绝（57.2%安全）。",
        "conclusion": "LLMs安全性依赖表面启发式而非鲁棒语义理解，提出不变对齐作为范式转变以确保跨语言和时态的安全稳定性。",
        "tags": [
          "Large Language Model",
          "Multilingual Safety",
          "Temporal Reasoning",
          "Invariant Alignment",
          "Adversarial Evaluation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:32.280890Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24555",
      "title": "From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme",
      "authors": [
        "Xueyan Li",
        "Yingyi Xue",
        "Mengjie Jiang",
        "Qingzi Zhu",
        "Yazhe Niu"
      ],
      "abstract": "Generating humorous memes is a challenging multimodal task that moves beyond direct image-to-caption supervision. It requires a nuanced reasoning over visual content, contextual cues, and subjective humor. To bridge this gap between visual perception and humorous punchline creation, we propose HUMOR}, a novel framework that guides VLMs through hierarchical reasoning and aligns them with group-wise human preferences. First, HUMOR employs a hierarchical, multi-path Chain-of-Thought (CoT): the model begins by identifying a template-level intent, then explores diverse reasoning paths under different contexts, and finally anchors onto a high-quality, context-specific path. This CoT supervision, which traces back from ground-truth captions, enhances reasoning diversity. We further analyze that this multi-path exploration with anchoring maintains a high expected humor quality, under the practical condition that high-quality paths retain significant probability mass. Second, to capture subjective humor, we train a pairwise reward model that operates within groups of memes sharing the same template. Following established theory, this approach ensures a consistent and robust proxy for human preference, even with subjective and noisy labels. The reward model then enables a group-wise reinforcement learning optimization, guaranteeing providing a theoretical guarantee for monotonic improvement within the trust region. Extensive experiments show that HUMOR empowers various VLMs with superior reasoning diversity, more reliable preference alignment, and higher overall meme quality. Beyond memes, our work presents a general training paradigm for open-ended, human-aligned multimodal generation, where success is guided by comparative judgment within coherent output group.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24555.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24555",
      "published": "2025-12-31T01:35:49Z",
      "updated": "2025-12-31T01:35:49Z",
      "comment": "46 pages, 20 figures",
      "light_analysis": {
        "overview": "提出了HUMOR框架，通过分层推理和群体偏好对齐，提升视觉语言模型生成幽默表情包的能力。",
        "motivation": "解决幽默表情包生成中视觉感知与幽默创作之间的差距，需处理多模态推理和主观幽默理解。",
        "method": "采用分层多路径思维链监督和基于群体成对奖励模型的强化学习，增强推理多样性和对齐人类偏好。",
        "result": "实验表明，HUMOR提升了多种视觉语言模型的推理多样性、偏好对齐和表情包整体质量。",
        "conclusion": "贡献了一个通用的开放端、人类对齐多模态生成训练范式，适用于超越表情包的应用。",
        "tags": [
          "Visual Language Model",
          "Chain-of-Thought",
          "Reinforcement Learning",
          "Multimodal Generation",
          "Preference Alignment"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:37.433439Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24552",
      "title": "OCP-LS: An Efficient Algorithm for Visual Localization",
      "authors": [
        "Jindi Zhong",
        "Hongxia Wang",
        "Huanshui Zhang"
      ],
      "abstract": "This paper proposes a novel second-order optimization algorithm. It aims to address large-scale optimization problems in deep learning because it incorporates the OCP method and appropriately approximating the diagonal elements of the Hessian matrix. Extensive experiments on multiple standard visual localization benchmarks demonstrate the significant superiority of the proposed method. Compared with conventional optimiza tion algorithms, our framework achieves competitive localization accuracy while exhibiting faster convergence, enhanced training stability, and improved robustness to noise interference.",
      "categories": [
        "cs.CV",
        "math.OC"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24552.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24552",
      "published": "2025-12-31T01:21:08Z",
      "updated": "2025-12-31T01:21:08Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出OCP-LS二阶优化算法，通过结合OCP方法并近似Hessian对角元素，高效解决视觉定位中的大规模优化问题。",
        "motivation": "解决深度学习中的大规模优化问题，特别是在视觉定位任务中，以提高优化效率和性能。",
        "method": "提出一种新的二阶优化算法，结合OCP方法并适当近似Hessian矩阵的对角元素。",
        "result": "在多个标准视觉定位基准测试中表现优势，具有更快收敛速度、增强训练稳定性和对噪声干扰的鲁棒性。",
        "conclusion": "OCP-LS算法在视觉定位中实现了竞争性精度，并改进了优化性能，贡献了一种高效的优化方法。",
        "tags": [
          "Second-order Optimization",
          "OCP Method",
          "Hessian Approximation",
          "Visual Localization",
          "Deep Learning Optimization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:32.916514Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24551",
      "title": "PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation",
      "authors": [
        "Yuanhao Cai",
        "Kunpeng Li",
        "Menglin Jia",
        "Jialiang Wang",
        "Junzhe Sun",
        "Feng Liang",
        "Weifeng Chen",
        "Felix Juefei-Xu",
        "Chu Wang",
        "Ali Thabet",
        "Xiaoliang Dai",
        "Xuan Ju",
        "Alan Yuille",
        "Ji Hou"
      ],
      "abstract": "Recent advances in text-to-video (T2V) generation have achieved good visual quality, yet synthesizing videos that faithfully follow physical laws remains an open challenge. Existing methods mainly based on graphics or prompt extension struggle to generalize beyond simple simulated environments or learn implicit physical reasoning. The scarcity of training data with rich physics interactions and phenomena is also a problem. In this paper, we first introduce a Physics-Augmented video data construction Pipeline, PhyAugPipe, that leverages a vision-language model (VLM) with chain-of-thought reasoning to collect a large-scale training dataset, PhyVidGen-135K. Then we formulate a principled Physics-aware Groupwise Direct Preference Optimization, PhyGDPO, framework that builds upon the groupwise Plackett-Luce probabilistic model to capture holistic preferences beyond pairwise comparisons. In PhyGDPO, we design a Physics-Guided Rewarding (PGR) scheme that embeds VLM-based physics rewards to steer optimization toward physical consistency. We also propose a LoRA-Switch Reference (LoRA-SR) scheme that eliminates memory-heavy reference duplication for efficient training. Experiments show that our method significantly outperforms state-of-the-art open-source methods on PhyGenBench and VideoPhy2. Please check our project page at https://caiyuanhao1998.github.io/project/PhyGDPO for more video results. Our code, models, and data will be released at https://github.com/caiyuanhao1998/Open-PhyGDPO",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24551.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24551",
      "published": "2025-12-31T01:19:14Z",
      "updated": "2025-12-31T01:19:14Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了PhyGDPO框架和PhyAugPipe数据管道，用于实现物理一致的文本到视频生成。",
        "motivation": "解决现有文本到视频生成方法难以遵循物理规律、数据稀缺的挑战。",
        "method": "使用PhyAugPipe构建数据集，PhyGDPO框架基于群组Plackett-Luce模型，集成VLM物理奖励和LoRA-SR高效训练方案。",
        "result": "在PhyGenBench和VideoPhy2基准上显著优于最先进开源方法。",
        "conclusion": "贡献了物理感知的偏好优化方法和数据集，提升了视频生成的物理一致性。",
        "tags": [
          "Text-to-Video Generation",
          "Direct Preference Optimization",
          "Plackett-Luce Model",
          "Vision-Language Model",
          "LoRA"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:45.000075Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24545",
      "title": "More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization",
      "authors": [
        "Yuma Ichikawa",
        "Yoshihiko Fujisawa",
        "Yudai Fujimoto",
        "Akira Sakai",
        "Katsuki Fujisawa"
      ],
      "abstract": "For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank-$l$ envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24545.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24545",
      "published": "2025-12-31T01:04:34Z",
      "updated": "2025-12-31T01:04:34Z",
      "comment": "14 pages, 2 figures",
      "light_analysis": {
        "overview": "提出多包络双二进制分解方法，以提升大语言模型极端量化性能并解决现有方法的局限性。",
        "motivation": "现有双二进制分解在极端量化中缩放参数限制导致性能饱和，需要改进以提升幅度表达能力。",
        "method": "引入秩-l包络替换单包络，保留共享符号矩阵，并采用闭式初始化和交替优化方法进行训练。",
        "result": "在LLaMA和Qwen模型家族上，MDBF在相同比特权重下相比之前二进制格式提高了困惑度和零样本准确性。",
        "conclusion": "MDBF在保持部署友好推理的同时，通过增强幅度表达能力有效提升了量化模型的性能。",
        "tags": [
          "Large Language Model",
          "Extreme Quantization",
          "Binary Factorization",
          "Model Compression",
          "Optimization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:05.560338Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24532",
      "title": "From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning",
      "authors": [
        "Amir Tahmasbi",
        "Sadegh Majidi",
        "Kazem Taram",
        "Aniket Bera"
      ],
      "abstract": "Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24532.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24532",
      "published": "2025-12-31T00:36:03Z",
      "updated": "2025-12-31T00:36:03Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一个两阶段方法，结合监督微调和强化学习，提升大型语言模型在空间推理和多步骤规划中的性能。",
        "motivation": "大型语言模型在空间变换和多步骤规划方面存在困难，影响导航和规划等应用，因此需要改进其空间推理能力。",
        "method": "采用两阶段方法：首先用监督微调学习基本空间变换（如旋转、平移和缩放），然后冻结模型，在GRPO框架中训练LoRA适配器进行多步骤规划；并合成了ASCII-art数据集和构建强化学习环境。",
        "result": "方法在动态和静态环境中均优于基线模型（包括通用骨干、物理感知模型和端到端RL），收敛更快、训练更稳定，并通过注意力分析验证了空间理解的改进。",
        "conclusion": "该方法通过分解空间推理为构建块并组合它们，有效提升了大型语言模型的多步骤规划能力，为空间推理研究提供了新思路。",
        "tags": [
          "Large Language Model",
          "Reinforcement Learning",
          "Supervised Fine-Tuning",
          "LoRA",
          "Spatial Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:30.973941Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24518",
      "title": "Using Large Language Models To Translate Machine Results To Human Results",
      "authors": [
        "Trishna Niraula",
        "Jonathan Stubblefield"
      ],
      "abstract": "Artificial intelligence (AI) has transformed medical imaging, with computer vision (CV) systems achieving state-of-the-art performance in classification and detection tasks. However, these systems typically output structured predictions, leaving radiologists responsible for translating results into full narrative reports. Recent advances in large language models (LLMs), such as GPT-4, offer new opportunities to bridge this gap by generating diagnostic narratives from structured findings. This study introduces a pipeline that integrates YOLOv5 and YOLOv8 for anomaly detection in chest X-ray images with a large language model (LLM) to generate natural-language radiology reports. The YOLO models produce bounding-box predictions and class labels, which are then passed to the LLM to generate descriptive findings and clinical summaries. YOLOv5 and YOLOv8 are compared in terms of detection accuracy, inference latency, and the quality of generated text, as measured by cosine similarity to ground-truth reports. Results show strong semantic similarity between AI and human reports, while human evaluation reveals GPT-4 excels in clarity (4.88/5) but exhibits lower scores for natural writing flow (2.81/5), indicating that current systems achieve clinical accuracy but remain stylistically distinguishable from radiologist-authored text.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24518.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24518",
      "published": "2025-12-30T23:32:04Z",
      "updated": "2025-12-30T23:32:04Z",
      "comment": "11 pages, 7 figures, 3 tables",
      "light_analysis": {
        "overview": "提出一个结合YOLO目标检测和大型语言模型的管道，自动生成胸片放射学报告。",
        "motivation": "解决医学影像中AI系统输出结构化预测，需人工转换为叙述报告的问题，利用LLM自动生成报告以减轻放射科医生负担。",
        "method": "集成YOLOv5和YOLOv8进行异常检测，然后将检测结果输入大型语言模型（如GPT-4）生成自然语言报告。",
        "result": "AI生成报告与人类报告语义相似度高，GPT-4在清晰度上得4.88/5，但自然写作流程仅2.81/5。",
        "conclusion": "系统实现了临床准确性，但在写作风格上与放射科医生文本仍有差距，为自动报告生成提供了可行方案。",
        "tags": [
          "Large Language Model",
          "YOLO",
          "Computer Vision",
          "Medical Imaging",
          "Natural Language Generation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:51.906291Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24517",
      "title": "Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech",
      "authors": [
        "Fabian Retkowski",
        "Alexander Waibel"
      ],
      "abstract": "Automatic speech transcripts are often delivered as unstructured word streams that impede readability and repurposing. We recast paragraph segmentation as the missing structuring step and fill three gaps at the intersection of speech processing and text segmentation. First, we establish TEDPara (human-annotated TED talks) and YTSegPara (YouTube videos with synthetic labels) as the first benchmarks for the paragraph segmentation task. The benchmarks focus on the underexplored speech domain, where paragraph segmentation has traditionally not been part of post-processing, while also contributing to the wider text segmentation field, which still lacks robust and naturalistic benchmarks. Second, we propose a constrained-decoding formulation that lets large language models insert paragraph breaks while preserving the original transcript, enabling faithful, sentence-aligned evaluation. Third, we show that a compact model (MiniSeg) attains state-of-the-art accuracy and, when extended hierarchically, jointly predicts chapters and paragraphs with minimal computational cost. Together, our resources and methods establish paragraph segmentation as a standardized, practical task in speech processing.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24517.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24517",
      "published": "2025-12-30T23:29:51Z",
      "updated": "2025-12-30T23:29:51Z",
      "comment": null,
      "light_analysis": {
        "overview": "本文提出并标准化了语音处理中的段落分割任务，通过建立新基准、新方法和高效模型推动该领域发展。",
        "motivation": "自动语音转录结果通常是无结构的词流，阻碍可读性和再利用，需要结构化的段落分割作为后处理步骤。",
        "method": "建立TEDPara和YTSegPara基准；提出基于大语言模型的约束解码方法插入段落断点；开发高效的紧凑模型MiniSeg。",
        "result": "MiniSeg模型达到最优准确率，并扩展为层级模型，能以极低成本联合预测章节和段落。",
        "conclusion": "研究通过提供资源和标准化方法，确立了段落分割作为语音处理中一个实用且标准化的任务。",
        "tags": [
          "Text Segmentation",
          "Large Language Model",
          "Constrained Decoding",
          "Benchmark Dataset",
          "Speech Processing"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:36.334892Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24506",
      "title": "Generalising E-prop to Deep Networks",
      "authors": [
        "Beren Millidge"
      ],
      "abstract": "Recurrent networks are typically trained with backpropagation through time (BPTT). However, BPTT requires storing the history of all states in the network and then replaying them sequentially backwards in time. This computation appears extremely implausible for the brain to implement. Real Time Recurrent Learning (RTRL) proposes an mathematically equivalent alternative where gradient information is propagated forwards in time locally alongside the regular forward pass, however it has significantly greater computational complexity than BPTT which renders it impractical for large networks. E-prop proposes an approximation of RTRL which reduces its complexity to the level of BPTT while maintaining a purely online forward update which can be implemented by an eligibility trace at each synapse. However, works on RTRL and E-prop ubiquitously investigate learning in a single layer with recurrent dynamics. However, learning in the brain spans multiple layers and consists of both hierarchal dynamics in depth as well as time. In this mathematical note, we extend the E-prop framework to handle arbitrarily deep networks, deriving a novel recursion relationship across depth which extends the eligibility traces of E-prop to deeper layers. Our results thus demonstrate an online learning algorithm can perform accurate credit assignment across both time and depth simultaneously, allowing the training of deep recurrent networks without backpropagation through time.",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24506.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24506",
      "published": "2025-12-30T23:10:12Z",
      "updated": "2025-12-30T23:10:12Z",
      "comment": "30/12/25 initial upload",
      "light_analysis": {
        "overview": "将在线学习算法E-prop扩展至任意深度网络，实现无需通过时间反向传播的深度循环网络训练。",
        "motivation": "传统的E-prop算法仅适用于单层循环网络，无法处理大脑中存在的多层、具有时空层次结构的信用分配问题。",
        "method": "推导了一种新的跨深度递归关系，将E-prop中的资格迹机制扩展到更深层的网络结构中。",
        "result": "证明了该在线学习算法能够同时跨时间和深度进行准确的信用分配，成功训练深度循环网络。",
        "conclusion": "将E-prop框架扩展到深度网络，为实现类脑、无需BPTT的在线深度学习算法提供了理论基础。",
        "tags": [
          "Online Learning",
          "Recurrent Neural Networks",
          "E-prop",
          "Gradient Approximation",
          "Credit Assignment"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:36.004181Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24505",
      "title": "Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems",
      "authors": [
        "Samuel Golladay",
        "Majid Bani-Yaghoub"
      ],
      "abstract": "Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24505.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24505",
      "published": "2025-12-30T23:05:11Z",
      "updated": "2025-12-30T23:05:11Z",
      "comment": "7 pages, submitted to ACM Transactions on Intelligent Systems and Technology",
      "light_analysis": {
        "overview": "通过 underrepresented 数学竞赛问题评估大型语言模型的推理能力，并分析其错误模式。",
        "motivation": "现有研究使用相同数据集评估LLMs数学推理，局限性大；本研究使用 underrepresented 数学竞赛问题以更全面评估。",
        "method": "使用密苏里大学数学竞赛问题提示三个LLMs，比较响应与正确答案，分析错误类型。",
        "result": "DeepSeek-V3在所有数学类别表现最佳，但所有模型在几何方面弱；错误模式因模型而异。",
        "conclusion": "使用 underrepresented 数据集评估能深入理解LLMs错误模式，突出结构化推理挑战，尤其是几何领域。",
        "tags": [
          "Large Language Model",
          "Mathematical Reasoning",
          "Benchmarking",
          "Error Analysis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:47.918086Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24504",
      "title": "Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments",
      "authors": [
        "Zhiwei Wei",
        "Yuxing Liu",
        "Hua Liao",
        "Wenjia Xu"
      ],
      "abstract": "Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24504.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24504",
      "published": "2025-12-30T23:04:29Z",
      "updated": "2025-12-30T23:04:29Z",
      "comment": "43 pages, 8 figures",
      "light_analysis": {
        "overview": "提出交互式评估框架，分析基础模型代理在地图环境中的探索、记忆和推理能力。",
        "motivation": "现有评估依赖静态输入，忽视交互性，需研究基础模型代理在动态地图环境中的空间理解。",
        "method": "使用交互式框架，让代理探索符号地图，基于局部观察执行六种空间任务，并比较探索策略、记忆表示和推理方案。",
        "result": "探索影响经验获取但推理准确性有限；结构化记忆提升路径规划等任务性能；推理方案优化知识使用；性能在模型规模超过阈值后饱和。",
        "conclusion": "揭示了探索、记忆和推理组件的功能角色，表明提升地图空间理解需专门机制而非仅扩展模型规模。",
        "tags": [
          "Foundation Model",
          "Interactive Evaluation",
          "Spatial Reasoning",
          "Memory Representation",
          "Graph-based Representation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:13.048791Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24503",
      "title": "Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice",
      "authors": [
        "Jiachen T. Wang",
        "Tong Wu",
        "Kaifeng Lyu",
        "James Zou",
        "Dawn Song",
        "Ruoxi Jia",
        "Prateek Mittal"
      ],
      "abstract": "Data teams at frontier AI companies routinely train small proxy models to make critical decisions about pretraining data recipes for full-scale training runs. However, the community has a limited understanding of whether and when conclusions drawn from small-scale experiments reliably transfer to full-scale model training. In this work, we uncover a subtle yet critical issue in the standard experimental protocol for data recipe assessment: the use of identical small-scale model training configurations across all data recipes in the name of \"fair\" comparison. We show that the experiment conclusions about data quality can flip with even minor adjustments to training hyperparameters, as the optimal training configuration is inherently data-dependent. Moreover, this fixed-configuration protocol diverges from full-scale model development pipelines, where hyperparameter optimization is a standard step. Consequently, we posit that the objective of data recipe assessment should be to identify the recipe that yields the best performance under data-specific tuning. To mitigate the high cost of hyperparameter tuning, we introduce a simple patch to the evaluation protocol: using reduced learning rates for proxy model training. We show that this approach yields relative performance that strongly correlates with that of fully tuned large-scale LLM pretraining runs. Theoretically, we prove that for random-feature models, this approach preserves the ordering of datasets according to their optimal achievable loss. Empirically, we validate this approach across 23 data recipes covering four critical dimensions of data curation, demonstrating dramatic improvements in the reliability of small-scale experiments.",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24503.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24503",
      "published": "2025-12-30T23:02:44Z",
      "updated": "2025-12-30T23:02:44Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出使用降低学习率训练代理模型的方法，以提高数据配方评估的可靠性。",
        "motivation": "解决使用固定配置的小代理模型评估数据配方时结论不可靠的问题，因为最优训练配置是数据依赖的。",
        "method": "修改评估协议，使用降低的学习率来训练代理模型，以模拟数据特定调优的效果。",
        "result": "理论证明该方法保留数据集根据最优损失的排序，实证验证在23个数据配方上性能与大规模训练强相关。",
        "conclusion": "该方法显著提高了小规模实验的可靠性，能更准确地指导数据策展决策。",
        "tags": [
          "Proxy Models",
          "Data Curation",
          "Hyperparameter Tuning",
          "Large Language Model",
          "Pretraining"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:28.538434Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24478",
      "title": "HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors",
      "authors": [
        "Hyunjun Kim"
      ],
      "abstract": "Causal discovery from observational data remains fundamentally limited by identifiability constraints. Recent work has explored leveraging Large Language Models (LLMs) as sources of prior causal knowledge, but existing approaches rely on heuristic integration that lacks theoretical grounding. We introduce HOLOGRAPH, a framework that formalizes LLM-guided causal discovery through sheaf theory--representing local causal beliefs as sections of a presheaf over variable subsets. Our key insight is that coherent global causal structure corresponds to the existence of a global section, while topological obstructions manifest as non-vanishing sheaf cohomology. We propose the Algebraic Latent Projection to handle hidden confounders and Natural Gradient Descent on the belief manifold for principled optimization. Experiments on synthetic and real-world benchmarks demonstrate that HOLOGRAPH provides rigorous mathematical foundations while achieving competitive performance on causal discovery tasks with 50-100 variables. Our sheaf-theoretic analysis reveals that while Identity, Transitivity, and Gluing axioms are satisfied to numerical precision (<10^{-6}), the Locality axiom fails for larger graphs, suggesting fundamental non-local coupling in latent variable projections. Code is available at [https://github.com/hyunjun1121/holograph](https://github.com/hyunjun1121/holograph).",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24478.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24478",
      "published": "2025-12-30T21:47:05Z",
      "updated": "2025-12-30T21:47:05Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了HOLOGRAPH框架，利用层理论为大型语言模型引导的因果发现提供严格数学基础。",
        "motivation": "因果发现受可识别性约束限制，现有利用LLM作为先验知识的方法缺乏理论支撑。",
        "method": "采用层理论表示局部因果信念，提出代数潜在投影处理隐藏混杂因素，使用自然梯度下降进行优化。",
        "result": "在50-100变量任务中实现竞争性能，层理论分析显示恒等性等公理满足，但局部性公理在大图中失效。",
        "conclusion": "贡献了形式化框架，揭示潜在变量投影中的非局部耦合，推动LLM在因果发现中的应用。",
        "tags": [
          "Causal Discovery",
          "Large Language Model",
          "Sheaf Theory",
          "Natural Gradient Descent"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:23.688650Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24473",
      "title": "F2IDiff: Real-world Image Super-resolution using Feature to Image Diffusion Foundation Model",
      "authors": [
        "Devendra K. Jangid",
        "Ripon K. Saha",
        "Dilshan Godaliyadda",
        "Jing Li",
        "Seok-Jun Lee",
        "Hamid R. Sheikh"
      ],
      "abstract": "With the advent of Generative AI, Single Image Super-Resolution (SISR) quality has seen substantial improvement, as the strong priors learned by Text-2-Image Diffusion (T2IDiff) Foundation Models (FM) can bridge the gap between High-Resolution (HR) and Low-Resolution (LR) images. However, flagship smartphone cameras have been slow to adopt generative models because strong generation can lead to undesirable hallucinations. For substantially degraded LR images, as seen in academia, strong generation is required and hallucinations are more tolerable because of the wide gap between LR and HR images. In contrast, in consumer photography, the LR image has substantially higher fidelity, requiring only minimal hallucination-free generation. We hypothesize that generation in SISR is controlled by the stringency and richness of the FM's conditioning feature. First, text features are high level features, which often cannot describe subtle textures in an image. Additionally, Smartphone LR images are at least $12MP$, whereas SISR networks built on T2IDiff FM are designed to perform inference on much smaller images ($<1MP$). As a result, SISR inference has to be performed on small patches, which often cannot be accurately described by text feature. To address these shortcomings, we introduce an SISR network built on a FM with lower-level feature conditioning, specifically DINOv2 features, which we call a Feature-to-Image Diffusion (F2IDiff) Foundation Model (FM). Lower level features provide stricter conditioning while being rich descriptors of even small patches.",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24473.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24473",
      "published": "2025-12-30T21:37:35Z",
      "updated": "2025-12-30T21:37:35Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出F2IDiff模型，利用低级特征条件的扩散基础模型进行真实世界图像超分辨率，以减少幻觉。",
        "motivation": "解决现有文本到图像扩散模型在智能手机超分辨率应用中导致不必要幻觉的问题，因为文本特征不适合描述高保真低分辨率图像的细微纹理。",
        "method": "引入基于特征到图像扩散基础模型（F2IDiff）的单图像超分辨率网络，使用DINOv2低级特征进行条件生成。",
        "result": "未明确说明",
        "conclusion": "主要贡献是提出F2IDiff模型，通过低级特征条件实现更严格和无幻觉的图像超分辨率，适用于消费摄影。",
        "tags": [
          "Image Super-resolution",
          "Diffusion Models",
          "Feature Conditioning",
          "DINOv2"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:48.384072Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24461",
      "title": "Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents",
      "authors": [
        "Seohui Bae",
        "Jeonghye Kim",
        "Youngchul Sung",
        "Woohyung Lim"
      ],
      "abstract": "In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24461.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24461",
      "published": "2025-12-30T20:51:28Z",
      "updated": "2025-12-30T20:51:28Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种测试时自适应的信念引导探索推理方法，用于世界接地的具身代理，无需额外训练或梯度更新。",
        "motivation": "解决部分可观察性下 LLM 代理与世界对齐的问题，避免依赖梯度更新或额外训练。",
        "method": "使用后验引导的信念细化、动作条件观察迭代更新信念、最大化信息增益的动作选择，基于轻量级 LLM 代理估计信息增益和新奖励机制评估对齐。",
        "result": "在推理时对齐潜在世界状态上优于提示增强或检索增强的 LLMs 基线，集成开销显著降低。",
        "conclusion": "该方法有效提升了 LLM 代理在部分可观察环境中的对齐能力，具有低集成开销的优势。",
        "tags": [
          "Belief Refinement",
          "Exploratory Inference",
          "LLM-based Agents",
          "Partial Observability",
          "Information Gain"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:28.616613Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24445",
      "title": "Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics",
      "authors": [
        "Akash Samanta",
        "Sheldon Williamson"
      ],
      "abstract": "Learning systems deployed in nonstationary and safety-critical environments often suffer from instability, slow convergence, or brittle adaptation when learning dynamics evolve over time. While modern optimization, reinforcement learning, and meta-learning methods adapt to gradient statistics, they largely ignore the temporal structure of the error signal itself. This paper proposes a diagnostic-driven adaptive learning framework that explicitly models error evolution through a principled decomposition into bias, capturing persistent drift; noise, capturing stochastic variability; and alignment, capturing repeated directional excitation leading to overshoot. These diagnostics are computed online from lightweight statistics of loss or temporal-difference error trajectories and are independent of model architecture or task domain. We show that the proposed bias-noise-alignment decomposition provides a unifying control backbone for supervised optimization, actor-critic reinforcement learning, and learned optimizers. Building on this framework, we derive diagnostic-driven instantiations including a stabilized supervised optimizer, a diagnostic-regulated actor-critic scheme, and a diagnostic-conditioned learned optimizer. Under standard smoothness assumptions, we establish bounded effective updates and stability properties for all cases. Representative diagnostic illustrations in actor-critic learning highlight how the proposed signals modulate adaptation in response to temporal-difference error structure. Overall, this work elevates error evolution to a first-class object in adaptive learning and provides an interpretable, lightweight foundation for reliable learning in dynamic environments.",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24445.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24445",
      "published": "2025-12-30T19:57:52Z",
      "updated": "2025-12-30T19:57:52Z",
      "comment": "This preprint focuses on the theoretical framework and diagnostic behavior. Comprehensive experimental validation in application-specific settings is deferred to a companion experimental study",
      "light_analysis": {
        "overview": "提出一种基于偏置-噪声-对齐诊断的自适应学习框架，以提升动态环境下的学习稳定性。",
        "motivation": "解决非平稳环境中学习系统因忽略误差信号时间结构而导致的不稳定、收敛慢或适应脆弱的问题。",
        "method": "将误差在线分解为偏置、噪声和对齐三个诊断分量，并以此为基础构建监督优化器、行动者-评论家方案和学习优化器。",
        "result": "在标准光滑性假设下，证明了所有情况下的有界有效更新和稳定性，并通过实验展示了诊断信号对适应过程的调制作用。",
        "conclusion": "该工作将误差演化提升为自适应学习的一级对象，为动态环境中的可靠学习提供了可解释、轻量化的基础。",
        "tags": [
          "Adaptive Learning",
          "Bias-Variance Decomposition",
          "Reinforcement Learning",
          "Meta-Learning",
          "Online Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:15.951552Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24443",
      "title": "Sparse classification with positive-confidence data in high dimensions",
      "authors": [
        "The Tien Mai",
        "Mai Anh Nguyen",
        "Trung Nghia Nguyen"
      ],
      "abstract": "High-dimensional learning problems, where the number of features exceeds the sample size, often require sparse regularization for effective prediction and variable selection. While established for fully supervised data, these techniques remain underexplored in weak-supervision settings such as Positive-Confidence (Pconf) classification. Pconf learning utilizes only positive samples equipped with confidence scores, thereby avoiding the need for negative data. However, existing Pconf methods are ill-suited for high-dimensional regimes. This paper proposes a novel sparse-penalization framework for high-dimensional Pconf classification. We introduce estimators using convex (Lasso) and non-convex (SCAD, MCP) penalties to address shrinkage bias and improve feature recovery. Theoretically, we establish estimation and prediction error bounds for the L1-regularized Pconf estimator, proving it achieves near minimax-optimal sparse recovery rates under Restricted Strong Convexity condition. To solve the resulting composite objective, we develop an efficient proximal gradient algorithm. Extensive simulations demonstrate that our proposed methods achieve predictive performance and variable selection accuracy comparable to fully supervised approaches, effectively bridging the gap between weak supervision and high-dimensional statistics.",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24443.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24443",
      "published": "2025-12-30T19:53:50Z",
      "updated": "2025-12-30T19:53:50Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了针对高维正置信分类的稀疏惩罚框架，并给出了理论保证和高效算法。",
        "motivation": "解决高维弱监督学习（仅使用带置信度的正样本）中，缺乏有效稀疏正则化方法的问题。",
        "method": "提出了结合凸（Lasso）与非凸（SCAD, MCP）惩罚的估计器，并开发了高效的近端梯度求解算法。",
        "result": "模拟实验表明，其预测性能与变量选择准确度可与全监督方法媲美，并建立了L1正则估计器的理论误差界。",
        "conclusion": "弥合了弱监督学习与高维统计之间的差距，为高维弱监督分类提供了一种有效的稀疏学习方法。",
        "tags": [
          "High-dimensional Learning",
          "Sparse Regularization",
          "Positive-Confidence Learning",
          "Variable Selection",
          "Proximal Gradient Descent"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:49.716835Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24438",
      "title": "Exploring Compositionality in Vision Transformers using Wavelet Representations",
      "authors": [
        "Akshad Shyam Purushottamdas",
        "Pranav K Nayak",
        "Divya Mehul Rajparia",
        "Deekshith Patel",
        "Yashmitha Gogineni",
        "Konda Reddy Mopuri",
        "Sumohana S. Channappayya"
      ],
      "abstract": "While insights into the workings of the transformer model have largely emerged by analysing their behaviour on language tasks, this work investigates the representations learnt by the Vision Transformer (ViT) encoder through the lens of compositionality. We introduce a framework, analogous to prior work on measuring compositionality in representation learning, to test for compositionality in the ViT encoder. Crucial to drawing this analogy is the Discrete Wavelet Transform (DWT), which is a simple yet effective tool for obtaining input-dependent primitives in the vision setting. By examining the ability of composed representations to reproduce original image representations, we empirically test the extent to which compositionality is respected in the representation space. Our findings show that primitives from a one-level DWT decomposition produce encoder representations that approximately compose in latent space, offering a new perspective on how ViTs structure information.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24438.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24438",
      "published": "2025-12-30T19:43:40Z",
      "updated": "2025-12-30T19:43:40Z",
      "comment": "9 pages, 6 figures",
      "light_analysis": {
        "overview": "使用小波变换研究视觉Transformer编码器的组合性，发现其表示近似可组合。",
        "motivation": "现有Transformer见解多来自语言任务，本研究通过组合性视角探究视觉Transformer编码器的表示学习特性。",
        "method": "引入框架，使用离散小波变换获取输入依赖的图像基元，测试ViT编码器表示的组合性。",
        "result": "一级离散小波变换分解的基元产生的编码器表示在潜在空间中近似可组合。",
        "conclusion": "实证揭示了视觉Transformer表示空间的组合性，为其信息结构化机制提供了新视角。",
        "tags": [
          "Vision Transformer",
          "Compositionality",
          "Discrete Wavelet Transform",
          "Representation Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:31.748554Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24410",
      "title": "Comparing Approaches to Automatic Summarization in Less-Resourced Languages",
      "authors": [
        "Chester Palen-Michel",
        "Constantine Lignos"
      ],
      "abstract": "Automatic text summarization has achieved high performance in high-resourced languages like English, but comparatively less attention has been given to summarization in less-resourced languages. This work compares a variety of different approaches to summarization from zero-shot prompting of LLMs large and small to fine-tuning smaller models like mT5 with and without three data augmentation approaches and multilingual transfer. We also explore an LLM translation pipeline approach, translating from the source language to English, summarizing and translating back. Evaluating with five different metrics, we find that there is variation across LLMs in their performance across similar parameter sizes, that our multilingual fine-tuned mT5 baseline outperforms most other approaches including zero-shot LLM performance for most metrics, and that LLM as judge may be less reliable on less-resourced languages.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24410.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24410",
      "published": "2025-12-30T18:45:00Z",
      "updated": "2025-12-30T18:45:00Z",
      "comment": "Under review",
      "light_analysis": {
        "overview": "系统比较了低资源语言自动摘要的多种方法，发现微调多语言模型mT5通常优于零提示LLM等方法。",
        "motivation": "自动摘要在高资源语言（如英语）性能优异，但在低资源语言上的研究相对不足，需探索有效方法。",
        "method": "比较了零提示大小LLM、微调mT5（使用数据增强与多语言迁移）及翻译-摘要-回译的LLM管道等多种方法。",
        "result": "多语言微调mT5基线在多数指标上超越了包括零提示LLM在内的大部分方法；不同LLM表现有差异；LLM作为评判者可能不可靠。",
        "conclusion": "为低资源语言自动摘要提供了全面基准，证明精心设计的微调方法优于直接使用LLM，并揭示了现有评估的局限性。",
        "tags": [
          "Large Language Models",
          "Fine-tuning",
          "Multilingual Transfer",
          "Data Augmentation",
          "mT5"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:32.945470Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24408",
      "title": "DyStream: Streaming Dyadic Talking Heads Generation via Flow Matching-based Autoregressive Model",
      "authors": [
        "Bohong Chen",
        "Haiyang Liu"
      ],
      "abstract": "Generating realistic, dyadic talking head video requires ultra-low latency. Existing chunk-based methods require full non-causal context windows, introducing significant delays. This high latency critically prevents the immediate, non-verbal feedback required for a realistic listener. To address this, we present DyStream, a flow matching-based autoregressive model that could generate video in real-time from both speaker and listener audio. Our method contains two key designs: (1) we adopt a stream-friendly autoregressive framework with flow-matching heads for probabilistic modeling, and (2) We propose a causal encoder enhanced by a lookahead module to incorporate short future context (e.g., 60 ms) to improve quality while maintaining low latency. Our analysis shows this simple-and-effective method significantly surpass alternative causal strategies, including distillation and generative encoder. Extensive experiments show that DyStream could generate video within 34 ms per frame, guaranteeing the entire system latency remains under 100 ms. Besides, it achieves state-of-the-art lip-sync quality, with offline and online LipSync Confidence scores of 8.13 and 7.61 on HDTF, respectively. The model, weights and codes are available.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24408.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24408",
      "published": "2025-12-30T18:43:38Z",
      "updated": "2025-12-30T18:43:38Z",
      "comment": "Project Page: https://robinwitch.github.io/DyStream-Page",
      "light_analysis": {
        "overview": "提出DyStream，一种基于流匹配的自回归模型，实现实时双向对话头部视频生成。",
        "motivation": "解决现有方法生成双向对话头部视频时延迟高的问题，影响实时非语言反馈的逼真性。",
        "method": "采用流匹配的自回归框架，结合因果编码器和前瞻模块，以纳入短期未来上下文来降低延迟并提高质量。",
        "result": "每帧生成时间仅34毫秒，总延迟低于100毫秒，在HDTF数据集上唇同步分数达到离线8.13和在线7.61。",
        "conclusion": "贡献是开发了一个低延迟的视频生成系统，推动了实时交互式AI应用的发展，并提供开源代码。",
        "tags": [
          "Flow Matching",
          "Autoregressive Model",
          "Causal Encoder",
          "Lookahead Module",
          "Talking Head Generation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:26.567676Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24407",
      "title": "Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models",
      "authors": [
        "Lars van der Laan",
        "Aurelien Bibaut",
        "Nathan Kallus"
      ],
      "abstract": "Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical DDC approaches impose restrictive parametric specifications and often require repeated dynamic programming. We develop a semiparametric framework for debiased inverse reinforcement learning that yields statistically efficient inference for a broad class of reward-dependent functionals in maximum entropy IRL and Gumbel-shock DDC models. We show that the log-behavior policy acts as a pseudo-reward that point-identifies policy value differences and, under a simple normalization, the reward itself. We then formalize these targets, including policy values under known and counterfactual softmax policies and functionals of the normalized reward, as smooth functionals of the behavior policy and transition kernel, establish pathwise differentiability, and derive their efficient influence functions. Building on this characterization, we construct automatic debiased machine-learning estimators that allow flexible nonparametric estimation of nuisance components while achieving $\\sqrt{n}$-consistency, asymptotic normality, and semiparametric efficiency. Our framework extends classical inference for DDC models to nonparametric rewards and modern machine-learning tools, providing a unified and computationally tractable approach to statistical inference in IRL.",
      "categories": [
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24407.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24407",
      "published": "2025-12-30T18:41:05Z",
      "updated": "2025-12-30T18:41:05Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一个半参数框架，用于逆强化学习和动态离散选择模型的统计高效推断。",
        "motivation": "现有逆强化学习方法依赖机器学习但缺乏推断保证，动态离散选择模型参数限制且计算复杂，需统一解决。",
        "method": "开发半参数框架，利用对数行为策略作为伪奖励识别奖励，推导高效影响函数并构建去偏机器学习估计器。",
        "result": "估计器实现√n-一致性、渐近正态性和半参数效率，扩展了经典推断到非参数奖励。",
        "conclusion": "提供统一且计算易处理的统计推断方法，促进逆强化学习和动态离散选择模型的应用。",
        "tags": [
          "Inverse Reinforcement Learning",
          "Dynamic Discrete Choice",
          "Semiparametric Inference",
          "Debiased Machine Learning",
          "Efficient Influence Functions"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:32.529668Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24404",
      "title": "Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning",
      "authors": [
        "Soham Pahari",
        "M. Srinivas"
      ],
      "abstract": "Multimodal intelligence development recently show strong progress in visual understanding and high level reasoning. Though, most reasoning system still reply on textual information as the main medium for inference. This limit their effectiveness in spatial tasks such as visual navigation and geo-localization. This work discuss about the potential scope of this field and eventually propose an idea visual reasoning paradigm Geo-Consistent Visual Planning, our introduced framework called Visual Reasoning for Localization, or ViReLoc, which performs planning and localization using only visual representations. The proposed framework learns spatial dependencies and geometric relations that text based reasoning often suffer to understand. By encoding step by step inference in the visual domain and optimizing with reinforcement based objectives, ViReLoc plans routes between two given ground images. The system also integrates contrastive learning and adaptive feature interaction to align cross view perspectives and reduce viewpoint differences. Experiments across diverse navigation and localization scenarios show consistent improvements in spatial reasoning accuracy and cross view retrieval performance. These results establish visual reasoning as a strong complementary approach for navigation and localization, and show that such tasks can be performed without real time global positioning system data, leading to more secure navigation solutions.",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24404.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24404",
      "published": "2025-12-30T18:36:39Z",
      "updated": "2025-12-30T18:36:39Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出ViReLoc视觉推理框架，实现无需GPS的地面到空中定位和路线规划。",
        "motivation": "解决基于文本的推理系统在视觉导航和地理定位等空间任务中效果有限的问题。",
        "method": "采用Geo-Consistent视觉规划范式，使用强化学习优化视觉推理，整合对比学习和自适应特征交互。",
        "result": "在多种导航和定位场景中，空间推理准确性和跨视图检索性能获得一致提升。",
        "conclusion": "视觉推理可作为导航和定位的强互补方法，无需实时GPS数据，提供更安全的导航解决方案。",
        "tags": [
          "Visual Reasoning",
          "Reinforcement Learning",
          "Contrastive Learning",
          "Cross-view Alignment",
          "Spatial Planning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:43.834512Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24385",
      "title": "Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems",
      "authors": [
        "Song Wang",
        "Lingdong Kong",
        "Xiaolu Liu",
        "Hao Shi",
        "Wentong Li",
        "Jianke Zhu",
        "Steven C. H. Hoi"
      ],
      "abstract": "The rapid advancement of autonomous systems, including self-driving vehicles and drones, has intensified the need to forge true Spatial Intelligence from multi-modal onboard sensor data. While foundation models excel in single-modal contexts, integrating their capabilities across diverse sensors like cameras and LiDAR to create a unified understanding remains a formidable challenge. This paper presents a comprehensive framework for multi-modal pre-training, identifying the core set of techniques driving progress toward this goal. We dissect the interplay between foundational sensor characteristics and learning strategies, evaluating the role of platform-specific datasets in enabling these advancements. Our central contribution is the formulation of a unified taxonomy for pre-training paradigms: ranging from single-modality baselines to sophisticated unified frameworks that learn holistic representations for advanced tasks like 3D object detection and semantic occupancy prediction. Furthermore, we investigate the integration of textual inputs and occupancy representations to facilitate open-world perception and planning. Finally, we identify critical bottlenecks, such as computational efficiency and model scalability, and propose a roadmap toward general-purpose multi-modal foundation models capable of achieving robust Spatial Intelligence for real-world deployment.",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24385.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24385",
      "published": "2025-12-30T17:58:01Z",
      "updated": "2025-12-30T17:58:01Z",
      "comment": "Preprint; 38 pages, 7 figures, 9 tables; GitHub at https://github.com/worldbench/awesome-spatial-intelligence",
      "light_analysis": {
        "overview": "提出了一个多模态预训练的综合框架和统一分类法，以推动自主系统的空间智能发展。",
        "motivation": "自主系统如自动驾驶车辆需要从多模态传感器数据中构建空间智能，但现有基础模型在多模态集成方面存在挑战。",
        "method": "分析了传感器特性与学习策略的相互作用，评估了平台特定数据集，并制定了从单模态到统一框架的预训练范式分类法。",
        "result": "制定了预训练范式的统一分类法，研究了文本输入和占据表示的集成，并识别了计算效率和模型可扩展性等瓶颈。",
        "conclusion": "贡献在于提出了一个综合框架和路线图，为实现通用多模态基础模型以支持真实世界部署的空间智能奠定了基础。",
        "tags": [
          "Multi-Modal Pre-training",
          "Spatial Intelligence",
          "3D Object Detection",
          "Semantic Occupancy Prediction",
          "Foundation Models"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:19.175822Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24381",
      "title": "Tubular Riemannian Laplace Approximations for Bayesian Neural Networks",
      "authors": [
        "Rodrigo Pereira David"
      ],
      "abstract": "Laplace approximations are among the simplest and most practical methods for approximate Bayesian inference in neural networks, yet their Euclidean formulation struggles with the highly anisotropic, curved loss surfaces and large symmetry groups that characterize modern deep models. Recent work has proposed Riemannian and geometric Gaussian approximations to adapt to this structure. Building on these ideas, we introduce the Tubular Riemannian Laplace (TRL) approximation. TRL explicitly models the posterior as a probabilistic tube that follows a low-loss valley induced by functional symmetries, using a Fisher/Gauss-Newton metric to separate prior-dominated tangential uncertainty from data-dominated transverse uncertainty. We interpret TRL as a scalable reparametrised Gaussian approximation that utilizes implicit curvature estimates to operate in high-dimensional parameter spaces. Our empirical evaluation on ResNet-18 (CIFAR-10 and CIFAR-100) demonstrates that TRL achieves excellent calibration, matching or exceeding the reliability of Deep Ensembles (in terms of ECE) while requiring only a fraction (1/5) of the training cost. TRL effectively bridges the gap between single-model efficiency and ensemble-grade reliability.",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24381.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24381",
      "published": "2025-12-30T17:50:55Z",
      "updated": "2025-12-30T17:50:55Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了 Tubular Riemannian Laplace (TRL) 近似，用于贝叶斯神经网络，以改进校准性和效率。",
        "motivation": "欧几里得拉普拉斯近似在处理现代深度模型的复杂损失表面时存在困难，因此需要适应神经网络结构的贝叶斯推断方法。",
        "method": "引入 TRL 近似，将后验建模为概率管，使用 Fisher/Gauss-Newton 度量分离不确定性，是一种可扩展的重新参数化高斯近似。",
        "result": "在 ResNet-18 (CIFAR-10/100) 上评估，TRL 达到优秀校准，匹配或超越 Deep Ensembles 的可靠性，训练成本仅为五分之一。",
        "conclusion": "TRL 桥接了单模型效率和集成级可靠性之间的差距，提供了高效的贝叶斯近似方法。",
        "tags": [
          "Bayesian Neural Networks",
          "Laplace Approximation",
          "Riemannian Geometry",
          "Fisher Information Metric",
          "Gauss-Newton Metric"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:07.898077Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24373",
      "title": "Skim-Aware Contrastive Learning for Efficient Document Representation",
      "authors": [
        "Waheed Ahmed Abro",
        "Zied Bouraoui"
      ],
      "abstract": "Although transformer-based models have shown strong performance in word- and sentence-level tasks, effectively representing long documents, especially in fields like law and medicine, remains difficult. Sparse attention mechanisms can handle longer inputs, but are resource-intensive and often fail to capture full-document context. Hierarchical transformer models offer better efficiency but do not clearly explain how they relate different sections of a document. In contrast, humans often skim texts, focusing on important sections to understand the overall message. Drawing from this human strategy, we introduce a new self-supervised contrastive learning framework that enhances long document representation. Our method randomly masks a section of the document and uses a natural language inference (NLI)-based contrastive objective to align it with relevant parts while distancing it from unrelated ones. This mimics how humans synthesize information, resulting in representations that are both richer and more computationally efficient. Experiments on legal and biomedical texts confirm significant gains in both accuracy and efficiency.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24373.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24373",
      "published": "2025-12-30T17:33:06Z",
      "updated": "2025-12-30T17:33:06Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于略读感知的自监督对比学习框架，提升长文档表示的准确性和效率。",
        "motivation": "解决 transformer 模型在法律和医学等长文档表示上的困难，现有方法资源密集或解释性差。",
        "method": "采用自监督对比学习框架，随机掩码文档部分，使用基于自然语言推理的对比目标对齐相关部分。",
        "result": "在法律和生物医学文本实验中，准确性和效率均有显著提升。",
        "conclusion": "模仿人类略读策略，开发了更丰富和计算高效的文档表示方法。",
        "tags": [
          "Contrastive Learning",
          "Self-Supervised Learning",
          "Natural Language Inference",
          "Transformer Models",
          "Document Representation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:51.880739Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24338",
      "title": "The Mechanics of CNN Filtering with Rectification",
      "authors": [
        "Liam Frija-Altrac",
        "Matthew Toews"
      ],
      "abstract": "This paper proposes elementary information mechanics as a new model for understanding the mechanical properties of convolutional filtering with rectification, inspired by physical theories of special relativity and quantum mechanics. We consider kernels decomposed into orthogonal even and odd components. Even components cause image content to diffuse isotropically while preserving the center of mass, analogously to rest or potential energy with zero net momentum. Odd kernels cause directional displacement of the center of mass, analogously to kinetic energy with non-zero momentum. The speed of information displacement is linearly related to the ratio of odd vs total kernel energy. Even-Odd properties are analyzed in the spectral domain via the discrete cosine transform (DCT), where the structure of small convolutional filters (e.g. $3 \\times 3$ pixels) is dominated by low-frequency bases, specifically the DC $Σ$ and gradient components $\\nabla$, which define the fundamental modes of information propagation. To our knowledge, this is the first work demonstrating the link between information processing in generic CNNs and the energy-momentum relation, a cornerstone of modern relativistic physics.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24338.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24338",
      "published": "2025-12-30T16:44:41Z",
      "updated": "2025-12-30T16:44:41Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于物理力学类比的新模型，解释CNN卷积滤波与整流操作中的信息传播机制。",
        "motivation": "为理解卷积神经网络中滤波与整流操作的“力学”特性，建立其信息处理过程的物理理论基础。",
        "method": "将卷积核分解为正交的偶、奇分量，在谱域通过DCT分析，并类比相对论中的能量-动量关系。",
        "result": "发现偶核导致信息扩散，奇核导致信息位移，位移速度与奇核能量占比呈线性关系。",
        "conclusion": "首次在通用CNN的信息处理与现代相对论物理的基石——能量-动量关系之间建立了理论联系。",
        "tags": [
          "Convolutional Neural Networks",
          "Orthogonal Decomposition",
          "Discrete Cosine Transform",
          "Energy-Momentum Relation",
          "Information Mechanics"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:30.826600Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24331",
      "title": "Spatial-aware Vision Language Model for Autonomous Driving",
      "authors": [
        "Weijie Wei",
        "Zhipeng Luo",
        "Ling Feng",
        "Venice Erin Liong"
      ],
      "abstract": "While Vision-Language Models (VLMs) show significant promise for end-to-end autonomous driving by leveraging the common sense embedded in language models, their reliance on 2D image cues for complex scene understanding and decision-making presents a critical bottleneck for safety and reliability. Current image-based methods struggle with accurate metric spatial reasoning and geometric inference, leading to unreliable driving policies. To bridge this gap, we propose LVLDrive (LiDAR-Vision-Language), a novel framework specifically designed to upgrade existing VLMs with robust 3D metric spatial understanding for autonomous driving by incoperating LiDAR point cloud as an extra input modality. A key challenge lies in mitigating the catastrophic disturbance introduced by disparate 3D data to the pre-trained VLMs. To this end, we introduce a Gradual Fusion Q-Former that incrementally injects LiDAR features, ensuring the stability and preservation of the VLM's existing knowledge base. Furthermore, we develop a spatial-aware question-answering (SA-QA) dataset to explicitly teach the model advanced 3D perception and reasoning capabilities. Extensive experiments on driving benchmarks demonstrate that LVLDrive achieves superior performance compared to vision-only counterparts across scene understanding, metric spatial perception, and reliable driving decision-making. Our work highlights the necessity of explicit 3D metric data for building trustworthy VLM-based autonomous systems.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24331.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24331",
      "published": "2025-12-30T16:35:00Z",
      "updated": "2025-12-30T16:35:00Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出LVLDrive框架，通过融合LiDAR点云增强视觉语言模型的3D空间理解能力，以提升自动驾驶的可靠性和安全性。",
        "motivation": "现有基于2D图像的视觉语言模型在自动驾驶中空间推理不准确，导致决策不可靠，需要引入3D数据来解决这一瓶颈。",
        "method": "结合LiDAR点云作为额外输入，设计Gradual Fusion Q-Former逐步注入LiDAR特征，并使用空间感知问答数据集训练模型。",
        "result": "在驾驶基准测试中优于仅视觉方法，显著提升了场景理解、度量空间感知和可靠决策性能。",
        "conclusion": "证明了显式3D度量数据对构建可信赖的基于视觉语言模型的自动驾驶系统至关重要。",
        "tags": [
          "Vision-Language Model",
          "LiDAR Point Cloud",
          "3D Spatial Understanding",
          "Autonomous Driving",
          "Gradual Fusion"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:51:02.170907Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24330",
      "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
      "authors": [
        "Yong Xien Chng",
        "Tao Hu",
        "Wenwen Tong",
        "Xueheng Li",
        "Jiandong Chen",
        "Haojia Yu",
        "Jiefan Lu",
        "Hewei Guo",
        "Hanming Deng",
        "Chengjun Xie",
        "Gao Huang",
        "Dahua Lin",
        "Lewei Lu"
      ],
      "abstract": "While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios that demand coordinated external tools such as search and image cropping. In this work, we introduce SenseNova-MARS, a novel Multimodal Agentic Reasoning and Search framework that empowers VLMs with interleaved visual reasoning and tool-use capabilities via reinforcement learning (RL). Specifically, SenseNova-MARS dynamically integrates the image search, text search, and image crop tools to tackle fine-grained and knowledge-intensive visual understanding challenges. In the RL stage, we propose the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve the training stability and advance the model's ability to invoke tools and reason effectively. To comprehensively evaluate the agentic VLMs on complex visual tasks, we introduce the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions. Experiments demonstrate that SenseNova-MARS achieves state-of-the-art performance on open-source search and fine-grained image understanding benchmarks. Specifically, on search-oriented benchmarks, SenseNova-MARS-8B scores 67.84 on MMSearch and 41.64 on HR-MMSearch, surpassing proprietary models such as Gemini-3-Flash and GPT-5. SenseNova-MARS represents a promising step toward agentic VLMs by providing effective and robust tool-use capabilities. To facilitate further research in this field, we will release all code, models, and datasets.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24330.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24330",
      "published": "2025-12-30T16:31:45Z",
      "updated": "2025-12-30T16:31:45Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出 SenseNova-MARS 框架，通过强化学习提升多模态模型在复杂任务中交替进行推理与工具使用的能力。",
        "motivation": "解决现有视觉语言模型（VLM）在知识密集型、视觉复杂的场景中，无法流畅地交替进行动态工具操作与连续推理的问题。",
        "method": "引入基于强化学习（RL）的框架，动态整合图像搜索、文本搜索和图像裁剪工具，并提出 BN-GSPO 算法以提升训练稳定性和工具调用能力。",
        "result": "在开源搜索和细粒度图像理解基准上达到 SOTA，如在 MMSearch 上得分为 67.84，超越了 Gemini-3-Flash 和 GPT-5 等模型。",
        "conclusion": "该框架为智能化的 VLM 提供了有效且鲁棒的工具使用能力，是迈向更强大智能体模型的重要一步。",
        "tags": [
          "Multimodal Agentic Reasoning",
          "Vision-Language Models",
          "Reinforcement Learning",
          "Policy Optimization",
          "Tool Use"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:36.827581Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24329",
      "title": "World model inspired sarcasm reasoning with large language model agents",
      "authors": [
        "Keito Inoshita",
        "Shinnosuke Mizuno"
      ],
      "abstract": "Sarcasm understanding is a challenging problem in natural language processing, as it requires capturing the discrepancy between the surface meaning of an utterance and the speaker's intentions as well as the surrounding social context. Although recent advances in deep learning and Large Language Models (LLMs) have substantially improved performance, most existing approaches still rely on black-box predictions of a single model, making it difficult to structurally explain the cognitive factors underlying sarcasm. Moreover, while sarcasm often emerges as a mismatch between semantic evaluation and normative expectations or intentions, frameworks that explicitly decompose and model these components remain limited. In this work, we reformulate sarcasm understanding as a world model inspired reasoning process and propose World Model inspired SArcasm Reasoning (WM-SAR), which decomposes literal meaning, context, normative expectation, and intention into specialized LLM-based agents. The discrepancy between literal evaluation and normative expectation is explicitly quantified as a deterministic inconsistency score, and together with an intention score, these signals are integrated by a lightweight Logistic Regression model to infer the final sarcasm probability. This design leverages the reasoning capability of LLMs while maintaining an interpretable numerical decision structure. Experiments on representative sarcasm detection benchmarks show that WM-SAR consistently outperforms existing deep learning and LLM-based methods. Ablation studies and case analyses further demonstrate that integrating semantic inconsistency and intention reasoning is essential for effective sarcasm detection, achieving both strong performance and high interpretability.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24329.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24329",
      "published": "2025-12-30T16:31:08Z",
      "updated": "2025-12-30T16:31:08Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出WM-SAR方法，通过LLM代理分解讽刺因素，实现高性能可解释的讽刺检测。",
        "motivation": "解决讽刺理解中黑盒预测问题，缺乏结构分解认知因素和显式建模框架。",
        "method": "采用世界模型启发的推理，分解为LLM代理处理字面意思、上下文等，量化不一致性和意图分数，用逻辑回归整合。",
        "result": "在讽刺检测基准上优于现有方法，消融研究证实语义不一致和意图推理的关键作用。",
        "conclusion": "WM-SAR结合LLM推理与可解释决策，为讽刺理解提供高性能且可解释的新框架。",
        "tags": [
          "Large Language Model",
          "Sarcasm Detection",
          "World Model",
          "Interpretability",
          "Logistic Regression"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:23.403884Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24323",
      "title": "Robust Egocentric Referring Video Object Segmentation via Dual-Modal Causal Intervention",
      "authors": [
        "Haijing Liu",
        "Zhiyuan Song",
        "Hefeng Wu",
        "Tao Pu",
        "Keze Wang",
        "Liang Lin"
      ],
      "abstract": "Egocentric Referring Video Object Segmentation (Ego-RVOS) aims to segment the specific object actively involved in a human action, as described by a language query, within first-person videos. This task is critical for understanding egocentric human behavior. However, achieving such segmentation robustly is challenging due to ambiguities inherent in egocentric videos and biases present in training data. Consequently, existing methods often struggle, learning spurious correlations from skewed object-action pairings in datasets and fundamental visual confounding factors of the egocentric perspective, such as rapid motion and frequent occlusions. To address these limitations, we introduce Causal Ego-REferring Segmentation (CERES), a plug-in causal framework that adapts strong, pre-trained RVOS backbones to the egocentric domain. CERES implements dual-modal causal intervention: applying backdoor adjustment principles to counteract language representation biases learned from dataset statistics, and leveraging front-door adjustment concepts to address visual confounding by intelligently integrating semantic visual features with geometric depth information guided by causal principles, creating representations more robust to egocentric distortions. Extensive experiments demonstrate that CERES achieves state-of-the-art performance on Ego-RVOS benchmarks, highlighting the potential of applying causal reasoning to build more reliable models for broader egocentric video understanding.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24323.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24323",
      "published": "2025-12-30T16:22:14Z",
      "updated": "2025-12-30T16:22:14Z",
      "comment": "NeurIPS 2025",
      "light_analysis": {
        "overview": "提出CERES框架，通过双重模态因果干预提升第一人称指涉视频对象分割的鲁棒性。",
        "motivation": "解决Ego-RVOS任务中因视频模糊性和数据偏差导致现有方法学习虚假相关性的问题。",
        "method": "引入插件因果框架CERES，实施后门调整对抗语言偏差和前门调整结合视觉与深度信息的双重模态因果干预。",
        "result": "在Ego-RVOS基准测试中达到最先进性能。",
        "conclusion": "展示了因果推理在构建更可靠的第一人称视频理解模型中的潜力。",
        "tags": [
          "Egocentric Video Object Segmentation",
          "Causal Intervention",
          "Backdoor Adjustment",
          "Front-door Adjustment",
          "Referring Expression"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:49.497939Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24321",
      "title": "UniAct: Unified Motion Generation and Action Streaming for Humanoid Robots",
      "authors": [
        "Nan Jiang",
        "Zimo He",
        "Wanhe Yu",
        "Lexi Pang",
        "Yunhao Li",
        "Hongjie Li",
        "Jieming Cui",
        "Yuhan Li",
        "Yizhou Wang",
        "Yixin Zhu",
        "Siyuan Huang"
      ],
      "abstract": "A long-standing objective in humanoid robotics is the realization of versatile agents capable of following diverse multimodal instructions with human-level flexibility. Despite advances in humanoid control, bridging high-level multimodal perception with whole-body execution remains a significant bottleneck. Existing methods often struggle to translate heterogeneous instructions -- such as language, music, and trajectories -- into stable, real-time actions. Here we show that UniAct, a two-stage framework integrating a fine-tuned MLLM with a causal streaming pipeline, enables humanoid robots to execute multimodal instructions with sub-500 ms latency. By unifying inputs through a shared discrete codebook via FSQ, UniAct ensures cross-modal alignment while constraining motions to a physically grounded manifold. This approach yields a 19% improvement in the success rate of zero-shot tracking of imperfect reference motions. We validate UniAct on UniMoCap, our 20-hour humanoid motion benchmark, demonstrating robust generalization across diverse real-world scenarios. Our results mark a critical step toward responsive, general-purpose humanoid assistants capable of seamless interaction through unified perception and control.",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24321.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24321",
      "published": "2025-12-30T16:20:13Z",
      "updated": "2025-12-30T16:20:13Z",
      "comment": "Project page: https://jnnan.github.io/uniact/",
      "light_analysis": {
        "overview": "UniAct框架通过整合微调MLLM和因果流管道，实现人形机器人多模态指令的实时运动生成和动作流。",
        "motivation": "解决人形机器人将高层面多模态感知（如语言、音乐）与全身执行桥接的瓶颈，实现异构指令的稳定实时转换。",
        "method": "采用两阶段框架，集成微调的多模态大语言模型和因果流管道，通过FSQ统一输入到共享离散码本以实现跨模态对齐。",
        "result": "实现亚500毫秒延迟，零样本跟踪不完美参考运动的成功率提升19%，在20小时UniMoCap基准上验证泛化能力。",
        "conclusion": "为响应式、通用人形助手提供统一感知和控制的关键步骤，推动人形机器人无缝交互能力的发展。",
        "tags": [
          "Multimodal Large Language Model",
          "Causal Streaming",
          "FSQ",
          "Humanoid Motion Generation",
          "Zero-shot Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:13.653976Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24314",
      "title": "QianfanHuijin Technical Report: A Novel Multi-Stage Training Paradigm for Finance Industrial LLMs",
      "authors": [
        "Shupeng Li",
        "Weipeng Lu",
        "Linyun Liu",
        "Chen Lin",
        "Shaofei Li",
        "Zhendong Tan",
        "Hanjun Zhong",
        "Yucheng Zeng",
        "Chenghao Zhu",
        "Mengyue Liu",
        "Daxiang Dong",
        "Jianmin Wu",
        "Yunting Xiao",
        "Annan Li",
        "Danyu Liu",
        "Jingnan Zhang",
        "Licen Liu",
        "Dawei Yin",
        "Dou Shen"
      ],
      "abstract": "Domain-specific enhancement of Large Language Models (LLMs) within the financial context has long been a focal point of industrial application. While previous models such as BloombergGPT and Baichuan-Finance primarily focused on knowledge enhancement, the deepening complexity of financial services has driven a growing demand for models that possess not only domain knowledge but also robust financial reasoning and agentic capabilities. In this paper, we present QianfanHuijin, a financial domain LLM, and propose a generalizable multi-stage training paradigm for industrial model enhancement.   Our approach begins with Continual Pre-training (CPT) on financial corpora to consolidate the knowledge base. This is followed by a fine-grained Post-training pipeline designed with increasing specificity: starting with Financial SFT, progressing to Finance Reasoning RL and Finance Agentic RL, and culminating in General RL aligned with real-world business scenarios. Empirical results demonstrate that QianfanHuijin achieves superior performance across various authoritative financial benchmarks. Furthermore, ablation studies confirm that the targeted Reasoning RL and Agentic RL stages yield significant gains in their respective capabilities. These findings validate our motivation and suggest that this fine-grained, progressive post-training methodology is poised to become a mainstream paradigm for various industrial-enhanced LLMs.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24314.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24314",
      "published": "2025-12-30T16:10:51Z",
      "updated": "2025-12-30T16:10:51Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种新颖的多阶段训练范式，用于增强金融领域大语言模型，提升其推理和代理能力。",
        "motivation": "金融服务复杂性增加，需求模型不仅具备金融知识，还需强化推理和代理能力，以弥补现有模型的不足。",
        "method": "采用多阶段训练范式，包括持续预训练巩固知识库，以及细粒度后训练管道，涵盖金融SFT、推理RL、代理RL和通用RL。",
        "result": "QianfanHuijin在权威金融基准测试中表现优异，消融研究证实推理RL和代理RL阶段显著提升相应能力。",
        "conclusion": "这种细粒度渐进式后训练方法验证了动机，有望成为工业增强大语言模型的主流范式。",
        "tags": [
          "Large Language Model",
          "Continual Pre-training",
          "Reinforcement Learning",
          "Financial Fine-tuning",
          "Agentic Reinforcement Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:38.531576Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24297",
      "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking",
      "authors": [
        "Meiqi Chen",
        "Fandong Meng",
        "Jie Zhou"
      ],
      "abstract": "Complex reasoning problems often involve implicit spatial, geometric, and structural relationships that are not explicitly encoded in text. While recent reasoning models have achieved strong performance across many domains, purely text-based reasoning struggles to represent global structural constraints in complex settings. In this paper, we introduce FIGR, which integrates active visual thinking into multi-turn reasoning via end-to-end reinforcement learning. FIGR externalizes intermediate structural hypotheses by constructing visual representations during problem solving. By adaptively regulating when and how visual reasoning should be invoked, FIGR enables more stable and coherent reasoning over global structural properties that are difficult to capture from text alone. Experiments on challenging mathematical reasoning benchmarks demonstrate that FIGR outperforms strong text-only chain-of-thought baselines. In particular, FIGR improves the base model by 13.12% on AIME 2025 and 11.00% on BeyondAIME, highlighting the effectiveness of figure-guided multimodal reasoning in enhancing the stability and reliability of complex reasoning.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24297.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24297",
      "published": "2025-12-30T15:39:11Z",
      "updated": "2025-12-30T15:39:11Z",
      "comment": null,
      "light_analysis": {
        "overview": "FIGR通过主动视觉思维与强化学习的结合，提升复杂推理中全局结构约束的处理能力。",
        "motivation": "解决纯文本推理在处理隐式空间、几何和结构关系时的局限性，尤其是在复杂问题中难以表示全局结构约束。",
        "method": "提出FIGR模型，使用端到端强化学习集成主动视觉思维，通过构建视觉表示外部化结构假设，并自适应调节视觉推理。",
        "result": "在数学推理基准AIME 2025和BeyondAIME上优于纯文本思维链基线，分别提升13.12%和11.00%。",
        "conclusion": "图引导的多模态推理能有效增强复杂推理的稳定性和可靠性，为处理结构约束问题提供新方法。",
        "tags": [
          "Reinforcement Learning",
          "Multimodal Reasoning",
          "Visual Representation",
          "Structural Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:24.725991Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24276",
      "title": "LiftProj: Space Lifting and Projection-Based Panorama Stitching",
      "authors": [
        "Yuan Jia",
        "Ruimin Wu",
        "Rui Song",
        "Jiaojiao Li",
        "Bin Song"
      ],
      "abstract": "Traditional image stitching techniques have predominantly utilized two-dimensional homography transformations and mesh warping to achieve alignment on a planar surface. While effective for scenes that are approximately coplanar or exhibit minimal parallax, these approaches often result in ghosting, structural bending, and stretching distortions in non-overlapping regions when applied to real three-dimensional scenes characterized by multiple depth layers and occlusions. Such challenges are exacerbated in multi-view accumulations and 360° closed-loop stitching scenarios. In response, this study introduces a spatially lifted panoramic stitching framework that initially elevates each input image into a dense three-dimensional point representation within a unified coordinate system, facilitating global cross-view fusion augmented by confidence metrics. Subsequently, a unified projection center is established in three-dimensional space, and an equidistant cylindrical projection is employed to map the fused data onto a single panoramic manifold, thereby producing a geometrically consistent 360° panoramic layout. Finally, hole filling is conducted within the canvas domain to address unknown regions revealed by viewpoint transitions, restoring continuous texture and semantic coherence. This framework reconceptualizes stitching from a two-dimensional warping paradigm to a three-dimensional consistency paradigm and is designed to flexibly incorporate various three-dimensional lifting and completion modules. Experimental evaluations demonstrate that the proposed method substantially mitigates geometric distortions and ghosting artifacts in scenarios involving significant parallax and complex occlusions, yielding panoramic results that are more natural and consistent.",
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24276.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24276",
      "published": "2025-12-30T15:03:38Z",
      "updated": "2025-12-30T15:03:38Z",
      "comment": "16 pages, 10 figures",
      "light_analysis": {
        "overview": "提出LiftProj框架，通过三维空间提升和投影实现几何一致的全景拼接，解决传统方法在复杂场景中的失真问题。",
        "motivation": "传统图像拼接在三维场景中易产生鬼影和几何失真，尤其在多深度层和遮挡情况下，影响全景图质量。",
        "method": "将图像提升为三维点云进行全局融合，再通过等距圆柱投影映射到全景流形，最后进行空洞填充以恢复纹理。",
        "result": "实验显示该方法在显著视差和复杂遮挡场景中有效减轻几何失真和鬼影，生成更自然一致的全景图。",
        "conclusion": "框架将拼接从二维扭曲转向三维一致性范式，可灵活集成三维提升和完成模块，提升几何准确性。",
        "tags": [
          "Panorama Stitching",
          "3D Reconstruction",
          "Equidistant Cylindrical Projection",
          "Point Cloud Fusion",
          "Hole Filling"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:42.491733Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24271",
      "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
      "authors": [
        "Zhe Huang",
        "Hao Wen",
        "Aiming Hao",
        "Bingze Song",
        "Meiqi Wu",
        "Jiahong Wu",
        "Xiangxiang Chu",
        "Sheng Lu",
        "Haoqian Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To address this, we introduce DualityForge, a novel counterfactual data synthesis framework that employs controllable, diffusion-based video editing to transform real-world videos into counterfactual scenarios. By embedding structured contextual information into the video editing and QA generation processes, the framework automatically produces high-quality QA pairs together with original-edited video pairs for contrastive training. Based on this, we build DualityVidQA, a large-scale video dataset designed to reduce MLLM hallucinations. In addition, to fully exploit the contrastive nature of our paired data, we propose Duality-Normalized Advantage Training (DNA-Train), a two-stage SFT-RL training regime where the RL phase applies pair-wise $\\ell_1$ advantage normalization, thereby enabling a more stable and efficient policy optimization. Experiments on DualityVidQA-Test demonstrate that our method substantially reduces model hallucinations on counterfactual videos, yielding a relative improvement of 24.0% over the Qwen2.5-VL-7B baseline. Moreover, our approach achieves significant gains across both hallucination and general-purpose benchmarks, indicating strong generalization capability. We will open-source our dataset and code.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24271.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24271",
      "published": "2025-12-30T14:53:33Z",
      "updated": "2025-12-30T14:53:33Z",
      "comment": "18 pages",
      "light_analysis": {
        "overview": "提出 DualityForge 框架，通过反事实视频生成和对比训练减少多模态大语言模型在视频理解中的幻觉。",
        "motivation": "解决多模态大语言模型在视频理解中过度依赖语言先验导致的视觉未锚定幻觉问题，特别是处理反事实视频时，由于数据不平衡和标注成本高。",
        "method": "引入 DualityForge 框架，利用扩散模型进行可控视频编辑生成反事实数据，构建 DualityVidQA 数据集，并提出 DNA-Train 训练方案，包括监督微调和强化学习阶段，应用优势归一化。",
        "result": "在 DualityVidQA-Test 上，模型幻觉显著减少，相对 Qwen2.5-VL-7B 基线提升 24.0%，在多个基准测试中取得增益，表明强泛化能力。",
        "conclusion": "贡献包括反事实数据合成框架、大规模数据集和高效训练方法，有效提升 MLLM 视频理解的鲁棒性，并开源促进研究。",
        "tags": [
          "Multimodal Large Language Model",
          "Diffusion Models",
          "Video Editing",
          "Reinforcement Learning",
          "Contrastive Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:38.273142Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24265",
      "title": "Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning",
      "authors": [
        "Ziqing Fan",
        "Yuqiao Xian",
        "Yan Sun",
        "Li Shen"
      ],
      "abstract": "A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in embeddings, which can be roughly categorized into quality and diversity metrics. Due to the high computational cost when applied to trillion-scale token pre-training datasets such as FineWeb and DCLM, these two or more types of metrics are rarely considered jointly in a single selection process. However, in our empirical study, selecting samples based on quality metrics exhibit severe diminishing returns during long-term pre-training, while selecting on diversity metrics removes too many valuable high-quality samples, both of which limit pre-trained LLMs' capabilities. Therefore, we introduce DATAMASK, a novel and efficient joint learning framework designed for large-scale pre-training data selection that can simultaneously optimize multiple types of metrics in a unified process, with this study focusing specifically on quality and diversity metrics. DATAMASK approaches the selection process as a mask learning problem, involving iterative sampling of data masks, computation of policy gradients based on predefined objectives with sampled masks, and updating of mask sampling logits. Through policy gradient-based optimization and various acceleration enhancements, it significantly reduces selection time by 98.9% compared to greedy algorithm, enabling our study to explore joint learning within trillion-scale tokens. With DATAMASK, we select a subset of about 10% from the 15 trillion-token FineWeb dataset, termed FineWeb-Mask. Evaluated across 12 diverse tasks, we achieves significant improvements of 3.2% on a 1.5B dense model and 1.9% on a 7B MoE model.",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24265.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24265",
      "published": "2025-12-30T14:38:34Z",
      "updated": "2025-12-30T14:38:34Z",
      "comment": null,
      "light_analysis": {
        "overview": "DATAMASK框架通过策略梯度优化实现大规模预训练数据的联合选择，提升模型性能。",
        "motivation": "现有数据选择方法单独使用质量或多样性指标时计算成本高、效果有限，需高效联合优化以提升预训练效率。",
        "method": "提出DATAMASK框架，将数据选择视为掩码学习问题，使用策略梯度优化迭代采样掩码和更新对数。",
        "result": "选择时间减少98.9%，从FineWeb数据集中选择10%子集，在12个任务上1.5B模型提升3.2%，7B MoE模型提升1.9%。",
        "conclusion": "DATAMASK成功实现高效联合数据选择，为大规模预训练提供新方法，显著增强LLM能力。",
        "tags": [
          "Large Language Model",
          "Policy Gradient",
          "Data Selection",
          "Mask Learning",
          "Pre-training"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:05.308763Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24263",
      "title": "Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment",
      "authors": [
        "Lijun Zhang",
        "Lin Li",
        "Wei Wei",
        "Yajie Qi",
        "Huizhong Song",
        "Jun Wang",
        "Yaodong Yang",
        "Jiye Liang"
      ],
      "abstract": "When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24263.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24263",
      "published": "2025-12-30T14:38:02Z",
      "updated": "2025-12-30T14:38:02Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出风险感知逐步对齐方法RSA，用于语言模型安全对齐，控制风险并抑制有害行为。",
        "motivation": "现有安全对齐方法风险中性，不足以处理模型偏离参考策略和罕见有害行为的风险。",
        "method": "使用嵌套风险度量，将安全对齐公式化为令牌级风险感知约束策略优化问题，通过逐步对齐过程求解。",
        "result": "实验表明RSA在保持高帮助性的同时确保强安全性，并显著抑制尾部风险（低概率高影响不安全响应）。",
        "conclusion": "RSA方法通过风险感知对齐增强语言模型安全性和鲁棒性，提供理论分析和实证支持。",
        "tags": [
          "Large Language Model",
          "Risk-aware Alignment",
          "Constrained Policy Optimization",
          "Token-level Optimization",
          "Nested Risk Measures"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:04.791265Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24251",
      "title": "Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem",
      "authors": [
        "Pengfu Wan",
        "Jiawei Chen",
        "Gangyan Xu"
      ],
      "abstract": "The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24251.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24251",
      "published": "2025-12-30T14:26:33Z",
      "updated": "2025-12-30T14:26:33Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种基于深度强化学习的方法，高效解决车队规模和混合车辆路径问题。",
        "motivation": "FSMVRP在现实场景如短期车辆租赁和按需物流中应用广泛，但其复杂性高，尤其是在大规模和时间受限环境下，需要高效求解方法。",
        "method": "采用深度强化学习技术，将问题建模为马尔可夫决策过程，并开发了FRIPN策略网络，集成车队组成和路径决策，使用专门设计的输入嵌入。",
        "result": "实验表明，该方法能在几秒内生成近似最优解，在计算效率和可扩展性上表现优异，尤其适用于大规模和时间受限场景。",
        "conclusion": "该方法展示了深度强化学习在实际问题中的潜力，为扩展应用到其他车辆路径问题变种提供了灵感。",
        "tags": [
          "Deep Reinforcement Learning",
          "Markov Decision Process",
          "Vehicle Routing Problem",
          "Policy Network"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:25.168969Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24243",
      "title": "MambaSeg: Harnessing Mamba for Accurate and Efficient Image-Event Semantic Segmentation",
      "authors": [
        "Fuqiang Gu",
        "Yuanke Li",
        "Xianlei Long",
        "Kangping Ji",
        "Chao Chen",
        "Qingyi Gu",
        "Zhenliang Ni"
      ],
      "abstract": "Semantic segmentation is a fundamental task in computer vision with wide-ranging applications, including autonomous driving and robotics. While RGB-based methods have achieved strong performance with CNNs and Transformers, their effectiveness degrades under fast motion, low-light, or high dynamic range conditions due to limitations of frame cameras. Event cameras offer complementary advantages such as high temporal resolution and low latency, yet lack color and texture, making them insufficient on their own. To address this, recent research has explored multimodal fusion of RGB and event data; however, many existing approaches are computationally expensive and focus primarily on spatial fusion, neglecting the temporal dynamics inherent in event streams. In this work, we propose MambaSeg, a novel dual-branch semantic segmentation framework that employs parallel Mamba encoders to efficiently model RGB images and event streams. To reduce cross-modal ambiguity, we introduce the Dual-Dimensional Interaction Module (DDIM), comprising a Cross-Spatial Interaction Module (CSIM) and a Cross-Temporal Interaction Module (CTIM), which jointly perform fine-grained fusion along both spatial and temporal dimensions. This design improves cross-modal alignment, reduces ambiguity, and leverages the complementary properties of each modality. Extensive experiments on the DDD17 and DSEC datasets demonstrate that MambaSeg achieves state-of-the-art segmentation performance while significantly reducing computational cost, showcasing its promise for efficient, scalable, and robust multimodal perception.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24243.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24243",
      "published": "2025-12-30T14:09:17Z",
      "updated": "2025-12-30T14:09:17Z",
      "comment": "Accepted by AAAI 2026",
      "light_analysis": {
        "overview": "提出了MambaSeg框架，利用Mamba编码器实现RGB和事件数据的准确高效语义分割。",
        "motivation": "RGB方法在快速运动、低光等条件下效果差；事件相机有优势但缺乏信息；现有多模态融合方法计算昂贵且忽视时间动态。",
        "method": "使用并行Mamba编码器构建双分支框架，并引入DDIM模块（包括CSIM和CTIM）进行空间和时间维度的精细融合。",
        "result": "在DDD17和DSEC数据集上达到最先进的分割性能，并显著降低计算成本。",
        "conclusion": "MambaSeg实现了高效、可扩展和鲁棒的多模态感知，为语义分割提供了新方案。",
        "tags": [
          "Semantic Segmentation",
          "Mamba",
          "Multimodal Fusion",
          "Event Camera",
          "Temporal Modeling"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:02.682339Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24231",
      "title": "MotivNet: Evolving Meta-Sapiens into an Emotionally Intelligent Foundation Model",
      "authors": [
        "Rahul Medicharla",
        "Alper Yilmaz"
      ],
      "abstract": "In this paper, we introduce MotivNet, a generalizable facial emotion recognition model for robust real-world application. Current state-of-the-art FER models tend to have weak generalization when tested on diverse data, leading to deteriorated performance in the real world and hindering FER as a research domain. Though researchers have proposed complex architectures to address this generalization issue, they require training cross-domain to obtain generalizable results, which is inherently contradictory for real-world application. Our model, MotivNet, achieves competitive performance across datasets without cross-domain training by using Meta-Sapiens as a backbone. Sapiens is a human vision foundational model with state-of-the-art generalization in the real world through large-scale pretraining of a Masked Autoencoder. We propose MotivNet as an additional downstream task for Sapiens and define three criteria to evaluate MotivNet's viability as a Sapiens task: benchmark performance, model similarity, and data similarity. Throughout this paper, we describe the components of MotivNet, our training approach, and our results showing MotivNet is generalizable across domains. We demonstrate that MotivNet can be benchmarked against existing SOTA models and meets the listed criteria, validating MotivNet as a Sapiens downstream task, and making FER more incentivizing for in-the-wild application. The code is available at https://github.com/OSUPCVLab/EmotionFromFaceImages.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24231.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24231",
      "published": "2025-12-30T13:44:57Z",
      "updated": "2025-12-30T13:44:57Z",
      "comment": "6 pages, 4 figures",
      "light_analysis": {
        "overview": "提出 MotivNet，一个基于 Meta-Sapiens 骨干网络的泛化面部情感识别模型，无需跨域训练。",
        "motivation": "解决当前面部情感识别模型在多样化数据上泛化能力弱的问题，以提升真实世界应用性能。",
        "method": "使用 Meta-Sapiens 基础模型作为骨干，将其扩展为下游任务，并定义基准性能、模型相似性和数据相似性评估标准。",
        "result": "MotivNet 在跨数据集上表现竞争性，满足评估标准，验证了其作为 Sapiens 下游任务的可行性和泛化能力。",
        "conclusion": "成功将 MotivNet 构建为 Sapiens 的有效下游任务，促进了面部情感识别在真实世界的应用。",
        "tags": [
          "Facial Emotion Recognition",
          "Foundation Model",
          "Masked Autoencoder",
          "Meta-Sapiens",
          "Downstream Task"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:59.634191Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24227",
      "title": "Mirage: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes",
      "authors": [
        "Shuyun Wang",
        "Haiyang Sun",
        "Bing Wang",
        "Hangjun Ye",
        "Xin Yu"
      ],
      "abstract": "Vision-centric autonomous driving systems rely on diverse and scalable training data to achieve robust performance. While video object editing offers a promising path for data augmentation, existing methods often struggle to maintain both high visual fidelity and temporal coherence. In this work, we propose \\textbf{Mirage}, a one-step video diffusion model for photorealistic and coherent asset editing in driving scenes. Mirage builds upon a text-to-video diffusion prior to ensure temporal consistency across frames. However, 3D causal variational autoencoders often suffer from degraded spatial fidelity due to compression, and directly passing 3D encoder features to decoder layers breaks temporal causality. To address this, we inject temporally agnostic latents from a pretrained 2D encoder into the 3D decoder to restore detail while preserving causal structures. Furthermore, because scene objects and inserted assets are optimized under different objectives, their Gaussians exhibit a distribution mismatch that leads to pose misalignment. To mitigate this, we introduce a two-stage data alignment strategy combining coarse 3D alignment and fine 2D refinement, thereby improving alignment and providing cleaner supervision. Extensive experiments demonstrate that Mirage achieves high realism and temporal consistency across diverse editing scenarios. Beyond asset editing, Mirage can also generalize to other video-to-video translation tasks, serving as a reliable baseline for future research. Our code is available at https://github.com/wm-research/mirage.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24227.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24227",
      "published": "2025-12-30T13:40:23Z",
      "updated": "2025-12-30T13:40:23Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出Mirage，一种用于自动驾驶场景逼真资产编辑的一步视频扩散模型。",
        "motivation": "自动驾驶系统需要多样训练数据，但现有视频编辑方法难以同时保持高视觉保真度和时间一致性。",
        "method": "基于文本到视频扩散先验，注入2D编码器潜在变量以恢复细节，并采用两阶段数据对齐策略改善姿势对齐。",
        "result": "实验表明Mirage在各种编辑场景中实现高真实感和时间一致性，并能泛化到其他视频翻译任务。",
        "conclusion": "Mirage为资产编辑提供了可靠基线，可促进未来视频处理研究。",
        "tags": [
          "Video Diffusion Model",
          "3D Causal Variational Autoencoder",
          "Temporal Consistency",
          "Data Alignment",
          "Generative Models"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:47.702867Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24224",
      "title": "ARM: A Learnable, Plug-and-Play Module for CLIP-based Open-vocabulary Semantic Segmentation",
      "authors": [
        "Ziquan Liu",
        "Zhewei Zhu",
        "Xuyang Shi"
      ],
      "abstract": "Open-vocabulary semantic segmentation (OVSS) is fundamentally hampered by the coarse, image-level representations of CLIP, which lack precise pixel-level details. Existing training-free methods attempt to resolve this by either importing priors from costly external foundation models (e.g., SAM, DINO) or by applying static, hand-crafted heuristics to CLIP's internal features. These approaches are either computationally expensive or sub-optimal. We propose the Attention Refinement Module (ARM), a lightweight, learnable module that effectively unlocks and refines CLIP's internal potential. Unlike static-fusion methods, ARM learns to adaptively fuse hierarchical features. It employs a semantically-guided cross-attention block, using robust deep features (K, V) to select and refine detail-rich shallow features (Q), followed by a self-attention block. The key innovation lies in a ``train once, use anywhere\" paradigm. Trained once on a general-purpose dataset (e.g., COCO-Stuff), ARM acts as a universal plug-and-play post-processor for diverse training-free frameworks. Extensive experiments show that ARM consistently boosts baseline performance on multiple benchmarks with negligible inference overhead, establishing an efficient and effective paradigm for training-free OVSS.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24224.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24224",
      "published": "2025-12-30T13:38:30Z",
      "updated": "2025-12-30T13:38:30Z",
      "comment": "10 pages, 4 figures",
      "light_analysis": {
        "overview": "提出ARM模块，一个可学习的即插即用模块，提升CLIP在开放词汇语义分割中的性能。",
        "motivation": "解决CLIP在开放词汇语义分割中细节不足的问题，现有无训练方法计算昂贵或效果次优。",
        "method": "设计注意力细化模块（ARM），使用语义引导的交叉注意力和自注意力自适应融合层次特征。",
        "result": "在多个基准上持续提升基线性能，推理开销可忽略不计。",
        "conclusion": "为无训练开放词汇语义分割建立高效有效的即插即用范式。",
        "tags": [
          "Open-vocabulary Semantic Segmentation",
          "CLIP",
          "Attention Mechanism",
          "Cross-Attention",
          "Self-Attention"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:18.340267Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24195",
      "title": "CorGi: Contribution-Guided Block-Wise Interval Caching for Training-Free Acceleration of Diffusion Transformers",
      "authors": [
        "Yonglak Son",
        "Suhyeok Kim",
        "Seungryong Kim",
        "Young Geun Kim"
      ],
      "abstract": "Diffusion transformer (DiT) achieves remarkable performance in visual generation, but its iterative denoising process combined with larger capacity leads to a high inference cost. Recent works have demonstrated that the iterative denoising process of DiT models involves substantial redundant computation across steps. To effectively reduce the redundant computation in DiT, we propose CorGi (Contribution-Guided Block-Wise Interval Caching), training-free DiT inference acceleration framework that selectively reuses the outputs of transformer blocks in DiT across denoising steps. CorGi caches low-contribution blocks and reuses them in later steps within each interval to reduce redundant computation while preserving generation quality. For text-to-image tasks, we further propose CorGi+, which leverages per-block cross-attention maps to identify salient tokens and applies partial attention updates to protect important object details. Evaluation on the state-of-the-art DiT models demonstrates that CorGi and CorGi+ achieve up to 2.0x speedup on average, while preserving high generation quality.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24195.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24195",
      "published": "2025-12-30T12:55:38Z",
      "updated": "2025-12-30T12:55:38Z",
      "comment": "16 pages, 20 figures",
      "light_analysis": {
        "overview": "提出了无需训练、基于贡献度引导的块间缓存方法CorGi，用于加速Diffusion Transformer的推理。",
        "motivation": "Diffusion Transformer(DiT)模型迭代去噪过程计算成本高，且存在大量跨步骤的冗余计算。",
        "method": "提出CorGi框架：评估Transformer块贡献度，选择性缓存并跨步复用低贡献块；针对文本生成任务提出CorGi+，利用交叉注意力图保护重要细节。",
        "result": "在先进DiT模型上评估，平均最高可实现2.0倍加速，同时保持高生成质量。",
        "conclusion": "提供了一种无需训练的高效推理加速框架，显著降低了DiT的计算开销，提升了其实用性。",
        "tags": [
          "Diffusion Transformer",
          "Model Acceleration",
          "Caching Mechanism",
          "Attention Mechanism",
          "Text-to-Image Generation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:41.382787Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24176",
      "title": "Guiding a Diffusion Transformer with the Internal Dynamics of Itself",
      "authors": [
        "Xingyu Zhou",
        "Qifan Li",
        "Xiaobin Hu",
        "Hai Chen",
        "Shuhang Gu"
      ],
      "abstract": "The diffusion model presents a powerful ability to capture the entire (conditional) data distribution. However, due to the lack of sufficient training and data to learn to cover low-probability areas, the model will be penalized for failing to generate high-quality images corresponding to these areas. To achieve better generation quality, guidance strategies such as classifier free guidance (CFG) can guide the samples to the high-probability areas during the sampling stage. However, the standard CFG often leads to over-simplified or distorted samples. On the other hand, the alternative line of guiding diffusion model with its bad version is limited by carefully designed degradation strategies, extra training and additional sampling steps. In this paper, we proposed a simple yet effective strategy Internal Guidance (IG), which introduces an auxiliary supervision on the intermediate layer during training process and extrapolates the intermediate and deep layer's outputs to obtain generative results during sampling process. This simple strategy yields significant improvements in both training efficiency and generation quality on various baselines. On ImageNet 256x256, SiT-XL/2+IG achieves FID=5.31 and FID=1.75 at 80 and 800 epochs. More impressively, LightningDiT-XL/1+IG achieves FID=1.34 which achieves a large margin between all of these methods. Combined with CFG, LightningDiT-XL/1+IG achieves the current state-of-the-art FID of 1.19.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24176.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24176",
      "published": "2025-12-30T12:16:46Z",
      "updated": "2025-12-30T12:16:46Z",
      "comment": "Project Page: https://zhouxingyu13.github.io/Internal-Guidance/",
      "light_analysis": {
        "overview": "提出一种名为“内部引导”的新策略，利用模型自身的中间层动态信息来提升扩散模型的生成质量。",
        "motivation": "扩散模型因训练数据不足难以覆盖低概率区域，传统引导方法如CFG会导致样本过简化或失真，现有其他方法则需要额外训练或采样步骤。",
        "method": "提出内部引导策略，在训练时对中间层施加辅助监督，采样时外推中间层和深层输出来指导生成过程。",
        "result": "在不同基线上显著提升了训练效率和生成质量。在ImageNet 256x256上，结合CFG后取得了当前最优的FID 1.19。",
        "conclusion": "内部引导是一种简单有效的策略，能有效缓解扩散模型在低概率区域的问题，并在多个任务上实现显著性能提升。",
        "tags": [
          "Diffusion Models",
          "Classifier-Free Guidance",
          "Diffusion Transformers",
          "Internal Guidance"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:57.567994Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24172",
      "title": "Deep Global Clustering for Hyperspectral Image Segmentation: Concepts, Applications, and Open Challenges",
      "authors": [
        "Yu-Tang Chang",
        "Pin-Wei Chen",
        "Shih-Fang Chen"
      ],
      "abstract": "Hyperspectral imaging (HSI) analysis faces computational bottlenecks due to massive data volumes that exceed available memory. While foundation models pre-trained on large remote sensing datasets show promise, their learned representations often fail to transfer to domain-specific applications like close-range agricultural monitoring where spectral signatures, spatial scales, and semantic targets differ fundamentally. This report presents Deep Global Clustering (DGC), a conceptual framework for memory-efficient HSI segmentation that learns global clustering structure from local patch observations without pre-training. DGC operates on small patches with overlapping regions to enforce consistency, enabling training in under 30 minutes on consumer hardware while maintaining constant memory usage. On a leaf disease dataset, DGC achieves background-tissue separation (mean IoU 0.925) and demonstrates unsupervised disease detection through navigable semantic granularity. However, the framework suffers from optimization instability rooted in multi-objective loss balancing: meaningful representations emerge rapidly but degrade due to cluster over-merging in feature space. We position this work as intellectual scaffolding - the design philosophy has merit, but stable implementation requires principled approaches to dynamic loss balancing. Code and data are available at https://github.com/b05611038/HSI_global_clustering.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24172.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24172",
      "published": "2025-12-30T12:10:43Z",
      "updated": "2025-12-30T12:10:43Z",
      "comment": "10 pages, 4 figures. Technical report extending ACPA 2025 conference paper. Code and data available at https://github.com/b05611038/HSI_global_clustering",
      "light_analysis": {
        "overview": "提出Deep Global Clustering框架，用于内存高效的高光谱图像分割。",
        "motivation": "高光谱成像分析因数据量大导致计算瓶颈，现有预训练模型难以迁移到农业监测等特定领域应用。",
        "method": "使用Deep Global Clustering框架，通过重叠小补丁学习全局聚类结构，无需预训练，确保训练效率。",
        "result": "在叶片病害数据集上，平均IoU达0.925，实现无监督病害检测，但存在优化不稳定性问题。",
        "conclusion": "该工作作为智力支架，设计哲学有效，但需 principled 方法解决动态损失平衡以实现稳定实现。",
        "tags": [
          "Deep Clustering",
          "Hyperspectral Imaging",
          "Unsupervised Learning",
          "Image Segmentation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:35.746961Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24165",
      "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
      "authors": [
        "Zefeng He",
        "Xiaoye Qu",
        "Yafu Li",
        "Tong Zhu",
        "Siyuan Huang",
        "Yu Cheng"
      ],
      "abstract": "While recent Multimodal Large Language Models (MLLMs) have attained significant strides in multimodal reasoning, their reasoning processes remain predominantly text-centric, leading to suboptimal performance in complex long-horizon, vision-centric tasks. In this paper, we establish a novel Generative Multimodal Reasoning paradigm and introduce DiffThinker, a diffusion-based reasoning framework. Conceptually, DiffThinker reformulates multimodal reasoning as a native generative image-to-image task, achieving superior logical consistency and spatial precision in vision-centric tasks. We perform a systematic comparison between DiffThinker and MLLMs, providing the first in-depth investigation into the intrinsic characteristics of this paradigm, revealing four core properties: efficiency, controllability, native parallelism, and collaboration. Extensive experiments across four domains (sequential planning, combinatorial optimization, constraint satisfaction, and spatial configuration) demonstrate that DiffThinker significantly outperforms leading closed source models including GPT-5 (+314.2\\%) and Gemini-3-Flash (+111.6\\%), as well as the fine-tuned Qwen3-VL-32B baseline (+39.0\\%), highlighting generative multimodal reasoning as a promising approach for vision-centric reasoning.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24165.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24165",
      "published": "2025-12-30T11:51:18Z",
      "updated": "2025-12-30T11:51:18Z",
      "comment": "Project page: https://diffthinker-project.github.io",
      "light_analysis": {
        "overview": "提出基于扩散模型的生成式多模态推理框架DiffThinker，显著提升视觉中心任务的性能。",
        "motivation": "当前多模态大语言模型推理过程以文本为中心，在复杂视觉中心任务上表现不佳。",
        "method": "提出DiffThinker，将多模态推理重构为原生图像生成任务，利用扩散模型实现逻辑一致和空间精确的推理。",
        "result": "在四个任务领域大幅超越GPT-5、Gemini-3-Flash等主流模型，例如相对GPT-5提升314.2%。",
        "conclusion": "生成式多模态推理是视觉中心推理的有效新范式，具备效率、可控性等核心特性。",
        "tags": [
          "Diffusion Models",
          "Generative Multimodal Reasoning",
          "Multimodal Large Language Models",
          "Vision-Centric Reasoning",
          "Image-to-Image Generation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:38.310535Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24162",
      "title": "Bayesian Self-Distillation for Image Classification",
      "authors": [
        "Anton Adelöw",
        "Matteo Gamba",
        "Atsuto Maki"
      ],
      "abstract": "Supervised training of deep neural networks for classification typically relies on hard targets, which promote overconfidence and can limit calibration, generalization, and robustness. Self-distillation methods aim to mitigate this by leveraging inter-class and sample-specific information present in the model's own predictions, but often remain dependent on hard targets, reducing their effectiveness. With this in mind, we propose Bayesian Self-Distillation (BSD), a principled method for constructing sample-specific target distributions via Bayesian inference using the model's own predictions. Unlike existing approaches, BSD does not rely on hard targets after initialization. BSD consistently yields higher test accuracy (e.g. +1.4% for ResNet-50 on CIFAR-100) and significantly lower Expected Calibration Error (ECE) (-40% ResNet-50, CIFAR-100) than existing architecture-preserving self-distillation methods for a range of deep architectures and datasets. Additional benefits include improved robustness against data corruptions, perturbations, and label noise. When combined with a contrastive loss, BSD achieves state-of-the-art robustness under label noise for single-stage, single-network methods.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24162.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24162",
      "published": "2025-12-30T11:48:06Z",
      "updated": "2025-12-30T11:48:06Z",
      "comment": "17 pages, 17 figures",
      "light_analysis": {
        "overview": "提出了贝叶斯自蒸馏方法，通过不依赖硬标签的样本特定目标分布提升图像分类的精度与鲁棒性。",
        "motivation": "监督训练依赖硬标签会导致模型过度自信，影响其校准、泛化能力和鲁棒性，现有自蒸馏方法效果有限。",
        "method": "提出贝叶斯自蒸馏，利用贝叶斯推理和模型自身预测构建样本特定目标分布，完全摒弃对硬标签的依赖。",
        "result": "在多个架构和数据集上，测试准确率显著提升，校准误差大幅降低，对数据损坏和标签噪声的鲁棒性增强。",
        "conclusion": "BSD是一种有效的单阶段单网络训练方法，结合对比损失后在标签噪声下达到最佳鲁棒性。",
        "tags": [
          "Self-Distillation",
          "Bayesian Inference",
          "Calibration",
          "Label Noise Robustness",
          "Contrastive Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:58.060006Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24157",
      "title": "Training Report of TeleChat3-MoE",
      "authors": [
        "Xinzhang Liu",
        "Chao Wang",
        "Zhihao Yang",
        "Zhuo Jiang",
        "Xuncheng Zhao",
        "Haoran Wang",
        "Lei Li",
        "Dongdong He",
        "Luobin Liu",
        "Kaizhe Yuan",
        "Han Gao",
        "Zihan Wang",
        "Yitong Yao",
        "Sishi Xiong",
        "Wenmin Deng",
        "Haowei He",
        "Kaidong Yu",
        "Yu Zhao",
        "Ruiyu Fang",
        "Yuhao Jiang",
        "Yingyan Li",
        "Xiaohui Hu",
        "Xi Yu",
        "Jingqi Li",
        "Yanwei Liu",
        "Qingli Li",
        "Xinyu Shi",
        "Junhao Niu",
        "Chengnuo Huang",
        "Yao Xiao",
        "Ruiwen Wang",
        "Fengkai Li",
        "Luwen Pu",
        "Kaipeng Jia",
        "Fubei Yao",
        "Yuyao Huang",
        "Xuewei He",
        "Zhuoru Jiang",
        "Ruiting Song",
        "Rui Xue",
        "Qiyi Xie",
        "Jie Zhang",
        "Zilu Huang",
        "Zhaoxi Zhang",
        "Zhilong Lu",
        "Yanhan Zhang",
        "Yin Zhang",
        "Yanlei Xue",
        "Zhu Yuan",
        "Teng Su",
        "Xin Jiang",
        "Shuangyong Song",
        "Yongxiang Li",
        "Xuelong Li"
      ],
      "abstract": "TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastructure that enables reliable and efficient scaling to frontier model sizes. We detail systematic methodologies for operator-level and end-to-end numerical accuracy verification, ensuring consistency across hardware platforms and distributed parallelism strategies. Furthermore, we introduce a suite of performance optimizations, including interleaved pipeline scheduling, attention-aware data scheduling for long-sequence training,hierarchical and overlapped communication for expert parallelism, and DVM-based operator fusion. A systematic parallelization framework, leveraging analytical estimation and integer linear programming, is also proposed to optimize multi-dimensional parallelism configurations. Additionally, we present methodological approaches to cluster-level optimizations, addressing host- and device-bound bottlenecks during large-scale training tasks. These infrastructure advancements yield significant throughput improvements and near-linear scaling on clusters comprising thousands of devices, providing a robust foundation for large-scale language model development on hardware ecosystems.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24157.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24157",
      "published": "2025-12-30T11:42:14Z",
      "updated": "2025-12-30T11:42:14Z",
      "comment": null,
      "light_analysis": {
        "overview": "介绍TeleChat3-MoE训练基础设施，包括优化方法和框架，实现大规模语言模型高效训练。",
        "motivation": "解决大规模语言模型训练中的可扩展性、效率和可靠性问题，以支持前沿模型规模的发展。",
        "method": "采用系统化数值精度验证、性能优化（如交错管道调度、注意力感知数据调度）、并行化框架（基于分析估计和整数线性编程）和集群级优化。",
        "result": "显著提高训练吞吐量，在数千设备集群上实现近线性缩放。",
        "conclusion": "提供了大规模语言模型训练的稳健基础设施，为硬件生态系统上的模型开发奠定基础。",
        "tags": [
          "Large Language Model",
          "Mixture-of-Experts",
          "Distributed Training",
          "Performance Optimization",
          "Integer Linear Programming"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:45.867798Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24156",
      "title": "Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks",
      "authors": [
        "Evgenii Rudakov",
        "Jonathan Shock",
        "Benjamin Ultan Cowley"
      ],
      "abstract": "We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24156.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24156",
      "published": "2025-12-30T11:40:23Z",
      "updated": "2025-12-30T11:40:23Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种无需训练的图基探索方法，用于解决ARC-AGI-3交互推理任务，显著优于基于前沿LLM的智能体。",
        "motivation": "解决ARC-AGI-3交互推理任务，因为现有最先进的LLM无法可靠捕获任务动态并解决这些问题。",
        "method": "结合基于视觉的帧处理与图结构表示，进行系统化状态空间探索、动作优先级排序和状态转移图维护。",
        "result": "在ARC-AGI-3预览挑战中，解决了52个关卡中的中位数30个，在私有排行榜上排名第三。",
        "conclusion": "显式的图结构探索可作为交互推理的强基线，突显了在LLM失效的环境中系统化状态跟踪和动作优先级的重要性。",
        "tags": [
          "Graph-Based Exploration",
          "Interactive Reasoning",
          "State-Space Exploration",
          "Visual Salience",
          "Systematic Exploration"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:09.674984Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24149",
      "title": "Large Emotional World Model",
      "authors": [
        "Changhao Song",
        "Yazhou Zhang",
        "Hui Gao",
        "Chang Yang",
        "Peng Zhang"
      ],
      "abstract": "World Models serve as tools for understanding the current state of the world and predicting its future dynamics, with broad application potential across numerous fields. As a key component of world knowledge, emotion significantly influences human decision-making. While existing Large Language Models (LLMs) have shown preliminary capability in capturing world knowledge, they primarily focus on modeling physical-world regularities and lack systematic exploration of emotional factors. In this paper, we first demonstrate the importance of emotion in understanding the world by showing that removing emotionally relevant information degrades reasoning performance. Inspired by theory of mind, we further propose a Large Emotional World Model (LEWM). Specifically, we construct the Emotion-Why-How (EWH) dataset, which integrates emotion into causal relationships and enables reasoning about why actions occur and how emotions drive future world states. Based on this dataset, LEWM explicitly models emotional states alongside visual observations and actions, allowing the world model to predict both future states and emotional transitions. Experimental results show that LEWM more accurately predicts emotion-driven social behaviors while maintaining comparable performance to general world models on basic tasks.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24149.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24149",
      "published": "2025-12-30T11:26:01Z",
      "updated": "2025-12-30T11:26:01Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了大情感世界模型，通过整合情感建模，提升了预测情感驱动社会行为的能力。",
        "motivation": "现有世界模型主要关注物理规律，缺乏对情感的系统探索，而情感是理解世界和决策的关键因素。",
        "method": "构建Emotion-Why-How数据集，基于理论模拟，显式建模情感状态、视觉观察和动作，以预测未来状态和情感转换。",
        "result": "LEWM更准确预测情感驱动社会行为，同时在基本任务上与一般世界模型性能相当。",
        "conclusion": "贡献是提出LEWM，将情感整合到世界模型中，增强了情感相关推理和社会行为预测能力。",
        "tags": [
          "World Models",
          "Large Language Models",
          "Emotion Modeling",
          "Causal Reasoning",
          "Theory of Mind"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:04.560324Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24146",
      "title": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning",
      "authors": [
        "Chubin Chen",
        "Sujie Hu",
        "Jiashu Zhu",
        "Meiqi Wu",
        "Jintao Chen",
        "Yanxun Li",
        "Nisha Huang",
        "Chengyu Fang",
        "Jiahong Wu",
        "Xiangxiang Chu",
        "Xiu Li"
      ],
      "abstract": "Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model's inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D$^2$-Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model's embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D$^2$-Align achieves superior alignment with human preference.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24146.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24146",
      "published": "2025-12-30T11:17:52Z",
      "updated": "2025-12-30T11:17:52Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出D^2-Align框架和DivGenBench基准，以解决扩散模型人类反馈强化学习中的偏好模式崩溃问题。",
        "motivation": "现有基于人类反馈的扩散模型强化学习方法易导致偏好模式崩溃，即模型为追求高分而收敛于狭窄的输出模式，损害生成多样性。",
        "method": "提出方向性解耦对齐方法，通过在冻结的奖励模型嵌入空间中学习方向性修正，并在优化过程中应用此修正以防止模型坍塌。",
        "result": "综合评估表明，D^2-Align在质量和多样性指标上均实现了更优的人类偏好对齐效果。",
        "conclusion": "本研究量化了偏好模式崩溃现象，并提出的新框架能有效缓解该问题，保持生成多样性。",
        "tags": [
          "Diffusion Models",
          "Reinforcement Learning from Human Feedback",
          "Reward Hacking",
          "Preference Alignment"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:56.099906Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24143",
      "title": "Activation Steering for Masked Diffusion Language Models",
      "authors": [
        "Adi Shnaidman",
        "Erin Feiglin",
        "Osher Yaari",
        "Efrat Mentel",
        "Amit Levi",
        "Raz Lapid"
      ],
      "abstract": "Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steering in MDLMs remain largely unexplored. We present an activation-steering framework for MDLMs that computes layer-wise steering vectors from a single forward pass using contrastive examples, without simulating the denoising trajectory. These directions are applied at every reverse-diffusion step, yielding an efficient inference-time control mechanism. Experiments on LLaDA-8B-Instruct demonstrate reliable modulation of high-level attributes, with ablations examining the effects of steering across transformer sub-modules and token scope (prompt vs.\\ response).",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24143.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24143",
      "published": "2025-12-30T11:10:52Z",
      "updated": "2025-12-30T11:10:52Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一个激活引导框架，用于掩码扩散语言模型的推理时控制和属性调制。",
        "motivation": "解决掩码扩散语言模型在推理时缺乏有效控制和引导机制的问题。",
        "method": "使用对比示例计算层间引导向量，并应用于每个反向扩散步骤，无需模拟去噪轨迹。",
        "result": "在 LLaDA-8B-Instruct 上实验，实现可靠的高级属性调制，并通过消融研究分析引导的影响。",
        "conclusion": "提出了一个高效的激活引导框架，为掩码扩散语言模型提供了可扩展的推理时控制方法。",
        "tags": [
          "Masked Diffusion Language Models",
          "Activation Steering",
          "Contrastive Learning",
          "Inference-time Control",
          "Transformer Sub-modules"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:20.549746Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24139",
      "title": "Colorful Pinball: Density-Weighted Quantile Regression for Conditional Guarantee of Conformal Prediction",
      "authors": [
        "Qianyi Chen",
        "Bo Li"
      ],
      "abstract": "While conformal prediction provides robust marginal coverage guarantees, achieving reliable conditional coverage for specific inputs remains challenging. Although exact distribution-free conditional coverage is impossible with finite samples, recent work has focused on improving the conditional coverage of standard conformal procedures. Distinct from approaches that target relaxed notions of conditional coverage, we directly minimize the mean squared error of conditional coverage by refining the quantile regression components that underpin many conformal methods. Leveraging a Taylor expansion, we derive a sharp surrogate objective for quantile regression: a density-weighted pinball loss, where the weights are given by the conditional density of the conformity score evaluated at the true quantile. We propose a three-headed quantile network that estimates these weights via finite differences using auxiliary quantile levels at \\(1-α\\pm δ\\), subsequently fine-tuning the central quantile by optimizing the weighted loss. We provide a theoretical analysis with exact non-asymptotic guarantees characterizing the resulting excess risk. Extensive experiments on diverse high-dimensional real-world datasets demonstrate remarkable improvements in conditional coverage performance.",
      "categories": [
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24139.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24139",
      "published": "2025-12-30T11:02:35Z",
      "updated": "2025-12-30T11:02:35Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出密度加权分位数回归方法，改进 conformal prediction 的条件覆盖性能。",
        "motivation": "conformal prediction 提供稳健边际覆盖保证，但实现可靠条件覆盖对特定输入仍有挑战，需改进标准方法。",
        "method": "通过泰勒展开推导密度加权 pinball 损失作为代理目标，使用三头分位数网络估计权重并微调中心分位数。",
        "result": "理论分析提供精确非渐进风险保证，高维真实数据集实验显示条件覆盖性能显著提升。",
        "conclusion": "直接最小化条件覆盖均方误差，改善标准 conformal 程序的条件覆盖，具有理论和实证意义。",
        "tags": [
          "Conformal Prediction",
          "Quantile Regression",
          "Density-Weighted Loss",
          "Conditional Coverage"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:25.312919Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24138",
      "title": "GARDO: Reinforcing Diffusion Models without Reward Hacking",
      "authors": [
        "Haoran He",
        "Yuxiao Ye",
        "Jie Liu",
        "Jiajun Liang",
        "Zhiyong Wang",
        "Ziyang Yuan",
        "Xintao Wang",
        "Hangyu Mao",
        "Pengfei Wan",
        "Ling Pan"
      ],
      "abstract": "Fine-tuning diffusion models via online reinforcement learning (RL) has shown great potential for enhancing text-to-image alignment. However, since precisely specifying a ground-truth objective for visual tasks remains challenging, the models are often optimized using a proxy reward that only partially captures the true goal. This mismatch often leads to reward hacking, where proxy scores increase while real image quality deteriorates and generation diversity collapses. While common solutions add regularization against the reference policy to prevent reward hacking, they compromise sample efficiency and impede the exploration of novel, high-reward regions, as the reference policy is usually sub-optimal. To address the competing demands of sample efficiency, effective exploration, and mitigation of reward hacking, we propose Gated and Adaptive Regularization with Diversity-aware Optimization (GARDO), a versatile framework compatible with various RL algorithms. Our key insight is that regularization need not be applied universally; instead, it is highly effective to selectively penalize a subset of samples that exhibit high uncertainty. To address the exploration challenge, GARDO introduces an adaptive regularization mechanism wherein the reference model is periodically updated to match the capabilities of the online policy, ensuring a relevant regularization target. To address the mode collapse issue in RL, GARDO amplifies the rewards for high-quality samples that also exhibit high diversity, encouraging mode coverage without destabilizing the optimization process. Extensive experiments across diverse proxy rewards and hold-out unseen metrics consistently show that GARDO mitigates reward hacking and enhances generation diversity without sacrificing sample efficiency or exploration, highlighting its effectiveness and robustness.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24138.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24138",
      "published": "2025-12-30T10:55:45Z",
      "updated": "2025-12-30T10:55:45Z",
      "comment": "17 pages. Project: https://tinnerhrhe.github.io/gardo_project",
      "light_analysis": {
        "overview": "提出GARDO框架，通过自适应正则化和多样性优化，解决扩散模型强化学习中的奖励黑客问题。",
        "motivation": "在线强化学习微调扩散模型时，代理奖励不匹配导致奖励黑客，图像质量下降和多样性崩溃，现有正则化方法损害样本效率并阻碍探索。",
        "method": "采用GARDO框架，包括选择性惩罚高不确定性样本的门控机制、自适应更新参考模型的正则化，以及奖励高质量高多样性样本的多样性感知优化。",
        "result": "实验显示GARDO在多种代理奖励和未见指标上有效缓解奖励黑客，增强生成多样性，且不牺牲样本效率或探索。",
        "conclusion": "GARDO为解决扩散模型强化学习中的奖励黑客和模式崩溃问题提供了一个通用、有效且鲁棒的框架。",
        "tags": [
          "Diffusion Models",
          "Reinforcement Learning",
          "Reward Hacking",
          "Adaptive Regularization",
          "Diversity Optimization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:51:05.654393Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24124",
      "title": "OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization",
      "authors": [
        "Advait Gadhikar",
        "Riccardo Grazzi",
        "James Hensman"
      ],
      "abstract": "The presence of outliers in Large Language Models (LLMs) weights and activations makes them difficult to quantize. Recent work has leveraged rotations to mitigate these outliers. In this work, we propose methods that learn fusible rotations by minimizing principled and cheap proxy objectives to the weight quantization error. We primarily focus on GPTQ as the quantization method. Our main method is OptRot, which reduces weight outliers simply by minimizing the element-wise fourth power of the rotated weights. We show that OptRot outperforms both Hadamard rotations and more expensive, data-dependent methods like SpinQuant and OSTQuant for weight quantization. It also improves activation quantization in the W4A8 setting. We also propose a data-dependent method, OptRot$^{+}$, that further improves performance by incorporating information on the activation covariance. In the W4A4 setting, we see that both OptRot and OptRot$^{+}$ perform worse, highlighting a trade-off between weight and activation quantization.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24124.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24124",
      "published": "2025-12-30T10:13:50Z",
      "updated": "2025-12-30T10:13:50Z",
      "comment": "25 pages, 10 figures",
      "light_analysis": {
        "overview": "提出OptRot方法，通过数据无关旋转减少大语言模型权重异常值，以改进后训练量化。",
        "motivation": "解决大型语言模型中权重和激活的异常值导致量化困难的问题。",
        "method": "提出OptRot，通过最小化旋转后权重元素四次方来学习可融合旋转；并扩展为数据依赖的OptRot+，结合激活协方差信息。",
        "result": "OptRot在权重量化上优于Hadamard旋转和SpinQuant等方法；在W4A8设置中改进激活量化；在W4A4设置中性能下降。",
        "conclusion": "贡献是提出高效的数据无关旋转方法，减少量化误差，并验证在特定量化设置中的有效性和权衡。",
        "tags": [
          "Large Language Model",
          "Post-Training Quantization",
          "GPTQ",
          "Weight Rotation",
          "Outlier Mitigation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:50.311160Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24120",
      "title": "Enhancing LLM-Based Neural Network Generation: Few-Shot Prompting and Efficient Validation for Automated Architecture Design",
      "authors": [
        "Chandini Vysyaraju",
        "Raghuvir Duvvuri",
        "Avi Goyal",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "abstract": "Automated neural network architecture design remains a significant challenge in computer vision. Task diversity and computational constraints require both effective architectures and efficient search methods. Large Language Models (LLMs) present a promising alternative to computationally intensive Neural Architecture Search (NAS), but their application to architecture generation in computer vision has not been systematically studied, particularly regarding prompt engineering and validation strategies. Building on the task-agnostic NNGPT/LEMUR framework, this work introduces and validates two key contributions for computer vision. First, we present Few-Shot Architecture Prompting (FSAP), the first systematic study of the number of supporting examples (n = 1, 2, 3, 4, 5, 6) for LLM-based architecture generation. We find that using n = 3 examples best balances architectural diversity and context focus for vision tasks. Second, we introduce Whitespace-Normalized Hash Validation, a lightweight deduplication method (less than 1 ms) that provides a 100x speedup over AST parsing and prevents redundant training of duplicate computer vision architectures. In large-scale experiments across seven computer vision benchmarks (MNIST, CIFAR-10, CIFAR-100, CelebA, ImageNette, SVHN, Places365), we generated 1,900 unique architectures. We also introduce a dataset-balanced evaluation methodology to address the challenge of comparing architectures across heterogeneous vision tasks. These contributions provide actionable guidelines for LLM-based architecture search in computer vision and establish rigorous evaluation practices, making automated design more accessible to researchers with limited computational resources.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24120.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24120",
      "published": "2025-12-30T10:01:55Z",
      "updated": "2025-12-30T10:01:55Z",
      "comment": null,
      "light_analysis": {
        "overview": "本文为LLM在计算机视觉架构生成提出了少样本提示与高效验证方法，并建立了系统评估规范。",
        "motivation": "旨在系统研究LLM在计算机视觉架构生成中的应用，解决其提示工程与高效验证策略缺乏的问题。",
        "method": "提出Few-Shot Architecture Prompting (FSAP)和Whitespace-Normalized Hash Validation，前者研究示例数量影响，后者用于轻量级架构去重。",
        "result": "发现使用3个示例时平衡最佳，验证方法提速100倍，在7个数据集上生成了1900个独特架构。",
        "conclusion": "为基于LLM的视觉架构搜索提供了实用指南和严格评估实践，降低了计算资源门槛。",
        "tags": [
          "Large Language Model",
          "Neural Architecture Search",
          "Computer Vision",
          "Prompt Engineering",
          "Few-Shot Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:29.774023Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24119",
      "title": "GeoBench: Rethinking Multimodal Geometric Problem-Solving via Hierarchical Evaluation",
      "authors": [
        "Yuan Feng",
        "Yue Yang",
        "Xiaohan He",
        "Jiatong Zhao",
        "Jianlong Chen",
        "Zijun Chen",
        "Daocheng Fu",
        "Qi Liu",
        "Renqiu Xia",
        "Bo Zhang",
        "Junchi Yan"
      ],
      "abstract": "Geometric problem solving constitutes a critical branch of mathematical reasoning, requiring precise analysis of shapes and spatial relationships. Current evaluations of geometric reasoning in vision-language models (VLMs) face limitations, including the risk of test data contamination from textbook-based benchmarks, overemphasis on final answers over reasoning processes, and insufficient diagnostic granularity. To address these issues, we present GeoBench, a hierarchical benchmark featuring four reasoning levels in geometric problem-solving: Visual Perception, Goal-Oriented Planning, Rigorous Theorem Application, and Self-Reflective Backtracking. Through six formally verified tasks generated via TrustGeoGen, we systematically assess capabilities ranging from attribute extraction to logical error correction. Experiments reveal that while reasoning models like OpenAI-o3 outperform general MLLMs, performance declines significantly with increasing task complexity. Key findings demonstrate that sub-goal decomposition and irrelevant premise filtering critically influence final problem-solving accuracy, whereas Chain-of-Thought prompting unexpectedly degrades performance in some tasks. These findings establish GeoBench as a comprehensive benchmark while offering actionable guidelines for developing geometric problem-solving systems.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24119.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24119",
      "published": "2025-12-30T09:56:37Z",
      "updated": "2025-12-30T09:56:37Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了GeoBench分层基准，用于评估多模态几何问题解决能力，并揭示关键影响因素。",
        "motivation": "解决当前几何推理评估中数据污染、重答案轻过程、诊断粒度不足等局限性。",
        "method": "提出GeoBench基准，包含四个推理级别，并通过TrustGeoGen生成六个正式验证任务进行系统评估。",
        "result": "推理模型性能随复杂度下降；子目标分解和前提过滤影响准确性；CoT提示在某些任务中降低性能。",
        "conclusion": "GeoBench成为综合评估基准，为开发几何问题解决系统提供了可行指南。",
        "tags": [
          "Vision-Language Models",
          "Geometric Reasoning",
          "Hierarchical Evaluation",
          "Chain-of-Thought Prompting",
          "TrustGeoGen"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:21.362088Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24111",
      "title": "Guided Diffusion-based Generation of Adversarial Objects for Real-World Monocular Depth Estimation Attacks",
      "authors": [
        "Yongtao Chen",
        "Yanbo Wang",
        "Wentao Zhao",
        "Guole Shen",
        "Tianchen Deng",
        "Jingchuan Wang"
      ],
      "abstract": "Monocular Depth Estimation (MDE) serves as a core perception module in autonomous driving systems, but it remains highly susceptible to adversarial attacks. Errors in depth estimation may propagate through downstream decision making and influence overall traffic safety. Existing physical attacks primarily rely on texture-based patches, which impose strict placement constraints and exhibit limited realism, thereby reducing their effectiveness in complex driving environments. To overcome these limitations, this work introduces a training-free generative adversarial attack framework that generates naturalistic, scene-consistent adversarial objects via a diffusion-based conditional generation process. The framework incorporates a Salient Region Selection module that identifies regions most influential to MDE and a Jacobian Vector Product Guidance mechanism that steers adversarial gradients toward update directions supported by the pre-trained diffusion model. This formulation enables the generation of physically plausible adversarial objects capable of inducing substantial adversarial depth shifts. Extensive digital and physical experiments demonstrate that our method significantly outperforms existing attacks in effectiveness, stealthiness, and physical deployability, underscoring its strong practical implications for autonomous driving safety assessment.",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24111.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24111",
      "published": "2025-12-30T09:41:41Z",
      "updated": "2025-12-30T09:41:41Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种基于扩散模型的训练无关框架，生成自然、场景一致的对抗对象以攻击单目深度估计系统。",
        "motivation": "单目深度估计在自动驾驶中易受攻击，现有纹理贴片攻击约束多、真实性差，需开发更有效的对抗攻击以评估系统安全。",
        "method": "使用扩散模型条件生成过程，结合显著性区域选择和Jacobian向量积指导机制，生成物理可行的对抗对象。",
        "result": "数字和物理实验表明，该方法在攻击效果、隐蔽性和物理部署性上显著优于现有攻击方法。",
        "conclusion": "该框架能生成诱导深度估计错误的对抗对象，为自动驾驶安全评估提供强实践意义。",
        "tags": [
          "Diffusion Models",
          "Adversarial Attacks",
          "Monocular Depth Estimation",
          "Jacobian Vector Product"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:03.170215Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24100",
      "title": "Think Before You Move: Latent Motion Reasoning for Text-to-Motion Generation",
      "authors": [
        "Yijie Qian",
        "Juncheng Wang",
        "Yuxiang Feng",
        "Chao Xu",
        "Wang Lu",
        "Yang Liu",
        "Baigui Sun",
        "Yiqiang Chen",
        "Yong Liu",
        "Shujun Wang"
      ],
      "abstract": "Current state-of-the-art paradigms predominantly treat Text-to-Motion (T2M) generation as a direct translation problem, mapping symbolic language directly to continuous poses. While effective for simple actions, this System 1 approach faces a fundamental theoretical bottleneck we identify as the Semantic-Kinematic Impedance Mismatch: the inherent difficulty of grounding semantically dense, discrete linguistic intent into kinematically dense, high-frequency motion data in a single shot. In this paper, we argue that the solution lies in an architectural shift towards Latent System 2 Reasoning. Drawing inspiration from Hierarchical Motor Control in cognitive science, we propose Latent Motion Reasoning (LMR) that reformulates generation as a two-stage Think-then-Act decision process. Central to LMR is a novel Dual-Granularity Tokenizer that disentangles motion into two distinct manifolds: a compressed, semantically rich Reasoning Latent for planning global topology, and a high-frequency Execution Latent for preserving physical fidelity. By forcing the model to autoregressively reason (plan the coarse trajectory) before it moves (instantiates the frames), we effectively bridge the ineffability gap between language and physics. We demonstrate LMR's versatility by implementing it for two representative baselines: T2M-GPT (discrete) and MotionStreamer (continuous). Extensive experiments show that LMR yields non-trivial improvements in both semantic alignment and physical plausibility, validating that the optimal substrate for motion planning is not natural language, but a learned, motion-aligned concept space. Codes and demos can be found in \\hyperlink{https://chenhaoqcdyq.github.io/LMR/}{https://chenhaoqcdyq.github.io/LMR/}",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24100.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24100",
      "published": "2025-12-30T09:17:44Z",
      "updated": "2025-12-30T09:17:44Z",
      "comment": "project page: https://chenhaoqcdyq.github.io/LMR/",
      "light_analysis": {
        "overview": "提出潜在运动推理方法，通过“先思考后行动”的两阶段决策，提升文本到动作生成的语义对齐与物理合理性。",
        "motivation": "解决现有T2M方法将语言直接映射到动作导致的“语义-运动学阻抗不匹配”问题，即一次性融合密集语义与高频运动数据的困难。",
        "method": "提出潜在运动推理框架，引入双粒度分词器将动作解耦为规划潜在空间和执行潜在空间，实现先规划粗粒度轨迹再生成细粒度帧的两阶段生成。",
        "result": "在两个代表性基线模型上均取得显著提升，在语义对齐和物理合理性方面均获得非平凡改进，验证了方法的有效性和通用性。",
        "conclusion": "研究通过引入分层推理机制，证明了使用习得的、动作对齐的概念空间进行规划，比直接使用自然语言更优，有效弥合了语言与物理动作间的鸿沟。",
        "tags": [
          "Text-to-Motion Generation",
          "Latent Space Disentanglement",
          "Autoregressive Generation",
          "Hierarchical Control",
          "Semantic Alignment"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:54.119744Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24097",
      "title": "Factorized Learning for Temporally Grounded Video-Language Models",
      "authors": [
        "Wenzheng Zeng",
        "Difei Gao",
        "Mike Zheng Shou",
        "Hwee Tou Ng"
      ],
      "abstract": "Recent video-language models have shown great potential for video understanding, but still struggle with accurate temporal grounding for event-level perception. We observe that two main factors in video understanding (i.e., temporal grounding and textual response) form a logical hierarchy: accurate temporal evidence grounding lays the foundation for reliable textual response. However, existing works typically handle these two tasks in a coupled manner without a clear logical structure, leading to sub-optimal objectives. We address this from a factorized learning perspective. We first propose D$^2$VLM, a framework that decouples the learning of these two tasks while also emphasizing their inherent dependency. We adopt a \"grounding then answering with evidence referencing\" paradigm and introduce evidence tokens for evidence grounding, which emphasize event-level visual semantic capture beyond the focus on timestamp representation in existing works. To further facilitate the learning of these two tasks, we introduce a novel factorized preference optimization (FPO) algorithm. Unlike standard preference optimization, FPO explicitly incorporates probabilistic temporal grounding modeling into the optimization objective, enabling preference learning for both temporal grounding and textual response. We also construct a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding. Experiments on various tasks demonstrate the clear advantage of our approach. Our source code is available at https://github.com/nusnlp/d2vlm.",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24097.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24097",
      "published": "2025-12-30T09:13:20Z",
      "updated": "2025-12-30T09:13:20Z",
      "comment": "ICCV 2025 paper. This arXiv version updates Figure 1 to include the concurrent work Qwen2.5-VL to ensure consistency with Table 1",
      "light_analysis": {
        "overview": "提出了因子化学习框架 D^2VLM 和 FPO 算法，用于提升视频语言模型的时间 grounding 准确性。",
        "motivation": "解决视频语言模型中时间 grounding 不准确的问题，现有方法耦合处理 grounding 和响应任务，导致逻辑结构不清。",
        "method": "采用 D^2VLM 框架解耦学习 grounding 和响应任务，引入证据令牌进行事件级 grounding，并提出因子化偏好优化（FPO）算法。",
        "result": "在多种任务上的实验证明了方法的明显优势。",
        "conclusion": "通过因子化学习和 FPO 算法，有效改善了视频语言模型的时间 grounding 和文本响应能力。",
        "tags": [
          "Video-Language Models",
          "Temporal Grounding",
          "Factorized Learning",
          "Preference Optimization",
          "Evidence Tokens"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:19.323566Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24092",
      "title": "HY-MT1.5 Technical Report",
      "authors": [
        "Mao Zheng",
        "Zheng Li",
        "Tao Chen",
        "Mingyang Song",
        "Di Wang"
      ],
      "abstract": "In this report, we introduce our latest translation models, HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of machine translation models developed through a holistic training framework tailored for high-performance translation. Our methodology orchestrates a multi-stage pipeline that integrates general and MT-oriented pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. HY-MT1.5-1.8B, the 1.8B-parameter model demonstrates remarkable parameter efficiency, comprehensively outperforming significantly larger open-source baselines (e.g., Tower-Plus-72B, Qwen3-32B) and mainstream commercial APIs (e.g., Microsoft Translator, Doubao Translator) in standard Chinese-foreign and English-foreign tasks. It achieves approximately 90% of the performance of ultra-large proprietary models such as Gemini-3.0-Pro, while marginally trailing Gemini-3.0-Pro on WMT25 and Mandarin-minority language benchmarks, it maintains a substantial lead over other competing models. Furthermore, HY-MT1.5-7B establishes a new state-of-the-art for its size class, achieving 95% of Gemini-3.0-Pro's performance on Flores-200 and surpassing it on the challenging WMT25 and Mandarin-minority language test sets. Beyond standard translation, the HY-MT1.5 series supports advanced constraints, including terminology intervention, context-aware translation, and format preservation. Extensive empirical evaluations confirm that both models offer highly competitive, robust solutions for general and specialized translation tasks within their respective parameter scales.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24092.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24092",
      "published": "2025-12-30T09:06:37Z",
      "updated": "2025-12-30T09:06:37Z",
      "comment": null,
      "light_analysis": {
        "overview": "介绍了HY-MT1.5系列高性能机器翻译模型，通过整体训练框架在参数效率和性能上超越现有模型。",
        "motivation": "开发参数高效的高性能机器翻译模型，以超越现有大型开源模型和商业API，提升翻译任务的性能与效率。",
        "method": "采用了多阶段训练框架，整合通用与MT专用预训练、监督微调、策略蒸馏和强化学习。",
        "result": "1.8B模型在标准任务上超越大模型，性能达Gemini-3.0-Pro的90%；7B模型在其尺寸类别中领先，Flores-200上达95%性能，并在挑战性任务上超越。",
        "conclusion": "HY-MT1.5系列模型在不同参数规模下提供高效、稳健的翻译方案，支持高级约束，推动了机器翻译技术的发展。",
        "tags": [
          "Machine Translation",
          "Pre-training",
          "Supervised Fine-Tuning",
          "Reinforcement Learning",
          "On-policy Distillation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:47.725089Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24086",
      "title": "RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention",
      "authors": [
        "Aiyue Chen",
        "Yaofu Liu",
        "Junjian Huang",
        "Guang Lian",
        "Yiwu Yao",
        "Wangli Lan",
        "Jing Lin",
        "Zhixin Ma",
        "Tingting Zhou",
        "Harry Yang"
      ],
      "abstract": "In video and image generation tasks, Diffusion Transformer (DiT) models incur extremely high computational costs due to attention mechanisms, which limits their practical applications. Furthermore, with hardware advancements, a wide range of devices besides graphics processing unit (GPU), such as application-specific integrated circuit (ASIC), have been increasingly adopted for model inference. Sparse attention, which leverages the inherent sparsity of attention by skipping computations for insignificant tokens, is an effective approach to mitigate computational costs. However, existing sparse attention methods have two critical limitations: the overhead of sparse pattern prediction and the lack of hardware generality, as most of these methods are designed for GPU. To address these challenges, this study proposes RainFusion2.0, which aims to develop an online adaptive, hardware-efficient, and low-overhead sparse attention mechanism to accelerate both video and image generative models, with robust performance across diverse hardware platforms. Key technical insights include: (1) leveraging block-wise mean values as representative tokens for sparse mask prediction; (2) implementing spatiotemporal-aware token permutation; and (3) introducing a first-frame sink mechanism specifically designed for video generation scenarios. Experimental results demonstrate that RainFusion2.0 can achieve 80% sparsity while achieving an end-to-end speedup of 1.5~1.8x without compromising video quality. Moreover, RainFusion2.0 demonstrates effectiveness across various generative models and validates its generalization across diverse hardware platforms.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24086.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24086",
      "published": "2025-12-30T08:55:20Z",
      "updated": "2025-12-30T08:55:20Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了RainFusion2.0，一种硬件高效、低开销的自适应稀疏注意力机制，用于加速图像和视频生成模型。",
        "motivation": "解决DiT模型因注意力机制导致的高计算成本，以及现有稀疏注意力方法存在预测开销大和硬件通用性差的问题。",
        "method": "利用分块均值作为代表token预测稀疏掩码，实现时空感知的token重排，并针对视频生成设计了首帧下沉机制。",
        "result": "实现了80%的稀疏度，端到端加速1.5~1.8倍且不影响视频质量，在多种生成模型和硬件平台有效。",
        "conclusion": "RainFusion2.0提供了一种通用且高效的稀疏注意力方案，显著降低了生成式模型的推理成本。",
        "tags": [
          "Sparse Attention",
          "Diffusion Transformer",
          "Video Generation",
          "Hardware-Aware Optimization",
          "Temporal-Spatial Awareness"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:43:14.850873Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24074",
      "title": "Balanced Hierarchical Contrastive Learning with Decoupled Queries for Fine-grained Object Detection in Remote Sensing Images",
      "authors": [
        "Jingzhou Chen",
        "Dexin Chen",
        "Fengchao Xiong",
        "Yuntao Qian",
        "Liang Xiao"
      ],
      "abstract": "Fine-grained remote sensing datasets often use hierarchical label structures to differentiate objects in a coarse-to-fine manner, with each object annotated across multiple levels. However, embedding this semantic hierarchy into the representation learning space to improve fine-grained detection performance remains challenging. Previous studies have applied supervised contrastive learning at different hierarchical levels to group objects under the same parent class while distinguishing sibling subcategories. Nevertheless, they overlook two critical issues: (1) imbalanced data distribution across the label hierarchy causes high-frequency classes to dominate the learning process, and (2) learning semantic relationships among categories interferes with class-agnostic localization. To address these issues, we propose a balanced hierarchical contrastive loss combined with a decoupled learning strategy within the detection transformer (DETR) framework. The proposed loss introduces learnable class prototypes and equilibrates gradients contributed by different classes at each hierarchical level, ensuring that each hierarchical class contributes equally to the loss computation in every mini-batch. The decoupled strategy separates DETR's object queries into classification and localization sets, enabling task-specific feature extraction and optimization. Experiments on three fine-grained datasets with hierarchical annotations demonstrate that our method outperforms state-of-the-art approaches.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24074.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24074",
      "published": "2025-12-30T08:35:54Z",
      "updated": "2025-12-30T08:35:54Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出平衡层次对比损失和解耦查询策略，提升遥感图像细粒度目标检测性能。",
        "motivation": "解决细粒度遥感目标检测中，层次标签嵌入的挑战，特别是数据分布不平衡和语义关系学习干扰定位的问题。",
        "method": "在DETR框架中，使用平衡层次对比损失结合可学习类原型均衡梯度，并通过解耦查询策略分离分类和定位任务。",
        "result": "在三个层次标注的细粒度数据集上实验，性能优于现有最先进方法。",
        "conclusion": "有效解决了层次对比学习中的不平衡和任务耦合问题，提高了细粒度检测精度。",
        "tags": [
          "Contrastive Learning",
          "Detection Transformer (DETR)",
          "Fine-grained Object Detection",
          "Remote Sensing Image Analysis"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:15.786554Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24058",
      "title": "Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models",
      "authors": [
        "Rohit Kumar Salla",
        "Manoj Saravanan",
        "Shrikar Reddy Kota"
      ],
      "abstract": "Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24058.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24058",
      "published": "2025-12-30T08:07:28Z",
      "updated": "2025-12-30T08:07:28Z",
      "comment": "5 pages, 4 tables, accepted at AAAI 2026",
      "light_analysis": {
        "overview": "提出综合可靠性评分(CRS)框架，统一评估大语言模型的校准性、鲁棒性和不确定性量化。",
        "motivation": "大语言模型在关键决策领域应用时，存在过度自信错误、对输入变化敏感、缺乏不确定性估计等问题，现有评估方法零散不统一。",
        "method": "引入综合可靠性评分(CRS)统一框架，集成校准、鲁棒性和不确定性量化，并在五个QA数据集上对十个领先开源LLM进行实验评估。",
        "result": "CRS能提供稳定的模型排名，揭示单一指标遗漏的隐藏失败模式，并表明最可靠的系统能平衡准确性、鲁棒性和校准的不确定性。",
        "conclusion": "CRS作为一个可解释的统一度量标准，有助于全面、可靠地评估大语言模型，特别是在决策关键型应用中。",
        "tags": [
          "Large Language Model",
          "Model Calibration",
          "Uncertainty Quantification",
          "Robustness Evaluation",
          "Question Answering"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:45.777698Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24035",
      "title": "Reinforced Diffusion: Learning to Push the Limits of Anisotropic Diffusion for Image Denoising",
      "authors": [
        "Xinran Qin",
        "Yuhui Quan",
        "Ruotao Xu",
        "Hui Ji"
      ],
      "abstract": "Image denoising is an important problem in low-level vision and serves as a critical module for many image recovery tasks. Anisotropic diffusion is a wide family of image denoising approaches with promising performance. However, traditional anisotropic diffusion approaches use explicit diffusion operators which are not well adapted to complex image structures. As a result, their performance is limited compared to recent learning-based approaches. In this work, we describe a trainable anisotropic diffusion framework based on reinforcement learning. By modeling the denoising process as a series of naive diffusion actions with order learned by deep Q-learning, we propose an effective diffusion-based image denoiser. The diffusion actions selected by deep Q-learning at different iterations indeed composite a stochastic anisotropic diffusion process with strong adaptivity to different image structures, which enjoys improvement over the traditional ones. The proposed denoiser is applied to removing three types of often-seen noise. The experiments show that it outperforms existing diffusion-based methods and competes with the representative deep CNN-based methods.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24035.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24035",
      "published": "2025-12-30T07:23:15Z",
      "updated": "2025-12-30T07:23:15Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于强化学习的可训练各向异性扩散框架，用于图像去噪。",
        "motivation": "传统各向异性扩散方法使用显式算子，难以适应复杂图像结构，性能落后于基于学习的方法。",
        "method": "将去噪过程建模为由深度Q学习决定顺序的一系列基础扩散动作，构成自适应的随机扩散过程。",
        "result": "在去除三种常见噪声的任务中，性能优于现有扩散方法，并与代表性的深度CNN方法竞争。",
        "conclusion": "提出的强化扩散框架增强了各向异性扩散的自适应性，提高了去噪性能。",
        "tags": [
          "Image Denoising",
          "Anisotropic Diffusion",
          "Reinforcement Learning",
          "Deep Q-learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:00.093578Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24026",
      "title": "PipeFlow: Pipelined Processing and Motion-Aware Frame Selection for Long-Form Video Editing",
      "authors": [
        "Mustafa Munir",
        "Md Mostafijur Rahman",
        "Kartikeya Bhardwaj",
        "Paul Whatmough",
        "Radu Marculescu"
      ],
      "abstract": "Long-form video editing poses unique challenges due to the exponential increase in the computational cost from joint editing and Denoising Diffusion Implicit Models (DDIM) inversion across extended sequences. To address these limitations, we propose PipeFlow, a scalable, pipelined video editing method that introduces three key innovations: First, based on a motion analysis using Structural Similarity Index Measure (SSIM) and Optical Flow, we identify and propose to skip editing of frames with low motion. Second, we propose a pipelined task scheduling algorithm that splits a video into multiple segments and performs DDIM inversion and joint editing in parallel based on available GPU memory. Lastly, we leverage a neural network-based interpolation technique to smooth out the border frames between segments and interpolate the previously skipped frames. Our method uniquely scales to longer videos by dividing them into smaller segments, allowing PipeFlow's editing time to increase linearly with video length. In principle, this enables editing of infinitely long videos without the growing per-frame computational overhead encountered by other methods. PipeFlow achieves up to a 9.6X speedup compared to TokenFlow and a 31.7X speedup over Diffusion Motion Transfer (DMT).",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24026.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24026",
      "published": "2025-12-30T06:54:57Z",
      "updated": "2025-12-30T06:54:57Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了PipeFlow方法，通过流水线调度和运动感知帧选择，实现长视频编辑时间的线性增长。",
        "motivation": "解决长视频编辑中，联合编辑和DDIM反演导致的计算成本指数级增长问题。",
        "method": "结合SSIM与光流进行运动分析以跳过低运动帧；设计流水线调度算法并行处理视频段；使用神经网络插值平滑边界与补充帧。",
        "result": "编辑时间与视频长度呈线性关系，相比TokenFlow和DMT分别实现最高9.6倍和31.7倍的加速。",
        "conclusion": "PipeFlow通过可扩展的流水线框架，理论上可实现任意长度视频的编辑，解决了传统方法的计算瓶颈。",
        "tags": [
          "Diffusion Models",
          "Optical Flow",
          "Frame Interpolation",
          "Video Editing",
          "SSIM"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:35.548915Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24023",
      "title": "RSAgent: Learning to Reason and Act for Text-Guided Segmentation via Multi-Turn Tool Invocations",
      "authors": [
        "Xingqi He",
        "Yujie Zhang",
        "Shuyong Gao",
        "Wenjie Li",
        "Lingyi Hong",
        "Mingxi Chen",
        "Kaixun Jiang",
        "Jiyuan Fu",
        "Wenqiang Zhang"
      ],
      "abstract": "Text-guided object segmentation requires both cross-modal reasoning and pixel grounding abilities. Most recent methods treat text-guided segmentation as one-shot grounding, where the model predicts pixel prompts in a single forward pass to drive an external segmentor, which limits verification, refocusing and refinement when initial localization is wrong. To address this limitation, we propose RSAgent, an agentic Multimodal Large Language Model (MLLM) which interleaves reasoning and action for segmentation via multi-turn tool invocations. RSAgent queries a segmentation toolbox, observes visual feedback, and revises its spatial hypothesis using historical observations to re-localize targets and iteratively refine masks. We further build a data pipeline to synthesize multi-turn reasoning segmentation trajectories, and train RSAgent with a two-stage framework: cold-start supervised fine-tuning followed by agentic reinforcement learning with fine-grained, task-specific rewards. Extensive experiments show that RSAgent achieves a zero-shot performance of 66.5% gIoU on ReasonSeg test, improving over Seg-Zero-7B by 9%, and reaches 81.5% cIoU on RefCOCOg, demonstrating state-of-the-art performance on both in-domain and out-of-domain benchmarks.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24023.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24023",
      "published": "2025-12-30T06:50:11Z",
      "updated": "2025-12-30T06:50:11Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出RSAgent代理式多模态大语言模型，通过多轮工具调用实现文本引导分割的迭代推理与动作。",
        "motivation": "现有文本引导分割方法为单次定位，无法在初始定位错误时验证、重新聚焦和细化，需解决此限制。",
        "method": "开发RSAgent模型，通过查询分割工具箱、观察反馈并迭代修正，使用数据管道合成轨迹，以监督微调和强化学习两阶段训练。",
        "result": "零样本在ReasonSeg测试中gIoU达66.5%，提升9%；在RefCOCOg上cIoU达81.5%，展示最先进性能。",
        "conclusion": "RSAgent通过多轮交互实现迭代分割，提高准确性和鲁棒性，展示代理式MLLM在视觉任务中的潜力。",
        "tags": [
          "Multimodal Large Language Model",
          "Reinforcement Learning",
          "Text-Guided Segmentation",
          "Tool Invocation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:35.993250Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24018",
      "title": "Structure-Guided Allocation of 2D Gaussians for Image Representation and Compression",
      "authors": [
        "Huanxiong Liang",
        "Yunuo Chen",
        "Yicheng Pan",
        "Sixian Wang",
        "Jincheng Dai",
        "Guo Lu",
        "Wenjun Zhang"
      ],
      "abstract": "Recent advances in 2D Gaussian Splatting (2DGS) have demonstrated its potential as a compact image representation with millisecond-level decoding. However, existing 2DGS-based pipelines allocate representation capacity and parameter precision largely oblivious to image structure, limiting their rate-distortion (RD) efficiency at low bitrates. To address this, we propose a structure-guided allocation principle for 2DGS, which explicitly couples image structure with both representation capacity and quantization precision, while preserving native decoding speed. First, we introduce a structure-guided initialization that assigns 2D Gaussians according to spatial structural priors inherent in natural images, yielding a localized and semantically meaningful distribution. Second, during quantization-aware fine-tuning, we propose adaptive bitwidth quantization of covariance parameters, which grants higher precision to small-scale Gaussians in complex regions and lower precision elsewhere, enabling RD-aware optimization, thereby reducing redundancy without degrading edge quality. Third, we impose a geometry-consistent regularization that aligns Gaussian orientations with local gradient directions to better preserve structural details. Extensive experiments demonstrate that our approach substantially improves both the representational power and the RD performance of 2DGS while maintaining over 1000 FPS decoding. Compared with the baseline GSImage, we reduce BD-rate by 43.44% on Kodak and 29.91% on DIV2K.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24018.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24018",
      "published": "2025-12-30T06:35:46Z",
      "updated": "2025-12-30T06:35:46Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出结构引导的2D高斯分配方法，提升图像表示与压缩的率失真性能，同时保持高速解码。",
        "motivation": "现有2D高斯泼溅方法在分配表示容量与参数精度时忽视图像结构，限制了低比特率下的率失真效率。",
        "method": "提出结构引导初始化、自适应比特量化与几何一致正则化，将图像结构与表示容量和量化精度耦合。",
        "result": "显著提升2DGS表示能力与RD性能，保持超1000 FPS解码，在Kodak和DIV2K数据集上BD-rate分别降低43.44%和29.91%。",
        "conclusion": "方法在保持解码速度的同时，通过结构引导分配有效提升了2D高斯泼溅的率失真效率。",
        "tags": [
          "2D Gaussian Splatting",
          "Rate-Distortion Optimization",
          "Adaptive Quantization",
          "Image Compression",
          "Structure-Guided Initialization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:59.590809Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24015",
      "title": "On Exact Editing of Flow-Based Diffusion Models",
      "authors": [
        "Zixiang Li",
        "Yue Song",
        "Jianing Peng",
        "Ting Liu",
        "Jun Huang",
        "Xiaochao Qu",
        "Luoqi Liu",
        "Wei Wang",
        "Yao Zhao",
        "Yunchao Wei"
      ],
      "abstract": "Recent methods in flow-based diffusion editing have enabled direct transformations between source and target image distribution without explicit inversion. However, the latent trajectories in these methods often exhibit accumulated velocity errors, leading to semantic inconsistency and loss of structural fidelity. We propose Conditioned Velocity Correction (CVC), a principled framework that reformulates flow-based editing as a distribution transformation problem driven by a known source prior. CVC rethinks the role of velocity in inter-distribution transformation by introducing a dual-perspective velocity conversion mechanism. This mechanism explicitly decomposes the latent evolution into two components: a structure-preserving branch that remains consistent with the source trajectory, and a semantically-guided branch that drives a controlled deviation toward the target distribution. The conditional velocity field exhibits an absolute velocity error relative to the true underlying distribution trajectory, which inherently introduces potential instability and trajectory drift in the latent space. To address this quantifiable deviation and maintain fidelity to the true flow, we apply a posterior-consistent update to the resulting conditional velocity field. This update is derived from Empirical Bayes Inference and Tweedie correction, which ensures a mathematically grounded error compensation over time. Our method yields stable and interpretable latent dynamics, achieving faithful reconstruction alongside smooth local semantic conversion. Comprehensive experiments demonstrate that CVC consistently achieves superior fidelity, better semantic alignment, and more reliable editing behavior across diverse tasks.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24015.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24015",
      "published": "2025-12-30T06:29:20Z",
      "updated": "2025-12-30T06:29:20Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了CVC框架，通过双分支速度转换和后验贝叶斯修正，解决了流基扩散模型编辑中的轨迹误差问题。",
        "motivation": "现有流基扩散编辑方法的潜在轨迹存在累积速度误差，导致语义不一致和结构保真度损失。",
        "method": "提出CVC框架，引入双视角速度转换机制，并使用经验贝叶斯推断与Tweedie修正进行后验一致更新。",
        "result": "在多种任务中，CVC实现了更高的图像重构保真度、更好的语义对齐及更稳定可靠的编辑行为。",
        "conclusion": "为流基扩散模型提供了一种精确编辑的稳定且可解释的解决方案，提升了编辑的保真度与可控性。",
        "tags": [
          "Flow-based Diffusion Models",
          "Velocity Correction",
          "Distribution Transformation",
          "Empirical Bayes Inference",
          "Tweedie Correction"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:42.253526Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24014",
      "title": "iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning",
      "authors": [
        "Sijia Chen",
        "Di Niu"
      ],
      "abstract": "Large language models (LLMs), when guided by explicit textual plans, can perform reliable step-by-step reasoning during problem-solving. However, generating accurate and effective textual plans remains challenging due to LLM hallucinations and the high diversity of task-specific questions. To address this, we draw inspiration from human Implicit Cognition (IC), the subconscious process by which decisions are guided by compact, generalized patterns learned from past experiences without requiring explicit verbalization. We propose iCLP, a novel framework that enables LLMs to adaptively generate latent plans (LPs), which are compact encodings of effective reasoning instructions. iCLP first distills explicit plans from existing step-by-step reasoning trajectories. It then learns discrete representations of these plans via a vector-quantized autoencoder coupled with a codebook. Finally, by fine-tuning LLMs on paired latent plans and corresponding reasoning steps, the models learn to perform implicit planning during reasoning. Experimental results on mathematical reasoning and code generation tasks demonstrate that, with iCLP, LLMs can plan in latent space while reasoning in language space. This approach yields significant improvements in both accuracy and efficiency and, crucially, demonstrates strong cross-domain generalization while preserving the interpretability of chain-of-thought reasoning.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24014.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24014",
      "published": "2025-12-30T06:19:04Z",
      "updated": "2025-12-30T06:19:04Z",
      "comment": "9 pages, 6 figures. The source code is publicly available at https://github.com/AgenticFinLab/latent-planning",
      "light_analysis": {
        "overview": "提出iCLP框架，使大语言模型能进行隐含认知潜在规划，提升推理准确性和效率。",
        "motivation": "解决大语言模型生成显式文本计划时的幻觉和任务多样性问题，受人类隐含认知启发。",
        "method": "iCLP从推理轨迹蒸馏显式计划，用向量量化的自编码器学习离散表示，并微调模型进行隐含规划。",
        "result": "在数学推理和代码生成任务中，模型在潜在空间规划、语言空间推理，提高了准确性和效率，并展示跨域泛化。",
        "conclusion": "iCLP实现了大语言模型的隐含规划，同时保持了链式思维推理的可解释性。",
        "tags": [
          "Large Language Model",
          "Implicit Cognition",
          "Latent Planning",
          "Vector-Quantized Autoencoder",
          "Chain-of-Thought Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:45.662946Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24000",
      "title": "WISE: Web Information Satire and Fakeness Evaluation",
      "authors": [
        "Gaurab Chhetri",
        "Subasish Das",
        "Tausif Islam Chowdhury"
      ],
      "abstract": "Distinguishing fake or untrue news from satire or humor poses a unique challenge due to their overlapping linguistic features and divergent intent. This study develops WISE (Web Information Satire and Fakeness Evaluation) framework which benchmarks eight lightweight transformer models alongside two baseline models on a balanced dataset of 20,000 samples from Fakeddit, annotated as either fake news or satire. Using stratified 5-fold cross-validation, we evaluate models across comprehensive metrics including accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, MCC, Brier score, and Expected Calibration Error. Our evaluation reveals that MiniLM, a lightweight model, achieves the highest accuracy (87.58%) among all models, while RoBERTa-base achieves the highest ROC-AUC (95.42%) and strong accuracy (87.36%). DistilBERT offers an excellent efficiency-accuracy trade-off with 86.28\\% accuracy and 93.90\\% ROC-AUC. Statistical tests confirm significant performance differences between models, with paired t-tests and McNemar tests providing rigorous comparisons. Our findings highlight that lightweight models can match or exceed baseline performance, offering actionable insights for deploying misinformation detection systems in real-world, resource-constrained settings.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24000.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24000",
      "published": "2025-12-30T05:44:32Z",
      "updated": "2025-12-30T05:44:32Z",
      "comment": "This is the author's preprint. Accepted to WEB&GRAPH 2026 (co-located with WSDM 2026), Boise, Idaho, USA, Feb 26, 2026. Final version will appear in WSDM 2026 Companion Proceedings. Conf: https://wsdm-conference.org/2026/ Workshop: https://aiimlab.org/events/WSDM_2026_WEB_and_GRAPH_2026_Workshop_on_Web_and_Graphs_Responsible_Intelligence_and_Social_Media.html",
      "light_analysis": {
        "overview": "提出WISE框架评估轻量级Transformer模型在区分假新闻与讽刺新闻任务上的表现。",
        "motivation": "区分假新闻与讽刺新闻具有挑战性，因其语言特征重叠但意图不同。研究旨在为资源受限场景提供有效的检测方案。",
        "method": "使用WISE框架，在平衡的Fakeddit数据集上，通过5折交叉验证，系统评估了八个轻量级Transformer模型和两个基线模型。",
        "result": "MiniLM准确率最高（87.58%），RoBERTa-base的ROC-AUC最佳（95.42%），DistilBERT在效率与准确率间取得良好平衡。轻量级模型可匹配或超越基线。",
        "conclusion": "研究表明轻量级模型在虚假信息检测任务上表现优异，为实际资源受限环境下的系统部署提供了可行的技术见解。",
        "tags": [
          "Transformer Models",
          "Fake News Detection",
          "Model Benchmarking",
          "Lightweight Models",
          "Text Classification"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:30.218300Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23988",
      "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process",
      "authors": [
        "Zhenyu Zhang",
        "Shujian Zhang",
        "John Lambert",
        "Wenxuan Zhou",
        "Zhangyang Wang",
        "Mingqing Chen",
        "Andrew Hard",
        "Rajiv Mathews",
        "Lun Wang"
      ],
      "abstract": "Despite the growing reasoning capabilities of recent large language models (LLMs), their internal mechanisms during the reasoning process remain underexplored. Prior approaches often rely on human-defined concepts (e.g., overthinking, reflection) at the word level to analyze reasoning in a supervised manner. However, such methods are limited, as it is infeasible to capture the full spectrum of potential reasoning behaviors, many of which are difficult to define in token space. In this work, we propose an unsupervised framework (namely, RISE: Reasoning behavior Interpretability via Sparse auto-Encoder) for discovering reasoning vectors, which we define as directions in the activation space that encode distinct reasoning behaviors. By segmenting chain-of-thought traces into sentence-level 'steps' and training sparse auto-encoders (SAEs) on step-level activations, we uncover disentangled features corresponding to interpretable behaviors such as reflection and backtracking. Visualization and clustering analyses show that these behaviors occupy separable regions in the decoder column space. Moreover, targeted interventions on SAE-derived vectors can controllably amplify or suppress specific reasoning behaviors, altering inference trajectories without retraining. Beyond behavior-specific disentanglement, SAEs capture structural properties such as response length, revealing clusters of long versus short reasoning traces. More interestingly, SAEs enable the discovery of novel behaviors beyond human supervision. We demonstrate the ability to control response confidence by identifying confidence-related vectors in the SAE decoder space. These findings underscore the potential of unsupervised latent discovery for both interpreting and controllably steering reasoning in LLMs.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23988.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23988",
      "published": "2025-12-30T05:09:11Z",
      "updated": "2025-12-30T05:09:11Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出无监督框架RISE，使用稀疏自编码器发现大语言模型的推理行为。",
        "motivation": "大语言模型推理机制未明，现有基于人工定义的方法难以捕捉全部推理行为。",
        "method": "提出RISE框架，使用稀疏自编码器在激活空间中发现推理向量，对应不同推理行为。",
        "result": "发现反射、回溯等可解释行为，可视化显示可分，干预可控制推理；发现置信度相关向量等新行为。",
        "conclusion": "无监督潜在发现为解释和可控引导大语言模型推理提供了潜力。",
        "tags": [
          "Large Language Model",
          "Sparse Auto-Encoder",
          "Chain-of-Thought",
          "Interpretability",
          "Unsupervised Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:51:00.253942Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23971",
      "title": "CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards",
      "authors": [
        "Zhiming Lin",
        "Kai Zhao",
        "Sophie Zhang",
        "Peilai Yu",
        "Canran Xiao"
      ],
      "abstract": "Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by enabling LLMs to correct their own mistakes. CEC-Zero synthesizes errorful inputs from clean text, computes cluster-consensus rewards via semantic similarity and candidate agreement, and optimizes the policy with PPO. It outperforms supervised baselines by 10--13 F$_1$ points and strong LLM fine-tunes by 5--8 points across 9 benchmarks, with theoretical guarantees of unbiased rewards and convergence. CEC-Zero establishes a label-free paradigm for robust, scalable CSC, unlocking LLM potential in noisy text pipelines.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23971.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23971",
      "published": "2025-12-30T03:58:38Z",
      "updated": "2025-12-30T03:58:38Z",
      "comment": "AAAI'26 poster",
      "light_analysis": {
        "overview": "提出CEC-Zero零监督强化学习框架，用于中文拼写纠正，无需人工标注。",
        "motivation": "解决现有方法对新错误缺乏鲁棒性且依赖昂贵标注的大规模中文拼写纠正问题。",
        "method": "采用强化学习，从干净文本合成错误输入，通过语义相似性和候选一致性计算奖励，并用PPO优化策略。",
        "result": "在9个基准测试中F1分数优于监督基线10-13点和强LLM微调5-8点，提供无偏奖励和收敛理论保证。",
        "conclusion": "建立了无标签的中文拼写纠正范式，释放了LLMs在噪声文本处理中的潜力，推动鲁棒可扩展应用。",
        "tags": [
          "Large Language Model",
          "Reinforcement Learning",
          "PPO",
          "Zero-Supervision",
          "Semantic Similarity"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:59.704341Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23966",
      "title": "Efficient Context Scaling with LongCat ZigZag Attention",
      "authors": [
        "Chen Zhang",
        "Yang Bai",
        "Jiahuan Li",
        "Anchun Gui",
        "Keheng Wang",
        "Feifan Liu",
        "Guanyu Wu",
        "Yuwei Jiang",
        "Defei Bu",
        "Li Wei",
        "Haihang Jing",
        "Hongyin Tang",
        "Xin Chen",
        "Xiangzhou Huang",
        "Fengcun Li",
        "Rongxiang Weng",
        "Yulei Qian",
        "Yifan Lu",
        "Yerui Sun",
        "Jingang Wang",
        "Yuchen Xie",
        "Xunliang Cai"
      ],
      "abstract": "We introduce LongCat ZigZag Attention (LoZA), which is a sparse attention scheme designed to transform any existing full-attention models into sparse versions with rather limited compute budget. In long-context scenarios, LoZA can achieve significant speed-ups both for prefill-intensive (e.g., retrieval-augmented generation) and decode-intensive (e.g., tool-integrated reasoning) cases. Specifically, by applying LoZA to LongCat-Flash during mid-training, we serve LongCat-Flash-Exp as a long-context foundation model that can swiftly process up to 1 million tokens, enabling efficient long-term reasoning and long-horizon agentic capabilities.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23966.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23966",
      "published": "2025-12-30T03:39:04Z",
      "updated": "2025-12-30T03:39:04Z",
      "comment": "10 pages, 3 figures, 3 tables",
      "light_analysis": {
        "overview": "提出了 LoZA 稀疏注意力方案，以有限计算预算高效扩展模型的长上下文处理能力。",
        "motivation": "解决在长上下文场景中，全注意力模型计算成本高的问题，以实现高效处理。",
        "method": "引入 LongCat ZigZag Attention (LoZA)，一种稀疏注意力方案，用于将全注意力模型转换为稀疏版本。",
        "result": "在长上下文任务中实现显著加速，并开发出能处理 100 万令牌的长上下文基础模型。",
        "conclusion": "LoZA 提供了一种高效扩展上下文的方法，支持长期推理和代理能力。",
        "tags": [
          "Sparse Attention",
          "Long-Context Modeling",
          "Retrieval-Augmented Generation",
          "Tool-Integrated Reasoning",
          "Foundation Model"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:49.993573Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23959",
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "authors": [
        "Chulun Zhou",
        "Chunkang Zhang",
        "Guoxin Yu",
        "Fandong Meng",
        "Jie Zhou",
        "Wai Lam",
        "Mo Yu"
      ],
      "abstract": "Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static nature overlooks the crucial high-order correlations among primitive facts, the compositions of which can often provide stronger guidance for subsequent steps. Therefore, their representational strength and impact on multi-step reasoning and knowledge evolution are limited, resulting in fragmented reasoning and weak global sense-making capacity in extended contexts. We introduce HGMem, a hypergraph-based memory mechanism that extends the concept of memory beyond simple storage into a dynamic, expressive structure for complex reasoning and global understanding. In our approach, memory is represented as a hypergraph whose hyperedges correspond to distinct memory units, enabling the progressive formation of higher-order interactions within memory. This mechanism connects facts and thoughts around the focal problem, evolving into an integrated and situated knowledge structure that provides strong propositions for deeper reasoning in subsequent steps. We evaluate HGMem on several challenging datasets designed for global sense-making. Extensive experiments and in-depth analyses show that our method consistently improves multi-step RAG and substantially outperforms strong baseline systems across diverse tasks.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23959.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23959",
      "published": "2025-12-30T03:13:10Z",
      "updated": "2025-12-30T03:13:10Z",
      "comment": "21 pages",
      "light_analysis": {
        "overview": "提出了基于超图的动态记忆机制HGMem，显著提升多步检索增强生成在长上下文复杂推理中的性能。",
        "motivation": "现有RAG系统的记忆模块多为静态存储，忽略了事实间的高阶关联，导致推理碎片化，全局理解能力弱。",
        "method": "引入HGMem机制，用超图表示记忆，超边对应记忆单元，支持渐进形成高阶交互以构建集成化的知识结构。",
        "result": "在多个为全局理解设计的挑战性数据集上，HGMem始终优于强基线系统，实验分析证实了其有效性。",
        "conclusion": "HGMem将记忆从简单存储扩展为动态表达结构，能有效建模复杂关系，为深度推理提供更强指导。",
        "tags": [
          "Retrieval-Augmented Generation",
          "Hypergraph",
          "Memory Mechanism",
          "Multi-step Reasoning",
          "Global Understanding"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:36:45.902755Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23862",
      "title": "Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining",
      "authors": [
        "Ruizhe Huang",
        "Kexuan Zhang",
        "Yihao Fang",
        "Baifeng Yu"
      ],
      "abstract": "This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM's limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.23862.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23862",
      "published": "2025-12-29T21:02:14Z",
      "updated": "2025-12-29T21:02:14Z",
      "comment": null,
      "light_analysis": {
        "overview": "本研究通过Infini-attention技术提升小型语言模型的长上下文能力，证明其在低资源预训练中的有效性。",
        "motivation": "解决小型语言模型在有限数据和计算下，长上下文外推能力的不足，以降低成本和提高可访问性。",
        "method": "采用Infini-attention构建压缩记忆并保留局部注意力，对300M参数LLaMA模型进行小规模预训练和实证研究。",
        "result": "模型训练稳定，长上下文检索优于基线，最高准确率提升31%，但平衡因子关键且压缩导致准确性下降。",
        "conclusion": "Infini-attention架构记忆有助于小型语言模型实现稳健的长上下文能力，补偿参数限制。",
        "tags": [
          "Infini-attention",
          "Small Language Model",
          "Pretraining",
          "Long-context Extrapolation",
          "LLaMA"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:47.974294Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23852",
      "title": "Trellis: Learning to Compress Key-Value Memory in Attention Models",
      "authors": [
        "Mahdi Karami",
        "Ali Behrouz",
        "Praneeth Kacham",
        "Vahab Mirrokni"
      ],
      "abstract": "Transformers, while powerful, suffer from quadratic computational complexity and the ever-growing Key-Value (KV) cache of the attention mechanism. This paper introduces Trellis, a novel Transformer architecture with bounded memory that learns how to compress its key-value memory dynamically at test time. Trellis replaces the standard KV cache with a fixed-size memory and train a two-pass recurrent compression mechanism to store new keys and values into memory. To achieve this, it leverages an online gradient descent procedure with a forget gate, enabling the compressed memory to be updated recursively while learning to retain important contextual information from incoming tokens at test time. Extensive experiments on language modeling, common-sense reasoning, recall-intensive tasks, and time series show that the proposed architecture outperforms strong baselines. Notably, its performance gains increase as the sequence length grows, highlighting its potential for long-context applications.",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.23852.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23852",
      "published": "2025-12-29T20:32:10Z",
      "updated": "2025-12-29T20:32:10Z",
      "comment": "In Second Conference on Language Modeling (COLM) (2025)",
      "light_analysis": {
        "overview": "提出Trellis Transformer架构，学习动态压缩键值内存，以解决长序列处理中的计算和内存瓶颈。",
        "motivation": "解决Transformer中二次计算复杂性和不断增长的键值缓存问题，特别是在长上下文应用中。",
        "method": "使用固定大小内存替换标准键值缓存，训练两遍循环压缩机制，结合在线梯度下降与遗忘门动态更新内存。",
        "result": "在语言建模、推理等任务上优于基线，性能增益随序列长度增加，适合长上下文应用。",
        "conclusion": "贡献了一种能动态压缩键值内存的Transformer变体，为长序列AI应用提供了高效解决方案。",
        "tags": [
          "Transformer",
          "Key-Value Memory Compression",
          "Recurrent Compression",
          "Online Gradient Descent",
          "Forget Gate"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:05.228788Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23850",
      "title": "The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models",
      "authors": [
        "Rahul Baxi"
      ],
      "abstract": "Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.23850.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23850",
      "published": "2025-12-29T20:29:09Z",
      "updated": "2025-12-29T20:29:09Z",
      "comment": "Currently under review at TMLR",
      "light_analysis": {
        "overview": "提出衡量语言模型知识稳健性的DDFT测试协议及理论框架，发现稳健性与规模无关。",
        "motivation": "现有基准测试无法衡量语言模型在信息质量下降或对抗性攻击下的知识保持（认知稳健性）能力。",
        "method": "提出DDFT协议，通过渐进式语义压缩和对抗性捏造来测试模型；并提出了包含语义系统和认知验证器的双系统模型。",
        "result": "评估9个模型发现，认知稳健性与参数量、架构类型无关，而与误差检测能力强相关，挑战了模型规模决定可靠性的假设。",
        "conclusion": "DDFT为关键应用部署前评估模型的认知稳健性提供了理论基础和实用工具。",
        "tags": [
          "Large Language Model Evaluation",
          "Epistemic Robustness",
          "Adversarial Testing",
          "Model Verification",
          "Semantic Compression"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:37:59.944050Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23848",
      "title": "Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs",
      "authors": [
        "Yukun Zhang",
        "Stefan Elbl Droguett",
        "Samyak Jain"
      ],
      "abstract": "This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper's top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (>7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.",
      "categories": [
        "cs.CL",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23848.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23848",
      "published": "2025-12-29T20:24:15Z",
      "updated": "2025-12-29T20:24:15Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出多检索器RAG方法，集成金融领域知识，提升大语言模型在金融数值推理问答任务上的性能。",
        "motivation": "解决大语言模型在金融数值推理问答任务中因缺乏领域知识而产生的错误和挑战。",
        "method": "实现多检索器检索增强生成系统，结合SecBERT编码器进行领域特定训练，并利用最新大语言模型处理任务。",
        "result": "最佳模型超越FinQA基线，基于提示的LLM生成器达到SOTA性能（改进>7%），但低于人类专家；揭示了幻觉与知识增益的权衡。",
        "conclusion": "证明了集成领域知识的多检索器RAG方法有效，领域特定训练提升性能，为大模型在金融QA中的应用提供见解。",
        "tags": [
          "Retrieval Augmented Generation",
          "Large Language Model",
          "SecBERT",
          "Few-Shot Learning",
          "Numerical Reasoning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:38:42.072362Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23837",
      "title": "Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation",
      "authors": [
        "Kaustubh Dhole"
      ],
      "abstract": "Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model's own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23837.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23837",
      "published": "2025-12-29T19:59:52Z",
      "updated": "2025-12-29T19:59:52Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种利用大语言模型中间注意力层的 token 分布生成对抗示例的方法，用于评估 LLM 评估管道的鲁棒性。",
        "motivation": "研究旨在利用注意力层的内部表示生成对抗示例，以评估下游任务的性能下降，从而测试基于 LLM 的评估系统的有效性。",
        "method": "从中间注意力层提取 token 预测，直接生成对抗示例，不同于传统的提示或梯度攻击，利用模型内部生成过程。",
        "result": "实验显示注意力层生成的对抗示例导致评估性能显著下降，同时保持语义相似，但某些层和位置会导致语法退化。",
        "conclusion": "展示了使用中间层表示作为对抗示例来源的潜力，但指出当前存在语法退化等限制，对于压力测试 LLM 评估管道有启示。",
        "tags": [
          "Attention Layers",
          "Adversarial Examples",
          "Mechanistic Interpretability",
          "Token Distributions",
          "LLM Evaluation"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:20.118818Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23836",
      "title": "Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?",
      "authors": [
        "Dingmin Wang",
        "Ji Ma",
        "Shankar Kumar"
      ],
      "abstract": "The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model's generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs' ability to effectively decline requests when faced with inadequate information.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23836.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23836",
      "published": "2025-12-29T19:59:10Z",
      "updated": "2025-12-29T19:59:10Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出自适应提示策略优化LLM在检索增强问答中的性能，并发现LLM在信息不足时易生成错误答案。",
        "motivation": "解决LLM在长上下文中因不相关信息导致性能下降，以及LLM在信息不足时错误回答而非拒绝的问题。",
        "method": "采用自适应提示策略，将检索信息分块并顺序提示LLM，通过调整块大小平衡相关与不相关信息。",
        "result": "在三个开放域问答数据集上，自适应策略使用更少令牌匹配标准提示性能，并发现LLM在信息不足时倾向于生成错误答案。",
        "conclusion": "贡献在于提出有效提示策略并指出需要增强LLM拒绝回答的能力，以降低错误。",
        "tags": [
          "Large Language Model",
          "Retrieval-Augmented Generation",
          "Adaptive Prompting",
          "Open-Domain Question Answering"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:39:28.442949Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23835",
      "title": "Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms",
      "authors": [
        "Himel Ghosh"
      ],
      "abstract": "Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23835.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23835",
      "published": "2025-12-29T19:58:11Z",
      "updated": "2025-12-29T19:58:11Z",
      "comment": "10 pages, 8 figures",
      "light_analysis": {
        "overview": "通过SHAP分析比较transformer偏见检测模型的决策机制，揭示架构对模型可靠性的关键影响。",
        "motivation": "研究动机是缺乏对新闻偏见检测模型决策机制的理解，旨在解释模型预测依据和失败原因。",
        "method": "采用SHAP可解释性方法，比较两个在BABE数据集上微调的transformer模型（偏见检测器和领域自适应RoBERTa）的词级归因。",
        "result": "发现两个模型关注相似语言类别但整合方式不同；域自适应模型误报减少63%，且归因模式更一致，错误源于语篇模糊。",
        "conclusion": "强调解释性评估对偏见检测系统的重要性，指出架构和训练选择关键影响模型可靠性和部署适用性。",
        "tags": [
          "Transformer Models",
          "SHAP",
          "RoBERTa",
          "Domain Adaptation",
          "Fine-tuning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:04.896277Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23808",
      "title": "MiMo-Audio: Audio Language Models are Few-Shot Learners",
      "authors": [
        "Xiaomi LLM-Core Team",
        ":",
        "Dong Zhang",
        "Gang Wang",
        "Jinlong Xue",
        "Kai Fang",
        "Liang Zhao",
        "Rui Ma",
        "Shuhuai Ren",
        "Shuo Liu",
        "Tao Guo",
        "Weiji Zhuang",
        "Xin Zhang",
        "Xingchen Song",
        "Yihan Yan",
        "Yongzhe He",
        "Cici",
        "Bowen Shen",
        "Chengxuan Zhu",
        "Chong Ma",
        "Chun Chen",
        "Heyu Chen",
        "Jiawei Li",
        "Lei Li",
        "Menghang Zhu",
        "Peidian Li",
        "Qiying Wang",
        "Sirui Deng",
        "Weimin Xiong",
        "Wenshan Huang",
        "Wenyu Yang",
        "Yilin Jiang",
        "Yixin Yang",
        "Yuanyuan Tian",
        "Yue Ma",
        "Yue Yu",
        "Zihan Zhang",
        "Zihao Yue",
        "Bangjun Xiao",
        "Bingquan Xia",
        "Bofei Gao",
        "Bowen Ye",
        "Can Cai",
        "Chang Liu",
        "Chenhong He",
        "Chunan Li",
        "Dawei Zhu",
        "Duo Zhang",
        "Fengyuan Shi",
        "Guoan Wang",
        "Hailin Zhang",
        "Hanglong Lv",
        "Hanyu Li",
        "Hao Tian",
        "Heng Qu",
        "Hongshen Xu",
        "Houbin Zhang",
        "Huaqiu Liu",
        "Jiangshan Duo",
        "Jianguang Zuo",
        "Jianyu Wei",
        "Jiebao Xiao",
        "Jinhao Dong",
        "Jun Shi",
        "Junhao Hu",
        "Kainan Bao",
        "Kang Zhou",
        "Linghao Zhang",
        "Meng Chen",
        "Nuo Chen",
        "Peng Zhang",
        "Qianli Chen",
        "Qiantong Wang",
        "Rang Li",
        "Shaohui Liu",
        "Shengfan Wang",
        "Shicheng Li",
        "Shihua Yu",
        "Shijie Cao",
        "Shimao Chen",
        "Shuhao Gu",
        "Weikun Wang",
        "Wenhan Ma",
        "Xiangwei Deng",
        "Xing Yong",
        "Xing Zhang",
        "Xu Wang",
        "Yifan Song",
        "Yihao Zhao",
        "Yingbo Zhao",
        "Yizhao Gao",
        "Yu Cheng",
        "Yu Tu",
        "Yudong Wang",
        "Zhaojun Huang",
        "Zhengju Tang",
        "Zhenru Lin",
        "Zhichao Song",
        "Zhipeng Xu",
        "Zhixian Zheng",
        "Zihan Jiang"
      ],
      "abstract": "Existing audio language models typically rely on task-specific fine-tuning to accomplish particular audio tasks. In contrast, humans are able to generalize to new audio tasks with only a few examples or simple instructions. GPT-3 has shown that scaling next-token prediction pretraining enables strong generalization capabilities in text, and we believe this paradigm is equally applicable to the audio domain. By scaling MiMo-Audio's pretraining data to over one hundred million of hours, we observe the emergence of few-shot learning capabilities across a diverse set of audio tasks. We develop a systematic evaluation of these capabilities and find that MiMo-Audio-7B-Base achieves SOTA performance on both speech intelligence and audio understanding benchmarks among open-source models. Beyond standard metrics, MiMo-Audio-7B-Base generalizes to tasks absent from its training data, such as voice conversion, style transfer, and speech editing. MiMo-Audio-7B-Base also demonstrates powerful speech continuation capabilities, capable of generating highly realistic talk shows, recitations, livestreaming and debates. At the post-training stage, we curate a diverse instruction-tuning corpus and introduce thinking mechanisms into both audio understanding and generation. MiMo-Audio-7B-Instruct achieves open-source SOTA on audio understanding benchmarks (MMSU, MMAU, MMAR, MMAU-Pro), spoken dialogue benchmarks (Big Bench Audio, MultiChallenge Audio) and instruct-TTS evaluations, approaching or surpassing closed-source models. Model checkpoints and full evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-Audio.",
      "categories": [
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23808.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23808",
      "published": "2025-12-29T19:06:05Z",
      "updated": "2025-12-29T19:06:05Z",
      "comment": null,
      "light_analysis": {
        "overview": "MiMo-Audio通过超大规模预训练实现音频语言模型的少样本学习，在多项音频任务中达到开源SOTA。",
        "motivation": "解决现有音频语言模型依赖任务特定微调、无法泛化的问题，旨在实现像人类一样的少样本学习能力于音频领域。",
        "method": "扩展预训练数据至超一亿小时，采用下一令牌预测预训练范式，后阶段引入指令调优和思维机制。",
        "result": "在语音智能和音频理解基准上达到开源SOTA，泛化到语音转换等未见任务，并能生成高度真实的语音内容。",
        "conclusion": "贡献是实现了音频语言模型的少样本学习，接近或超越闭源模型，为音频AI提供新泛化范式。",
        "tags": [
          "Audio Language Model",
          "Few-Shot Learning",
          "Pre-training",
          "Instruction Tuning",
          "Thinking Mechanisms"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:38.692960Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23707",
      "title": "Training AI Co-Scientists Using Rubric Rewards",
      "authors": [
        "Shashwat Goel",
        "Rishi Hazra",
        "Dulhan Jayalath",
        "Timon Willi",
        "Parag Jain",
        "William F. Shen",
        "Ilias Leontiadis",
        "Francesco Barbieri",
        "Yoram Bachrach",
        "Jonas Geiping",
        "Chenxi Whitehouse"
      ],
      "abstract": "AI co-scientists are emerging as a tool to assist human researchers in achieving their research goals. A crucial feature of these AI co-scientists is the ability to generate a research plan given a set of aims and constraints. The plan may be used by researchers for brainstorming, or may even be implemented after further refinement. However, language models currently struggle to generate research plans that follow all constraints and implicit requirements. In this work, we study how to leverage the vast corpus of existing research papers to train language models that generate better research plans. We build a scalable, diverse training corpus by automatically extracting research goals and goal-specific grading rubrics from papers across several domains. We then train models for research plan generation via reinforcement learning with self-grading. A frozen copy of the initial policy acts as the grader during training, with the rubrics creating a generator-verifier gap that enables improvements without external human supervision. To validate this approach, we conduct a study with human experts for machine learning research goals, spanning 225 hours. The experts prefer plans generated by our finetuned Qwen3-30B-A3B model over the initial model for 70% of research goals, and approve 84% of the automatically extracted goal-specific grading rubrics. To assess generality, we also extend our approach to research goals from medical papers, and new arXiv preprints, evaluating with a jury of frontier models. Our finetuning yields 12-22% relative improvements and significant cross-domain generalization, proving effective even in problem settings like medical research where execution feedback is infeasible. Together, these findings demonstrate the potential of a scalable, automated training recipe as a step towards improving general AI co-scientists.",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.23707.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23707",
      "published": "2025-12-29T18:59:33Z",
      "updated": "2025-12-29T18:59:33Z",
      "comment": "11 pages in the main paper, total 119 including sample outputs in the Appendix",
      "light_analysis": {
        "overview": "提出基于规则奖励的自动化训练方法，通过强化学习和自我评分提升语言模型生成研究计划的能力。",
        "motivation": "现有语言模型难以生成符合所有约束与隐含要求的研究计划，需要利用海量论文数据来训练更好的AI科研助手。",
        "method": "从多领域论文自动提取研究目标及评分规则，通过强化学习结合自我评分（冻结初始策略作为评分者）训练模型。",
        "result": "微调模型在70%研究目标上优于基线，84%的评分规则获专家认可，并在医学等领域实现12-22%的相对提升。",
        "conclusion": "该自动化、可扩展的训练方案能有效提升AI科研助手能力，且具备跨领域泛化性。",
        "tags": [
          "Large Language Model",
          "Reinforcement Learning",
          "Self-Grading",
          "Rubric-based Training",
          "Cross-domain Generalization"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:40:27.870449Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23701",
      "title": "Eliciting Behaviors in Multi-Turn Conversations",
      "authors": [
        "Jing Huang",
        "Shujian Zhang",
        "Lun Wang",
        "Andrew Hard",
        "Rajiv Mathews",
        "John Lambert"
      ],
      "abstract": "Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23701.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23701",
      "published": "2025-12-29T18:57:10Z",
      "updated": "2025-12-29T18:57:10Z",
      "comment": null,
      "light_analysis": {
        "overview": "本文研究多轮对话中大型语言模型的行为引出，提出广义在线方法并评估其效率。",
        "motivation": "解决现有行为引出方法主要在单轮设置中，而多轮对话中识别复杂行为评估不足的问题。",
        "method": "提出分析框架将方法分类为三类，并引入广义多轮在线行为引出方法，统一单轮和多轮设置。",
        "result": "在线方法在少量查询下于三个任务中达到平均45/19/77%的成功率，优于静态方法。",
        "conclusion": "贡献是将行为引出方法应用于多轮对话评估，并强调需要转向动态基准。",
        "tags": [
          "Large Language Model",
          "Behavior Elicitation",
          "Multi-Turn Conversations",
          "Online Interaction",
          "Dynamic Benchmarking"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:11.982688Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23693",
      "title": "Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans",
      "authors": [
        "Sky CH-Wang",
        "Justin Svegliato",
        "Helen Appel",
        "Jason Eisner"
      ],
      "abstract": "We present a method and dataset for fine-tuning language models with preference supervision using feedback-driven improvement chains. Given a model response, an annotator provides fine-grained feedback by marking ``liked'' and ``disliked'' spans and specifying what they liked or disliked about them. The base model then rewrites the disliked spans accordingly, proceeding from left to right, forming a sequence of incremental improvements. We construct preference pairs for direct alignment from each adjacent step in the chain, enabling the model to learn from localized, targeted edits. We find that our approach outperforms direct alignment methods based on standard A/B preference ranking or full contrastive rewrites, demonstrating that structured, revision-based supervision leads to more efficient and effective preference tuning.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23693.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23693",
      "published": "2025-12-29T18:51:56Z",
      "updated": "2025-12-29T18:51:56Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了基于细粒度人工反馈和修订链来微调语言模型的方法与数据集。",
        "motivation": "为了解决现有基于标准偏好排序的直接对齐方法可能不够高效或有效的问题。",
        "method": "使用反馈驱动的改进链：标注者标记喜欢/不喜欢的文本片段并提供原因，基础模型据此逐步重写，形成偏好对用于对齐。",
        "result": "该方法在偏好微调上优于基于标准A/B偏好排序或完整对比重写的直接对齐方法。",
        "conclusion": "结构化、基于修订的细粒度监督能实现更高效和有效的语言模型偏好对齐。",
        "tags": [
          "Fine-Tuning",
          "Preference Learning",
          "Alignment from Human Feedback",
          "Revision Chain",
          "Feedback-Driven Improvement Chain"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:18.532707Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23684",
      "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
      "authors": [
        "Panagiotis Theocharopoulos",
        "Ajinkya Kulkarni",
        "Mathew Magimai. -Doss"
      ],
      "abstract": "Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23684.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23684",
      "published": "2025-12-29T18:43:05Z",
      "updated": "2025-12-29T18:43:05Z",
      "comment": null,
      "light_analysis": {
        "overview": "评估了多语言隐藏提示注入攻击对基于LLM的学术评审系统的影响，发现不同语言攻击效果存在显著差异。",
        "motivation": "随着LLM被应用于学术评审等高影响力工作流，其面对文档级隐藏提示注入攻击的脆弱性亟待评估。",
        "method": "构建了约500篇真实ICLR论文的数据集，在文档中嵌入四种语言（英、日、中、阿）的语义相同对抗指令，并利用LLM进行评审。",
        "result": "英语、日语和中文的提示注入会显著改变评审分数和录取决定，而阿拉伯语注入几乎无效。",
        "conclusion": "揭示了基于LLM的评审系统普遍易受文档级提示注入攻击，且不同语言的攻击效力存在明显差异。",
        "tags": [
          "Prompt Injection Attack",
          "Large Language Model",
          "Academic Peer Review",
          "Multilingual Evaluation",
          "Adversarial Attack"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:41:56.782142Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23676",
      "title": "Web World Models",
      "authors": [
        "Jichen Feng",
        "Yifan Zhang",
        "Chenggong Zhang",
        "Yifu Lu",
        "Shilong Liu",
        "Mengdi Wang"
      ],
      "abstract": "Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.23676.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23676",
      "published": "2025-12-29T18:31:45Z",
      "updated": "2025-12-29T18:31:45Z",
      "comment": "Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models",
      "light_analysis": {
        "overview": "提出了Web World Model (WWM)，结合web代码和大语言模型，实现可控且开放的世界模型。",
        "motivation": "解决现有世界模型方法在可靠性和可控性之间的极端问题，为语言代理提供折中的持久世界环境。",
        "method": "使用web代码定义世界状态和物理以确保逻辑一致性，大语言模型生成上下文和决策，构建多种WWM实例。",
        "result": "提出了WWM的设计原则，并展示web栈可作为可控且开放环境的可扩展基底。",
        "conclusion": "WWM框架平衡了可控性和开放性，推动了语言代理在复杂世界中的发展，具有实用工程意义。",
        "tags": [
          "Large Language Models",
          "Web Stack",
          "World Models",
          "Deterministic Generation",
          "Typed Interfaces"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:42:46.923642Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23611",
      "title": "Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing",
      "authors": [
        "Yuwen Li",
        "Wei Zhang",
        "Zelong Huang",
        "Mason Yang",
        "Jiajun Wu",
        "Shawn Guo",
        "Huahao Hu",
        "Lingyi Sun",
        "Jian Yang",
        "Mingjie Tang",
        "Byran Dai"
      ],
      "abstract": "Enabling Large Language Models (LLMs) to reliably invoke external tools remains a critical bottleneck for autonomous agents. Existing approaches suffer from three fundamental challenges: expensive human annotation for high-quality trajectories, poor generalization to unseen tools, and quality ceilings inherent in single-model synthesis that perpetuate biases and coverage gaps. We introduce InfTool, a fully autonomous framework that breaks these barriers through self-evolving multi-agent synthesis. Given only raw API specifications, InfTool orchestrates three collaborative agents (User Simulator, Tool-Calling Assistant, and MCP Server) to generate diverse, verified trajectories spanning single-turn calls to complex multi-step workflows. The framework establishes a closed loop: synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, the improved model generates higher-quality data targeting capability gaps, and this cycle iterates without human intervention. Experiments on the Berkeley Function-Calling Leaderboard (BFCL) demonstrate that InfTool transforms a base 32B model from 19.8% to 70.9% accuracy (+258%), surpassing models 10x larger and rivaling Claude-Opus, and entirely from synthetic data without human annotation.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23611.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23611",
      "published": "2025-12-29T17:12:39Z",
      "updated": "2025-12-29T17:12:39Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出InfTool框架，通过多智能体自演进来合成高质量工具使用数据，大幅提升LLM工具调用能力。",
        "motivation": "解决LLM可靠调用外部工具的三个瓶颈：人工标注成本高、对未见工具泛化差、单模型合成数据存在偏差和质量天花板。",
        "method": "使用三个协作智能体（用户模拟器、工具调用助手、MCP服务器）和闭环训练机制（Group Relative Policy Optimization + 门控奖励），仅从API规范生成多样化、已验证的数据。",
        "result": "在伯克利函数调用排行榜上，将基础32B模型的准确率从19.8%提升至70.9%（+258%），超越大10倍的模型，媲美Claude-Opus，且完全无需人工标注。",
        "conclusion": "实现了完全自主、自我演进的高质量工具使用数据合成与模型训练闭环，突破了传统方法的限制。",
        "tags": [
          "Multi-Agent System",
          "Tool-Calling",
          "Synthetic Data Generation",
          "Group Relative Policy Optimization",
          "Self-Improving Loop"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:44:10.815167Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23578",
      "title": "Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models",
      "authors": [
        "Yu-Xiang Lin",
        "Cheng-Han Chiang",
        "Hung-yi Lee"
      ],
      "abstract": "In this paper, we show that when spoken language models (SLMs) are instructed to speak in a specific speaking style at the beginning of a multi-turn conversation, they cannot maintain the required speaking styles after several turns of interaction; we refer to this as the style amnesia of SLMs. We focus on paralinguistic speaking styles, including emotion, accent, volume, and speaking speed. We evaluate three proprietary and two open-source SLMs, demonstrating that none of these models can maintain a consistent speaking style when instructed to do so. We further show that when SLMs are asked to recall the style instruction in later turns, they can recall the style instruction, but they fail to express it throughout the conversation. We also show that explicitly asking the model to recall the style instruction can partially mitigate style amnesia. In addition, we examine various prompting strategies and find that SLMs struggle to follow the required style when the instruction is placed in system messages rather than user messages, which contradicts the intended function of system prompts.",
      "categories": [
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23578.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23578",
      "published": "2025-12-29T16:23:54Z",
      "updated": "2025-12-29T16:23:54Z",
      "comment": "Work in progress",
      "light_analysis": {
        "overview": "论文发现spoken language models在多轮对话中存在说话风格遗忘问题，并探索了缓解策略。",
        "motivation": "解决SLMs在多轮对话中无法维持指定副语言说话风格的问题，以提升对话连贯性和模型性能。",
        "method": "评估多个专有和开源SLMs，测试不同提示策略，包括明确要求模型回忆风格指令。",
        "result": "所有模型都无法维持风格一致性；明确回忆指令可部分缓解；系统消息中指令效果更差。",
        "conclusion": "识别了style amnesia现象，为SLMs设计提供了改进方向，并揭示了提示策略的影响。",
        "tags": [
          "Spoken Language Model",
          "Multi-turn Conversation",
          "Paralinguistic Style",
          "Prompt Engineering",
          "Style Amnesia"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:02.305032Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23572",
      "title": "Instruction-Following Evaluation of Large Vision-Language Models",
      "authors": [
        "Daiki Shiono",
        "Shumpei Miyawaki",
        "Ryota Tanaka",
        "Jun Suzuki"
      ],
      "abstract": "Following the initial flourishing of large language models (LLMs), there has been a surge in proposed large vision-language models (LVLMs) that integrate LLMs with vision capabilities. However, it has been observed that LVLMs, after tuning to visual instruction using commonly used training datasets, often fail to exhibit the instruction-following ability that was present in the LLM before integration, leading to results in which they do not follow task instructions as expected. This study quantitatively demonstrates that LVLMs' instruction-following ability declines after fine-tuning and analyzes its underlying causes. In particular, we constructed new training datasets highlighting whether the output format is specified. Then, we investigated how explicitly indicating the output format during fine-tuning affects LVLMs' instruction-following ability. Our quantitative evaluation confirmed that LVLMs' instruction-following ability declines after fine-tuning with commonly used datasets. Furthermore, we found that LVLMs trained with datasets, including instructions on output format, tend to follow instructions more accurately than models that do not. These findings suggest that including samples with instructions on output format during (visual) instruction tuning may help mitigate the decline in instruction-following abilities.",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23572.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23572",
      "published": "2025-12-29T16:12:33Z",
      "updated": "2025-12-29T16:12:33Z",
      "comment": "21 pages, 7 figures",
      "light_analysis": {
        "overview": "量化分析大型视觉语言模型微调后指令跟随能力下降，并提出输出格式指令可缓解此问题。",
        "motivation": "解决大型视觉语言模型在视觉指令调优后指令跟随能力下降，导致模型不按预期执行任务的问题。",
        "method": "构建强调输出格式是否指定的新训练数据集，定量评估微调对指令跟随能力的影响。",
        "result": "定量确认指令跟随能力下降，且包含输出格式指令的训练能提高模型对指令的遵循准确性。",
        "conclusion": "在视觉指令调优中加入输出格式指令样本可帮助缓解大型视觉语言模型的指令跟随能力下降。",
        "tags": [
          "Large Vision-Language Models",
          "Instruction Following",
          "Fine-tuning",
          "Output Format",
          "Visual Instruction Tuning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:15.985646Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23562",
      "title": "VL-RouterBench: A Benchmark for Vision-Language Model Routing",
      "authors": [
        "Zhehao Huang",
        "Baijiong Lin",
        "Jingyuan Zhang",
        "Jingying Wang",
        "Yuhang Liu",
        "Ning Lu",
        "Tao Li",
        "Xiaolin Huang"
      ],
      "abstract": "Multi-model routing has evolved from an engineering technique into essential infrastructure, yet existing work lacks a systematic, reproducible benchmark for evaluating vision-language models (VLMs). We present VL-RouterBench to assess the overall capability of VLM routing systems systematically. The benchmark is grounded in raw inference and scoring logs from VLMs and constructs quality and cost matrices over sample-model pairs. In scale, VL-RouterBench covers 14 datasets across 3 task groups, totaling 30,540 samples, and includes 15 open-source models and 2 API models, yielding 519,180 sample-model pairs and a total input-output token volume of 34,494,977. The evaluation protocol jointly measures average accuracy, average cost, and throughput, and builds a ranking score from the harmonic mean of normalized cost and accuracy to enable comparison across router configurations and cost budgets. On this benchmark, we evaluate 10 routing methods and baselines and observe a significant routability gain, while the best current routers still show a clear gap to the ideal Oracle, indicating considerable room for improvement in router architecture through finer visual cues and modeling of textual structure. We will open-source the complete data construction and evaluation toolchain to promote comparability, reproducibility, and practical deployment in multimodal routing research.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.23562.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23562",
      "published": "2025-12-29T16:01:19Z",
      "updated": "2025-12-29T16:01:19Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了VL-RouterBench，一个系统评估视觉-语言模型路由能力的基准。",
        "motivation": "现有工作缺乏系统化、可复现的基准来评估视觉-语言模型路由系统，阻碍了多模态路由研究的发展。",
        "method": "基于VLMs的原始推理日志构建样本-模型对的质量和成本矩阵，覆盖14个数据集和17个模型，使用调和平均数联合评估准确率、成本和吞吐量。",
        "result": "评估10个路由方法显示显著路由能力增益，但最佳路由器与理想Oracle仍有差距，表明改进空间。",
        "conclusion": "VL-RouterBench促进了多模态路由研究的可比性、可复现性和实际部署，并指出通过精细视觉线索和文本结构建模可改进路由器架构。",
        "tags": [
          "Vision-Language Model",
          "Multi-model Routing",
          "Benchmarking",
          "Cost-Accuracy Trade-off",
          "Throughput Measurement"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:45:55.369353Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23547",
      "title": "Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs",
      "authors": [
        "Sahil Kale",
        "Antonio Luca Alfeo"
      ],
      "abstract": "Hallucinations, the generation of apparently convincing yet false statements, remain a major barrier to the safe deployment of LLMs. Building on the strong performance of self-detection methods, we examine the use of structured knowledge representations, namely knowledge graphs, to improve hallucination self-detection. Specifically, we propose a simple yet powerful approach that enriches hallucination self-detection by (i) converting LLM responses into knowledge graphs of entities and relations, and (ii) using these graphs to estimate the likelihood that a response contains hallucinations. We evaluate the proposed approach using two widely used LLMs, GPT-4o and Gemini-2.5-Flash, across two hallucination detection datasets. To support more reliable future benchmarking, one of these datasets has been manually curated and enhanced and is released as a secondary outcome of this work. Compared to standard self-detection methods and SelfCheckGPT, a state-of-the-art approach, our method achieves up to 16% relative improvement in accuracy and 20% in F1-score. Our results show that LLMs can better analyse atomic facts when they are structured as knowledge graphs, even when initial outputs contain inaccuracies. This low-cost, model-agnostic approach paves the way toward safer and more trustworthy language models.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23547.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23547",
      "published": "2025-12-29T15:41:13Z",
      "updated": "2025-12-29T15:41:13Z",
      "comment": "Accepted to ICPRAM 2026 in Marbella, Spain",
      "light_analysis": {
        "overview": "提出基于知识图谱的LLM幻觉自我检测方法，显著提升检测性能。",
        "motivation": "幻觉是LLM安全部署的主要障碍，需改进自我检测方法的鲁棒性。",
        "method": "将LLM响应转换为实体和关系的知识图谱，利用图谱估计响应包含幻觉的可能性。",
        "result": "在GPT-4o和Gemini-2.5-Flash上评估，相比标准方法，准确率和F1分数相对提升16%和20%。",
        "conclusion": "该方法低成本、模型无关，能提升LLM对原子事实的分析能力，促进更安全可信的语言模型发展。",
        "tags": [
          "Large Language Model",
          "Knowledge Graph",
          "Hallucination Detection",
          "Self-Detection",
          "Benchmarking"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:13.740367Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23518",
      "title": "Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias",
      "authors": [
        "Hazel Kim",
        "Philip Torr"
      ],
      "abstract": "Large language models (LLMs) are highly vulnerable to input confirmation bias. When a prompt implies a preferred answer, models often reinforce that bias rather than explore alternatives. This phenomenon remains underexplored, yet it is already harmful in base models and poses an even greater risk in multi-agent debate, where echo chambers reinforce bias instead of correction. We introduce Mixture of Latent Concept Experts (MoLaCE), a lightweight inference-time framework that addresses confirmation bias by mixing experts instantiated as different activation strengths over latent concepts that shape model responses. Our key insight is that, due to the compositional nature of language, differently phrased prompts reweight latent concepts in prompt-specific ways that affect factual correctness, so no single fixed intervention can be applied universally across inputs. This design enables a single LLM to emulate the benefits of debate internally while remaining computationally efficient and scalable. It can also be integrated into multi-agent debate frameworks to diversify perspectives and reduce correlated errors. We empirically show that it consistently reduces confirmation bias, improves robustness, and matches or surpasses multi-agent debate while requiring only a fraction of the computation.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23518.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23518",
      "published": "2025-12-29T14:52:34Z",
      "updated": "2025-12-29T14:52:34Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出MoLaCE框架，通过混合潜在概念专家减少大语言模型的确认偏见，提升鲁棒性和计算效率。",
        "motivation": "大语言模型易受输入确认偏见影响，尤其在提示隐含偏好答案时强化偏见，对基础模型和多智能体辩论构成风险。",
        "method": "引入MoLaCE，一个轻量级推理时框架，通过调整潜在概念的激活强度来适应不同提示，解决确认偏见。",
        "result": "MoLaCE持续减少确认偏见，提高鲁棒性，匹配或超越多智能体辩论，同时计算量大幅减少。",
        "conclusion": "MoLaCE使单个LLM能内部模拟辩论，计算高效且可扩展，可集成到多智能体框架中多样化视角。",
        "tags": [
          "Large Language Model",
          "Confirmation Bias",
          "Mixture of Experts",
          "Latent Concepts",
          "Inference-time Framework"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:33.406143Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23512",
      "title": "UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?",
      "authors": [
        "Fengjiao Chen",
        "Minhao Jing",
        "Weitao Lu",
        "Yan Feng",
        "Xiaoyu Li",
        "Xuezhi Cao"
      ],
      "abstract": "Vision-language large models are moving toward the unification of visual understanding and visual generation tasks. However, whether generation can enhance understanding is still under-explored on large data scale. In this work, we analysis the unified structure with a concise model, UniHetero, under large-scale pretraining (>200M samples). Our key observations are: (1) Generation can improve understanding, but Only if you generate Semantics, Not Pixels. A common assumption in unified vision-language models is that adding generation will naturally strengthen understanding. However, this is not always true at scale. At 200M+ pretraining samples, generation helps understanding only when it operates at the semantic level, i.e. when the model learns to autoregress high-level visual representations inside the LLM. Once pixel-level objectives (e.g., diffusion losses) directly interfere with the LLM, understanding performance often degrades. (2) Generation reveals a superior Data Scaling trend and higher Data Utilization. Unified generation-understanding demonstrates a superior scaling trend compared to understanding alone, revealing a more effective way to learn vision-only knowledge directive from vision modality rather than captioning to text. (3) Autoregression on Input Embedding is effective to capture visual details. Compared to the commonly-used vision encoder, make visual autoregression on input embedding shows less cumulative error and is modality independent, which can be extend to all modalities. The learned semantic representations capture visual information such as objects, locations, shapes, and colors; further enable pixel-level image generation.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23512.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23512",
      "published": "2025-12-29T14:49:50Z",
      "updated": "2025-12-30T13:23:48Z",
      "comment": null,
      "light_analysis": {
        "overview": "研究发现语义级的视觉生成能有效增强视觉语言模型的理解能力，并提升数据缩放效率。",
        "motivation": "探究在大规模数据下，视觉生成任务是否能统一并增强视觉理解任务的性能，以优化视觉语言模型的设计。",
        "method": "提出了简洁的统一模型 UniHetero，在大规模预训练数据下，分析对高层语义视觉表示进行自回归生成的方法。",
        "result": "1. 仅语义级生成能提升理解性能；2. 统一模型展现更优数据缩放趋势；3. 输入嵌入自回归能有效捕捉视觉细节并支持像素生成。",
        "conclusion": "为视觉语言模型的统一架构提供了实证指导，验证了语义生成对理解的关键促进作用及统一模型的数据效率优势。",
        "tags": [
          "Vision-Language Model",
          "Large-scale Pretraining",
          "Autoregressive Generation",
          "Semantic Representation Learning",
          "Unified Model Architecture"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:46:48.561609Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23471",
      "title": "Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings",
      "authors": [
        "Thomas Haschka",
        "Joseph Bakarji"
      ],
      "abstract": "Semantic text classification has undergone significant advances in recent years due to the rise of large language models (LLMs) and their high dimensional embeddings. While LLM-embeddings are frequently used to store and retrieve text by semantic similarity in vector databases, the global structure semantic relationships in text corpora often remains opaque. Herein we propose a nested density clustering approach, to infer hierarchical trees of semantically related texts. The method starts by identifying texts of strong semantic similarity as it searches for dense clusters in LLM embedding space. As the density criterion is gradually relaxed, these dense clusters merge into more diffuse clusters, until the whole dataset is represented by a single cluster -- the root of the tree. By embedding dense clusters into increasingly diffuse ones, we construct a tree structure that captures hierarchical semantic relationships among texts. We outline how this approach can be used to classify textual data for abstracts of scientific abstracts as a case study. This enables the data-driven discovery research areas and their subfields without predefined categories. To evaluate the general applicability of the method, we further apply it to established benchmark datasets such as the 20 Newsgroups and IMDB 50k Movie Reviews, demonstrating its robustness across domains. Finally we discuss possible applications on scientometrics, topic evolution, highlighting how nested density trees can reveal semantic structure and evolution in textual datasets.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23471.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23471",
      "published": "2025-12-29T13:55:23Z",
      "updated": "2025-12-29T13:55:23Z",
      "comment": "20 pages, 9 figures",
      "light_analysis": {
        "overview": "提出一种结合大语言模型嵌入的嵌套密度聚类方法，用于推断文本的层次语义树结构。",
        "motivation": "解决文本语料库中全局语义关系不透明的问题，实现无需预定义类别的数据驱动语义发现。",
        "method": "采用嵌套密度聚类，在LLM嵌入空间中搜索密集簇，通过逐渐放松密度标准构建层次树。",
        "result": "方法应用于科学摘要分类和基准数据集（如20 Newsgroups和IMDB），展示了跨领域的鲁棒性。",
        "conclusion": "嵌套密度树能揭示文本数据的语义结构和演化，在科学计量学和主题演化等领域有应用潜力。",
        "tags": [
          "Large Language Model Embeddings",
          "Nested Density Clustering",
          "Hierarchical Tree Inference",
          "Semantic Text Classification"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:47:51.703253Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23457",
      "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following",
      "authors": [
        "Kongcheng Zhang",
        "Qi Yao",
        "Shunyu Liu",
        "Wenjian Zhang",
        "Min Cen",
        "Yang Zhou",
        "Wenkai Fang",
        "Yiru Zhao",
        "Baisheng Lai",
        "Mingli Song"
      ],
      "abstract": "Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.23457.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23457",
      "published": "2025-12-29T13:31:08Z",
      "updated": "2025-12-29T13:31:08Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出Hindsight instruction Replay (HiR)框架，通过重放失败尝试为成功，实现样本高效的强化学习以优化大型语言模型指令遵循。",
        "motivation": "强化学习对齐大型语言模型以遵循指令时，初始模型因能力有限难以生成满足约束的响应，导致奖励稀疏，阻碍学习效率。",
        "method": "采用HiR框架，使用select-then-rewrite策略将失败尝试基于已满足约束重放为成功，进行强化学习，理论框架为指令和响应级别的双偏好学习。",
        "result": "实验显示HiR在不同指令遵循任务上表现良好，取得改进结果，同时所需计算预算更少。",
        "conclusion": "贡献是提出了一个样本高效的强化学习框架，能有效优化大型语言模型在复杂指令遵循任务中的性能。",
        "tags": [
          "Reinforcement Learning",
          "Large Language Model",
          "Instruction Following",
          "Hindsight Replay",
          "Preference Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:18.484797Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23447",
      "title": "Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss",
      "authors": [
        "Ang Lv",
        "Jin Ma",
        "Yiyuan Ma",
        "Siyuan Qiao"
      ],
      "abstract": "Mixture-of-Experts (MoE) models lack explicit constraints to ensure the router's decisions align well with the experts' capabilities, which ultimately limits model performance. To address this, we propose expert-router coupling (ERC) loss, a lightweight auxiliary loss that tightly couples the router's decisions with expert capabilities. Our approach treats each expert's router embedding as a proxy token for the tokens assigned to that expert, and feeds perturbed router embeddings through the experts to obtain internal activations. The ERC loss enforces two constraints on these activations: (1) Each expert must exhibit higher activation for its own proxy token than for the proxy tokens of any other expert. (2) Each proxy token must elicit stronger activation from its corresponding expert than from any other expert. These constraints jointly ensure that each router embedding faithfully represents its corresponding expert's capability, while each expert specializes in processing the tokens actually routed to it. The ERC loss is computationally efficient, operating only on n^2 activations, where n is the number of experts. This represents a fixed cost independent of batch size, unlike prior coupling methods that scale with the number of tokens (often millions per batch). Through pre-training MoE-LLMs ranging from 3B to 15B parameters and extensive analysis on trillions of tokens, we demonstrate the effectiveness of the ERC loss. Moreover, the ERC loss offers flexible control and quantitative tracking of expert specialization levels during training, providing valuable insights into MoEs.",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23447.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23447",
      "published": "2025-12-29T13:03:18Z",
      "updated": "2025-12-29T13:03:18Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一种高效的辅助损失函数，以增强混合专家模型中路由决策与专家能力的对齐。",
        "motivation": "混合专家模型缺乏确保路由器决策与专家能力对齐的显式约束，这限制了模型性能。",
        "method": "提出专家-路由器耦合损失（ERC），通过施加双重约束，使用专家的代理令牌来对齐路由器决策与专家能力。",
        "result": "在3B至15B参数的MoE-LLM预训练中验证有效，并提供对专家专业化程度的定量追踪能力。",
        "conclusion": "提供了一种计算高效的损失方法，改进了MoE的性能，并增强了对模型内部机理的可解释性。",
        "tags": [
          "Mixture-of-Experts",
          "Large Language Model",
          "Router Mechanism",
          "Auxiliary Loss",
          "Pre-training"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:48:21.601931Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23430",
      "title": "C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs",
      "authors": [
        "Xuan Feng",
        "Bo An",
        "Tianlong Gu",
        "Liang Chang",
        "Fengrui Hao",
        "Peipeng Yu",
        "Shuai Zhao"
      ],
      "abstract": "Bias in Large Language Models (LLMs) poses significant risks to trustworthiness, manifesting primarily as stereotypical biases (e.g., gender or racial stereotypes) and structural biases (e.g., lexical overlap or position preferences). However, prior paradigms typically address these in isolation, often mitigating one at the expense of exacerbating the other. To address this, we conduct a systematic exploration of these reasoning failures and identify a primary inducement: the latent spurious feature correlations within the input that drive these erroneous reasoning shortcuts. Driven by these findings, we introduce Causal-Contrastive Preference Optimization (C2PO), a unified alignment framework designed to tackle these specific failures by simultaneously discovering and suppressing these correlations directly within the optimization process. Specifically, C2PO leverages causal counterfactual signals to isolate bias-inducing features from valid reasoning paths, and employs a fairness-sensitive preference update mechanism to dynamically evaluate logit-level contributions and suppress shortcut features. Extensive experiments across multiple benchmarks covering stereotypical bias (BBQ, Unqover), structural bias (MNLI, HANS, Chatbot, MT-Bench), out-of-domain fairness (StereoSet, WinoBias), and general utility (MMLU, GSM8K) demonstrate that C2PO effectively mitigates stereotypical and structural biases while preserving robust general reasoning capabilities.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23430.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23430",
      "published": "2025-12-29T12:49:32Z",
      "updated": "2025-12-29T12:49:32Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了C2PO对齐框架，统一解决大语言模型中的刻板印象与结构偏见，并保持模型通用能力。",
        "motivation": "现有方法孤立地处理刻板印象或结构偏见，常顾此失彼，需要统一框架同时发现并抑制导致偏见的潜在虚假特征关联。",
        "method": "C2PO框架，利用因果反事实信号隔离偏见特征，并使用公平敏感的偏好更新机制动态抑制捷径特征。",
        "result": "在多个偏见与能力基准测试（如BBQ、MNLI、MMLU）上，有效减轻了两种偏见，同时保持了强大的通用推理性能。",
        "conclusion": "提供了一个统一的、因果驱动的对齐框架，能在消除偏见的同时保护模型的通用能力，提升LLM的可信度。",
        "tags": [
          "Large Language Model",
          "Bias Mitigation",
          "Causal Inference",
          "Preference Optimization",
          "Contrastive Learning"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:49:22.057689Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23422",
      "title": "Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data",
      "authors": [
        "Jiapeng Wang",
        "Yiwen Hu",
        "Yanzipeng Gao",
        "Haoyu Wang",
        "Shuo Wang",
        "Hongyu Lu",
        "Jiaxin Mao",
        "Wayne Xin Zhao",
        "Junyi Li",
        "Xiao Zhang"
      ],
      "abstract": "As access to high-quality, domain-specific data grows increasingly scarce, multi-epoch training has become a practical strategy for adapting large language models (LLMs). However, autoregressive models often suffer from performance degradation under repeated data exposure, where overfitting leads to a marked decline in model capability. Through empirical analysis, we trace this degradation to an imbalance in learning dynamics: predictable, low-entropy tokens are learned quickly and come to dominate optimization, while the model's ability to generalize on high-entropy tokens deteriorates with continued training. To address this, we introduce EntroDrop, an entropy-guided token dropout method that functions as structured data regularization. EntroDrop selectively masks low-entropy tokens during training and employs a curriculum schedule to adjust regularization strength in alignment with training progress. Experiments across model scales from 0.6B to 8B parameters show that EntroDrop consistently outperforms standard regularization baselines and maintains robust performance throughout extended multi-epoch training. These findings underscore the importance of aligning regularization with token-level learning dynamics when training on limited data. Our approach offers a promising pathway toward more effective adaptation of LLMs in data-constrained domains.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23422.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23422",
      "published": "2025-12-29T12:35:51Z",
      "updated": "2025-12-29T12:35:51Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出熵引导令牌丢弃方法，改善有限数据下大型语言模型的多轮训练性能。",
        "motivation": "解决自回归语言模型在有限领域数据多轮训练中因学习动态不平衡导致的性能下降问题。",
        "method": "引入EntroDrop方法，通过熵引导选择性屏蔽低熵令牌，并结合课程计划调整正则化强度。",
        "result": "实验在0.6B到8B参数模型上显示，EntroDrop优于标准正则化基线，并在多轮训练中保持鲁棒性能。",
        "conclusion": "贡献在于EntroDrop方法，强调了正则化与令牌级学习动态对齐的重要性，为数据受限领域LLM适应提供有效途径。",
        "tags": [
          "Autoregressive Language Model",
          "Token Dropout",
          "Entropy-Guided Regularization",
          "Curriculum Learning",
          "Multi-epoch Training"
        ],
        "relevance_score": 1.0
      },
      "analyzed_at": "2026-01-03T22:50:08.358296Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24946",
      "title": "HaineiFRDM: Explore Diffusion to Restore Defects in Fast-Movement Films",
      "authors": [
        "Rongji Xun",
        "Junjie Yuan",
        "Zhongjie Wang"
      ],
      "abstract": "Existing open-source film restoration methods show limited performance compared to commercial methods due to training with low-quality synthetic data and employing noisy optical flows. In addition, high-resolution films have not been explored by the open-source methods.We propose HaineiFRDM(Film Restoration Diffusion Model), a film restoration framework, to explore diffusion model's powerful content-understanding ability to help human expert better restore indistinguishable film defects.Specifically, we employ a patch-wise training and testing strategy to make restoring high-resolution films on one 24GB-VRAMR GPU possible and design a position-aware Global Prompt and Frame Fusion Modules.Also, we introduce a global-local frequency module to reconstruct consistent textures among different patches. Besides, we firstly restore a low-resolution result and use it as global residual to mitigate blocky artifacts caused by patching process.Furthermore, we construct a film restoration dataset that contains restored real-degraded films and realistic synthetic data.Comprehensive experimental results conclusively demonstrate the superiority of our model in defect restoration ability over existing open-source methods. Code and the dataset will be released.",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24946.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24946",
      "published": "2025-12-31T16:18:07Z",
      "updated": "2025-12-31T16:18:07Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了HaineiFRDM扩散模型框架，以解决高分辨率快速运动影片的缺陷修复难题。",
        "motivation": "解决现有开源电影修复方法因使用低质量合成数据和噪声光流导致的性能不足，并应对高分辨率影片的修复挑战。",
        "method": "采用基于分块的训练与测试策略，设计位置感知全局提示、帧融合模块和全局-局部频率模块，并利用低分辨率结果作为全局残差。",
        "result": "模型在缺陷修复能力上优于现有开源方法，并构建了包含真实修复影片与合成数据的电影修复数据集。",
        "conclusion": "成功探索了扩散模型在电影修复中的应用，所提方法能有效修复高分辨率影片缺陷，代码与数据集将开源。",
        "tags": [
          "Diffusion Model",
          "Image Restoration",
          "High-Resolution Processing",
          "Patch-based Training",
          "Film Restoration Dataset"
        ],
        "relevance_score": 0.95
      },
      "analyzed_at": "2026-01-03T22:45:54.036726Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24903",
      "title": "FinMMDocR: Benchmarking Financial Multimodal Reasoning with Scenario Awareness, Document Understanding, and Multi-Step Computation",
      "authors": [
        "Zichen Tang",
        "Haihong E",
        "Rongjin Li",
        "Jiacheng Liu",
        "Linwei Jia",
        "Zhuodi Hao",
        "Zhongjun Yang",
        "Yuanze Li",
        "Haolin Tian",
        "Xinyi Hu",
        "Peizhi Zhao",
        "Yuan Liu",
        "Zhengyu Wang",
        "Xianghe Wang",
        "Yiling Huang",
        "Xueyuan Lin",
        "Ruofei Bai",
        "Zijian Xie",
        "Qian Huang",
        "Ruining Cao",
        "Haocheng Gao"
      ],
      "abstract": "We introduce FinMMDocR, a novel bilingual multimodal benchmark for evaluating multimodal large language models (MLLMs) on real-world financial numerical reasoning. Compared to existing benchmarks, our work delivers three major advancements. (1) Scenario Awareness: 57.9% of 1,200 expert-annotated problems incorporate 12 types of implicit financial scenarios (e.g., Portfolio Management), challenging models to perform expert-level reasoning based on assumptions; (2) Document Understanding: 837 Chinese/English documents spanning 9 types (e.g., Company Research) average 50.8 pages with rich visual elements, significantly surpassing existing benchmarks in both breadth and depth of financial documents; (3) Multi-Step Computation: Problems demand 11-step reasoning on average (5.3 extraction + 5.7 calculation steps), with 65.0% requiring cross-page evidence (2.4 pages average). The best-performing MLLM achieves only 58.0% accuracy, and different retrieval-augmented generation (RAG) methods show significant performance variations on this task. We expect FinMMDocR to drive improvements in MLLMs and reasoning-enhanced methods on complex multimodal reasoning tasks in real-world scenarios.",
      "categories": [
        "cs.CV",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24903.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24903",
      "published": "2025-12-31T15:00:03Z",
      "updated": "2025-12-31T15:00:03Z",
      "comment": "Accepted by AAAI-26 Main Track",
      "light_analysis": {
        "overview": "提出了一个名为FinMMDocR的金融多模态推理基准，包含场景意识、文档理解和多步计算三大创新，用于评估MLLMs。",
        "motivation": "现有基准不足以全面评估多模态大语言模型在现实世界、复杂的金融数值推理任务上的能力。",
        "method": "创建了一个包含1200个专家标注问题、837份双语长文档的基准，特点是嵌入了12种隐含金融场景，并要求平均11步的跨页推理。",
        "result": "表现最佳的MLLM准确率仅为58.0%，不同的检索增强生成方法在该任务上表现差异显著。",
        "conclusion": "该基准推动了MLLMs在现实复杂多模态推理任务上的改进，并为评估推理增强方法提供了重要工具。",
        "tags": [
          "Multimodal Large Language Models",
          "Retrieval-Augmented Generation",
          "Numerical Reasoning",
          "Document Understanding",
          "Benchmark"
        ],
        "relevance_score": 0.95
      },
      "analyzed_at": "2026-01-03T22:38:33.638620Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24848",
      "title": "PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI",
      "authors": [
        "Srija Mukhopadhyay",
        "Sathwik Reddy",
        "Shruthi Muthukumar",
        "Jisun An",
        "Ponnurangam Kumaraguru"
      ],
      "abstract": "Personalized AI agents rely on access to a user's digital footprint, which often includes sensitive data from private emails, chats and purchase histories. Yet this access creates a fundamental societal and privacy risk: systems lacking social-context awareness can unintentionally expose user secrets, threatening digital well-being. We introduce PrivacyBench, a benchmark with socially grounded datasets containing embedded secrets and a multi-turn conversational evaluation to measure secret preservation. Testing Retrieval-Augmented Generation (RAG) assistants reveals that they leak secrets in up to 26.56% of interactions. A privacy-aware prompt lowers leakage to 5.12%, yet this measure offers only partial mitigation. The retrieval mechanism continues to access sensitive data indiscriminately, which shifts the entire burden of privacy preservation onto the generator. This creates a single point of failure, rendering current architectures unsafe for wide-scale deployment. Our findings underscore the urgent need for structural, privacy-by-design safeguards to ensure an ethical and inclusive web for everyone.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24848.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24848",
      "published": "2025-12-31T13:16:45Z",
      "updated": "2025-12-31T13:16:45Z",
      "comment": "11 pages, 2 figures",
      "light_analysis": {
        "overview": "提出了一个名为PrivacyBench的对话基准，用于评估个性化AI在保护用户嵌入秘密方面的能力，揭示了现有RAG架构的重大隐私风险。",
        "motivation": "个性化AI助手需要访问用户敏感数据，但缺乏社会语境意识的系统可能无意中泄露用户秘密，构成隐私风险和数字福祉威胁。",
        "method": "构建了一个包含嵌入秘密的社交基础数据集基准，并采用多轮对话评估框架，以量化AI助手在交互过程中对秘密的保护程度。",
        "result": "测试显示，RAG助手在高达26.56%的交互中泄露秘密；使用隐私提示可降至5.12%，但检索机制仍会暴露敏感数据，形成单点故障。",
        "conclusion": "当前AI架构的隐私保护措施不完善，存在单点故障，迫切需要从系统设计层面构建隐私保护机制，以实现安全、道德的广泛应用。",
        "tags": [
          "Privacy Benchmark",
          "Retrieval-Augmented Generation",
          "Privacy in AI",
          "Conversational AI",
          "Generative AI"
        ],
        "relevance_score": 0.95
      },
      "analyzed_at": "2026-01-03T22:49:27.245763Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24260",
      "title": "Physically-Grounded Manifold Projection with Foundation Priors for Metal Artifact Reduction in Dental CBCT",
      "authors": [
        "Zhi Li",
        "Yaqi Wang",
        "Bingtao Ma",
        "Yifan Zhang",
        "Huiyu Zhou",
        "Shuai Wang"
      ],
      "abstract": "Metal artifacts in Dental CBCT severely obscure anatomical structures, hindering diagnosis. Current deep learning for Metal Artifact Reduction (MAR) faces limitations: supervised methods suffer from spectral blurring due to \"regression-to-the-mean\", while unsupervised ones risk structural hallucinations. Denoising Diffusion Models (DDPMs) offer realism but rely on slow, stochastic iterative sampling, unsuitable for clinical use. To resolve this, we propose the Physically-Grounded Manifold Projection (PGMP) framework. First, our Anatomically-Adaptive Physics Simulation (AAPS) pipeline synthesizes high-fidelity training pairs via Monte Carlo spectral modeling and patient-specific digital twins, bridging the synthetic-to-real gap. Second, our DMP-Former adapts the Direct x-Prediction paradigm, reformulating restoration as a deterministic manifold projection to recover clean anatomy in a single forward pass, eliminating stochastic sampling. Finally, a Semantic-Structural Alignment (SSA) module anchors the solution using priors from medical foundation models (MedDINOv3), ensuring clinical plausibility. Experiments on synthetic and multi-center clinical datasets show PGMP outperforms state-of-the-art methods on unseen anatomy, setting new benchmarks in efficiency and diagnostic reliability. Code and data: https://github.com/ricoleehduu/PGMP",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24260.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24260",
      "published": "2025-12-30T14:36:26Z",
      "updated": "2025-12-30T14:36:26Z",
      "comment": "This manuscript has been submitted to Medical Image Analysis for peer review",
      "light_analysis": {
        "overview": "提出结合物理模拟与医学先验的确定性框架PGMP，高效去除牙齿CBCT金属伪影，提升诊断可靠性。",
        "motivation": "解决牙齿CBCT中金属伪影严重阻碍诊断，以及现有深度学习MAR方法存在伪影残留、结构幻觉或速度慢的问题。",
        "method": "提出PGMP框架：AAPS生成高保真训练数据；DMP-Former进行确定性流形投影实现单次修复；SSA引入医学基础模型先验确保结构合理。",
        "result": "在合成与多中心临床数据集上超越现有方法，在效率和诊断可靠性方面均设立了新基准。",
        "conclusion": "结合物理建模、确定性学习与基础模型先验，为临床CBCT图像质量提升提供了高效可靠的解决方案。",
        "tags": [
          "Medical Imaging",
          "Metal Artifact Reduction",
          "Denoising Diffusion Models",
          "Monte Carlo Simulation",
          "Foundation Models"
        ],
        "relevance_score": 0.95
      },
      "analyzed_at": "2026-01-03T22:37:26.652961Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24113",
      "title": "CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation",
      "authors": [
        "Jiaxin Hu",
        "Tao Wang",
        "Bingsan Yang",
        "Hongrun Wang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent \"Black-Box\" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24113.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24113",
      "published": "2025-12-30T09:50:50Z",
      "updated": "2025-12-30T09:50:50Z",
      "comment": "9 pages, 6 figures",
      "light_analysis": {
        "overview": "提出CogRec认知推荐智能体，融合大语言模型与Soar认知架构，实现可解释的推荐与在线学习。",
        "motivation": "解决LLM推荐系统的黑箱性、知识幻觉和在线学习能力有限，以及Soar架构知识获取困难的互补性问题。",
        "method": "以Soar为核心推理引擎，LLM初始化知识；感知-认知-行动循环中遇阻碍则查询LLM，其解答通过“块化”转为新的产生式规则。",
        "result": "在三个公开数据集上的评估显示，在推荐准确性、可解释性及处理长尾问题方面均有显著优势。",
        "conclusion": "提出LLM与认知架构融合的新范式，实现了知识库的持续演进和为推荐提供高度可解释的理由。",
        "tags": [
          "Large Language Model",
          "Soar Cognitive Architecture",
          "Explainable Recommendation",
          "Online Learning",
          "Production Rules"
        ],
        "relevance_score": 0.95
      },
      "analyzed_at": "2026-01-03T22:36:54.566724Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.25055",
      "title": "Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings",
      "authors": [
        "Tianzhi He",
        "Farrokh Jazizadeh"
      ],
      "abstract": "This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.25055.pdf",
      "abs_url": "https://arxiv.org/abs/2512.25055",
      "published": "2025-12-31T18:51:19Z",
      "updated": "2025-12-31T18:51:19Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了一个基于大语言模型的上下文感知 AI 代理框架，用于智能建筑的能源管理系统。",
        "motivation": "解决现有能源管理系统在上下文感知和自然语言交互方面的局限性，通过 AI 代理提升能源管理的智能化。",
        "method": "设计了三模块（感知、中央控制、行动）的 LLM-based AI 代理框架，利用自然语言处理进行能源数据分析和管理。",
        "result": "原型在设备控制（86%准确率）、记忆任务（97%）等任务中表现良好，但成本估计准确率较低（49%），需改进。",
        "conclusion": "该研究形式化了 LLM-based BEMS AI 代理的评估，强调准确性与计算效率的权衡，为未来研究提供方向。",
        "tags": [
          "Large Language Model",
          "AI Agents",
          "Smart Buildings",
          "Energy Management",
          "Natural Language Processing"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:41:01.398611Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24997",
      "title": "Classifying long legal documents using short random chunks",
      "authors": [
        "Luis Adrián Cabrera-Diego"
      ],
      "abstract": "Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens). Besides, we present its deployment pipeline using Temporal, a durable execution solution, which allow us to have a reliable and robust processing workflow. The best model had a weighted F-score of 0.898, while the pipeline running on CPU had a processing median time of 498 seconds per 100 files.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24997.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24997",
      "published": "2025-12-31T17:48:08Z",
      "updated": "2025-12-31T17:48:08Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了基于DeBERTa V3和LSTM的分类器，使用随机短块处理长法律文档，并部署了可靠管道。",
        "motivation": "解决长法律文档分类中，由于文档长度导致Transformers模型输入困难和效率低下的问题。",
        "method": "采用DeBERTa V3和LSTM模型，输入为48个随机选择的短块（最大128令牌），并使用Temporal构建部署管道。",
        "result": "最佳模型加权F-score达0.898，管道在CPU上处理100个文件的中位时间为498秒。",
        "conclusion": "贡献了一种高效分类长法律文档的方法，结合了模型优化和可靠的部署流程。",
        "tags": [
          "DeBERTa V3",
          "LSTM",
          "Random Chunk Selection",
          "Document Classification",
          "Temporal"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:43:19.315148Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24975",
      "title": "Attribution-Guided Distillation of Matryoshka Sparse Autoencoders",
      "authors": [
        "Cristina P. Martin-Linares",
        "Jonathan P. Ling"
      ],
      "abstract": "Sparse autoencoders (SAEs) aim to disentangle model activations into monosemantic, human-interpretable features. In practice, learned features are often redundant and vary across training runs and sparsity levels, which makes interpretations difficult to transfer and reuse. We introduce Distilled Matryoshka Sparse Autoencoders (DMSAEs), a training pipeline that distills a compact core of consistently useful features and reuses it to train new SAEs. DMSAEs run an iterative distillation cycle: train a Matryoshka SAE with a shared core, use gradient X activation to measure each feature's contribution to next-token loss in the most nested reconstruction, and keep only the smallest subset that explains a fixed fraction of the attribution. Only the core encoder weight vectors are transferred across cycles; the core decoder and all non-core latents are reinitialized each time. On Gemma-2-2B layer 12 residual stream activations, seven cycles of distillation (500M tokens, 65k width) yielded a distilled core of 197 features that were repeatedly selected. Training using this distilled core improves several SAEBench metrics and demonstrates that consistent sets of latent features can be transferred across sparsity levels",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24975.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24975",
      "published": "2025-12-31T17:12:55Z",
      "updated": "2025-12-31T17:12:55Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出蒸馏Matryoshka稀疏自编码器方法，通过迭代蒸馏提取一致特征核心，改善可解释性和重用性。",
        "motivation": "解决稀疏自编码器特征冗余且在不同训练和稀疏度下变化的问题，使解释难以转移和重用。",
        "method": "引入DMSAEs训练流程，迭代蒸馏循环：训练Matryoshka SAE，用梯度X激活归因筛选核心特征，仅保留编码器权重。",
        "result": "在Gemma-2-2B上蒸馏出197个核心特征，改善SAEBench指标，证明特征可跨稀疏度转移。",
        "conclusion": "DMSAEs能提取一致特征核心，提升稀疏自编码器的解释性和跨条件重用性。",
        "tags": [
          "Sparse Autoencoders",
          "Distillation",
          "Gradient Attribution",
          "Matryoshka Models",
          "Interpretability"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:51:04.652870Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24965",
      "title": "ShowUI-$π$: Flow-based Generative Models as GUI Dexterous Hands",
      "authors": [
        "Siyuan Hu",
        "Kevin Qinghong Lin",
        "Mike Zheng Shou"
      ],
      "abstract": "Building intelligent agents capable of dexterous manipulation is essential for achieving human-like automation in both robotics and digital environments. However, existing GUI agents rely on discrete click predictions (x,y), which prohibits free-form, closed-loop trajectories (e.g. dragging a progress bar) that require continuous, on-the-fly perception and adjustment. In this work, we develop ShowUI-$π$, the first flow-based generative model as GUI dexterous hand, featuring the following designs: (i) Unified Discrete-Continuous Actions, integrating discrete clicks and continuous drags within a shared model, enabling flexible adaptation across diverse interaction modes; (ii) Flow-based Action Generation for drag modeling, which predicts incremental cursor adjustments from continuous visual observations via a lightweight action expert, ensuring smooth and stable trajectories; (iii) Drag Training data and Benchmark, where we manually collect and synthesize 20K drag trajectories across five domains (e.g. PowerPoint, Adobe Premiere Pro), and introduce ScreenDrag, a benchmark with comprehensive online and offline evaluation protocols for assessing GUI agents' drag capabilities. Our experiments show that proprietary GUI agents still struggle on ScreenDrag (e.g. Operator scores 13.27, and the best Gemini-2.5-CUA reaches 22.18). In contrast, ShowUI-$π$ achieves 26.98 with only 450M parameters, underscoring both the difficulty of the task and the effectiveness of our approach. We hope this work advances GUI agents toward human-like dexterous control in digital world. The code is available at https://github.com/showlab/showui-pi.",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24965.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24965",
      "published": "2025-12-31T16:51:14Z",
      "updated": "2025-12-31T16:51:14Z",
      "comment": "17 pages, 15 figures",
      "light_analysis": {
        "overview": "提出首个基于流的生成模型ShowUI-$π$，用于GUI灵巧操作，统一离散和连续动作。",
        "motivation": "现有GUI代理依赖离散点击预测，无法处理连续拖动操作如进度条拖动，限制了自动化能力。",
        "method": "使用基于流的生成模型，统一离散点击和连续拖动动作，通过流模型预测连续光标调整。",
        "result": "在ScreenDrag基准上得分26.98，优于其他代理（如Operator 13.27），仅用450M参数。",
        "conclusion": "推动了GUI代理向数字世界中的类人灵巧控制发展，提供了开源代码和基准。",
        "tags": [
          "Flow-based Generative Models",
          "GUI Agents",
          "Continuous Control",
          "Drag Modeling"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:44:39.422874Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24952",
      "title": "VIPER: Process-aware Evaluation for Generative Video Reasoning",
      "authors": [
        "Yifan Li",
        "Yukai Gu",
        "Yingqian Min",
        "Zikang Liu",
        "Yifan Du",
        "Kun Zhou",
        "Min Yang",
        "Wayne Xin Zhao",
        "Minghui Qiu"
      ],
      "abstract": "Recent breakthroughs in video generation have demonstrated an emerging capability termed Chain-of-Frames (CoF) reasoning, where models resolve complex tasks through the generation of continuous frames. While these models show promise for Generative Video Reasoning (GVR), existing evaluation frameworks often rely on single-frame assessments, which can lead to outcome-hacking, where a model reaches a correct conclusion through an erroneous process. To address this, we propose a process-aware evaluation paradigm. We introduce VIPER, a comprehensive benchmark spanning 16 tasks across temporal, structural, symbolic, spatial, physics, and planning reasoning. Furthermore, we propose Process-outcome Consistency (POC@r), a new metric that utilizes VLM-as-Judge with a hierarchical rubric to evaluate both the validity of the intermediate steps and the final result. Our experiments reveal that state-of-the-art video models achieve only about 20% POC@1.0 and exhibit a significant outcome-hacking. We further explore the impact of test-time scaling and sampling robustness, highlighting a substantial gap between current video generation and true generalized visual reasoning. Our benchmark will be publicly released.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24952.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24952",
      "published": "2025-12-31T16:31:59Z",
      "updated": "2025-12-31T16:31:59Z",
      "comment": "Work in progress",
      "light_analysis": {
        "overview": "提出了关注视频生成推理过程有效性的新评估框架VIPER及POC@r指标。",
        "motivation": "现有视频推理评估多基于单帧结果，导致模型可能通过错误过程得到正确结论（结果作弊）。",
        "method": "构建了涵盖六大类推理任务的VIPER基准，并设计了基于VLM评估与分层规则的POC@r指标。",
        "result": "实验表明，先进视频模型POC@1.0得分仅约20%，存在显著结果作弊现象，与真实推理存在差距。",
        "conclusion": "为生成式视频推理提供了一个过程感知的评估标准，揭示了当前模型的局限性并指明了方向。",
        "tags": [
          "Generative Video Reasoning",
          "Chain-of-Frames",
          "VLM-as-Judge",
          "Process Evaluation",
          "Benchmark Construction"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:37:31.429145Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24898",
      "title": "PRISM: A hierarchical multiscale approach for time series forecasting",
      "authors": [
        "Zihao Chen",
        "Alexandre Andre",
        "Wenrui Ma",
        "Ian Knight",
        "Sergey Shuvaev",
        "Eva Dyer"
      ],
      "abstract": "Forecasting is critical in areas such as finance, biology, and healthcare. Despite the progress in the field, making accurate forecasts remains challenging because real-world time series contain both global trends, local fine-grained structure, and features on multiple scales in between. Here, we present a new forecasting method, PRISM (Partitioned Representation for Iterative Sequence Modeling), that addresses this challenge through a learnable tree-based partitioning of the signal. At the root of the tree, a global representation captures coarse trends in the signal, while recursive splits reveal increasingly localized views of the signal. At each level of the tree, data are projected onto a time-frequency basis (e.g., wavelets or exponential moving averages) to extract scale-specific features, which are then aggregated across the hierarchy. This design allows the model to jointly capture global structure and local dynamics of the signal, enabling accurate forecasting. Experiments across benchmark datasets show that our method outperforms state-of-the-art methods for forecasting. Overall, these results demonstrate that our hierarchical approach provides a lightweight and flexible framework for forecasting multivariate time series. The code is available at https://github.com/nerdslab/prism.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24898.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24898",
      "published": "2025-12-31T14:51:12Z",
      "updated": "2025-12-31T14:51:12Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了PRISM方法，一种分层的多尺度时间序列预测框架，通过树状分割捕捉全局和局部特征。",
        "motivation": "解决时间序列预测中因包含全局趋势和局部精细结构等多尺度特征而导致的挑战。",
        "method": "使用可学习的树状分割信号，结合时间-频率基础（如小波）提取多尺度特征，并跨层次聚合。",
        "result": "在基准数据集上的实验显示，该方法优于现有的最先进预测方法。",
        "conclusion": "该方法为多元时间序列预测提供了一个轻量级和灵活的框架。",
        "tags": [
          "Time Series Forecasting",
          "Hierarchical Modeling",
          "Multiscale Analysis",
          "Wavelet Transform"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:50:52.237685Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24880",
      "title": "mHC: Manifold-Constrained Hyper-Connections",
      "authors": [
        "Zhenda Xie",
        "Yixuan Wei",
        "Huanqi Cao",
        "Chenggang Zhao",
        "Chengqi Deng",
        "Jiashi Li",
        "Damai Dai",
        "Huazuo Gao",
        "Jiang Chang",
        "Liang Zhao",
        "Shangyan Zhou",
        "Zhean Xu",
        "Zhengyan Zhang",
        "Wangding Zeng",
        "Shengding Hu",
        "Yuqing Wang",
        "Jingyang Yuan",
        "Lean Wang",
        "Wenfeng Liang"
      ],
      "abstract": "Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24880.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24880",
      "published": "2025-12-31T14:16:26Z",
      "updated": "2025-12-31T14:16:26Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出流形约束的超连接框架，解决训练不稳定问题并提升模型扩展性。",
        "motivation": "解决超连接技术破坏残差恒等映射特性导致的训练不稳定、可扩展性差和高内存开销问题。",
        "method": "将超连接的残差空间投影到特定流形以恢复恒等映射，并进行严格的基础设施优化。",
        "result": "实验证明该方法可有效进行大规模训练，实现了性能提升和更优的可扩展性。",
        "conclusion": "作为超连接的实用扩展，mHC有助于深化对拓扑架构设计的理解，并为基础模型进化指明了方向。",
        "tags": [
          "Hyper-Connections",
          "Residual Connections",
          "Manifold Constraint",
          "Neural Architecture Design"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:47:16.810665Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24838",
      "title": "CropTrack: A Tracking with Re-Identification Framework for Precision Agriculture",
      "authors": [
        "Md Ahmed Al Muzaddid",
        "Jordan A. James",
        "William J. Beksi"
      ],
      "abstract": "Multiple-object tracking (MOT) in agricultural environments presents major challenges due to repetitive patterns, similar object appearances, sudden illumination changes, and frequent occlusions. Contemporary trackers in this domain rely on the motion of objects rather than appearance for association. Nevertheless, they struggle to maintain object identities when targets undergo frequent and strong occlusions. The high similarity of object appearances makes integrating appearance-based association nontrivial for agricultural scenarios. To solve this problem we propose CropTrack, a novel MOT framework based on the combination of appearance and motion information. CropTrack integrates a reranking-enhanced appearance association, a one-to-many association with appearance-based conflict resolution strategy, and an exponential moving average prototype feature bank to improve appearance-based association. Evaluated on publicly available agricultural MOT datasets, CropTrack demonstrates consistent identity preservation, outperforming traditional motion-based tracking methods. Compared to the state of the art, CropTrack achieves significant gains in identification F1 and association accuracy scores with a lower number of identity switches.",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24838.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24838",
      "published": "2025-12-31T12:59:38Z",
      "updated": "2025-12-31T12:59:38Z",
      "comment": "8 pages, 5 figures, and 3 tables",
      "light_analysis": {
        "overview": "提出CropTrack框架，融合外观与运动信息解决农业场景多目标追踪中的身份保持难题。",
        "motivation": "农业环境中目标外观高度相似且遮挡频繁，现有基于运动的追踪方法难以维持目标身份。",
        "method": "结合外观与运动信息，引入重新排序增强的外观关联、基于外观冲突解决的一对多关联和指数移动平均原型特征库。",
        "result": "在农业MOT数据集上身份保持更一致，身份F1分数和关联准确率显著提升，身份切换更少。",
        "conclusion": "CropTrack框架通过有效结合外观信息，提升了农业场景下目标追踪的鲁棒性和准确性。",
        "tags": [
          "Multiple-object Tracking (MOT)",
          "Re-identification",
          "Appearance-based Association",
          "Exponential Moving Average",
          "Feature Bank"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:39:43.179291Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24826",
      "title": "Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with Multi-Information Derivative-Free Control",
      "authors": [
        "Jason Armitage",
        "Rico Sennnrich"
      ],
      "abstract": "Cross-modal systems trained on 2D visual inputs are presented with a dimensional shift when processing 3D scenes. An in-scene camera bridges the dimensionality gap but requires learning a control module. We introduce a new method that improves multivariate mutual information estimates by regret minimisation with derivative-free optimisation. Our algorithm enables off-the-shelf cross-modal systems trained on 2D visual inputs to adapt online to object occlusions and differentiate features. The pairing of expressive measures and value-based optimisation assists control of an in-scene camera to learn directly from the noisy outputs of vision-language models. The resulting pipeline improves performance in cross-modal tasks on multi-object 3D scenes without resorting to pretraining or finetuning.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24826.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24826",
      "published": "2025-12-31T12:39:03Z",
      "updated": "2025-12-31T12:39:03Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出无导数优化方法改进互信息估计，使2D跨模态系统能在线适应3D多对象场景。",
        "motivation": "解决2D训练的跨模态系统处理3D场景时的维度偏移问题，需要控制场景内相机来桥接维度差距。",
        "method": "采用无导数优化的遗憾最小化改进多元互信息估计，结合表达性度量和基于值优化控制相机从视觉-语言模型输出学习。",
        "result": "算法提高了跨模态任务在多对象3D场景上的性能，无需预训练或微调。",
        "conclusion": "贡献在于提出管道通过在线适应改进跨模态系统性能，避免额外训练。",
        "tags": [
          "Cross-modal systems",
          "Derivative-free optimisation",
          "Mutual information estimation",
          "Vision-language models",
          "Online adaptation"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:50:45.388357Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24763",
      "title": "UniC-Lift: Unified 3D Instance Segmentation via Contrastive Learning",
      "authors": [
        "Ankit Dhiman",
        "Srinath R",
        "Jaswanth Reddy",
        "Lokesh R Boregowda",
        "Venkatesh Babu Radhakrishnan"
      ],
      "abstract": "3D Gaussian Splatting (3DGS) and Neural Radiance Fields (NeRF) have advanced novel-view synthesis. Recent methods extend multi-view 2D segmentation to 3D, enabling instance/semantic segmentation for better scene understanding. A key challenge is the inconsistency of 2D instance labels across views, leading to poor 3D predictions. Existing methods use a two-stage approach in which some rely on contrastive learning with hyperparameter-sensitive clustering, while others preprocess labels for consistency. We propose a unified framework that merges these steps, reducing training time and improving performance by introducing a learnable feature embedding for segmentation in Gaussian primitives. This embedding is then efficiently decoded into instance labels through a novel \"Embedding-to-Label\" process, effectively integrating the optimization. While this unified framework offers substantial benefits, we observed artifacts at the object boundaries. To address the object boundary issues, we propose hard-mining samples along these boundaries. However, directly applying hard mining to the feature embeddings proved unstable. Therefore, we apply a linear layer to the rasterized feature embeddings before calculating the triplet loss, which stabilizes training and significantly improves performance. Our method outperforms baselines qualitatively and quantitatively on the ScanNet, Replica3D, and Messy-Rooms datasets.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24763.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24763",
      "published": "2025-12-31T10:20:01Z",
      "updated": "2025-12-31T10:20:01Z",
      "comment": "Accepted to AAAI 2026. Project Page: https://unic-lift.github.io/",
      "light_analysis": {
        "overview": "提出UniC-Lift统一框架，通过对比学习和特征嵌入改进3D实例分割的性能和效率。",
        "motivation": "解决多视图2D分割标签不一致导致3D实例分割效果差的问题，现有方法复杂且超参数敏感。",
        "method": "使用统一框架合并两阶段过程，引入可学习特征嵌入和'Embedding-to-Label'解码，结合硬挖掘和稳定三元组损失处理边界问题。",
        "result": "在ScanNet、Replica3D和Messy-Rooms数据集上，定性和定量评估均优于基线方法。",
        "conclusion": "贡献在于高效统一的3D实例分割方法，提升分割准确性、训练稳定性并解决标签不一致。",
        "tags": [
          "Contrastive Learning",
          "3D Instance Segmentation",
          "Gaussian Splatting",
          "Feature Embedding",
          "Triplet Loss"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:41:10.352497Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24696",
      "title": "Causal Discovery with Mixed Latent Confounding via Precision Decomposition",
      "authors": [
        "Amir Asiaee",
        "Samhita Pal",
        "James O'quinn",
        "James P. Long"
      ],
      "abstract": "We study causal discovery from observational data in linear Gaussian systems affected by \\emph{mixed latent confounding}, where some unobserved factors act broadly across many variables while others influence only small subsets. This setting is common in practice and poses a challenge for existing methods: differentiable and score-based DAG learners can misinterpret global latent effects as causal edges, while latent-variable graphical models recover only undirected structure.   We propose \\textsc{DCL-DECOR}, a modular, precision-led pipeline that separates these roles. The method first isolates pervasive latent effects by decomposing the observed precision matrix into a structured component and a low-rank component. The structured component corresponds to the conditional distribution after accounting for pervasive confounders and retains only local dependence induced by the causal graph and localized confounding. A correlated-noise DAG learner is then applied to this deconfounded representation to recover directed edges while modeling remaining structured error correlations, followed by a simple reconciliation step to enforce bow-freeness.   We provide identifiability results that characterize the recoverable causal target under mixed confounding and show how the overall problem reduces to well-studied subproblems with modular guarantees. Synthetic experiments that vary the strength and dimensionality of pervasive confounding demonstrate consistent improvements in directed edge recovery over applying correlated-noise DAG learning directly to the confounded data.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24696.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24696",
      "published": "2025-12-31T08:03:41Z",
      "updated": "2025-12-31T08:03:41Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出DCL-DECOR方法，通过精度分解处理混合潜在混淆，提升因果发现的准确性和可识别性。",
        "motivation": "解决线性高斯系统中因果发现受混合潜在混淆影响的挑战，现有方法易误解全局混淆为因果边或只能恢复无向结构。",
        "method": "采用DCL-DECOR管道，分解精度矩阵以隔离普遍混淆，再应用相关噪声DAG学习恢复有向边并建模剩余相关性。",
        "result": "理论证明可识别性，合成实验显示在定向边恢复上优于直接应用相关噪声DAG学习的方法。",
        "conclusion": "该方法能有效分离混淆角色，为混合混淆下的因果发现提供模块化解决方案和改进性能。",
        "tags": [
          "Causal Discovery",
          "Latent Confounding",
          "Precision Decomposition",
          "DAG Learning",
          "Graphical Models"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:39:43.700613Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24684",
      "title": "R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory",
      "authors": [
        "Maoyuan Li",
        "Zhongsheng Wang",
        "Haoyuan Li",
        "Jiamou Liu"
      ],
      "abstract": "We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24684.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24684",
      "published": "2025-12-31T07:33:12Z",
      "updated": "2025-12-31T07:33:12Z",
      "comment": "Accepteed by AAMAS 2026 full paper",
      "light_analysis": {
        "overview": "R-Debater框架通过论辩记忆和检索增强技术生成立场一致、证据支持的多轮辩论。",
        "motivation": "基于修辞学和记忆理论，旨在解决多轮辩论中保持立场一致、有效回应对手并运用证据的问题。",
        "method": "集成辩论知识库进行证据和辩论动作检索，结合基于角色的代理生成跨轮次连贯话语。",
        "result": "在ORCHID辩论数据集上评估，R-Debater在单轮和多轮任务中超越强LLM基线，人类评估确认其一致性和证据使用。",
        "conclusion": "检索基础与结构化规划结合能产生更忠实、立场对齐和连贯的辩论生成。",
        "tags": [
          "Retrieval-Augmented Generation",
          "Argumentative Memory",
          "Role-based Agent",
          "Large Language Model"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:37:39.198138Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24593",
      "title": "3D Semantic Segmentation for Post-Disaster Assessment",
      "authors": [
        "Nhut Le",
        "Maryam Rahnemoonfar"
      ],
      "abstract": "The increasing frequency of natural disasters poses severe threats to human lives and leads to substantial economic losses. While 3D semantic segmentation is crucial for post-disaster assessment, existing deep learning models lack datasets specifically designed for post-disaster environments. To address this gap, we constructed a specialized 3D dataset using unmanned aerial vehicles (UAVs)-captured aerial footage of Hurricane Ian (2022) over affected areas, employing Structure-from-Motion (SfM) and Multi-View Stereo (MVS) techniques to reconstruct 3D point clouds. We evaluated the state-of-the-art (SOTA) 3D semantic segmentation models, Fast Point Transformer (FPT), Point Transformer v3 (PTv3), and OA-CNNs on this dataset, exposing significant limitations in existing methods for disaster-stricken regions. These findings underscore the urgent need for advancements in 3D segmentation techniques and the development of specialized 3D benchmark datasets to improve post-disaster scene understanding and response.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24593.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24593",
      "published": "2025-12-31T03:30:58Z",
      "updated": "2025-12-31T03:30:58Z",
      "comment": "Accepted by the 2025 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2025)",
      "light_analysis": {
        "overview": "构建了一个针对灾后场景的3D语义分割数据集，并评估了现有先进模型，揭示了其在该领域的局限性。",
        "motivation": "自然灾害频发造成重大损失，而现有的3D语义分割模型缺乏专门针对灾后环境的训练和评估数据集。",
        "method": "利用无人机采集飓风灾后图像，通过运动恢复结构和多视图立体技术重建3D点云数据集，并评估了Fast Point Transformer等SOTA模型。",
        "result": "发现现有最先进的3D语义分割模型在灾后场景数据集上表现不佳，存在显著局限性。",
        "conclusion": "该研究强调了为提升灾后场景理解能力，亟需开发专门的3D基准数据集并推动3D分割技术进步。",
        "tags": [
          "3D Semantic Segmentation",
          "Structure-from-Motion",
          "Multi-View Stereo",
          "Point Cloud",
          "Dataset Creation"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:44:23.453962Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24572",
      "title": "Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities",
      "authors": [
        "Hongseok Oh",
        "Wonseok Hwang",
        "Kyoung-Woon On"
      ],
      "abstract": "We introduce the Korean Canonical Legal Benchmark (KCL), a benchmark designed to assess language models' legal reasoning capabilities independently of domain-specific knowledge. KCL provides question-level supporting precedents, enabling a more faithful disentanglement of reasoning ability from parameterized knowledge. KCL consists of two components: (1) KCL-MCQA, multiple-choice problems of 283 questions with 1,103 aligned precedents, and (2) KCL-Essay, open-ended generation problems of 169 questions with 550 aligned precedents and 2,739 instance-level rubrics for automated evaluation. Our systematic evaluation of 30+ models shows large remaining gaps, particularly in KCL-Essay, and that reasoning-specialized models consistently outperform their general-purpose counterparts. We release all resources, including the benchmark dataset and evaluation code, at https://github.com/lbox-kr/kcl.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24572.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24572",
      "published": "2025-12-31T02:35:54Z",
      "updated": "2025-12-31T02:35:54Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了韩国规范法律基准KCL，用于独立评估大语言模型的法律推理能力。",
        "motivation": "为解决现有评估方法难以分离模型法律推理能力与领域知识的问题。",
        "method": "构建包含多选题和开放生成题的基准数据集，并为每个问题提供配套判例以支持知识独立的评估。",
        "result": "评估了30多个模型，发现其在法律推理上仍有显著差距，专门化推理模型优于通用模型。",
        "conclusion": "构建并开源了KCL基准与评估代码，促进了对大语言模型纯法律推理能力的研究。",
        "tags": [
          "Legal Reasoning",
          "Benchmark",
          "Large Language Model",
          "Evaluation Metrics"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:41:29.700724Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24497",
      "title": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?",
      "authors": [
        "Basile Terver",
        "Tsung-Yen Yang",
        "Jean Ponce",
        "Adrien Bardes",
        "Yann LeCun"
      ],
      "abstract": "A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24497.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24497",
      "published": "2025-12-30T22:50:03Z",
      "updated": "2025-12-30T22:50:03Z",
      "comment": null,
      "light_analysis": {
        "overview": "系统研究基于联合嵌入预测世界模型的规划技术，找出最优组合并提出新模型，在导航和操作任务上超越基线。",
        "motivation": "解决智能体在多样化物理任务中泛化能力的长期挑战，探究在表征空间中进行规划（JEPA-WMs）的关键成功因素。",
        "method": "将此类模型归类为JEPA-WMs，并系统性地研究模型架构、训练目标和规划算法等关键组件的影响。",
        "result": "在模拟和真实机器人数据上的实验表明，结合研究发现的模型在导航与操作任务上超越了DINO-WM和V-JEPA-2-AC基线。",
        "conclusion": "对JEPA-WM模型族进行了系统性分析，识别了成功规划的关键因素，并提出了一种表现更优的模型。",
        "tags": [
          "Joint-Embedding Predictive Architecture",
          "World Model",
          "Representation Learning",
          "Planning Algorithms",
          "Robotics"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:43:39.330329Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24411",
      "title": "AI-Driven Evaluation of Surgical Skill via Action Recognition",
      "authors": [
        "Yan Meng",
        "Daniel A. Donoho",
        "Marcelle Altshuler",
        "Omar Arnaout"
      ],
      "abstract": "The development of effective training and evaluation strategies is critical. Conventional methods for assessing surgical proficiency typically rely on expert supervision, either through onsite observation or retrospective analysis of recorded procedures. However, these approaches are inherently subjective, susceptible to inter-rater variability, and require substantial time and effort from expert surgeons. These demands are often impractical in low- and middle-income countries, thereby limiting the scalability and consistency of such methods across training programs. To address these limitations, we propose a novel AI-driven framework for the automated assessment of microanastomosis performance. The system integrates a video transformer architecture based on TimeSformer, improved with hierarchical temporal attention and weighted spatial attention mechanisms, to achieve accurate action recognition within surgical videos. Fine-grained motion features are then extracted using a YOLO-based object detection and tracking method, allowing for detailed analysis of instrument kinematics. Performance is evaluated along five aspects of microanastomosis skill, including overall action execution, motion quality during procedure-critical actions, and general instrument handling. Experimental validation using a dataset of 58 expert-annotated videos demonstrates the effectiveness of the system, achieving 87.7% frame-level accuracy in action segmentation that increased to 93.62% with post-processing, and an average classification accuracy of 76% in replicating expert assessments across all skill aspects. These findings highlight the system's potential to provide objective, consistent, and interpretable feedback, thereby enabling more standardized, data-driven training and evaluation in surgical education.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24411.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24411",
      "published": "2025-12-30T18:45:34Z",
      "updated": "2025-12-30T18:45:34Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于AI的视频动作识别框架，自动评估手术技能，实现客观、可扩展的培训评估。",
        "motivation": "传统手术技能评估依赖专家，主观性强、耗时且难以规模化，尤其在低收入国家。",
        "method": "采用改进的TimeSformer视频变换器，集成分层时间注意力和加权空间注意力进行动作识别，并使用YOLO进行目标检测跟踪提取运动特征。",
        "result": "在58个专家注释视频数据集上，动作分割准确率87.7%（后处理提升至93.62%），平均分类准确率76%复制专家评估。",
        "conclusion": "系统能提供客观、一致、可解释的反馈，促进手术教育的标准化和数据驱动培训。",
        "tags": [
          "Video Transformer",
          "Action Recognition",
          "TimeSformer",
          "YOLO",
          "Attention Mechanism"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:49:09.506689Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24324",
      "title": "Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction",
      "authors": [
        "Haojin Li",
        "Anbang Zhang",
        "Chen Sun",
        "Chenyuan Feng",
        "Kaiqian Qu",
        "Tony Q. S. Quek",
        "Haijun Zhang"
      ],
      "abstract": "The low-altitude economy (LAE) is rapidly expanding driven by urban air mobility, logistics drones, and aerial sensing, while fast and accurate beam prediction in uncrewed aerial vehicles (UAVs) communications is crucial for achieving reliable connectivity. Current research is shifting from single-signal to multi-modal collaborative approaches. However, existing multi-modal methods mostly employ fixed or empirical weights, assuming equal reliability across modalities at any given moment. Indeed, the importance of different modalities fluctuates dramatically with UAV motion scenarios, and static weighting amplifies the negative impact of degraded modalities. Furthermore, modal mismatch and weak alignment further undermine cross-scenario generalization. To this end, we propose a reliability-aware dynamic weighting scheme applied to a semantic-aware multi-modal beam prediction framework, named SaM2B. Specifically, SaM2B leverages lightweight cues such as environmental visual, flight posture, and geospatial data to adaptively allocate contributions across modalities at different time points through reliability-aware dynamic weight updates. Moreover, by utilizing cross-modal contrastive learning, we align the \"multi-source representation beam semantics\" associated with specific beam information to a shared semantic space, thereby enhancing discriminative power and robustness under modal noise and distribution shifts. Experiments on real-world low-altitude UAV datasets show that SaM2B achieves more satisfactory results than baseline methods.",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24324.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24324",
      "published": "2025-12-30T16:24:34Z",
      "updated": "2025-12-30T16:24:34Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出SaM2B框架，通过可靠性感知动态加权和跨模态对比学习提升无人机多模态波束预测性能。",
        "motivation": "现有多模态波束预测方法采用固定权重，无法适应模态可靠性动态变化，导致性能下降和泛化能力弱。",
        "method": "利用环境视觉、飞行姿态和地理空间数据，通过可靠性感知动态权重更新和跨模态对比学习进行语义对齐。",
        "result": "在真实低空无人机数据集上，SaM2B比基线方法取得了更满意的实验结果。",
        "conclusion": "SaM2B通过动态加权和语义空间对齐，增强了波束预测的鲁棒性、判别能力和跨场景泛化。",
        "tags": [
          "Multi-modal Learning",
          "Dynamic Weighting",
          "Cross-modal Contrastive Learning",
          "Beam Prediction",
          "UAV Communications"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:47:34.787408Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24259",
      "title": "Tracing the Flow of Knowledge From Science to Technology Using Deep Learning",
      "authors": [
        "Michael E. Rose",
        "Mainak Ghosh",
        "Sebastian Erhardt",
        "Cheng Li",
        "Erik Buunk",
        "Dietmar Harhoff"
      ],
      "abstract": "We develop a language similarity model suitable for working with patents and scientific publications at the same time. In a horse race-style evaluation, we subject eight language (similarity) models to predict credible Patent-Paper Citations. We find that our Pat-SPECTER model performs best, which is the SPECTER2 model fine-tuned on patents. In two real-world scenarios (separating patent-paper-pairs and predicting patent-paper-pairs) we demonstrate the capabilities of the Pat-SPECTER. We finally test the hypothesis that US patents cite papers that are semantically less similar than in other large jurisdictions, which we posit is because of the duty of candor. The model is open for the academic community and practitioners alike.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24259.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24259",
      "published": "2025-12-30T14:36:17Z",
      "updated": "2025-12-30T14:36:17Z",
      "comment": "4 tables, 7 figures",
      "light_analysis": {
        "overview": "开发了适用于专利与论文的专用语义相似度模型Pat-SPECTER，以追踪知识流动。",
        "motivation": "追踪科学发现（论文）转化为技术创新（专利）过程中的知识流动，需要一个能同时处理两类文本的模型。",
        "method": "在SPECTER2通用文档嵌入模型的基础上，使用专利数据进行微调，得到专用模型Pat-SPECTER，并进行对比评测。",
        "result": "Pat-SPECTER在预测可信的专利-论文引用任务上表现最佳，并用于实证分析不同司法辖区的引用模式差异。",
        "conclusion": "开源了Pat-SPECTER模型，为知识流动研究提供了有效工具，并初步验证了其在实际场景中的应用能力。",
        "tags": [
          "Document Embedding",
          "Patent Analysis",
          "Text Similarity",
          "Model Fine-tuning",
          "SPECTER"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:46:03.976169Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24181",
      "title": "MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring",
      "authors": [
        "Qipeng Wang",
        "Rui Sheng",
        "Yafei Li",
        "Huamin Qu",
        "Yushi Sun",
        "Min Zhu"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated significant promise in clinical diagnosis. However, current models struggle to emulate the iterative, diagnostic hypothesis-driven reasoning of real clinical scenarios. Specifically, current LLMs suffer from three critical limitations: (1) generating hallucinated medical content due to weak grounding in verified knowledge, (2) asking redundant or inefficient questions rather than discriminative ones that hinder diagnostic progress, and (3) losing coherence over multi-turn dialogues, leading to contradictory or inconsistent conclusions. To address these challenges, we propose MedKGI, a diagnostic framework grounded in clinical practices. MedKGI integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies, selects questions based on information gain to maximize diagnostic efficiency, and adopts an OSCE-format structured state to maintain consistent evidence tracking across turns. Experiments on clinical benchmarks show that MedKGI outperforms strong LLM baselines in both diagnostic accuracy and inquiry efficiency, improving dialogue efficiency by 30% on average while maintaining state-of-the-art accuracy.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24181.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24181",
      "published": "2025-12-30T12:31:53Z",
      "updated": "2025-12-30T12:31:53Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出MedKGI框架，通过集成医学知识图谱和信息增益指导，提升临床诊断的迭代推理准确性和效率。",
        "motivation": "解决当前大型语言模型在临床诊断中生成幻觉内容、提问冗余低效和多轮对话不一致的问题。",
        "method": "结合医学知识图谱约束推理，基于信息增益选择高效问题，采用OSCE格式结构化状态维持证据一致性。",
        "result": "在临床基准测试中优于基线模型，诊断准确性保持最佳，对话效率平均提高30%。",
        "conclusion": "MedKGI框架有效克服了LLMs的临床诊断局限，实现了更可靠和高效的迭代诊断推理。",
        "tags": [
          "Large Language Model",
          "Knowledge Graph",
          "Information Gain",
          "Clinical Decision Support"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:48:21.398417Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24145",
      "title": "Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators",
      "authors": [
        "Udit Sharma"
      ],
      "abstract": "Machine learning systems appear stochastic but are deterministically random, as seeded pseudorandom number generators produce identical realisations across executions. Learning-based simulators are widely used to compare algorithms, design choices, and interventions under such dynamics, yet evaluation outcomes often exhibit high variance due to random initialisation and learning stochasticity. We analyse the statistical structure of comparative evaluation in these settings and show that standard independent evaluation designs fail to exploit shared sources of randomness across alternatives. We formalise a paired seed evaluation design in which competing systems are evaluated under identical random seeds, inducing matched realisations of stochastic components and strict variance reduction whenever outcomes are positively correlated at the seed level. This yields tighter confidence intervals, higher statistical power, and effective sample size gains at fixed computational budgets. Empirically, seed-level correlations are typically large and positive, producing order-of-magnitude efficiency gains. Paired seed evaluation is weakly dominant in practice, improving statistical reliability when correlation is present and reducing to independent evaluation without loss of validity when it is not.",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24145.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24145",
      "published": "2025-12-30T11:15:04Z",
      "updated": "2025-12-30T11:15:04Z",
      "comment": "12 pages, 3 figures",
      "light_analysis": {
        "overview": "论文提出配对种子评估方法，提高基于学习的模拟器的统计可靠性。",
        "motivation": "由于随机初始化和学习随机性导致评估结果方差高，标准独立评估设计未能利用共享随机源。",
        "method": "形式化配对种子评估设计，在相同随机种子下评估竞争系统，诱导匹配随机实现。",
        "result": "实现方差减少，更紧置信区间和更高统计功效；经验上种子相关性大，带来数量级效率增益。",
        "conclusion": "配对种子评估是弱主导实践方法，提高统计可靠性，无相关性时退化为独立评估而不损失有效性。",
        "tags": [
          "Paired Seed Evaluation",
          "Statistical Reliability",
          "Variance Reduction",
          "Learning-Based Simulators"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:45:10.357588Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24064",
      "title": "Neighbor-aware Instance Refining with Noisy Labels for Cross-Modal Retrieval",
      "authors": [
        "Yizhi Liu",
        "Ruitao Pu",
        "Shilin Xu",
        "Yingke Chen",
        "Quan-Hui Liu",
        "Yuan Sun"
      ],
      "abstract": "In recent years, Cross-Modal Retrieval (CMR) has made significant progress in the field of multi-modal analysis. However, since it is time-consuming and labor-intensive to collect large-scale and well-annotated data, the annotation of multi-modal data inevitably contains some noise. This will degrade the retrieval performance of the model. To tackle the problem, numerous robust CMR methods have been developed, including robust learning paradigms, label calibration strategies, and instance selection mechanisms. Unfortunately, they often fail to simultaneously satisfy model performance ceilings, calibration reliability, and data utilization rate. To overcome the limitations, we propose a novel robust cross-modal learning framework, namely Neighbor-aware Instance Refining with Noisy Labels (NIRNL). Specifically, we first propose Cross-modal Margin Preserving (CMP) to adjust the relative distance between positive and negative pairs, thereby enhancing the discrimination between sample pairs. Then, we propose Neighbor-aware Instance Refining (NIR) to identify pure subset, hard subset, and noisy subset through cross-modal neighborhood consensus. Afterward, we construct different tailored optimization strategies for this fine-grained partitioning, thereby maximizing the utilization of all available data while mitigating error propagation. Extensive experiments on three benchmark datasets demonstrate that NIRNL achieves state-of-the-art performance, exhibiting remarkable robustness, especially under high noise rates.",
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24064.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24064",
      "published": "2025-12-30T08:19:07Z",
      "updated": "2025-12-30T08:19:07Z",
      "comment": "9 pages, 4 figures, and AAAI-26 conference",
      "light_analysis": {
        "overview": "提出NIRNL框架，通过邻居感知实例精炼处理噪声标签，提升跨模态检索的鲁棒性。",
        "motivation": "由于大规模精确标注数据难以获取，多模态数据中存在噪声标签，影响检索性能，现有方法不能同时满足性能、可靠性和数据利用率。",
        "method": "提出了NIRNL框架，包括跨模态边界保持和邻居感知实例精炼，通过邻域共识识别子集，并实施定制化优化策略。",
        "result": "在三个基准数据集上实验表明，NIRNL实现了最先进性能，尤其是在高噪声率下表现出显著鲁棒性。",
        "conclusion": "该框架能最大化数据利用率，缓解错误传播，为噪声标签下的跨模态检索提供了有效解决方案。",
        "tags": [
          "Cross-Modal Retrieval",
          "Noisy Labels",
          "Margin Preserving",
          "Neighbor-aware Refining",
          "Robust Learning"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:45:15.107447Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24022",
      "title": "FUSE-RSVLM: Feature Fusion Vision-Language Model for Remote Sensing",
      "authors": [
        "Yunkai Dang",
        "Donghao Wang",
        "Jiacheng Yang",
        "Yifan Jiang",
        "Meiyi Zhu",
        "Yuekun Yang",
        "Cong Wang",
        "Qi Fan",
        "Wenbin Li",
        "Yang Gao"
      ],
      "abstract": "Large vision-language models (VLMs) exhibit strong performance across various tasks. However, these VLMs encounter significant challenges when applied to the remote sensing domain due to the inherent differences between remote sensing images and natural images. Existing remote sensing VLMs often fail to extract fine-grained visual features and suffer from visual forgetting during deep language processing. To address this, we introduce MF-RSVLM, a Multi-Feature Fusion Remote Sensing Vision--Language Model that effectively extracts and fuses visual features for RS understanding. MF-RSVLM learns multi-scale visual representations and combines global context with local details, improving the capture of small and complex structures in RS scenes. A recurrent visual feature injection scheme ensures the language model remains grounded in visual evidence and reduces visual forgetting during generation. Extensive experiments on diverse RS benchmarks show that MF-RSVLM achieves state-of-the-art or highly competitive performance across remote sensing classification, image captioning, and VQA tasks. Our code is publicly available at https://github.com/Yunkaidang/RSVLM.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24022.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24022",
      "published": "2025-12-30T06:48:07Z",
      "updated": "2025-12-30T06:48:07Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出MF-RSVLM模型，通过多特征融合和循环视觉特征注入，解决遥感视觉-语言模型的特征提取和视觉遗忘问题。",
        "motivation": "现有视觉-语言模型在遥感领域应用时，因图像差异导致无法提取细粒度特征并出现视觉遗忘，需改进。",
        "method": "采用多尺度视觉表示学习，融合全局与局部细节，并设计循环视觉特征注入方案以减少视觉遗忘。",
        "result": "在遥感分类、图像描述和视觉问答任务上，MF-RSVLM在多个基准测试中达到最先进或高度竞争性能。",
        "conclusion": "该模型有效提升了遥感视觉-语言理解的性能，为遥感AI应用提供了新方法。",
        "tags": [
          "Vision-Language Model",
          "Remote Sensing",
          "Multi-Scale Feature Fusion",
          "Recurrent Feature Injection"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:46:45.885235Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24016",
      "title": "FitControler: Toward Fit-Aware Virtual Try-On",
      "authors": [
        "Lu Yang",
        "Yicheng Liu",
        "Yanan Li",
        "Xiang Bai",
        "Hao Lu"
      ],
      "abstract": "Realistic virtual try-on (VTON) concerns not only faithful rendering of garment details but also coordination of the style. Prior art typically pursues the former, but neglects a key factor that shapes the holistic style -- garment fit. Garment fit delineates how a garment aligns with the body of a wearer and is a fundamental element in fashion design. In this work, we introduce fit-aware VTON and present FitControler, a learnable plug-in that can seamlessly integrate into modern VTON models to enable customized fit control. To achieve this, we highlight two challenges: i) how to delineate layouts of different fits and ii) how to render the garment that matches the layout. FitControler first features a fit-aware layout generator to redraw the body-garment layout conditioned on a set of delicately processed garment-agnostic representations, and a multi-scale fit injector is then used to deliver layout cues to enable layout-driven VTON. In particular, we build a fit-aware VTON dataset termed Fit4Men, including 13,000 body-garment pairs of different fits, covering both tops and bottoms, and featuring varying camera distances and body poses. Two fit consistency metrics are also introduced to assess the fitness of generations. Extensive experiments show that FitControler can work with various VTON models and achieve accurate fit control. Code and data will be released.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24016.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24016",
      "published": "2025-12-30T06:31:19Z",
      "updated": "2025-12-30T06:31:19Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出FitControler插件，实现虚拟试穿的定制化合身度控制。",
        "motivation": "现有虚拟试穿方法忽视服装合身度对整体风格的影响，而合身度是时尚设计的关键因素。",
        "method": "FitControler包括合身度感知布局生成器和多尺度合身度注入器，基于服装无关表示重绘布局并传递线索。",
        "result": "构建Fit4Men数据集，含13,000个身体-服装对；引入合身度一致性指标；实验验证兼容多种模型并实现准确控制。",
        "conclusion": "引入合身度感知虚拟试穿，提出可集成插件FitControler，实现定制化合身度控制，提升虚拟试穿真实性。",
        "tags": [
          "Virtual Try-On",
          "Fit-Aware Layout Generation",
          "Multi-Scale Fit Injector",
          "Fit Consistency Metrics"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:47:45.991144Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23686",
      "title": "PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech",
      "authors": [
        "Deepak Babu Piskala"
      ],
      "abstract": "Automatic Speech Recognition (ASR) in professional settings faces challenges that existing benchmarks underplay: dense domain terminology, formal register variation, and near-zero tolerance for critical entity errors. We present ProfASR-Bench, a professional-talk evaluation suite for high-stakes applications across finance, medicine, legal, and technology. Each example pairs a natural-language prompt (domain cue and/or speaker profile) with an entity-rich target utterance, enabling controlled measurement of context-conditioned recognition. The corpus supports conventional ASR metrics alongside entity-aware scores and slice-wise reporting by accent and gender. Using representative families Whisper (encoder-decoder ASR) and Qwen-Omni (audio language models) under matched no-context, profile, domain+profile, oracle, and adversarial conditions, we find a consistent pattern: lightweight textual context produces little to no change in average word error rate (WER), even with oracle prompts, and adversarial prompts do not reliably degrade performance. We term this the context-utilization gap (CUG): current systems are nominally promptable yet underuse readily available side information. ProfASR-Bench provides a standardized context ladder, entity- and slice-aware reporting with confidence intervals, and a reproducible testbed for comparing fusion strategies across model families.   Dataset: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench   Code: https://github.com/prdeepakbabu/ProfASR-Bench",
      "categories": [
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23686.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23686",
      "published": "2025-12-29T18:43:23Z",
      "updated": "2025-12-29T18:43:23Z",
      "comment": "Benchmark dataset and evaluation suite. Data and code available at: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench https://github.com/prdeepakbabu/ProfASR-Bench",
      "light_analysis": {
        "overview": "提出了ProfASR-Bench基准测试，用于评估高风险专业场景下，自动语音识别系统利用上下文信息的能力。",
        "motivation": "现有基准测试低估了专业场景ASR的挑战，如密集术语、正式语体变化及对关键实体错误的零容忍。",
        "method": "构建了包含金融、医疗等领域的专业语音评估数据集，支持上下文提示，并使用Whisper和Qwen-Omni模型在不同上下文条件下测试。",
        "result": "发现当前系统存在上下文利用差距，轻量级文本上下文对词错误率改善甚微，即使提供完美提示，性能也未显著提升或降低。",
        "conclusion": "主要贡献是提供了一个标准化的、支持实体和切片分析的测试平台，用于比较不同模型利用上下文的策略。",
        "tags": [
          "Automatic Speech Recognition",
          "Encoder-Decoder",
          "Audio Language Models",
          "Benchmark Evaluation",
          "Context-Conditioned ASR"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:41:51.122320Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23647",
      "title": "Nested Browser-Use Learning for Agentic Information Seeking",
      "authors": [
        "Baixuan Li",
        "Jialong Wu",
        "Wenbiao Yin",
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Zhengwei Tao",
        "Liwen Zhang",
        "Pengjun Xie",
        "Jingren Zhou",
        "Yong Jiang"
      ],
      "abstract": "Information-seeking (IS) agents have achieved strong performance across a range of wide and deep search tasks, yet their tool use remains largely restricted to API-level snippet retrieval and URL-based page fetching, limiting access to the richer information available through real browsing. While full browser interaction could unlock deeper capabilities, its fine-grained control and verbose page content returns introduce substantial complexity for ReAct-style function-calling agents. To bridge this gap, we propose Nested Browser-Use Learning (NestBrowse), which introduces a minimal and complete browser-action framework that decouples interaction control from page exploration through a nested structure. This design simplifies agentic reasoning while enabling effective deep-web information acquisition. Empirical results on challenging deep IS benchmarks demonstrate that NestBrowse offers clear benefits in practice. Further in-depth analyses underscore its efficiency and flexibility.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23647.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23647",
      "published": "2025-12-29T17:59:14Z",
      "updated": "2025-12-29T17:59:14Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出NestBrowse框架，通过嵌套浏览器操作简化代理信息寻求，提升深度网络交互能力。",
        "motivation": "现有信息寻求代理工具使用有限，仅支持API级检索和URL获取，无法利用真实浏览的丰富信息，且完整浏览器交互复杂，需解决此问题。",
        "method": "引入嵌套浏览器使用学习（NestBrowse），一个最小完整浏览器操作框架，采用嵌套结构解耦交互控制与页面探索。",
        "result": "在挑战性深度信息寻求基准测试中，NestBrowse表现出明显优势，实证结果强调其高效灵活。",
        "conclusion": "NestBrowse简化了代理推理，实现了有效深度网络信息获取，为代理浏览器交互提供实用方案。",
        "tags": [
          "Information Seeking Agents",
          "Browser Interaction",
          "ReAct-style Agents",
          "Nested Framework",
          "Deep Web Information Acquisition"
        ],
        "relevance_score": 0.9
      },
      "analyzed_at": "2026-01-03T22:43:38.909889Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24772",
      "title": "Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection",
      "authors": [
        "Mohammad Zia Ur Rehman",
        "Velpuru Navya",
        "Sanskar",
        "Shuja Uddin Qureshi",
        "Nagendra Kumar"
      ],
      "abstract": "Detecting depression from social media text is still a challenging task. This is due to different language styles, informal expression, and the lack of annotated data in many languages. To tackle these issues, we propose, Semi-SMDNet, a strong Semi-Supervised Multilingual Depression detection Network. It combines teacher-student pseudo-labelling, ensemble learning, and augmentation of data. Our framework uses a group of teacher models. Their predictions come together through soft voting. An uncertainty-based threshold filters out low-confidence pseudo-labels to reduce noise and improve learning stability. We also use a confidence-weighted training method that focuses on reliable pseudo-labelled samples. This greatly boosts robustness across languages. Tests on Arabic, Bangla, English, and Spanish datasets show that our approach consistently beats strong baselines. It significantly reduces the performance gap between settings that have plenty of resources and those that do not. Detailed experiments and studies confirm that our framework is effective and can be used in various situations. This shows that it is suitable for scalable, cross-language mental health monitoring where labelled resources are limited.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24772.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24772",
      "published": "2025-12-31T10:35:59Z",
      "updated": "2025-12-31T10:35:59Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一个不确定性感知的半监督集成教师框架Semi-SMDNet，用于提升多语言抑郁症检测性能。",
        "motivation": "解决社交媒体抑郁症检测中面临的语言风格多样、表达非正式以及多语言标注数据稀缺的挑战。",
        "method": "结合教师-学生伪标签、集成学习与数据增强，使用软投票集成多个教师模型，并通过不确定性阈值过滤低置信度伪标签。",
        "result": "在阿拉伯语、孟加拉语、英语和西班牙语数据集上超越基线，显著缩小资源丰富与匮乏设置间的性能差距。",
        "conclusion": "框架在标注资源有限的情况下有效且通用，适用于可扩展的跨语言心理健康监测。",
        "tags": [
          "Semi-supervised Learning",
          "Ensemble Learning",
          "Pseudo-labeling",
          "Multilingual NLP",
          "Uncertainty Quantification"
        ],
        "relevance_score": 0.85
      },
      "analyzed_at": "2026-01-03T22:40:10.402626Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24686",
      "title": "BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis",
      "authors": [
        "Songqi Zhou",
        "Ruixue Liu",
        "Boman Su",
        "Jiazhou Wang",
        "Yixing Wang",
        "Benben Jiang"
      ],
      "abstract": "Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their \"black-box\" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a \"numerical-semantic\" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from \"passive detection\" to \"intelligent diagnosis\" for battery safety management.",
      "categories": [
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24686.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24686",
      "published": "2025-12-31T07:38:53Z",
      "updated": "2025-12-31T07:38:53Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出融合物理知识与大语言模型推理的层次化框架BatteryAgent，实现电池可解释故障诊断。",
        "motivation": "现有电池故障诊断深度学习方法缺乏可解释性，且受限于二分类，无法提供根因分析和维护建议。",
        "method": "提出三层框架：物理感知层提取机制特征；检测归因层使用GBDT和SHAP量化贡献；推理诊断层用LLM结合数值与语义信息生成报告。",
        "result": "有效纠正硬边界样本误分类，AUROC达0.986，显著优于SOTA方法，并将二分类扩展为多类型可解释诊断。",
        "conclusion": "为电池安全管理提供了从“被动检测”到“智能诊断”的新范式，实现了可解释的多类型故障诊断与维护建议生成。",
        "tags": [
          "Large Language Model",
          "Physics-Informed Features",
          "SHAP",
          "Gradient Boosting Decision Trees",
          "Fault Diagnosis"
        ],
        "relevance_score": 0.85
      },
      "analyzed_at": "2026-01-03T22:37:08.862544Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23440",
      "title": "ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning",
      "authors": [
        "Yuqi Tang",
        "Jing Yu",
        "Zichang Su",
        "Kehua Feng",
        "Zhihui Zhu",
        "Libin Wang",
        "Lei Liang",
        "Qiang Zhang",
        "Keyan Ding",
        "Huajun Chen"
      ],
      "abstract": "Clinical diagnosis begins with doctor-patient interaction, during which physicians iteratively gather information, determine examination and refine differential diagnosis through patients' response. This dynamic clinical-reasoning process is poorly represented by existing LLM benchmarks that focus on static question-answering. To mitigate these gaps, recent methods explore dynamic medical frameworks involving interactive clinical dialogues. Although effective, they often rely on limited, contamination-prone datasets and lack granular, multi-level evaluation. In this work, we propose ClinDEF, a dynamic framework for assessing clinical reasoning in LLMs through simulated diagnostic dialogues. Grounded in a disease knowledge graph, our method dynamically generates patient cases and facilitates multi-turn interactions between an LLM-based doctor and an automated patient agent. Our evaluation protocol goes beyond diagnostic accuracy by incorporating fine-grained efficiency analysis and rubric-based assessment of diagnostic quality. Experiments show that ClinDEF effectively exposes critical clinical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23440.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23440",
      "published": "2025-12-29T12:58:58Z",
      "updated": "2025-12-29T12:58:58Z",
      "comment": "23 pages, 4 figures, under review",
      "light_analysis": {
        "overview": "提出了ClinDEF框架，通过模拟诊断对话动态评估大语言模型在临床推理中的表现。",
        "motivation": "现有LLM基准测试缺乏动态临床推理评估，难以模拟真实医生-患者互动，需要更精确的多层次评估。",
        "method": "基于疾病知识图动态生成患者病例，模拟LLM医生与自动化患者代理的多轮交互对话进行评估。",
        "result": "框架有效暴露了顶尖LLMs的关键临床推理缺陷，提供了更细致和临床有意义的评估结果。",
        "conclusion": "ClinDEF建立了动态评估范式，能更全面评估LLMs的临床推理能力，提升医疗应用评估质量。",
        "tags": [
          "Large Language Model",
          "Clinical Reasoning",
          "Dynamic Evaluation",
          "Knowledge Graph",
          "Simulated Dialogue"
        ],
        "relevance_score": 0.85
      },
      "analyzed_at": "2026-01-03T22:49:03.541353Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24948",
      "title": "ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT",
      "authors": [
        "Xinran Gong",
        "Gorkem Durak",
        "Halil Ertugrul Aktas",
        "Vedat Cicek",
        "Jinkui Hao",
        "Ulas Bagci",
        "Nilay S. Shah",
        "Bo Zhou"
      ],
      "abstract": "Coronary artery calcium (CAC) scoring from chest CT is a well-established tool to stratify and refine clinical cardiovascular disease risk estimation. CAC quantification relies on the accurate delineation of calcified lesions, but is oftentimes affected by artifacts introduced by cardiac and respiratory motion. ECG-gated cardiac CTs substantially reduce motion artifacts, but their use in population screening and routine imaging remains limited due to gating requirements and lack of insurance coverage. Although identification of incidental CAC from non-gated chest CT is increasingly considered for it offers an accessible and widely available alternative, this modality is limited by more severe motion artifacts. We present ProDM (Property-aware Progressive Correction Diffusion Model), a generative diffusion framework that restores motion-free calcified lesions from non-gated CTs. ProDM introduces three key components: (1) a CAC motion simulation data engine that synthesizes realistic non-gated acquisitions with diverse motion trajectories directly from cardiac-gated CTs, enabling supervised training without paired data; (2) a property-aware learning strategy incorporating calcium-specific priors through a differentiable calcium consistency loss to preserve lesion integrity; and (3) a progressive correction scheme that reduces artifacts gradually across diffusion steps to enhance stability and calcium fidelity. Experiments on real patient datasets show that ProDM significantly improves CAC scoring accuracy, spatial lesion fidelity, and risk stratification performance compared with several baselines. A reader study on real non-gated scans further confirms that ProDM suppresses motion artifacts and improves clinical usability. These findings highlight the potential of progressive, property-aware frameworks for reliable CAC quantification from routine chest CT imaging.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24948.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24948",
      "published": "2025-12-31T16:29:05Z",
      "updated": "2025-12-31T16:29:05Z",
      "comment": "21 pages, 8 figures",
      "light_analysis": {
        "overview": "ProDM是一种属性感知渐进扩散模型，用于纠正非门控CT中冠状动脉钙化的运动伪影，提高评分准确性。",
        "motivation": "非门控胸部CT用于CAC评分时易受运动伪影影响，导致准确性下降；门控CT使用受限，需从非门控CT恢复无运动图像的方法。",
        "method": "提出ProDM扩散框架，包括合成数据引擎、属性感知学习策略（钙一致性损失）和渐进校正方案。",
        "result": "实验显示ProDM显著提高CAC评分准确性、空间病变保真度和风险分层性能；读者研究证实其抑制伪影并提升临床可用性。",
        "conclusion": "ProDM展示了渐进属性感知框架在从常规胸部CT进行可靠CAC量化中的潜力。",
        "tags": [
          "Diffusion Model",
          "Motion Correction",
          "Synthetic Data Generation",
          "Property-aware Learning",
          "Progressive Diffusion"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:38:12.922197Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24947",
      "title": "CPJ: Explainable Agricultural Pest Diagnosis via Caption-Prompt-Judge with LLM-Judged Refinement",
      "authors": [
        "Wentao Zhang",
        "Tao Fang",
        "Lina Lu",
        "Lifei Wang",
        "Weihe Zhong"
      ],
      "abstract": "Accurate and interpretable crop disease diagnosis is essential for agricultural decision-making, yet existing methods often rely on costly supervised fine-tuning and perform poorly under domain shifts. We propose Caption--Prompt--Judge (CPJ), a training-free few-shot framework that enhances Agri-Pest VQA through structured, interpretable image captions. CPJ employs large vision-language models to generate multi-angle captions, refined iteratively via an LLM-as-Judge module, which then inform a dual-answer VQA process for both recognition and management responses. Evaluated on CDDMBench, CPJ significantly improves performance: using GPT-5-mini captions, GPT-5-Nano achieves \\textbf{+22.7} pp in disease classification and \\textbf{+19.5} points in QA score over no-caption baselines. The framework provides transparent, evidence-based reasoning, advancing robust and explainable agricultural diagnosis without fine-tuning. Our code and data are publicly available at: https://github.com/CPJ-Agricultural/CPJ-Agricultural-Diagnosis.",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24947.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24947",
      "published": "2025-12-31T16:21:31Z",
      "updated": "2025-12-31T16:21:31Z",
      "comment": "This paper is 6 pages in length and contains 2 figures. Tao Fang (Corresponding Author), Lina Lu (Co-corresponding Author)",
      "light_analysis": {
        "overview": "提出CPJ框架，通过大视觉语言模型生成结构化字幕和LLM判断优化，无需训练地提升农业病虫害诊断的可解释性和性能。",
        "motivation": "现有农业病虫害诊断方法依赖昂贵监督微调，且领域转移时表现差，需要准确可解释的解决方案。",
        "method": "采用Caption-Prompt-Judge框架，使用大视觉语言模型生成多角度图像字幕，通过LLM-as-Judge模块迭代优化，驱动双答案VQA过程。",
        "result": "在CDDMBench上评估，使用GPT-5-mini字幕时，GPT-5-Nano在疾病分类提升22.7个百分点，QA分数提升19.5点，优于无字幕基线。",
        "conclusion": "CPJ提供透明、基于证据的推理，推进了无需微调的稳健可解释农业诊断，代码和数据公开。",
        "tags": [
          "Large Vision-Language Model",
          "LLM-as-Judge",
          "Few-Shot Learning",
          "Visual Question Answering",
          "Explainable AI"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:38:27.957746Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24901",
      "title": "Spectral Graph Neural Networks for Cognitive Task Classification in fMRI Connectomes",
      "authors": [
        "Debasis Maji",
        "Arghya Banerjee",
        "Debaditya Barman"
      ],
      "abstract": "Cognitive task classification using machine learning plays a central role in decoding brain states from neuroimaging data. By integrating machine learning with brain network analysis, complex connectivity patterns can be extracted from functional magnetic resonance imaging connectomes. This process transforms raw blood-oxygen-level-dependent (BOLD) signals into interpretable representations of cognitive processes. Graph neural networks (GNNs) further advance this paradigm by modeling brain regions as nodes and functional connections as edges, capturing topological dependencies and multi-scale interactions that are often missed by conventional approaches. Our proposed SpectralBrainGNN model, a spectral convolution framework based on graph Fourier transforms (GFT) computed via normalized Laplacian eigendecomposition. Experiments on the Human Connectome Project-Task (HCPTask) dataset demonstrate the effectiveness of the proposed approach, achieving a classification accuracy of 96.25\\%. The implementation is publicly available at https://github.com/gnnplayground/SpectralBrainGNN to support reproducibility and future research.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24901.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24901",
      "published": "2025-12-31T14:54:06Z",
      "updated": "2025-12-31T14:54:06Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出一种基于图傅里叶变换的图神经网络模型，用于从fMRI脑网络数据中分类认知任务，并取得高准确率。",
        "motivation": "为了从神经影像数据中解码大脑状态，需要机器学习方法从功能连接组中提取复杂的、传统方法可能忽略的拓扑连接模式。",
        "method": "提出了SpectralBrainGNN模型，这是一个基于图傅里叶变换（通过归一化拉普拉斯特征分解计算）的光谱卷积框架。",
        "result": "在Human Connectome Project-Task数据集上实现了96.25%的分类准确率，并开源了代码以支持可复现性。",
        "conclusion": "该光谱图神经网络框架能有效捕捉脑网络的多尺度交互与拓扑依赖，为基于连接组的认知任务解码提供了有力工具。",
        "tags": [
          "Graph Neural Networks",
          "Spectral Convolution",
          "Graph Fourier Transform",
          "fMRI Connectomes",
          "Cognitive Task Classification"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:50:27.407788Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24896",
      "title": "Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing",
      "authors": [
        "Andrii Gamalii",
        "Daniel Górniak",
        "Robert Nowak",
        "Bartłomiej Olber",
        "Krystian Radlak",
        "Jakub Winter"
      ],
      "abstract": "This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24896.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24896",
      "published": "2025-12-31T14:43:48Z",
      "updated": "2025-12-31T14:43:48Z",
      "comment": null,
      "light_analysis": {
        "overview": "设计了一个半自动数据标注流程，用于加速自动驾驶多模态数据集的准备。",
        "motivation": "手动标注异构驾驶数据成本高、耗时，需降低标注负担。",
        "method": "采用人机协同方法，基于3D物体检测算法生成初始标注，结合迭代重训练和匿名化技术。",
        "result": "大幅节省时间，确保跨传感器模态的一致、高质量标注。",
        "conclusion": "该工具加速了大规模标注数据集的创建，支持自动驾驶研究的技术基础。",
        "tags": [
          "Semi-Automated Annotation",
          "Human-in-the-Loop",
          "3D Object Detection",
          "Data Anonymization",
          "Domain Adaptation"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:47:11.767114Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24863",
      "title": "Big AI is accelerating the metacrisis: What can we do?",
      "authors": [
        "Steven Bird"
      ],
      "abstract": "The world is in the grip of ecological, meaning, and language crises which are converging into a metacrisis. Big AI is accelerating them all. Language engineers are playing a central role, persisting with a scalability story that is failing humanity, supplying critical talent to plutocrats and kleptocrats, and creating new technologies as if the whole endeavour was value-free. We urgently need to explore alternatives, applying our collective intelligence to design a life-affirming future for NLP that is centered on human flourishing on a living planet.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24863.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24863",
      "published": "2025-12-31T13:49:56Z",
      "updated": "2025-12-31T13:49:56Z",
      "comment": "9 pages, 1 figure",
      "light_analysis": {
        "overview": "论文批判大AI加速元危机，并呼吁设计一个以人类繁荣为中心的NLP未来。",
        "motivation": "世界正面临生态、意义和语言危机，大AI加速了这些危机，需要探索替代方案以促进人类繁荣。",
        "method": "未明确说明",
        "result": "未明确说明",
        "conclusion": "论文呼吁语言工程师探索替代方案，共同设计一个肯定生命的NLP未来。",
        "tags": [
          "Big AI",
          "Natural Language Processing",
          "AI Ethics",
          "Scalability"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:49:01.751098Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24853",
      "title": "A study on constraint extraction and exception exclusion in care worker scheduling",
      "authors": [
        "Koki Suenaga",
        "Tomohiro Furuta",
        "Satoshi Ono"
      ],
      "abstract": "Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24853.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24853",
      "published": "2025-12-31T13:22:50Z",
      "updated": "2025-12-31T13:22:50Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于约束模板和异常排除机制的护理人员排班约束提取方法。",
        "motivation": "解决长期护理机构排班条件各异、需人工访谈设计约束的问题，实现自动化约束提取。",
        "method": "使用约束模板提取班次模式和员工组合等约束，并加入异常排除机制，通过约束编程求解器生成排班。",
        "result": "实验成功创建满足所有硬约束的排班，并通过避免异常约束提取减少了软约束违反数量。",
        "conclusion": "贡献在于提出了一种能有效提取约束并排除异常的方法，提高了排班生成的效率和准确性。",
        "tags": [
          "Constraint Programming",
          "Constraint Extraction",
          "Exception Exclusion",
          "Scheduling Optimization"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:49:03.488875Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24847",
      "title": "AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference",
      "authors": [
        "Linhao Fan",
        "Hongqiang Fang",
        "Jingyang Dai",
        "Yong Jiang",
        "Qixing Zhang"
      ],
      "abstract": "High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty quantification.To address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.",
      "categories": [
        "cs.LG",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24847.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24847",
      "published": "2025-12-31T13:16:10Z",
      "updated": "2025-12-31T13:16:10Z",
      "comment": "17 pages, 9 figures",
      "light_analysis": {
        "overview": "提出AODDiff，一种基于扩散贝叶斯推断的概率框架，用于重建气溶胶光学深度场，支持灵活任务适应和不确定性量化。",
        "motivation": "解决气溶胶光学深度场重建中完整训练数据稀缺和缺乏不确定性量化的问题。",
        "method": "采用扩散贝叶斯推断框架，包括corruption-aware训练策略学习时空先验，和解耦退火后验采样策略集成观测约束。",
        "result": "在降尺度和修复任务中验证了有效性和鲁棒性，保持高空间谱保真度，并通过多重采样实现不确定性量化。",
        "conclusion": "AODDiff框架能灵活适应多种重建任务无需再训练，并提供不确定性量化，对大气监测下游应用有重要价值。",
        "tags": [
          "Diffusion Models",
          "Bayesian Inference",
          "Generative Models",
          "Uncertainty Quantification",
          "Spatiotemporal Modeling"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:37:00.684313Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24829",
      "title": "Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences",
      "authors": [
        "Emmanuel Fashae",
        "Michael Burke",
        "Leimin Tian",
        "Lingheng Meng",
        "Pamela Carreno-Medrano"
      ],
      "abstract": "Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24829.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24829",
      "published": "2025-12-31T12:46:05Z",
      "updated": "2025-12-31T12:46:05Z",
      "comment": "Accepted to the 2026 ACM/IEEE International Conference on Human-Robot Interaction (HRI '26)",
      "light_analysis": {
        "overview": "提出四个可解释的家庭物品摆放偏好构念，并将其集成到机器人规划器中以生成符合人类偏好的布局。",
        "motivation": "解决现有基于隐式偏好模型的机器人系统对人类决策因素解释性不足的问题。",
        "method": "设计并验证了基于四个可解释构念的问卷，随后将其整合到蒙特卡洛树搜索（MCTS）规划器中。",
        "result": "问卷研究验证了构念的有效性；集成构念的规划器能生成与人类参与者偏好高度一致的物品布局。",
        "conclusion": "贡献了一个紧凑、可解释的物品摆放偏好框架，并演示了其在实际机器人任务规划中的可操作性。",
        "tags": [
          "Interpretable AI",
          "Human Preference Modeling",
          "Monte Carlo Tree Search",
          "Robot Planning",
          "Human-Robot Interaction"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:50:04.915282Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24825",
      "title": "Practising responsibility: Ethics in NLP as a hands-on course",
      "authors": [
        "Malvina Nissim",
        "Viviana Patti",
        "Beatrice Savoldi"
      ],
      "abstract": "As Natural Language Processing (NLP) systems become more pervasive, integrating ethical considerations into NLP education has become essential. However, this presents inherent challenges in curriculum development: the field's rapid evolution from both academia and industry, and the need to foster critical thinking beyond traditional technical training. We introduce our course on Ethical Aspects in NLP and our pedagogical approach, grounded in active learning through interactive sessions, hands-on activities, and \"learning by teaching\" methods. Over four years, the course has been refined and adapted across different institutions, educational levels, and interdisciplinary backgrounds; it has also yielded many reusable products, both in the form of teaching materials and in the form of actual educational products aimed at diverse audiences, made by the students themselves. By sharing our approach and experience, we hope to provide inspiration for educators seeking to incorporate social impact considerations into their curricula.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24825.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24825",
      "published": "2025-12-31T12:26:20Z",
      "updated": "2025-12-31T12:26:20Z",
      "comment": null,
      "light_analysis": {
        "overview": "设计并实施了一个融合动手实践与主动学习的NLP伦理课程，并分享了相关经验。",
        "motivation": "为解决NLP伦理教育融入课程面临的挑战，如领域快速变化和培养批判性思维的需求。",
        "method": "采用基于主动学习的教学法，包括互动环节、实践活动和“教学相长”的方法。",
        "result": "课程经过四年迭代，适应了不同机构与背景，并产生了可复用的教学材料和实际教育产品。",
        "conclusion": "分享课程设计与实践经验，旨在启发其他教育者将伦理与社会影响考量整合到教学中去。",
        "tags": [
          "NLP Ethics",
          "Active Learning",
          "Hands-on Learning",
          "Learning by Teaching",
          "Curriculum Design"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:50:52.719278Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24733",
      "title": "BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature",
      "authors": [
        "Sibo Wei",
        "Peng Chen",
        "Lifeng Dong",
        "Yin Luo",
        "Lei Wang",
        "Peng Zhang",
        "Wenpeng Lu",
        "Jianbin Guo",
        "Hongjun Yang",
        "Dajun Zeng"
      ],
      "abstract": "Multi-omics studies often rely on pathway enrichment to interpret heterogeneous molecular changes, but pathway enrichment (PE)-based workflows inherit structural limitations of pathway resources, including curation lag, functional redundancy, and limited sensitivity to molecular states and interventions. Although recent work has explored using large language models (LLMs) to improve PE-based interpretation, the lack of a standardized benchmark for end-to-end multi-omics pathway mechanism elucidation has largely confined evaluation to small, manually curated datasets or ad hoc case studies, hindering reproducible progress. To address this issue, we introduce BIOME-Bench, constructed via a rigorous four-stage workflow, to evaluate two core capabilities of LLMs in multi-omics analysis: Biomolecular Interaction Inference and end-to-end Multi-Omics Pathway Mechanism Elucidation. We develop evaluation protocols for both tasks and conduct comprehensive experiments across multiple strong contemporary models. Experimental results demonstrate that existing models still exhibit substantial deficiencies in multi-omics analysis, struggling to reliably distinguish fine-grained biomolecular relation types and to generate faithful, robust pathway-level mechanistic explanations.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24733.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24733",
      "published": "2025-12-31T09:01:27Z",
      "updated": "2025-12-31T09:01:27Z",
      "comment": null,
      "light_analysis": {
        "overview": "为评估大语言模型在多组学分析中的核心能力，提出了BIOME-Bench基准测试。",
        "motivation": "现有基于通路富集的多组学分析存在局限，且缺乏标准基准来评估大语言模型在端到端通路机制阐明方面的性能。",
        "method": "通过四阶段工作流程构建了BIOME-Bench基准，包含两个核心任务，并针对多个主流大语言模型设计了评估协议。",
        "result": "实验表明，现有模型在区分细粒度生物分子关系类型和生成忠实、鲁棒的通路级解释方面仍存在显著不足。",
        "conclusion": "创建了首个用于评估大语言模型进行生物分子相互作用推理与多组学通路阐明的标准化基准，揭示了现有模型的缺陷。",
        "tags": [
          "Multi-omics Analysis",
          "Biomolecular Interaction Inference",
          "Large Language Models",
          "Benchmark Evaluation",
          "Pathway Mechanism Elucidation"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:40:19.859212Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24679",
      "title": "Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions",
      "authors": [
        "Pengcheng Xia",
        "Yixiang Huang",
        "Chengjin Qin",
        "Chengliang Liu"
      ],
      "abstract": "Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24679.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24679",
      "published": "2025-12-31T07:10:32Z",
      "updated": "2025-12-31T07:10:32Z",
      "comment": "21 pages, 8 figures",
      "light_analysis": {
        "overview": "提出双重解耦多模态跨域混合融合模型，提升故障诊断在未见工况下的泛化能力。",
        "motivation": "现有故障诊断方法在未见工作条件下性能下降，域适应方法依赖目标域样本，且忽视多模态信息的互补性。",
        "method": "开发双重解耦框架分离模态与域的不变/特定特征，设计跨域混合融合策略及三元模态自适应融合机制。",
        "result": "在感应电机故障诊断的未见工况实验中，性能优于先进方法，消融实验验证了各组件及多模态融合的有效性。",
        "conclusion": "通过解耦和融合多模态跨域信息，实现了对未见工作条件下故障诊断的更鲁棒域泛化。",
        "tags": [
          "Domain Generalization",
          "Multi-modal Fusion",
          "Feature Disentanglement",
          "Fault Diagnosis",
          "Cross-domain Adaptation"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:37:42.064449Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24643",
      "title": "A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling",
      "authors": [
        "Malikussaid",
        "Septian Caesar Floresko",
        "Ade Romadhony",
        "Isman Kurniawan",
        "Warih Maharani",
        "Hilal Hudan Nuha"
      ],
      "abstract": "This study presents a large-scale predictive modeling framework for logP prediction using 426850 bioactive compounds rigorously curated from the intersection of three authoritative chemical databases: PubChem, ChEMBL, and eMolecules. We developed a novel computational infrastructure to address the data integration challenge, reducing processing time from a projected over 100 days to 3.2 hours through byte-offset indexing architecture, a 740-fold improvement. Our comprehensive analysis revealed critical insights into the multivariate nature of lipophilicity: while molecular weight exhibited weak bivariate correlation with logP, SHAP analysis on ensemble models identified it as the single most important predictor globally. We systematically evaluated multiple modeling approaches, discovering that linear models suffered from inherent heteroskedasticity that classical remediation strategies, including weighted least squares and Box-Cox transformation, failed to address. Tree-based ensemble methods, including Random Forest and XGBoost, proved inherently robust to this violation, achieving an R-squared of 0.765 and RMSE of 0.731 logP units on the test set. Furthermore, a stratified modeling strategy, employing specialized models for drug-like molecules (91 percent of dataset) and extreme cases (nine percent), achieved optimal performance: an RMSE of 0.838 for the drug-like subset and an R-squared of 0.767 for extreme molecules, the highest of all evaluated approaches. These findings provide actionable guidance for molecular design, establish robust baselines for lipophilicity prediction using only 2D descriptors, and demonstrate that well-curated, descriptor-based ensemble models remain competitive with state-of-the-art graph neural network architectures.",
      "categories": [
        "cs.LG",
        "cs.CE",
        "cs.DB",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24643.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24643",
      "published": "2025-12-31T05:32:13Z",
      "updated": "2025-12-31T05:32:13Z",
      "comment": "18 pages, 15 figures, 4 equations, 2 algorithms, 6 tables, to be published in KST 2026, unabridged version",
      "light_analysis": {
        "overview": "提出了一个可扩展的logP预测框架，通过高效数据集成和可解释集成建模实现高性能预测。",
        "motivation": "解决大规模化学数据集成和logP预测挑战，建立稳健基线模型，为分子设计提供指导。",
        "method": "采用字节偏移索引架构进行数据集成，使用树基集成方法如Random Forest和XGBoost，结合SHAP分析和分层建模策略。",
        "result": "测试集R平方0.765，RMSE 0.731；分层建模后药物样分子RMSE 0.838，极端分子R平方0.767；数据集成效率提升740倍。",
        "conclusion": "为分子设计提供实用指导，建立了仅使用2D描述符的稳健基线模型，证明集成模型与先进图神经网络竞争。",
        "tags": [
          "Data Integration",
          "Ensemble Modeling",
          "Random Forest",
          "XGBoost",
          "SHAP Analysis"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:40:49.691707Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24622",
      "title": "FireRescue: A UAV-Based Dataset and Enhanced YOLO Model for Object Detection in Fire Rescue Scenes",
      "authors": [
        "Qingyu Xu",
        "Runtong Zhang",
        "Zihuan Qiu",
        "Fanman Meng"
      ],
      "abstract": "Object detection in fire rescue scenarios is importance for command and decision-making in firefighting operations. However, existing research still suffers from two main limitations. First, current work predominantly focuses on environments such as mountainous or forest areas, while paying insufficient attention to urban rescue scenes, which are more frequent and structurally complex. Second, existing detection systems include a limited number of classes, such as flames and smoke, and lack a comprehensive system covering key targets crucial for command decisions, such as fire trucks and firefighters. To address the above issues, this paper first constructs a new dataset named \"FireRescue\" for rescue command, which covers multiple rescue scenarios, including urban, mountainous, forest, and water areas, and contains eight key categories such as fire trucks and firefighters, with a total of 15,980 images and 32,000 bounding boxes. Secondly, to tackle the problems of inter-class confusion and missed detection of small targets caused by chaotic scenes, diverse targets, and long-distance shooting, this paper proposes an improved model named FRS-YOLO. On the one hand, the model introduces a plug-and-play multidi-mensional collaborative enhancement attention module, which enhances the discriminative representation of easily confused categories (e.g., fire trucks vs. ordinary trucks) through cross-dimensional feature interaction. On the other hand, it integrates a dynamic feature sampler to strengthen high-response foreground features, thereby mitigating the effects of smoke occlusion and background interference. Experimental results demonstrate that object detection in fire rescue scenarios is highly challenging, and the proposed method effectively improves the detection performance of YOLO series models in this context.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24622.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24622",
      "published": "2025-12-31T04:37:51Z",
      "updated": "2025-12-31T04:37:51Z",
      "comment": null,
      "light_analysis": {
        "overview": "构建了用于火灾救援场景的无人机数据集，并提出了改进的YOLO模型以提升目标检测性能。",
        "motivation": "解决现有研究对复杂城市救援场景关注不足，以及检测类别（如消防车、消防员）覆盖不全面的问题。",
        "method": "构建了FireRescue数据集；提出了FRS-YOLO模型，引入了多维协同增强注意力模块和动态特征采样器。",
        "result": "实验表明该场景检测挑战性高，所提方法有效提升了YOLO系列模型在此场景下的检测性能。",
        "conclusion": "贡献在于发布了全面的火灾救援数据集，并提出针对性模型改进，有助于消防救援指挥决策。",
        "tags": [
          "Object Detection",
          "YOLO",
          "Attention Mechanism",
          "Computer Vision",
          "Drone Vision"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:42:41.454977Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24547",
      "title": "Hierarchical Vector-Quantized Latents for Perceptual Low-Resolution Video Compression",
      "authors": [
        "Manikanta Kotthapalli",
        "Banafsheh Rekabdar"
      ],
      "abstract": "The exponential growth of video traffic has placed increasing demands on bandwidth and storage infrastructure, particularly for content delivery networks (CDNs) and edge devices. While traditional video codecs like H.264 and HEVC achieve high compression ratios, they are designed primarily for pixel-domain reconstruction and lack native support for machine learning-centric latent representations, limiting their integration into deep learning pipelines. In this work, we present a Multi-Scale Vector Quantized Variational Autoencoder (MS-VQ-VAE) designed to generate compact, high-fidelity latent representations of low-resolution video, suitable for efficient storage, transmission, and client-side decoding. Our architecture extends the VQ-VAE-2 framework to a spatiotemporal setting, introducing a two-level hierarchical latent structure built with 3D residual convolutions. The model is lightweight (approximately 18.5M parameters) and optimized for 64x64 resolution video clips, making it appropriate for deployment on edge devices with constrained compute and memory resources. To improve perceptual reconstruction quality, we incorporate a perceptual loss derived from a pre-trained VGG16 network. Trained on the UCF101 dataset using 2-second video clips (32 frames at 16 FPS), on the test set we achieve 25.96 dB PSNR and 0.8375 SSIM. On validation, our model improves over the single-scale baseline by 1.41 dB PSNR and 0.0248 SSIM. The proposed framework is well-suited for scalable video compression in bandwidth-sensitive scenarios, including real-time streaming, mobile video analytics, and CDN-level storage optimization.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24547.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24547",
      "published": "2025-12-31T01:07:17Z",
      "updated": "2025-12-31T01:07:17Z",
      "comment": "11 pages",
      "light_analysis": {
        "overview": "提出了一个多尺度向量量化变分自编码器，用于低分辨率视频的感知压缩。",
        "motivation": "视频流量增长对带宽和存储的需求增加，传统编解码器缺乏对机器学习潜在表示的支持，限制了深度学习管道的集成。",
        "method": "扩展VQ-VAE-2到时空设置，引入基于3D残差卷积的两层分层潜在结构，并融入预训练VGG16的感知损失。",
        "result": "在UCF101数据集测试集上达到25.96 dB PSNR和0.8375 SSIM，验证集上比基线提高1.41 dB PSNR和0.0248 SSIM。",
        "conclusion": "该框架适用于带宽敏感场景，如实时流媒体和移动视频分析，支持高效存储和传输。",
        "tags": [
          "Vector Quantized Variational Autoencoder",
          "3D Residual Convolutions",
          "Perceptual Loss",
          "Video Compression"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:47:31.516483Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24463",
      "title": "Spectral and Spatial Graph Learning for Multispectral Solar Image Compression",
      "authors": [
        "Prasiddha Siwakoti",
        "Atefeh Khoshkhahtinat",
        "Piyush M. Mehta",
        "Barbara J. Thompson",
        "Michael S. F. Kirk",
        "Daniel da Silva"
      ],
      "abstract": "High-fidelity compression of multispectral solar imagery remains challenging for space missions, where limited bandwidth must be balanced against preserving fine spectral and spatial details. We present a learned image compression framework tailored to solar observations, leveraging two complementary modules: (1) the Inter-Spectral Windowed Graph Embedding (iSWGE), which explicitly models inter-band relationships by representing spectral channels as graph nodes with learned edge features; and (2) the Windowed Spatial Graph Attention and Convolutional Block Attention (WSGA-C), which combines sparse graph attention with convolutional attention to reduce spatial redundancy and emphasize fine-scale structures. Evaluations on the SDOML dataset across six extreme ultraviolet (EUV) channels show that our approach achieves a 20.15%reduction in Mean Spectral Information Divergence (MSID), up to 1.09% PSNR improvement, and a 1.62% log transformed MS-SSIM gain over strong learned baselines, delivering sharper and spectrally faithful reconstructions at comparable bits-per-pixel rates. The code is publicly available at https://github.com/agyat4/sgraph .",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24463.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24463",
      "published": "2025-12-30T20:54:43Z",
      "updated": "2025-12-30T20:54:43Z",
      "comment": "8 pages, 6 figures 1 table. Code available at https://github.com/agyat4/sgraph",
      "light_analysis": {
        "overview": "提出一种结合图学习的光谱和空间压缩方法，显著提升多光谱太阳图像压缩质量。",
        "motivation": "解决太空任务中多光谱太阳图像在有限带宽下实现高保真压缩的挑战。",
        "method": "采用Inter-Spectral Windowed Graph Embedding建模光谱关系，Windowed Spatial Graph Attention与Convolutional Block Attention结合减少空间冗余。",
        "result": "在SDOML数据集上，相比基线MSID减少20.15%，PSNR提高1.09%，MS-SSIM增益1.62%，重建更清晰。",
        "conclusion": "该学习压缩框架有效提升了多光谱太阳图像的压缩性能，具有实用价值。",
        "tags": [
          "Graph Learning",
          "Learned Image Compression",
          "Graph Attention",
          "Convolutional Attention",
          "Multispectral Imaging"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:48:24.065845Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24460",
      "title": "IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback",
      "authors": [
        "Titas Ramancauskas",
        "Kotryna Ramancauske"
      ],
      "abstract": "This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback.   Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative $R^2$ values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive $R^2$. This enabled Cycle 5's adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen's d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.",
      "categories": [
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24460.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24460",
      "published": "2025-12-30T20:49:43Z",
      "updated": "2025-12-30T20:49:43Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出基于设计研究迭代优化的雅思写作平台，结合自动化评分和自适应反馈，有效提升考生成绩。",
        "motivation": "解决传统雅思备考方法缺乏针对评分标准(rubric)的个性化反馈问题。",
        "method": "采用基于设计研究的迭代开发，从规则系统升级为使用带回归头的DistilBERT模型进行评分，并实现自适应反馈。",
        "result": "最终模型将MAE降至0.66，自适应反馈使写作分数平均显著提高0.06分（p=0.011）。",
        "conclusion": "自动反馈可作为人工指导的有效补充，在雅思备考中，保守的表面修正比激进的结构干预更可靠。",
        "tags": [
          "Automated Essay Scoring",
          "Transformer Models",
          "Adaptive Feedback",
          "Design-Based Research",
          "DistilBERT"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:42:57.967230Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24459",
      "title": "Cleaning English Abstracts of Scientific Publications",
      "authors": [
        "Michael E. Rose",
        "Nils A. Herrmann",
        "Sebastian Erhardt"
      ],
      "abstract": "Scientific abstracts are often used as proxies for the content and thematic focus of research publications. However, a significant share of published abstracts contains extraneous information-such as publisher copyright statements, section headings, author notes, registrations, and bibliometric or bibliographic metadata-that can distort downstream analyses, particularly those involving document similarity or textual embeddings. We introduce an open-source, easy-to-integrate language model designed to clean English-language scientific abstracts by automatically identifying and removing such clutter. We demonstrate that our model is both conservative and precise, alters similarity rankings of cleaned abstracts and improves information content of standard-length embeddings.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24459.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24459",
      "published": "2025-12-30T20:45:50Z",
      "updated": "2025-12-30T20:45:50Z",
      "comment": "2 tables, 2 figures",
      "light_analysis": {
        "overview": "开发一个开源语言模型，自动清理科学论文摘要中的无关信息，以提升下游分析质量。",
        "motivation": "科学摘要常被用作研究内容代理，但许多摘要包含无关信息（如版权声明、元数据等），可能扭曲文档相似性或文本嵌入等下游分析。",
        "method": "提出一个开源、易于集成的语言模型，用于自动识别和移除英文科学摘要中的无关信息。",
        "result": "模型表现保守且精确，能改变清理后摘要的相似性排名，并改进标准长度嵌入的信息内容。",
        "conclusion": "主要贡献是提供了一个工具，用于清洁科学摘要，从而提高基于摘要的分析任务的准确性和信息含量。",
        "tags": [
          "Language Model",
          "Document Similarity",
          "Textual Embeddings",
          "Data Cleaning"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:43:50.963450Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24446",
      "title": "Generative forecasting with joint probability models",
      "authors": [
        "Patrick Wyrod",
        "Ashesh Chattopadhyay",
        "Daniele Venturi"
      ],
      "abstract": "Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most existing approaches focus on next-step conditional prediction rather than the structure of the underlying dynamics. In this work, we reframe forecasting as a fully generative problem by learning the joint probability distribution of lagged system states over short temporal windows and obtaining forecasts through marginalization. This new perspective allows the model to capture nonlinear temporal dependencies, represent multistep trajectory segments, and produce next-step predictions consistent with the learned joint distribution. We also introduce a general, model-agnostic training and inference framework for joint generative forecasting and show how it enables assessment of forecast robustness and reliability using three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, and cumulative Wasserstein drift), without access to ground truth. We evaluate the performance of the proposed method on two canonical chaotic dynamical systems, the Lorenz-63 system and the Kuramoto-Sivashinsky equation, and show that joint generative models yield improved short-term predictive skill, preserve attractor geometry, and achieve substantially more accurate long-range statistical behaviour than conventional conditional next-step models.",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24446.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24446",
      "published": "2025-12-30T20:00:09Z",
      "updated": "2025-12-30T20:00:09Z",
      "comment": "18 pages, 11 figures",
      "light_analysis": {
        "overview": "提出基于联合概率模型的生成预测方法，改善混沌动力系统的预测性能和不确定性量化。",
        "motivation": "混沌动力系统的确定性预测因敏感性和多尺度过程而有限；现有生成模型过于关注下一步预测，忽略动态结构，需发展更可靠的预测框架。",
        "method": "将预测重构为生成问题，学习短时间窗口内滞后系统状态的联合概率分布，通过边际化获得预测，并引入模型无关训练框架和三种不确定性量化指标。",
        "result": "在 Lorenz-63 和 Kuramoto-Sivashinsky 系统上评估，联合生成模型在短期预测技能、吸引子几何保持和长期统计行为上优于传统条件模型。",
        "conclusion": "该方法能捕获非线性时间依赖，提供更准确可靠的预测，并支持无需真实数据的不确定性评估，对动力系统预测有重要改进。",
        "tags": [
          "Generative Models",
          "Joint Probability Models",
          "Uncertainty Quantification",
          "Ensemble Methods",
          "Wasserstein Distance"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:42:32.330799Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24386",
      "title": "RedunCut: Measurement-Driven Sampling and Accuracy Performance Modeling for Low-Cost Live Video Analytics",
      "authors": [
        "Gur-Eyal Sela",
        "Kumar Krishna Agrawal",
        "Bharathan Balaji",
        "Joseph Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Live video analytics (LVA) runs continuously across massive camera fleets, but inference cost with modern vision models remains high. To address this, dynamic model size selection (DMSS) is an attractive approach: it is content-aware but treats models as black boxes, and could potentially reduce cost by up to 10x without model retraining or modification. Without ground truth labels at runtime, we observe that DMSS methods use two stages per segment: (i) sampling a few models to calculate prediction statistics (e.g., confidences), then (ii) selection of the model size from those statistics. Prior systems fail to generalize to diverse workloads, particularly to mobile videos and lower accuracy targets. We identify that the failure modes stem from inefficient sampling whose cost exceeds its benefit, and inaccurate per-segment accuracy prediction.   In this work, we present RedunCut, a new DMSS system that addresses both: It uses a measurement-driven planner that estimates the cost-benefit tradeoff of sampling, and a lightweight, data-driven performance model to improve accuracy prediction. Across road-vehicle, drone, and surveillance videos and multiple model families and tasks, RedunCut reduces compute cost by 14-62% at fixed accuracy and remains robust to limited historical data and to drift.",
      "categories": [
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24386.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24386",
      "published": "2025-12-30T18:01:17Z",
      "updated": "2025-12-30T18:01:17Z",
      "comment": "21 pages, 23 figures",
      "light_analysis": {
        "overview": "论文提出RedunCut系统，通过测量驱动的采样和性能建模降低实时视频分析的计算成本。",
        "motivation": "解决实时视频分析中高推理成本问题，现有动态模型大小选择方法采样效率低、准确性预测差，难以适应多样化负载。",
        "method": "使用测量驱动的规划器估计采样成本效益权衡，并采用轻量级数据驱动性能模型来改进准确性预测。",
        "result": "在多种视频和模型任务中，RedunCut在固定精度下将计算成本降低14-62%，并对有限历史数据和漂移保持稳健。",
        "conclusion": "RedunCut系统解决了采样效率和准确性预测问题，提高了实时视频分析的成本效益和鲁棒性。",
        "tags": [
          "Live Video Analytics",
          "Dynamic Model Selection",
          "Measurement-Driven Sampling",
          "Performance Modeling"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:50:18.997629Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24340",
      "title": "DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images",
      "authors": [
        "Wen-wai Yim",
        "Yujuan Fu",
        "Asma Ben Abacha",
        "Meliha Yetisgen",
        "Noel Codella",
        "Roberto Andres Novoa",
        "Josep Malvehy"
      ],
      "abstract": "Recent advances in dermatological image analysis have been driven by large-scale annotated datasets; however, most existing benchmarks focus on dermatoscopic images and lack patient-authored queries and clinical context, limiting their applicability to patient-centered care. To address this gap, we introduce DermaVQA-DAS, an extension of the DermaVQA dataset that supports two complementary tasks: closed-ended question answering (QA) and dermatological lesion segmentation. Central to this work is the Dermatology Assessment Schema (DAS), a novel expert-developed framework that systematically captures clinically meaningful dermatological features in a structured and standardized form. DAS comprises 36 high-level and 27 fine-grained assessment questions, with multiple-choice options in English and Chinese. Leveraging DAS, we provide expert-annotated datasets for both closed QA and segmentation and benchmark state-of-the-art multimodal models. For segmentation, we evaluate multiple prompting strategies and show that prompt design impacts performance: the default prompt achieves the best results under Mean-of-Max and Mean-of-Mean evaluation aggregation schemes, while an augmented prompt incorporating both patient query title and content yields the highest performance under majority-vote-based microscore evaluation, achieving a Jaccard index of 0.395 and a Dice score of 0.566 with BiomedParse. For closed-ended QA, overall performance is strong across models, with average accuracies ranging from 0.729 to 0.798; o3 achieves the best overall accuracy (0.798), closely followed by GPT-4.1 (0.796), while Gemini-1.5-Pro shows competitive performance within the Gemini family (0.783). We publicly release DermaVQA-DAS, the DAS schema, and evaluation protocols to support and accelerate future research in patient-centered dermatological vision-language modeling (https://osf.io/72rp3).",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24340.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24340",
      "published": "2025-12-30T16:48:20Z",
      "updated": "2025-12-30T16:48:20Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了DermaVQA-DAS数据集和DAS模式，支持皮肤病图像的封闭式问答和分割任务，基准测试多模态模型。",
        "motivation": "现有皮肤病图像数据集主要基于皮肤镜图像，缺乏患者生成图像和临床上下文，限制了患者中心护理的应用，需改进数据资源。",
        "method": "引入专家开发的DAS模式，扩展数据集以支持QA和分割，基准测试多模态模型，并评估不同提示策略对性能的影响。",
        "result": "分割任务中，BiomedParse在增强提示下达到Jaccard指数0.395；QA任务中o3模型准确率0.798，整体模型表现稳健。",
        "conclusion": "公开发布DermaVQA-DAS数据集、DAS模式和评估协议，推动患者中心皮肤病视觉语言建模研究，提供标准化工具。",
        "tags": [
          "Dermatological Image Analysis",
          "Lesion Segmentation",
          "Question Answering",
          "Multimodal Models",
          "Vision-Language Modeling"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:46:47.516901Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24294",
      "title": "Virtual-Eyes: Quantitative Validation of a Lung CT Quality-Control Pipeline for Foundation-Model Cancer Risk Prediction",
      "authors": [
        "Md. Enamul Hoq",
        "Linda Larson-Prior",
        "Fred Prior"
      ],
      "abstract": "Robust preprocessing is rarely quantified in deep-learning pipelines for low-dose CT (LDCT) lung cancer screening. We develop and validate Virtual-Eyes, a clinically motivated 16-bit CT quality-control pipeline, and measure its differential impact on generalist foundation models versus specialist models. Virtual-Eyes enforces strict 512x512 in-plane resolution, rejects short or non-diagnostic series, and extracts a contiguous lung block using Hounsfield-unit filtering and bilateral lung-coverage scoring while preserving the native 16-bit grid. Using 765 NLST patients (182 cancer, 583 non-cancer), we compute slice-level embeddings from RAD-DINO and Merlin with frozen encoders and train leakage-free patient-level MLP heads; we also evaluate Sybil and a 2D ResNet-18 baseline under Raw versus Virtual-Eyes inputs without backbone retraining. Virtual-Eyes improves RAD-DINO slice-level AUC from 0.576 to 0.610 and patient-level AUC from 0.646 to 0.683 (mean pooling) and from 0.619 to 0.735 (max pooling), with improved calibration (Brier score 0.188 to 0.112). In contrast, Sybil and ResNet-18 degrade under Virtual-Eyes (Sybil AUC 0.886 to 0.837; ResNet-18 AUC 0.571 to 0.596) with evidence of context dependence and shortcut learning, and Merlin shows limited transferability (AUC approximately 0.507 to 0.567) regardless of preprocessing. These results demonstrate that anatomically targeted QC can stabilize and improve generalist foundation-model workflows but may disrupt specialist models adapted to raw clinical context.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24294.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24294",
      "published": "2025-12-30T15:34:18Z",
      "updated": "2025-12-30T15:34:18Z",
      "comment": "23 pages, and Under Review-MIDL-2026",
      "light_analysis": {
        "overview": "提出并定量验证一个用于肺癌CT筛查的16位质量控制流程，评估其对基础模型与专家模型性能的差异化影响。",
        "motivation": "在低剂量CT肺癌筛查的深度学习流程中，鲁棒的预处理步骤很少被量化研究。",
        "method": "开发名为Virtual-Eyes的CT质量控制流程，包括固定分辨率、筛选序列和肺区提取；使用多个预训练模型（RAD-DINO、Merlin、Sybil）和基线模型对比原始与预处理数据下的性能。",
        "result": "Virtual-Eyes显著提升了基础模型RAD-DINO的AUC和校准度，但导致专家模型Sybil性能下降，并揭示了模型存在上下文依赖和捷径学习现象。",
        "conclusion": "针对解剖结构的质量控制能稳定并改进基础模型的工作流，但可能破坏已适应原始临床环境的专家模型。",
        "tags": [
          "CT Quality-Control",
          "Foundation Models",
          "Low-Dose CT Screening",
          "Transfer Learning",
          "Model Calibration"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:47:33.252779Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24289",
      "title": "Automated Analysis of Sustainability Reports: Using Large Language Models for the Extraction and Prediction of EU Taxonomy-Compliant KPIs",
      "authors": [
        "Jonathan Schmoll",
        "Adam Jatowt"
      ],
      "abstract": "The manual, resource-intensive process of complying with the EU Taxonomy presents a significant challenge for companies. While Large Language Models (LLMs) offer a path to automation, research is hindered by a lack of public benchmark datasets. To address this gap, we introduce a novel, structured dataset from 190 corporate reports, containing ground-truth economic activities and quantitative Key Performance Indicators (KPIs). We use this dataset to conduct the first systematic evaluation of LLMs on the core compliance workflow. Our results reveal a clear performance gap between qualitative and quantitative tasks. LLMs show moderate success in the qualitative task of identifying economic activities, with a multi-step agentic framework modestly enhancing precision. Conversely, the models comprehensively fail at the quantitative task of predicting financial KPIs in a zero-shot setting. We also discover a paradox, where concise metadata often yields superior performance to full, unstructured reports, and find that model confidence scores are poorly calibrated. We conclude that while LLMs are not ready for full automation, they can serve as powerful assistive tools for human experts. Our dataset provides a public benchmark for future research.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24289.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24289",
      "published": "2025-12-30T15:28:03Z",
      "updated": "2025-12-30T15:28:03Z",
      "comment": null,
      "light_analysis": {
        "overview": "引入新数据集，首次系统评估大语言模型在欧盟分类法合规工作流中的表现，发现其在定量任务中表现不佳。",
        "motivation": "解决欧盟分类法合规手动过程的挑战，由于缺乏公共基准数据集，阻碍了LLMs在该领域的自动化研究。",
        "method": "构建了来自190份公司报告的结构化数据集，用于首次系统评估大语言模型在合规工作流中的表现，包括使用多步代理框架。",
        "result": "LLMs在识别经济活动的定性任务中表现中等，但在预测KPIs的定量任务中失败；简洁元数据表现更佳，模型置信度校准差。",
        "conclusion": "LLMs尚未实现完全自动化，但可作为人类专家的辅助工具；新数据集为未来研究提供了公共基准。",
        "tags": [
          "Large Language Model",
          "Zero-shot Learning",
          "Agentic Framework",
          "Text Extraction"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:45:53.060566Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24278",
      "title": "One-shot synthesis of rare gastrointestinal lesions improves diagnostic accuracy and clinical training",
      "authors": [
        "Jia Yu",
        "Yan Zhu",
        "Peiyao Fu",
        "Tianyi Chen",
        "Zhihua Wang",
        "Fei Wu",
        "Quanlin Li",
        "Pinghong Zhou",
        "Shuo Wang",
        "Xian Yang"
      ],
      "abstract": "Rare gastrointestinal lesions are infrequently encountered in routine endoscopy, restricting the data available for developing reliable artificial intelligence (AI) models and training novice clinicians. Here we present EndoRare, a one-shot, retraining-free generative framework that synthesizes diverse, high-fidelity lesion exemplars from a single reference image. By leveraging language-guided concept disentanglement, EndoRare separates pathognomonic lesion features from non-diagnostic attributes, encoding the former into a learnable prototype embedding while varying the latter to ensure diversity. We validated the framework across four rare pathologies (calcifying fibrous tumor, juvenile polyposis syndrome, familial adenomatous polyposis, and Peutz-Jeghers syndrome). Synthetic images were judged clinically plausible by experts and, when used for data augmentation, significantly enhanced downstream AI classifiers, improving the true positive rate at low false-positive rates. Crucially, a blinded reader study demonstrated that novice endoscopists exposed to EndoRare-generated cases achieved a 0.400 increase in recall and a 0.267 increase in precision. These results establish a practical, data-efficient pathway to bridge the rare-disease gap in both computer-aided diagnostics and clinical education.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24278.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24278",
      "published": "2025-12-30T15:07:09Z",
      "updated": "2025-12-30T15:07:09Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出EndoRare框架，通过单张图像合成罕见胃肠道病变图像，提升AI诊断准确性和临床培训效果。",
        "motivation": "罕见胃肠道病变数据稀缺，限制了开发可靠AI模型和培训新临床医生的数据需求。",
        "method": "使用语言引导的概念解缠技术，分离病理特征与非诊断属性，从单张参考图像合成多样高保真病变图像。",
        "result": "合成图像临床合理，增强AI分类器性能；新内窥镜医生培训后召回率提高0.400，精确率提高0.267。",
        "conclusion": "EndoRare提供了一种数据高效途径，弥合罕见疾病在计算机辅助诊断和临床教育中的差距。",
        "tags": [
          "One-shot Synthesis",
          "Language-Guided Disentanglement",
          "Generative Models",
          "Data Augmentation",
          "Medical AI"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:48:19.969521Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24253",
      "title": "Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm",
      "authors": [
        "Alireza Rafiei",
        "Farshid Hajati",
        "Alireza Rezaee",
        "Amirhossien Panahi",
        "Shahadat Uddin"
      ],
      "abstract": "Sepsis, characterized by a dysregulated immune response to infection, results in significant mortality, morbidity, and healthcare costs. The timely prediction of sepsis progression is crucial for reducing adverse outcomes through early intervention. Despite the development of numerous models for Intensive Care Unit (ICU) patients, there remains a notable gap in approaches for the early detection of sepsis in non-ward settings. This research introduces and evaluates four novel machine learning algorithms designed for predicting the onset of sepsis on wearable devices by analyzing heart rate data. The architecture of these models was refined through a genetic algorithm, optimizing for performance, computational complexity, and memory requirements. Performance metrics were subsequently extracted for each model to evaluate their feasibility for implementation on wearable devices capable of accurate heart rate monitoring. The models were initially tailored for a prediction window of one hour, later extended to four hours through transfer learning. The encouraging outcomes of this study suggest the potential for wearable technology to facilitate early sepsis detection outside ICU and ward environments.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24253.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24253",
      "published": "2025-12-30T14:27:43Z",
      "updated": "2025-12-30T14:27:43Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出并评估了基于心率信号和遗传优化LSTM算法的可穿戴设备脓毒症早期预测模型。",
        "motivation": "解决脓毒症早期预测的空白，现有模型主要用于ICU患者，缺乏非病房环境（如可穿戴设备）的检测方法。",
        "method": "开发四种机器学习算法，通过遗传算法优化LSTM模型架构，利用心率数据预测脓毒症发作，并应用迁移学习扩展预测窗口。",
        "result": "取得鼓舞人心的结果，表明模型在可穿戴设备上可行，有潜力用于ICU外环境的早期脓毒症检测。",
        "conclusion": "可穿戴技术能促进非ICU环境的脓毒症早期检测，为远程医疗监测提供新途径。",
        "tags": [
          "LSTM",
          "Genetic Algorithm",
          "Transfer Learning",
          "Heart Rate Monitoring",
          "Wearable Devices"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:43:53.688146Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24235",
      "title": "LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring",
      "authors": [
        "May Bashendy",
        "Walid Massoud",
        "Sohaila Eltanbouly",
        "Salam Albatarni",
        "Marwan Sayed",
        "Abrar Abir",
        "Houda Bouamor",
        "Tamer Elsayed"
      ],
      "abstract": "Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24235.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24235",
      "published": "2025-12-30T13:49:52Z",
      "updated": "2025-12-30T13:49:52Z",
      "comment": null,
      "light_analysis": {
        "overview": "论文介绍了LAILA，目前最大的公开阿拉伯语自动作文评分数据集。",
        "motivation": "解决阿拉伯语自动作文评分研究因缺乏公开数据集而受限的问题。",
        "method": "设计并收集了7859篇论文，进行整体和七个特征维度的注释，使用先进的阿拉伯语和英语模型在特定提示和跨提示设置下进行基准测试。",
        "result": "创建了包含七维度评分的论文数据集，并提供了基准测试结果，支持模型评估。",
        "conclusion": "LAILA填补了阿拉伯语自动作文评分研究的关键需求，有助于开发鲁棒的评分系统。",
        "tags": [
          "Automated Essay Scoring",
          "Arabic NLP",
          "Dataset Creation",
          "Benchmarking"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:46:54.619402Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24214",
      "title": "Medical Image Classification on Imbalanced Data Using ProGAN and SMA-Optimized ResNet: Application to COVID-19",
      "authors": [
        "Sina Jahromi",
        "Farshid Hajati",
        "Alireza Rezaee",
        "Javaher Nourian"
      ],
      "abstract": "The challenge of imbalanced data is prominent in medical image classification. This challenge arises when there is a significant disparity in the number of images belonging to a particular class, such as the presence or absence of a specific disease, as compared to the number of images belonging to other classes. This issue is especially notable during pandemics, which may result in an even more significant imbalance in the dataset. Researchers have employed various approaches in recent years to detect COVID-19 infected individuals accurately and quickly, with artificial intelligence and machine learning algorithms at the forefront. However, the lack of sufficient and balanced data remains a significant obstacle to these methods. This study addresses the challenge by proposing a progressive generative adversarial network to generate synthetic data to supplement the real ones. The proposed method suggests a weighted approach to combine synthetic data with real ones before inputting it into a deep network classifier. A multi-objective meta-heuristic population-based optimization algorithm is employed to optimize the hyper-parameters of the classifier. The proposed model exhibits superior cross-validated metrics compared to existing methods when applied to a large and imbalanced chest X-ray image dataset of COVID-19. The proposed model achieves 95.5% and 98.5% accuracy for 4-class and 2-class imbalanced classification problems, respectively. The successful experimental outcomes demonstrate the effectiveness of the proposed model in classifying medical images using imbalanced data during pandemics.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24214.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24214",
      "published": "2025-12-30T13:26:01Z",
      "updated": "2025-12-30T13:26:01Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出结合ProGAN生成合成数据与SMA优化ResNet的方法，以提升不平衡医学图像分类性能。",
        "motivation": "解决医学图像分类，尤其是疫情期间COVID-19检测中，因数据类别分布不均衡而阻碍AI模型性能的问题。",
        "method": "使用ProGAN生成合成数据，加权融合真实与合成数据后，输入经SMA（一种元启发式算法）优化超参数的ResNet分类器。",
        "result": "在不平衡的COVID-19胸部X光数据集上，四分类和二分类准确率分别达到95.5%和98.5%，优于现有方法。",
        "conclusion": "该方法能有效应对不平衡医学图像数据分类的挑战，为疫情等场景下的快速、准确诊断提供了有效工具。",
        "tags": [
          "ProGAN",
          "ResNet",
          "Medical Image Classification",
          "Meta-heuristic Optimization",
          "Imbalanced Data"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:39:19.882275Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24205",
      "title": "Micro-Macro Tensor Neural Surrogates for Uncertainty Quantification in Collisional Plasma",
      "authors": [
        "Wei Chen",
        "Giacomo Dimarco",
        "Lorenzo Pareschi"
      ],
      "abstract": "Plasma kinetic equations exhibit pronounced sensitivity to microscopic perturbations in model parameters and data, making reliable and efficient uncertainty quantification (UQ) essential for predictive simulations. However, the cost of uncertainty sampling, the high-dimensional phase space, and multiscale stiffness pose severe challenges to both computational efficiency and error control in traditional numerical methods. These aspects are further emphasized in presence of collisions where the high-dimensional nonlocal collision integrations and conservation properties pose severe constraints. To overcome this, we present a variance-reduced Monte Carlo framework for UQ in the Vlasov--Poisson--Landau (VPL) system, in which neural network surrogates replace the multiple costly evaluations of the Landau collision term. The method couples a high-fidelity, asymptotic-preserving VPL solver with inexpensive, strongly correlated surrogates based on the Vlasov--Poisson--Fokker--Planck (VPFP) and Euler--Poisson (EP) equations. For the surrogate models, we introduce a generalization of the separable physics-informed neural network (SPINN), developing a class of tensor neural networks based on an anisotropic micro-macro decomposition, to reduce velocity-moment costs, model complexity, and the curse of dimensionality. To further increase correlation with VPL, we calibrate the VPFP model and design an asymptotic-preserving SPINN whose small- and large-Knudsen limits recover the EP and VP systems, respectively. Numerical experiments show substantial variance reduction over standard Monte Carlo, accurate statistics with far fewer high-fidelity samples, and lower wall-clock time, while maintaining robustness to stochastic dimension.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24205.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24205",
      "published": "2025-12-30T13:07:35Z",
      "updated": "2025-12-30T13:07:35Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出了基于张量神经网络的微宏观分解代理模型，用于减少等离子体碰撞模拟中不确定性量化的计算成本。",
        "motivation": "等离子体动力学方程对微观扰动敏感，不确定性量化至关重要，但传统方法因高成本、高维度和多尺度刚度而面临挑战，尤其在碰撞存在时。",
        "method": "开发了方差减少的蒙特卡洛框架，使用神经网络代理替代昂贵碰撞项；引入广义可分离物理信息神经网络，基于各向异性微宏观分解构建张量神经网络。",
        "result": "数值实验显示方差大幅减少，用更少高保真样本获得准确统计，计算时间降低，且对随机维度鲁棒。",
        "conclusion": "贡献在于提出了一种高效、鲁棒的方法，结合高保真求解器和神经代理，用于等离子体碰撞模拟的不确定性量化。",
        "tags": [
          "Neural Network Surrogates",
          "Tensor Neural Networks",
          "Physics-Informed Neural Networks",
          "Monte Carlo Methods",
          "Uncertainty Quantification"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:44:37.269377Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24193",
      "title": "PointRAFT: 3D deep learning for high-throughput prediction of potato tuber weight from partial point clouds",
      "authors": [
        "Pieter M. Blok",
        "Haozhou Wang",
        "Hyun Kwon Suh",
        "Peicheng Wang",
        "James Burridge",
        "Wei Guo"
      ],
      "abstract": "Potato yield is a key indicator for optimizing cultivation practices in agriculture. Potato yield can be estimated on harvesters using RGB-D cameras, which capture three-dimensional (3D) information of individual tubers moving along the conveyor belt. However, point clouds reconstructed from RGB-D images are incomplete due to self-occlusion, leading to systematic underestimation of tuber weight. To address this, we introduce PointRAFT, a high-throughput point cloud regression network that directly predicts continuous 3D shape properties, such as tuber weight, from partial point clouds. Rather than reconstructing full 3D geometry, PointRAFT infers target values directly from raw 3D data. Its key architectural novelty is an object height embedding that incorporates tuber height as an additional geometric cue, improving weight prediction under practical harvesting conditions. PointRAFT was trained and evaluated on 26,688 partial point clouds collected from 859 potato tubers across four cultivars and three growing seasons on an operational harvester in Japan. On a test set of 5,254 point clouds from 172 tubers, PointRAFT achieved a mean absolute error of 12.0 g and a root mean squared error of 17.2 g, substantially outperforming a linear regression baseline and a standard PointNet++ regression network. With an average inference time of 6.3 ms per point cloud, PointRAFT supports processing rates of up to 150 tubers per second, meeting the high-throughput requirements of commercial potato harvesters. Beyond potato weight estimation, PointRAFT provides a versatile regression network applicable to a wide range of 3D phenotyping and robotic perception tasks. The code, network weights, and a subset of the dataset are publicly available at https://github.com/pieterblok/pointraft.git.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24193.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24193",
      "published": "2025-12-30T12:52:20Z",
      "updated": "2025-12-30T12:52:20Z",
      "comment": "14 pages, 7 figures, 3 tables",
      "light_analysis": {
        "overview": "提出了PointRAFT，一个可直接从部分3D点云预测马铃薯块茎重量的高通量深度学习网络。",
        "motivation": "解决农业收获中，因自遮挡导致马铃薯点云不完整，进而系统性地低估块茎重量的问题。",
        "method": "提出PointRAFT点云回归网络，引入物体高度嵌入作为额外几何线索，直接从原始点云推断重量。",
        "result": "在5254个测试点云上，MAE为12.0g，RMSE为17.2g，推理速度达6.3ms/点云，优于基线方法。",
        "conclusion": "PointRAFT为3D表型分析和机器人感知提供了通用的回归网络，满足商业收获机的高通量要求。",
        "tags": [
          "3D Point Cloud",
          "Deep Learning",
          "Regression Network",
          "Phenotyping",
          "Computer Vision"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:49:22.936454Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24189",
      "title": "SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents",
      "authors": [
        "Yankai Jiang",
        "Wenjie Lou",
        "Lilong Wang",
        "Zhenyu Tang",
        "Shiyang Feng",
        "Jiaxuan Lu",
        "Haoran Sun",
        "Yaning Pan",
        "Shuang Gu",
        "Haoyang Su",
        "Feng Liu",
        "Wangxu Wei",
        "Pan Tan",
        "Dongzhan Zhou",
        "Fenghua Ling",
        "Cheng Tan",
        "Bo Zhang",
        "Xiaosong Wang",
        "Lei Bai",
        "Bowen Zhou"
      ],
      "abstract": "We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "pdf_url": "https://arxiv.org/pdf/2512.24189.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24189",
      "published": "2025-12-30T12:45:32Z",
      "updated": "2025-12-30T12:45:32Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出SCP协议，旨在通过标准化协议和架构连接全球科学资源与AI代理，加速科学发现。",
        "motivation": "解决科学资源（工具、模型、数据、仪器）分散、集成成本高，以及难以实现跨平台、大规模、可复现的AI代理协作问题。",
        "method": "基于两大支柱：一是统一资源集成协议，二是包含中心化Hub和联邦化Server的架构，以管理实验全生命周期。",
        "result": "构建了集成超过1600个工具资源的平台，促进了异构AI系统与研究人员的安全协作，显著降低集成开销并提升可重复性。",
        "conclusion": "SCP在协议层面标准化了科学上下文和工具编排，为可扩展、多机构、代理驱动的科学研究建立了关键基础设施。",
        "tags": [
          "Autonomous Agents",
          "Scientific Workflow Orchestration",
          "Multi-agent Systems",
          "Tool Integration Protocol"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:49:46.800779Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24160",
      "title": "Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset",
      "authors": [
        "TsaiChing Ni",
        "ZhenQi Chen",
        "YuanFu Yang"
      ],
      "abstract": "We present IMDD-1M, the first large-scale Industrial Multimodal Defect Dataset comprising 1,000,000 aligned image-text pairs, designed to advance multimodal learning for manufacturing and quality inspection. IMDD-1M contains high-resolution real-world defects spanning over 60 material categories and more than 400 defect types, each accompanied by expert-verified annotations and fine-grained textual descriptions detailing defect location, severity, and contextual attributes. This dataset enables a wide spectrum of applications, including classification, segmentation, retrieval, captioning, and generative modeling. Building upon IMDD-1M, we train a diffusion-based vision-language foundation model from scratch, specifically tailored for industrial scenarios. The model serves as a generalizable foundation that can be efficiently adapted to specialized domains through lightweight fine-tuning. With less than 5% of the task-specific data required by dedicated expert models, it achieves comparable performance, highlighting the potential of data-efficient foundation model adaptation for industrial inspection and generation, paving the way for scalable, domain-adaptive, and knowledge-grounded manufacturing intelligence.",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24160.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24160",
      "published": "2025-12-30T11:45:22Z",
      "updated": "2025-12-30T11:45:22Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出大规模工业多模态缺陷数据集IMDD-1M和扩散视觉-语言基础模型，推动开放词汇工业缺陷理解。",
        "motivation": "为促进制造业多模态学习和质量检测，解决工业缺陷的开集理解和应用挑战。",
        "method": "构建了包含100万对齐图像-文本对的IMDD-1M数据集，并从头训练基于扩散的视觉-语言基础模型。",
        "result": "模型通过轻量微调，仅需少于5%任务数据即可达到专家模型可比性能，实现高效适应。",
        "conclusion": "为可扩展、领域自适应的制造智能奠定了基础，推动工业检测和生成技术的进步。",
        "tags": [
          "Multimodal Dataset",
          "Diffusion Models",
          "Vision-Language Models",
          "Industrial Defect Detection",
          "Foundation Models"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:41:47.699371Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24066",
      "title": "Pathology Context Recalibration Network for Ocular Disease Recognition",
      "authors": [
        "Zunjie Xiao",
        "Xiaoqing Zhang",
        "Risa Higashita",
        "Jiang Liu"
      ],
      "abstract": "Pathology context and expert experience play significant roles in clinical ocular disease diagnosis. Although deep neural networks (DNNs) have good ocular disease recognition results, they often ignore exploring the clinical pathology context and expert experience priors to improve ocular disease recognition performance and decision-making interpretability. To this end, we first develop a novel Pathology Recalibration Module (PRM) to leverage the potential of pathology context prior via the combination of the well-designed pixel-wise context compression operator and pathology distribution concentration operator; then this paper applies a novel expert prior Guidance Adapter (EPGA) to further highlight significant pixel-wise representation regions by fully mining the expert experience prior. By incorporating PRM and EPGA into the modern DNN, the PCRNet is constructed for automated ocular disease recognition. Additionally, we introduce an Integrated Loss (IL) to boost the ocular disease recognition performance of PCRNet by considering the effects of sample-wise loss distributions and training label frequencies. The extensive experiments on three ocular disease datasets demonstrate the superiority of PCRNet with IL over state-of-the-art attention-based networks and advanced loss methods. Further visualization analysis explains the inherent behavior of PRM and EPGA that affects the decision-making process of DNNs.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "pdf_url": "https://arxiv.org/pdf/2512.24066.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24066",
      "published": "2025-12-30T08:21:23Z",
      "updated": "2025-12-30T08:21:23Z",
      "comment": "The article has been accepted for publication at Machine Intelligence Research (MIR)",
      "light_analysis": {
        "overview": "提出PCRNet，通过病理重校准和专家先验指导结合临床先验知识，提升眼科疾病识别性能。",
        "motivation": "现有深度神经网络在眼科疾病识别中忽略临床病理背景和专家经验先验，限制性能提升和决策可解释性。",
        "method": "设计病理重校准模块(PRM)和专家先验指导适配器(EPGA)，集成到DNN中，并引入集成损失(IL)优化训练。",
        "result": "在三个眼科疾病数据集上，PCRNet优于最先进的注意力网络和损失方法，可视化分析解释了模块行为。",
        "conclusion": "PCRNet有效整合病理和专家先验知识，提高了疾病识别准确性和模型决策的可解释性。",
        "tags": [
          "Pathology Context Recalibration",
          "Expert Prior Guidance",
          "Integrated Loss",
          "Deep Neural Networks",
          "Attention Mechanisms"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:44:35.583810Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23941",
      "title": "Disentangling Learning from Judgment: Representation Learning for Open Response Analytics",
      "authors": [
        "Conrad Borchers",
        "Manit Patel",
        "Seiyon M. Lee",
        "Anthony F. Botelho"
      ],
      "abstract": "Open-ended responses are central to learning, yet automated scoring often conflates what students wrote with how teachers grade. We present an analytics-first framework that separates content signals from rater tendencies, making judgments visible and auditable via analytics. Using de-identified ASSISTments mathematics responses, we model teacher histories as dynamic priors and derive text representations from sentence embeddings, incorporating centering and residualization to mitigate prompt and teacher confounds. Temporally-validated linear models quantify the contributions of each signal, and a projection surfaces model disagreements for qualitative inspection. Results show that teacher priors heavily influence grade predictions; the strongest results arise when priors are combined with content embeddings (AUC~0.815), while content-only models remain above chance but substantially weaker (AUC~0.626). Adjusting for rater effects sharpens the residual content representation, retaining more informative embedding dimensions and revealing cases where semantic evidence supports understanding as opposed to surface-level differences in how students respond. The contribution presents a practical pipeline that transforms embeddings from mere features into learning analytics for reflection, enabling teachers and researchers to examine where grading practices align (or conflict) with evidence of student reasoning and learning.",
      "categories": [
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23941.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23941",
      "published": "2025-12-30T02:06:28Z",
      "updated": "2025-12-30T02:06:28Z",
      "comment": "Short research paper accepted at Learning Analytics and Knowledge (LAK '26)",
      "light_analysis": {
        "overview": "提出一个分析框架，通过表示学习分离开放式回答的内容与教师评分倾向，实现自动化评分的可审计性。",
        "motivation": "解决自动化评分中混淆学生回答内容与教师评分倾向的问题，以更准确评估学习过程。",
        "method": "建模教师历史为动态先验，使用句子嵌入生成文本表示，结合中心化和残差化减少干扰，采用时间验证线性模型量化信号贡献。",
        "result": "教师先验对预测影响大；结合先验和内容嵌入的模型AUC达0.815，仅内容模型AUC为0.626；调整评分者效应锐化了内容表示。",
        "conclusion": "提供了一个实用管道，将嵌入转化为反思性学习分析工具，帮助教师检查评分实践与学生推理证据的一致性。",
        "tags": [
          "Representation Learning",
          "Sentence Embeddings",
          "Linear Models",
          "Residualization"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:37:33.345057Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23813",
      "title": "StressRoBERTa: Cross-Condition Transfer Learning from Depression, Anxiety, and PTSD to Stress Detection",
      "authors": [
        "Amal Alqahtani",
        "Efsun Kayi",
        "Mona Diab"
      ],
      "abstract": "The prevalence of chronic stress represents a significant public health concern, with social media platforms like Twitter serving as important venues for individuals to share their experiences. This paper introduces StressRoBERTa, a cross-condition transfer learning approach for automatic detection of self-reported chronic stress in English tweets. The investigation examines whether continual training on clinically related conditions (depression, anxiety, PTSD), disorders with high comorbidity with chronic stress, improves stress detection compared to general language models and broad mental health models. RoBERTa is continually trained on the Stress-SMHD corpus (108M words from users with self-reported diagnoses of depression, anxiety, and PTSD) and fine-tuned on the SMM4H 2022 Task 8 dataset. StressRoBERTa achieves 82% F1-score, outperforming the best shared task system (79% F1) by 3 percentage points. The results demonstrate that focused cross-condition transfer from stress-related disorders (+1% F1 over vanilla RoBERTa) provides stronger representations than general mental health training. Evaluation on Dreaddit (81% F1) further demonstrates transfer from clinical mental health contexts to situational stress discussions.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23813.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23813",
      "published": "2025-12-29T19:16:14Z",
      "updated": "2025-12-29T19:16:14Z",
      "comment": null,
      "light_analysis": {
        "overview": "提出StressRoBERTa模型，通过跨条件迁移学习提升社交媒体中慢性压力的自动检测效果。",
        "motivation": "慢性压力是重要的公共卫生问题，研究旨在探索使用临床相关精神障碍数据是否能改进社交媒体中的压力检测。",
        "method": "基于RoBERTa，先在抑郁、焦虑、PTSD语料上进行持续训练，再在压力检测任务上进行微调的跨条件迁移学习方法。",
        "result": "在SMM4H 2022任务上取得82%的F1分数，优于最佳共享系统3个百分点，在Dreaddit数据集上F1为81%。",
        "conclusion": "从相关临床障碍进行跨条件迁移学习，比通用或宽泛精神健康训练能获得更好的压力检测表示。",
        "tags": [
          "Transfer Learning",
          "RoBERTa",
          "Mental Health Detection",
          "NLP",
          "Fine-tuning"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:39:45.961662Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23659",
      "title": "Less is more: Probabilistic reduction is best explained by small-scale predictability measures",
      "authors": [
        "Cassandra L. Jacobs",
        "Andrés Buxó-Lugo",
        "Anna K. Taylor",
        "Marie Leopold-Hooke"
      ],
      "abstract": "The primary research questions of this paper center on defining the amount of context that is necessary and/or appropriate when investigating the relationship between language model probabilities and cognitive phenomena. We investigate whether whole utterances are necessary to observe probabilistic reduction and demonstrate that n-gram representations suffice as cognitive units of planning.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23659.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23659",
      "published": "2025-12-29T18:12:37Z",
      "updated": "2025-12-29T18:12:37Z",
      "comment": null,
      "light_analysis": {
        "overview": "证明了研究语言概率缩减现象时，n-gram足以替代完整话语作为认知分析单位。",
        "motivation": "探究在研究语言模型概率与认知现象关系时，多大上下文是必要且合适的。",
        "method": "通过对比分析，探索了完整话语与n-gram表示在研究概率缩减现象中的效用。",
        "result": "发现n-gram表示足以作为认知规划的单位来解释概率缩减现象。",
        "conclusion": "表明小规模的可预测性度量优于完整话语，能有效解释概率缩减这一认知现象。",
        "tags": [
          "Language Model",
          "Probabilistic Reduction",
          "Cognitive Linguistics",
          "N-gram"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:42:52.497827Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23637",
      "title": "A Dataset and Benchmark for Consumer Healthcare Question Summarization",
      "authors": [
        "Abhishek Basu",
        "Deepak Gupta",
        "Dina Demner-Fushman",
        "Shweta Yadav"
      ],
      "abstract": "The quest for seeking health information has swamped the web with consumers health-related questions. Generally, consumers use overly descriptive and peripheral information to express their medical condition or other healthcare needs, contributing to the challenges of natural language understanding. One way to address this challenge is to summarize the questions and distill the key information of the original question. Recently, large-scale datasets have significantly propelled the development of several summarization tasks, such as multi-document summarization and dialogue summarization. However, a lack of a domain-expert annotated dataset for the consumer healthcare questions summarization task inhibits the development of an efficient summarization system. To address this issue, we introduce a new dataset, CHQ-Sum,m that contains 1507 domain-expert annotated consumer health questions and corresponding summaries. The dataset is derived from the community question answering forum and therefore provides a valuable resource for understanding consumer health-related posts on social media. We benchmark the dataset on multiple state-of-the-art summarization models to show the effectiveness of the dataset",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23637.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23637",
      "published": "2025-12-29T17:49:43Z",
      "updated": "2025-12-29T17:49:43Z",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2206.06581",
      "light_analysis": {
        "overview": "提出了一个领域专家标注的消费者健康问题总结数据集CHQ-Sum，并进行了基准测试。",
        "motivation": "消费者健康问题描述冗长，自然语言理解困难，且缺乏专门的数据集来支持总结任务。",
        "method": "创建了CHQ-Sum数据集，包含1507个来自社区问答论坛的专家标注问题和摘要。",
        "result": "在多个最先进的总结模型上进行了基准测试，验证了数据集的有效性。",
        "conclusion": "该数据集为消费者健康问题总结提供了宝贵资源，推动了相关系统的发展。",
        "tags": [
          "Text Summarization",
          "Dataset Creation",
          "Benchmarking",
          "Healthcare NLP"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:43:57.085129Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23504",
      "title": "Automatic Detection of Complex Quotation Patterns in Aggadic Literature",
      "authors": [
        "Hadar Miller",
        "Tsvi Kuflik",
        "Moshe Lavee"
      ],
      "abstract": "This paper presents ACT (Allocate Connections between Texts), a novel three-stage algorithm for the automatic detection of biblical quotations in Rabbinic literature. Unlike existing text reuse frameworks that struggle with short, paraphrased, or structurally embedded quotations, ACT combines a morphology-aware alignment algorithm with a context-sensitive enrichment stage that identifies complex citation patterns such as \"Wave\" and \"Echo\" quotations.   Our approach was evaluated against leading systems, including Dicta, Passim, Text-Matcher, as well as human-annotated critical editions. We further assessed three ACT configurations to isolate the contribution of each component. Results demonstrate that the full ACT pipeline (ACT-QE) outperforms all baselines, achieving an F1 score of 0.91, with superior Recall (0.89) and Precision (0.94). Notably, ACT-2, which lacks stylistic enrichment, achieves higher Recall (0.90) but suffers in Precision, while ACT-3, using longer n-grams, offers a tradeoff between coverage and specificity.   In addition to improving quotation detection, ACT's ability to classify stylistic patterns across corpora opens new avenues for genre classification and intertextual analysis. This work contributes to digital humanities and computational philology by addressing the methodological gap between exhaustive machine-based detection and human editorial judgment. ACT lays a foundation for broader applications in historical textual analysis, especially in morphologically rich and citation-dense traditions like Aggadic literature.",
      "categories": [
        "cs.CL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23504.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23504",
      "published": "2025-12-29T14:45:58Z",
      "updated": "2025-12-29T14:45:58Z",
      "comment": "This paper is under review at Cogent Arts & Humanities",
      "light_analysis": {
        "overview": "提出了ACT算法，用于自动检测圣经引用在拉比文学中的复杂模式。",
        "motivation": "现有文本重用框架难以处理短、意译或结构嵌入的引用，需改进对复杂引用模式的自动检测。",
        "method": "采用三阶段ACT算法，结合词形学对齐算法和上下文敏感丰富阶段，识别如'Wave'和'Echo'等引用模式。",
        "result": "ACT-QE配置在F1得分上达到0.91，召回率0.89和精确率0.94，优于基线系统。",
        "conclusion": "提升了引用检测准确度，为数字人文中的流派分类和互文分析提供新方法，贡献于计算文献学。",
        "tags": [
          "Text Reuse Detection",
          "Alignment Algorithm",
          "Context-Sensitive Analysis",
          "Morphological Analysis"
        ],
        "relevance_score": 0.8
      },
      "analyzed_at": "2026-01-03T22:47:31.662950Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24767",
      "title": "From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis",
      "authors": [
        "Yutong Cai",
        "Hua Wang"
      ],
      "abstract": "Autonomous taxi services represent a transformative advancement in urban mobility, offering safety, efficiency, and round-the-clock operations. While existing literature has explored user acceptance of autonomous taxis through stated preference experiments and hypothetical scenarios, few studies have investigated actual user behavior based on operational AV services. This study addresses that gap by leveraging survey data from Wuhan, China, where Baidu's Apollo Robotaxi service operates at scale. We design a realistic survey incorporating actual service attributes and collect 336 valid responses from actual users. Using Structural Equation Modeling, we identify six latent psychological constructs, namely Trust \\& Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, and Education. Their influences on adoption behavior, measured by the selection frequency of autonomous taxis in ten scenarios, are examined and interpreted. Results show that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption, while other latent constructs play more nuanced roles. The model demonstrates strong goodness-of-fit across multiple indices. Our findings offer empirical evidence to support policymaking, fare design, and public outreach strategies for scaling autonomous taxis deployments in real-world urban settings.",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "pdf_url": "https://arxiv.org/pdf/2512.24767.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24767",
      "published": "2025-12-31T10:27:53Z",
      "updated": "2025-12-31T10:27:53Z",
      "comment": null,
      "light_analysis": {
        "overview": "本研究通过结构方程模型分析实际用户数据，识别影响自动驾驶出租车采用的关键心理因素。",
        "motivation": "现有研究多基于假设场景，缺乏基于实际运营自动驾驶出租车服务的用户行为研究，本研究旨在填补这一空白。",
        "method": "采用调查方法收集336份有效响应，运用结构方程建模分析六个潜在心理构念对采用行为的影响。",
        "result": "成本敏感性和行为意向是采用行为的最强正向预测因子，模型在多个指数上表现出良好拟合度。",
        "conclusion": "为自动驾驶出租车在现实城市环境中的规模化部署提供实证证据，支持政策制定、票价设计和公众推广。",
        "tags": [
          "Autonomous Vehicles",
          "Structural Equation Modeling",
          "Survey Research",
          "Behavioral Intention"
        ],
        "relevance_score": 0.7
      },
      "analyzed_at": "2026-01-03T22:39:04.535749Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.24098",
      "title": "Training a Huggingface Model on AWS Sagemaker (Without Tears)",
      "authors": [
        "Liling Tan"
      ],
      "abstract": "The development of Large Language Models (LLMs) has primarily been driven by resource-rich research groups and industry partners. Due to the lack of on-premise computing resources required for increasingly complex models, many researchers are turning to cloud services like AWS SageMaker to train Hugging Face models. However, the steep learning curve of cloud platforms often presents a barrier for researchers accustomed to local environments. Existing documentation frequently leaves knowledge gaps, forcing users to seek fragmented information across the web. This demo paper aims to democratize cloud adoption by centralizing the essential information required for researchers to successfully train their first Hugging Face model on AWS SageMaker from scratch.",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.24098.pdf",
      "abs_url": "https://arxiv.org/abs/2512.24098",
      "published": "2025-12-30T09:14:17Z",
      "updated": "2025-12-30T09:14:17Z",
      "comment": null,
      "light_analysis": {
        "overview": "提供在AWS SageMaker上训练Hugging Face模型的无缝操作指南，以降低云平台使用门槛。",
        "motivation": "解决研究人员因缺乏本地算力和云平台复杂文档而难以利用AWS SageMaker训练大型语言模型的问题。",
        "method": "整合并集中化关键操作信息，创建一份从零开始在AWS SageMaker上训练Hugging Face模型的完整指南。",
        "result": "未明确说明。摘要未提供具体的量化效果或用户反馈数据。",
        "conclusion": "通过整合分散的信息，旨在推动更多人采用云服务进行AI模型训练，降低技术门槛。",
        "tags": [
          "AWS SageMaker",
          "Hugging Face",
          "Large Language Model",
          "Cloud Computing",
          "Model Training"
        ],
        "relevance_score": 0.7
      },
      "analyzed_at": "2026-01-03T22:48:34.309917Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2512.23429",
      "title": "The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective",
      "authors": [
        "Yi Zhao",
        "Yongjun Zhu",
        "Donghun Kim",
        "Yuzhuo Wang",
        "Heng Zhang",
        "Chao Lu",
        "Chengzhi Zhang"
      ],
      "abstract": "The influence of gender diversity on the success of scientific teams is of great interest to academia. However, prior findings remain inconsistent, and most studies operationalize diversity in aggregate terms, overlooking internal role differentiation. This limitation obscures a more nuanced understanding of how gender diversity shapes team impact. In particular, the effect of gender diversity across different team roles remains poorly understood. To this end, we define a scientific team as all coauthors of a paper and measure team impact through five-year citation counts. Using author contribution statements, we classified members into leadership and support roles. Drawing on more than 130,000 papers from PLOS journals, most of which are in biomedical-related disciplines, we employed multivariable regression to examine the association between gender diversity in these roles and team impact. Furthermore, we apply a threshold regression model to investigate how team size moderates this relationship. The results show that (1) the relationship between gender diversity and team impact follows an inverted U-shape for both leadership and support groups; (2) teams with an all-female leadership group and an all-male support group achieve higher impact than other team types. Interestingly, (3) the effect of leadership-group gender diversity is significantly negative for small teams but becomes positive and statistically insignificant in large teams. In contrast, the estimates for support-group gender diversity remain significant and positive, regardless of team size.",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "pdf_url": "https://arxiv.org/pdf/2512.23429.pdf",
      "abs_url": "https://arxiv.org/abs/2512.23429",
      "published": "2025-12-29T12:49:21Z",
      "updated": "2025-12-29T12:49:21Z",
      "comment": null,
      "light_analysis": {
        "overview": "本研究从团队角色视角分析性别多样性对科学团队影响力的影响，发现倒U形关系和角色特异性效应。",
        "motivation": "先前研究对性别多样性影响的结果不一致，且忽视团队内部角色分化，需探究不同角色的性别多样性效应。",
        "method": "基于13万篇PLOS论文数据，利用作者贡献声明区分领导和支持角色，采用多变量回归和阈值回归模型分析。",
        "result": "性别多样性呈倒U形关系；全女性领导加全男性支持的团队影响力更高；领导多样性效应受团队大小调节。",
        "conclusion": "通过团队角色视角深化了对性别多样性影响的理解，强调了角色分化和团队大小的关键作用。",
        "tags": [
          "Multivariable Regression",
          "Threshold Regression",
          "Team Roles Classification",
          "Citation Analysis"
        ],
        "relevance_score": 0.2
      },
      "analyzed_at": "2026-01-03T22:49:57.250239Z",
      "analysis_status": "success",
      "analysis_error": null
    }
  ],
  "all_news": [
    {
      "id": "b3564790a038d245",
      "title": "Chinese AI models have lagged the US frontier by 7 months on average since 2023",
      "url": "https://epoch.ai/data-insights/us-vs-china-eci",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T20:29:20Z",
      "summary": "Article URL: https://epoch.ai/data-insights/us-vs-china-eci\nComments URL: https://news.ycombinator.com/item?id=46481185\nPoints: 3\n# Comments: 3",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "根据Hacker News报道，自2023年以来，中国AI模型平均滞后美国前沿7个月，反映中美在人工智能发展上的差距。",
        "category": "行业",
        "relevance_score": 0.9,
        "sentiment": "negative",
        "keywords": [
          "中国AI模型",
          "美国前沿",
          "差距",
          "2023",
          "平均滞后"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:14.489835Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "ed807cd0ba15bc3f",
      "title": "FakeParts: A New Family of AI-Generated DeepFakes",
      "url": "https://arxiv.org/abs/2508.21052",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T18:14:11Z",
      "summary": "Article URL: https://arxiv.org/abs/2508.21052\nComments URL: https://news.ycombinator.com/item?id=46479718\nPoints: 1\n# Comments: 0",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "研究人员提出名为FakeParts的新型AI深度伪造技术家族，展示了生成逼真虚假内容的能力，可能加剧深度伪造检测的挑战。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "neutral",
        "keywords": [
          "FakeParts",
          "DeepFakes",
          "AI-Generated",
          "生成对抗网络",
          "伪造检测"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:17.348933Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "57606c610dd50481",
      "title": "微信炼出扩散语言模型，实现vLLM部署AR模型3倍加速，低熵场景超10倍",
      "url": "https://www.jiqizhixin.com/articles/2026-01-04-2",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-04T01:23:27+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "微信团队研发了扩散语言模型，并通过vLLM部署实现了对AR模型的加速，推理速度提升了3倍，在低熵场景下甚至能超过10倍，显著提高了效率。",
        "category": "AI",
        "relevance_score": 1.0,
        "sentiment": "positive",
        "keywords": [
          "微信",
          "扩散语言模型",
          "vLLM",
          "AR模型",
          "部署加速"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:14.483037Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "78d25eb3e7416c16",
      "title": "让模型自己找关键帧、视觉线索，小红书Video-Thinker破解视频推理困局",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-5",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:33:36+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "小红书提出 Video-Thinker 模型，使其能够自主定位视频中的关键帧和关键视觉线索，以解决现有模型在长视频理解与推理方面的难题。",
        "category": "AI",
        "relevance_score": 1.0,
        "sentiment": "positive",
        "keywords": [
          "小红书",
          "Video-Thinker",
          "视频理解",
          "关键帧检测",
          "多模态推理"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:20.218812Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "cb72ac5bbfd1378d",
      "title": "告别KV Cache枷锁，将长上下文压入权重，持续学习大模型有希望了？",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-3",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:19:00+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "标题暗示一项技术进展，通过将长上下文信息编码到模型权重中，减少或消除对KV Cache的依赖，有望使大模型实现持续学习，提升处理长序列的能力。",
        "category": "LLM",
        "relevance_score": 1.0,
        "sentiment": "positive",
        "keywords": [
          "KV Cache",
          "长上下文",
          "模型权重",
          "持续学习",
          "大模型"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:05.255213Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "30bc9d7fbf3e8c7c",
      "title": "Skeptic impressed by colleague's AI workflow",
      "url": "https://news.ycombinator.com/item?id=46481814",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T21:31:15Z",
      "summary": "I've been in the AI-code-assistant skeptic camp for a while, but a recent conversation with a dev I know and respect may be changing my mind. He's solo-programmed a few popular online games and is working on another one. So I asked him for a specific feature example and to see his AGENTS.md file.Here's what he had to say about his workflow that prompted our discussion:\"I’m (we’re) kicking out feature after feature that is being done right because I have an agentic AI flow that not only writes co...",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一位原本对AI代码助手持怀疑态度的开发者，在了解到同事采用AI代理工作流高效开发游戏功能后改变了看法，体现了AI在实际开发中的应用价值。",
        "category": "AI",
        "relevance_score": 0.85,
        "sentiment": "positive",
        "keywords": [
          "AI工作流",
          "代码助手",
          "AI代理",
          "软件开发",
          "Hacker News"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:35.878031Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "f240d2ff423bd5f7",
      "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "url": "https://arstechnica.com/ai/2026/01/openai-plans-new-voice-model-in-early-2026-audio-based-hardware-in-2027/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T17:48:37Z",
      "summary": "Article URL: https://arstechnica.com/ai/2026/01/openai-plans-new-voice-model-in-early-2026-audio-based-hardware-in-2027/\nComments URL: https://news.ycombinator.com/item?id=46479430\nPoints: 2\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "OpenAI 重组部分团队，计划开发基于音频的 AI 硬件产品，显示公司向硬件领域扩展的战略动向。",
        "category": "产品",
        "relevance_score": 0.85,
        "sentiment": "neutral",
        "keywords": [
          "OpenAI",
          "AI硬件",
          "音频AI",
          "团队重组",
          "产品开发"
        ]
      },
      "analyzed_at": "2026-01-03T22:54:03.487038Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "b571a4546d976d07",
      "title": "ControlNet作者张吕敏最新论文：长视频也能实现超短上下文",
      "url": "https://www.jiqizhixin.com/articles/2026-01-04-5",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-04T01:39:09+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "ControlNet作者张吕敏发表新论文，提出方法使长视频处理仅需超短上下文，可能降低视频AI任务的计算复杂度。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "positive",
        "keywords": [
          "ControlNet",
          "张吕敏",
          "长视频",
          "超短上下文",
          "论文"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:45.597027Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "47ecc5d5ccfaa95a",
      "title": "LeCun在Meta还有论文：JEPA物理规划的「终极指南」",
      "url": "https://www.jiqizhixin.com/articles/2026-01-04-3",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-04T01:29:24+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Yann LeCun及其Meta团队发布了关于JEPA物理规划的详细技术指南，为理解和实现这一非生成式AI模型提供了重要参考。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "neutral",
        "keywords": [
          "LeCun",
          "Meta",
          "JEPA",
          "物理规划",
          "AI规划"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:57.771194Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "03b34026529de243",
      "title": "Sebastian Raschka万字年终复盘：2025，属于「推理模型」的一年",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-9",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:58:51+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Sebastian Raschka 发布年终复盘，指出 2025 年将是推理模型成为 AI 领域发展关键的一年，强调推理能力的重要性。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "positive",
        "keywords": [
          "Sebastian Raschka",
          "推理模型",
          "2025",
          "年终复盘",
          "AI"
        ]
      },
      "analyzed_at": "2026-01-03T22:54:07.418587Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "73cab3090b8df8e8",
      "title": "KAN作者刘子鸣：AI还没等到它的「牛顿」",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-8",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:45:59+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "KAN（Kolmogorov-Arnold Network）论文作者刘子鸣表示，人工智能领域尚未出现类似牛顿的奠基性理论突破，暗示当前AI发展仍处于探索阶段。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "neutral",
        "keywords": [
          "KAN",
          "刘子鸣",
          "AI",
          "牛顿",
          "神经网络"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:45.174273Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "4388d52993b1b0a5",
      "title": "自回归也能做强视觉模型？NEPA开启「下一嵌入预测」时代，谢赛宁参与",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-7",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:41:44+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "谢赛宁参与的研究团队提出NEPA模型，利用自回归方法进行下一嵌入预测，为视觉模型开辟新途径，可能提升AI视觉领域性能。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "positive",
        "keywords": [
          "NEPA",
          "自回归",
          "视觉模型",
          "下一嵌入预测",
          "谢赛宁"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:59.105905Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "a1407419ff3fc489",
      "title": "Meta重磅：让智能体摆脱人类知识的瓶颈，通往自主AI的SSR级研究",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-4",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:26:06+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Meta公司发布了一项重磅研究，旨在让AI智能体摆脱对人类知识的依赖，推动向自主人工智能的发展，被视为SSR级的重要突破。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "positive",
        "keywords": [
          "Meta",
          "智能体",
          "自主AI",
          "瓶颈",
          "研究"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:50.923063Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "7f9e5b82d6ac92b4",
      "title": "AI Industry Signals from Noise",
      "url": "https://neosignal.io/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T21:54:32Z",
      "summary": "Article URL: https://neosignal.io\nComments URL: https://news.ycombinator.com/item?id=46482052\nPoints: 2\n# Comments: 0",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一篇在Hacker News上分享的文章，标题为'AI Industry Signals from Noise'，讨论如何从AI行业的噪声中提取有价值信号，以洞察行业趋势。",
        "category": "行业",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "AI",
          "Industry",
          "Signals",
          "Noise",
          "Hacker News"
        ]
      },
      "analyzed_at": "2026-01-03T22:54:03.180487Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "d2fc329186c71f14",
      "title": "Execution Control Layer: a reference architecture for AI agents",
      "url": "https://github.com/Rick-Kirby/execution-control-layer/releases/tag/v1.1.0",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T21:34:36Z",
      "summary": "Article URL: https://github.com/Rick-Kirby/execution-control-layer/releases/tag/v1.1.0\nComments URL: https://news.ycombinator.com/item?id=46481850\nPoints: 2\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Rick-Kirby 在 GitHub 上发布了 Execution Control Layer 的参考架构，旨在为 AI 代理的开发提供标准化的架构指南。",
        "category": "开源",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "Execution Control Layer",
          "AI代理",
          "参考架构",
          "GitHub",
          "Rick-Kirby"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:44.533914Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "dcd20b2c86fec4ca",
      "title": "Show HN: Konstantly 2.0 – AI-powered course creation for teams",
      "url": "https://konstantly.com/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T21:28:31Z",
      "summary": "Article URL: https://konstantly.com\nComments URL: https://news.ycombinator.com/item?id=46481786\nPoints: 1\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Konstantly 发布了 2.0 版本，该产品利用人工智能技术为团队提供课程创建服务，旨在提升企业培训效率。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "Konstantly",
          "AI",
          "course creation",
          "teams"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:20.853740Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "864339e1fe8a4858",
      "title": "Show HN: Fixing Robotic AI Text with a Simple Browser Extension",
      "url": "https://chromewebstore.google.com/detail/arzuno-humanizer-write-li/mcepgjnmffnlonbkmemeppjndacfomhc",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T20:52:02Z",
      "summary": "I Made Arzuno Humanizer to get rid of the ai robotic Text\n\nComments URL: https://news.ycombinator.com/item?id=46481406\nPoints: 2\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一位开发者创建了 Arzuno Humanizer 浏览器扩展，旨在通过简单工具消除 AI 生成文本的机械感，使其更自然可读。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "Arzuno Humanizer",
          "Browser Extension",
          "AI Text",
          "Robotic Text",
          "Humanizer"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:49.156506Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "5ee317798b5f1a44",
      "title": "Show HN: Fixing Robotic AI Text with a Simple Browser Extension",
      "url": "https://news.ycombinator.com/item?id=46481393",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T20:50:34Z",
      "summary": "I Made Arzuno Humanizer to get rid of the ai robotic sounding Text\n\nComments URL: https://news.ycombinator.com/item?id=46481393\nPoints: 2\n# Comments: 0",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一个开发者发布了名为Arzuno Humanizer的浏览器扩展，旨在消除AI生成文本的机器人感，使其更自然人类化。",
        "category": "开源",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "Arzuno Humanizer",
          "浏览器扩展",
          "AI文本",
          "文本人类化",
          "Show HN"
        ]
      },
      "analyzed_at": "2026-01-03T22:54:07.965308Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "1c70874f4b636701",
      "title": "Show HN: Chat with AI to create invoices instead of filling forms",
      "url": "https://www.invoce.ai/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T20:35:32Z",
      "summary": "Hey HN, I’m Atmiya.\nI built Invoce.ai because invoicing always felt unnecessarily slow and bloated.Most tools make you click through forms and settings just to send an invoice. With Invoce, you simply chat with AI, describe the work you did, and it creates a clean invoice instantly.It’s early and intentionally simple. I’m curious how others here handle invoicing today and what feels most frustrating. Happy to answer questions and hear feedback.\n\nComments URL: https://news.ycombinator.com/item?id...",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Atmiya 开发了 Invoce.ai，一个通过AI聊天生成发票的工具，用户只需描述工作内容即可即时创建发票，旨在简化传统表单填写的繁琐过程。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "Invoce.ai",
          "AI",
          "chat",
          "invoice",
          "Atmiya"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:41.901218Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "1b08c881a95f6067",
      "title": "Show HN: An authority gate for AI-generated customer communications",
      "url": "https://authority.bhaviavelayudhan.com/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T20:28:04Z",
      "summary": "Many teams now allow AI systems to draft customer-facing messages across support, CRM, and billing workflows.This introduces a specific failure mode:\nAI can generate text that constitutes an irreversible business commitment\n(refunds, credits, billing changes, contractual promises).Once emitted, the commitment exists. Detection after delivery is irrelevant.This project implements a hard authority boundary.Model\n--------\nAI systems propose messages.\nThey do not decide whether those messages are al...",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一个开源项目实现权限门控系统，用于AI生成的客户通信，防止AI自动发送构成不可逆业务承诺的消息，确保消息发送前需人工审核。",
        "category": "开源",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "权限门控",
          "AI生成",
          "客户通信",
          "业务承诺",
          "开源项目"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:22.356632Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "bf2bfa5685f7207b",
      "title": "Show HN: Vibe to Prod – Production-ready template for AI-assisted development",
      "url": "https://github.com/muyen/vibe-to-prod",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T20:10:48Z",
      "summary": "I built a production-ready full-stack template optimized for Claude Code and AI-assisted development.The problem: You can vibe code features in hours. But shipping to production takes weeks of CI/CD, security scanning, infrastructure, testing, and deployment pipelines.This template gives you the entire production stack from day one:\n- Backend: Go + Echo\n- Frontend: Next.js, Swift/iOS, Kotlin/Android\n- Infra: Google Cloud Run + Pulumi IaC\n- CI/CD: GitHub Actions with security scanning\n- Database:...",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "作者发布了名为'Vibe to Prod'的生产就绪全栈模板，专为AI辅助开发优化，特别针对Claude Code，旨在解决从快速开发到生产部署的瓶颈，加速整个流程。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "Vibe to Prod",
          "Claude Code",
          "AI-assisted development",
          "Production-ready template",
          "GitHub Actions"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:42.219012Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "f009accae047e4f2",
      "title": "2025 took AI from party tricks to production tools",
      "url": "https://quesma.com/blog/year-of-ai-2025/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T19:39:09Z",
      "summary": "Article URL: https://quesma.com/blog/year-of-ai-2025/\nComments URL: https://news.ycombinator.com/item?id=46480671\nPoints: 1\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "2025 年标志着人工智能从娱乐性应用转向实际生产工具的重要转折点，推动了 AI 技术的工业化和商业化进程。",
        "category": "行业",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "人工智能",
          "2025",
          "生产工具",
          "行业转型"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:45.863246Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "fe8aabc8abf39415",
      "title": "Ask HN: How to Handle Randomness with AI?",
      "url": "https://news.ycombinator.com/item?id=46479988",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T18:37:46Z",
      "summary": "hi,i end up making the ai (openai) chose 20 random words, then taking a random word from those and passing it to the next call to the ai.i also use the seed parameter but it keeps giving the same answers even with different seedswhat do you think?thanks,\ndorian\n\nComments URL: https://news.ycombinator.com/item?id=46479988\nPoints: 2\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一位开发者在Hacker News提问，表示在使用OpenAI API时，即使设置了不同的种子参数，模型在生成随机单词的任务中仍然输出相同答案，反映了在使用大语言模型时控制输出随机性所遇到的技术困惑。",
        "category": "LLM",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "OpenAI",
          "随机性",
          "种子参数",
          "大语言模型",
          "API"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:47.644083Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "cb4002f886a90592",
      "title": "Seedream 4.0 AI 1-Second Image Generation and Editing Studio",
      "url": "https://seedream4.me/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T18:31:11Z",
      "summary": "Article URL: https://seedream4.me/\nComments URL: https://news.ycombinator.com/item?id=46479914\nPoints: 1\n# Comments: 0",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Seedream 4.0 发布了一款 AI 图像生成和编辑工作室，声称能在 1 秒内完成图像处理和编辑，展示了 AI 图像技术的快速应用进展。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "Seedream 4.0",
          "AI Image Generation",
          "Image Editing",
          "AI Studio",
          "Rapid Generation"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:18.571499Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "ad45a705ec69f3ed",
      "title": "Show HN: RustAPI – An AI-first Rust API framework",
      "url": "https://news.ycombinator.com/item?id=46479446",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T17:50:34Z",
      "summary": "Hi HN,I’ve been working on RustAPI, an open-source Rust API framework designed with AI-first development in mind.While frameworks like Actix and Axum are powerful, I noticed that LLMs struggle with their boilerplate-heavy and rigid patterns when generating APIs. RustAPI focuses on readability, composability, and predictable structures so both humans and AI can work with it more effectively.It includes built-in OpenAPI/Swagger support and is optimized for SSE, MCP, and LLM-driven workflows.I’m sh...",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "开发者推出开源Rust API框架RustAPI，专为AI优先开发设计，旨在通过提升代码可读性与结构可预测性，解决现有框架对LLM不友好的问题，优化AI驱动的工作流。",
        "category": "开源",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "RustAPI",
          "Rust",
          "开源框架",
          "LLM",
          "API开发"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:35.222734Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "5b125f533832debb",
      "title": "The Year of the LLM Desktop",
      "url": "https://non.io/The-year-of-the-LLM-desktop",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T17:36:57Z",
      "summary": "Article URL: https://non.io/The-year-of-the-LLM-desktop\nComments URL: https://news.ycombinator.com/item?id=46479320\nPoints: 3\n# Comments: 0",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "文章预测2024年将成为“LLM桌面之年”，探讨了大型语言模型与桌面操作系统深度融合的趋势及其对个人计算体验的潜在影响。",
        "category": "LLM",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "LLM",
          "桌面",
          "AI",
          "操作系统",
          "本地AI"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:28.898880Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "f4629490fcb7b780",
      "title": "Show HN: I made a free AI tool for SWEs who struggle to land interviews",
      "url": "https://sweprofile.com/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T17:18:27Z",
      "summary": "Article URL: https://sweprofile.com\nComments URL: https://news.ycombinator.com/item?id=46479116\nPoints: 1\n# Comments: 0",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "开发者创建了一个免费的AI工具，旨在帮助软件工程师优化求职材料，以解决难以获得面试的问题，提升求职成功率。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "AI工具",
          "软件工程师",
          "面试",
          "SWEProfile",
          "免费"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:46.512565Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "0527a3417721733a",
      "title": "Show HN: Realtime Infinite Wlkpedia AI",
      "url": "https://747.run/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T17:12:52Z",
      "summary": "click any word once an hour to get new info & learn more just like Wlkpedia, every word is a URL & Ai checks all URL's every hour and writes a new article based on the URL but the Ai hallucinates sometimes, share link 2 connect with anyone, press space to chat with the Ai, realtime infinite Wlkpedia Ai\n\nComments URL: https://news.ycombinator.com/item?id=46479050\nPoints: 1\n# Comments: 2",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "开发者展示了一个实时无限的Wikipedia AI工具，用户点击任意单词可每小时获取新信息，AI检查URL并生成文章，但有时会产生幻觉；支持分享链接和与AI实时聊天。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "Realtime Infinite Wikipedia AI",
          "AI",
          "Wikipedia",
          "hallucination",
          "URL"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:18.459207Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2651e320524f01d8",
      "title": "Ilion Stateless AI Identity Framework for Semantic Alignment and Moral Integrity",
      "url": "https://ilion-project.org/",
      "source_name": "Hacker News - AI",
      "source_category": "ai",
      "language": "en",
      "published": "2026-01-03T17:04:36Z",
      "summary": "Article URL: https://ilion-project.org\nComments URL: https://news.ycombinator.com/item?id=46478943\nPoints: 1\n# Comments: 1",
      "weight": 1.0,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "Ilion项目发布了一个无状态AI身份框架，专注于语义对齐和道德完整性，旨在提升AI系统的伦理标准。",
        "category": "AI",
        "relevance_score": 0.8,
        "sentiment": "neutral",
        "keywords": [
          "Ilion",
          "无状态AI",
          "身份框架",
          "语义对齐",
          "道德完整性"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:38.237332Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "8550bb260c75e346",
      "title": "机器人也怕疼！港城突破性电子皮肤：主动痛觉+损伤自检buff拉满",
      "url": "https://www.qbitai.com/2026/01/366466.html",
      "source_name": "量子位",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T06:30:01Z",
      "summary": "把触觉转成“神经脉冲”",
      "weight": 0.85,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "香港城市大学研究团队开发突破性电子皮肤，赋予机器人主动痛觉感知和损伤自检能力，通过模拟神经脉冲实现触觉转化，提升机器人安全性和适应性。",
        "category": "AI",
        "relevance_score": 0.9,
        "sentiment": "positive",
        "keywords": [
          "电子皮肤",
          "机器人",
          "痛觉感知",
          "损伤自检",
          "神经脉冲"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:49.494727Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "1643a22dd821c81b",
      "title": "4个月烧掉30亿Token，这位「菜鸟」程序员做出50多个产品，360万人围观",
      "url": "https://www.jiqizhixin.com/articles/2026-01-04-4",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-04T01:33:38+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "一位自称「菜鸟」的程序员在4个月内消耗30亿Token，开发了50多个产品，吸引了360万人关注，展示了利用AI资源进行快速产品创新的现象。",
        "category": "LLM",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "Token",
          "程序员",
          "产品",
          "AI",
          "开发"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:02.244903Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "72f69d152e00ffff",
      "title": "陶哲轩：AI让数学进入「工业化」时代，数学家也可以是「包工头」",
      "url": "https://www.jiqizhixin.com/articles/2026-01-04",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-04T01:19:50+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "陶哲轩指出，AI技术正在推动数学研究进入工业化时代，数学家角色可能转变为管理和协调AI工具的包工头。",
        "category": "AI",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "陶哲轩",
          "AI",
          "数学",
          "工业化",
          "数学家"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:48.678523Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "5a350296ae008610",
      "title": "百度AI芯片公司冲刺IPO：出货量国产第二",
      "url": "https://www.qbitai.com/2026/01/366454.html",
      "source_name": "量子位",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T06:26:23Z",
      "summary": "比亚迪也投资了",
      "weight": 0.85,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "百度旗下的AI芯片公司正计划进行首次公开募股（IPO），其芯片出货量在国内市场排名第二。比亚迪也参与了投资。",
        "category": "行业",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "百度",
          "比亚迪",
          "AI芯片",
          "IPO",
          "出货量"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:41.989640Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "117910e5d0edb8bc",
      "title": "中信建投：量子计算产业规模有望保持高复合增长",
      "url": "https://36kr.com/newsflashes/3623403455284224?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T16:18:24+08:00",
      "summary": "中信建投研报称，量子计算有望迎来高复合增长阶段，市场增长潜力可观。根据光子盒研究院预测，量子计算有望进入高复合增长阶段，全球量子计算产业规模有望从2024年的50亿美元左右，增长至2035年的8000亿美元左右，占据量子科技近90%的份额，成为其主要增长引擎。产业链上游发展相对成熟、增长显著，下游处于产业初期，增长潜力巨大，有望从2024年的2.7亿美元，逐步增长到2035年的2026.7亿美元。量子计算招标市场聚焦上游关键设备，下游科研领域应用最为主流。（证券时报）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "中信建投和光子盒研究院预测，量子计算产业将迎来高复合增长，全球规模从2024年约50亿美元增至2035年约8000亿美元，产业链上游成熟、下游潜力巨大。",
        "category": "行业",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "量子计算",
          "中信建投",
          "光子盒研究院",
          "产业规模",
          "产业链"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:02.779151Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "d3b98a385279fd34",
      "title": "全国首单 “具身智能数据集”在江苏省数据交易所上架并完成交易",
      "url": "https://36kr.com/newsflashes/3623375084815364?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T15:27:44+08:00",
      "summary": "据南京发布，在江苏箸境智能科技有限公司数据采集室内，工作人员轻轻弯肘、抬臂、向前抓取——每一个基础动作，都被实时同步给一旁的机器人，转化为一条条结构化的数据。这些数据包含视频、关节角度与力矩参数，如同给机器注入了“肌肉记忆”。近日，由这些数据汇聚而成的“具身智能数据集”在江苏省数据交易所上架并完成交易，实现全国范围内具身智能数据集数交所交易的“零的突破”。（财联社）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "江苏箸境智能科技有限公司制作的具身智能数据集在江苏省数据交易所上架并完成交易，这是全国首例，标志着具身智能数据商业化的重要突破。",
        "category": "行业",
        "relevance_score": 0.8,
        "sentiment": "positive",
        "keywords": [
          "具身智能数据集",
          "江苏省数据交易所",
          "江苏箸境智能科技",
          "数据交易",
          "机器人"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:58.425709Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "91d506d3670947a9",
      "title": "法国对马斯克旗下聊天机器人涉嫌生成色情内容启动调查",
      "url": "https://36kr.com/newsflashes/3623285792687360?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T14:29:50+08:00",
      "summary": "法国巴黎检方2日对媒体证实，将对美国企业家马斯克旗下人工智能企业xAI的聊天机器人“格罗克(Grok)”涉嫌生成非法色情内容启动调查。“格罗克”由xAI公司开发，并内置于马斯克拥有的社交媒体平台X，X用户可直接调用该聊天机器人。近日，X平台出现部分用户利用“格罗克”编辑图片和视频的现象，部分生成的内容可以假乱真。一些用户借此生成真实人物的虚假性暴露内容，并在X平台上散播。受害者包括数百名女性和未成年人。 (新华社)",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "法国巴黎检方对马斯克旗下AI公司xAI开发的聊天机器人Grok启动调查，因其涉嫌被用户用于生成真实人物的虚假非法色情内容并传播。",
        "category": "产品",
        "relevance_score": 0.8,
        "sentiment": "negative",
        "keywords": [
          "xAI",
          "Grok",
          "马斯克",
          "生成式AI",
          "X平台"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:10.473020Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "100875a56740c2e7",
      "title": "这里还有8个“Manus”：1亿美元ARR，都是ToC",
      "url": "https://www.qbitai.com/2026/01/366495.html",
      "source_name": "量子位",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T10:10:09Z",
      "summary": "还是非Big Labs",
      "weight": 0.85,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "多个类似‘Manus’的公司或项目实现1亿美元年经常性收入，专注于面向消费者的业务，与Big Labs无关。",
        "category": "行业",
        "relevance_score": 0.5,
        "sentiment": "positive",
        "keywords": [
          "Manus",
          "ARR",
          "ToC",
          "Big Labs"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:30.468969Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "4f31fcd0b6b9fbef",
      "title": "我国规模最大全钒液流电池储能电站全容量投产运行",
      "url": "https://36kr.com/newsflashes/3623503008941061?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T17:37:52+08:00",
      "summary": "我国规模最大全钒液流电池储能电站——三峡集团新疆吉木萨尔全钒液流储能电站近日实现全容量投产运行。电站额定功率20万千瓦，储能规模100万千瓦时，预计每年可提升项目配套光伏电站利用率10%以上，最高可增发超2.3亿千瓦时的清洁电能。（财联社）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "三峡集团新疆吉木萨尔全钒液流储能电站实现全容量投产，成为我国规模最大的全钒液流电池储能电站，额定功率20万千瓦，储能规模100万千瓦时，预计每年提升配套光伏电站利用率10%以上，最高增发超2.3亿千瓦时清洁电能。",
        "category": "行业",
        "relevance_score": 0.4,
        "sentiment": "positive",
        "keywords": [
          "三峡集团",
          "全钒液流电池",
          "储能电站",
          "光伏电站",
          "清洁电能"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:22.921664Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "e163e56bf3c2a98f",
      "title": "「辍学创业」的风再次席卷硅谷，但真正的变量从来不是学位",
      "url": "https://www.jiqizhixin.com/articles/2026-01-03-6",
      "source_name": "机器之心",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T00:37:17+08:00",
      "summary": null,
      "weight": 0.9,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "硅谷再次兴起辍学创业浪潮，但新闻指出创业成功的真正变量并非学位，而是创新等关键因素，反映创业文化变化。",
        "category": "行业",
        "relevance_score": 0.3,
        "sentiment": "neutral",
        "keywords": [
          "辍学创业",
          "硅谷",
          "学位",
          "创业",
          "变量"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:13.157813Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "0b05b91fee07ddb0",
      "title": "中国“人造太阳”突破密度极限，聚变点火迎来新路径 | Science子刊",
      "url": "https://www.qbitai.com/2026/01/366477.html",
      "source_name": "量子位",
      "source_category": "ai",
      "language": "zh",
      "published": "2026-01-03T07:02:20Z",
      "summary": "成功进入“密度自由区”",
      "weight": 0.85,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "中国“人造太阳”项目突破等离子体密度极限，成功进入“密度自由区”，为可控核聚变点火开辟新路径，有望推动清洁能源技术发展。",
        "category": "其他",
        "relevance_score": 0.3,
        "sentiment": "positive",
        "keywords": [
          "人造太阳",
          "密度极限",
          "聚变点火",
          "Science子刊",
          "核聚变"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:34.343206Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "5cd690cddc93d15c",
      "title": "中信建投：2026年A股牛市有望持续 预计指数震荡上行但涨幅放缓",
      "url": "https://36kr.com/newsflashes/3623402577528067?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T16:07:31+08:00",
      "summary": "中信建投研报称，2026年A股牛市有望持续，预计指数依然震荡上行但涨幅放缓，投资者更加关注基本面改善和景气验证。应警惕科技板块结构性/阶段性回调风险，资源品很可能成为A股在科技主线后一条新的主线方向。行业重点关注：新能源、有色金属、基础化工、石油石化、非银、军工、机械设备、计算机等。主题重点关注：新材料、固态电池、商业航天、核电、两岸融合等。（第一财经）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "中信建投发布研报预测，2026年A股牛市将持续，但指数涨幅可能放缓。报告建议投资者关注基本面改善，警惕科技板块回调风险，并认为资源品可能成为新的投资主线。",
        "category": "行业",
        "relevance_score": 0.3,
        "sentiment": "neutral",
        "keywords": [
          "中信建投",
          "A股",
          "牛市",
          "科技板块",
          "资源品"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:22.002111Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "8fafe5e923165c4b",
      "title": "小米辟谣“17 Ultra徕卡版变焦环造假”：拆机内容断章取义，与事实严重不符",
      "url": "https://36kr.com/newsflashes/3623282864817154?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T14:06:53+08:00",
      "summary": "小米公司发言人官方微博发文，对小米17 Ultra徕卡版变焦环结构原理进行说明。小米表示，近日大量社交媒体账号发布视频，对某拆机博主的小米17 Ultra徕卡版拆机内容断章取义、歪曲解读，称“变焦环造假，是软件调控”。这一说法，与事实严重不符。针对相关恶意歪曲、误导性传播，原拆机博主本人已发布澄清内容。（华尔街见闻）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "小米公司官方辟谣，否认小米17 Ultra徕卡版变焦环造假传闻，指出社交媒体内容断章取义、歪曲解读。原拆机博主已发布澄清。",
        "category": "产品",
        "relevance_score": 0.3,
        "sentiment": "neutral",
        "keywords": [
          "小米",
          "小米17 Ultra徕卡版",
          "变焦环",
          "软件调控",
          "辟谣"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:19.653369Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "43fd372aa7107329",
      "title": "2025年近5000万人次旅客访港",
      "url": "https://36kr.com/newsflashes/3623504186361093?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T17:46:52+08:00",
      "summary": "香港特区政府文化体育及旅游局罗淑佩今日（1月3日）表示，2025年全年有4990万人次旅客访港，超出估算，其中74%是内地旅客，海外旅客比例增加至26%，她对数字感到满意及鼓舞。罗淑佩指出，今年特区政府将会继续推动盛事经济，包括举行明星演唱会、农历新年活动，以及国际七榄赛事等。（界面）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "香港特区政府罗淑佩表示，2025年访港旅客达4990万人次，超出估算，其中74%为内地旅客，海外旅客比例增至26%。政府将继续推动盛事经济，举办演唱会、新年活动等。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "香港",
          "旅客",
          "内地旅客",
          "海外旅客",
          "盛事经济"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:01.460664Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "2f9a2ac147fdf9a4",
      "title": "立讯精密：公司核心业务按计划正常开展，不存在影响经营与发展的异常情况",
      "url": "https://36kr.com/newsflashes/3623487788958981?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T17:22:23+08:00",
      "summary": "1月3日，立讯精密发布《关于近期不实传闻的澄清说明》称，近日，市场上出现涉及公司的不实传闻，相关内容对市场认知造成干扰。公司特此郑重说明：目前公司核心业务推进有序，按计划正常开展，不存在影响公司正常经营与发展的异常情况。公司将持续专注主业，以稳健经营和长期价值创造回馈客户、投资者及社会各界。同时，对于任何捏造事实、散布谣言、恶意损害本公司声誉的行为，公司将依法保留追究相关法律责任的权利。（界面）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "立讯精密发布澄清声明，否认市场不实传闻，强调核心业务正常开展，无经营异常，并警告追究法律责任。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "立讯精密",
          "澄清说明",
          "不实传闻",
          "核心业务",
          "经营异常"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:36.688283Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "45a395c726fd10a3",
      "title": "2025年我国批准创新药76个，对外授权破千亿美元",
      "url": "https://36kr.com/newsflashes/3623331185788163?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T14:53:02+08:00",
      "summary": "据央视新闻，记者今天从国家药监局获悉，2025年我国已批准上市的创新药达76个，大幅超过2024年全年48个，创历史新高。此外，2025年我国创新药对外授权交易总金额超过1300亿美元，授权交易数量超过150笔，同样创历史新高。据了解，2025年国家药监局批准上市的76个创新药，包括47个化学药品、23个生物制品和6个中药。47个化学药品中，38个为国产创新药，9个为进口创新药，国产创新药占比达80.85%；23个生物制品中，21个为国产创新药，2个为进口创新药，国产创新药占比达91.30%。2025年我国创新药对外授权交易总金额超过1300亿美元，授权交易数量超过150笔，远超2024年全年519亿美元和94笔，同样创历史新高。我国在研新药管线约占全球30%，位列全球第二。（央视新闻）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "2025年，中国国家药监局批准了76个创新药，对外授权交易总额超1300亿美元，均创历史新高，国产药占比高，显示医药行业创新实力增强。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "创新药",
          "国家药监局",
          "对外授权",
          "国产创新药",
          "在研管线"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:40.074305Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "a7a2adb12e1c11bc",
      "title": "飞猪：元旦出游意愿提升 人均购买件数增长20%",
      "url": "https://36kr.com/newsflashes/3623283749651720?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T14:13:47+08:00",
      "summary": "36氪获悉，1月3日，飞猪发布的《2026元旦假期出游快报》显示，元旦假期，消费者出游意愿与消费力双双提升：人均购买件数同比增长超20%、人均消费金额同比去年增长超30%。1月1日元旦当天，飞猪国内酒店预订量同比去年劲增280%，国内目的地玩乐商品预订量同比增长超270%。",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "飞猪发布元旦假期出游报告，显示消费者出游意愿提升，人均购买件数增长20%，消费金额增长30%，酒店预订量劲增280%。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "飞猪",
          "元旦假期",
          "出游",
          "酒店预订",
          "消费增长"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:49.383448Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "8b77d20cb5c7e8f0",
      "title": "北京口岸2025年出入境人员总量2140万人次，免签入境翻番",
      "url": "https://36kr.com/newsflashes/3623282309137666?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T13:53:21+08:00",
      "summary": "据“北京顺义”微信公众号消息，截至2025年12月31日，北京口岸2025年全年出入境人员总量达2140万余人次，同比增长17.4%，创下2020年以来北京口岸出入境人员量新高。\n\n从全年出入境人员量来看，外国人入出境数量增长明显，经北京口岸入出境外国人超650万人次，占出入境人员总量的30.4%，同比增长34.5%。其中享受免签和临时入境许可政策入境的外国人突破200万人次，是去年同期的1.9倍，占入境外国人员总量的60.8%。内地居民经北京口岸出入境人数同样稳步攀升，达1380万余人次，同比增长10.6%，商务出行、跨境旅游等需求持续释放。",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "北京口岸2025年出入境人员总量达2140万人次，同比增长17.4%，创2020年以来新高；其中免签入境外国人突破200万人次，是去年同期的1.9倍，反映政策促进和旅游业复苏。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "北京口岸",
          "出入境",
          "免签",
          "外国人",
          "2025年"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:20.639452Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "76544df479b6872e",
      "title": "携程：元旦假期旅游市场强劲开局，景区门票预订量增长超4倍",
      "url": "https://36kr.com/newsflashes/3623229002810371?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T13:17:06+08:00",
      "summary": "1月3日，携程最新发布的元旦旅行报告显示，2026年元旦假期，国内旅游市场迎来强劲开局，文旅消费热潮全面点燃，国内景区门票预订量同比增长超4倍，入境游相关预订亦大幅提升，掀起了2026年度首个消费热潮。（华尔街见闻）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "携程发布的元旦旅行报告显示，2026年元旦假期国内旅游市场开局强劲，景区门票预订量同比增长超4倍，入境游预订大幅提升，点燃了年度首个消费热潮。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "携程",
          "元旦假期",
          "旅游市场",
          "景区门票",
          "预订量"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:57.116751Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "d1e06c9c3b22c5fc",
      "title": "宝马中国回应30多款车型降价：并非打价格战",
      "url": "https://36kr.com/newsflashes/3623191466902528?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T13:02:55+08:00",
      "summary": "近日有消息称，宝马中国自2026年1月1日起，对旗下31款主力车型进行建议零售价调整。对此，1月3日，宝马中国方面回应称，此次调价行为是宝马调整了部分产品的官方指导价，终端价格还是由经销商自行决定，所以并不是宝马陷入价格战。（界面）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "宝马中国回应旗下31款车型降价传闻，称是调整官方指导价，终端价格由经销商决定，并非参与价格战。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "neutral",
        "keywords": [
          "宝马中国",
          "车型降价",
          "价格战",
          "官方指导价",
          "经销商"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:11.609171Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "aa88655566d3c2bd",
      "title": "2025年千亿管理人增至16家，这十只ETF规模正狂飙",
      "url": "https://36kr.com/newsflashes/3623176331707653?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T12:46:25+08:00",
      "summary": "Wind数据显示，2025年有16家基金公司ETF管理规模超千亿元，相比2024年的12家增加了4家。另外，2025年ETF管理规模排名前十位的基金公司位次出现了变化，富国基金规模排名提升2个位次，广发基金、国泰基金提升1个位次。（每经网）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "2025年ETF管理规模超千亿元的基金公司增至16家，前十排名变动，富国、广发、国泰等公司位次提升，显示ETF市场持续扩张。",
        "category": "行业",
        "relevance_score": 0.2,
        "sentiment": "positive",
        "keywords": [
          "ETF",
          "富国基金",
          "广发基金",
          "国泰基金",
          "Wind数据"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:55.832438Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "3c094ac6e333a1e6",
      "title": "元旦假期超682万游客畅游上海，实现全要素旅游消费总额122.71亿元",
      "url": "https://36kr.com/newsflashes/3623531360224261?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T18:06:42+08:00",
      "summary": "据上海旅游大数据监测，元旦假期上海共接待游客682.03万人次，实现全要素旅游消费总额122.71亿元，宾馆旅馆平均客房出租率达70%，假日文旅市场迎来“开门红”。（华尔街见闻）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "元旦假期上海接待游客682.03万人次，实现旅游消费总额122.71亿元，宾馆平均出租率达70%，文旅市场迎来开门红。",
        "category": "其他",
        "relevance_score": 0.1,
        "sentiment": "positive",
        "keywords": [
          "上海",
          "元旦假期",
          "旅游消费",
          "大数据监测",
          "文旅市场"
        ]
      },
      "analyzed_at": "2026-01-03T22:51:50.813066Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "3e65666ab97a58cf",
      "title": "2026元旦档票房破7亿元",
      "url": "https://36kr.com/newsflashes/3623432665973769?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T16:35:17+08:00",
      "summary": "据网络平台数据，截至1月3日15时56分，2026年元旦档（1月1日—1月3日）档期票房已突破7亿元，影片《疯狂动物城2》《阿凡达3》《匿杀》暂列档期票房前三名。(证券时报)",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "数据显示2026年元旦档票房突破7亿元人民币，《疯狂动物城2》《阿凡达3》《匿杀》三部影片位列档期票房前三名，反映出节假日电影市场的强劲表现。",
        "category": "行业",
        "relevance_score": 0.1,
        "sentiment": "positive",
        "keywords": [
          "2026元旦档",
          "票房",
          "7亿元",
          "疯狂动物城2",
          "阿凡达3"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:36.569374Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "a8d41a06f4acb2c8",
      "title": "元旦假期全社会跨区域人员流动量预计5.9亿人次 同比增长19.5%",
      "url": "https://36kr.com/newsflashes/3623401966404871?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T15:55:05+08:00",
      "summary": "从交通运输部获悉：1月1日至1月3日，全社会跨区域人员流动量预计5.9亿人次（日均1.98亿人次），同比（2025年1日至3日，1天假期，下同）增长19.5%。其中：铁路客运量预计4822.3万人次，日均1607.5万人次，同比增长53.1%。（财联社）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "交通运输部发布数据，预计元旦假期全社会跨区域人员流动量达5.9亿人次，同比增长19.5%，其中铁路客运量增长53.1%，反映出行需求旺盛。",
        "category": "其他",
        "relevance_score": 0.1,
        "sentiment": "positive",
        "keywords": [
          "交通运输部",
          "跨区域人员流动量",
          "元旦假期",
          "铁路客运量",
          "同比增长"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:41.909452Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "616b66dc555de924",
      "title": "我国“八纵八横”高铁网重要枢纽西安东站预计今年6月投运",
      "url": "https://36kr.com/newsflashes/3623376102900740?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T15:39:38+08:00",
      "summary": "作为国家“八纵八横”高铁网络中的重要枢纽，陕西西安东站正在加速建设。目前，这座西北地区最大的高铁站房主体结构全面完工，这个元旦假期，工程建设依然在全速推进。据了解，西安东站不仅是西安“米”字形高铁网的关键一环，更是国家“八纵八横”高铁网络中的重要枢纽——从东站延伸出的正在建设的西康高铁，正是“八纵八横”高铁通道包（银）海通道、京昆通道的重要组成部分。预计在今年6月，西安东站与西康高铁将同步投入运营。届时，西安至安康的铁路运行时间将从3小时缩至1小时内，秦巴山区将首次接入全国高铁网，关中与陕南的“1小时生活圈”也将正式形成。（财联社）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "西安东站作为国家‘八纵八横’高铁网重要枢纽，主体结构完工，预计今年6月投运。西康高铁同步运营后，西安至安康时间将缩至1小时内，秦巴山区首次接入全国高铁网。",
        "category": "其他",
        "relevance_score": 0.1,
        "sentiment": "positive",
        "keywords": [
          "西安东站",
          "八纵八横",
          "西康高铁",
          "高铁网",
          "秦巴山区"
        ]
      },
      "analyzed_at": "2026-01-03T22:53:55.641618Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "5d44ab87a4701364",
      "title": "元旦假期前两日，海南离岛免税购物金额达5.05亿元",
      "url": "https://36kr.com/newsflashes/3623329753941257?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T14:41:37+08:00",
      "summary": "据海口海关统计，元旦假期前两日：海口海关共监管海南离岛免税销售30.7万件，同比增长48.3%；购物人数达6.5万人次，同比增长60.9%；购物金额达5.05亿元，同比增长121.5%。（央视新闻）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "海口海关统计显示，元旦假期前两日海南离岛免税购物金额达5.05亿元，同比增长121.5%，购物人数和销售件数也大幅增长。",
        "category": "其他",
        "relevance_score": 0.1,
        "sentiment": "positive",
        "keywords": [
          "海南离岛免税",
          "海口海关",
          "购物金额",
          "同比增长",
          "元旦假期"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:15.821097Z",
      "analysis_status": "success",
      "analysis_error": null
    },
    {
      "id": "534464b5aa4617c7",
      "title": "印度证券监管机构出台投资银行业务新规",
      "url": "https://36kr.com/newsflashes/3623284981859588?f=rss",
      "source_name": "36氪 - AI",
      "source_category": "tech",
      "language": "zh",
      "published": "2026-01-03T14:22:02+08:00",
      "summary": "印度证券交易委员会于周五发布的一份公告显示，该机构已针对投资银行出台新规，内容涵盖提高资本充足率要求、强化合规监管措施等方面。\n现有投资银行将拥有两年过渡期，以全面落实新规要求。\n大型投资银行需在2027年1月前将资本充足率对应的最低净资产维持在2.5亿卢比，2028年1月前进一步提升至5亿卢比；\n小型投资银行则需在2027年1月前将该指标达标线设为7500万卢比，2028年1月前提升至1亿卢比。（新浪财经）",
      "weight": 0.8,
      "fetch_type": "rss",
      "company": null,
      "light_analysis": {
        "summary": "印度证券交易委员会出台针对投资银行的新规，要求提高资本充足率并强化合规监管，现有机构有两年过渡期以落实新要求。此举旨在提升行业风险抵御能力。",
        "category": "行业",
        "relevance_score": 0.1,
        "sentiment": "neutral",
        "keywords": [
          "印度证券交易委员会",
          "投资银行",
          "资本充足率",
          "合规监管",
          "净资产要求"
        ]
      },
      "analyzed_at": "2026-01-03T22:52:26.102131Z",
      "analysis_status": "success",
      "analysis_error": null
    }
  ],
  "stats": {
    "total_papers": 244,
    "papers_by_category": {
      "cs.CV": 88,
      "cs.LG": 53,
      "cs.CL": 75,
      "cs.AI": 28
    },
    "total_news": 56,
    "news_by_category": {
      "行业": 20,
      "AI": 13,
      "LLM": 4,
      "产品": 10,
      "开源": 4,
      "其他": 5
    },
    "top_keywords": [
      "Large Language Model",
      "Reinforcement Learning",
      "Diffusion Models",
      "Contrastive Learning",
      "AI",
      "Retrieval-Augmented Generation",
      "Foundation Models",
      "Fine-tuning",
      "Vision-Language Model",
      "Benchmarking"
    ]
  },
  "generated_at": "2026-01-04T06:57:20.788506"
}