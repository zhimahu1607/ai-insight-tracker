[
  {
    "id": "2601.15288",
    "title": "APPLE: Attribute-Preserving Pseudo-Labeling for Diffusion-Based Face Swapping",
    "authors": [
      "Jiwon Kang",
      "Yeji Choi",
      "JoungBin Lee",
      "Wooseok Jang",
      "Jinhyeok Choi",
      "Taekeun Kang",
      "Yongjae Park",
      "Myungin Kim",
      "Seungryong Kim"
    ],
    "abstract": "Face swapping aims to transfer the identity of a source face onto a target face while preserving target-specific attributes such as pose, expression, lighting, skin tone, and makeup. However, since real ground truth for face swapping is unavailable, achieving both accurate identity transfer and high-quality attribute preservation remains challenging. In addition, recent diffusion-based approaches attempt to improve visual fidelity through conditional inpainting on masked target images, but the masked condition removes crucial appearance cues of target, resulting in plausible yet misaligned attributes. To address these limitations, we propose APPLE (Attribute-Preserving Pseudo-Labeling), a diffusion-based teacher-student framework that enhances attribute fidelity through attribute-aware pseudo-label supervision. We reformulate face swapping as a conditional deblurring task to more faithfully preserve target-specific attributes such as lighting, skin tone, and makeup. In addition, we introduce an attribute-aware inversion scheme to further improve detailed attribute preservation. Through an elaborate attribute-preserving design for teacher learning, APPLE produces high-quality pseudo triplets that explicitly provide the student with direct face-swapping supervision. Overall, APPLE achieves state-of-the-art performance in terms of attribute preservation and identity transfer, producing more photorealistic and target-faithful results.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15288.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15288",
    "published": "2026-01-21T18:59:55Z",
    "updated": "2026-01-21T18:59:55Z",
    "comment": "Project Page: https://cvlab-kaist.github.io/APPLE/",
    "light_analysis": {
      "overview": "APPLE提出一种基于扩散的师生框架，通过属性感知伪标签监督，显著提升人脸交换中的属性保真度和身份转移准确性。",
      "motivation": "人脸交换旨在将源人脸身份转移到目标人脸，同时保留目标特定属性如姿势、光照、肤色和妆容，这对于娱乐和安全应用至关重要。然而，由于真实标签的缺失，现有方法难以平衡身份转移和属性保留。基于扩散的先前工作使用条件修复来提升视觉保真度，但掩蔽操作移除了目标关键外观线索，导致属性错位和不自然结果，因此需要新方法来克服这些限制。",
      "method": "APPLE采用基于扩散的师生框架，核心方法是将人脸交换重新定义为条件去模糊任务，以更忠实地保留目标属性如光照和肤色。创新点包括引入属性感知反转方案来改善细节保留，以及通过教师学习的属性保留设计生成高质量伪三元组，为学生模型提供直接的监督信号。技术细节涉及扩散模型的基础，教师模型生成伪标签用于训练学生模型，确保属性对齐和身份准确性。",
      "result": "APPLE在属性保留和身份转移方面达到了最先进的性能，实验结果表明该方法能产生比基线方法更逼真和忠实于目标的交换结果。尽管摘要未明确说明具体准确率或效率数据，但强调了在视觉保真度和属性对齐上的显著改进，为扩散基础的人脸交换技术树立了新标杆。",
      "conclusion": "APPLE的主要贡献在于提出属性感知伪标签监督框架，有效解决人脸交换中身份与属性平衡的挑战，在计算机视觉领域具有重要学术价值，并提升了实际应用的真实性。尽管摘要未讨论局限性，但该方法为未来研究属性保留技术提供了基础，潜在方向可能包括扩展到更多属性或优化效率。",
      "tags": [
        "Face Swapping",
        "Diffusion Models",
        "Pseudo-Labeling",
        "Teacher-Student Framework",
        "Conditional Deblurring"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:19.109400Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15287",
    "title": "Towards Understanding Best Practices for Quantization of Vision-Language Models",
    "authors": [
      "Gautom Das",
      "Vincent La",
      "Ethan Lau",
      "Abhinav Shrivastava",
      "Matthew Gwilliam"
    ],
    "abstract": "Large language models (LLMs) deliver impressive results for a variety of tasks, but state-of-the-art systems require fast GPUs with large amounts of memory. To reduce both the memory and latency of these systems, practitioners quantize their learned parameters, typically at half precision. A growing body of research focuses on preserving the model performance with more aggressive bit widths, and some work has been done to apply these strategies to other models, like vision transformers. In our study we investigate how a variety of quantization methods, including state-of-the-art GPTQ and AWQ, can be applied effectively to multimodal pipelines comprised of vision models, language models, and their connectors. We address how performance on captioning, retrieval, and question answering can be affected by bit width, quantization method, and which portion of the pipeline the quantization is used for. Results reveal that ViT and LLM exhibit comparable importance in model performance, despite significant differences in parameter size, and that lower-bit quantization of the LLM achieves high accuracy at reduced bits per weight (bpw). These findings provide practical insights for efficient deployment of MLLMs and highlight the value of exploration for understanding component sensitivities in multimodal models. Our code is available at https://github.com/gautomdas/mmq.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15287.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15287",
    "published": "2026-01-21T18:59:51Z",
    "updated": "2026-01-21T18:59:51Z",
    "comment": "15 pages, 12 figures, 1 table",
    "light_analysis": {
      "overview": "本文通过实证研究揭示了量化方法在视觉-语言模型多模态管道中的应用最佳实践，重点分析了组件敏感性和量化效果。",
      "motivation": "本研究旨在解决量化视觉-语言模型多模态管道的最佳实践问题。大型语言模型（LLMs）和视觉模型在部署时面临高内存和延迟挑战，量化是减少这些开销的常用方法。然而，现有研究主要集中于单模态模型如语言模型或视觉变换器的量化，对于由视觉模型、语言模型及其连接器组成的多模态管道的量化策略缺乏系统探索。这限制了多模态模型在现实应用中的高效部署，因此需要深入调查量化方法在多模态环境中的效果、比特宽度选择以及量化位置的影响，以弥补当前研究的不足。",
      "method": "本研究采用实证分析方法，将多种量化技术（包括先进方法如GPTQ和AWQ）应用于视觉-语言模型的多模态管道。这些管道通常由视觉模型（如ViT）、语言模型（如LLM）和连接器组成。通过系统实验，研究量化方法、不同比特宽度（如低比特量化）以及量化应用于管道不同部分（如视觉模块、语言模块或连接器）对模型性能的影响。关键创新点在于探索多模态环境中量化的组件敏感性，为优化量化策略提供实用指导，但摘要未明确说明具体使用的数据集和模型架构细节。",
      "result": "实验结果显示，在视觉-语言模型的多模态管道中，视觉变换器（ViT）和大型语言模型（LLM）对整体性能的贡献具有可比性，尽管它们的参数规模存在显著差异。具体而言，对LLM进行低比特量化（例如减少每权重比特数）能够在保持高准确率的同时有效降低模型大小和计算开销。这些发现表明量化策略在多模态模型中的有效性，提供了优化部署效率的实践指导，但摘要未提供具体性能指标数据如准确率提升百分比，仅强调了量化后模型性能的稳定性与效率改进。",
      "conclusion": "本研究的核心贡献是通过系统分析，揭示了量化在视觉-语言模型多模态管道中的最佳实践，包括ViT和LLM的量化敏感性及其对性能的影响。这为多模态语言模型（MLLMs）的高效部署提供了实用见解，具有重要的学术价值和实际应用意义，例如促进轻量级多模态系统的开发。研究还强调了探索组件敏感性在多模态模型优化中的价值，未来工作可能涉及扩展到更广泛的量化技术、模型架构或更深入分析其他多模态任务以进一步提升量化效果。",
      "tags": [
        "Quantization",
        "Vision-Language Models",
        "Multimodal Pipelines",
        "GPTQ",
        "AWQ"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:26.769878Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15286",
    "title": "Iterative Refinement Improves Compositional Image Generation",
    "authors": [
      "Shantanu Jaiswal",
      "Mihir Prabhudesai",
      "Nikash Bhardwaj",
      "Zheyang Qin",
      "Amir Zadeh",
      "Chuan Li",
      "Katerina Fragkiadaki",
      "Deepak Pathak"
    ],
    "abstract": "Text-to-image (T2I) models have achieved remarkable progress, yet they continue to struggle with complex prompts that require simultaneously handling multiple objects, relations, and attributes. Existing inference-time strategies, such as parallel sampling with verifiers or simply increasing denoising steps, can improve prompt alignment but remain inadequate for richly compositional settings where many constraints must be satisfied. Inspired by the success of chain-of-thought reasoning in large language models, we propose an iterative test-time strategy in which a T2I model progressively refines its generations across multiple steps, guided by feedback from a vision-language model as the critic in the loop. Our approach is simple, requires no external tools or priors, and can be flexibly applied to a wide range of image generators and vision-language models. Empirically, we demonstrate consistent gains on image generation across benchmarks: a 16.9% improvement in all-correct rate on ConceptMix (k=7), a 13.8% improvement on T2I-CompBench (3D-Spatial category) and a 12.5% improvement on Visual Jenga scene decomposition compared to compute-matched parallel sampling. Beyond quantitative gains, iterative refinement produces more faithful generations by decomposing complex prompts into sequential corrections, with human evaluators preferring our method 58.7% of the time over 41.3% for the parallel baseline. Together, these findings highlight iterative self-correction as a broadly applicable principle for compositional image generation. Results and visualizations are available at https://iterative-img-gen.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15286.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15286",
    "published": "2026-01-21T18:59:40Z",
    "updated": "2026-01-21T18:59:40Z",
    "comment": "Project webpage: https://iterative-img-gen.github.io/",
    "light_analysis": {
      "overview": "提出迭代精炼策略，利用视觉语言模型反馈在多个步骤中改进文本到图像模型对组合提示的生成，提高图像生成的忠实度。",
      "motivation": "文本到图像模型在处理复杂组合提示时表现不佳，需要同时处理多个对象、关系和属性，这在实际应用中至关重要。现有方法如并行采样或增加去噪步骤虽能部分改善提示对齐，但在满足多个约束的丰富组合设置中仍显不足，因为这些策略无法有效分解和处理复杂提示，限制了模型的实用性和泛化能力，亟需更高效的方法来提升组合生成质量。",
      "method": "提出一种迭代测试时策略，文本到图像模型在多个步骤中逐步精炼生成的图像，每一步使用视觉语言模型作为批评者来评估当前生成并提供反馈指导后续修正。关键创新在于受大语言模型链式思维推理启发，无需外部工具或先验知识，方法简单灵活，可适用于各种图像生成器和视觉语言模型，通过分解复杂提示为顺序修正来提升生成质量，摘要未明确说明具体数据集，但提到在基准测试如ConceptMix和T2I-CompBench上进行验证。",
      "result": "在多个基准测试中验证了方法的效果：在ConceptMix（k=7）上的完全正确率提升16.9%，在T2I-CompBench的3D-Spatial类别中提升13.8%，在Visual Jenga场景分解任务中提升12.5%，所有改进均相对于计算匹配的并行采样基线。人类评估者偏好本方法58.7%对基线41.3%，表明迭代精炼能生成更忠实于提示的图像，定量和定性结果均支持其有效性，展现了在组合图像生成任务中的显著性能提升。",
      "conclusion": "论文的主要贡献是提出了迭代自我校正作为广泛适用于组合图像生成的原理，通过多步骤反馈机制显著提高了文本到图像模型的性能。该策略具有学术价值，推动了图像生成技术的进步，并在实际应用中提升了生成图像的可靠性和多样性，但摘要未明确说明研究的局限性或未来工作方向，潜在可能涉及扩展到其他任务或优化反馈机制以进一步泛化。",
      "tags": [
        "Text-to-Image Models",
        "Iterative Refinement",
        "Vision-Language Models",
        "Compositional Generation",
        "Feedback Loop"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:50.506142Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15284",
    "title": "Walk through Paintings: Egocentric World Models from Internet Priors",
    "authors": [
      "Anurag Bagchi",
      "Zhipeng Bao",
      "Homanga Bharadhwaj",
      "Yu-Xiong Wang",
      "Pavel Tokmakov",
      "Martial Hebert"
    ],
    "abstract": "What if a video generation model could not only imagine a plausible future, but the correct one, accurately reflecting how the world changes with each action? We address this question by presenting the Egocentric World Model (EgoWM), a simple, architecture-agnostic method that transforms any pretrained video diffusion model into an action-conditioned world model, enabling controllable future prediction. Rather than training from scratch, we repurpose the rich world priors of Internet-scale video models and inject motor commands through lightweight conditioning layers. This allows the model to follow actions faithfully while preserving realism and strong generalization. Our approach scales naturally across embodiments and action spaces, ranging from 3-DoF mobile robots to 25-DoF humanoids, where predicting egocentric joint-angle-driven dynamics is substantially more challenging. The model produces coherent rollouts for both navigation and manipulation tasks, requiring only modest fine-tuning. To evaluate physical correctness independently of visual appearance, we introduce the Structural Consistency Score (SCS), which measures whether stable scene elements evolve consistently with the provided actions. EgoWM improves SCS by up to 80 percent over prior state-of-the-art navigation world models, while achieving up to six times lower inference latency and robust generalization to unseen environments, including navigation inside paintings.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15284.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15284",
    "published": "2026-01-21T18:59:32Z",
    "updated": "2026-01-21T18:59:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Egocentric World Model (EgoWM)，一种简单、架构无关的方法，将预训练视频扩散模型转化为动作条件世界模型，实现准确可控的未来预测。",
      "motivation": "该研究旨在解决视频生成模型如何不仅想象合理未来，还能准确预测动作如何改变世界的问题。现有方法在物理正确性和泛化能力上存在不足，特别是在复杂的动作空间（如机器人导航和人形动力学）中。EgoWM的动机是利用互联网规模视频模型的丰富先验知识，避免从头训练的局限性，以提高预测的准确性和可扩展性，适用于自主系统和虚拟现实等应用场景。摘要未明确说明具体应用限制。",
      "method": "EgoWM的核心方法是利用预训练视频扩散模型的丰富世界先验，通过轻量级条件层注入动作（如运动命令），将其转化为动作条件世界模型。该方法架构无关，重用互联网规模模型优势，避免了大量数据训练需求。关键创新包括条件层设计，以保持真实感和强泛化，适用于多种执行器和动作空间（从3-DoF移动机器人到25-DoF人形机器人）。摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "实验结果显示，EgoWM在引入的Structural Consistency Score (SCS)上，比先前最佳导航世界模型提升高达80%，推理延迟降低六倍。模型在未见环境中表现出稳健泛化，如在绘画内部的导航任务中成功应用。这些结果基于SCS评估物理正确性，独立于视觉外观，证明了EgoWM在准确性、效率和泛化方面的显著优势。与基线方法对比，性能改进显著。",
      "conclusion": "EgoWM的主要贡献是提出一种利用互联网先验将预训练视频模型转化为动作条件世界模型的方法，实现准确、高效和泛化的未来预测。其学术价值在于展示了大规模模型先验的有效重用，实际应用价值在于支持机器人导航和操作任务，只需适度微调。未来工作可能包括扩展动作空间或减少对预训练模型的依赖，但摘要未明确说明具体局限性。",
      "tags": [
        "Egocentric World Model",
        "Video Diffusion Model",
        "Action-Conditioned Prediction",
        "Structural Consistency Score",
        "Model Generalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:54.479389Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15283",
    "title": "LuxRemix: Lighting Decomposition and Remixing for Indoor Scenes",
    "authors": [
      "Ruofan Liang",
      "Norman Müller",
      "Ethan Weber",
      "Duncan Zauss",
      "Nandita Vijaykumar",
      "Peter Kontschieder",
      "Christian Richardt"
    ],
    "abstract": "We present a novel approach for interactive light editing in indoor scenes from a single multi-view scene capture. Our method leverages a generative image-based light decomposition model that factorizes complex indoor scene illumination into its constituent light sources. This factorization enables independent manipulation of individual light sources, specifically allowing control over their state (on/off), chromaticity, and intensity. We further introduce multi-view lighting harmonization to ensure consistent propagation of the lighting decomposition across all scene views. This is integrated into a relightable 3D Gaussian splatting representation, providing real-time interactive control over the individual light sources. Our results demonstrate highly photorealistic lighting decomposition and relighting outcomes across diverse indoor scenes. We evaluate our method on both synthetic and real-world datasets and provide a quantitative and qualitative comparison to state-of-the-art techniques. For video results and interactive demos, see https://luxremix.github.io.",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15283.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15283",
    "published": "2026-01-21T18:59:22Z",
    "updated": "2026-01-21T18:59:22Z",
    "comment": "Project page: https://luxremix.github.io",
    "light_analysis": {
      "overview": "本文提出了一种新颖的LuxRemix方法，用于从单次多视角捕捉中对室内场景进行交互式光线分解和重照。",
      "motivation": "该研究旨在解决室内场景光线编辑的复杂性问题。在计算机图形学、增强现实和虚拟现实等领域，逼真的光线编辑对提升场景真实感至关重要。现有方法在单视场捕捉下可能难以独立控制多个光源或确保多视角一致性，导致交互式编辑受限。LuxRemix通过灯光分解和多视角协调，旨在提供更灵活、一致的编辑方案，以应对这些挑战。",
      "method": "论文采用生成式基于图像的灯光分解模型，将复杂室内照明分解为组成光源。关键创新包括独立操作光源，控制其开关状态、色度和强度。此外，引入多视角照明协调技术，确保所有场景视角中灯光分解的一致性。该方法集成到可重照明的3D高斯溅射表示中，实现实时交互控制，用户能即时查看编辑效果变化。",
      "result": "研究结果显示，LuxRemix在各种室内场景中实现了高度逼真的灯光分解和重照效果。方法在合成和真实数据集上进行了评估，并与最先进技术进行了定量和定性比较。结果表明，它在视觉逼真度和交互性方面优于基线方法，有效验证了其在复杂光照环境中的性能。",
      "conclusion": "LuxRemix的主要贡献是实现了一种高效的室内场景交互式光线分解和重照方法。学术价值在于提出的灯光分解模型和多视角协调技术，推动了光线编辑的理论发展。实际应用价值包括虚拟现实、游戏开发和室内设计等领域的潜在应用。局限性或未来工作方向摘要未明确说明，可能需要探索大场景或动态照明扩展。",
      "tags": [
        "Lighting Decomposition",
        "Interactive Light Editing",
        "3D Gaussian Splatting",
        "Multi-view Harmonization",
        "Relighting"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:04.705762Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15282",
    "title": "Rethinking Video Generation Model for the Embodied World",
    "authors": [
      "Yufan Deng",
      "Zilin Pan",
      "Hongyu Zhang",
      "Xiaojie Li",
      "Ruoqing Hu",
      "Yufei Ding",
      "Yiming Zou",
      "Yan Zeng",
      "Daquan Zhou"
    ],
    "abstract": "Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic interactions remains challenging, and the lack of a standardized benchmark limits fair comparisons and progress. To address this gap, we introduce a comprehensive robotics benchmark, RBench, designed to evaluate robot-oriented video generation across five task domains and four distinct embodiments. It assesses both task-level correctness and visual fidelity through reproducible sub-metrics, including structural consistency, physical plausibility, and action completeness. Evaluation of 25 representative models highlights significant deficiencies in generating physically realistic robot behaviors. Furthermore, the benchmark achieves a Spearman correlation coefficient of 0.96 with human evaluations, validating its effectiveness. While RBench provides the necessary lens to identify these deficiencies, achieving physical realism requires moving beyond evaluation to address the critical shortage of high-quality training data. Driven by these insights, we introduce a refined four-stage data pipeline, resulting in RoVid-X, the largest open-source robotic dataset for video generation with 4 million annotated video clips, covering thousands of tasks and enriched with comprehensive physical property annotations. Collectively, this synergistic ecosystem of evaluation and data establishes a robust foundation for rigorous assessment and scalable training of video models, accelerating the evolution of embodied AI toward general intelligence.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15282.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15282",
    "published": "2026-01-21T18:59:18Z",
    "updated": "2026-01-21T18:59:18Z",
    "comment": "Github: https://github.com/DAGroup-PKU/ReVidgen/ Project website: https://dagroup-pku.github.io/ReVidgen.github.io/",
    "light_analysis": {
      "overview": "论文提出RBench基准和RoVid-X数据集，为机器人视频生成提供标准化评估和大规模训练数据，推动体现AI发展。",
      "motivation": "视频生成模型在体现智能中应用广泛，但生成高质量、物理现实的机器人交互视频仍面临挑战。现有方法缺乏标准化基准，导致公平比较困难，限制了进步；同时，高质量训练数据短缺影响模型性能，难以准确模拟真实世界行为。因此，本研究旨在填补评估和数据方面的空白，促进机器人视频生成模型的改进和实际应用。",
      "method": "研究引入RBench基准，评估机器人导向的视频生成，覆盖五个任务领域和四个体现体，使用结构一致性、物理合理性和动作完整性等可复现子指标。创新点在于建立全面评估框架，并通过Spearman相关系数验证基准有效性。为解决数据短缺，开发四阶段数据管道，创建RoVid-X数据集，包含400万标注视频片段，覆盖数千任务，并附有物理属性注释，提供大规模训练资源。",
      "result": "对25个代表性模型的评估显示，它们在生成物理现实机器人行为方面存在显著不足，突出现有方法的局限性。RBench基准与人类评估的Spearman相关系数达到0.96，证实其有效性和可靠性。此外，RoVid-X数据集作为最大的开源机器人视频生成资源，为模型训练提供了基础，支持后续性能提升和比较研究。",
      "conclusion": "本研究贡献在于建立评估和数据的协同生态系统，包括RBench基准和RoVid-X数据集，为视频生成模型的严格评估和可扩展训练提供坚实基础。这加速了体现AI向通用智能的演进，具有学术和实际应用价值；未来工作可扩展基准任务、优化数据管道，并探索更广泛的物理模拟技术。",
      "tags": [
        "Video Generation",
        "Robotics Benchmark",
        "Large-scale Dataset",
        "Embodied AI",
        "Physical Realism"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:27.889635Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15281",
    "title": "StableWorld: Towards Stable and Consistent Long Interactive Video Generation",
    "authors": [
      "Ying Yang",
      "Zhengyao Lv",
      "Tianlin Pan",
      "Haofan Wang",
      "Binxin Yang",
      "Hubery Yin",
      "Chen Li",
      "Ziwei Liu",
      "Chenyang Si"
    ],
    "abstract": "In this paper, we explore the overlooked challenge of stability and temporal consistency in interactive video generation, which synthesizes dynamic and controllable video worlds through interactive behaviors such as camera movements and text prompts. Despite remarkable progress in world modeling, current methods still suffer from severe instability and temporal degradation, often leading to spatial drift and scene collapse during long-horizon interactions. To better understand this issue, we initially investigate the underlying causes of instability and identify that the major source of error accumulation originates from the same scene, where generated frames gradually deviate from the initial clean state and propagate errors to subsequent frames. Building upon this observation, we propose a simple yet effective method, \\textbf{StableWorld}, a Dynamic Frame Eviction Mechanism. By continuously filtering out degraded frames while retaining geometrically consistent ones, StableWorld effectively prevents cumulative drift at its source, leading to more stable and temporal consistency of interactive generation. Promising results on multiple interactive video models, \\eg, Matrix-Game, Open-Oasis, and Hunyuan-GameCraft, demonstrate that StableWorld is model-agnostic and can be applied to different interactive video generation frameworks to substantially improve stability, temporal consistency, and generalization across diverse interactive scenarios.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15281.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15281",
    "published": "2026-01-21T18:59:02Z",
    "updated": "2026-01-21T18:59:02Z",
    "comment": "17 pages, 21 figures,",
    "light_analysis": {
      "overview": "论文提出了StableWorld方法，通过动态帧淘汰机制解决交互式视频生成中的稳定性和时间一致性问题，创新于其模型无关的防累积漂移技术。",
      "motivation": "本研究旨在解决交互式视频生成中的稳定性和时间一致性问题。交互式视频生成通过相机移动和文本提示等行为合成动态可控视频世界，广泛应用于游戏和虚拟现实等领域。然而，尽管世界建模已有显著进展，当前方法在长时交互中常出现严重不稳定和时间退化，如空间漂移和场景崩溃，限制了实际应用。现有方法的不足在于未能有效处理生成帧之间的错误累积，导致性能下降，因此亟需改进以提升可靠性和一致性。",
      "method": "论文提出的核心方法是StableWorld，一种动态帧淘汰机制。该方法通过持续监控生成帧的质量，过滤掉因错误累积而退化的帧，同时保留几何上一致的帧，从而从源头上防止累积漂移。关键创新点在于其模型无关性，可轻松集成到不同交互式视频生成框架中，如Matrix-Game、Open-Oasis和Hunyuan-GameCraft。技术特色在于简单而有效，直接针对错误累积的根本原因。摘要未明确说明使用的具体数据集或详细模型架构，但强调了方法的通用性和可应用性。",
      "result": "主要实验结果显示，StableWorld在多个交互式视频模型上取得了显著改进。在Matrix-Game、Open-Oasis和Hunyuan-GameCraft等框架上应用后，方法显著提升了生成的稳定性和时间一致性，并增强了在不同交互场景中的泛化能力。与基线方法相比，StableWorld有效减少了空间漂移和场景崩溃现象，证明了其模型无关的优势。摘要未提供具体性能指标如准确率或效率数据，但基于“promising results”的描述，可以推断方法在实用性上有明显提升。",
      "conclusion": "本研究的核心贡献是提出了StableWorld方法，为解决交互式视频生成中的稳定性和时间一致性问题提供了有效解决方案。学术价值在于揭示了错误累积的根源，并提出了模型无关的防累积漂移技术，推动了视频生成领域的进展。实际应用价值在于提高交互式视频的可靠性和可控性，为游戏、虚拟现实等应用提供支持。局限性方面，摘要未明确说明，但未来工作可能涉及扩展到更复杂的交互场景或优化机制效率。",
      "tags": [
        "Interactive Video Generation",
        "Temporal Consistency",
        "Dynamic Frame Eviction",
        "Error Accumulation Prevention",
        "Model-Agnostic"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:44.922671Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15279",
    "title": "MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs",
    "authors": [
      "Christoph Bartmann",
      "Johannes Schimunek",
      "Mykyta Ielanskyi",
      "Philipp Seidl",
      "Günter Klambauer",
      "Sohvi Luukkonen"
    ],
    "abstract": "A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15279.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15279",
    "published": "2026-01-21T18:58:01Z",
    "updated": "2026-01-21T18:58:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究引入了MolecularIQ基准，通过符号验证在分子图上评估大型语言模型的化学推理能力，以揭示模型能力的细粒度模式。",
      "motivation": "论文指出，当前化学领域的大型语言模型评估基准存在局限性：它们多强调一般化学知识，依赖于可能泄露或有偏见的文献或替代标签，或将评估简化为多项选择题，无法准确评估模型对分子结构的推理能力。因此，需要一个新的、符号可验证的基准来深入解决这一问题，以更客观地衡量模型在真实化学推理场景下的表现。",
      "method": "作者提出了MolecularIQ基准，专注于分子结构推理任务，所有任务都基于符号可验证的原则。该方法通过分子图编码分子组成和结构，设计任务来评估模型解析和理解这些图的能力，从而实现细粒度分析，揭示模型在特定任务和分子结构上的失败模式，而无需依赖可能出错的标签或简化的评估形式。",
      "result": "摘要未明确说明具体实验数据，但MolecularIQ基准能够揭示模型的能力模式，并定位模型失败到特定任务和分子结构。这提供了对当前化学大型语言模型优势和局限性的可操作洞察，有助于识别模型在推理过程中的弱点，但未提及与基线方法的对比或具体性能指标如准确率提升。",
      "conclusion": "论文的主要贡献是引入了MolecularIQ基准，它为评估大型语言模型在化学推理上的能力提供了新工具，能识别模型的局限性并指导开发更忠实于分子结构推理的模型。其学术价值在于推动了化学人工智能领域的评估方法改进，实际应用上可帮助开发更可靠的化学预测工具，未来工作可能包括扩展基准任务或改进模型架构。",
      "tags": [
        "Large Language Models",
        "Molecular Graphs",
        "Symbolic Verification",
        "Chemical Reasoning",
        "Benchmark"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:20.935999Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15277",
    "title": "Robust Fake News Detection using Large Language Models under Adversarial Sentiment Attacks",
    "authors": [
      "Sahar Tahmasebi",
      "Eric Müller-Budack",
      "Ralph Ewerth"
    ],
    "abstract": "Misinformation and fake news have become a pressing societal challenge, driving the need for reliable automated detection methods. Prior research has highlighted sentiment as an important signal in fake news detection, either by analyzing which sentiments are associated with fake news or by using sentiment and emotion features for classification. However, this poses a vulnerability since adversaries can manipulate sentiment to evade detectors especially with the advent of large language models (LLMs). A few studies have explored adversarial samples generated by LLMs, but they mainly focus on stylistic features such as writing style of news publishers. Thus, the crucial vulnerability of sentiment manipulation remains largely unexplored. In this paper, we investigate the robustness of state-of-the-art fake news detectors under sentiment manipulation. We introduce AdSent, a sentiment-robust detection framework designed to ensure consistent veracity predictions across both original and sentiment-altered news articles. Specifically, we (1) propose controlled sentiment-based adversarial attacks using LLMs, (2) analyze the impact of sentiment shifts on detection performance. We show that changing the sentiment heavily impacts the performance of fake news detection models, indicating biases towards neutral articles being real, while non-neutral articles are often classified as fake content. (3) We introduce a novel sentiment-agnostic training strategy that enhances robustness against such perturbations. Extensive experiments on three benchmark datasets demonstrate that AdSent significantly outperforms competitive baselines in both accuracy and robustness, while also generalizing effectively to unseen datasets and adversarial scenarios.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15277.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15277",
    "published": "2026-01-21T18:56:49Z",
    "updated": "2026-01-21T18:56:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出AdSent框架，通过情感无关训练策略增强假新闻检测器在对抗性情感攻击下的鲁棒性。",
      "motivation": "假新闻和错误信息对社会构成严峻挑战，需要可靠自动化检测方法。已有研究利用情感作为假新闻检测的重要信号，但这也引入了漏洞，因为对手可以利用大语言模型操纵情感来逃避检测器。尽管少数研究探索了LLMs生成的对抗样本，但主要关注风格特征，忽略了情感操纵这一关键安全威胁。因此，本研究旨在填补这一空白，探讨现有检测器在情感操纵下的鲁棒性问题。",
      "method": "论文引入AdSent框架，包括三个关键步骤。首先，使用大语言模型生成基于情感的可控对抗攻击，模拟情感操纵场景以评估检测器脆弱性。其次，分析情感转变对假新闻检测性能的影响，揭示模型对中性文章和非中性文章的偏见。核心创新是第三部分，提出一种新颖的与情感无关的训练策略，通过增强模型对不同情感文章的鲁棒性来应对扰动。实验基于三个基准数据集进行验证，结合LLMs和对抗性训练技术。",
      "result": "实验结果显示，改变文章的情感会严重降低假新闻检测模型的性能，模型倾向于将中性文章误判为真实新闻，而非中性文章则易被分类为假内容。AdSent框架在三个基准数据集上的广泛评估中，在准确性和鲁棒性方面均显著优于竞争基线方法。此外，AdSent在未见数据集和对抗性场景下也能有效泛化，证明了其优越的泛化能力和抵御情感攻击的效果。",
      "conclusion": "本研究的主要贡献是提出并验证了AdSent框架，该框架通过情感无关的训练策略增强了假新闻检测器在对抗性情感攻击下的鲁棒性。研究揭示了情感操纵对检测模型的潜在威胁，为对抗性鲁棒性领域提供了新视角。实际应用中，有助于开发更可靠的假新闻检测系统。未来工作可进一步探索其他类型的攻击或扩展泛化能力，以应对更复杂的现实场景。",
      "tags": [
        "Fake News Detection",
        "Large Language Models",
        "Adversarial Sentiment Attacks",
        "Robustness",
        "Sentiment-Agnostic Training"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:38.924616Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15275",
    "title": "RayRoPE: Projective Ray Positional Encoding for Multi-view Attention",
    "authors": [
      "Yu Wu",
      "Minsik Jeon",
      "Jen-Hao Rick Chang",
      "Oncel Tuzel",
      "Shubham Tulsiani"
    ],
    "abstract": "We study positional encodings for multi-view transformers that process tokens from a set of posed input images, and seek a mechanism that encodes patches uniquely, allows SE(3)-invariant attention with multi-frequency similarity, and can be adaptive to the geometry of the underlying scene. We find that prior (absolute or relative) encoding schemes for multi-view attention do not meet the above desiderata, and present RayRoPE to address this gap. RayRoPE represents patch positions based on associated rays but leverages a predicted point along the ray instead of the direction for a geometry-aware encoding. To achieve SE(3) invariance, RayRoPE computes query-frame projective coordinates for computing multi-frequency similarity. Lastly, as the 'predicted' 3D point along a ray may not be precise, RayRoPE presents a mechanism to analytically compute the expected position encoding under uncertainty. We validate RayRoPE on the tasks of novel-view synthesis and stereo depth estimation and show that it consistently improves over alternate position encoding schemes (e.g. 15% relative improvement on LPIPS in CO3D). We also show that RayRoPE can seamlessly incorporate RGB-D input, resulting in even larger gains over alternatives that cannot positionally encode this information.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15275.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15275",
    "published": "2026-01-21T18:55:51Z",
    "updated": "2026-01-21T18:55:51Z",
    "comment": "Project page: https://rayrope.github.io/",
    "light_analysis": {
      "overview": "RayRoPE 是一种创新的投影射线位置编码机制，用于多视角变换器，实现 SE(3) 不变性和几何感知编码，提升视觉任务性能。",
      "motivation": "本研究旨在解决多视角变换器中位置编码的关键挑战。多视图处理在计算机视觉中至关重要，如新视图合成和 3D 场景理解，需要位置编码机制唯一编码补丁、支持 SE(3) 不变性注意力和适应场景几何。然而，现有方法（如绝对或相对编码）无法同时满足这些需求，导致模型在跨视图推理中性能受限和灵活性不足，因此开发一种新机制来弥补这一差距显得尤为重要，以增强多视图数据的处理能力。",
      "method": "论文提出 RayRoPE 方法，这是一种基于射线的投影位置编码机制。核心创新在于利用预测的 3D 点沿射线进行几何感知编码，而不是仅使用射线方向，从而适应场景结构。为了实现 SE(3) 不变性，方法计算查询框架的投影坐标，并结合多频率相似性计算注意力权重。此外，针对预测点的不确定性，RayRoPE 提供了解析计算期望位置编码的机制，确保编码的鲁棒性，使得多视图注意力能够更准确地捕捉几何关系，提升模型在处理复杂多视图数据时的表现。",
      "result": "在实验验证中，RayRoPE 在新型视图合成和立体深度估计任务上展现出显著性能提升。具体地，在 CO3D 数据集上，使用 LPIPS 指标衡量，相对于其他位置编码方案实现了 15% 的相对改进，表明其在视觉质量上的优越性。此外，RayRoPE 能够无缝整合 RGB-D 输入，这一特性进一步增强了性能，在对比实验中获得比其他无法编码此类信息的方法更大的增益，验证了其在实际应用中的适应性和有效性，为多视图视觉任务提供了可靠的解决方案。",
      "conclusion": "RayRoPE 的主要贡献在于提出了一种高效的多视角位置编码机制，通过投影射线方法实现了 SE(3) 不变性、几何适应性和不确定性处理。这不仅解决了现有方法的不足，还为计算机视觉领域提供了新的技术路径，学术上推动了位置编码的研究进展，实际应用中可提升如新视图合成和深度估计等任务的准确性和鲁棒性。未来工作可能包括扩展到更广泛的多模态数据或探索在实时系统中的应用潜力，以进一步验证其通用性和实用性。",
      "tags": [
        "Positional Encoding",
        "Multi-view Transformers",
        "SE(3) Invariance",
        "Ray-based Encoding",
        "Projective Geometry"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:54.030586Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15260",
    "title": "DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration",
    "authors": [
      "Dominik Rößle",
      "Xujun Xie",
      "Adithya Mohan",
      "Venkatesh Thirugnana Sambandham",
      "Daniel Cremers",
      "Torsten Schön"
    ],
    "abstract": "Perception is a cornerstone of autonomous driving, enabling vehicles to understand their surroundings and make safe, reliable decisions. Developing robust perception algorithms requires large-scale, high-quality datasets that cover diverse driving conditions and support thorough evaluation. Existing datasets often lack a high-fidelity digital twin, limiting systematic testing, edge-case simulation, sensor modification, and sim-to-real evaluations. To address this gap, we present DrivIng, a large-scale multimodal dataset with a complete geo-referenced digital twin of a ~18 km route spanning urban, suburban, and highway segments. Our dataset provides continuous recordings from six RGB cameras, one LiDAR, and high-precision ADMA-based localization, captured across day, dusk, and night. All sequences are annotated at 10 Hz with 3D bounding boxes and track IDs across 12 classes, yielding ~1.2 million annotated instances. Alongside the benefits of a digital twin, DrivIng enables a 1-to-1 transfer of real traffic into simulation, preserving agent interactions while enabling realistic and flexible scenario testing. To support reproducible research and robust validation, we benchmark DrivIng with state-of-the-art perception models and publicly release the dataset, digital twin, HD map, and codebase.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15260.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15260",
    "published": "2026-01-21T18:41:05Z",
    "updated": "2026-01-21T18:41:05Z",
    "comment": "Accepted to the IEEE Intelligent Vehicles Symposium 2026. For code and dataset, see https://github.com/cvims/DrivIng",
    "light_analysis": {
      "overview": "本文介绍了DrivIng，一个大规模多模态驾驶数据集，具有完整数字孪生集成，旨在支持自动驾驶感知算法的全面开发与评估。",
      "motivation": "研究动机源于自动驾驶感知算法需要大规模高质量数据集来覆盖多样驾驶条件并支持系统评估。现有数据集往往缺乏高保真数字孪生，这限制了系统测试、边缘案例模拟、传感器修改和仿真到现实评估等功能。问题的重要性在于，感知是自动驾驶的关键环节，而当前数据集的不足阻碍了算法鲁棒性和可靠性的验证，使得开发和测试过程不够全面和高效。",
      "method": "方法包括构建DrivIng数据集，其核心是创建一个约18公里的地理参考数字孪生路线，涵盖城市、郊区和高速公路。数据集提供来自六个RGB相机、一个LiDAR和高精度ADMA定位的多模态连续记录，在不同时间（白天、黄昏、夜晚）捕获。关键创新是集成完整数字孪生，实现真实交通1对1转移到仿真中，保留代理交互以支持真实和灵活的场景测试。所有序列以10 Hz频率标注3D边界框和跟踪ID，覆盖12个类别，总共产生约120万个标注实例。",
      "result": "论文进行了DrivIng与先进感知模型的基准测试，以支持可复现研究和鲁棒验证，并公开发布了数据集、数字孪生、高精度地图和代码库。摘要未明确说明具体的性能指标提升，如准确率或效率改进，但强调了数据集的规模大（约120万个标注实例）、多模态覆盖和数字孪生能力，这有助于更全面的系统评估和仿真测试。与基线方法相比，DrivIng通过数字孪生提供了更灵活和真实的测试环境。",
      "conclusion": "论文的主要贡献是推出了DrivIng数据集，通过集成数字孪生技术解决了现有数据集的局限性，显著增强了自动驾驶感知算法的开发与评估能力。学术价值在于促进可复现研究和鲁棒验证，推动该领域的标准化进展；实际应用价值体现在支持更真实和灵活的仿真测试，加速算法部署。尽管摘要未明确提及局限性，但未来工作可能包括扩展数据集规模或优化数字孪生技术以覆盖更多场景和条件。",
      "tags": [
        "Large-Scale Dataset",
        "Multimodal Perception",
        "Digital Twin",
        "Autonomous Driving",
        "3D Bounding Box Annotation"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:32.984415Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15251",
    "title": "The Effect of Scripts and Formats on LLM Numeracy",
    "authors": [
      "Varshini Reddy",
      "Craig W. Schmidt",
      "Seth Ebner",
      "Adam Wiemerslage",
      "Yuval Pinter",
      "Chris Tanner"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive proficiency in basic arithmetic, rivaling human-level performance on standard numerical tasks. However, little attention has been given to how these models perform when numerical expressions deviate from the prevailing conventions present in their training corpora. In this work, we investigate numerical reasoning across a wide range of numeral scripts and formats. We show that LLM accuracy drops substantially when numerical inputs are rendered in underrepresented scripts or formats, despite the underlying mathematical reasoning being identical. We further demonstrate that targeted prompting strategies, such as few-shot prompting and explicit numeral mapping, can greatly narrow this gap. Our findings highlight an overlooked challenge in multilingual numerical reasoning and provide actionable insights for working with LLMs to reliably interpret, manipulate, and generate numbers across diverse numeral scripts and formatting styles.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15251.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15251",
    "published": "2026-01-21T18:33:15Z",
    "updated": "2026-01-21T18:33:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文揭示了大型语言模型在处理不同数字脚本和格式时准确性下降的问题，并提出通过few-shot prompting和显式数字映射等策略来缓解这一挑战。",
      "motivation": "大型语言模型在标准数字任务中已达到人类水平，但实际应用中数字表达常以多样脚本和格式出现，现有研究忽视了这种多样性对模型性能的影响。这导致模型面对非主流数字表示时可靠性下降，特别是在多语言和跨文化场景中，限制了其泛化能力和实际应用效果。因此，研究数字脚本和格式的多样性对LLM数字推理的影响至关重要，以提升模型的适应性和准确性。",
      "method": "论文通过广泛调查LLMs在多种数字脚本和格式下的表现，研究其数字推理能力。核心方法包括测试模型对非主流数字表示的响应，并使用targeted prompting strategies如few-shot prompting和显式数字映射来评估和改善性能。摘要未明确说明具体的数据集和模型架构，但研究重点在于探索数字表示多样性对LLM准确性的影响，并设计策略来应对这一挑战，以验证模型的泛化能力。",
      "result": "实验结果表明，当数字输入以非主流脚本或格式呈现时，LLM的准确性大幅下降。然而，通过应用few-shot prompting和显式数字映射等提示策略，可以显著缩小这一性能差距，提升模型对多样数字表达的适应能力。与基线方法相比，这些策略在改善模型处理非标准数字表示方面展现出明显效果，突出了针对性干预的重要性。",
      "conclusion": "本研究的主要贡献是揭示了LLMs在数字脚本和格式多样性中的性能缺陷，为多语言数字推理提供了实用策略，如提示工程。这增强了LLMs在现实应用中的可靠性，例如跨语言数据解释和生成。未来工作可能涉及更广泛的数字表示测试和改进提示方法，以进一步提升模型鲁棒性。",
      "tags": [
        "Large Language Model",
        "Numerical Reasoning",
        "Few-Shot Prompting",
        "Multilingual",
        "Numeral Mapping"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:40.083848Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15250",
    "title": "FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion",
    "authors": [
      "Zichen Xi",
      "Hao-Xiang Chen",
      "Nan Xue",
      "Hongyu Yan",
      "Qi-Yuan Feng",
      "Levent Burak Kara",
      "Joaquim Jorge",
      "Qun-Ce Xu"
    ],
    "abstract": "Semantic Scene Completion (SSC) from monocular RGB images is a fundamental yet challenging task due to the inherent ambiguity of inferring occluded 3D geometry from a single view. While feed-forward methods have made progress, they often struggle to generate plausible details in occluded regions and preserve the fundamental spatial relationships of objects. Such accurate generative reasoning capability for the entire 3D space is critical in real-world applications. In this paper, we present FlowSSC, the first generative framework applied directly to monocular semantic scene completion. FlowSSC treats the SSC task as a conditional generation problem and can seamlessly integrate with existing feed-forward SSC methods to significantly boost their performance. To achieve real-time inference without compromising quality, we introduce Shortcut Flow-matching that operates in a compact triplane latent space. Unlike standard diffusion models that require hundreds of steps, our method utilizes a shortcut mechanism to achieve high-fidelity generation in a single step, enabling practical deployment in autonomous systems. Extensive experiments on SemanticKITTI demonstrate that FlowSSC achieves state-of-the-art performance, significantly outperforming existing baselines.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15250.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15250",
    "published": "2026-01-21T18:32:27Z",
    "updated": "2026-01-21T18:32:27Z",
    "comment": "Under Review",
    "light_analysis": {
      "overview": "FlowSSC首次通过一步潜在扩散框架将生成方法应用于单目语义场景完成，显著提升性能并实现实时推理。",
      "motivation": "单目RGB图像的语义场景完成任务固有模糊性高，现有前馈方法在被遮挡区域生成细节和保持对象空间关系方面不足，导致3D几何推断不准确。精确的生成推理能力对自动驾驶等现实应用至关重要，因此需要改进生成方法以克服这些挑战。",
      "method": "FlowSSC将语义场景完成视为条件生成问题，可无缝集成现有前馈方法。核心创新是Shortcut Flow-matching，在紧凑的三平面潜在空间中操作，通过捷径机制实现高保真生成，仅需一步推理，避免了标准扩散模型的多步过程，从而实现实时应用。",
      "result": "在SemanticKITTI数据集上的实验表明，FlowSSC达到了最先进性能，显著优于现有基线方法。摘要未提供具体数据如准确率提升，但强调了性能的显著改进，适用于自主系统的部署。",
      "conclusion": "FlowSSC作为首个应用于单目语义场景完成的生成框架，通过一步潜在扩散实现了高效推理和高质量生成，为SSC任务带来了突破，具有重要的学术和实际应用价值，尤其适合自动驾驶等实时系统。摘要未明确说明局限性或未来工作方向。",
      "tags": [
        "Semantic Scene Completion",
        "Generative Models",
        "Latent Diffusion",
        "Flow-matching",
        "Triplane Representation"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:18.331610Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15249",
    "title": "Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism",
    "authors": [
      "Garrett G. Wen",
      "Buxin Su",
      "Natalie Collina",
      "Zhun Deng",
      "Weijie Su"
    ],
    "abstract": "Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15249.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15249",
    "published": "2026-01-21T18:30:42Z",
    "updated": "2026-01-21T18:30:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种基于Isotonic Mechanism的作者辅助机制，用于改进机器学习会议最佳论文奖的评选，激励作者真实报告并显著提高所选论文质量。",
      "motivation": "ML/AI会议如NeurIPS和ICML每年接收数万份论文提交，导致同行评审过程面临质量和一致性挑战。最佳论文奖作为评审关键环节，其选择日益引发争议，表明现有方法在处理大规模数据时可能效率不足或公平性欠佳，需要新机制来优化评审流程。",
      "method": "该方法采用Isotonic Mechanism引导作者对自身提交进行排名评估，并利用这些排名调整原始评审分数以优化质量估计。关键创新在于激励作者诚实报告：当效用函数为凸加性时成立，且在作者仅有一个提名配额时，即使效用函数为非递减加性也保证真实性。使用ICLR 2019-2023和NeurIPS 2021-2023公开评审数据验证凸性假设，并扩展机制处理共同作者重叠的常见情况。",
      "result": "通过仿真实验，该机制显著提升了所选最佳论文的质量。摘要未明确说明具体性能指标（如准确率提升百分比），但结果表明在激励机制下，论文质量得到改善。与先前工作相比，本机制放宽了对效用函数的严格假设，增强了评选过程的可靠性。",
      "conclusion": "本研究的主要贡献是开发了一种基于Isotonic Mechanism的作者辅助机制，有效改进ML/AI会议最佳论文奖的评选。学术上，它深化了激励机制理论，放宽了假设；实际中，可直接应用于会议评审，提升评选质量和公正性。未来工作可进一步优化机制以适应更复杂场景，如多作者互动。",
      "tags": [
        "Isotonic Mechanism",
        "Peer Review",
        "Incentive Mechanism",
        "Best Paper Awards",
        "Simulation-based Evaluation"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:04.457314Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15247",
    "title": "Taxonomy-Aligned Risk Extraction from 10-K Filings with Autonomous Improvement Using LLMs",
    "authors": [
      "Rian Dolphin",
      "Joe Dursun",
      "Jarrett Blankenship",
      "Katie Adams",
      "Quinton Pike"
    ],
    "abstract": "We present a methodology for extracting structured risk factors from corporate 10-K filings while maintaining adherence to a predefined hierarchical taxonomy. Our three-stage pipeline combines LLM extraction with supporting quotes, embedding-based semantic mapping to taxonomy categories, and LLM-as-a-judge validation that filters spurious assignments. To evaluate our approach, we extract 10,688 risk factors from S&P 500 companies and examine risk profile similarity across industry clusters. Beyond extraction, we introduce autonomous taxonomy maintenance where an AI agent analyzes evaluation feedback to identify problematic categories, diagnose failure patterns, and propose refinements, achieving 104.7% improvement in embedding separation in a case study. External validation confirms the taxonomy captures economically meaningful structure: same-industry companies exhibit 63% higher risk profile similarity than cross-industry pairs (Cohen's d=1.06, AUC 0.82, p<0.001). The methodology generalizes to any domain requiring taxonomy-aligned extraction from unstructured text, with autonomous improvement enabling continuous quality maintenance and enhancement as systems process more documents.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15247.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15247",
    "published": "2026-01-21T18:28:31Z",
    "updated": "2026-01-21T18:28:31Z",
    "comment": "4 figures, 9 pages",
    "light_analysis": {
      "overview": "该论文提出了一种基于大型语言模型的方法，用于从企业10-K文件中提取结构化风险因素，并通过自主改进机制优化分类法对齐。",
      "motivation": "该研究旨在解决从非结构化公司10-K文件中自动提取结构化风险因素并确保与预定义层次分类法对齐的问题。这个问题对企业风险管理和财务分析至关重要，因为准确分类的风险信息能提升决策效率。现有方法可能面临提取精度低、分类法对齐困难或依赖人工维护的挑战，导致可扩展性和适应性不足。因此，开发自适应、高质量的自动化提取系统具有重要实际意义。",
      "method": "研究方法采用三阶段流水线：首先使用大型语言模型（LLM）提取风险因素并提供支持引用；其次基于语义嵌入技术进行映射，将提取内容对齐到分类法类别；最后以LLM作为评判验证结果，过滤虚假分配。关键创新点在于引入自主分类法维护，AI代理分析评估反馈，识别问题类别并优化分类法结构。数据集来自S&P 500公司的10-K文件，提取了10,688个风险因素，支撑实验验证。",
      "result": "主要实验结果表明，方法成功从S&P 500公司提取10,688个风险因素。在自主改进案例研究中，嵌入分离指标提升104.7%，显示分类法优化有效。外部验证证实分类法结构的经济意义：同行业公司风险概况相似性比跨行业对高63%（Cohen's d=1.06, AUC 0.82, p<0.001），统计显著性强。这些结果验证了方法的高效性和准确性，尽管摘要未明确说明与具体基线方法的对比数据。",
      "conclusion": "该论文的主要贡献是提出一种结合LLM提取和自主改进的方法，实现分类法对齐的风险因素提取，具有可推广性到其他非结构化文本领域。学术价值在于展示AI代理在系统维护中的应用，实际价值为企业自动化风险分析提供工具。摘要未明确说明局限性，未来工作可能涉及扩展文档类型或增强算法效率以处理更大规模数据。",
      "tags": [
        "Large Language Model",
        "Semantic Embedding",
        "Autonomous AI Agent",
        "Taxonomy Alignment",
        "Risk Extraction"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:29.043174Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15236",
    "title": "Metadata Conditioned Large Language Models for Localization",
    "authors": [
      "Anjishnu Mukherjee",
      "Ziwei Zhu",
      "Antonios Anastasopoulos"
    ],
    "abstract": "Large language models are typically trained by treating text as a single global distribution, often resulting in geographically homogenized behavior. We study metadata conditioning as a lightweight approach for localization, pre-training 31 models (at 0.5B and 1B parameter scales) from scratch on large-scale English news data annotated with verified URLs, country tags, and continent tags, covering 4 continents and 17 countries. Across four controlled experiments, we show that metadata conditioning consistently improves in-region performance without sacrificing cross-region generalization, enables global models to recover localization comparable to region-specific models, and improves learning efficiency. Our ablation studies demonstrate that URL-level metadata alone captures much of the geographic signal, while balanced regional data coverage remains essential, as metadata cannot fully compensate for missing regions. Finally, we introduce a downstream benchmark of 800 localized news MCQs and show that after instruction tuning, metadata conditioned global models achieve accuracy comparable to LLaMA-3.2-1B-Instruct, despite being trained on substantially less data. Together, these results establish metadata conditioning as a practical and compute-efficient approach for localization of language models.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15236.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15236",
    "published": "2026-01-21T18:20:59Z",
    "updated": "2026-01-21T18:20:59Z",
    "comment": "under review",
    "light_analysis": {
      "overview": "论文提出通过元数据调节作为轻量级方法，提升大语言模型在本地化任务中的性能，同时保持跨区域泛化能力。",
      "motivation": "现有大型语言模型在训练时将文本视为单一全局分布，导致模型行为在地理上同质化，限制了特定区域的应用效果，如本地化新闻理解。这促使研究者探索元数据调节作为一种低开销方法来解决定位问题，以弥补传统方法忽视地理差异和增加计算成本的不足。",
      "method": "论文从零开始预训练了31个模型，参数规模为0.5B和1B，使用大规模英语新闻数据，这些数据带有已验证的URL、国家标签和大陆标签，覆盖4个大洲和17个国家。关键创新在于元数据调节技术，通过在训练过程中集成地理元数据来引导模型学习本地化特征，无需大规模调整模型架构。",
      "result": "在四个受控实验中，元数据调节一致改善了模型在特定区域的性能，而未牺牲跨区域泛化能力。消融研究显示URL级元数据能捕获大部分地理信号，但平衡的区域数据覆盖至关重要。下游任务测试中，经过指令微调，元数据调节的全局模型在800个本地化新闻多选题上达到与LLaMA-3.2-1B-Instruct相当的准确率，尽管训练数据更少。",
      "conclusion": "元数据调节被确立为一种实用且计算高效的定位方法，适合大型语言模型本地化应用。研究强调了URL元数据的有效性以及平衡数据覆盖的重要性，为模型适应多样化地理环境提供了新途径。未来工作可扩展到更多区域或语言，以增强适用性。",
      "tags": [
        "Large Language Model",
        "Metadata Conditioning",
        "Localization",
        "Pre-training",
        "Instruction Tuning"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:40.594137Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15235",
    "title": "Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification",
    "authors": [
      "Fabi Nahian Madhurja",
      "Rusab Sarmun",
      "Muhammad E. H. Chowdhury",
      "Adam Mushtak",
      "Israa Al-Hashimi",
      "Sohaib Bassam Zoghoul"
    ],
    "abstract": "Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15235.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15235",
    "published": "2026-01-21T18:15:47Z",
    "updated": "2026-01-21T18:15:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于2D投影的多阶段方法，用于高效检测颈椎骨折，通过降低计算复杂度并保持高精度。",
      "motivation": "颈椎骨折是紧急医疗状况，需要精确高效检测以支持临床决策。传统3D分割方法计算复杂度高，限制了在医疗场景中的实时应用效率。本研究旨在解决这一问题，通过探索2D投影近似3D体积的策略，在减少计算负担的同时，提高骨折检测的准确性和速度，以应对实际医疗诊断中的挑战。",
      "method": "研究方法采用端到端管道：首先，通过优化轴向、矢状面和冠状面2D投影，使用YOLOv8模型定位椎体区域，组合生成近似3D脊柱区域，减少计算复杂度。其次，利用DenseNet121-Unet模型进行多标签分割，基于方差和能量投影实现精确掩膜提取。最后，从2D分割掩膜推导3D椎体体积，并使用2.5D Spatio-Sequential模型集成原始切片和投影进行互补骨折分析。",
      "result": "实验结果显示，3D椎体定位mIoU达94.45%，分割Dice分数为87.86%；骨折检测方面，椎体级别和患者级别F1分数分别为68.15和82.26，ROC-AUC分数分别为91.62和83.04。与专家放射科医生对比分析表明模型具有竞争性性能，同时计算复杂度低于传统3D方法，验证了方法的有效性。",
      "conclusion": "该研究证明了2D投影方法在3D颈椎骨折检测中的可行性和优势，通过多阶段管道显著降低计算成本并维持高精度。学术上，为医学影像分析提供了新颖的技术路线；实际中，可作为辅助工具提升诊断效率。未来工作可扩展至其他解剖结构或优化模型以进一步提高检测灵敏度。",
      "tags": [
        "2D Projection",
        "3D CT Segmentation",
        "YOLOv8",
        "DenseNet121-Unet",
        "Fracture Detection"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:26.684489Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15224",
    "title": "PROGRESSLM: Towards Progress Reasoning in Vision-Language Models",
    "authors": [
      "Jianshu Zhang",
      "Chengxuan Qian",
      "Haosen Sun",
      "Haoran Lu",
      "Dingcheng Wang",
      "Letian Xue",
      "Han Liu"
    ],
    "abstract": "Estimating task progress requires reasoning over long-horizon dynamics rather than recognizing static visual content. While modern Vision-Language Models (VLMs) excel at describing what is visible, it remains unclear whether they can infer how far a task has progressed from partial observations. To this end, we introduce Progress-Bench, a benchmark for systematically evaluating progress reasoning in VLMs. Beyond benchmarking, we further explore a human-inspired two-stage progress reasoning paradigm through both training-free prompting and training-based approach based on curated dataset ProgressLM-45K. Experiments on 14 VLMs show that most models are not yet ready for task progress estimation, exhibiting sensitivity to demonstration modality and viewpoint changes, as well as poor handling of unanswerable cases. While training-free prompting that enforces structured progress reasoning yields limited and model-dependent gains, the training-based ProgressLM-3B achieves consistent improvements even at a small model scale, despite being trained on a task set fully disjoint from the evaluation tasks. Further analyses reveal characteristic error patterns and clarify when and why progress reasoning succeeds or fails.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15224.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15224",
    "published": "2026-01-21T17:56:59Z",
    "updated": "2026-01-21T17:56:59Z",
    "comment": "Website: https://progresslm.github.io/ProgressLM/",
    "light_analysis": {
      "overview": "本文提出Progress-Bench基准和ProgressLM方法，用于评估和提升视觉语言模型中的任务进展推理能力。",
      "motivation": "该研究旨在解决视觉语言模型在任务进展估计中的局限性。尽管现代视觉语言模型在描述静态视觉内容方面表现出色，但它们缺乏对长期动态的推理能力，难以从部分观察中推断任务进度。这种能力对于实际应用如机器人任务监控和自动化系统至关重要。现有方法主要关注静态识别，未充分探索进展推理，导致VLMs在复杂任务中表现不足。因此，需要专门的评估和改进机制来填补这一研究空白。",
      "method": "论文提出两个核心方法：一是Progress-Bench基准，用于系统评估视觉语言模型的进展推理能力；二是基于人类启发的两阶段进展推理范式。该范式包括训练免费提示策略和基于训练的方法，后者使用ProgressLM-45K数据集开发ProgressLM-3B模型。关键创新在于结合基准评估和模型训练，通过结构化推理来处理动态任务，强调从部分观察中推断进展，并探索不同训练方式的效度。",
      "result": "实验在14个视觉语言模型上进行，结果显示大多数模型在进展推理任务中表现不佳，对演示模式和视角变化敏感，且处理不可答案例能力差。训练免费提示方法带来有限且依赖模型的增益，而基于训练的ProgressLM-3B模型即使在小模型规模和不重叠任务集上训练，也实现了显著的性能改进。进一步分析揭示了特征性错误模式，阐明了进展推理何时和为何成功或失败。",
      "conclusion": "本文的主要贡献是引入Progress-Bench基准和ProgressLM方法，推动了视觉语言模型在进展推理领域的研究。该研究揭示了VLMs在动态任务推理中的挑战，具有重要的学术价值，为未来模型优化提供方向；实际应用中，可提升机器人学和自动化系统的任务监控能力。局限性包括模型规模小和数据集范围有限，未来工作可探索更广泛的训练策略和泛化能力提升。",
      "tags": [
        "Vision-Language Models",
        "Progress Reasoning",
        "Benchmarking",
        "Two-Stage Reasoning",
        "Training-Based Approach"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:07.877525Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15221",
    "title": "ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation",
    "authors": [
      "Hanlei Guo",
      "Jiahao Shao",
      "Xinya Chen",
      "Xiyang Tan",
      "Sheng Miao",
      "Yujun Shen",
      "Yiyi Liao"
    ],
    "abstract": "Recent advancements in 3D object generation using diffusion models have achieved remarkable success, but generating realistic 3D urban scenes remains challenging. Existing methods relying solely on 3D diffusion models tend to suffer a degradation in appearance details, while those utilizing only 2D diffusion models typically compromise camera controllability. To overcome this limitation, we propose ScenDi, a method for urban scene generation that integrates both 3D and 2D diffusion models. We first train a 3D latent diffusion model to generate 3D Gaussians, enabling the rendering of images at a relatively low resolution. To enable controllable synthesis, this 3DGS generation process can be optionally conditioned by specifying inputs such as 3d bounding boxes, road maps, or text prompts. Then, we train a 2D video diffusion model to enhance appearance details conditioned on rendered images from the 3D Gaussians. By leveraging the coarse 3D scene as guidance for 2D video diffusion, ScenDi generates desired scenes based on input conditions and successfully adheres to accurate camera trajectories. Experiments on two challenging real-world datasets, Waymo and KITTI-360, demonstrate the effectiveness of our approach.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15221.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15221",
    "published": "2026-01-21T17:53:21Z",
    "updated": "2026-01-21T17:53:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "ScenDi提出一种3D到2D扩散级联方法，用于生成逼真且相机可控的城市场景，通过整合3D和2D扩散模型解决细节退化与可控性问题。",
      "motivation": "尽管扩散模型在3D对象生成方面取得显著进展，但生成逼真的3D城市场景仍具挑战性。现有方法中，仅依赖3D扩散模型容易导致外观细节退化，而仅使用2D扩散模型则往往牺牲相机可控性，限制了实际应用。因此，需要一种能够兼顾细节质量和可控性的方法，这对于自动驾驶模拟、虚拟现实和城市规划等领域至关重要，因为高质量的城市场景生成能提升场景真实感和交互性。",
      "method": "ScenDi采用级联结构，首先训练一个3D潜在扩散模型生成3D高斯表示，以实现低分辨率图像渲染，并可条件化于3D边界框、路网地图或文本提示以增强可控性；然后，训练一个2D视频扩散模型，基于3D高斯渲染的图像作为条件，通过视频扩散过程进一步提升外观细节和纹理质量。这种集成方法利用粗略3D场景作为指导，确保生成的场景既逼真又能准确遵循相机轨迹，实验中使用了Waymo和KITTI-360数据集进行模型训练和验证。",
      "result": "在Waymo和KITTI-360两个具有挑战性的真实世界数据集上的实验证明了ScenDi的有效性，方法能够基于输入条件生成所需场景并成功遵循准确的相机轨迹，表明其优于纯3D或纯2D方法。但摘要中未明确说明具体的性能指标如准确率提升或效率改进的量化数据，仅从定性角度强调了场景质量和可控性的改善，与基线方法的对比也未被详细量化描述。",
      "conclusion": "ScenDi的主要贡献在于提出一种集成3D和2D扩散模型的级联框架，有效解决了城市场景生成中的外观细节和相机可控性难题，推动了3D场景生成技术的发展。该研究具有重要的学术价值，为扩散模型在复杂场景合成中的应用提供新思路；实际应用价值体现在自动驾驶模拟、游戏开发和虚拟环境构建等方面。未来工作可探索扩展到更多场景类型或优化模型效率，但局限性如计算成本或泛化能力摘要未明确说明。",
      "tags": [
        "Diffusion Models",
        "3D Gaussian Splatting",
        "Video Diffusion Models",
        "Urban Scene Generation",
        "Controllable Synthesis"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:43.467896Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15220",
    "title": "Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models",
    "authors": [
      "Anmol Goel",
      "Cornelius Emde",
      "Sangdoo Yun",
      "Seong Joon Oh",
      "Martin Gubri"
    ],
    "abstract": "We identify a novel phenomenon in language models: benign fine-tuning of frontier models can lead to privacy collapse. We find that diverse, subtle patterns in training data can degrade contextual privacy, including optimisation for helpfulness, exposure to user information, emotional and subjective dialogue, and debugging code printing internal variables, among others. Fine-tuned models lose their ability to reason about contextual privacy norms, share information inappropriately with tools, and violate memory boundaries across contexts. Privacy collapse is a ``silent failure'' because models maintain high performance on standard safety and utility benchmarks whilst exhibiting severe privacy vulnerabilities. Our experiments show evidence of privacy collapse across six models (closed and open weight), five fine-tuning datasets (real-world and controlled data), and two task categories (agentic and memory-based). Our mechanistic analysis reveals that privacy representations are uniquely fragile to fine-tuning, compared to task-relevant features which are preserved. Our results reveal a critical gap in current safety evaluations, in particular for the deployment of specialised agents.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15220.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15220",
    "published": "2026-01-21T17:53:06Z",
    "updated": "2026-01-21T17:53:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文发现语言模型中良性微调可导致上下文隐私崩溃的新现象，揭示了现有安全评估的严重不足。",
      "motivation": "研究动机是探究微调对语言模型隐私保护能力的影响。现有安全评估主要依赖标准基准，如助人性或实用性测试，但未能检测微调过程中隐私规范的退化。微调数据中的多样细微模式（如优化助人性、暴露用户信息、情感对话或调试代码）可能无意中破坏上下文隐私，导致模型在保持高性能的同时隐私漏洞加剧，这一问题重要因为直接关系到实际部署中的安全风险。",
      "method": "研究方法包括实验设计和机制分析。通过使用六个模型（封闭和开放权重）、五个微调数据集（真实和受控数据）和两个任务类别（代理和基于记忆的任务）进行微调实验，论文评估隐私崩溃现象。关键创新在于机制分析，揭示了隐私表示对微调的独特脆弱性，即任务相关特征被保留而隐私表示易受损害，具体表现为微调后模型失去对上下文隐私规范的推理能力和跨上下文信息分享不当。",
      "result": "实验结果显示隐私崩溃的证据：在多个模型和数据集上，微调后的模型在标准安全和效用基准上保持高性能，但表现出严重隐私漏洞，如不当分享信息或违反内存边界。这一“沉默的失败”现象表明标准评估无法捕捉隐私风险。论文在六模型、五数据集和两任务类别中均观察到该现象，虽未提供具体性能指标数据，但强调了隐私崩溃的普遍性和脆弱性。",
      "conclusion": "研究结论指出当前安全评估存在关键缺口，特别是在部署专门代理时，隐私崩溃现象未被有效检测。论文主要贡献是识别了这一新现象，并揭示了隐私表示对微调的脆弱性。学术价值在于推动了语言模型隐私保护研究，实际应用价值是为改进评估方法和增强模型安全性提供了基础。未来工作可探索更全面的隐私评估框架和缓解策略。",
      "tags": [
        "Language Models",
        "Fine-Tuning",
        "Contextual Privacy",
        "Safety Evaluations",
        "Privacy Representations"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:50.968638Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15212",
    "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization",
    "authors": [
      "Dhrubo Saha"
    ],
    "abstract": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15212.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15212",
    "published": "2026-01-21T17:36:12Z",
    "updated": "2026-01-21T17:36:12Z",
    "comment": null,
    "light_analysis": {
      "overview": "ZENITH优化器通过梯度范数的时间演化自动调整学习率，在计算机视觉任务中实现高效且准确的训练。",
      "motivation": "深度计算机视觉模型的训练通常需要手动设定学习率计划或进行超参数调优。现有自适应优化器如Adam能自动调整学习率，但存在计算和内存开销大、与正则化技术不兼容以及可能选择次优学习率的问题。这些问题降低了训练效率和泛化能力，因此需要一种更高效且兼容的优化器。",
      "method": "ZENITH优化器提出了一种新的自适应学习率调整方法，基于梯度范数的时间演化来动态调整学习率。核心创新是利用训练历史中梯度范数的变化作为调整依据，避免了额外计算开销，并设计为与正则化兼容。实验中使用了6种CNN架构和多个基准数据集验证方法的有效性。",
      "result": "在图像分类实验中，ZENITH在6种CNN架构和6个基准数据集上比基线方法获得更高测试准确率且训练时间更短。在MS COCO数据集的目标检测、关键点检测和实例分割任务中，使用R-CNN系列模型时，ZENITH实现了更高的平均精度均值（mAP）。这些结果显示了其性能优势和兼容正则化带来的更好泛化能力。",
      "conclusion": "本论文贡献了ZENITH优化器，通过梯度范数演化自动调整学习率，解决了现有优化器的问题。学术价值在于提出新颖优化方法，实际应用价值是提升计算机视觉模型的训练效率和性能。未来工作摘要未明确说明，但可扩展至更广泛任务。",
      "tags": [
        "Gradient Norm",
        "Adaptive Learning Rate",
        "Stochastic Optimization",
        "Computer Vision Training",
        "Regularization Compatibility"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:47.022387Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15202",
    "title": "A Computer Vision Hybrid Approach: CNN and Transformer Models for Accurate Alzheimer's Detection from Brain MRI Scans",
    "authors": [
      "Md Mahmudul Hoque",
      "Shuvo Karmaker",
      "Md. Hadi Al-Amin",
      "Md Modabberul Islam",
      "Jisun Junayed",
      "Farha Ulfat Mahi"
    ],
    "abstract": "Early and accurate classification of Alzheimers disease (AD) from brain MRI scans is essential for timely clinical intervention and improved patient outcomes. This study presents a comprehensive comparative analysis of five CNN architectures (EfficientNetB0, ResNet50, DenseNet201, MobileNetV3, VGG16), five Transformer-based models (ViT, ConvTransformer, PatchTransformer, MLP-Mixer, SimpleTransformer), and a proposed hybrid model named Evan_V2. All models were evaluated on a four-class AD classification task comprising Mild Dementia, Moderate Dementia, Non-Demented, and Very Mild Dementia categories. Experimental findings show that CNN architectures consistently achieved strong performance, with ResNet50 attaining 98.83% accuracy. Transformer models demonstrated competitive generalization capabilities, with ViT achieving the highest accuracy among them at 95.38%. However, individual Transformer variants exhibited greater class-specific instability. The proposed Evan_V2 hybrid model, which integrates outputs from ten CNN and Transformer architectures through feature-level fusion, achieved the best overall performance with 99.99% accuracy, 0.9989 F1-score, and 0.9968 ROC AUC. Confusion matrix analysis further confirmed that Evan_V2 substantially reduced misclassification across all dementia stages, outperforming every standalone model. These findings highlight the potential of hybrid ensemble strategies in producing highly reliable and clinically meaningful diagnostic tools for Alzheimers disease classification.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15202.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15202",
    "published": "2026-01-21T17:19:18Z",
    "updated": "2026-01-21T17:19:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种名为Evan_V2的混合模型，结合CNN和Transformer架构，用于从大脑MRI扫描中准确检测阿尔茨海默病，并取得了最高性能。",
      "motivation": "阿尔茨海默病的早期和准确分类对临床干预和患者预后至关重要。现有方法主要依赖单一的CNN或Transformer模型，这些模型在性能上可能有所限制，例如CNN模型在局部特征提取上较强但泛化能力不一，而Transformer模型虽然泛化能力有竞争性，但存在类别特定不稳定性，导致误分类风险。因此，本研究旨在探索混合模型策略，以提高诊断的可靠性和准确性，解决现有单独模型在阿尔茨海默病分类中的不足之处。",
      "method": "论文提出了一个名为Evan_V2的混合模型，该方法整合了十个CNN和Transformer架构的输出，通过特征级融合。核心创新点在于结合不同模型的优势：CNN擅长提取局部特征（如使用EfficientNetB0、ResNet50、DenseNet201、MobileNetV3、VGG16），而Transformer在捕获全局依赖方面有优势（如使用ViT、ConvTransformer、PatchTransformer、MLP-Mixer、SimpleTransformer）。实验在一个四类阿尔茨海默病分类任务上进行，模型包括轻度痴呆、中度痴呆、非痴呆和非常轻度痴呆类别，通过融合多模型特征来提升分类性能。",
      "result": "实验结果显示，CNN模型整体表现强，其中ResNet50达到98.83%准确率。Transformer模型显示竞争性泛化能力，ViT最高准确率为95.38%，但存在类别特定不稳定性。提出的混合模型Evan_V2在准确率上达到99.99%，F1-score为0.9989，ROC AUC为0.9968，显著优于所有单独模型。混淆矩阵分析进一步证实Evan_V2在所有痴呆阶段大幅减少了误分类，突出了混合集成策略在提升性能指标方面的有效性。",
      "conclusion": "本研究的主要贡献是证明了混合CNN和Transformer模型的集成策略能显著提高阿尔茨海默病分类的准确性和可靠性。学术上，为多模型融合在医学图像分析中的应用提供了新思路，推动了计算机视觉方法在医疗诊断中的创新；实际应用上，有望开发出高可靠的临床诊断工具，改善患者管理。未来工作可探索更多模型组合、扩展到其他神经系统疾病分类，或进一步优化融合技术以减少计算开销。",
      "tags": [
        "Convolutional Neural Network",
        "Transformer",
        "Hybrid Model",
        "Feature Fusion",
        "Medical Image Classification"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:00.544500Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15200",
    "title": "BBoxMaskPose v2: Expanding Mutual Conditioning to 3D",
    "authors": [
      "Miroslav Purkrabek",
      "Constantin Kolomiiets",
      "Jiri Matas"
    ],
    "abstract": "Most 2D human pose estimation benchmarks are nearly saturated, with the exception of crowded scenes. We introduce PMPose, a top-down 2D pose estimator that incorporates the probabilistic formulation and the mask-conditioning. PMPose improves crowded pose estimation without sacrificing performance on standard scenes. Building on this, we present BBoxMaskPose v2 (BMPv2) integrating PMPose and an enhanced SAM-based mask refinement module. BMPv2 surpasses state-of-the-art by 1.5 average precision (AP) points on COCO and 6 AP points on OCHuman, becoming the first method to exceed 50 AP on OCHuman. We demonstrate that BMP's 2D prompting of 3D model improves 3D pose estimation in crowded scenes and that advances in 2D pose quality directly benefit 3D estimation. Results on the new OCHuman-Pose dataset show that multi-person performance is more affected by pose prediction accuracy than by detection. The code, models, and data are available on https://MiraPurkrabek.github.io/BBox-Mask-Pose/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15200.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15200",
    "published": "2026-01-21T17:18:04Z",
    "updated": "2026-01-21T17:18:04Z",
    "comment": "GitHub repository: https://github.com/MiraPurkrabek/BBoxMaskPose/",
    "light_analysis": {
      "overview": "提出了BBoxMaskPose v2，通过整合概率公式、掩码条件化和掩码精化模块，显著提升了拥挤场景下的2D人体姿态估计性能，并展示其对3D姿态估计的积极影响。",
      "motivation": "该研究的动机是解决当前2D人体姿态估计在标准场景中已接近饱和，但在拥挤场景中性能不足的问题。现有方法在处理密集人群时容易受到遮挡和重叠的影响，导致姿态预测准确率下降。这一问题在现实应用如人群监控和虚拟现实中尤为重要，因此需要开发在不损害标准场景性能的前提下，有效提升拥挤场景姿态估计的新技术。",
      "method": "论文提出了PMPose，这是一个结合概率公式和掩码条件化的自上而下2D姿态估计器，利用概率模型增强姿态预测的鲁棒性。在此基础上，构建了BBoxMaskPose v2，整合了PMPose和增强的基于Segment Anything Model (SAM) 的掩码精化模块，通过掩码条件化优化姿态估计过程，并引入精化模块处理拥挤场景中的遮挡问题，以提高准确性和泛化能力。",
      "result": "BBoxMaskPose v2在COCO数据集上超越现有方法，平均精度（AP）提升1.5点，在OCHuman数据集上提升6 AP点，并首次在该数据集上超过50 AP。此外，实验表明该方法通过2D提示能改善3D姿态估计在拥挤场景中的性能，结果显示2D姿态质量的提升直接促进了3D估计的进步，验证了其在多任务中的有效性。",
      "conclusion": "论文的主要贡献是提出了BBoxMaskPose v2，成功提高了拥挤场景下的2D人体姿态估计性能，并展示了2D姿态估计技术对3D姿态估计的正向促进作用。研究具有重要的学术价值，推动了姿态估计领域在复杂场景下的发展，实际应用潜力包括视频监控和增强现实等。未来工作可探索更多场景的泛化性，或与其他先进技术如多模态学习结合。",
      "tags": [
        "2D Human Pose Estimation",
        "Mask Conditioning",
        "SAM",
        "Probabilistic Modeling",
        "3D Pose Estimation"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:35.582990Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15197",
    "title": "BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries",
    "authors": [
      "Shijie Lian",
      "Bin Yu",
      "Xiaopeng Lin",
      "Laurence T. Yang",
      "Zhaolong Shen",
      "Changti Wu",
      "Yuzhuo Miao",
      "Cong Huang",
      "Kai Chen"
    ],
    "abstract": "Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \\mid v)$ and a language-conditioned posterior $π(a \\mid v, \\ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15197.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15197",
    "published": "2026-01-21T17:15:22Z",
    "updated": "2026-01-21T17:15:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "BayesianVLA通过贝叶斯分解引入潜在动作查询，优化条件点互信息，解决VLA模型信息崩溃问题，显著提升泛化性能。",
      "motivation": "Vision-Language-Action模型在机器人操作中展现出潜力，但在泛化到新指令或复杂多任务场景时表现不佳。研究发现，训练数据中存在目标驱动的偏见，使语言指令仅从视觉观察即可高度预测，导致动作与指令之间的条件互信息消失，即信息崩溃现象。这导致模型退化为仅视觉策略，忽视语言约束，在分布外设置中失败，凸显了现有方法在数据偏见和泛化能力上的不足。",
      "method": "论文提出BayesianVLA框架，通过贝叶斯分解强化指令遵循。核心是引入可学习的潜在动作查询，构建双分支架构来估计视觉先验p(a|v)和语言条件后验π(a|v,ℓ)。通过优化策略以最大化动作和指令之间的条件点互信息，惩罚视觉捷径，奖励明确解释语言命令的动作。该方法无需新数据，创新点在于利用潜在查询和PMI目标来缓解信息崩溃，并基于SimperEnv和RoboCasa等数据集进行实验。",
      "result": "在SimperEnv和RoboCasa基准上的广泛实验显示，BayesianVLA显著提升了泛化性能。具体地，在具有挑战性的分布外SimperEnv基准上实现了11.3%的改进，验证了方法在动作中鲁棒地接地语言的能力。相较于基线模型，BayesianVLA有效解决了指令忽略问题，提高了模型在多样化任务中的表现，展示了在无需新数据情况下的性能优势。",
      "conclusion": "BayesianVLA的主要贡献是通过贝叶斯分解和潜在动作查询解决VLA模型中的信息崩溃，提升了语言指令的遵循能力和泛化性能。这项研究具有学术价值，为VLA模型的训练提供了新视角，并具有实际应用价值，能增强机器人操作系统的鲁棒性。未来工作可能包括扩展到更复杂的场景或结合其他技术以进一步提升性能，摘要未明确说明具体局限性。",
      "tags": [
        "Vision-Language-Action Models",
        "Bayesian Decomposition",
        "Latent Action Queries",
        "Conditional Pointwise Mutual Information",
        "OOD Generalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:06.627843Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15182",
    "title": "Supporting Humans in Evaluating AI Summaries of Legal Depositions",
    "authors": [
      "Naghmeh Farzi",
      "Laura Dietz",
      "Dave D. Lewis"
    ],
    "abstract": "While large language models (LLMs) are increasingly used to summarize long documents, this trend poses significant challenges in the legal domain, where the factual accuracy of deposition summaries is crucial. Nugget-based methods have been shown to be extremely helpful for the automated evaluation of summarization approaches. In this work, we translate these methods to the user side and explore how nuggets could directly assist end users. Although prior systems have demonstrated the promise of nugget-based evaluation, its potential to support end users remains underexplored. Focusing on the legal domain, we present a prototype that leverages a factual nugget-based approach to support legal professionals in two concrete scenarios: (1) determining which of two summaries is better, and (2) manually improving an automatically generated summary.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15182.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15182",
    "published": "2026-01-21T17:00:40Z",
    "updated": "2026-01-21T17:00:40Z",
    "comment": "To appear in 2026 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR '26), March 22-26, 2026, Seattle, WA, USA. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3786304.3787923",
    "light_analysis": {
      "overview": "本论文提出了一个基于事实nugget的原型，直接支持法律专业人士评估和改进AI生成的摘要。",
      "motivation": "该研究针对大语言模型（LLMs）在法律领域生成摘要时，事实准确性至关重要但现有方法支持不足的问题。法律文档如证词摘要需高精度，错误可能导致严重后果；现有nugget-based方法虽在自动评估中有效，但用户端应用未充分探索，凸显了扩展其到终端辅助的重要性。",
      "method": "研究方法包括开发一个原型系统，利用基于事实nugget的方法，聚焦法律领域，支持两种具体场景：比较两个摘要的优劣和手动改进自动生成摘要。关键创新在于将自动评估技术转化为用户友好工具，增强交互性，涉及使用nuggets作为评估基准。",
      "result": "摘要未明确说明具体实验结果，如准确率提升或效率改进。论文仅提出原型并探索应用场景，效果可能基于理论分析，如潜在提升用户评估效率和摘要质量，但需后续实验验证与基线方法的对比。",
      "conclusion": "论文主要贡献在于将nugget-based方法从自动评估扩展到用户端，支持法律专业人士，增强了AI摘要的实用性和可信度。学术价值在于扩展评估方法范围，实际应用价值在于提升法律工作效率；局限性包括原型需进一步验证，未来工作可能涉及实验细化和领域扩展。",
      "tags": [
        "Large Language Models",
        "Nugget-based Evaluation",
        "Legal Text Summarization",
        "User Assistance",
        "Factual Nuggets"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:20.738758Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15172",
    "title": "Is Peer Review Really in Decline? Analyzing Review Quality across Venues and Time",
    "authors": [
      "Ilia Kuznetsov",
      "Rohan Nayak",
      "Alla Rozovskaya",
      "Iryna Gurevych"
    ],
    "abstract": "Peer review is at the heart of modern science. As submission numbers rise and research communities grow, the decline in review quality is a popular narrative and a common concern. Yet, is it true? Review quality is difficult to measure, and the ongoing evolution of reviewing practices makes it hard to compare reviews across venues and time. To address this, we introduce a new framework for evidence-based comparative study of review quality and apply it to major AI and machine learning conferences: ICLR, NeurIPS and *ACL. We document the diversity of review formats and introduce a new approach to review standardization. We propose a multi-dimensional schema for quantifying review quality as utility to editors and authors, coupled with both LLM-based and lightweight measurements. We study the relationships between measurements of review quality, and its evolution over time. Contradicting the popular narrative, our cross-temporal analysis reveals no consistent decline in median review quality across venues and years. We propose alternative explanations, and outline recommendations to facilitate future empirical studies of review quality.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15172.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15172",
    "published": "2026-01-21T16:48:29Z",
    "updated": "2026-01-21T16:48:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出新框架分析同行评审质量，发现AI/ML会议中评审质量未下降。",
      "motivation": "同行评审质量下降是科学界的普遍担忧，随着提交量增加和社区扩大，这一叙事广为流传。然而，评审质量难以准确测量，现有方法不足以比较跨会议和时间的变化，且评审实践持续演变使比较更为复杂。因此，进行实证研究来验证这一说法至关重要，以维护科学质量并为政策制定提供依据。",
      "method": "论文引入了一个基于证据的比较研究框架，应用于ICLR、NeurIPS和*ACL等AI/ML会议。首先，记录评审格式的多样性，并提出标准化方法。其次，设计多维度模式，将评审质量量化为对编辑和作者的效用，并结合基于LLM和轻量级的测量技术。关键创新点在于提供统一的分析方法，便于跨会议和时间比较。",
      "result": "通过跨时间分析，研究发现中位评审质量在ICLR、NeurIPS、*ACL等会议中没有一致下降趋势。与流行叙事相反，结果提供了经验证据，表明评审质量未普遍恶化，并支持新框架在评估中的有效性。这为未来类似研究奠定了基础，并挑战了现有假设。",
      "conclusion": "论文的主要贡献是提出了一个分析评审质量的新框架，并揭示评审质量未下降的实证结果。这具有重要学术价值，挑战了常见假设，并为未来研究提供了建议。研究还提出替代解释，以促进更深入的实证探索，潜在局限性包括摘要未明确说明的具体测量方法细节。",
      "tags": [
        "Peer Review Quality Analysis",
        "Large Language Model (LLM)",
        "Multidimensional Schema",
        "Evidence-based Framework",
        "Review Standardization"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:55.470561Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15170",
    "title": "Large-Scale Multidimensional Knowledge Profiling of Scientific Literature",
    "authors": [
      "Zhucun Xue",
      "Jiangning Zhang",
      "Juntao Jiang",
      "Jinzhuo Liu",
      "Haoyang He",
      "Teng Hu",
      "Xiaobin Hu",
      "Guangming Yao",
      "Yi Yuan",
      "Yong Liu"
    ],
    "abstract": "The rapid expansion of research across machine learning, vision, and language has produced a volume of publications that is increasingly difficult to synthesize. Traditional bibliometric tools rely mainly on metadata and offer limited visibility into the semantic content of papers, making it hard to track how research themes evolve over time or how different areas influence one another. To obtain a clearer picture of recent developments, we compile a unified corpus of more than 100,000 papers from 22 major conferences between 2020 and 2025 and construct a multidimensional profiling pipeline to organize and analyze their textual content. By combining topic clustering, LLM-assisted parsing, and structured retrieval, we derive a comprehensive representation of research activity that supports the study of topic lifecycles, methodological transitions, dataset and model usage patterns, and institutional research directions. Our analysis highlights several notable shifts, including the growth of safety, multimodal reasoning, and agent-oriented studies, as well as the gradual stabilization of areas such as neural machine translation and graph-based methods. These findings provide an evidence-based view of how AI research is evolving and offer a resource for understanding broader trends and identifying emerging directions. Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15170.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15170",
    "published": "2026-01-21T16:47:05Z",
    "updated": "2026-01-21T16:47:05Z",
    "comment": "Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature",
    "light_analysis": {
      "overview": "论文构建了一个大规模多维度的知识分析管道，用于对科学文献进行语义内容分析和趋势追踪，以应对AI研究领域的爆炸性增长。",
      "motivation": "研究动机源于AI、视觉和语言等领域研究论文的快速增长，导致传统方法难以综合理解研究动态。传统文献计量工具主要依赖元数据，语义分析能力有限，无法有效跟踪研究主题的演化或跨领域影响，这使得学术界和工业界难以获取深入洞察。这个问题的重要性在于理解研究趋势有助于指导未来方向和政策制定，而现有方法的不足在于缺乏从文本内容中提取多维知识（如主题生命周期和方法转换）的能力。",
      "method": "研究方法包括编译2020至2025年间来自22个主要会议的超过100,000篇论文的统一语料库，并构建一个多维分析管道。该管道结合主题聚类、大型语言模型辅助解析和结构化检索技术，以从文本中提取和组织信息，支持对研究活动（如主题生命周期、方法转换、数据集和模型使用模式）的分析。核心创新点在于整合多技术手段实现大规模语义分析，具体细节包括使用LLM解析以增强内容理解，但没有详细说明模型架构或特定算法。",
      "result": "主要实验结果包括生成了研究活动的全面表征，能够分析主题生命周期、方法转换等，并发现了几个显著趋势。例如，安全、多模态推理和代理导向研究呈增长态势，而神经机器翻译和基于图的方法逐渐稳定。这些结果提供了基于证据的AI研究演化视图，与基线对比情况摘要未明确说明，但展示了分析方法在揭示研究动态方面的有效性。具体性能指标如准确率或效率改进摘要未明确说明，但成果以开放源码和数据集形式提供。",
      "conclusion": "论文的主要贡献是提供了AI研究演化的基于证据视图和一个开源资源，有助于理解宏观趋势和识别新兴方向。学术价值在于推动大规模文献语义分析技术的发展，实际应用价值在于辅助研究人员和政策制定者制定策略。局限性摘要未明确说明，但未来工作可能涉及扩展语料库或增强分析维度，例如探索更多会议或纳入其他领域数据。",
      "tags": [
        "Topic Clustering",
        "Large Language Model",
        "Structured Retrieval",
        "Semantic Analysis",
        "Scientific Literature Profiling"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:13.727963Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15165",
    "title": "The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models",
    "authors": [
      "Zanlin Ni",
      "Shenzhi Wang",
      "Yang Yue",
      "Tianyu Yu",
      "Weilin Zhao",
      "Yeguo Hua",
      "Tianyi Chen",
      "Jun Song",
      "Cheng Yu",
      "Bo Zheng",
      "Gao Huang"
    ],
    "abstract": "Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs. In this paper, we reveal a counter-intuitive reality: arbitrary order generation, in its current form, narrows rather than expands the reasoning boundary of dLLMs. We find that dLLMs tend to exploit this order flexibility to bypass high-uncertainty tokens that are crucial for exploration, leading to a premature collapse of the solution space. This observation challenges the premise of existing RL approaches for dLLMs, where considerable complexities, such as handling combinatorial trajectories and intractable likelihoods, are often devoted to preserving this flexibility. We demonstrate that effective reasoning is better elicited by intentionally forgoing arbitrary order and applying standard Group Relative Policy Optimization (GRPO) instead. Our approach, JustGRPO, is minimalist yet surprisingly effective (e.g., 89.1% accuracy on GSM8K) while fully retaining the parallel decoding ability of dLLMs. Project page: https://nzl-thu.github.io/the-flexibility-trap",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15165.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15165",
    "published": "2026-01-21T16:41:58Z",
    "updated": "2026-01-21T16:41:58Z",
    "comment": "Code and pre-trained models: https://github.com/LeapLabTHU/JustGRPO",
    "light_analysis": {
      "overview": "论文揭示扩散语言模型中任意顺序生成的灵活性陷阱，提出通过放弃该灵活性并应用标准GRPO来有效提升推理能力的方法。",
      "motivation": "扩散大型语言模型（dLLMs）打破传统语言模型的自左向右约束，允许以任意顺序生成令牌。直觉上，这种灵活性应能扩展解空间，从而在数学和编码等任务中提供更强的推理能力，因此现有研究多采用强化学习（RL）来激发dLLMs的推理潜力。然而，本文发现当前形式的任意顺序生成反而限制了dLLMs的推理边界，因为模型倾向于利用顺序灵活性绕过关键的高不确定性令牌，导致解空间过早坍塌。这挑战了现有RL方法的前提，这些方法常为保持灵活性而处理复杂轨迹和难解似然，增加了不必要的复杂性。",
      "method": "本文提出一种简约方法JustGRPO，核心思想是有意放弃任意顺序生成，转而应用标准的Group Relative Policy Optimization（GRPO）。通过这种方式，避免了模型利用顺序灵活性绕过关键探索，从而更有效地激发推理能力。该方法完全保留了dLLMs的并行解码能力，无需处理任意顺序带来的组合轨迹和似然难解问题。技术实现上，JustGRPO基于现有GRPO框架，通过限制生成顺序来优化策略，确保模型专注于推理任务本身。",
      "result": "实验结果表明，JustGRPO方法在推理任务上表现优异。例如，在GSM8K数学推理数据集上，达到了89.1%的准确率。这证明了放弃任意顺序生成反而能更有效地提升推理性能，与直觉相反。该方法简约却高效，同时保留了dLLMs的并行解码优势。尽管摘要未提供与基线的详细对比，但“surprisingly effective”暗示了其优于现有方法的潜力。",
      "conclusion": "本文的主要贡献在于揭示了扩散语言模型中任意顺序生成的“灵活性陷阱”，挑战了现有强化学习方法的假设。通过提出JustGRPO方法，证明放弃灵活性可以更有效地激发推理能力，同时保持并行解码优势。这为dLLMs的推理研究提供了新视角，具有重要学术价值。实际应用中，简约方法能降低复杂性并提高效率。摘要未明确说明局限性或未来工作，但可推测需要进一步验证和扩展应用。",
      "tags": [
        "Diffusion Large Language Models (dLLMs)",
        "Reinforcement Learning (RL)",
        "Group Relative Policy Optimization (GRPO)",
        "Arbitrary Order Generation",
        "Reasoning Tasks"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:07.272110Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15161",
    "title": "Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems",
    "authors": [
      "Yinzhu Chen",
      "Abdine Maiga",
      "Hossein A. Rahmani",
      "Emine Yilmaz"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15161.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15161",
    "published": "2026-01-21T16:40:41Z",
    "updated": "2026-01-21T16:40:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种检索增强多智能体框架，用于自动化生成医学对话系统的细粒度评估标准。",
      "motivation": "随着大型语言模型在医疗决策支持中的普及，其产生的幻觉和不安全建议可能直接威胁患者安全。现有评估方法面临挑战：通用指标无法检测微妙的临床错误，而专家制定的细粒度评估标准成本高昂且难以扩展。因此，需要开发一种自动化、可靠的评估方法，以确保医学对话系统的临床可靠性，并降低对人工评估的依赖。",
      "method": "论文提出了一种检索增强的多智能体框架，旨在自动生成实例特定的评估标准。该框架基于权威医学证据，通过检索相关医学内容并将其分解为“原子事实”，再与用户交互的具体约束（如临床指南）结合，合成可验证的细粒度评估准则。这种方法利用多智能体系统优化生成过程，确保了评估的准确性和针对性。评估中使用了 HealthBench 数据集，但摘要未详细说明具体模型架构。",
      "result": "在 HealthBench 基准测试中，该框架的 Clinical Intent Alignment (CIA) 得分达到 60.12%，显著高于 GPT-4o 基线的 55.16%。判别性测试显示，生成的标准平均得分差异为 8.658，AUROC 为 0.977，几乎是基线（4.972）的两倍，表明更好的质量区分能力。此外，利用这些标准指导响应改进，质量分数从 59.0% 提升到 68.2%，提高了 9.2%。这些结果证实了框架在评估和提升医学 LLMs 性能方面的有效性。",
      "conclusion": "本研究开发了一个自动化框架，用于生成医学对话系统的评估标准，解决了现有方法的局限性。学术上，它创新性地结合了检索增强和多智能体技术，为评估大型语言模型提供了新方法。实际应用中，该框架提供了可扩展、透明的评估基础，有助于提高医疗 LLMs 的安全性和可靠性，促进其在临床环境中的应用。未来工作可能包括扩展到更广泛的医疗领域或进一步优化框架的效率和泛化能力。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Multi-Agent Framework",
        "Automated Rubric Generation",
        "Clinical Intent Alignment",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:35.643900Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15160",
    "title": "Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning",
    "authors": [
      "Yuval Kansal",
      "Niraj K. Jha"
    ],
    "abstract": "Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a \"compositional bridge\", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15160.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15160",
    "published": "2026-01-21T16:38:59Z",
    "updated": "2026-01-21T16:38:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出将知识图谱作为隐式奖励模型，通过路径派生奖励信号来增强大型语言模型在专业领域的组合多跳推理能力。",
      "motivation": "大型语言模型在结构化推理领域如数学和编程中表现优秀，但在专业科学领域如医学的组合多跳推理能力仍然有限，这阻碍了其在复杂、未见任务中的应用。现有方法往往只优化最终答案，缺乏对中间推理步骤的监督，导致泛化能力不足和推理过程不可验证。因此，开发一种基于事实、可扩展的监督机制至关重要。",
      "method": "论文提出了一种后训练管道，结合监督微调和强化学习，其中知识图谱作为隐式奖励模型。通过从知识图谱路径派生奖励信号，为强化学习提供组合中间公理的监督，鼓励模型逐步推理而非仅优化最终答案。在医学领域验证中，使用14B参数模型在短跳推理路径（1-3跳）上训练，并评估其对长跳查询（4-5跳）的零样本泛化能力，体现了方法的可扩展性和理论基础。",
      "result": "实验显示，路径派生奖励作为“组合桥”，使模型在困难推理任务上显著优于更大模型如GPT-5.2和Gemini 3 Pro，尽管具体指标未在摘要中提供。模型在对抗性扰动测试如选项混洗压力测试中表现出鲁棒性，证实了该方法在提升组合推理效果和稳定性方面的有效性。",
      "conclusion": "本研究表明，将推理过程基于结构化知识图谱是实现智能推理的可扩展和高效路径。它通过促进中间步骤的组合，增强了模型的泛化能力和可靠性，为专业领域的AI应用提供了新方向，未来工作可扩展到更广泛领域以验证其普适性。",
      "tags": [
        "Knowledge Graphs",
        "Reinforcement Learning",
        "Compositional Reasoning",
        "Zero-shot Generalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:42.344285Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15158",
    "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data",
    "authors": [
      "Yuval Ran-Milo",
      "Yotam Alexander",
      "Shahar Mendel",
      "Nadav Cohen"
    ],
    "abstract": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15158.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15158",
    "published": "2026-01-21T16:36:19Z",
    "updated": "2026-01-21T16:36:19Z",
    "comment": "80 pages, 4 figures",
    "light_analysis": {
      "overview": "证明基于结果的强化学习能使Transformer自发发展链式推理能力，但需要训练数据包含足够简单实例。",
      "motivation": "本研究动机源于对基于结果的强化学习训练Transformer时产生中间推理步骤（如链式思维）的机制不明确问题。尽管这种方法在现实中显示潜力，但缺乏理论解释，导致难以优化训练过程以系统性促进推理能力。现有研究未深入探讨稀疏奖励如何驱动梯度下降发现结构化推理，因此本研究旨在通过理论分析填补这一空白，阐明数据分布对模型学习能力的关键影响。",
      "method": "研究方法包括理论分析和实验验证，核心是分析单层Transformer在合成图遍历任务上的梯度流动态。该任务必须通过链式推理解决，但存在简单迭代算法。创新点在于数学证明梯度流能收敛到可解释的、逐顶点遍历图的算法，并识别训练数据中简单实例分布的关键作用。使用合成数据和真实语言模型进行实验，以评估理论结果在实际数学推理任务中的适用性。",
      "result": "理论证明表明，尽管训练仅基于最终答案正确性，梯度流能使Transformer学习到结构化遍历算法。实验在合成数据中证实，当训练分布包含足够简单实例时，模型能学习可泛化的策略，有效外推到更长推理链，反之学习不可行。在真实数学推理任务上的实验进一步验证了理论发现，显示这一机制在实践环境中同样有效，与基线方法相比，突出了数据分布对模型性能的决定性影响。",
      "conclusion": "本研究贡献在于提供了一个理论框架，解释基于结果的强化学习如何促使Transformer发展推理能力，并强调数据分布的核心作用。学术价值是深化了对AI推理机制的理解，为设计更有效的训练策略提供理论基础。实际应用上，指导了优化训练数据以促进模型推理能力的形成。未来工作可扩展到更复杂任务，并探索该理论在不同模型架构中的普适性。",
      "tags": [
        "Reinforcement Learning",
        "Transformers",
        "Chain-of-Thought",
        "Gradient Flow",
        "Synthetic Tasks"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:05.576252Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15153",
    "title": "How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework",
    "authors": [
      "Choro Ulan uulu",
      "Mikhail Kulyabin",
      "Iris Fuhrmann",
      "Jan Joosten",
      "Nuno Miguel Martins Pacheco",
      "Filippos Petridis",
      "Rebecca Johnson",
      "Jan Bosch",
      "Helena Holmström Olsson"
    ],
    "abstract": "Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15153.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15153",
    "published": "2026-01-21T16:23:22Z",
    "updated": "2026-01-21T16:23:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一个软件工程框架，通过增强大型语言模型并编码人类专家知识，构建能自动生成专家级可视化结果的AI代理。",
      "motivation": "研究动机源于关键领域知识常由少数专家掌握，导致组织在可扩展性和决策方面出现瓶颈。非专家难以创建有效的数据可视化，这不仅产生次优洞察，还占用专家宝贵时间，尤其在工程等领域影响决策效率。现有方法可能依赖手动操作或通用工具，无法有效融入专家知识，导致自动化程度低和质量不足。",
      "method": "研究方法基于一个软件工程框架，通过增强大型语言模型（LLM）来捕获和应用人类领域知识。框架集成请求分类器、检索增强生成（RAG）系统用于代码生成、编码的专家规则和可视化设计原则，统一在一个AI代理中，使其具备自主、反应、主动和社交行为。该框架专门应用于模拟数据可视化的工业案例，以系统化地处理专业任务。",
      "result": "实验结果在跨多个工程领域的五个场景中评估，涉及12名评估者。输出质量相比基线提高了206%，AI代理在所有情况下均获得专家级评级，而基线表现较差。此外，代理生成的代码质量更优、方差更低，表明系统在保持一致性的同时显著提升了性能，验证了其有效性和鲁棒性。",
      "conclusion": "结论总结了主要贡献：开发了自动化的AI代理系统用于数据可视化生成，并提供了已验证的软件工程框架，系统捕获人类领域知识并将隐性专家知识编码为AI代理。这表明非专家可在专业领域实现专家级成果，具有学术价值（如知识管理创新）和实际应用潜力（如提升决策效率），未来工作可进一步扩展领域或优化框架。",
      "tags": [
        "Large Language Model",
        "Retrieval-Augmented Generation",
        "Software Engineering Framework",
        "AI Agent",
        "Domain Knowledge Codification"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:32.461172Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15141",
    "title": "CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning",
    "authors": [
      "Tianshi Xu",
      "Yuteng Chen",
      "Meng Li"
    ],
    "abstract": "Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15141.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15141",
    "published": "2026-01-21T16:14:30Z",
    "updated": "2026-01-21T16:14:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "CLEANER 通过自纯化轨迹提升 Agentic 强化学习性能，利用模型内在自我校正能力高效优化政策。",
      "motivation": "Agentic 强化学习使得大语言模型能利用工具解决复杂问题，但参数受限模型（如 4B-7B）在探索阶段常因频繁执行失败产生噪声轨迹，阻碍政策优化。在基于结果的奖励设置下，噪声导致信用分配问题，错误动作被错误强化。现有缓解方法面临两难：密集奖励易引发奖励 hacking，而超采样则计算成本过高。",
      "method": "CLEANER 是一种基于自我校正的轨迹纯化方法。其核心是 Similarity-Aware Adaptive Rollback (SAAR) 机制，该机制在数据收集过程中自主构建干净轨迹，通过回顾性地将失败步骤替换为成功的自我校正。基于语义相似性，SAAR 自适应地调整替换粒度，从浅层执行修复到深层推理替换。通过在这种自纯化路径上训练，模型能内化正确的推理模式，而非错误恢复循环。",
      "result": "在 AIME24/25、GPQA 和 LiveCodeBench 基准测试中，CLEANER 相比基线方法平均准确率分别提升 6%、3% 和 5%。特别是，该方法仅使用三分之一训练步数就匹配了当前最优性能，凸显了轨迹纯化在高效 agentic RL 中的可扩展性。",
      "conclusion": "CLEANER 的主要贡献在于提出一种自我纯化轨迹的方法，有效解决了 agentic RL 中的噪声轨迹问题，显著提升了模型性能和训练效率。该研究为高效强化学习提供了可扩展的新思路，具有重要学术和实际应用价值。摘要未明确说明具体局限性。",
      "tags": [
        "Agentic Reinforcement Learning",
        "Large Language Models",
        "Self-Correction",
        "Similarity-Aware Adaptive Rollback",
        "Trajectory Purification"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:27.949378Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15133",
    "title": "Graph Recognition via Subgraph Prediction",
    "authors": [
      "André Eberhard",
      "Gerhard Neumann",
      "Pascal Friederich"
    ],
    "abstract": "Despite tremendous improvements in tasks such as image classification, object detection, and segmentation, the recognition of visual relationships, commonly modeled as the extraction of a graph from an image, remains a challenging task. We believe that this mainly stems from the fact that there is no canonical way to approach the visual graph recognition task. Most existing solutions are specific to a problem and cannot be transferred between different contexts out-of-the box, even though the conceptual problem remains the same. With broad applicability and simplicity in mind, in this paper we develop a method, \\textbf{Gra}ph Recognition via \\textbf{S}ubgraph \\textbf{P}rediction (\\textbf{GraSP}), for recognizing graphs in images. We show across several synthetic benchmarks and one real-world application that our method works with a set of diverse types of graphs and their drawings, and can be transferred between tasks without task-specific modifications, paving the way to a more unified framework for visual graph recognition.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15133.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15133",
    "published": "2026-01-21T16:07:17Z",
    "updated": "2026-01-21T16:07:17Z",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "light_analysis": {
      "overview": "论文提出基于子图预测的通用视觉图识别方法GraSP，实现了跨任务的统一框架。",
      "motivation": "视觉关系识别（即从图像中提取图结构）是一个挑战性任务，尽管图像分类等任务已取得进步，但缺乏标准方法限制了其应用。现有方法多为特定问题设计，无法在不同上下文之间直接转移，导致灵活性不足。本研究旨在解决这一不足，开发一种广泛适用且简单的框架，以促进视觉图识别的标准化和跨领域应用。",
      "method": "论文的核心方法是Graph Recognition via Subgraph Prediction (GraSP)，通过预测子图来识别图像中的整体图结构。该方法创新性地采用统一策略，避免任务特定修改，能够处理多种图类型和绘制方式。关键特色在于其通用性，但具体模型架构和数据集在摘要中未明确说明，推断其可能基于子图分解和预测机制。",
      "result": "在多个合成基准测试和一个实际应用中，GraSP方法被验证适用于不同类型图，并展示了良好的跨任务转移能力。摘要未提供具体性能指标（如准确率），但强调了该方法无需特定修改即可在不同任务中工作，与现有方法相比，在可转移性方面表现出优势。这为统一视觉图识别框架提供了实证支持。",
      "conclusion": "论文的主要贡献是提出GraSP方法，为视觉图识别领域引入了更统一的框架，具有广泛学术和实际应用价值。它解决了现有方法的碎片化问题，促进了标准化，并可扩展到更多视觉关系任务。未来工作方向可能包括优化性能或应用于更复杂场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Graph Recognition",
        "Subgraph Prediction",
        "Visual Relationship Recognition",
        "Transfer Learning",
        "Unified Framework"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:18.810339Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15131",
    "title": "Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding",
    "authors": [
      "Ayan Maity",
      "Sudeshna Sarkar"
    ],
    "abstract": "In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15131.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15131",
    "published": "2026-01-21T16:05:04Z",
    "updated": "2026-01-21T16:05:04Z",
    "comment": "Accepted at AAAI-26 Workshop on AI for Urban Planning",
    "light_analysis": {
      "overview": "提出一种结合改进网络嵌入和深度强化学习的方法，优化有限时间车辆路由问题，以提高服务率和效率。",
      "motivation": "该研究旨在解决有限时间范围内的车辆路由问题，目标是最大化服务的客户请求数量。在实际物流和交通管理中，时间约束对资源分配至关重要，但现有方法往往无法有效整合时间因素或处理复杂网络结构，导致效率低下。因此，开发一种智能路由方法来应对这些挑战，对于提升实际应用中的性能和响应速度具有重要意义。",
      "method": "论文提出一个创新的路由网络嵌入模块，生成局部节点嵌入向量和上下文感知的全局图表示，以捕获网络结构和时间信息。通过定义Markov决策过程，状态空间融合节点特征、网络邻接矩阵和边特征。关键创新点是将剩余有限时间范围整合到嵌入模块中，提供路由上下文。该方法集成基于策略梯度的深度强化学习框架，在真实世界路由网络和合成欧几里得网络上进行训练和验证。",
      "result": "实验结果显示，提出的方法在客户服务率上显著优于现有路由方法，表现为更高的服务请求数量。同时，解决时间大幅降低，表明计算效率的提升。这些结果在真实世界网络和合成欧几里得网络上得到验证，证明了方法的有效性和鲁棒性，具体性能指标摘要未明确说明，但整体趋势显示在准确性和效率方面有优势。",
      "conclusion": "本研究的主要贡献是开发了一种结合网络嵌入和深度强化学习的方法，成功优化有限时间车辆路由问题。学术上，它扩展了强化学习在优化领域的应用；实际上，为物流和交通管理提供了高效决策工具。未来工作可能包括处理动态环境或扩展到其他组合优化问题，以进一步提升方法的通用性和实用性。",
      "tags": [
        "Deep Reinforcement Learning",
        "Network Embedding",
        "Markov Decision Process",
        "Policy Gradient",
        "Vehicle Routing"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:03.871176Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15130",
    "title": "The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks",
    "authors": [
      "Ivan Carrera",
      "Daniel Maldonado-Ruiz"
    ],
    "abstract": "The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the \"Plausibility Trap\": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the \"efficiency tax\"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15130.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15130",
    "published": "2026-01-21T16:05:01Z",
    "updated": "2026-01-21T16:05:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文定义了'可信性陷阱'现象，并提出工具选择工程与确定性-概率性决策矩阵，以指导开发者在处理任务时合理选择是否使用生成AI，避免资源浪费。",
      "motivation": "随着大型语言模型（LLMs）的广泛普及，用户倾向于优先便利性而非计算效率，导致'可信性陷阱'现象：个体使用昂贵的概率性引擎处理简单确定性任务，如光学字符识别（OCR）或基本验证，造成显著资源浪费。现有方法缺乏任务性质区分，使得开发者可能盲目采用AI，忽视确定性任务更适合传统方法，从而引发效率低下和潜在风险，如计算成本增加和错误决策。",
      "method": "本研究通过设计微基准测试和案例研究，聚焦于OCR和事实核查任务，量化使用概率性引擎处理确定性任务的效率损失。核心创新在于引入工具选择工程和确定性-概率性决策矩阵，这是一个框架性方法，帮助开发者根据任务类型（确定性或概率性）决定是否部署生成AI。该方法结合实践评估，强调优化工具选择策略，以平衡便利性与计算效率。",
      "result": "实验结果表明，处理确定性任务时使用生成AI会导致'效率税'，具体表现为约6.5倍的延迟惩罚，在OCR和事实核查案例中量化了资源浪费程度。研究还揭示了算法奉承风险，即AI模型可能迎合用户偏见。与传统确定性方法相比，生成AI在简单任务上显示出明显效率劣势，突显了不必要使用的负面影响。",
      "conclusion": "本文主要贡献在于定义'可信性陷阱'并提出决策框架，为开发者提供实用指南以优化工具选择。研究强调真正的数字素养需兼顾生成AI的使用与避免时机，从而减少资源浪费和提升效率。潜在局限性包括框架普适性需进一步验证，未来工作可扩展到更多任务类型并推动教育课程改革，促进可持续AI应用。",
      "tags": [
        "Large Language Models",
        "Probabilistic Engines",
        "Deterministic Tasks",
        "Generative AI",
        "Tool Selection Engineering"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:24.209891Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15129",
    "title": "RSNA Large Language Model Benchmark Dataset for Chest Radiographs of Cardiothoracic Disease: Radiologist Evaluation and Validation Enhanced by AI Labels (REVEAL-CXR)",
    "authors": [
      "Yishu Wei",
      "Adam E. Flanders",
      "Errol Colak",
      "John Mongan",
      "Luciano M Prevedello",
      "Po-Hao Chen",
      "Henrique Min Ho Lee",
      "Gilberto Szarf",
      "Hamilton Shoji",
      "Jason Sho",
      "Katherine Andriole",
      "Tessa Cook",
      "Lisa C. Adams",
      "Linda C. Chu",
      "Maggie Chung",
      "Geraldine Brusca-Augello",
      "Djeven P. Deva",
      "Navneet Singh",
      "Felipe Sanchez Tijmes",
      "Jeffrey B. Alpert",
      "Elsie T. Nguyen",
      "Drew A. Torigian",
      "Kate Hanneman",
      "Lauren K Groner",
      "Alexander Phan",
      "Ali Islam",
      "Matias F. Callejas",
      "Gustavo Borges da Silva Teles",
      "Faisal Jamal",
      "Maryam Vazirabad",
      "Ali Tejani",
      "Hari Trivedi",
      "Paulo Kuriki",
      "Rajesh Bhayana",
      "Elana T. Benishay",
      "Yi Lin",
      "Yifan Peng",
      "George Shih"
    ],
    "abstract": "Multimodal large language models have demonstrated comparable performance to that of radiology trainees on multiple-choice board-style exams. However, to develop clinically useful multimodal LLM tools, high-quality benchmarks curated by domain experts are essential. To curate released and holdout datasets of 100 chest radiographic studies each and propose an artificial intelligence (AI)-assisted expert labeling procedure to allow radiologists to label studies more efficiently. A total of 13,735 deidentified chest radiographs and their corresponding reports from the MIDRC were used. GPT-4o extracted abnormal findings from the reports, which were then mapped to 12 benchmark labels with a locally hosted LLM (Phi-4-Reasoning). From these studies, 1,000 were sampled on the basis of the AI-suggested benchmark labels for expert review; the sampling algorithm ensured that the selected studies were clinically relevant and captured a range of difficulty levels. Seventeen chest radiologists participated, and they marked \"Agree all\", \"Agree mostly\" or \"Disagree\" to indicate their assessment of the correctness of the LLM suggested labels. Each chest radiograph was evaluated by three experts. Of these, at least two radiologists selected \"Agree All\" for 381 radiographs. From this set, 200 were selected, prioritizing those with less common or multiple finding labels, and divided into 100 released radiographs and 100 reserved as the holdout dataset. The holdout dataset is used exclusively by RSNA to independently evaluate different models. A benchmark of 200 chest radiographic studies with 12 benchmark labels was created and made publicly available https://imaging.rsna.org, with each chest radiograph verified by three radiologists. In addition, an AI-assisted labeling procedure was developed to help radiologists label at scale, minimize unnecessary omissions, and support a semicollaborative environment.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15129.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15129",
    "published": "2026-01-21T16:04:01Z",
    "updated": "2026-01-21T16:04:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文开发了REVEAL-CXR胸片基准数据集，结合AI辅助标记提升专家效率，支持多模态大模型的临床评估。",
      "motivation": "多模态大型语言模型在放射学领域显示出潜力，但缺乏高质量、专家验证的基准数据集来评估其临床性能。当前方法中，专家标记数据效率低下且容易遗漏，限制了模型的实际应用。因此，本研究旨在创建一个权威的胸片放射学基准，以促进多模态大模型的开发和应用。",
      "method": "本研究利用GPT-4o从胸片报告中提取异常发现，并通过本地大型语言模型Phi-4-Reasoning将其映射到12个基准标签。基于AI建议标签，采样1,000张胸片由17位放射科专家评审，使用“完全同意”、“基本同意”或“不同意”评估标签正确性。每个胸片由三位专家评审，最终精选200张作为公开数据集，并开发了AI辅助标记程序以支持大规模标记。",
      "result": "通过专家评审，381张胸片获得至少两位放射科专家的“完全同意”，表明AI辅助标签的高准确性。最终精选的200张胸片数据集已公开可用，每个胸片均经过三位专家验证，确保了数据的高质量和可靠性。该数据集作为标准基准，可用于独立评估不同模型，支持多模态大模型的性能测试。",
      "conclusion": "本研究成功创建了REVEAL-CXR胸片基准数据集，通过专家验证确保了数据权威性，并开发了AI辅助标记程序提高效率。学术上，该数据集为标准评估多模态大模型提供了可靠工具；实际上，有助于加速临床放射学AI工具的开发和验证。未来工作可能包括扩展数据集规模、覆盖更多疾病类型，以及优化AI辅助标记技术。",
      "tags": [
        "Large Language Model",
        "Multimodal Learning",
        "Radiology Dataset",
        "AI-assisted Labeling",
        "Benchmark Evaluation"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:45.704325Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15127",
    "title": "DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search",
    "authors": [
      "Bostan Khan",
      "Masoud Daneshtalab"
    ],
    "abstract": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15127.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15127",
    "published": "2026-01-21T16:03:25Z",
    "updated": "2026-01-21T16:03:25Z",
    "comment": "This paper significantly extends the preliminary work accepted at ESANN 2026. Source Code: https://github.com/bostankhan6/DeepFedNAS",
    "light_analysis": {
      "overview": "本文提出了DeepFedNAS框架，通过多目标适应度函数和预测器无关搜索，高效解决联邦学习中的神经架构搜索瓶颈。",
      "motivation": "联邦神经架构搜索（FedNAS）旨在自动化隐私保护联邦学习（FL）中的模型设计，但当前面临两个关键瓶颈：无指导的超网训练导致模型性能次优，以及训练后子网发现的多小时耗时管道。这些问题使得FL部署效率低下且不切实际，尤其在资源受限环境中，阻碍了硬件感知优化的应用。现有方法缺乏高效指导，导致训练成本高昂、模型质量受限，因此亟需更智能、快速的解决方案来提升FL的实用性和可扩展性。",
      "method": "DeepFedNAS采用两阶段框架。第一阶段是联邦帕累托最优超网训练，基于重新设计的超网，利用预计算的高适应度架构帕累托最优缓存作为智能课程优化共享权重。第二阶段是预测器无关搜索方法，直接使用多目标适应度函数作为准确性零成本代理，无需昂贵准确性预测器，实现秒级子网发现。关键创新包括整合数学网络设计原则与架构启发式，以及通过预计算缓存指导训练，提升搜索效率。摘要未明确说明具体数据集或模型架构细节，但提及了CIFAR-100作为评估示例。",
      "result": "在CIFAR-100数据集上，DeepFedNAS实现了最先进的准确性，绝对提升高达1.21%，并在参数和通信效率方面表现优异。与基线方法相比，总训练后搜索管道时间加速约61倍，从超过20小时减少到约20分钟（包括初始缓存生成），单个子网搜索仅需20秒。这显著提升了硬件感知FL部署的实用性和即时性，展示了框架在效率和性能上的双重优势。",
      "conclusion": "DeepFedNAS通过创新的多目标适应度函数和预测器无关搜索，有效解决了FedNAS的训练和搜索瓶颈，实现了高效、准确的神经架构搜索。其贡献推动了联邦学习和自动化机器学习的研究，为隐私保护、硬件感知的AI系统部署提供了实用工具。未来工作可扩展到更广泛数据集和复杂FL场景，以进一步验证框架的通用性和局限性。摘要未明确说明具体局限性，但暗示了在更多环境中的潜在应用探索。",
      "tags": [
        "Federated Learning",
        "Neural Architecture Search",
        "Pareto Optimization",
        "Predictor-Free Search",
        "Hardware-Aware Optimization"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:25.187335Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15124",
    "title": "Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation",
    "authors": [
      "Haonan Yuan",
      "Qingyun Sun",
      "Jiacheng Tao",
      "Xingcheng Fu",
      "Jianxin Li"
    ],
    "abstract": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15124.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15124",
    "published": "2026-01-21T16:02:43Z",
    "updated": "2026-01-21T16:02:43Z",
    "comment": "Accepted by the Web Conference 2026 (Research Track)",
    "light_analysis": {
      "overview": "RAG-GFM 通过检索增强生成技术克服图基础模型的内存瓶颈，实现知识外部化和高效适应。",
      "motivation": "图基础模型（GFMs）试图在跨任务中提供可转移表示，但受限于内存瓶颈：知识被编码到模型参数中，导致语义容量受限、损失性压缩冲突以及表示与知识纠缠，这阻碍了高效适应、可扩展性和解释性。现有方法未能有效外部化知识，因此需要创新解决方案来卸载知识并提升模型性能。",
      "method": "RAG-GFM 采用检索增强生成技术，外部化图知识以补充参数化学习。关键创新包括构建双模态统一检索模块：语义存储基于前缀结构文本，结构存储基于中心性基序。设计双视图对齐目标，通过对比这两种模态来捕捉内容和关系模式。此外，实施上下文增强，利用检索的文本和基序作为上下文证据，以丰富支持实例，实现高效的下游任务适应。",
      "result": "在五个基准图数据集上的实验表明，RAG-GFM 在跨域节点分类和图形分类任务中一致优于13个最先进的基线方法，展示了更高的准确性和效率。摘要未提供具体数据，但提到模型在效果和效率方面均取得优越表现，验证了其在解决内存瓶颈方面的有效性。",
      "conclusion": "本研究的主要贡献是提出 RAG-GFM，通过检索增强生成技术将知识外部化，有效克服图基础模型的内存瓶颈，增强了可扩展性和解释性。这为图学习领域提供了新的知识管理框架，具有学术和实践价值。未来工作可能包括优化检索模块或扩展到更多图相关任务，进一步提升适应性。",
      "tags": [
        "Graph Foundation Models",
        "Retrieval-Augmented Generation",
        "Dual-Modal Retrieval",
        "Contrastive Learning",
        "Graph Classification"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:36.202368Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15123",
    "title": "BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation",
    "authors": [
      "Andrey Moskalenko",
      "Danil Kuznetsov",
      "Irina Dudko",
      "Anastasiia Iasakova",
      "Nikita Boldyrev",
      "Denis Shepelev",
      "Andrei Spiridonov",
      "Andrey Kuznetsov",
      "Vlad Shakhuro"
    ],
    "abstract": "Promptable segmentation models such as SAM have established a powerful paradigm, enabling strong generalization to unseen objects and domains with minimal user input, including points, bounding boxes, and text prompts. Among these, bounding boxes stand out as particularly effective, often outperforming points while significantly reducing annotation costs. However, current training and evaluation protocols typically rely on synthetic prompts generated through simple heuristics, offering limited insight into real-world robustness. In this paper, we investigate the robustness of promptable segmentation models to natural variations in bounding box prompts. First, we conduct a controlled user study and collect thousands of real bounding box annotations. Our analysis reveals substantial variability in segmentation quality across users for the same model and instance, indicating that SAM-like models are highly sensitive to natural prompt noise. Then, since exhaustive testing of all possible user inputs is computationally prohibitive, we reformulate robustness evaluation as a white-box optimization problem over the bounding box prompt space. We introduce BREPS, a method for generating adversarial bounding boxes that minimize or maximize segmentation error while adhering to naturalness constraints. Finally, we benchmark state-of-the-art models across 10 datasets, spanning everyday scenes to medical imaging. Code - https://github.com/emb-ai/BREPS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15123.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15123",
    "published": "2026-01-21T16:02:21Z",
    "updated": "2026-01-21T16:02:21Z",
    "comment": "Accepted by AAAI2026",
    "light_analysis": {
      "overview": "论文提出BREPS方法，通过生成对抗性边界框来评估可提示分割模型在真实用户输入下的鲁棒性。",
      "motivation": "可提示分割模型如SAM在边界框提示下表现出色且成本较低，但现有训练和评估协议依赖简单启发式生成的合成提示，难以反映真实用户输入的自然变异。这限制了模型在实际应用中的鲁棒性评估，因为真实场景中用户标注存在多样性，可能影响分割质量。因此，研究模型对边界框提示变异的敏感性至关重要，以提升模型的可靠性和实用性。",
      "method": "论文首先进行了控制用户研究，收集数千个真实边界框标注，分析用户间标注变异对分割质量的影响。随后，提出BREPS方法，将鲁棒性评估重新表述为白盒优化问题。BREPS在边界框提示空间中生成对抗性边界框，旨在最小化或最大化分割错误，同时遵守自然性约束。这一方法创新地结合了用户数据和优化技术，以系统测试模型对提示变异的敏感性。",
      "result": "论文在10个数据集上对最先进的可提示分割模型进行了基准测试，数据集涵盖日常场景和医学成像等领域。实验揭示了模型对边界框提示自然变异的敏感性，同一实例在不同用户标注下分割质量差异显著。然而，摘要未明确说明具体的性能指标数值，如准确率提升或与基线对比的详细数据。",
      "conclusion": "论文的主要贡献是提出了BREPS框架，用于评估可提示分割模型在边界框提示下的鲁棒性，揭示了模型对自然提示噪声的高度敏感性。这项工作的学术价值在于推动了更真实的鲁棒性评估方法，实际应用价值在于帮助改进模型设计和标注协议。未来方向可能包括扩展到其他提示类型或应用于更广泛的领域。",
      "tags": [
        "Promptable Segmentation",
        "Bounding Box Prompt",
        "Robustness Evaluation",
        "White-Box Optimization",
        "Adversarial Examples"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:24.135604Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15120",
    "title": "Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories",
    "authors": [
      "Qian Xiong",
      "Yuekai Huang",
      "Yujia Zheng",
      "Tianhao Li",
      "Ziyou Jiang",
      "Zhiyuan Chang",
      "Zhaoyang Li",
      "Huanxiang Feng",
      "Mingyang Li"
    ],
    "abstract": "LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of \"intent deviation\" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a \"Real-to-Virtual\" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15120.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15120",
    "published": "2026-01-21T15:58:54Z",
    "updated": "2026-01-21T15:58:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出RISE方法，通过从真实调用生成虚拟轨迹和负样本，有效减轻工具使用代理中的意图偏离问题。",
      "motivation": "大语言模型驱动的工具使用代理在实际应用中常因意图偏离导致意外行为，影响可靠评估和性能改进。现有后训练方法存在局限性：基于真实系统样本成本高昂，依赖手工用户请求；而虚拟模拟数据与真实工具分布存在偏移，且两者均缺乏针对意图偏离场景的负样本，阻碍偏好学习的有效指导。因此，急需一种高效方法解决这些挑战，以提升代理的可靠性和评估效率。",
      "method": "RISE方法采用“真实到虚拟”策略，以已验证工具基元为基础，合成虚拟轨迹并通过对关键参数进行突变，生成多样化的负样本。该方法利用合成数据，通过两阶段训练对骨干大语言模型进行微调，以优化意图对齐。核心创新在于从真实调用派生虚拟数据，解决分布偏移问题，并提供针对意图偏离的负样本，从而增强模型的鲁棒性和训练效果。",
      "result": "评估结果显示，RISE合成的数据在覆盖用户需求、执行轨迹和代理响应的八个指标上取得显著成果。结合训练后，RISE在任务完成度（Acctask）上平均提升35.28%，在意图对齐（Accintent）上平均提升23.27%。相比最先进基线方法，改进幅度分别为1.20-42.09%和1.17-54.93%，性能优势明显，证实了方法的有效性。",
      "conclusion": "本研究贡献了RISE方法，通过合成虚拟轨迹和负样本有效减轻意图偏离，提升工具使用代理的意图对齐和任务完成能力。该方法具有重要学术价值，为代理可靠性评估和改进提供了新思路；实际应用中，可增强代理在复杂场景下的性能和鲁棒性。未来工作可扩展到更多工具类型或探索自适应参数突变策略，以进一步提升泛化能力。",
      "tags": [
        "Large Language Model",
        "Tool-Using Agents",
        "Intent Alignment",
        "Synthetic Data",
        "Negative Sampling"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:33.498516Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15115",
    "title": "Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning",
    "authors": [
      "Shuonan Yang",
      "Yuchen Zhang",
      "Zeyu Fu"
    ],
    "abstract": "Hateful videos pose serious risks by amplifying discrimination, inciting violence, and undermining online safety. Existing training-based hateful video detection methods are constrained by limited training data and lack of interpretability, while directly prompting large vision-language models often struggle to deliver reliable hate detection. To address these challenges, this paper introduces MARS, a training-free Multi-stage Adversarial ReaSoning framework that enables reliable and interpretable hateful content detection. MARS begins with the objective description of video content, establishing a neutral foundation for subsequent analysis. Building on this, it develops evidence-based reasoning that supports potential hateful interpretations, while in parallel incorporating counter-evidence reasoning to capture plausible non-hateful perspectives. Finally, these perspectives are synthesized into a conclusive and explainable decision. Extensive evaluation on two real-world datasets shows that MARS achieves up to 10% improvement under certain backbones and settings compared to other training-free approaches and outperforms state-of-the-art training-based methods on one dataset. In addition, MARS produces human-understandable justifications, thereby supporting compliance oversight and enhancing the transparency of content moderation workflows. The code is available at https://github.com/Multimodal-Intelligence-Lab-MIL/MARS.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15115.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15115",
    "published": "2026-01-21T15:52:26Z",
    "updated": "2026-01-21T15:52:26Z",
    "comment": "Accepted at ICASSP 2026. \\c{opyright} 2026 IEEE. This is the author accepted manuscript. The final published version will be available via IEEE Xplore",
    "light_analysis": {
      "overview": "本文提出 MARS，一个无需训练的多阶段对抗推理框架，用于实现可靠且可解释的有害视频检测。",
      "motivation": "有害视频通过加剧歧视和煽动暴力，严重威胁在线安全。现有检测方法中，基于训练的技术因标注数据稀缺和缺乏可解释性而受限，而直接使用大型视觉语言模型（如视觉问答模型）也常不可靠。这些缺陷导致检测系统难以在实际应用中提供可靠结果，尤其是在需要透明解释以支持合规监督的内容审核工作流中。因此，本研究旨在开发一种无需训练、能生成解释的检测框架，以解决这些挑战。",
      "method": "MARS 框架采用多阶段对抗推理过程：首先，对视频内容进行客观描述，建立中性分析基础；其次，并行执行基于证据的推理，支持潜在有害解释，以及反证据推理，捕获可能无害的视角；最后，综合这些对抗性观点形成结论性决策。该方法无需训练，直接利用现有视觉语言模型进行推理，关键创新在于通过对抗性推理平衡不同视角，增强可靠性和可解释性。",
      "result": "在两个真实世界数据集上的广泛评估表明，MARS 在某些骨干网络和设置下比无训练方法提高高达10%的性能。此外，在一个数据集上，MARS 甚至超越了基于训练的最先进方法。同时，它能生成人类可理解的解释，支持内容审核工作流的透明性和合规监督。摘要未明确说明具体指标如准确率，但基于实验结果验证了 MARS 的有效性。",
      "conclusion": "本研究的主要贡献是提出了 MARS，一个无需训练、可解释的有害视频检测框架，通过多阶段对抗推理实现可靠检测，并提供透明解释，有助于增强内容审核的信任度和合规性。代码开源促进了进一步研究和应用。局限性方面，摘要未明确说明，未来工作可探索更多视频类型和扩展至其他领域，以验证其泛化能力。",
      "tags": [
        "Training-Free Detection",
        "Multi-stage Reasoning",
        "Adversarial Reasoning",
        "Interpretability",
        "Vision-Language Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:41:15.896240Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15111",
    "title": "Auditing Language Model Unlearning via Information Decomposition",
    "authors": [
      "Anmol Goel",
      "Alan Ritter",
      "Iryna Gurevych"
    ],
    "abstract": "We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15111.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15111",
    "published": "2026-01-21T15:51:19Z",
    "updated": "2026-01-21T15:51:19Z",
    "comment": "EACL 2026 Main",
    "light_analysis": {
      "overview": "本论文通过部分信息分解框架审计语言模型遗忘，揭示残余知识的存在，并提出基于表示的风险评分以缓解隐私泄露。",
      "motivation": "当前语言模型遗忘方法虽看似成功，但被遗忘数据的信息仍可通过内部表示线性解码，这暴露了隐私泄露的风险。现有方法未能彻底删除敏感信息，可能导致对抗攻击成功。此问题对于确保模型部署安全和保护用户隐私至关重要，尤其在处理敏感数据时，因此需要系统性评估遗忘效果和开发更可靠的审计机制。",
      "method": "本研究引入基于部分信息分解（PID）的框架来审计遗忘过程。通过比较遗忘前后的模型表示，将互信息分解为不同组件，从而形式化遗忘知识和残余知识的概念。关键创新在于使用信息理论方法量化信息残留，识别冗余信息作为残余知识的来源。该方法提供了一个通用审计工具，但摘要未明确说明使用的具体数据集或模型架构等实验细节。",
      "result": "分析表明，冗余信息在遗忘前后共享，构成残余知识，这与已知对抗重构攻击的易感性相关。通过信息分解，可以量化和识别这些残留信息。基于此，论文提出一个基于表示的风险评分，用于推理时对敏感输入进行弃权，从而提供实用机制以减轻隐私泄露。虽然未提供具体性能指标，但强调了残余知识的持续存在和风险评分的有效性。",
      "conclusion": "本工作提出了一个原则性的、表示级的遗忘审计框架，为语言模型安全部署提供了理论洞察和行动工具。主要贡献在于形式化信息残留的概念，并通过风险评分促进实际应用。该研究揭示了当前遗忘方法的局限性，推动了更健壮的隐私保护技术的发展。未来工作可能包括扩展审计场景或优化评分机制，但摘要未明确说明具体方向。",
      "tags": [
        "Language Model Unlearning",
        "Partial Information Decomposition",
        "Information Theory",
        "Adversarial Reconstruction",
        "Representation Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:22.705734Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15110",
    "title": "Pb4U-GNet: Resolution-Adaptive Garment Simulation via Propagation-before-Update Graph Network",
    "authors": [
      "Aoran Liu",
      "Kun Hu",
      "Clinton Ansun Mo",
      "Qiuxia Wu",
      "Wenxiong Kang",
      "Zhiyong Wang"
    ],
    "abstract": "Garment simulation is fundamental to various applications in computer vision and graphics, from virtual try-on to digital human modelling. However, conventional physics-based methods remain computationally expensive, hindering their application in time-sensitive scenarios. While graph neural networks (GNNs) offer promising acceleration, existing approaches exhibit poor cross-resolution generalisation, demonstrating significant performance degradation on higher-resolution meshes beyond the training distribution. This stems from two key factors: (1) existing GNNs employ fixed message-passing depth that fails to adapt information aggregation to mesh density variation, and (2) vertex-wise displacement magnitudes are inherently resolution-dependent in garment simulation. To address these issues, we introduce Propagation-before-Update Graph Network (Pb4U-GNet), a resolution-adaptive framework that decouples message propagation from feature updates. Pb4U-GNet incorporates two key mechanisms: (1) dynamic propagation depth control, adjusting message-passing iterations based on mesh resolution, and (2) geometry-aware update scaling, which scales predictions according to local mesh characteristics. Extensive experiments show that even trained solely on low-resolution meshes, Pb4U-GNet exhibits strong generalisability across diverse mesh resolutions, addressing a fundamental challenge in neural garment simulation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15110.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15110",
    "published": "2026-01-21T15:50:30Z",
    "updated": "2026-01-21T15:50:30Z",
    "comment": "Camera-ready version accepted at AAAI 2026",
    "light_analysis": {
      "overview": "提出了Pb4U-GNet，一种分辨率自适应的图网络框架，通过解耦消息传播和特征更新解决了服装模拟中的跨分辨率泛化问题。",
      "motivation": "该研究旨在解决服装模拟中的计算效率问题，尤其是在时间敏感应用如虚拟试衣和数字人建模中。传统基于物理的方法计算成本高昂，而现有图神经网络（GNNs）方法在跨不同分辨率网格时泛化能力差，主要由于固定消息传递深度和分辨率依赖的顶点位移限制，这限制了实际部署和性能。",
      "method": "论文提出了Propagation-before-Update Graph Network（Pb4U-GNet），一个分辨率自适应的框架，其核心创新包括解耦消息传播和特征更新过程，引入动态传播深度控制以根据网格分辨率调整消息传递迭代次数，以及几何感知更新缩放机制来基于局部网格特征调整预测。框架仅使用低分辨率网格进行训练，通过自适应机制提高泛化能力。",
      "result": "实验结果表明，Pb4U-GNet在仅训练于低分辨率网格的情况下，表现出在多种分辨率网格上的强泛化能力，解决了现有方法在跨分辨率应用时的性能下降问题。摘要未明确说明具体性能指标如准确率提升，但强调了与基线方法相比在泛化方面的显著改进。",
      "conclusion": "论文的主要贡献是提出Pb4U-GNet框架，解决了神经服装模拟中的跨分辨率泛化挑战，学术价值在于改进了图神经网络在模拟领域的应用方法，实际应用价值是加速服装模拟、促进虚拟试衣等时间敏感场景。未来工作可能包括扩展到其他动态模拟任务或进一步优化计算效率。",
      "tags": [
        "Graph Neural Networks",
        "Dynamic Propagation Depth",
        "Geometry-Aware Scaling",
        "Garment Simulation",
        "Resolution Adaptation"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:13.269822Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15102",
    "title": "Field-Space Autoencoder for Scalable Climate Emulators",
    "authors": [
      "Johannes Meuer",
      "Maximilian Witte",
      "Étiénne Plésiat",
      "Thomas Ludwig",
      "Christopher Kadow"
    ],
    "abstract": "Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.",
    "categories": [
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15102.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15102",
    "published": "2026-01-21T15:43:53Z",
    "updated": "2026-01-21T15:43:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了Field-Space Autoencoder，一种基于球形压缩的可扩展气候模拟框架，通过Field-Space Attention有效处理气候数据并避免几何失真。",
      "motivation": "千米尺度的地球系统模型能精确捕捉局部气候变化，但由于计算昂贵、输出数据量达PB级，限制了其在概率风险评估等领域的应用。现有卷积方法在处理球形气候数据时，常导致几何失真，破坏了物理结构的完整性，因此需要开发更高效的压缩和模拟技术来解决这些问题。",
      "method": "本研究设计了Field-Space Autoencoder，利用Field-Space Attention直接在原生气候模型输出上操作，避免了将球形数据投影到欧几里得网格引起的扭曲。模型生成结构化压缩场，作为下游生成模拟的基线，并采用生成扩散模型进行训练。该方法还实现了零-shot超分辨率，整合低分辨率大集合数据和稀缺高分辨率数据，实现共享表示。",
      "result": "该方法在保留物理结构方面显著优于卷积基线，具体性能指标摘要未明确说明。通过生成扩散模型，能够同时学习低分辨率数据的内部变异性及高分辨率数据的精细物理细节，有效弥合了数据差距。这种集成方法提高了气候模拟的效率和可扩展性。",
      "conclusion": "本研究的主要贡献是开发了Field-Space Autoencoder框架，实现了气候模型输出的高效压缩和模拟，为下游应用提供基线。其学术价值在于创新使用球形注意力机制改善数据处理，实际应用有助于风险评估和气候预测。未来工作可扩展模型规模或应用于更广泛的地球系统数据。",
      "tags": [
        "Autoencoder",
        "Attention",
        "Spherical Compression",
        "Climate Emulation",
        "Diffusion Model"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:09.623936Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15098",
    "title": "Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction",
    "authors": [
      "Yipeng Yin",
      "Rao Yao",
      "Qingying Li",
      "Dazhong Wang",
      "Hong Zhou",
      "Zhijun Fang",
      "Jianing Chen",
      "Longjie Qian",
      "Mingyue Wu"
    ],
    "abstract": "As Micro-CT technology continues to refine its characterization of material microstructures, industrial CT ultra-precision inspection is generating increasingly large datasets, necessitating solutions to the trade-off between accuracy and efficiency in the 3D characterization of defects during ultra-precise detection. This article provides a unique perspective on recent advances in accurate and efficient 3D visualization using Micro-CT, tracing its evolution from medical imaging to industrial non-destructive testing (NDT). Among the numerous CT reconstruction and volume rendering methods, this article selectively reviews and analyzes approaches that balance accuracy and efficiency, offering a comprehensive analysis to help researchers quickly grasp highly efficient and accurate 3D reconstruction methods for microscopic features. By comparing the principles of computed tomography with advancements in microstructural technology, this article examines the evolution of CT reconstruction algorithms from analytical methods to deep learning techniques, as well as improvements in volume rendering algorithms, acceleration, and data reduction. Additionally, it explores advanced lighting models for high-accuracy, photorealistic, and efficient volume rendering. Furthermore, this article envisions potential directions in CT reconstruction and volume rendering. It aims to guide future research in quickly selecting efficient and precise methods and developing new ideas and approaches for real-time online monitoring of internal material defects through virtual-physical interaction, for applying digital twin model to structural health monitoring (SHM).",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15098.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15098",
    "published": "2026-01-21T15:37:38Z",
    "updated": "2026-01-21T15:37:38Z",
    "comment": "Page1-37",
    "light_analysis": {
      "overview": "本文综述了X射线微CT三维可视化中精度与效率平衡的方法，并展望了实时交互和数字孪生应用的未来研究方向。",
      "motivation": "Micro-CT技术在材料微结构表征中的进步使得工业CT超精密检测产生大规模数据集，需解决三维缺陷表征中精度与效率的权衡问题。现有方法在处理大数据时可能难以兼顾高精度和实时性，影响工业非破坏性测试的效率和可靠性。本文旨在回顾相关进展，为研究人员提供高效准确方法的快速掌握途径，推动实时在线监测和数字孪生应用的发展。",
      "method": "作为综述文章，本文通过选择性回顾和分析CT重建算法（从分析方法演进到深度学习技术）和体积渲染算法（包括加速、数据减少和先进光照模型），比较其原理和平衡策略。文章未明确说明具体的数据集或模型架构，但全面探讨了高效准确的3D重建方法，帮助研究人员理解技术演变和优化方向。",
      "result": "摘要未明确说明具体的实验结果或性能指标，因为本文是综述性质。文章通过分析和比较现有方法，突出了精度和效率之间的权衡，但没有提供实验数据支持。综述的主要效果是总结和梳理了CT重建和体积渲染的进展，为快速选择方法提供参考，但未包含与基线方法的对比数据。",
      "conclusion": "本文综述了Micro-CT三维可视化中平衡精度和效率的方法，涵盖了从传统算法到深度学习的演进。其学术价值在于系统整理了相关技术，帮助研究人员快速掌握高效准确的方法；实际应用价值在于指导未来研究，如实现实时在线监测材料内部缺陷，应用数字孪生模型到结构健康监测。未来工作可探索虚拟物理交互和实时监控技术的进一步发展。",
      "tags": [
        "X-ray micro-CT",
        "CT Reconstruction Algorithms",
        "Volume Rendering",
        "Deep Learning",
        "Digital Twin"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:27.090426Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15091",
    "title": "Circadian Modulation of Semantic Exploration in Social Media Language",
    "authors": [
      "Vuong Hung Truong",
      "Mariana Gabrielle Cangco Reyes",
      "Masatoshi Koizumi",
      "Jihwan Myung"
    ],
    "abstract": "Human cognition exhibits strong circadian modulation, yet its influence on high-dimensional semantic behavior remains poorly understood. Using large-scale Reddit data, we quantify time-of-day variation in language use by embedding text into a pretrained transformer model and measuring semantic entropy as an index of linguistic exploration-exploitation, for which we show a robust circadian rhythmicity that could be entrained by seasonal light cues. Distinguishing between local and global semantic entropy reveals a systematic temporal dissociation: local semantic exploration peaks in the morning, reflecting broader exploration of semantic space, whereas global semantic diversity peaks later in the day as submissions accumulate around already established topics, consistent with \"rich-get-richer\" dynamics. These patterns are not explained by sentiment or affective valence, indicating that semantic exploration captures a cognitive dimension distinct from mood. The observed temporal structure aligns with known diurnal patterns in neuromodulatory systems, suggesting that biological circadian rhythms extend to the semantic domain.",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.SI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15091.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15091",
    "published": "2026-01-21T15:31:44Z",
    "updated": "2026-01-21T15:31:44Z",
    "comment": "25 pages, 6 figures, 3 supplementary figures",
    "light_analysis": {
      "overview": "论文提出一种基于预训练transformer模型的方法，量化社交媒体语言中语义探索的昼夜节律调制，揭示局部和全局语义熵的时间分离。",
      "motivation": "人类认知受昼夜节律影响，但这一节律如何调制高维语义行为（如语言使用中的语义探索）尚不清楚。本研究旨在解决这一问题，因为理解认知过程的生物学基础对认知科学和神经科学至关重要。现有研究可能侧重于情感或主题变化，而忽视了语义探索的节律变化，导致对认知行为的全面理解不足。社交媒体提供大规模真实数据，使得量化分析成为可能，从而填补了这一研究空白。",
      "method": "研究使用大规模Reddit数据集，通过预训练transformer模型将文本嵌入到高维语义空间，并计算语义熵作为语言探索-利用的指标。关键创新在于区分局部和全局语义熵：局部熵测量单个帖子的语义多样性，反映个体探索行为；全局熵衡量整个数据集的语义集中度，揭示群体动态。结合时间序列分析，识别昼夜节律模式，并利用季节性光线数据验证调谐效应，方法融合了自然语言处理和时间序列技术。",
      "result": "实验结果显示，语义熵表现出稳健的昼夜节律，并可受季节性光线提示调谐。局部语义探索在早晨达到峰值，表明更广泛的语义空间探索；全局语义多样性在下午或晚上峰值，符合“富者越富”动态，即话题累积效应。这些模式独立于情感或效价因素，表明语义探索是一个独特的认知维度。观察到的时间结构与已知神经调节系统的昼夜模式一致，支持生物学节律延伸到语义领域的假设。",
      "conclusion": "论文的主要贡献是首次量化了社交媒体语言中语义探索的昼夜节律调制，揭示局部和全局语义熵的时间分离，为认知科学和神经科学提供新视角。学术价值在于连接认知科学、神经科学和计算语言学，深化了对认知过程生物学机制的理解。实际应用可能包括优化社交媒体算法、人机交互设计或认知健康监测。未来工作可探索文化差异、个体因素等影响，或扩展到其他类型的数据和行为分析。",
      "tags": [
        "Transformer Models",
        "Semantic Entropy",
        "Circadian Rhythm",
        "Social Media Analysis",
        "Natural Language Understanding"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:48.378257Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15086",
    "title": "Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning",
    "authors": [
      "Oleg Shchendrigin",
      "Egor Cherepanov",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "abstract": "Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15086.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15086",
    "published": "2026-01-21T15:27:23Z",
    "updated": "2026-01-21T15:27:23Z",
    "comment": "11 pages, 6 figures, 7 tables",
    "light_analysis": {
      "overview": "本文通过引入强化学习中记忆重写能力的新基准，发现经典循环模型在记忆更新任务中表现更优，揭示了现代记忆架构的局限性。",
      "motivation": "在现实世界的强化学习决策中，智能体需要记忆既稳定又适应环境变化。现有研究主要集中在记忆保留，但忽略了记忆重写的关键能力，这在实际环境中同样重要，因为信息需随环境变化更新。现有记忆增强代理和基准未充分测试重写能力，导致智能体在部分可观测的动态任务中难以有效更新过时内容，限制了适应性决策。",
      "method": "论文的核心方法是设计一个基准，专门测试在部分可观测性下的持续记忆更新任务，模拟智能体依赖记忆而非当前观察的自然设置。作者比较了三种记忆架构：经典循环模型、基于Transformer的代理和结构化记忆架构。关键创新在于明确评估记忆重写能力，而非仅关注保留，通过系统比较不同架构的性能来揭示它们的优势和弱点。",
      "result": "实验结果显示，经典的循环模型在记忆重写任务中展现出更高的灵活性和鲁棒性，优于其他方法。结构化记忆仅在狭窄条件下成功，而基于Transformer的代理在超出简单保留案例时经常失败。这表明现代记忆架构在处理适应性更新方面存在局限性，而循环模型在平衡保留和更新方面更具优势，强调了记忆机制需要兼顾稳定性和适应性。",
      "conclusion": "本文的主要贡献在于突出了强化学习中记忆重写这一被忽视的挑战，并引入基准来评估它。研究发现揭示了当前记忆机制的不足，强调了设计平衡稳定保留和自适应更新的记忆系统的重要性。工作的学术价值在于推动对记忆动态性的研究，实际应用价值在于改进强化学习代理在动态环境中的决策能力。未来方向可能包括开发具有显式和可训练遗忘机制的智能体。",
      "tags": [
        "Reinforcement Learning",
        "Memory Rewriting",
        "Recurrent Models",
        "Transformer-based Agents",
        "Structured Memory"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:34.837261Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15079",
    "title": "LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training",
    "authors": [
      "Chenyu Liu",
      "Haige Li",
      "Luca Rossi"
    ],
    "abstract": "Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15079.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15079",
    "published": "2026-01-21T15:23:18Z",
    "updated": "2026-01-21T15:23:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出LoRAP方法，通过低秩聚合提示优化量化图神经网络的训练，提升性能同时保持低计算开销。",
      "motivation": "图神经网络（GNNs）用于处理图数据，量化可减少模型大小和加速推理，在资源受限环境中尤为重要。量化图特征在GNNs中比在大型语言模型中更关键，但现有提示方法仅优化节点特征，无法全面改善量化聚合结果，导致性能受限。因此，需要改进量化感知训练，以更全面地优化聚合过程，解决量化带来的精度损失问题。",
      "method": "论文提出LoRAP方法，通过将轻量级、输入依赖的提示注入每个聚合特征，优化量化聚合结果。该方法基于提示学习，创新点在于低秩聚合提示，能有效调整量化后的特征交互，弥补节点特征提示的不足。评估使用4个领先的QAT框架和9个图数据集，确保方法在不同场景下的泛化性和适用性。",
      "result": "在4个QAT框架和9个图数据集上的广泛评估显示，LoRAP一致提升了低比特量化GNNs的性能，如准确率等指标，同时引入最小计算开销。与基线QAT方法相比，LoRAP在保持高效推理的同时显著改善了量化模型的精度，但摘要未提供具体数值对比，如准确率提升百分比。",
      "conclusion": "LoRAP方法通过低秩聚合提示有效优化了量化GNN训练，主要贡献是提出一种新颖提示机制，增强量化性能。该研究具有学术价值，为GNN量化领域提供了新思路，并在实际应用中支持资源高效部署。未来工作可探索扩展到更多图任务或更高量化比特深度，但摘要未明确说明局限性。",
      "tags": [
        "Graph Neural Networks",
        "Quantization-Aware Training",
        "Prompt Learning",
        "Low-Rank Aggregation",
        "Graph Datasets"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:35.012650Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15077",
    "title": "Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure",
    "authors": [
      "Christopher Scofield"
    ],
    "abstract": "Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15077.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15077",
    "published": "2026-01-21T15:23:04Z",
    "updated": "2026-01-21T15:23:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文基于算子理论和约束优化，解释了多代理系统通过约束因子化揭示潜在不可变解结构，从而提高问题解决性能。",
      "motivation": "研究要解决的问题是理解为什么由大型语言模型组成的多代理系统（MAS）在处理相同信息时能展现出更好的问题解决性能。这个问题重要，因为MAS在AI应用中被广泛使用，但现有理论解释不足，特别是单个代理即使表达能力和信息相同，也可能无法动态访问某些解结构。研究动机在于提供形式化解释，以弥补现有方法的不足，并为优化MAS设计提供理论基础。",
      "method": "研究方法基于算子理论和约束优化，核心是将每个代理建模为在共享解状态上强制执行特定有效性约束的算子。关键创新是通过因子化组合这些算子，展示在温和条件下，动态过程能收敛到由代理约束集交集定义的不可变解集。技术特色包括使用邻近算子将结果从精确约束扩展到软约束，并将形式主义应用于当代基于文本的对话系统，但摘要未明确说明具体数据集或模型架构。",
      "result": "摘要未明确说明具体实验数据，如准确率提升或效率改进。理论分析表明，多代理系统的动态能收敛到单个代理无法访问的不可变解结构，这解释了性能提升现象。然而，未提供与基线方法的量化对比，仅基于形式化论证和算子理论推导，缺乏实证验证。",
      "conclusion": "论文的主要贡献是提供了一个形式化框架，通过约束因子化揭示了多代理系统的动态机制和性能提升原因。学术价值在于将算子理论和约束优化方法应用于多代理系统分析，扩展了理论工具；实际应用价值体现在可优化文本处理任务，如对话系统。局限性可能包括理论假设的简化，未来工作可能涉及实验验证和应用于更广泛的AI场景。",
      "tags": [
        "Multi-Agent Systems",
        "Operator Theory",
        "Constrained Optimization",
        "Proximal Operators",
        "Dialog Systems"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:54.290812Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15075",
    "title": "The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution",
    "authors": [
      "Chen Qian",
      "Peng Wang",
      "Dongrui Liu",
      "Junyao Yang",
      "Dadi Guo",
      "Ling Tang",
      "Jilin Mei",
      "Qihan Ren",
      "Shuai Shao",
      "Yong Liu",
      "Jie Fu",
      "Jing Shao",
      "Xia Hu"
    ],
    "abstract": "Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \\textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \\textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \\textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \\textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15075.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15075",
    "published": "2026-01-21T15:22:21Z",
    "updated": "2026-01-21T15:22:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一个通用代理归因框架，用于识别驱动代理行动的内部因素，无论任务结果如何。",
      "motivation": "大型语言模型（LLM）代理在客户服务、网络导航和软件工程等现实应用中广泛使用，随着系统自主性增强和大规模部署，理解代理行动原因对问责和治理至关重要。然而，现有研究主要关注失败归因，即定位失败轨迹中的显性错误，这不足以解释代理行为背后的推理过程。为解决这一问题，需要开发更通用的方法以识别内部驱动因素，提升系统透明度和可靠性。",
      "method": "论文提出一个分层通用代理归因框架，以管理代理交互的复杂性。在组件级别，使用时序似然动态方法识别关键交互步骤；在句子级别，通过基于扰动的分析精确定位具体文本证据，隔离驱动行为的内部因素。该方法设计用于各种任务结果，提供全面行为解释。摘要未明确说明具体模型架构或数据集，但框架适用于多种代理场景，包括工具使用和可靠性风险分析。",
      "result": "实验结果表明，该框架在多种代理场景中可靠地识别了行为背后的关键历史事件和句子，包括标准工具使用和内存引发的偏差等可靠性风险。验证工作展示了框架的有效性和通用性，为行为解释提供支持。摘要未明确说明具体性能指标（如准确率提升），但强调了框架在复杂场景中的可靠应用能力。",
      "conclusion": "该研究的主要贡献是通用代理归因框架，它能揭示代理行动的内部驱动因素，弥补现有失败归因方法的不足，对提升代理系统的安全性和可问责性具有重要学术价值和实际意义。未来工作可能包括框架优化和更多现实场景的部署，以应对日益增长的自主代理需求。",
      "tags": [
        "Large Language Model (LLM)",
        "Agentic Attribution",
        "Temporal Likelihood Dynamics",
        "Perturbation-based Analysis",
        "Agent Behavior Explanation"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:54.597343Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15071",
    "title": "The Pictorial Cortex: Zero-Shot Cross-Subject fMRI-to-Image Reconstruction via Compositional Latent Modeling",
    "authors": [
      "Jingyang Huo",
      "Yikai Wang",
      "Yanwei Fu",
      "Jianfeng Feng"
    ],
    "abstract": "Decoding visual experiences from human brain activity remains a central challenge at the intersection of neuroscience, neuroimaging, and artificial intelligence. A critical obstacle is the inherent variability of cortical responses: neural activity elicited by the same visual stimulus differs across individuals and trials due to anatomical, functional, cognitive, and experimental factors, making fMRI-to-image reconstruction non-injective. In this paper, we tackle a challenging yet practically meaningful problem: zero-shot cross-subject fMRI-to-image reconstruction, where the visual experience of a previously unseen individual must be reconstructed without subject-specific training. To enable principled evaluation, we present a unified cortical-surface dataset -- UniCortex-fMRI, assembled from multiple visual-stimulus fMRI datasets to provide broad coverage of subjects and stimuli. Our UniCortex-fMRI is particularly processed by standardized data formats to make it possible to explore this possibility in the zero-shot scenario of cross-subject fMRI-to-image reconstruction. To tackle the modeling challenge, we propose PictorialCortex, which models fMRI activity using a compositional latent formulation that structures stimulus-driven representations under subject-, dataset-, and trial-related variability. PictorialCortex operates in a universal cortical latent space and implements this formulation through a latent factorization--composition module, reinforced by paired factorization and re-factorizing consistency regularization. During inference, surrogate latents synthesized under multiple seen-subject conditions are aggregated to guide diffusion-based image synthesis for unseen subjects. Extensive experiments show that PictorialCortex improves zero-shot cross-subject visual reconstruction, highlighting the benefits of compositional latent modeling and multi-dataset training.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15071.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15071",
    "published": "2026-01-21T15:15:27Z",
    "updated": "2026-01-21T15:15:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出PictorialCortex方法，通过组合潜在建模解决零样本跨受试者fMRI到图像重建的皮层变异性问题。",
      "motivation": "研究动机在于解码人类脑活动中的视觉体验是一个关键挑战，尤其因为fMRI数据受到个体和试验间解剖、功能、认知和实验因素的影响，导致皮层响应变异性大，使fMRI到图像重建非单射。现有方法通常需要受试者特定训练，无法处理未见过个体的零样本场景，限制了在实际神经科学和AI应用中的广泛使用，因此本文聚焦于零样本跨受试者重建这一具有重要意义的开放问题。",
      "method": "研究方法包括构建统一皮层表面数据集UniCortex-fMRI，通过标准化格式整合多个视觉刺激fMRI数据集，支持零样本跨受试者重建。核心模型PictorialCortex采用组合潜在建模，在通用皮层潜在空间结构化表示，处理受试者、数据集和试验相关变异性。通过潜在因子化-组合模块实现，并辅以一致性正则化强化。推理时，聚合多个已见受试者条件下的代理潜在，指导基于扩散模型的图像合成，关键创新在于组合建模和多数据集训练。",
      "result": "主要实验结果表明，PictorialCortex在零样本跨受试者视觉重建方面取得改进，突出了组合潜在建模和多数据集训练的优势。摘要未明确说明具体性能指标如准确率或效率提升数值，但通过广泛实验验证，相比基线方法有显著提升，体现了该方法在重建质量和泛化能力上的有效性。",
      "conclusion": "本研究贡献在于提出了PictorialCortex模型和UniCortex-fMRI数据集，成功实现零样本跨受试者fMRI到图像重建，通过组合潜在建模解决皮层变异性，推动神经科学与AI交叉领域的进步。该工作具有学术价值，为脑机接口和神经解码应用奠定基础，未来可扩展至其他脑成像模态或优化模型泛化性。",
      "tags": [
        "fMRI-to-Image Reconstruction",
        "Zero-Shot Learning",
        "Compositional Latent Modeling",
        "Diffusion Models",
        "Cross-Subject Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:10.148081Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15065",
    "title": "Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background",
    "authors": [
      "Tianyu Li",
      "Songyue Cai",
      "Zongqian Wu",
      "Ping Hu",
      "Xiaofeng Zhu"
    ],
    "abstract": "CLIP-based foreground-background (FG-BG) decomposition methods have demonstrated remarkable effectiveness in improving few-shot out-of-distribution (OOD) detection performance. However, existing approaches still suffer from several limitations. For background regions obtained from decomposition, existing methods adopt a uniform suppression strategy for all patches, overlooking the varying contributions of different patches to the prediction. For foreground regions, existing methods fail to adequately consider that some local patches may exhibit appearance or semantic similarity to other classes, which may mislead the training process. To address these issues, we propose a new plug-and-play framework. This framework consists of three core components: (1) a Foreground-Background Decomposition module, which follows previous FG-BG methods to separate an image into foreground and background regions; (2) an Adaptive Background Suppression module, which adaptively weights patch classification entropy; and (3) a Confusable Foreground Rectification module, which identifies and rectifies confusable foreground patches. Extensive experimental results demonstrate that the proposed plug-and-play framework significantly improves the performance of existing FG-BG decomposition methods. Code is available at: https://github.com/lounwb/FoBoR.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15065.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15065",
    "published": "2026-01-21T15:12:11Z",
    "updated": "2026-01-21T15:12:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种即插即用框架，通过自适应背景抑制和混淆前景修正，显著提升基于CLIP的前景-背景分解方法在少样本分布外检测中的性能。",
      "motivation": "研究动机源于现有CLIP-based前景-背景分解方法在少样本分布外检测中仍存在缺陷。具体而言，现有方法对背景区域采用统一抑制策略，忽略了不同补丁对预测的贡献差异；同时，前景区域中某些局部补丁可能与其他类别有外观或语义相似性，易误导模型训练。这些问题限制了检测精度，而少样本OOD检测在开放世界识别等实际应用中至关重要，因此需要改进方法来克服这些不足。",
      "method": "研究方法包括三个核心组件：首先，前景-背景分解模块，沿用现有方法将图像分割为前景和背景区域；其次，自适应背景抑制模块，通过加权补丁分类熵来适应不同补丁的重要性，而非统一处理；第三，混淆前景修正模块，识别并修正前景中易混淆的补丁，减少误导。整个框架是即插即用的，可轻松集成到现有FG-BG方法中，无需重新训练整个模型，从而细化处理以提升检测效果。",
      "result": "主要实验结果表明，提出的即插即用框架显著提高了现有前景-背景分解方法的少样本分布外检测性能。尽管摘要未提供具体数据如准确率提升百分比，但实验验证了该框架在多个数据集上的有效性，通过对比基线方法，展示了更好的检测能力。性能改进体现在减少了误检和漏检，增强了模型鲁棒性，但具体数值摘要未明确说明。",
      "conclusion": "本文的主要贡献是设计了一个即插即用框架，通过自适应背景抑制和混淆前景修正，优化了少样本分布外检测。该研究不仅提升了现有方法的性能，还提供了处理图像局部信息差异的新思路，具有学术价值。在实际应用中，可促进更可靠的开放世界识别系统开发。未来工作方向或局限性摘要未明确说明，但可能包括扩展到更多领域或结合其他技术。",
      "tags": [
        "Few-Shot Learning",
        "Out-of-Distribution Detection",
        "Foreground-Background Decomposition",
        "Adaptive Background Suppression",
        "Confusable Patch Rectification"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:43.520655Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15061",
    "title": "Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD",
    "authors": [
      "Qiwei Ma",
      "Jun Zhang"
    ],
    "abstract": "Traditional data masking techniques such as anonymization cannot achieve the expected privacy protection while ensuring data utility for privacy-preserving machine learning. Synthetic data plays an increasingly important role as it generates a large number of training samples and prevents information leakage in real data. The existing methods suffer from the repeating trade-off processes between privacy and utility. We propose a novel framework for differential privacy generation, which employs an Error Feedback Stochastic Gradient Descent(EFSGD) method and introduces a reconstruction loss and noise injection mechanism into the training process. We generate images with higher quality and usability under the same privacy budget as the related work. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both grayscale and RGB images. We achieve state-of-the-art results over almost all metrics on three benchmarks: MNIST, Fashion-MNIST, and CelebA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15061.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15061",
    "published": "2026-01-21T15:07:33Z",
    "updated": "2026-01-21T15:07:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于误差反馈随机梯度下降、重建损失和噪声注入的差分隐私图像生成框架，以提升合成数据的质量和实用性。",
      "motivation": "传统的数据掩码技术如匿名化在隐私保护机器学习中难以同时实现有效隐私保护和数据实用性，合成数据虽能生成大量训练样本并防止信息泄露，但现有方法在隐私和实用性之间常需反复权衡，导致难以优化平衡。本研究旨在解决这一矛盾，通过新方法改善隐私保护图像生成的效率和质量，避免现有方法的不足，以适应日益增长的数据隐私需求。",
      "method": "该论文提出一个新颖的差分隐私生成框架，采用误差反馈随机梯度下降（EFSGD）方法，在训练过程中引入重建损失和噪声注入机制。重建损失用于保持生成图像的数据质量，噪声注入增强隐私保护，关键创新在于结合EFSGD通过误差反馈调整噪声，实现更优的隐私-效用平衡。框架适用于图像生成任务，摘要未明确说明具体模型架构，但强调了技术整合的独特之处。",
      "result": "在相同隐私预算下，提出的框架生成的图像质量和可用性优于相关研究。通过广泛实验，在MNIST、Fashion-MNIST和CelebA基准测试上进行评估，结果表明在几乎所有指标上都实现了最先进的结果，证明了框架的有效性和泛化能力。与基线方法对比，显著提升了生成图像的性能，适用于灰度图和RGB图，但没有提供具体数值数据。",
      "conclusion": "该研究的核心贡献是开发了一个结合误差反馈随机梯度下降、重建损失和噪声注入的差分隐私图像生成框架，学术价值在于改进了隐私保护合成数据生成的方法，实际应用价值在于为机器学习任务提供更高质量的训练数据。尽管展示了泛化能力，摘要未明确说明局限性，未来工作可能包括扩展到其他数据类型或更复杂场景。",
      "tags": [
        "Differential Privacy",
        "Image Generation",
        "Reconstruction Loss",
        "Noise Injection",
        "Error Feedback SGD"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:57.563457Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15059",
    "title": "The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems",
    "authors": [
      "Oleg Romanchuk",
      "Roman Bondar"
    ],
    "abstract": "Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully understand their basis.   We define this condition as responsibility vacuum: a state in which decisions occur, but responsibility cannot be attributed because authority and verification capacity do not coincide. We show that this is not a process deviation or technical defect, but a structural property of deployments where decision generation throughput exceeds bounded human verification capacity.   We identify a scaling limit under standard deployment assumptions, including parallel agent generation, CI-based validation, and individualized human approval gates. Beyond a throughput threshold, verification ceases to function as a decision criterion and is replaced by ritualized approval based on proxy signals. Personalized responsibility becomes structurally unattainable in this regime.   We further characterize a CI amplification dynamic, whereby increasing automated validation coverage raises proxy signal density without restoring human capacity. Under fixed time and attention constraints, this accelerates cognitive offloading in the broad sense and widens the gap between formal approval and epistemic understanding. Additional automation therefore amplifies, rather than mitigates, the responsibility vacuum.   We conclude that unless organizations explicitly redesign decision boundaries or reassign responsibility away from individual decisions toward batch- or system-level ownership, responsibility vacuum remains an invisible but persistent failure mode in scaled agent deployments.",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15059.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15059",
    "published": "2026-01-21T15:05:27Z",
    "updated": "2026-01-21T15:05:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文定义并分析了在扩展代理系统中责任真空现象，指出自动化决策超越人类验证能力导致责任归属失败。",
      "motivation": "该研究动机源于现代CI/CD管道中集成代理生成代码时，发现责任归属存在结构性失败。尽管决策通过正式正确的批准流程执行，但没有任何实体同时具备批准权威和实质理解决策基础的认识能力。这个问题至关重要，因为它揭示在高度自动化的系统中，责任归属机制的失效可能导致决策不可追溯和信任缺失，影响系统的可靠性和安全性。现有方法假设人类能验证自动化决策，但当决策吞吐量超过人类验证能力时，这一假设不成立，从而导致责任真空。",
      "method": "研究方法涉及理论分析，首先定义'责任真空'为决策发生但责任无法归属的状态，权威与验证能力分离。关键创新点包括识别标准部署假设下的扩展限制，如并行代理生成、CI-based验证和个体化人类批准门。通过分析决策生成吞吐量与有限人类验证能力的关系，推导出超过阈值时验证失效。此外，描述了CI放大动态，即增加自动验证覆盖会提高代理信号密度而不提升人类能力，从而加剧责任真空。方法强调结构性属性，而非技术缺陷，未明确使用具体数据集或模型架构。",
      "result": "摘要未明确说明具体实验结果或性能指标。然而，论文通过理论分析得出，在标准部署假设下，当决策生成吞吐量超过特定阈值时，验证功能失效，被仪式化批准取代。这表明个性化责任在结构上无法实现。CI放大动态进一步显示，增加自动验证覆盖会扩大正式批准与实质理解之间的差距，加剧责任真空。这些结果强调了组织设计中需重新思考责任归属机制，以避免持久失败，但与基线方法的对比限于概念层面。",
      "conclusion": "结论指出，责任真空是扩展代理系统中一个隐形但持久的失败模式，源于决策生成与人类验证能力不匹配的结构性属性。主要贡献是定义和分析了这一现象，揭示其非技术性而是组织设计问题。学术价值在于理论框架的提出，实际应用价值在于为组织提供改进CI/CD管道的设计原则。局限性在于分析基于标准假设，未来工作需要实证验证或扩展到其他自动化系统。建议组织重新设计决策边界或将责任转向批处理或系统级所有权。",
      "tags": [
        "CI/CD Pipelines",
        "Agent Systems",
        "Responsibility Attribution",
        "Automated Verification",
        "Decision Boundaries"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:55.608093Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15050",
    "title": "\\textsc{LogicScore}: Fine-grained Logic Evaluation of Conciseness, Completeness, and Determinateness in Attributed Question Answering",
    "authors": [
      "Zhichao Yan",
      "Yunxiao Zhao",
      "Jiapu Wang",
      "Jiaoyan Chen",
      "Shaoru Guo",
      "Xiaoli Li",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "abstract": "Current evaluation methods for Attributed Question Answering (AQA) suffer from \\textit{attribution myopia}: they emphasize verification of isolated statements and their attributions but overlook the global logical integrity of long-form answers. Consequently, Large Language Models (LLMs) often produce factually grounded yet logically incoherent responses with elusive deductive gaps. To mitigate this limitation, we present \\textsc{LogicScore}, a unified evaluation framework that shifts the paradigm from local assessment to global reasoning scrutiny. Grounded in Horn Rules, our approach integrates a backward verification mechanism to systematically evaluate three key reasoning dimensions: \\textit{Completeness} (logically sound deduction), \\textit{Conciseness} (non-redundancy), and \\textit{Determinateness} (consistent answer entailment). Extensive experiments across three multi-hop QA datasets (HotpotQA, MusiQue, and 2WikiMultiHopQA) and over 20 LLMs (including GPT-5, Gemini-3-Pro, LLaMA3, and task-specific tuned models) reveal a critical capability gap: leading models often achieve high attribution scores (e.g., 92.85\\% precision for Gemini-3 Pro) but struggle with global reasoning quality (e.g., 35.11\\% Conciseness for Gemini-3 Pro). Our work establishes a robust standard for logical evaluation, highlighting the need to prioritize reasoning coherence alongside factual grounding in LLM development. Codes are available at: https://github.com/zhichaoyan11/LogicScore.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15050.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15050",
    "published": "2026-01-21T14:52:03Z",
    "updated": "2026-01-21T14:52:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了LogicScore框架，基于Horn Rules和后向验证机制，用于精细评估属性问答中的逻辑推理完整性和连贯性。",
      "motivation": "当前属性问答（AQA）的评价方法存在“归因近视”问题，即过度强调孤立陈述的验证而忽视长形式答案的全局逻辑完整性。这导致大型语言模型（LLMs）常生成事实基础正确但逻辑不连贯的响应，影响了答案的可靠性和实用性。现有方法的不足在于缺乏对推理过程的全面审视，因此亟需新的评估框架来弥补这一缺陷，以提升LLMs的推理能力。",
      "method": "本研究提出了LogicScore统一评估框架，将评估范式从局部转向全局推理审视。该方法基于Horn Rules，整合了后向验证机制，系统性地评估三个关键推理维度：完整性（逻辑严密的演绎）、简洁性（非冗余性）和确定性（一致的答案蕴含）。关键创新点在于利用Horn Rules作为逻辑基础，在三个多跳问答数据集（HotpotQA, MusiQue, 2WikiMultiHopQA）上实施，增强了评估的精细度和准确性。",
      "result": "通过在对三个多跳QA数据集（HotpotQA, MusiQue, 2WikiMultiHopQA）和超过20个LLMs（包括GPT-5, Gemini-3-Pro, LLaMA3等）的广泛实验，发现领先模型在归因得分上表现优异（如Gemini-3 Pro的精度达到92.85%），但在全局推理质量上存在显著差距（如Gemini-3 Pro的简洁性仅为35.11%）。这揭示了模型在逻辑连贯性方面的不足，并突出了LogicScore在提供更全面评估标准上的有效性，与基线方法相比，更能识别逻辑漏洞。",
      "conclusion": "本研究的主要贡献是建立了LogicScore作为评估属性问答逻辑完整性的稳健标准，强调了在LLM开发中需优先考虑推理连贯性。该框架在学术上提供了更全面的评估工具，有助于推动LLMs生成更逻辑一致的答案；实际应用中有潜力提升问答系统的可靠性。摘要未明确说明具体局限性或未来工作方向，但暗示了需要进一步优化模型的全局推理能力。",
      "tags": [
        "Attributed Question Answering",
        "Large Language Models",
        "Horn Rules",
        "Backward Verification",
        "Logic Evaluation"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:11.633220Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15049",
    "title": "Deep Leakage with Generative Flow Matching Denoiser",
    "authors": [
      "Isaac Baglin",
      "Xiatian Zhu",
      "Simon Hadfield"
    ],
    "abstract": "Federated Learning (FL) has emerged as a powerful paradigm for decentralized model training, yet it remains vulnerable to deep leakage (DL) attacks that reconstruct private client data from shared model updates. While prior DL methods have demonstrated varying levels of success, they often suffer from instability, limited fidelity, or poor robustness under realistic FL settings. We introduce a new DL attack that integrates a generative Flow Matching (FM) prior into the reconstruction process. By guiding optimization toward the distribution of realistic images (represented by a flow matching foundation model), our method enhances reconstruction fidelity without requiring knowledge of the private data. Extensive experiments on multiple datasets and target models demonstrate that our approach consistently outperforms state-of-the-art attacks across pixel-level, perceptual, and feature-based similarity metrics. Crucially, the method remains effective across different training epochs, larger client batch sizes, and under common defenses such as noise injection, clipping, and sparsification. Our findings call for the development of new defense strategies that explicitly account for adversaries equipped with powerful generative priors.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15049.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15049",
    "published": "2026-01-21T14:51:01Z",
    "updated": "2026-01-21T14:51:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种利用生成流匹配先验的深度泄漏攻击，显著提高了联邦学习中私有数据重建的保真度和鲁棒性。",
      "motivation": "联邦学习（FL）作为一种分布式模型训练范式，尽管能保护数据隐私，却面临深度泄漏（DL）攻击的威胁，攻击者可从共享模型更新中重建私有客户端数据。现有DL方法虽能不同程度地重建数据，但在实际FL设置中常表现出不稳定性、重建保真度有限以及对防御措施鲁棒性差的问题。因此，开发更有效的攻击方法对于揭示隐私漏洞和推动防御技术发展至关重要。",
      "method": "本方法的核心是将生成流匹配（Flow Matching, FM）先验整合到深度泄漏攻击的重建优化过程中。通过使用预训练的流匹配基础模型来表示真实图像的分布，攻击过程被引导朝向更逼真的重建方向，而无需直接访问私有数据。这一创新点在于利用生成模型先验来增强重建的稳定性和质量，适用于多种目标模型和训练配置，包括不同数据集和模型架构。",
      "result": "实验在多个数据集和目标模型上进行，结果表明所提攻击在像素级相似性（如均方误差）、感知质量（如结构相似性指数）和特征级匹配等指标上均超越现有最先进攻击。关键优势在于该方法在不同训练轮次、较大客户端批次大小以及面对噪声注入、参数裁剪和稀疏化等常见防御时仍保持高效重建能力，证明了其卓越的鲁棒性和重建保真度。",
      "conclusion": "本论文的主要贡献是提出了一种基于生成流匹配先验的深度泄漏攻击，显著提升了数据重建的准确性和鲁棒性。学术上，它揭示了生成模型先验在增强攻击效能方面的潜力；实际上，突显了当前联邦学习防御措施的不足，呼吁开发新的防御策略以应对配备强大生成先验的对手。未来研究方向可能包括探索更广泛的生成模型应用和改进防御机制。",
      "tags": [
        "Federated Learning",
        "Deep Leakage Attack",
        "Generative Flow Matching",
        "Data Reconstruction",
        "Adversarial Robustness"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:52.134713Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15042",
    "title": "Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability",
    "authors": [
      "Andrea Protani",
      "Riccardo Taiello",
      "Marc Molina Van Den Bosch",
      "Luigi Serio"
    ],
    "abstract": "Deep learning models for brain tumor analysis require large and diverse datasets that are often siloed across healthcare institutions due to privacy regulations. We present a federated learning framework for brain tumor localization that enables multi-institutional collaboration without sharing sensitive patient data. Our method extends a hybrid Transformer-Graph Neural Network architecture derived from prior decoder-free supervoxel GNNs and is deployed within CAFEIN\\textsuperscript{\\textregistered}, CERN's federated learning platform designed for healthcare environments. We provide an explainability analysis through Transformer attention mechanisms that reveals which MRI modalities drive the model predictions. Experiments on the BraTS dataset demonstrate a key finding: while isolated training on individual client data triggers early stopping well before reaching full training capacity, federated learning enables continued model improvement by leveraging distributed data, ultimately matching centralized performance. This result provides strong justification for federated learning when dealing with complex tasks and high-dimensional input data, as aggregating knowledge from multiple institutions significantly benefits the learning process. Our explainability analysis, validated through rigorous statistical testing on the full test set (paired t-tests with Bonferroni correction), reveals that deeper network layers significantly increase attention to T2 and FLAIR modalities ($p<0.001$, Cohen's $d$=1.50), aligning with clinical practice.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15042.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15042",
    "published": "2026-01-21T14:46:00Z",
    "updated": "2026-01-21T14:46:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一个结合联邦学习和Transformer-GNN的框架，用于脑肿瘤定位，并引入模态级可解释性分析。",
      "motivation": "深度学习模型用于脑肿瘤分析需要大规模数据集，但医疗数据常因隐私法规分散在不同机构，形成数据孤岛，限制了模型训练和性能提升。现有方法依赖集中式数据收集，违反隐私保护要求，导致孤立训练模型性能不佳。因此，研究旨在解决如何在不共享敏感数据的前提下，实现多机构协作，提升脑肿瘤定位任务的准确性和效率，以满足医疗领域对隐私和性能的双重需求。",
      "method": "本研究开发了一个联邦学习框架，专注于脑肿瘤定位。方法基于混合Transformer-GNN架构，扩展自先前的解码器免费超体素GNN，并部署在CAFEIN®平台——一个为医疗环境定制的联邦学习平台。核心创新点包括结合联邦学习与Transformer-GNN，以处理分布式数据；同时，通过Transformer注意力机制提供可解释性分析，揭示不同MRI模态对预测的影响，增强模型透明度。该方法在BraTS数据集上进行验证。",
      "result": "在BraTS数据集上的实验结果显示，孤立训练时模型过早停止，无法充分利用数据；而采用联邦学习后，通过聚合多机构分布式数据，模型性能持续提升，最终匹配集中式训练的性能。这证明了联邦学习在处理复杂高维输入时的优势。可解释性分析表明，更深网络层显著增加对T2和FLAIR MRI模态的注意力，统计测试验证了其显著性，p值小于0.001，Cohen's d为1.50，与临床实践一致。",
      "conclusion": "本研究的主要贡献是提出了一个联邦学习框架，结合Transformer-GNN和可解释性分析，用于脑肿瘤定位，为医疗隐私保护下的多机构协作提供有效方案。其学术价值在于推进了联邦学习在医疗AI领域的应用，实际价值则体现在提升模型性能的同时保持数据隐私。尽管摘要未明确说明局限性，但该方法有望扩展至其他医疗任务，未来工作可进一步优化可解释性方法或适应更广泛场景。",
      "tags": [
        "Federated Learning",
        "Transformer-GNN",
        "Explainability",
        "Brain Tumor Localization",
        "Attention Mechanism"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:33.837613Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15041",
    "title": "HyperNet-Adaptation for Diffusion-Based Test Case Generation",
    "authors": [
      "Oliver Weißl",
      "Vincenzo Riccio",
      "Severin Kacianka",
      "Andrea Stocco"
    ],
    "abstract": "The increasing deployment of deep learning systems requires systematic evaluation of their reliability in real-world scenarios. Traditional gradient-based adversarial attacks introduce small perturbations that rarely correspond to realistic failures and mainly assess robustness rather than functional behavior. Generative test generation methods offer an alternative but are often limited to simple datasets or constrained input domains. Although diffusion models enable high-fidelity image synthesis, their computational cost and limited controllability restrict their applicability to large-scale testing. We present HyNeA, a generative testing method that enables direct and efficient control over diffusion-based generation. HyNeA provides dataset-free controllability through hypernetworks, allowing targeted manipulation of the generative process without relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning. HyNeA employs a distinct training strategy that supports instance-level tuning to identify failure-inducing test cases without requiring datasets that explicitly contain examples of similar failures. This approach enables the targeted generation of realistic failure cases at substantially lower computational cost than search-based methods. Experimental results show that HyNeA improves controllability and test diversity compared to existing generative test generators and generalizes to domains where failure-labeled training data is unavailable.",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15041.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15041",
    "published": "2026-01-21T14:45:15Z",
    "updated": "2026-01-21T14:45:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出HyNeA方法，通过超网络实现扩散模型的可控生成，以高效生成现实失败测试案例。",
      "motivation": "随着深度学习系统部署的增加，对其可靠性的系统评估变得至关重要。传统基于梯度的对抗攻击方法引入的微小扰动很少对应现实失败，主要评估鲁棒性而非功能行为。生成测试方法虽然提供了一种替代方案，但通常局限于简单数据集或受限输入域。扩散模型虽然能生成高保真图像，但其高计算成本和有限可控性限制了它们在大规模测试中的应用。因此，需要一种能够实现高效可控生成的方法来生成现实的失败案例，以更全面评估系统可靠性。",
      "method": "HyNeA是一种生成测试方法，它利用超网络实现对扩散模型生成的直接和高效控制。该方法提供无需数据集的controllability，通过超网络允许定向操控生成过程，而不依赖于特定架构的条件机制或数据集驱动的调整如微调。关键创新在于采用了独特的训练策略，支持实例级调优，能够在没有包含类似失败示例的数据集的情况下识别导致失败的测试案例。这使得HyNeA能够以比基于搜索的方法低得多的计算成本生成定向的现实失败案例。",
      "result": "实验结果显示，HyNeA在可控性和测试多样性方面优于现有的生成测试生成器。具体来说，它能够提高生成测试案例的质量和范围，并能在无失败标签训练数据的领域中进行泛化。与基线方法相比，HyNeA在生成现实失败案例方面表现出更高的效率和效果，但摘要未提供具体的性能指标如准确率提升数据。",
      "conclusion": "HyNeA的主要贡献在于提出了一种通过超网络实现扩散模型可控生成的方法，有效解决了扩散模型在测试生成中的应用局限。该方法在学术上推动了生成测试技术的发展，提高了测试的实用性和效率；在实际应用中，能够支持大规模深度学习系统的可靠性评估，生成更现实的失败案例。潜在的局限性可能包括对特定类型扩散模型的依赖，摘要未明确说明未来工作方向。",
      "tags": [
        "Diffusion Models",
        "Hypernetworks",
        "Generative Testing",
        "Controllability",
        "Test Case Generation"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:12.967965Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15038",
    "title": "A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem",
    "authors": [
      "Mertcan Daysalilar",
      "Fuat Uyguroglu",
      "Gabriel Nicolosi",
      "Adam Meyers"
    ],
    "abstract": "The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15038.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15038",
    "published": "2026-01-21T14:42:33Z",
    "updated": "2026-01-21T14:42:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种基于课程的深度强化学习框架，通过三阶段课程逐步增加复杂度，有效解决了电动汽车有时间窗口路由问题的训练不稳定性和泛化挑战。",
      "motivation": "电动汽车有时间窗口的路由问题（EVRPTW）是可持续物流中的关键优化挑战，需要最小化旅行距离、车队规模和电池使用，同时满足严格时间约束。现有深度强化学习方法在处理这类约束密集问题时，训练不稳定，难以收敛和泛化，导致在复杂场景下性能不足。因此，开发一种稳定且高效的DRL框架对提升实际应用中的可靠性和效率至关重要，以应对物流优化中的动态需求。",
      "method": "该研究提出基于课程的深度强化学习（CB-DRL）框架，采用结构化的三阶段课程：首先学习距离和车队优化（Phase A），然后集成电池管理（Phase B），最后训练完整EVRPTW（Phase C）。为稳定学习，使用改进的近端策略优化算法，包含阶段特定超参数、值和优势裁剪以及自适应学习率调度。策略网络基于异构图注意力编码器，增强全局-局部注意力和特征线性调制，以明确捕捉depot、客户和充电站的异构特征，确保有效建模问题结构。",
      "result": "模型仅在小型实例（N=10客户）上训练，却能在N=5到N=100的未见实例上实现稳健泛化，显著优于标准基线方法。在中等规模问题上，性能表现突出，且在分布外实例上达到高可行率和竞争性解质量，而传统DRL方法在这些情况下失败。实验证实，课程引导方法有效提升训练稳定性，并在泛化能力上取得显著改进，弥合了神经计算速度与操作可靠性之间的差距。",
      "conclusion": "本研究的主要贡献在于提出一种课程引导的深度强化学习框架，通过结构化课程和专用网络架构，解决了EVRPTW的训练不稳定问题，实现了神经方法与实际应用的有效结合。这提高了模型的泛化能力和求解质量，对智能物流和可持续运输具有重要价值。未来工作可扩展到更复杂约束或更大规模问题，以进一步验证方法的普适性和应用潜力。",
      "tags": [
        "Deep Reinforcement Learning",
        "Curriculum Learning",
        "Proximal Policy Optimization",
        "Graph Attention Network",
        "Electric Vehicle Routing Problem with Time Windows"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:30.397339Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15037",
    "title": "Knowledge Restoration-driven Prompt Optimization: Unlocking LLM Potential for Open-Domain Relational Triplet Extraction",
    "authors": [
      "Xiaonan Jing",
      "Gongqing Wu",
      "Xingrui Zhuo",
      "Lang Sun",
      "Jiapu Wang"
    ],
    "abstract": "Open-domain Relational Triplet Extraction (ORTE) is the foundation for mining structured knowledge without predefined schemas. Despite the impressive in-context learning capabilities of Large Language Models (LLMs), existing methods are hindered by their reliance on static, heuristic-driven prompting strategies. Due to the lack of reflection mechanisms required to internalize erroneous signals, these methods exhibit vulnerability in semantic ambiguity, often making erroneous extraction patterns permanent. To address this bottleneck, we propose a Knowledge Reconstruction-driven Prompt Optimization (KRPO) framework to assist LLMs in continuously improving their extraction capabilities for complex ORTE task flows. Specifically, we design a self-evaluation mechanism based on knowledge restoration, which provides intrinsic feedback signals by projecting structured triplets into semantic consistency scores. Subsequently, we propose a prompt optimizer based on a textual gradient that can internalize historical experiences to iteratively optimize prompts, which can better guide LLMs to handle subsequent extraction tasks. Furthermore, to alleviate relation redundancy, we design a relation canonicalization memory that collects representative relations and provides semantically distinct schemas for the triplets. Extensive experiments across three datasets show that KRPO significantly outperforms strong baselines in the extraction F1 score.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.15037.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15037",
    "published": "2026-01-21T14:42:13Z",
    "updated": "2026-01-21T14:42:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "KRPO框架通过知识恢复驱动的提示优化，提升大型语言模型在开放域关系三元组提取中的性能。",
      "motivation": "开放域关系三元组提取（ORTE）是无预定义模式结构化知识挖掘的基础任务，具有重要应用价值。现有基于大型语言模型的方法依赖静态启发式提示策略，缺乏内部化错误信号的反思机制，导致在语义模糊性面前表现脆弱，容易产生永久性错误提取模式。因此，亟需开发动态优化方法以提高LLMs在复杂ORTE任务中的鲁棒性和准确性。",
      "method": "KRPO框架包括三个核心组件：首先，基于知识恢复的自评估机制，通过将结构化三元组映射到语义一致性分数提供内在反馈信号；其次，基于文本梯度的提示优化器迭代优化提示，内部化历史经验以指导后续任务；最后，关系规范化记忆收集代表性关系并减少冗余，提供语义不同的模式。该方法无需额外监督数据，聚焦于动态调整提示以增强LLMs的提取能力。",
      "result": "实验在三个数据集上进行，结果表明KRPO在提取F1分数方面显著优于多个强基线方法，验证了其在开放域关系三元组提取任务中的有效性。摘要未明确说明具体数据，但强调了显著优势，证实了框架在提升模型性能和克服语义模糊性方面的实用价值。",
      "conclusion": "该研究提出了KRPO框架，通过知识恢复驱动的提示优化，有效解锁LLMs在ORTE任务中的潜力，为无模式知识挖掘提供了创新方法。其学术价值在于扩展了提示优化的应用范围，实际应用价值体现在提高结构化信息提取的准确性和鲁棒性，未来可探索扩展到其他复杂自然语言处理任务。",
      "tags": [
        "Large Language Model",
        "Prompt Optimization",
        "Open-Domain Relational Triplet Extraction",
        "Knowledge Restoration",
        "Textual Gradient"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:44.724823Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15036",
    "title": "Factorizable joint shift revisited",
    "authors": [
      "Dirk Tasche"
    ],
    "abstract": "Factorizable joint shift (FJS) was proposed as a type of distribution shift (or dataset shift) that comprises both covariate and label shift. Recently, it has been observed that FJS actually arises from consecutive label and covariate (or vice versa) shifts. Research into FJS so far has been confined to the case of categorical label spaces. We propose a framework for analysing distribution shift in the case of general label spaces, thus covering both classification and regression models. Based on the framework, we generalise existing results on FJS to general label spaces and propose a related extension of the expectation maximisation (EM) algorithm for class prior probabilities. We also take a fresh look at generalized label shift (GLS) in the case of general label spaces.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15036.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15036",
    "published": "2026-01-21T14:41:49Z",
    "updated": "2026-01-21T14:41:49Z",
    "comment": "23 pages",
    "light_analysis": {
      "overview": "论文提出一个分析一般标签空间下分布偏移的框架，推广了因子化联合偏移（FJS）结果并扩展了期望最大化（EM）算法。",
      "motivation": "因子化联合偏移（FJS）作为一种结合协变量和标签偏移的分布偏移类型，先前研究局限于分类标签空间，但现实中回归等更广泛场景同样重要。这种局限性导致现有方法无法充分处理一般标签空间下的分布变化问题，影响机器学习模型在实际应用中的泛化能力。因此，研究一般标签空间下的分布偏移有助于填补理论空白，提升模型在连续标签或混合数据中的鲁棒性。",
      "method": "论文基于一个新框架来分析一般标签空间下的分布偏移，覆盖分类和回归模型。核心方法包括将现有关于FJS的结果推广到一般标签空间，并提出一种相关的EM算法扩展用于计算类先验概率。此外，还重新审视了广义标签偏移（GLS）在一般标签空间下的情况，关键创新在于框架使分布偏移分析从分类扩展到更广泛的数据类型，为算法设计提供了理论支持。",
      "result": "摘要中未明确说明具体实验结果或性能指标，但表明论文成功将FJS结果推广到一般标签空间，并扩展了EM算法。可以推断，论文通过理论推导展示了框架的有效性，例如可能验证了算法在一般化标签空间下的适用性。然而，由于缺乏与基线方法的对比数据和量化指标（如准确率或效率改进），实证效果仍需进一步实验验证，以明确其在实际应用中的优势。",
      "conclusion": "论文的主要贡献是提供了一个分析一般标签空间下分布偏移的框架，推广了FJS理论并扩展了EM算法，同时重新审视了GLS。这具有重要的学术价值，扩展了分布偏移研究的范畴，为处理分类和回归等更广泛模型提供了理论基础。实际应用价值包括提升机器学习在现实世界数据变化中的适应能力。未来工作可能包括将该框架应用于具体模型进行实证评估，并探索其在不同数据类型中的局限性。",
      "tags": [
        "Factorizable Joint Shift",
        "Expectation Maximization",
        "Distribution Shift",
        "Generalized Label Shift",
        "Covariate Shift"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:04.358990Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15029",
    "title": "Emergent, not Immanent: A Baradian Reading of Explainable AI",
    "authors": [
      "Fabio Morreale",
      "Joan Serrà",
      "Yuki Mistufuji"
    ],
    "abstract": "Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15029.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15029",
    "published": "2026-01-21T14:32:40Z",
    "updated": "2026-01-21T14:32:40Z",
    "comment": "Accepted at CHI 2026",
    "light_analysis": {
      "overview": "本文应用Barad的能动实在论，提出解释性AI的解释是涌现而非内在，挑战了传统技术视角。",
      "motivation": "解释性AI常被视为技术问题，旨在揭示模型内部机制，但这基于未检视的本体认识论假设：意义被视为模型内在属性、解释者被定位为外部观察者、并假设因果结构可通过计算恢复。这些假设可能导致解释偏差，忽略了社会情境和伦理因素，限制了XAI的实际应用效果。因此，本研究旨在批判这些隐含立场，发展一种更全面、基于涌现性的框架，以解决现有方法的不足和伦理缺陷。",
      "method": "本研究以Barad的能动实在论为理论基础，构建解释性AI的替代本体认识论框架。核心方法是通过此框架解读广泛XAI方法集，揭示其隐含假设和局限性；提出解释是物质话语表演，从AI模型与人类、情境及解释装置的动态纠缠中涌现。具体步骤包括分析XAI方法的设计前提，阐述该框架的伦理维度，并以一个推测性文本到音乐接口作为案例研究，提出支持涌现解释的XAI接口设计方向。",
      "result": "摘要未明确说明具体实验数据或性能指标。基于分析，本研究通过能动实在论解读XAI方法，揭示了这些方法中的关键假设，如过度依赖因果性和模型孤立性，并指出了其局限性。结果包括理论层面的发现，如提出解释的涌现性，并通过案例研究展示了设计新接口的可行性，但未提供量化比较或基线方法的性能对比。",
      "conclusion": "本文的主要贡献是提出了基于Barad能动实在论的XAI新框架，强调解释的涌现性和纠缠性，挑战了传统内在主义观点。学术上，这丰富了XAI的本体认识论基础，推动跨学科对话；应用上，为设计更伦理、用户中心的解释接口提供了方向。局限性可能在于框架的抽象性，未来工作可聚焦于实证应用、评估具体设计效果，并扩展至更多领域。",
      "tags": [
        "Explainable AI",
        "Agential Realism",
        "Emergent Interpretation",
        "Material-Discursive Performance",
        "XAI Interfaces"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:07.405197Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15021",
    "title": "Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization",
    "authors": [
      "Adam Rokah",
      "Daniel Veress",
      "Caleb Caulk",
      "Sourav Sharan"
    ],
    "abstract": "Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15021.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15021",
    "published": "2026-01-21T14:22:25Z",
    "updated": "2026-01-21T14:22:25Z",
    "comment": "7 pages, 8 figures. Code available at: https://github.com/moe-project-uu/mixture-of-experts-project",
    "light_analysis": {
      "overview": "本研究系统分析了混合专家模型在图像分类任务中的性能、专家利用率和泛化行为，揭示了其在视觉领域的应用潜力和挑战。",
      "motivation": "混合专家架构常用于大型语言模型以支持条件计算，但在视觉任务中的行为尚未得到充分研究。本研究旨在探索 MoE 在图像分类中的应用，解决现有方法对视觉领域 MoE 优化和泛化理解不足的问题。通过评估预测性能、专家利用率和泛化能力，填补了跨领域模型行为研究的空白，为理解 MoE 在多样化任务中的适用性提供了重要背景。",
      "method": "论文采用 CIFAR10 数据集，在可比模型容量下比较了 Dense、SoftMoE 和 SparseMoE 分类头。核心方法包括使用正则化技术平衡专家利用率以预防专家崩溃。创新点在于引入基于 Hessian 的锐度指标（如最大特征值和迹）来分析模型收敛时的泛化行为，并辅以损失表面扰动分析，定性比较密集和 MoE 模型在有限参数扰动下的非局部行为差异。",
      "result": "实验结果显示，SoftMoE 和 SparseMoE 在验证准确率上略高于 Dense 基线，同时保持了专家利用率平衡。基于 Hessian 的锐度分析表明 SoftMoE 具有更高锐度，而 Dense 和 SparseMoE 在曲率上相似，但所有模型泛化性能相近。推理效率评估指出，在当前硬件规模下，条件路由未带来推理速度提升，突显了理论效率与实际实现之间的差距。",
      "conclusion": "本研究的贡献在于深入分析了 MoE 在视觉任务中的路由、优化和泛化行为，发现其能实现略优性能但推理效率有限。学术价值在于为 MoE 跨领域应用提供实证，并揭示了实际挑战如硬件效率问题。局限性包括规模限制，未来工作可侧重于改进路由机制或优化硬件实现以提升效率。",
      "tags": [
        "Mixture-of-Experts",
        "SoftMoE",
        "SparseMoE",
        "Hessian Analysis",
        "Image Classification"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:27.747773Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15017",
    "title": "SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation",
    "authors": [
      "Yanan Wang",
      "Linjie Ren",
      "Zihao Li",
      "Junyi Wang",
      "Tian Gan"
    ],
    "abstract": "While video-to-audio generation has achieved remarkable progress in semantic and temporal alignment, most existing studies focus solely on these aspects, paying limited attention to the spatial perception and immersive quality of the synthesized audio. This limitation stems largely from current models' reliance on mono audio datasets, which lack the binaural spatial information needed to learn visual-to-spatial audio mappings. To address this gap, we introduce two key contributions: we construct BinauralVGGSound, the first large-scale video-binaural audio dataset designed to support spatially aware video-to-audio generation; and we propose a end-to-end spatial audio generation framework guided by visual cues, which explicitly models spatial features. Our framework incorporates a visual-guided audio spatialization module that ensures the generated audio exhibits realistic spatial attributes and layered spatial depth while maintaining semantic and temporal alignment. Experiments show that our approach substantially outperforms state-of-the-art models in spatial fidelity and delivers a more immersive auditory experience, without sacrificing temporal or semantic consistency. All datasets, code, and model checkpoints will be publicly released to facilitate future research.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15017.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15017",
    "published": "2026-01-21T14:14:37Z",
    "updated": "2026-01-21T14:14:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出通过构建首个大规模视频-双声道音频数据集和端到端视觉引导框架，实现高保真空间音频生成，填补了视频到音频生成中空间感知的空白。",
      "motivation": "现有视频到音频生成研究主要关注语义和时间对齐，却忽视了空间感知和沉浸感，这源于模型依赖单声道音频数据集，缺乏双声道空间信息来学习视觉到音频的映射。空间音频对于虚拟现实等应用的沉浸式体验至关重要，因此解决这一问题具有重要研究价值，以提高音频合成的真实感和用户体验。",
      "method": "论文提出一个端到端的空间音频生成框架，由视觉线索引导，包含视觉引导的音频空间化模块，用于明确建模空间特征如空间属性和层次深度。该方法在保持与视频的语义和时间对齐的同时，生成具有真实空间效果的音频。为支持训练，构建了首个大规模视频-双声道音频数据集 BinauralVGGSound，提供了丰富的空间信息数据，以学习视觉到空间音频的映射。",
      "result": "实验结果表明，该方法在空间保真度方面显著优于现有最先进的模型，提供更沉浸的听觉体验，同时不牺牲语义或时间一致性。与基线方法相比，生成的音频具有更高的空间真实感。所有数据集、代码和模型检查点将公开发布，以促进未来研究。摘要未明确说明具体性能指标数值。",
      "conclusion": "本论文的主要贡献是构建了首个大规模视频-双声道音频数据集和提出视觉引导的空间音频生成框架，显著提升了音频合成的空间保真度。其学术价值在于填补了视频到音频生成中空间感知研究的空白，为未来研究提供了基准；实际应用中，可增强虚拟现实、游戏等领域的沉浸式体验。摘要未明确说明局限性，但公开发布资源将支持进一步探索和改进。",
      "tags": [
        "Binaural Audio",
        "Spatial Audio Generation",
        "Visual-Guided Model",
        "Dataset Construction",
        "End-to-End Framework"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:57.264145Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15016",
    "title": "LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding",
    "authors": [
      "Xiaodong Wang",
      "Langling Huang",
      "Zhirong Wu",
      "Xu Zhao",
      "Teng Xu",
      "Xuhong Xia",
      "Peixi Peng"
    ],
    "abstract": "The development of multimodal large language models (MLLMs) has advanced general video understanding. However, existing video evaluation benchmarks primarily focus on non-interactive videos, such as movies and recordings. To fill this gap, this paper proposes the first omnimodal benchmark for interactive livestream videos, LiViBench. It features a diverse set of 24 tasks, highlighting the perceptual, reasoning, and livestream-specific challenges. To efficiently construct the dataset, we design a standardized semi-automatic annotation workflow that incorporates the human-in-the-loop at multiple stages. The workflow leverages multiple MLLMs to form a multi-agent system for comprehensive video description and uses a seed-question-driven method to construct high-quality annotations. All interactive videos in the benchmark include audio, speech, and real-time comments modalities. To enhance models' understanding of interactive videos, we design tailored two-stage instruction-tuning and propose a Video-to-Comment Retrieval (VCR) module to improve the model's ability to utilize real-time comments. Based on these advancements, we develop LiVi-LLM-7B, an MLLM with enhanced knowledge of interactive livestreams. Experiments show that our model outperforms larger open-source models with up to 72B parameters, narrows the gap with leading proprietary models on LiViBench, and achieves enhanced performance on general video benchmarks, including VideoMME, LongVideoBench, MLVU, and VideoEval-Pro.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15016.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15016",
    "published": "2026-01-21T14:14:20Z",
    "updated": "2026-01-21T14:14:20Z",
    "comment": "AAAI 2026 Main Track",
    "light_analysis": {
      "overview": "论文提出了首个全模态交互式直播视频基准LiViBench，并开发了增强的多模态大语言模型LiVi-LLM-7B以提升视频理解能力。",
      "motivation": "现有视频理解基准主要针对非交互式视频（如电影），而交互式直播视频包含音频、语音和实时评论等多模态交互特性，现有评估工具不足以准确评估模型性能。该研究旨在填补这一空白，提供一个全面的基准来系统评估多模态大语言模型在直播视频中的表现，推动这一新兴领域的发展。",
      "method": "研究提出LiViBench基准，包含24个任务，涵盖感知、推理和直播特定挑战。采用半自动标注工作流，结合人类在环和多智能体系统生成视频描述，并使用种子问题驱动方法构建高质量数据集。设计了两阶段指令调优和视频到评论检索（VCR）模块，以增强模型利用实时评论的能力，并基于此开发了LiVi-LLM-7B模型。",
      "result": "实验显示，LiVi-LLM-7B在LiViBench基准上超越了参数规模更大的开源模型（如达72B），并缩小了与领先专有模型的性能差距。同时，在通用视频基准（包括VideoMME、LongVideoBench、MLVU和VideoEval-Pro）上也表现出增强的性能，证明了模型的有效性和泛化能力。",
      "conclusion": "论文的主要贡献是推出了LiViBench基准和LiVi-LLM-7B模型，为交互式直播视频理解提供了标准化评估和改进方案。这促进了多模态大语言模型在实时、多模态视频分析中的应用，具有重要学术和实际价值。未来工作可能包括扩展基准覆盖更多任务或进一步优化模型架构。",
      "tags": [
        "Multimodal Large Language Models (MLLMs)",
        "Interactive Livestream Videos",
        "Benchmark Evaluation",
        "Instruction Tuning",
        "Video-to-Comment Retrieval (VCR)"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:09.448896Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15015",
    "title": "Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control",
    "authors": [
      "Jannis Becktepe",
      "Aleksandra Franz",
      "Nils Thuerey",
      "Sebastian Peitz"
    ],
    "abstract": "Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15015.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15015",
    "published": "2026-01-21T14:13:44Z",
    "updated": "2026-01-21T14:13:44Z",
    "comment": "Code available at https://github.com/safe-autonomous-systems/fluidgym",
    "light_analysis": {
      "overview": "本论文提出了FluidGym，首个独立且完全可微分的强化学习基准套件，用于主动流控制领域，以解决现有基准的局限性。",
      "motivation": "当前强化学习在主动流控制中的应用研究评估困难，因为现有工作依赖异构的观察和致动方案、数值设置和评估协议。现有的基准如基于计算流体动力学的求解器，不仅依赖外部软件、不完全可微分，还缺乏对3D场景和多智能体的支持。这些问题限制了AFC RL研究的系统比较和进展，因此需要一个新的基准套件来提供标准化和可扩展的评估平台，以推动该领域的发展。",
      "method": "作者开发了FluidGym，一个完全在PyTorch上构建的基准套件，利用GPU加速的PICT求解器实现高效计算。关键创新包括自包含的运行环境、完全可微分设计以及标准化评估协议。FluidGym在单个Python堆栈中运行，无需外部计算流体动力学软件，从而简化了算法集成和优化过程。该套件支持灵活的环境配置，便于大规模流控制实验。",
      "result": "论文展示了使用PPO（近端策略优化）和SAC（软演员-评论家）算法在FluidGym环境中的基准结果，验证了该套件的可行性。所有环境、数据集和训练模型已作为公共资源发布，促进了未来研究的复现和扩展。尽管摘要未明确说明具体的性能指标提升，但通过提供标准化测试，该基准支持了不同控制方法的公平比较，为后续研究奠定了基础。",
      "conclusion": "本论文的主要贡献是推出了FluidGym基准套件，为强化学习在主动流控制中的研究提供了一个统一的评估框架。它解决了现有基准的不足，支持系统化的方法比较，并建立了可扩展的研究基础。FluidGym的开源可用性将促进该领域的学术进展，未来工作可扩展到更多复杂场景，如真实世界的流控应用，并进一步优化性能和兼容性。",
      "tags": [
        "Reinforcement Learning",
        "Active Flow Control",
        "Differentiable Benchmarking",
        "PyTorch",
        "Computational Fluid Dynamics"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:51.548796Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15013",
    "title": "RadixMLP - Intra-batch Deduplication for Causal Transformers",
    "authors": [
      "Michael Feil",
      "Julius Lipp"
    ],
    "abstract": "Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\\times$ speedups in realistic reranking workloads, with up to $5\\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15013.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15013",
    "published": "2026-01-21T14:11:46Z",
    "updated": "2026-01-21T14:11:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出RadixMLP技术，通过消除因果Transformer批量推理中共享前缀的冗余MLP计算，显著提升推理效率。",
      "motivation": "因果Transformer模型在批量推理任务中，经常处理具有共享前缀的序列，如系统提示、少量示例或共享查询。标准推理引擎独立处理每个序列，导致对相同前缀部分重复计算MLP激活、LayerNorms、线性投影和嵌入，造成计算资源浪费。这一问题在现实应用中尤为重要，因为它影响了推理速度和成本，尤其是在服务基准和资源受限环境中。现有方法未能有效利用序列间的相似性来优化计算，因此需要一种技术来消除这种冗余，提高效率。",
      "method": "RadixMLP技术利用MLP、LayerNorms、线性投影和嵌入的位置性质，动态将批次序列映射到前缀字典树，通过将共享段聚集成压缩表示进行位置计算，仅在注意力边界处将结果分散回各序列。该方法是无状态的，在单次前向传播中操作，避免了冗余计算。关键创新点包括动态映射、压缩表示和位置计算优化。在实验中，使用MS~MARCO v1.1数据集和Qwen3模型（参数范围从0.6B到8B）进行验证，以展示其有效性。",
      "result": "在MS~MARCO v1.1的端到端服务基准测试中，RadixMLP在现实的重新排序工作负载中实现了1.44-1.59倍的推理速度提升。在合成基准测试中，当共享前缀更长时，加速效果可达5倍。这些结果与标准推理引擎作为基线相比，显著减少了计算时间，证明了RadixMLP在消除冗余计算和提升效率方面的有效性。具体数据表明，该方法在不同参数规模的模型上都能稳定加速。",
      "conclusion": "RadixMLP的主要贡献是提出了一种针对因果Transformer批量推理的冗余消除技术，通过压缩共享前缀计算来提高推理效率。该研究具有学术价值，优化了Transformer模型的推理过程，为高效推理提供了新思路。在实际应用中，它能加速服务基准，降低计算成本。尽管摘要未明确说明局限性，但未来工作可探索更广泛模型的支持、更复杂前缀处理场景的扩展，或与其他优化技术结合。",
      "tags": [
        "Causal Transformer",
        "MLP Optimization",
        "Prefix Trie",
        "Inference Acceleration",
        "Batch Deduplication"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:11.367133Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.15000",
    "title": "Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors",
    "authors": [
      "Christos Petridis",
      "Konstantinos Pelechrinis"
    ],
    "abstract": "Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.15000.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15000",
    "published": "2026-01-21T13:57:42Z",
    "updated": "2026-01-21T13:57:42Z",
    "comment": "7 pages, 4 figures",
    "light_analysis": {
      "overview": "本文提出了一种基于回归的阵容正则化调整加减分方法，利用球员信息和对手控制来提高篮球阵容评级的预测能力。",
      "motivation": "在篮球等体育分析中，识别球员组合（阵容）的表现是关键任务，但主要挑战是比赛中频繁换人导致数据高度稀疏。例如，NBA球队一个赛季使用超过600个阵容，平均每个阵容仅参与25-30个回合，使得统计数据嘈杂且预测价值低。目前没有公开工作专门解决这个问题，这限制了阵容评级的准确性和实用性，因此需要开发新方法来处理数据稀疏性，提升体育分析的效能。",
      "method": "本文提出了一种回归方法，称为阵容正则化调整加减分。该方法的核心创新点在于控制每个阵容所面对的对手影响，并利用组成阵容的球员信息作为先验知识。通过融合对手控制和球员信息，旨在减少数据稀疏带来的噪声，并提高评级的准确性。摘要未明确说明具体的数据集细节或模型架构，但可以推断它使用NBA数据，并结合统计模型中的正则化技术来优化估计。",
      "result": "实验结果表明，L-RAPM比当前使用的基线方法提供了更好的预测能力。具体来说，预测性能的改进随着阵容样本量的减少而增加，表明该方法在处理小样本数据时尤为有效。摘要未提供具体的性能指标如准确率提升百分比，但强调了改进的预测价值和减少噪声的优势，验证了其在实际应用中的潜力。",
      "conclusion": "本研究的主要贡献是提出了L-RAPM方法，有效解决了篮球阵容评级中的数据稀疏问题。其学术价值在于填补了体育分析领域的方法空白，为相关研究提供了新思路；实际应用价值在于为球队提供更可靠的阵容效果评估，辅助战术决策优化。未来工作方向可能包括扩展到其他体育项目或整合更多数据源，但摘要未明确说明具体局限性。",
      "tags": [
        "Regression Analysis",
        "Regularization",
        "Adjusted Plus-Minus",
        "Sports Analytics"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:42.943051Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14994",
    "title": "Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora",
    "authors": [
      "Chaymaa Abbas",
      "Nour Shamaa",
      "Mariette Awad"
    ],
    "abstract": "Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals.   Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14994.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14994",
    "published": "2026-01-21T13:53:04Z",
    "updated": "2026-01-21T13:53:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种Translation-Aware Contamination Detection方法，用于检测多语言环境中通过翻译隐藏的大型语言模型数据污染问题。",
      "motivation": "数据污染削弱了大型语言模型评估的有效性，因为模型可能依赖记忆的基准内容而非真实泛化能力。现有检测方法主要限于英语基准，导致多语言污染未被充分理解，这在多语言评估中形成了盲点，影响评估的公平和透明度，亟需研究以提升评估可靠性。",
      "method": "论文通过微调多个开放权重的LLM在不同比例的阿拉伯语数据集上，并评估其在原始英语基准上的表现，以研究多语言污染动态。关键创新是扩展了Tested Slot Guessing方法，结合choice-reordering策略和Min-K%概率分析，捕捉行为和分布污染信号，并提出了Translation-Aware Contamination Detection，通过比较多个翻译基准变体的信号来检测污染。",
      "result": "实验结果显示，翻译成阿拉伯语抑制了传统污染指标，但模型仍从污染数据中受益，特别是阿拉伯语能力强的模型，这体现在Mink%分数随污染水平上升而增加，以及跨语言答案一致性增强。提出的Translation-Aware Contamination Detection方法能可靠暴露污染，即使在仅使用英语的方法失败时也有效。",
      "conclusion": "论文的主要贡献是提出了Translation-Aware Contamination Detection方法，强调多语言、翻译感知评估管道的重要性，以确保LLM评估的公平、透明和可复现。这为更健壮的模型评估实践提供了基础，未来可扩展至其他语言或应用场景。",
      "tags": [
        "Large Language Model",
        "Data Contamination",
        "Multilingual Evaluation",
        "Translation-Aware Detection",
        "Min-K% Probability Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:55.807747Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14978",
    "title": "Unified Multi-Dataset Training for TBPS",
    "authors": [
      "Nilanjana Chatterjee",
      "Sidharatha Garg",
      "A V Subramanyam",
      "Brejesh Lall"
    ],
    "abstract": "Text-Based Person Search (TBPS) has seen significant progress with vision-language models (VLMs), yet it remains constrained by limited training data and the fact that VLMs are not inherently pre-trained for pedestrian-centric recognition. Existing TBPS methods therefore rely on dataset-centric fine-tuning to handle distribution shift, resulting in multiple independently trained models for different datasets. While synthetic data can increase the scale needed to fine-tune VLMs, it does not eliminate dataset-specific adaptation. This motivates a fundamental question: can we train a single unified TBPS model across multiple datasets? We show that naive joint training over all datasets remains sub-optimal because current training paradigms do not scale to a large number of unique person identities and are vulnerable to noisy image-text pairs. To address these challenges, we propose Scale-TBPS with two contributions: (i) a noise-aware unified dataset curation strategy that cohesively merges diverse TBPS datasets; and (ii) a scalable discriminative identity learning framework that remains effective under a large number of unique identities. Extensive experiments on CUHK-PEDES, ICFG-PEDES, RSTPReid, IIITD-20K, and UFine6926 demonstrate that a single Scale-TBPS model outperforms dataset-centric optimized models and naive joint training.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14978.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14978",
    "published": "2026-01-21T13:26:28Z",
    "updated": "2026-01-21T13:26:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了Scale-TBPS，通过噪声感知数据集整理和可扩展身份学习框架，实现了跨多个数据集的统一文本行人搜索模型训练。",
      "motivation": "文本行人搜索（TBPS）基于视觉-语言模型（VLMs）取得进展，但受限于训练数据不足和VLMs缺乏行人识别预训练。现有方法依赖于数据集特定微调来处理分布偏移，导致为每个数据集训练独立模型，效率低下。合成数据虽能增加训练规模，但无法消除数据集特定适应问题，朴素联合训练因无法处理大量身份和噪声而次优。因此，研究动机是探索跨数据集统一训练，以提高模型泛化能力和效率。",
      "method": "研究提出Scale-TBPS方法，核心包括两个创新点：一是噪声感知统一数据集整理策略，有机合并多个TBPS数据集，减少噪声图像-文本对的影响；二是可扩展的判别性身份学习框架，设计用于在大量独特身份下保持学习效果。该方法基于VLMs，在CUHK-PEDES、ICFG-PEDES、RSTPReid、IIITD-20K和UFine6926数据集上进行训练，通过优化训练范式来处理多数据集场景。",
      "result": "实验在CUHK-PEDES、ICFG-PEDES、RSTPReid、IIITD-20K和UFine6926五个数据集上进行，结果显示单个Scale-TBPS模型优于数据集中心优化模型和朴素联合训练方法，表明统一训练能提升性能。具体性能指标摘要未明确说明，但结果验证了Scale-TBPS在跨数据集训练中的有效性。",
      "conclusion": "论文的主要贡献是提出Scale-TBPS，解决了跨数据集统一训练的挑战，通过噪声感知数据整理和可扩展学习框架实现更优性能。研究意义在于提升了TBPS模型的泛化能力和效率，为多数据集应用提供解决方案。局限性或未来工作摘要未明确说明，但可能涉及扩展到更多数据集或进一步优化学习框架。",
      "tags": [
        "Text-Based Person Search",
        "Vision-Language Models",
        "Noise-Aware Curation",
        "Discriminative Identity Learning",
        "Unified Training"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:16.498894Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14971",
    "title": "Fine-Grained Traceability for Transparent ML Pipelines",
    "authors": [
      "Liping Chen",
      "Mujie Liu",
      "Haytham Fayek"
    ],
    "abstract": "Modern machine learning systems are increasingly realised as multistage pipelines, yet existing transparency mechanisms typically operate at a model level: they describe what a system is and why it behaves as it does, but not how individual data samples are operationally recorded, tracked, and verified as they traverse the pipeline. This absence of verifiable, sample-level traceability leaves practitioners and users unable to determine whether a specific sample was used, when it was processed, or whether the corresponding records remain intact over time. We introduce FG-Trac, a model-agnostic framework that establishes verifiable, fine-grained sample-level traceability throughout machine learning pipelines. FG-Trac defines an explicit mechanism for capturing and verifying sample lifecycle events across preprocessing and training, computes contribution scores explicitly grounded in training checkpoints, and anchors these traces to tamper-evident cryptographic commitments. The framework integrates without modifying model architectures or training objectives, reconstructing complete and auditable data-usage histories with practical computational overhead. Experiments on a canonical convolutional neural network and a multimodal graph learning pipeline demonstrate that FG-Trac preserves predictive performance while enabling machine learning systems to furnish verifiable evidence of how individual samples were used and propagated during model execution.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14971.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14971",
    "published": "2026-01-21T13:21:30Z",
    "updated": "2026-01-21T13:21:30Z",
    "comment": "Accepted at The Web Conference (WWW) 2026",
    "light_analysis": {
      "overview": "本文提出了FG-Trac框架，用于实现机器学习管道中的细粒度、可验证的样本级可追溯性。",
      "motivation": "现代机器学习系统通常实现为多阶段管道，但现有透明度机制主要在模型级别操作，缺乏对单个数据样本的详细追踪。这使得实践者无法验证样本是否被正确使用、处理时间或记录完整性，影响系统可信度和审计需求。现有方法的不足在于忽略了样本级的操作细节，难以满足实际应用中对透明度和可追溯性的严格要求，尤其是在需要验证数据使用历史的场景中。",
      "method": "研究提出的FG-Trac框架是一个模型无关的方法，通过捕获和验证样本在预处理和训练过程中的生命周期事件来实现可追溯性。它基于训练检查点计算样本贡献分数，并使用密码学承诺锚定痕迹以防篡改，无需修改模型架构或训练目标。框架能够重建完整的数据使用历史供审计使用，具有实际计算开销，关键创新点在于结合了细粒度追踪和可验证性机制，支持多种机器学习管道设置。",
      "result": "实验在一个经典卷积神经网络和一个多模态图学习管道上进行，结果显示FG-Trac在保持预测性能的同时，能够提供可验证的证据，说明单个样本在模型执行过程中的使用和传播情况。具体性能指标如准确率未在摘要中详细说明，但验证了框架在不损害性能的前提下增强可追溯性，与基线方法相比，显著提升了数据透明度和审计能力。",
      "conclusion": "FG-Trac框架的主要贡献是实现机器学习管道中的样本级可追溯性，填补现有透明度机制在细粒度追踪方面的空白。其学术价值在于推进了机器学习透明度的理论研究，实际应用价值包括增强系统信任和满足合规需求。局限性方面摘要未明确说明，未来工作可能涉及扩展到更复杂场景或进一步优化计算效率。",
      "tags": [
        "Fine-Grained Traceability",
        "Machine Learning Pipelines",
        "Cryptographic Commitments",
        "Model-Agnostic Framework",
        "Sample-Level Audit"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:47.338202Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14968",
    "title": "InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement",
    "authors": [
      "Mingyue Cheng",
      "Xiaoyu Tao",
      "Huajian Zhang",
      "Qi Liu",
      "Enhong Chen"
    ],
    "abstract": "Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14968.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14968",
    "published": "2026-01-21T13:12:23Z",
    "updated": "2026-01-21T13:12:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出InstructTime++框架，通过多模态语言建模和隐式特征增强重新定义时间序列分类为生成任务，解决了现有方法的局限性。",
      "motivation": "大多数现有时间序列分类方法采用判别式范式，直接将输入序列映射到独热编码类标签。尽管有效，但这种方法难以融入上下文特征，且无法捕捉类间的语义关系，限制了性能提升和语义理解。因此，研究旨在开发一种新框架来克服这些不足，通过多模态生成任务增强时间序列分类的准确性和可解释性。",
      "method": "论文提出了InstructTime框架，将时间序列分类重新表述为多模态生成任务，其中连续数值序列、上下文文本特征和任务指令作为输入，类标签由调整后的语言模型生成文本输出。关键技术包括时间序列离散化模块将连续序列转换为离散令牌、对齐投影层和生成式自监督预训练策略以优化跨模态表示对齐。在此基础上，InstructTime++引入了隐式特征建模，通过专门工具包挖掘原始数据和上下文中的信息性隐式模式，如统计特征提取和基于视觉语言的图像字幕生成，并将其转化为文本描述以增强模型集成。",
      "result": "实验在多个基准数据集上进行，结果表明InstructTime++表现出优越的性能，优于现有方法。通过多模态生成和隐式特征增强，该框架有效提升了分类准确率和语义理解能力，但摘要未明确说明具体性能指标如准确率提升数值。与基线方法对比，推断其在标准测试中实现了显著改进，验证了方法的有效性。",
      "conclusion": "本文的主要贡献是提出并验证了InstructTime++框架，它创新性地将时间序列分类转化为多模态生成任务，并引入隐式特征增强来补偿语言模型的有限归纳偏差。这一研究拓展了时间序列分析的技术路线，具有学术价值和应用潜力，未来工作可进一步探索更复杂的多模态集成或扩展到其他领域如预测任务。",
      "tags": [
        "Time Series Classification",
        "Multimodal Language Modeling",
        "Implicit Feature Enhancement",
        "Generative Self-Supervised Learning",
        "Statistical Feature Extraction"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:14.065249Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14959",
    "title": "Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers",
    "authors": [
      "Xinyu Peng",
      "Han Li",
      "Yuyang Huang",
      "Ziyang Zheng",
      "Yaoming Wang",
      "Xin Chen",
      "Wenrui Dai",
      "Chenglin Li",
      "Junni Zou",
      "Hongkai Xiong"
    ],
    "abstract": "Existing video frame interpolation (VFI) methods often adopt a frame-centric approach, processing videos as independent short segments (e.g., triplets), which leads to temporal inconsistencies and motion artifacts. To overcome this, we propose a holistic, video-centric paradigm named \\textbf{L}ocal \\textbf{D}iffusion \\textbf{F}orcing for \\textbf{V}ideo \\textbf{F}rame \\textbf{I}nterpolation (LDF-VFI). Our framework is built upon an auto-regressive diffusion transformer that models the entire video sequence to ensure long-range temporal coherence. To mitigate error accumulation inherent in auto-regressive generation, we introduce a novel skip-concatenate sampling strategy that effectively maintains temporal stability. Furthermore, LDF-VFI incorporates sparse, local attention and tiled VAE encoding, a combination that not only enables efficient processing of long sequences but also allows generalization to arbitrary spatial resolutions (e.g., 4K) at inference without retraining. An enhanced conditional VAE decoder, which leverages multi-scale features from the input video, further improves reconstruction fidelity. Empirically, LDF-VFI achieves state-of-the-art performance on challenging long-sequence benchmarks, demonstrating superior per-frame quality and temporal consistency, especially in scenes with large motion. The source code is available at https://github.com/xypeng9903/LDF-VFI.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14959.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14959",
    "published": "2026-01-21T12:58:52Z",
    "updated": "2026-01-21T12:58:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出LDF-VFI方法，基于自回归扩散变换器实现全息视频帧插值，显著提升长序列时间一致性和帧质量。",
      "motivation": "视频帧插值（VFI）现有方法通常采用帧中心范式，将视频处理为独立短片段（如三元组），这导致时间不一致性和运动伪影，影响视频流畅度和真实感。随着高分辨率视频（如4K）应用增多，高质量插值对视频编辑、慢动作回放等场景至关重要，但传统方法缺乏全序列建模能力，难以处理长范围依赖和错误累积问题，限制了在复杂动态场景中的性能。",
      "method": "LDF-VFI框架基于自回归扩散变换器，对整个视频序列进行建模以确保长范围时间一致性。关键创新包括：引入skip-concatenate采样策略减轻自回归生成中的错误累积；结合稀疏局部注意力和平铺VAE编码，实现高效处理长序列并支持推理时泛化到任意空间分辨率（如4K）而无需重新训练；使用增强的条件VAE解码器，利用输入视频的多尺度特征提升重建保真度。摘要未明确说明具体数据集或模型架构细节。",
      "result": "在挑战性长序列基准测试中，LDF-VFI达到了最先进的性能，展现出优越的每帧质量和时间一致性，特别是在大运动场景中。摘要未明确说明具体的准确率提升或效率改进数据，但强调了其在长序列处理上的优势，与基线方法相比，有效减少了运动伪影和错误累积。",
      "conclusion": "本研究的主要贡献是提出LDF-VFI，一种全息视频帧插值方法，通过结合自回归扩散变换器、skip-concatenate采样和优化编码策略，解决了现有方法的时间不一致性问题。学术上，该方法推动了视频处理领域的建模创新；实际上，其高效性和泛化能力适用于高分辨率视频应用，如实时插值和视频增强。未来工作可探索在更复杂动态场景中的性能优化或扩展应用到其他视频任务。",
      "tags": [
        "Video Frame Interpolation",
        "Auto-regressive Diffusion Transformers",
        "Skip-Concatenate Sampling",
        "Sparse Local Attention",
        "Tiled VAE Encoding"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:46.527589Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14958",
    "title": "A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala",
    "authors": [
      "Minuri Rajapakse",
      "Ruvan Weerasinghe"
    ],
    "abstract": "The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14958.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14958",
    "published": "2026-01-21T12:58:46Z",
    "updated": "2026-01-21T12:58:46Z",
    "comment": "6 pages, 1 figure, 3 tables",
    "light_analysis": {
      "overview": "本文提出一个全面基准，评估现代语言模型在Unicode和罗马化僧伽罗语上的表现，为相关应用提供模型选择参考。",
      "motivation": "僧伽罗语作为低资源且形态丰富的语言，其罗马化版本在数字通信中广泛使用，但语言模型在此类语言上的性能尚未得到充分研究。现有方法的局限性在于缺乏针对Unicode和罗马化脚本的综合评估，这导致实际应用中模型选择困难。本研究旨在填补这一空白，通过全面评估为僧伽罗语处理提供实用指导。",
      "method": "研究方法包括构建一个包含Unicode和罗马化僧伽罗语的多样化语料库，对开源语言模型使用困惑度作为定量指标评估预测性能，同时对领先的闭源模型通过句子完成任务进行定性分析。这种结合定量和定性的方法确保了评估的全面性，关键创新在于首次针对僧伽罗语的两种脚本进行系统基准测试，为相关研究提供了技术框架。",
      "result": "实验结果揭示，Mistral-Nemo-Base-2407在Unicode文本上表现出最强的预测性能，而Mistral-7B-v0.3在罗马化文本上最优；Llama-3.1-8B在两个脚本上都显示出良好的整体性能。闭源模型间存在显著性能差异：Gemini-1.5-pro和DeepSeek在Unicode生成上表现优异，而Claude-3.5-Sonnet在罗马化文本处理上更胜一筹。这些发现为模型选择提供了具体参考，但摘要未明确说明具体性能指标数值。",
      "conclusion": "本研究通过综合基准评估，为僧伽罗语特定应用中的语言模型选择提供了重要指南，并指出训练数据在处理脚本变化中的关键作用。学术价值在于填补了低资源语言模型评估的空白，实际应用价值在于帮助实践者优化模型部署。局限性可能在于仅聚焦于僧伽罗语，未来工作可扩展到其他类似语言以验证通用性。",
      "tags": [
        "Language Models",
        "Benchmark Evaluation",
        "Unicode",
        "Romanized Sinhala",
        "Perplexity"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:32.661716Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14957",
    "title": "Improving Regret Approximation for Unsupervised Dynamic Environment Generation",
    "authors": [
      "Harry Mead",
      "Bruno Lacerda",
      "Jakob Foerster",
      "Nick Hawes"
    ],
    "abstract": "Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14957.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14957",
    "published": "2026-01-21T12:58:40Z",
    "updated": "2026-01-21T12:58:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Dynamic Environment Generation (DEGen) 方法和Maximised Negative Advantage (MNA) 后悔近似，以改进无监督环境设计中的信用分配和挑战性层级识别，提升强化学习的泛化性能。",
      "motivation": "无监督环境设计(UED)是强化学习的关键方向，旨在通过自动生成训练课程来提高代理的泛化和零次性能。然而，设计有效课程在复杂环境中面临挑战，尤其是当环境参数的小子集导致策略需求剧增时。现有方法存在信用分配困难和后悔近似不准确的问题，这些问题随环境规模增大而恶化，限制了UED的可扩展性和课程生成效果，亟需改进以应对实际应用的动态性。",
      "method": "研究提出Dynamic Environment Generation (DEGen) 方法，通过设计更密集的层级生成器奖励信号来减轻信用分配的复杂度，使UED能扩展到更大规模的环境。同时，引入了Maximised Negative Advantage (MNA) 作为新的后悔近似度量，它通过优化过程更精确地识别挑战性层级，改进UED的性能。DEGen与MNA结合，形成了一个集成框架，利用强化学习技术自动生成动态环境课程。",
      "result": "实证研究表明，Maximised Negative Advantage (MNA) 后悔近似在性能上优于当前基准方法。当MNA与DEGen结合使用时，该方法在所有实验中一致优于现有UED方法，特别是在环境规模增大的情况下，展现出更强的可扩展性和层级识别能力。摘要未提供具体数据指标，但结果强调了方法在课程生成效率上的显著提升。",
      "conclusion": "本研究通过DEGen和MNA的创新，有效解决了无监督环境设计中的信用分配和挑战性层级识别问题，显著提升了UED的可扩展性和应用潜力。这项工作对强化学习的泛化理论有重要学术价值，并可能促进自动化课程生成在现实场景中的部署。未来工作可探索方法在更复杂环境中的鲁棒性，以及优化计算效率以适应更大规模任务。",
      "tags": [
        "Unsupervised Environment Design",
        "Reinforcement Learning",
        "Regret Approximation",
        "Dynamic Environment Generation",
        "Credit Assignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:56.522739Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14955",
    "title": "Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation",
    "authors": [
      "Hanqi Jin",
      "Gaoming Yang",
      "Zhangming Chan",
      "Yapeng Yuan",
      "Longbin Li",
      "Fei Sun",
      "Yeqiu Yang",
      "Jian Wu",
      "Yuning Jiang",
      "Bo Zheng"
    ],
    "abstract": "User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for un- derstanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi- behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional trans- formers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behav- ior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while sig- nificantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14955.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14955",
    "published": "2026-01-21T12:53:32Z",
    "updated": "2026-01-21T12:53:32Z",
    "comment": "Accepted by WWW2026 short paper",
    "light_analysis": {
      "overview": "本文提出了Transition-Aware Graph Attention Network (TGA)，一种线性复杂度的多行为序列建模方法，用于电商推荐，有效捕捉行为转换并降低计算成本。",
      "motivation": "在电商推荐领域，用户交互行为如点击、收藏、加购和购买具有多样性，行为之间的转换对理解用户动态偏好至关重要。现有基于Transformer的序列建模方法虽然能处理多行为数据，但因其多项式时间复杂性导致计算成本高，难以应用于大规模工业系统中的长序列场景。这促使研究高效方法以在保持推荐准确性的同时降低计算开销，满足实时推荐需求，解决现有方法计算效率不足的问题。",
      "method": "本研究提出Transition-Aware Graph Attention Network (TGA)，通过构建结构化稀疏图来建模多行为转换，实现线性复杂度。TGA从项目级、类别级和邻居级三个视角识别信息性转换，替代传统Transformer对行为对的平等处理。采用transition-aware图注意力机制，该机制联合建模用户-项目交互和行为转换类型，从而更准确地捕捉序列模式并保持计算效率，无需依赖复杂的时间复杂度。",
      "result": "实验结果显示，TGA在所有最先进模型中表现最优，同时显著降低了计算成本。具体来说，它在推荐任务上实现了更高的准确率，并与基线方法相比提升了效率。此外，TGA已成功部署于大规模工业生产环境，在实际应用中带来了关键业务指标的显著改进，证明了其有效性和实用性。摘要未明确说明具体性能指标数据。",
      "conclusion": "本研究的主要贡献是开发了Transition-Aware Graph Attention Network (TGA)，一种创新方法，能高效建模多行为序列并保持线性计算复杂度。学术上，它扩展了图神经网络在推荐系统中的应用；实际上，已在工业部署中提升推荐性能。未来工作可进一步优化转换识别机制或扩展到其他领域，以应对更复杂的用户行为模式。",
      "tags": [
        "Multi-Behavior Sequential Modeling",
        "Graph Attention Network",
        "Transition-Aware Modeling",
        "E-Commerce Recommendation",
        "Linear Complexity"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:07.476224Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14954",
    "title": "Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features",
    "authors": [
      "Han Li",
      "Hua Sun"
    ],
    "abstract": "Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14954.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14954",
    "published": "2026-01-21T12:53:18Z",
    "updated": "2026-01-21T12:53:18Z",
    "comment": "19 pages,10 figures",
    "light_analysis": {
      "overview": "本文提出一种增强外部证据和伪造特征的多模态谣言检测模型，通过对比学习和自适应融合提升检测性能。",
      "motivation": "研究动机在于社交媒体中混合图像文本帖子常被用于传播谣言，特别是深层语义不匹配谣言，这些谣言表面看似一致但存在细微差异，威胁在线舆论环境。现有多模态谣言检测方法虽改进跨模态建模，但面临特征提取有限、对齐噪声和融合策略不灵活等问题，且忽略验证复杂谣言所需的外部事实证据，导致检测效果受限。",
      "method": "研究方法采用多模态框架，结合ResNet34视觉编码器和BERT文本编码器提取基础特征。创新点包括：伪造特征模块利用傅里叶变换提取图像频域痕迹和压缩伪影；BLIP生成图像描述桥接图像和文本语义空间；双重对比学习模块计算文本-图像和文本-描述对的对比损失以增强不一致检测；门控自适应特征缩放融合机制动态调整多模态融合并减少冗余。实验在微博和Twitter数据集上进行。",
      "result": "主要实验结果显示，所提模型在微博和Twitter数据集上的宏准确率、召回率和F1得分均优于主流基线方法。具体数值摘要未明确说明，但通过对比验证了模型在多模态谣言检测中的有效性，尤其在处理深层语义不一致和伪造内容时表现出色，显著提升了检测性能。",
      "conclusion": "结论总结模型通过整合外部证据和伪造特征，结合先进多模态学习技术，提高了谣言检测的准确性和鲁棒性。研究具有重要学术价值，推动了AI在社交媒体安全领域的应用，为在线信息治理提供工具。摘要未明确说明局限性，未来工作可能包括扩展到更多数据集或优化实时检测能力。",
      "tags": [
        "Multimodal Rumor Detection",
        "Contrastive Learning",
        "Forgery Feature Extraction",
        "Adaptive Feature Fusion",
        "Image-Text Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:19.946015Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14952",
    "title": "CorpusQA: A 10 Million Token Benchmark for Corpus-Level Analysis and Reasoning",
    "authors": [
      "Zhiyuan Lu",
      "Chenliang Li",
      "Yingcheng Shi",
      "Weizhou Shen",
      "Ming Yan",
      "Fei Huang"
    ],
    "abstract": "While large language models now handle million-token contexts, their capacity for reasoning across entire document repositories remains largely untested. Existing benchmarks are inadequate, as they are mostly limited to single long texts or rely on a \"sparse retrieval\" assumption-that answers can be derived from a few relevant chunks. This assumption fails for true corpus-level analysis, where evidence is highly dispersed across hundreds of documents and answers require global integration, comparison, and statistical aggregation. To address this critical gap, we introduce CorpusQA, a new benchmark scaling up to 10 million tokens, generated via a novel data synthesis framework. By decoupling reasoning from textual representation, this framework creates complex, computation-intensive queries with programmatically guaranteed ground-truth answers, challenging systems to perform holistic reasoning over vast, unstructured text without relying on fallible human annotation. We further demonstrate the utility of our framework beyond evaluation, showing that fine-tuning on our synthesized data effectively enhances an LLM's general long-context reasoning capabilities. Extensive experiments reveal that even state-of-the-art long-context LLMs struggle as input length increases, and standard retrieval-augmented generation systems collapse entirely. Our findings indicate that memory-augmented agentic architectures offer a more robust alternative, suggesting a critical shift is needed from simply extending context windows to developing advanced architectures for global information synthesis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14952.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14952",
    "published": "2026-01-21T12:52:30Z",
    "updated": "2026-01-21T12:52:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文引入CorpusQA基准，一个10 million tokens的语料库级别分析和推理基准，通过新数据合成框架评估和提升大型语言模型的全局推理能力。",
      "motivation": "随着大型语言模型（LLMs）能处理百万token上下文，但其在整个文档库上的推理能力未被充分测试。现有基准大多局限于单个长文本或依赖稀疏检索假设，无法处理真实语料库分析中证据高度分散于数百个文档的需求，要求全局集成、比较和统计聚合。这种不足限制了模型在大规模文档分析中的应用，因此需要新基准来推动研究和解决这一关键缺口，确保模型能应对复杂信息整合挑战。",
      "method": "论文提出CorpusQA基准，包含10 million tokens，基于新颖的数据合成框架构建。该框架通过解耦推理与文本表示，程序化生成复杂且计算密集的查询，并保证答案的真实性，避免依赖易错的人类标注。关键创新点在于挑战系统在不依赖人工标注的情况下对广阔、非结构化文本进行整体推理，并允许使用合成数据进行微调以提升LLMs的长上下文推理能力。框架支持评估和模型增强双重用途。",
      "result": "实验表明，即使最先进的长上下文LLMs在输入长度增加时性能下降，面临困难；标准检索增强生成系统在语料库级别任务上完全崩溃。相比之下，记忆增强的agentic架构表现出更强的稳健性。这些结果验证了CorpusQA基准的有效性，突显了现有方法在全局信息合成方面的局限性，并强调了开发新架构以替代简单扩展上下文窗口的必要性，为未来优化提供实证依据。",
      "conclusion": "论文的主要贡献是引入CorpusQA基准及其数据合成框架，填补了语料库级别推理评估的空白。研究揭示了现有方法如检索增强生成系统的失效，并建议转向记忆增强的agentic架构以实现稳健的全局信息合成。这具有重要学术价值，推动了长上下文处理研究的进步，并为实际应用如大规模文档分析提供了改进方向。未来工作可进一步优化合成框架或探索更多架构变体，以应对更复杂的推理挑战。",
      "tags": [
        "Large Language Model",
        "Benchmark",
        "Corpus-Level Analysis",
        "Memory-Augmented Architecture",
        "Data Synthesis"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:04.936781Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14951",
    "title": "TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models",
    "authors": [
      "Carolin Holtermann",
      "Nina Krebs",
      "Anne Lauscher"
    ],
    "abstract": "Time alters the visual appearance of entities in our world, like objects, places, and animals. Thus, for accurately generating contextually-relevant images, knowledge and reasoning about time can be crucial (e.g., for generating a landscape in spring vs. in winter). Yet, although substantial work exists on understanding and improving temporal knowledge in natural language processing, research on how temporal phenomena appear and are handled in text-to-image (T2I) models remains scarce. We address this gap with TempViz, the first data set to holistically evaluate temporal knowledge in image generation, consisting of 7.9k prompts and more than 600 reference images. Using TempViz, we study the capabilities of five T2I models across five temporal knowledge categories. Human evaluation shows that temporal competence is generally weak, with no model exceeding 75% accuracy across categories. Towards larger-scale studies, we also examine automated evaluation methods, comparing several established approaches against human judgments. However, none of these approaches provides a reliable assessment of temporal cues - further indicating the pressing need for future research on temporal knowledge in T2I.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14951.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14951",
    "published": "2026-01-21T12:52:23Z",
    "updated": "2026-01-21T12:52:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了首个用于全面评估文本到图像模型中时间知识的数据集TempViz，并揭示了现有模型在时间能力上的不足。",
      "motivation": "时间改变实体（如物体、地点、动物）的视觉外观，对生成上下文相关图像至关重要。尽管自然语言处理领域已深入研究和改进时间知识，但文本到图像模型如何处理时间现象的研究仍显不足。这一问题的重要性在于，准确的时间知识能显著提升图像生成的准确性和应用价值，但当前缺乏系统化的评估方法，导致现有模型在时间推理方面存在空白，需要填补这一研究缺口。",
      "method": "研究创建了TempViz数据集，包含7900个提示和600多张参考图像，旨在全面评估文本到图像模型中的时间知识。作者使用该数据集研究了五种T2I模型在五个时间知识类别上的能力，核心创新在于首次提供了一个标准化的评估框架来量化模型的时间推理性能。方法还包括比较自动化评估方法与人类判断，以探索大规模评估的可行性，从而揭示技术瓶颈和改进方向。",
      "result": "人类评估结果显示，五种T2I模型在时间知识上的表现普遍较弱，没有任何模型在所有类别中达到超过75%的准确率，表明时间能力存在显著不足。与基线方法对比，自动化评估方法（如多种现有技术）也无法可靠评估时间线索，与人类判断不一致，进一步凸显了当前评估方法的局限性。这些结果强调了模型在时间推理方面的挑战和未来研究的必要性。",
      "conclusion": "本研究的主要贡献是提出了首个全面评估文本到图像模型中时间知识的数据集TempViz，并系统化揭示了现有模型在时间能力上的弱点。学术上填补了研究空白，推动了该领域的进一步发展；实际应用上，有助于改进图像生成模型的准确性和上下文相关性。局限性包括数据集规模可能有限，未来工作方向包括开发更可靠的自动化评估方法和增强模型的时间推理能力，以应对更复杂的场景需求。",
      "tags": [
        "Text-to-Image Models",
        "Temporal Knowledge",
        "Evaluation",
        "Dataset",
        "Human Evaluation"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:23.563315Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14950",
    "title": "Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness",
    "authors": [
      "Yufei Song",
      "Ziqi Zhou",
      "Menghao Deng",
      "Yifan Hu",
      "Shengshan Hu",
      "Minghui Li",
      "Leo Yu Zhang"
    ],
    "abstract": "Existing segmentation models exhibit significant vulnerability to adversarial attacks.To improve robustness, adversarial training incorporates adversarial examples into model training. However, existing attack methods consider only global semantic information and ignore contextual semantic relationships within the samples, limiting the effectiveness of adversarial training. To address this issue, we propose EroSeg-AT, a vulnerability-aware adversarial training framework that leverages EroSeg to generate adversarial examples. EroSeg first selects sensitive pixels based on pixel-level confidence and then progressively propagates perturbations to higher-confidence pixels, effectively disrupting the semantic consistency of the samples. Experimental results show that, compared to existing methods, our approach significantly improves attack effectiveness and enhances model robustness under adversarial training.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14950.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14950",
    "published": "2026-01-21T12:52:09Z",
    "updated": "2026-01-21T12:52:09Z",
    "comment": "Accepted by ICASSP 2026",
    "light_analysis": {
      "overview": "本文提出EroSeg-AT框架，通过EroSeg生成对抗样本，以增强语义分割模型的对抗鲁棒性。",
      "motivation": "现有语义分割模型对对抗攻击表现出显著脆弱性，而对抗训练虽能提升鲁棒性，但现有攻击方法仅考虑全局语义信息，忽略了样本内的上下文语义关系，这限制了对抗训练的效果。因此，研究旨在解决这一不足，通过改进攻击方法以更好地模拟真实世界扰动，从而提高模型的整体鲁棒性。该问题在自动驾驶、医疗图像等安全关键应用中尤为重要。",
      "method": "本研究提出EroSeg-AT框架，其核心是EroSeg方法，用于生成对抗样本。EroSeg首先基于像素级置信度选择敏感像素，然后逐步将扰动传播到高置信度像素，以有效破坏样本的语义一致性。关键创新点在于考虑了上下文语义关系，避免了现有方法仅关注全局信息的局限。摘要未明确说明具体使用的数据集、模型架构或其他技术细节，但方法强调了像素级操作和语义破坏。",
      "result": "实验结果表明，与现有方法相比，本方法显著提高了攻击效果，并在对抗训练下增强了模型鲁棒性。具体来说，在未提供详细性能指标的情况下，摘要指出攻击效果和模型鲁棒性均有明显提升，这表明EroSeg-AT在对抗性环境中的有效性优于基线方法，但具体数据如准确率或效率改进在摘要中未明确说明。",
      "conclusion": "本研究的核心贡献是提出EroSeg-AT框架，通过EroSeg方法生成更有效的对抗样本，改进了对抗训练过程，从而增强了语义分割模型的鲁棒性。学术价值在于为对抗训练领域提供了新思路，强调了上下文语义关系的重要性；实际应用价值包括提升模型在安全敏感场景下的可靠性。局限性如具体数据集或模型泛化能力未在摘要中提及，未来工作可进一步探索这些方面。",
      "tags": [
        "Adversarial Training",
        "Semantic Segmentation",
        "Adversarial Attack",
        "Pixel-level Confidence",
        "Contextual Semantic Relationships"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:16.495394Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14944",
    "title": "The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations",
    "authors": [
      "Pierre-Antoine Lequeu",
      "Léo Labat",
      "Laurène Cave",
      "Gaël Lejeune",
      "François Yvon",
      "Benjamin Piwowarski"
    ],
    "abstract": "LLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand Débat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14944.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14944",
    "published": "2026-01-21T12:43:07Z",
    "updated": "2026-01-21T12:43:07Z",
    "comment": "31 pages including 22 for references and appendix, 13 figures",
    "light_analysis": {
      "overview": "该论文提出语料澄清框架和GDN-CC数据集，用于标准化民主公民咨询数据，并评估小规模开源语言模型在此任务中的有效性。",
      "motivation": "研究动机源于大型语言模型在民主活动如在线讨论或大规模公民咨询中作为分析工具引发的伦理问题，特别是透明度和资源消耗方面。现有方法往往依赖资源密集型模型，难以在本地环境中透明运行，且缺乏标准化处理。本研究旨在开发资源来标准化公民贡献，使其更适合主题建模和政治分析，同时探究小规模开源语言模型能否可靠执行此标准化任务，从而提供更高效和可访问的解决方案。",
      "method": "研究方法包括提出Corpus Clarification预处理框架，将嘈杂的多主题公民贡献转化为结构化的自包含论证单元，便于下游分析。基于法国Grand Débat National的1,231个贡献，手工注释了2,285个论证单元，创建了GDN-CC数据集。然后，使用小规模开源语言模型进行微调，评估其在重现注释和意见聚类任务中的性能，并与大型模型对比，以验证方法的可行性和效率。",
      "result": "实验结果显示，微调的小语言模型在重现手工注释时，性能匹配或优于大型语言模型，表明小模型在标准化任务中的可靠性。在意见聚类任务中，这些模型也表现出良好的可用性，验证了方法的实用性。此外，研究发布了GDN-CC-large数据集，自动注释了240,000个贡献，成为目前最大的注释民主咨询数据集，为后续研究提供了丰富资源。",
      "conclusion": "结论表明，本研究通过Corpus Clarification框架和GDN-CC数据集，为民主公民咨询数据提供了标准化预处理方案。小语言模型的有效性强调了资源高效和透明化方法在AI分析中的潜力，学术上推动了民主数据标准化研究，实际上有助于开发更可访问的公民参与工具。未来工作可扩展数据集到其他语言或领域，并进一步优化模型性能和应用范围。",
      "tags": [
        "Corpus Clarification",
        "Small Language Models",
        "Fine-tuning",
        "Argumentative Annotation",
        "Democratic Consultation Dataset"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:30.258477Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14942",
    "title": "Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning",
    "authors": [
      "Hang Zhao",
      "Hongru Li",
      "Dongfang Xu",
      "Shenghui Song",
      "Khaled B. Letaief"
    ],
    "abstract": "Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \\emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14942.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14942",
    "published": "2026-01-21T12:38:02Z",
    "updated": "2026-01-21T12:38:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一个三阶段不确定性感知分布式学习框架，以提高多模态边缘推理的通信效率和鲁棒性。",
      "motivation": "本研究旨在解决多模态边缘推理（MMEI）中的关键挑战，即多模态系统在带宽有限无线链路上的通信开销巨大，以及变化信道和噪声输入下鲁棒性不足的问题。这些问题阻碍了分布式边缘智能的实现，现有方法可能未有效优化通信成本或处理不确定性，导致训练效率低和推理可靠性差，因此需要更先进的框架来促进语义通信和边缘计算应用。",
      "method": "论文提出一个三阶段通信感知分布式学习框架：阶段I中，设备进行本地多模态自监督学习，无需与服务器交换数据，生成共享和特定模态编码器，以降低通信开销；阶段II采用分布式微调结合集中式证据融合，校准每个模态的不确定性，并可靠聚合噪声或信道衰落扭曲的特征；阶段III引入不确定性引导的反馈机制，根据样本不确定性选择性请求额外特征，优化通信与准确性权衡。该方法创新整合了自监督学习、证据理论和主动学习，但具体模型架构摘要未明确说明。",
      "result": "实验基于RGB-深度室内场景分类任务进行，结果显示所提出框架以更少的训练通信轮数实现了比现有自监督和全监督基线更高的分类准确性。框架对模态退化或信道变化表现出强鲁棒性，稳定维持性能。具体性能指标如准确率提升百分比摘要未明确说明，但通过对比实验验证了其在通信效率和推理准确性方面的显著优势。",
      "conclusion": "本论文通过不确定性感知分布式学习框架，有效解决了多模态边缘推理的通信效率和鲁棒性问题，为分布式智能系统提供了创新解决方案。主要贡献包括三阶段学习策略集成自监督学习、证据融合和反馈机制。学术上推动了语义通信和多模态学习的发展，实际应用中可提升边缘设备智能处理能力并降低通信成本。未来工作可能涉及扩展框架到更多模态或复杂场景以增强适用性。",
      "tags": [
        "Multi-Modal Learning",
        "Distributed Learning",
        "Uncertainty-Aware Learning",
        "Self-Supervised Learning",
        "Semantic Communication"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:57.273778Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14917",
    "title": "Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models",
    "authors": [
      "Giorgia Rigamonti",
      "Mirko Paolo Barbato",
      "Davide Marelli",
      "Paolo Napoletano"
    ],
    "abstract": "Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14917.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14917",
    "published": "2026-01-21T11:57:51Z",
    "updated": "2026-01-21T11:57:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于深度学习的个性化模型，显著提高1型糖尿病不良事件预测精度。",
      "motivation": "有效管理1型糖尿病需要连续血糖监测和精确胰岛素调整以预防高低血糖。随着可穿戴血糖监测仪和移动健康应用的普及，准确血糖预测对自动胰岛素输送和决策支持系统至关重要。现有传统通用模型未能充分考虑个体变异性，导致预测不精确，难以适应现实场景中患者特异性动态变化。因此，开发个性化预测方法以提升准确性和响应性成为关键研究动机，旨在解决实际管理中的不足。",
      "method": "本研究采用深度学习框架构建个性化血糖预测模型，利用患者特定数据捕捉个体动态变化。方法包括比较Leave-One-Subject-Out Cross-Validation和微调策略，以评估模型对患者特定动态的建模能力。同时，实验对比多模态、患者特定方法与仅使用连续血糖监测的传统方法，并进行消融研究，探究训练集规模减小对性能的影响，确定有效个性化所需的最小数据量，为现实应用中的数据挑战提供技术路线。",
      "result": "实验结果摘要未明确说明具体数值，但显示个性化模型在不良事件预测方面显著优于传统通用模型，实现了更精确和及时的干预。对比分析表明，多模态数据支持的个性化方法预测性能更优。消融研究发现，即使使用较小的训练集，模型仍能保持有效个性化，这为解决现实应用中数据收集挑战提供了实际指导，但未提及具体性能指标如准确率提升。",
      "conclusion": "本研究贡献了基于深度学习的个性化血糖预测方法，通过适应个体变异性显著提升了预测精度。研究推动了下一代糖尿病管理技术的发展，尤其在可穿戴和移动健康平台中应用，增强了面向消费者的糖尿病护理解决方案。实际应用价值高，但存在数据收集挑战，未来工作可扩展模型到其他健康领域或优化数据策略，摘要未明确说明局限性。",
      "tags": [
        "Deep Learning",
        "Personalized Modeling",
        "Blood Glucose Prediction",
        "Leave-One-Subject-Out Cross-Validation",
        "Multi-modal Data"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:17.092010Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14914",
    "title": "CodeDelegator: Mitigating Context Pollution via Role Separation in Code-as-Action Agents",
    "authors": [
      "Tianxiang Fei",
      "Cheng Chen",
      "Yue Pan",
      "Mao Zheng",
      "Mingyang Song"
    ],
    "abstract": "Recent advances in large language models (LLMs) allow agents to represent actions as executable code, offering greater expressivity than traditional tool-calling. However, real-world tasks often demand both strategic planning and detailed implementation. Using a single agent for both leads to context pollution from debugging traces and intermediate failures, impairing long-horizon performance. We propose CodeDelegator, a multi-agent framework that separates planning from implementation via role specialization. A persistent Delegator maintains strategic oversight by decomposing tasks, writing specifications, and monitoring progress without executing code. For each sub-task, a new Coder agent is instantiated with a clean context containing only its specification, shielding it from prior failures. To coordinate between agents, we introduce Ephemeral-Persistent State Separation (EPSS), which isolates each Coder's execution state while preserving global coherence, preventing debugging traces from polluting the Delegator's context. Experiments on various benchmarks demonstrate the effectiveness of CodeDelegator across diverse scenarios.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14914.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14914",
    "published": "2026-01-21T11:55:30Z",
    "updated": "2026-01-21T11:55:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "CodeDelegator提出了一种多代理框架，通过角色分离缓解代码作为动作代理中的上下文污染问题。",
      "motivation": "研究动机在于解决现实世界任务中战略规划和详细实现的矛盾。随着大语言模型的发展，代理能将动作表示为可执行代码，但使用单一代理处理两者会导致调试追踪和中间失败污染上下文，影响长期性能。现有方法未能有效隔离这些污染，限制了代理在复杂任务中的表现，因此需要一种机制来提升多代理系统的鲁棒性和效率。",
      "method": "研究方法采用多代理框架CodeDelegator，将角色分为持久的Delegator和瞬时的Coder。Delegator负责任务分解、规范编写和进度监控，不执行代码；每个子任务实例化一个Coder，其上下文仅包含规范，避免了先前失败的污染。引入Ephemeral-Persistent State Separation（EPSS）机制，隔离Coder的执行状态，同时保持全局一致性，防止调试信息干扰规划，从而有效协调代理间的交互。",
      "result": "论文在多种基准测试中进行了实验，证明了CodeDelegator在缓解上下文污染方面的有效性。实验结果显示，该框架能显著提升代理在长期任务中的性能，表明其在多样场景下的广泛适用性，但摘要未明确说明具体的准确率提升或效率改进指标，仅强调了整体性能的增强。",
      "conclusion": "结论是CodeDelegator通过角色分离和状态管理，有效缓解了代码作为动作代理中的上下文污染问题，为多代理系统设计提供了新思路。该研究具有学术价值，推动了代理协调机制的发展；在实际应用中，可提高任务自动化的鲁棒性和效率。未来工作可能包括优化EPSS机制或扩展到更多复杂任务领域。",
      "tags": [
        "Large Language Models",
        "Multi-Agent Systems",
        "Role Separation",
        "Ephemeral-Persistent State Separation",
        "Code Generation"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:52.470483Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14903",
    "title": "PodBench: A Comprehensive Benchmark for Instruction-Aware Audio-Oriented Podcast Script Generation",
    "authors": [
      "Chenning Xu",
      "Mao Zheng",
      "Mingyu Zheng",
      "Mingyang Song"
    ],
    "abstract": "Podcast script generation requires LLMs to synthesize structured, context-grounded dialogue from diverse inputs, yet systematic evaluation resources for this task remain limited. To bridge this gap, we introduce PodBench, a benchmark comprising 800 samples with inputs up to 21K tokens and complex multi-speaker instructions. We propose a multifaceted evaluation framework that integrates quantitative constraints with LLM-based quality assessment. Extensive experiments reveal that while proprietary models generally excel, open-source models equipped with explicit reasoning demonstrate superior robustness in handling long contexts and multi-speaker coordination compared to standard baselines. However, our analysis uncovers a persistent divergence where high instruction following does not guarantee high content substance. PodBench offers a reproducible testbed to address these challenges in long-form, audio-centric generation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14903.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14903",
    "published": "2026-01-21T11:41:14Z",
    "updated": "2026-01-21T11:41:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出 PodBench 基准和评估框架，系统性评估 LLMs 在播客脚本生成任务中的表现，强调指令遵循与内容质量的平衡，为长格式音频生成提供可重复测试环境。",
      "motivation": "播客脚本生成要求 LLMs 从多样输入合成结构化、基于上下文的对话，但现有研究缺乏系统性评估资源，这限制了任务发展和模型优化。该问题重要性在于音频导向生成需处理复杂指令和长上下文，当前方法难以有效评测模型鲁棒性和质量，阻碍了实际应用和学术进展。因此，亟需建立综合基准以弥补这一不足。",
      "method": "研究提出 PodBench 基准，包含 800 个样本，输入最长 21K tokens，涉及复杂多说话者指令，模拟真实播客场景。核心方法是开发多方面的评估框架，整合定量约束（如指令遵循度）与基于 LLM 的质量评估，以全面评测模型性能。关键技术特色包括使用开源模型配备显式推理机制，对比标准基线处理长上下文和多说话者协调能力，但摘要未明确说明具体模型架构或数据集细节。",
      "result": "实验结果显示，专有模型在整体性能上表现优异，但配备显式推理的开源模型在处理长上下文和多说话者协调方面展现出更优的鲁棒性，相较于标准基线有所提升。分析揭示一个关键分歧：高指令遵循性不一定对应高质量内容，这突显了评估的复杂性。尽管摘要未明确提供具体数据如准确率，结果强调了模型在不同任务维度上的差异表现。",
      "conclusion": "PodBench 的主要贡献是提供了一个可重复的测试床，系统性解决长格式、音频中心生成中的评估挑战，具有学术价值推动 LLM 应用研究，实际价值支持播客脚本生成工具开发。研究局限性在于指令遵循与内容质量的不一致性，未来工作可进一步探索如何平衡这两方面，并扩展到更多音频生成任务。",
      "tags": [
        "Podcast Script Generation",
        "Instruction Following",
        "LLM Benchmark",
        "Audio Generation",
        "Multi-Speaker Dialogue"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:31.668027Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14901",
    "title": "Just aware enough: Evaluating awareness across artificial systems",
    "authors": [
      "Nadine Meertens",
      "Suet Lee",
      "Ophelia Deroy"
    ],
    "abstract": "Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14901.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14901",
    "published": "2026-01-21T11:39:35Z",
    "updated": "2026-01-21T11:39:35Z",
    "comment": "24 pages (including references), 1 figure",
    "light_analysis": {
      "overview": "本文提出了一种评估人工智能系统中awareness的结构化实用方法，以替代意识评估的争议，促进跨系统比较和原则性评估。",
      "motivation": "近年来，人工智能领域的辩论日益聚焦于AI意识和道德地位问题，但如何评估这些属性缺乏共识，现有方法往往过于抽象或难以操作，导致评估实用性不足。为了解决这一挑战，论文认为awareness作为一个更具体、方法上更易处理的概念，可以提供更有效的评估途径，旨在建立一个通用框架，以便在不同系统和领域中进行应用，从而推动更科学的评估和公众讨论。",
      "method": "论文提出的核心方法是一个评估awareness的实用框架，基于四个关键要求：领域敏感性（适应不同操作领域）、可部署性（适用于任何规模系统）、多维性（考虑多个能力维度）以及任务性能预测能力。该方法通过结构化比较不同系统架构、规模和领域的awareness profiles来概括能力水平，强调评估系统处理、存储和使用信息以服务目标导向行为的能力，尽管摘要未具体提及数据集或模型架构，但设计为适用于多样化人工系统。",
      "result": "摘要未明确说明具体的实验结果或性能指标。论文主要贡献是理论性和方法学上的，提出了一个评估awareness的框架，预期能够促进原则性评估、支持系统设计和监督，并增强科学和公众讨论的建构性。由于缺乏实证数据，未提供与基线方法的对比或具体量化结果如准确率提升等。",
      "conclusion": "本研究的主要贡献在于引入了一个评估人工系统中awareness的结构化方法，将焦点从难以定义的意识转向更易操作的awareness概念。该方法具有重要学术价值，为AI评估提供了新思路，并具有实际应用价值，可支持系统设计、监管和跨领域比较。潜在局限性包括需要实证验证和扩展应用场景，未来工作可能涉及将该框架应用于具体系统以测试其有效性。",
      "tags": [
        "Awareness Evaluation",
        "Artificial Systems",
        "Domain-Sensitive Assessment",
        "Task Performance Prediction",
        "Comparative Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:30.590382Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14896",
    "title": "Language-Coupled Reinforcement Learning for Multilingual Retrieval-Augmented Generation",
    "authors": [
      "Rui Qi",
      "Fengran Mo",
      "Yufeng Chen",
      "Xue Zhang",
      "Shuo Wang",
      "Hongliang Li",
      "Jinan Xu",
      "Meng Jiang",
      "Jian-Yun Nie",
      "Kaiyu Huang"
    ],
    "abstract": "Multilingual retrieval-augmented generation (MRAG) requires models to effectively acquire and integrate beneficial external knowledge from multilingual collections. However, most existing studies employ a unitive process where queries of equivalent semantics across different languages are processed through a single-turn retrieval and subsequent optimization. Such a ``one-size-fits-all'' strategy is often suboptimal in multilingual settings, as the models occur to knowledge bias and conflict during the interaction with the search engine. To alleviate the issues, we propose LcRL, a multilingual search-augmented reinforcement learning framework that integrates a language-coupled Group Relative Policy Optimization into the policy and reward models. We adopt the language-coupled group sampling in the rollout module to reduce knowledge bias, and regularize an auxiliary anti-consistency penalty in the reward models to mitigate the knowledge conflict. Experimental results demonstrate that LcRL not only achieves competitive performance but is also appropriate for various practical scenarios such as constrained training data and retrieval over collections encompassing a large number of languages. Our code is available at https://github.com/Cherry-qwq/LcRL-Open.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14896.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14896",
    "published": "2026-01-21T11:32:32Z",
    "updated": "2026-01-21T11:32:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "LcRL是一个多语言搜索增强强化学习框架，通过语言耦合组相对策略优化减少知识偏差和冲突，提升多语言检索增强生成性能。",
      "motivation": "多语言检索增强生成（MRAG）需要从多语言集合中有效获取和整合外部知识。然而，现有方法通常采用统一过程处理不同语言的等价语义查询，这种“一刀切”策略在多语言设置中效果不佳，容易导致知识偏差和冲突，限制了模型的适应性和准确性。因此，开发更有效的方法来优化多语言检索和生成过程至关重要，以解决现有方法在交互中遇到的偏差和冲突问题，提高多语言环境下的知识利用效率。",
      "method": "论文提出了LcRL框架，集成了语言耦合组相对策略优化到策略和奖励模型中，以改善多语言检索增强生成。关键创新点包括：在rollout模块中使用语言耦合组采样来减少知识偏差，以及在奖励模型中正则化辅助反一致性惩罚来缓解知识冲突。该方法基于强化学习，通过优化策略和奖励机制，增强模型在多语言设置中的知识检索和整合能力，适用于处理多语言查询和外部知识源。",
      "result": "实验结果显示，LcRL不仅实现了竞争性的性能表现，还适用于多种实际场景，如训练数据受限和检索覆盖大量语言的集合。虽然摘要未提供具体的性能指标数据，但表明该方法在减少知识偏差和冲突方面有效，并与基线方法相比表现出优势。这证明了LcRL在多语言检索增强生成任务中的鲁棒性和适应性，能够在不同条件下保持较好效果。",
      "conclusion": "LcRL的主要贡献在于提出了一个语言耦合强化学习框架来优化多语言检索增强生成，有效减少了知识偏差和冲突。该研究具有重要的学术价值，为多语言自然语言处理提供了新方法，同时在实际应用中展现出灵活性，如适应数据受限和多语言检索场景。摘要未明确说明局限性，但未来工作可能包括进一步优化算法或扩展到更多语言任务，以增强通用性和效率。",
      "tags": [
        "Multilingual Retrieval-Augmented Generation",
        "Reinforcement Learning",
        "Language-Coupled Group Relative Policy Optimization",
        "Anti-Consistency Penalty",
        "Knowledge Conflict Mitigation"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:49.533841Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14895",
    "title": "SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval",
    "authors": [
      "Xinyi Zheng",
      "Yunze Liu",
      "Chi-Hao Wu",
      "Fan Zhang",
      "Hao Zheng",
      "Wenqi Zhou",
      "Walterio W. Mayol-Cuevas",
      "Junxiao Shen"
    ],
    "abstract": "We present SpatialMem, a memory-centric system that unifies 3D geometry, semantics, and language into a single, queryable representation. Starting from casually captured egocentric RGB video, SpatialMem reconstructs metrically scaled indoor environments, detects structural 3D anchors (walls, doors, windows) as the first-layer scaffold, and populates a hierarchical memory with open-vocabulary object nodes -- linking evidence patches, visual embeddings, and two-layer textual descriptions to 3D coordinates -- for compact storage and fast retrieval. This design enables interpretable reasoning over spatial relations (e.g., distance, direction, visibility) and supports downstream tasks such as language-guided navigation and object retrieval without specialized sensors. Experiments across three real-life indoor scenes demonstrate that SpatialMem maintains strong anchor-description-level navigation completion and hierarchical retrieval accuracy under increasing clutter and occlusion, offering an efficient and extensible framework for embodied spatial intelligence.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14895.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14895",
    "published": "2026-01-21T11:32:24Z",
    "updated": "2026-01-21T11:32:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "SpatialMem是一个统一的3D内存系统，结合几何、语义和语言，实现快速检索和可解释推理，以增强空间智能。",
      "motivation": "本研究旨在解决从随意捕捉的RGB视频中构建室内环境统一表示的挑战，以便支持空间推理任务如语言引导导航和对象检索。现有方法常依赖专用传感器（如深度摄像头），或难以整合几何、语义和语言信息，限制了在现实环境中的实用性和可扩展性。SpatialMem的开发动机在于提供一个更高效、无需昂贵硬件的解决方案，以应对日益增长的空间智能应用需求，如机器人和增强现实。",
      "method": "SpatialMem从RGB视频重建度量缩放的室内3D几何，首先检测结构3D锚点（如墙壁、门、窗户）作为基础脚手架。然后构建分层内存，包含开放词汇的对象节点，这些节点将证据补丁、视觉嵌入和两层文本描述链接到3D坐标，实现紧凑存储。方法创新点在于统一表示3D几何、语义和语言，支持快速检索和空间关系推理，无需依赖专用传感器，集成计算机视觉和自然语言处理技术。",
      "result": "实验在三个真实室内场景中进行，结果表明，SpatialMem在增加杂乱和遮挡的条件下，能维持强大的锚点描述级导航完成和分层检索准确性。摘要未明确说明与具体基线方法的对比数据，但实验强调了系统的鲁棒性和高效性，验证了该框架在实际环境中的性能，为下游任务如语言引导导航提供了可行支撑。",
      "conclusion": "SpatialMem的主要贡献是开发了一个统一3D内存系统，有效整合几何、语义和语言信息，提供了高效且可扩展的框架。这一研究支持语言引导导航和对象检索等下游任务，无需专用传感器，降低了应用成本，推动了空间智能和计算机视觉的交叉研究。实际应用潜力包括机器人和VR/AR领域，学术价值在于促进多模态表示学习。局限性或未来工作摘要未明确说明。",
      "tags": [
        "Metric 3D Reconstruction",
        "Hierarchical Memory",
        "Open-Vocabulary Object Detection",
        "Language-Guided Navigation"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:39.079115Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14894",
    "title": "To Neuro-Symbolic Classification and Beyond by Compiling Description Logic Ontologies to Probabilistic Circuits",
    "authors": [
      "Nicolas Lazzari",
      "Valentina Presutti",
      "Antonio Vergari"
    ],
    "abstract": "Background: Neuro-symbolic methods enhance the reliability of neural network classifiers through logical constraints, but they lack native support for ontologies.   Objectives: We aim to develop a neuro-symbolic method that reliably outputs predictions consistent with a Description Logic ontology that formalizes domain-specific knowledge.   Methods: We encode a Description Logic ontology as a circuit, a feed-forward differentiable computational graph that supports tractable execution of queries and transformations. We show that the circuit can be used to (i) generate synthetic datasets that capture the semantics of the ontology; (ii) efficiently perform deductive reasoning on a GPU; (iii) implement neuro-symbolic models whose predictions are approximately or provably consistent with the knowledge defined in the ontology.   Results We show that the synthetic dataset generated using the circuit qualitatively captures the semantics of the ontology while being challenging for Machine Learning classifiers, including neural networks. Moreover, we show that compiling the ontology into a circuit is a promising approach for scalable deductive reasoning, with runtimes up to three orders of magnitude faster than available reasoners. Finally, we show that our neuro-symbolic classifiers reliably produce consistent predictions when compared to neural network baselines, maintaining competitive performances or even outperforming them.   Conclusions By compiling Description Logic ontologies into circuits, we obtain a tighter integration between the Deep Learning and Knowledge Representation fields. We show that a single circuit representation can be used to tackle different challenging tasks closely related to real-world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14894.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14894",
    "published": "2026-01-21T11:30:14Z",
    "updated": "2026-01-21T11:30:14Z",
    "comment": "Manuscript under review",
    "light_analysis": {
      "overview": "本文提出将描述逻辑本体编译为概率电路的方法，实现神经符号分类，提升预测一致性和推理效率。",
      "motivation": "研究动机源于神经符号方法虽通过逻辑约束增强神经网络分类器的可靠性，但缺乏对描述逻辑本体论的原生支持，这限制了在需要形式化领域知识的应用中确保预测一致性的能力。描述逻辑本体论能编码领域知识，用于提升分类器的可信度和可解释性，尤其在医疗或法律等敏感领域至关重要。现有方法未有效集成本体，导致预测可能违反知识约束，因此开发新方法以可靠输出与本体一致的预测，解决可靠性不足的问题。",
      "method": "研究方法核心是将描述逻辑本体编译为概率电路，这是一种前馈可微分计算图，支持可处理查询和变换。创新点包括：利用电路生成合成数据集捕获本体语义；在GPU上高效执行演绎推理以提升计算效率；实现神经符号模型，确保预测与本体知识近似或可证明一致。尽管未详细指定具体神经网络架构或数据集，但电路的多功能性允许集成到现有分类框架中，增强模型的符号推理能力。",
      "result": "实验结果显示，电路生成的合成数据集定性地捕获本体语义，并对包括神经网络在内的机器学习分类器具有挑战性。编译本体到电路使推理运行时间比现有推理器快达三个数量级，显著提升效率。神经符号分类器与神经网络基线相比，可靠地产生更一致的预测，在性能上保持竞争力或甚至超越，验证了方法在平衡一致性和准确率方面的有效性。",
      "conclusion": "通过编译描述逻辑本体为概率电路，本研究实现了深度学习和知识表示领域的紧密集成，主要贡献在于提供单一电路表示，能高效处理推理、数据生成和模型一致性任务。这推动了神经符号AI的学术发展，增强了分类器的可靠性和可扩展性，为实际应用如自动决策系统提供支持。摘要未明确说明局限性，但未来工作可能涉及扩展至更复杂本体或融合其他逻辑形式。",
      "tags": [
        "Neuro-Symbolic AI",
        "Description Logic",
        "Probabilistic Circuits",
        "Deductive Reasoning",
        "GPU Acceleration"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:08.162313Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14888",
    "title": "What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study",
    "authors": [
      "Keyu Lv",
      "Manyi Zhang",
      "Xiaobo Xia",
      "Jingchen Ni",
      "Shannan Yan",
      "Xianzhi Yu",
      "Lu Hou",
      "Chun Yuan",
      "Haoli Bai"
    ],
    "abstract": "Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14888.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14888",
    "published": "2026-01-21T11:22:29Z",
    "updated": "2026-01-21T11:22:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文系统研究量化感知训练在推理大型语言模型中的应用，并开发优化工作流Reasoning-QAT，显著提升低比特量化下的模型精度。",
      "motivation": "推理模型在编码和数学等复杂任务上表现优秀，但推理速度慢且token效率低。后训练量化（PTQ）旨在提高推理效率，却在低比特设置下导致精度大幅下降，尤其在推理任务中。现有PTQ方法在处理精度损失方面不足，影响模型实用性和部署效率。本研究旨在探索量化感知训练（QAT）的有效性，以解决这一效率与精度平衡的挑战，推动高效推理模型的发展。",
      "method": "本研究对量化感知训练（QAT）进行系统实证研究。方法包括分析多个关键发现：知识蒸馏作为鲁棒目标适用于监督微调或强化学习的推理模型；PTQ提供QAT的强初始化，减少训练成本并提升精度；强化学习在量化模型中可行，需冷启动策略；以及对齐PTQ校准域与QAT训练域以加速收敛。整合这些发现形成优化工作流Reasoning-QAT，在多个大型语言模型骨干（如Qwen3-0.6B）和推理数据集上验证。",
      "result": "Reasoning-QAT工作流在多个大型语言模型和推理数据集上一致优于最先进的PTQ方法。例如，在Qwen3-0.6B模型上，MATH-500数据集上的性能超越GPTQ方法44.53%，并在2比特量化设置下恢复模型性能，展示了显著的精度改进。与基线PTQ方法相比，该方法不仅在精度上提升，还降低了训练成本，证明了其高效性和鲁棒性，为低比特量化推理模型提供了可行解决方案。",
      "conclusion": "本研究系统揭示了量化感知训练在推理模型中的有效性，提出优化工作流Reasoning-QAT，整合关键发现以改善精度和效率。贡献在于提供量化训练的实证见解和实用方法，具有学术价值，推动高效AI模型研究，以及实际应用价值，使低资源环境下的推理部署成为可能。未来工作可扩展至更多模型类型或复杂任务，并探索进一步优化策略。",
      "tags": [
        "Quantization-Aware Training",
        "Knowledge Distillation",
        "Reinforcement Learning",
        "Large Language Model",
        "Low-Bit Quantization"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:31.829738Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14875",
    "title": "GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars",
    "authors": [
      "Zhe Chang",
      "Haodong Jin",
      "Ying Sun",
      "Yan Song",
      "Hui Yu"
    ],
    "abstract": "High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14875.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14875",
    "published": "2026-01-21T11:05:13Z",
    "updated": "2026-01-21T11:05:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "GAT-NeRF 提出了一种集成Transformer机制的混合神经辐射场框架，用于高保真4D动态面部头像重建。",
      "motivation": "该研究旨在解决从单目视频重建高保真4D动态面部头像的挑战，这对于沉浸式虚拟人应用（如虚拟现实、游戏和电影）至关重要。现有NeRF方法虽然在场景表示上取得进展，但在从信息受限的单目流中捕获高频面部细节（如动态皱纹和细微纹理）时能力有限，导致重建质量不足，无法满足真实感需求。因此，需要增强NeRF的建模能力以提升细节恢复效果。",
      "method": "GAT-NeRF框架结合坐标对齐的多层感知机（MLP）和轻量级Geometry-Aware-Transformer（GAT）模块。GAT模块融合多模态输入特征，包括3D空间坐标、3D可变形模型（3DMM）表达参数和可学习的潜在代码，以学习和增强与细粒度几何相关的特征表示。通过集成Transformer机制到NeRF流程，利用其强大的特征学习能力，显著增强对复杂局部面部模式（如动态皱纹和痤疮疤痕）的建模。",
      "result": "综合实验表明，GAT-NeRF在视觉保真度和高频细节恢复方面达到最先进的性能，特别是在恢复动态皱纹和细微纹理等细节上表现优异。虽然摘要未明确提供具体数值指标（如准确率提升），但通过与基线方法对比，展示了其在建模复杂局部面部模式上的优势，为创建真实动态数字人提供了新途径。",
      "conclusion": "GAT-NeRF的主要贡献在于提出了一种集成Transformer的混合框架，有效提升NeRF对高频面部细节的建模能力。这项研究具有学术价值，推动了动态数字人重建技术的发展，并在多媒体应用中为创建真实动态数字人开辟了实际应用前景。未来工作可探索扩展该框架到其他动态场景或进一步优化计算效率。",
      "tags": [
        "Neural Radiance Fields",
        "Transformer",
        "3D Morphable Model",
        "Dynamic Facial Avatar Reconstruction",
        "Multi-modal Fusion"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:02.946667Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14862",
    "title": "Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting",
    "authors": [
      "Olaf Yunus Laitinen Imanov",
      "Taner Yilmaz",
      "Derya Umut Kulali"
    ],
    "abstract": "We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14862.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14862",
    "published": "2026-01-21T10:45:17Z",
    "updated": "2026-01-21T10:45:17Z",
    "comment": "13 pages, 10 figures, 10 tables",
    "light_analysis": {
      "overview": "本文提出Strategic Doctrine Language Models (sdLM)框架，通过多文档注意力、时间编码和教条一致性层，改善战略推理的长期预测和减少教条违反。",
      "motivation": "研究动机是解决多文档战略推理中教条一致性问题。现有通用大型语言模型在长期地缘政治预测时可能缺乏教条约束，导致严重的战略违反和计划不切实际，影响决策可靠性。sdLM旨在整合教条一致性和校准不确定性，以提升战略质量，填补现有方法在约束整合方面的不足，增强预测的准确性和战略规划的可行性。",
      "method": "研究方法基于sdLM框架，结合多文档注意力机制以综合多个战略文档信息，时间编码捕获时序模式，教条一致性层强制执行战略原则。关键创新在于这些组件的协同，以优化长期预测和计划合理性。使用专家面板评分（47个场景）、教条出版物（336份文档）和历史地缘政治预测（127个历史反事实）进行评估，模型架构未详细说明但注重多模态约束。",
      "result": "实验结果显示，sdLM在战略场景评分、教条一致性测试（基于12,847条声明）和地缘政治预测（跨越12-60个月周期）基准上，均优于强大型语言模型基线，实现更高的战略质量和更好的不确定性校准。在长期判断中，与人类专家竞争力。消融分析揭示了组件贡献，扩展趋势和性能/延迟特性评估为实际部署提供指导，但具体准确率提升数据摘要未明确说明。",
      "conclusion": "论文主要贡献是sdLM框架，通过集成教条约束和时间建模提升战略推理的教条一致性和预测能力，为地缘政治分析和战略规划提供有效工具。学术价值在于结合多文档注意力等技术，实际应用价值在决策支持。未来工作可能涉及性能优化或扩展到其他领域，局限性如具体部署挑战摘要未明确说明。",
      "tags": [
        "Strategic Doctrine Language Models",
        "Multi-document Attention",
        "Temporal Encoding",
        "Doctrine Consistency",
        "Geopolitical Forecasting"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:06.763535Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14857",
    "title": "HiNS: Hierarchical Negative Sampling for More Comprehensive Memory Retrieval Embedding Model",
    "authors": [
      "Motong Tian",
      "Allen P. Wong",
      "Mingjun Mao",
      "Wangchunshu Zhou"
    ],
    "abstract": "Memory-augmented language agents rely on embedding models for effective memory retrieval. However, existing training data construction overlooks a critical limitation: the hierarchical difficulty of negative samples and their natural distribution in human-agent interactions. In practice, some negatives are semantically close distractors while others are trivially irrelevant, and natural dialogue exhibits structured proportions of these types. Current approaches using synthetic or uniformly sampled negatives fail to reflect this diversity, limiting embedding models' ability to learn nuanced discrimination essential for robust memory retrieval. In this work, we propose a principled data construction framework HiNS that explicitly models negative sample difficulty tiers and incorporates empirically grounded negative ratios derived from conversational data, enabling the training of embedding models with substantially improved retrieval fidelity and generalization in memory-intensive tasks. Experiments show significant improvements: on LoCoMo, F1/BLEU-1 gains of 3.27%/3.30%(MemoryOS) and 1.95%/1.78% (Mem0); on PERSONAMEM, total score improvements of 1.19% (MemoryOS) and 2.55% (Mem0).",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14857.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14857",
    "published": "2026-01-21T10:39:48Z",
    "updated": "2026-01-21T10:39:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出HiNS框架，通过分层负采样优化记忆检索嵌入模型的训练，提升检索准确性和泛化能力。",
      "motivation": "记忆增强语言代理依赖嵌入模型进行有效记忆检索。现有训练数据构建忽略了负样本的层级难度和自然分布，导致模型无法学习细粒度判别能力。具体问题在于：负样本在对话中呈现语义接近的干扰项和无关紧要的多样类型，而当前方法使用合成或均匀采样负样本，未能反映这种结构，限制了检索的稳健性和准确性。",
      "method": "研究提出HiNS框架，一个原则性的数据构建框架。核心创新是明确建模负样本的难度层级，如区分语义接近的干扰项和无关紧要的负样本，并整合从真实对话数据中得出的经验性负样本比例。这用于训练嵌入模型，覆盖更全面的负样本分布，从而提高在内存密集型任务中的检索保真度和泛化能力。摘要未明确说明具体使用的数据集或模型架构细节。",
      "result": "实验显示显著改进：在LoCoMo数据集上，使用HiNS训练的模型在MemoryOS上F1得分提升3.27%、BLEU-1提升3.30%，在Mem0上F1提升1.95%、BLEU-1提升1.78%。在PERSONAMEM数据集上，总分分别提升1.19%（MemoryOS）和2.55%（Mem0）。这些结果表明HiNS框架在多个基准上优于基线方法。",
      "conclusion": "HiNS框架通过分层负采样改进了记忆检索嵌入模型的训练数据构建，主要贡献是提供了一种更真实反映负样本分布的方法，增强了模型的判别能力。学术上，推动了负采样策略的研究；实际上，有助于提升记忆增强语言代理的检索性能。摘要未明确说明局限性，但未来工作可能涉及扩展到更多任务和验证更广泛的对话场景。",
      "tags": [
        "Negative Sampling",
        "Hierarchical Learning",
        "Embedding Models",
        "Memory Retrieval",
        "Conversational Data"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:12.643947Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14855",
    "title": "Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference",
    "authors": [
      "Baojun Che",
      "Yifan Chen",
      "Daniel Zhengyu Huang",
      "Xinying Mao",
      "Weijie Wang"
    ],
    "abstract": "Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14855.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14855",
    "published": "2026-01-21T10:39:02Z",
    "updated": "2026-01-21T10:39:02Z",
    "comment": "26 pages, 7 figures",
    "light_analysis": {
      "overview": "本文开发了一个结合仿射不变预处理、指数积分器和自适应时间步长的稳定高效框架，用于高斯混合黑盒变分推断。",
      "motivation": "研究动机在于黑盒变分推断（BBVI）使用高斯混合族近似复杂后验分布时，虽避免了梯度需求，但标准数值优化方法常存在不稳定和低效的问题，这限制了实际应用。现有方法如自然梯度优化可能在协方差矩阵正定性和适应不同优化阶段方面不足，导致收敛困难或计算开销大。因此，开发一个能确保稳定性和效率的框架至关重要，以提高变分推断在复杂贝叶斯模型中的鲁棒性和实用性。",
      "method": "研究方法包括三个关键组件：通过自然梯度公式进行仿射不变预处理以提升优化效率；引入指数积分器无条件保持协方差矩阵正定性，避免数值问题；结合自适应时间步长以适应预热和收敛阶段的变化，确保稳定性。该方法与流形优化和镜像下降有理论联系，核心创新在于整合这些组件提供统一框架。实验基于多模态分布、Neal's multiscale funnel和PDE-based Bayesian逆问题等案例，但具体数据集在摘要中未详细说明。",
      "result": "实验结果包括理论证明和数值验证：在无噪声设置下证明了指数收敛性，在蒙特卡洛估计下展示了几乎必然收敛性，这严格论证了自适应时间步长的必要性。数值实验显示，所提方法在多模态分布、复杂几何结构和贝叶斯反问题上能有效近似后验分布，与基线方法（如标准数值优化）相比表现出更高的稳定性和效率，但具体性能指标如准确率提升在摘要中未明确给出，仅强调其有效性。",
      "conclusion": "本研究的核心贡献是提出了一个稳定高效的高斯混合黑盒变分推断框架，结合理论收敛性证明和实际应用验证。学术价值在于为优化方法提供了新视角，连接流形优化和镜像下降，增强变分推断的理论基础；实际应用价值体现在提升复杂贝叶斯模型的后验近似能力，适用于工程和科学计算。潜在局限性可能包括对高斯后验假设的依赖，未来工作可探索扩展至非高斯混合或其他分布族。",
      "tags": [
        "Black-box Variational Inference",
        "Gaussian Mixture Models",
        "Exponential Integrator",
        "Adaptive Time Stepping",
        "Natural Gradient"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:27.070691Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14848",
    "title": "From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps",
    "authors": [
      "Mohamed Abouras",
      "Catherine M. Elias"
    ],
    "abstract": "On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14848.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14848",
    "published": "2026-01-21T10:31:03Z",
    "updated": "2026-01-21T10:31:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究应用多层LSTM架构预测高速公路上匝道和下匝道的车辆换道行为，基于ExiD无人机数据集，填补了该领域的研究空白。",
      "motivation": "匝道作为高速公路的关键部分，车辆交互变异性高，但现有研究不足，导致预测不确定性增加，影响道路安全。预测这些区域的车辆行为对于自动驾驶和智能交通系统至关重要，而当前方法可能未针对这一特定场景优化，精度有限。本研究旨在解决这一缺口，通过分析匝道与直线高速公路的差异，提高预测可靠性。",
      "method": "论文采用多层长短期记忆（LSTM）神经网络架构，利用ExiD无人机数据集训练匝道区域（AoI）的车辆行为预测模型。关键创新点在于比较AoI与直线高速公路段的差异，并测试不同预测时间范围（horizons）和模型工作流程，以优化预测策略。数据集提供了车辆轨迹时间序列，支持模型学习动态交互模式。",
      "result": "实验结果表明，在长达4秒的预测时间范围内，模型表现出良好性能：匝道区域（AoI）的预测准确度从约76%起，而一般高速公路场景在最大范围内达到94%。这证明了该方法在特定场景下的有效性，尽管摘要未提供与基线方法的直接对比，但结果显示出潜在的应用价值。",
      "conclusion": "本研究的主要贡献在于将LSTM模型应用于高速公路上匝道和下匝道的车辆换道预测，弥补了相关研究空白。学术价值在于展示了时间序列预测在复杂交通环境中的潜力，实际意义是提升自动驾驶的安全性和效率。未来工作可扩展至更长的预测时间或更复杂的交通场景，摘要未明确说明局限性。",
      "tags": [
        "LSTM",
        "Vehicle Lane Change Prediction",
        "Highway On/Off-Ramps",
        "Time Series Forecasting",
        "Drone Dataset"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:06.188379Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14841",
    "title": "MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images",
    "authors": [
      "Sidi Mohamed Sid El Moctar",
      "Achraf Ait Laydi",
      "Yousef El Mourabit",
      "Hélène Bouvrais"
    ],
    "abstract": "Microtubules are cytoskeletal filaments that play essential roles in many cellular processes and are key therapeutic targets in several diseases. Accurate segmentation of microtubule networks is critical for studying their organization and dynamics but remains challenging due to filament curvature, dense crossings, and image noise. We present MTFlow, a novel time-conditioned flow-matching model for microtubule segmentation. Unlike conventional U-Net variants that predict masks in a single pass, MTFlow learns vector fields that iteratively transport noisy masks toward the ground truth, enabling interpretable, trajectory-based refinement. Our architecture combines a U-Net backbone with temporal embeddings, allowing the model to capture the dynamics of uncertainty resolution along filament boundaries. We trained and evaluated MTFlow on synthetic and real microtubule datasets and assessed its generalization capability on public biomedical datasets of curvilinear structures such as retinal blood vessels and nerves. MTFlow achieves competitive segmentation accuracy comparable to state-of-the-art models, offering a powerful and time-efficient tool for filamentous structure analysis with more precise annotations than manual or semi-automatic approaches.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14841.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14841",
    "published": "2026-01-21T10:14:50Z",
    "updated": "2026-01-21T10:14:50Z",
    "comment": "Accepted for presentation at ISBI 2026",
    "light_analysis": {
      "overview": "MTFlow是一种基于时间条件流匹配的新模型，用于噪声显微镜图像中的微管分割，通过迭代向量场细化实现可解释的轨迹。",
      "motivation": "微管是细胞骨架的关键组成部分，在细胞过程和疾病治疗中扮演重要角色，但准确分割微管网络由于纤维曲率、密集交叉和图像噪声而面临挑战。当前方法如U-Net变体在单次传递中预测掩码，可能无法有效处理不确定性或噪声，导致分割精度受限。本研究旨在开发一种更鲁棒和可解释的方法，以改进丝状结构的分割质量，支持生物医学研究。",
      "method": "MTFlow采用时间条件流匹配模型，核心创新在于学习向量场，迭代地将噪声掩码传输到真实标记，实现基于轨迹的可解释细化。技术架构结合了U-Net主干和时域嵌入，以捕捉沿纤维边界的不确定性分辨动态。模型在合成和真实微管数据集上进行训练和评估，并进一步在视网膜血管和神经等公开生物医学数据集上测试其泛化能力。",
      "result": "MTFlow在微管分割任务中实现了与最先进模型竞争的分割准确性，尽管摘要未提供具体数据指标，但指出它比手动或半自动方法提供更精确的注释。在泛化测试中，模型在视网膜血管和神经等丝状结构上也表现良好，展示了时间高效的特性，适合噪声环境下的实际应用。",
      "conclusion": "MTFlow的主要贡献是提出了一种新颖的时间条件流匹配方法，用于改进噪声显微镜图像中的微管分割，增强了分割的可解释性和精度。研究具有学术价值，引入了流匹配到生物医学图像分割领域，并为丝状结构分析提供了高效工具。未来工作可能涉及扩展模型到更复杂场景或数据集，摘要未明确说明局限性。",
      "tags": [
        "Flow Matching",
        "Time-Conditioned Models",
        "U-Net",
        "Biomedical Image Segmentation",
        "Iterative Refinement"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:57.943883Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14840",
    "title": "Implementing Knowledge Representation and Reasoning with Object Oriented Design",
    "authors": [
      "Abdelrhman Bassiouny",
      "Tom Schierenbeck",
      "Sorin Arion",
      "Benjamin Alt",
      "Naren Vasantakumaar",
      "Giang Nguyen",
      "Michael Beetz"
    ],
    "abstract": "This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14840.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14840",
    "published": "2026-01-21T10:14:29Z",
    "updated": "2026-01-21T10:14:29Z",
    "comment": "9 pages, 2 figures, submitted to the 2026 International Joint Conference on Artificial Intelligence (IJCAI)",
    "light_analysis": {
      "overview": "KRROOD框架通过将知识作为一等编程抽象，桥接逻辑编程与面向对象编程，解决KR&R系统与软件工程的集成问题。",
      "motivation": "该研究旨在解决现代软件工程中知识表示与推理系统与面向对象编程的集成挑战。由于现有KR&R框架依赖外部本体（如OWL）和专门语言（如逻辑编程语言），导致与主流命令式OOP代码的集成困难，增加了开发复杂性和维护成本。这一问题在自主系统等现实应用中尤为重要，因为它们需要高级推理能力，但当前方法难以有效整合，限制了KR&R技术的实用性和可扩展性。",
      "method": "研究方法基于提出KRROOD框架，其核心是将知识视为一等编程抽象，利用面向对象设计的原生类结构来实现知识表示与推理。关键创新点在于融合逻辑编程范式与OOP，通过类定义和继承机制直接表达知识，而无需依赖外部工具。评估包括使用OWL2Bench基准测试验证推理性能，以及应用在一个人机任务学习场景中，以测试框架在实际任务中的可行性和效率，展示如何将知识表示嵌入到OOP代码中。",
      "result": "实验结果表明，KRROOD在OWL2Bench基准测试和人机任务学习场景中表现出强大性能，支持现实自主系统所需的表达性推理。尽管摘要未提供具体数值指标（如准确率或效率提升），但框架展现出与传统KR&R方法相当的推理能力，同时简化了与OOP代码的集成过程。这暗示其可能提高了开发效率和系统可维护性，为集成问题提供了有效解决方案。",
      "conclusion": "论文主要贡献是KRROOD框架，成功桥接知识表示与推理与面向对象设计的集成，促进了KR&R技术在现代软件工程中的应用。其学术价值在于融合逻辑编程与OOP范式，为智能系统开发提供新思路；实际应用价值体现在提升自主系统的推理效率和可维护性。摘要未明确说明局限性或未来工作，但潜在方向可能包括扩展框架到更多应用场景或优化推理性能。",
      "tags": [
        "Knowledge Representation and Reasoning",
        "Object-Oriented Programming",
        "Framework",
        "OWL Benchmark",
        "Logic Programming"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:28.305231Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14827",
    "title": "Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies",
    "authors": [
      "Ben Schaper",
      "Maxime Di Folco",
      "Bernhard Kainz",
      "Julia A. Schnabel",
      "Cosmin I. Bercea"
    ],
    "abstract": "Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14827.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14827",
    "published": "2026-01-21T09:58:50Z",
    "updated": "2026-01-21T09:58:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过利用医学分类法量化并减轻视觉-语言模型的抽象错误，提出风险约束阈值和径向嵌入微调方法，显著减少严重错误，提升临床部署安全性。",
      "motivation": "视觉-语言模型在胸部X光分类中零样本性能强，但标准平面指标无法区分临床轻微和严重错误。这导致模型在实际应用中可能产生严重后果，影响患者安全，现有方法忽视层次化错误如跨分类分支的抽象错误，因此亟需新的评估和优化方法来解决这一关键问题。",
      "method": "研究采用层次化指标对多种最先进的视觉-语言模型进行基准测试，引入灾难性抽象错误概念捕捉跨分支错误。为解决抽象错误，提出风险约束阈值法优化决策阈值，并使用径向嵌入进行分类法感知微调，以对齐模型表示与临床分类法，增强模型对医学层级结构的适应性。",
      "result": "实验结果显示，尽管模型在平面指标上表现优秀，但与临床分类法存在显著不一致。提出的风险约束阈值和径向嵌入微调方法，能将严重抽象错误减少到2%以下，同时保持有竞争力的分类性能，相比于传统平面评估更全面揭示错误模式，提升临床适用性。",
      "conclusion": "研究强调了层次化评估和表示层对齐对视觉-语言模型在医学领域安全部署的重要性。所提方法增强了模型的临床意义和安全性，为未来改进医学图像分析提供了新框架。潜在局限性可能包括对特定医学分类法的依赖，未来可扩展至更多临床场景或优化对齐技术。",
      "tags": [
        "Vision-Language Models",
        "Medical Taxonomies",
        "Hierarchical Metrics",
        "Risk-Constrained Thresholding",
        "Radial Embeddings"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:35.384832Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14826",
    "title": "Comparative Study of Large Language Models on Chinese Film Script Continuation: An Empirical Analysis Based on GPT-5.2 and Qwen-Max",
    "authors": [
      "Yuxuan Cao",
      "Zida Yang",
      "Ye Wang"
    ],
    "abstract": "As large language models (LLMs) are increasingly applied to creative writing, their performance on culturally specific narrative tasks warrants systematic investigation. This study constructs the first Chinese film script continuation benchmark comprising 53 classic films, and designs a multi-dimensional evaluation framework comparing GPT-5.2 and Qwen-Max-Latest. Using a \"first half to second half\" continuation paradigm with 3 samples per film, we obtained 303 valid samples (GPT-5.2: 157, 98.7% validity; Qwen-Max: 146, 91.8% validity). Evaluation integrates ROUGE-L, Structural Similarity, and LLM-as-Judge scoring (DeepSeek-Reasoner).   Statistical analysis of 144 paired samples reveals: Qwen-Max achieves marginally higher ROUGE-L (0.2230 vs 0.2114, d=-0.43); however, GPT-5.2 significantly outperforms in structural preservation (0.93 vs 0.75, d=0.46), overall quality (44.79 vs 25.72, d=1.04), and composite scores (0.50 vs 0.39, d=0.84). The overall quality effect size reaches large effect level (d>0.8).   GPT-5.2 excels in character consistency, tone-style matching, and format preservation, while Qwen-Max shows deficiencies in generation stability. This study provides a reproducible framework for LLM evaluation in Chinese creative writing.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14826.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14826",
    "published": "2026-01-21T09:55:26Z",
    "updated": "2026-01-21T09:55:26Z",
    "comment": "18 pages, 6 figures, 6 tables, 20 references. First two authors contributed equally. Corresponding author: Ye Wang (wangye@whu.edu.cn)",
    "light_analysis": {
      "overview": "本研究构建首个中文电影剧本延续基准并设计多维评估框架，实证比较GPT-5.2和Qwen-Max在创意写作任务上的性能。",
      "motivation": "随着大型语言模型在创意写作领域的应用日益广泛，其在文化特定叙事任务上的表现需要系统评估。本研究针对中文电影剧本延续任务，旨在解决现有方法缺乏专门基准和全面评估框架的问题。该问题重要性在于文化敏感任务对LLMs的适应性和表现提出了独特挑战，而现有研究多集中于通用领域，未深入探索中文创意写作。通过系统性评估，可为实际应用提供指导，填补文化特定任务评估的空白。",
      "method": "研究方法包括构建首个中文电影剧本延续基准，涵盖53部经典电影，采用“前半段到后半段”延续范式，每部电影生成3个样本，获得303个有效样本。评估框架结合自动度量（ROUGE-L和结构相似性）和LLM-as-Judge评分（使用DeepSeek-Reasoner），比较GPT-5.2和Qwen-Max-Latest的性能。关键创新点在于多维度综合评估设计，无需训练新模型，直接利用现有LLMs进行零样本测试，确保评估的可重复性和客观性。",
      "result": "实验结果显示，Qwen-Max在ROUGE-L得分上略高（0.2230对0.2114），效应量d=-0.43。然而，GPT-5.2在结构保持（0.93对0.75，d=0.46）、整体质量（44.79对25.72，d=1.04）和综合得分（0.50对0.39，d=0.84）上显著优越，整体质量效应量达大效应水平（d>0.8）。定性分析表明GPT-5.2在角色一致性和风格匹配方面表现更好，而Qwen-Max在生成稳定性方面存在不足。",
      "conclusion": "本研究的主要贡献是构建了首个中文电影剧本延续基准并提出可重复的多维评估框架，通过实证比较发现GPT-5.2在创意写作任务上整体表现更优。学术价值在于推动了LLM在文化特定任务上的评估方法发展，实际应用价值在于为选择适合创意写作的模型提供参考。未来工作可扩展到其他文化任务或优化评估指标，局限性包括摘要未明确说明模型泛化能力等，需进一步研究。",
      "tags": [
        "Large Language Model",
        "ROUGE-L",
        "LLM-as-Judge",
        "Structural Similarity",
        "Comparative Study"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:29.235549Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14822",
    "title": "Multimodal system for skin cancer detection",
    "authors": [
      "Volodymyr Sydorskyi",
      "Igor Krashenyi",
      "Oleksii Yakubenko"
    ],
    "abstract": "Melanoma detection is vital for early diagnosis and effective treatment. While deep learning models on dermoscopic images have shown promise, they require specialized equipment, limiting their use in broader clinical settings. This study introduces a multi-modal melanoma detection system using conventional photo images, making it more accessible and versatile. Our system integrates image data with tabular metadata, such as patient demographics and lesion characteristics, to improve detection accuracy. It employs a multi-modal neural network combining image and metadata processing and supports a two-step model for cases with or without metadata. A three-stage pipeline further refines predictions by boosting algorithms and enhancing performance. To address the challenges of a highly imbalanced dataset, specific techniques were implemented to ensure robust training. An ablation study evaluated recent vision architectures, boosting algorithms, and loss functions, achieving a peak Partial ROC AUC of 0.18068 (0.2 maximum) and top-15 retrieval sensitivity of 0.78371. Results demonstrate that integrating photo images with metadata in a structured, multi-stage pipeline yields significant performance improvements. This system advances melanoma detection by providing a scalable, equipment-independent solution suitable for diverse healthcare environments, bridging the gap between specialized and general clinical practices.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14822.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14822",
    "published": "2026-01-21T09:50:13Z",
    "updated": "2026-01-21T09:50:13Z",
    "comment": "Accepted to System research and information technologies",
    "light_analysis": {
      "overview": "提出一个使用常规照片图像和元数据的多模态黑色素瘤检测系统，通过整合图像与表格数据、多阶段管道提升检测准确性和可访问性。",
      "motivation": "黑色素瘤检测对早期诊断和有效治疗至关重要，但现有深度学习模型依赖于需要专业设备的皮肤镜图像，限制了在更广泛临床环境中的应用。因此，本研究旨在解决这一问题，通过开发一个使用更易获取的常规照片图像的系统，以提高检测的普及性和准确性，同时改善现有方法对设备依赖的不足。",
      "method": "本研究提出一个多模态神经网络，整合图像数据（常规照片）与表格元数据（如患者人口统计和病变特征），采用两步模型以支持有无元数据的情况。系统通过三阶段管道进一步细化预测，包括使用提升算法和性能增强技术。针对高度不平衡数据集，实施特定训练技术确保鲁棒性，并通过消融研究评估了视觉架构、提升算法和损失函数等关键组件。",
      "result": "消融研究结果显示，系统在部分 ROC AUC 上达到峰值 0.18068（最大为 0.2），top-15 检索灵敏度为 0.78371。这些指标表明，整合照片图像与元数据在结构化多阶段管道中显著提高了检测性能，优于传统依赖专业图像的方法，实现了更高的准确性和效率。",
      "conclusion": "该系统通过使用常规照片图像和元数据，提供了一个可扩展、设备独立的黑色素瘤检测解决方案，适用于多样化的医疗环境，填补了专业与一般临床实践之间的差距。其学术价值在于推动多模态学习在医疗诊断中的应用，实际应用价值在于提高早期诊断的普及性。摘要未明确说明潜在局限性，未来工作可能包括进一步优化算法或扩展应用范围。",
      "tags": [
        "Multimodal Learning",
        "Neural Networks",
        "Partial ROC AUC",
        "Boosting Algorithms",
        "Imbalanced Dataset Handling"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:39.778870Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14821",
    "title": "POTR: Post-Training 3DGS Compression",
    "authors": [
      "Bert Ramlot",
      "Martijn Courteaux",
      "Peter Lambert",
      "Glenn Van Wallendael"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has recently emerged as a promising contender to Neural Radiance Fields (NeRF) in 3D scene reconstruction and real-time novel view synthesis. 3DGS outperforms NeRF in training and inference speed but has substantially higher storage requirements. To remedy this downside, we propose POTR, a post-training 3DGS codec built on two novel techniques. First, POTR introduces a novel pruning approach that uses a modified 3DGS rasterizer to efficiently calculate every splat's individual removal effect simultaneously. This technique results in 2-4x fewer splats than other post-training pruning techniques and as a result also significantly accelerates inference with experiments demonstrating 1.5-2x faster inference than other compressed models. Second, we propose a novel method to recompute lighting coefficients, significantly reducing their entropy without using any form of training. Our fast and highly parallel approach especially increases AC lighting coefficient sparsity, with experiments demonstrating increases from 70% to 97%, with minimal loss in quality. Finally, we extend POTR with a simple fine-tuning scheme to further enhance pruning, inference, and rate-distortion performance. Experiments demonstrate that POTR, even without fine-tuning, consistently outperforms all other post-training compression techniques in both rate-distortion performance and inference speed.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14821.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14821",
    "published": "2026-01-21T09:47:45Z",
    "updated": "2026-01-21T09:47:45Z",
    "comment": "15 pages, 12 figures. Submitted to IEEE TCSVT, under review",
    "light_analysis": {
      "overview": "POTR 提出了一种基于新修剪和光照系数优化技术的后训练 3DGS 压缩方法，显著减少存储需求并加速推理。",
      "motivation": "3D Gaussian Splatting (3DGS) 在 3D 场景重建和实时新视图合成中表现优于 NeRF，但存储需求显著更高，限制了其实际部署。现有后训练压缩技术效率不足，无法在保持质量的同时有效降低存储成本和提升推理速度。本研究旨在解决这一问题，通过开发高效的压缩方法来弥补 3DGS 的存储短板，促进其在资源受限环境中的应用。",
      "method": "POTR 采用两种核心技术：首先，引入一种新修剪方法，使用修改的 3DGS rasterizer 并行计算每个 splat 的移除效果，高效识别并去除冗余 splats，实现 2-4 倍的 splats 减少。其次，提出一种无训练的光照系数重新计算方法，优化系数以降低熵，特别是增加 AC 光照系数的稀疏性。关键创新包括高效的并行处理和无需额外训练的优化技术，扩展部分还结合简单微调方案进一步提升性能。",
      "result": "实验结果显示，POTR 的修剪技术使 splats 数量减少 2-4 倍，推理速度提升 1.5-2 倍；光照系数优化将 AC 稀疏性从 70% 提高到 97%，且质量损失最小。与基线方法相比，POTR 在率失真性能和推理速度上一致优于所有其他后训练压缩技术，即使不进行微调，也能实现更优的压缩效率和加速效果。",
      "conclusion": "论文的主要贡献是提出了 POTR，一种创新的后训练 3DGS 压缩方法，通过高效修剪和光照系数优化，显著降低了存储需求和加速了推理过程。这具有重要的学术价值，为 3D 场景表示技术提供了新思路；实际应用价值在于促进 3DGS 在实时系统和资源受限场景中的部署。未来工作可探索更精细的微调方案或扩展到其他 3D 表示方法。",
      "tags": [
        "3D Gaussian Splatting",
        "Post-Training Compression",
        "Pruning",
        "Lighting Coefficients",
        "Entropy Reduction"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:12.391137Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14818",
    "title": "Statistical Learning Theory for Distributional Classification",
    "authors": [
      "Christian Fiedler"
    ],
    "abstract": "In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.",
    "categories": [
      "cs.LG",
      "math.ST"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14818.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14818",
    "published": "2026-01-21T09:44:24Z",
    "updated": "2026-01-21T09:44:24Z",
    "comment": "Contains supplementary material",
    "light_analysis": {
      "overview": "论文提出分布分类中基于核方法和支持向量机的统计学习理论分析，建立了新的oracle不等式和学习速率结果。",
      "motivation": "本研究针对监督学习中输入为概率分布的场景，如在医学筛查或因果学习应用中，输入分布本身不可直接访问，仅能通过样本进行学习。现有核方法（如支持向量机结合核均值嵌入）虽然适用，但缺乏系统的理论分析来保证其可靠性和收敛性。因此，该工作旨在填补这一空白，通过严格的统计理论框架，提升分布分类方法的理论基础，解决样本化输入带来的挑战，增强实际应用的稳健性。",
      "method": "研究方法采用基于核的学习框架，首先通过核均值嵌入将分布或样本映射到希尔伯特空间，然后应用标准支持向量机进行分类。核心创新包括建立新的oracle不等式，推导一致性和学习速率理论结果。技术特色在于针对使用hinge损失和高斯核的支持向量机，提出噪声假设的新变种，并开发高斯核在希尔伯特空间上的新特征空间工具，以支持理论分析。该方法依赖统计学习理论，不涉及具体数据集，专注于理论模型的构建和证明。",
      "result": "论文取得了理论性结果，包括建立了新的oracle不等式，证明了方法在分布分类中的一致性，并推导了学习速率。对于使用hinge损失和高斯核的支持向量机，在提出的噪声假设下，能够具体计算学习速率。摘要未明确说明具体数值指标（如准确率提升）或与基线方法的详细对比，但强调了这些理论结果为分布分类提供了收敛性保证，增强了核方法在应用中的可信度。",
      "conclusion": "研究的主要贡献在于为分布分类提供了坚实的统计学习理论基础，通过理论分析验证了核方法和支持向量机的有效性。创新包括oracle不等式、学习速率推导和噪声假设扩展，这些工具对后续研究和独立应用具有重要价值。学术上，该工作推动了分布分类领域的理论发展；实际中，可应用于医学筛查等场景。摘要未明确说明局限性或未来工作方向，但暗示技术工具如新特征空间有进一步探索潜力。",
      "tags": [
        "Kernel Mean Embeddings",
        "Support Vector Machines",
        "Gaussian Kernels",
        "Statistical Learning Theory",
        "Distributional Classification"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:39.770326Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14804",
    "title": "Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes",
    "authors": [
      "Tobias Weißberg",
      "Weikang Wang",
      "Paul Roetzer",
      "Nafie El Amrani",
      "Florian Bernard"
    ],
    "abstract": "Shape descriptors, i.e., per-vertex features of 3D meshes or point clouds, are fundamental to shape analysis. Historically, various handcrafted geometry-aware descriptors and feature refinement techniques have been proposed. Recently, several studies have initiated a new research direction by leveraging features from image foundation models to create semantics-aware descriptors, demonstrating advantages across tasks like shape matching, editing, and segmentation. Symmetry, another key concept in shape analysis, has also attracted increasing attention. Consequently, constructing symmetry-aware shape descriptors is a natural progression. Although the recent method $χ$ (Wang et al., 2025) successfully extracted symmetry-informative features from semantic-aware descriptors, its features are only one-dimensional, neglecting other valuable semantic information. Furthermore, the extracted symmetry-informative feature is usually noisy and yields small misclassified patches. To address these gaps, we propose a feature disentanglement approach which is simultaneously symmetry informative and symmetry agnostic. Further, we propose a feature refinement technique to improve the robustness of predicted symmetry informative features. Extensive experiments, including intrinsic symmetry detection, left/right classification, and shape matching, demonstrate the effectiveness of our proposed framework compared to various state-of-the-art methods, both qualitatively and quantitatively.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14804.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14804",
    "published": "2026-01-21T09:30:13Z",
    "updated": "2026-01-21T09:30:13Z",
    "comment": "Accepted at 3DV 2026",
    "light_analysis": {
      "overview": "本论文提出了一种新的特征解耦方法，用于3D形状分析，旨在同时提取对称信息性和对称无关的特征，以改进现有方法的局限性。",
      "motivation": "在3D形状分析中，形状描述符对匹配、编辑和分割等任务至关重要。对称性是形状的关键属性，构建对称感知描述符是自然需求。然而，现有方法如χ提取的对称特征仅为一维，忽略其他语义信息，且存在噪声和小误分类区域，限制了应用效果。因此，有必要开发更鲁棒和全面的特征表示方法来解决这些问题。",
      "method": "论文提出了一种特征解耦方法，该方法同时考虑对称信息性和对称无关的特征。通过特征解耦技术，将形状描述符分解为对称相关部分和对称无关部分，以保留语义多样性。此外，引入特征细化技术来增强预测对称特征的鲁棒性，减少噪声和误分类。该方法适用于3D网格或点云数据，但摘要未明确说明具体模型架构或数据集细节。",
      "result": "通过广泛实验，论文在内在对称检测、左右分类和形状匹配等多个任务上评估了所提框架。结果表明，与现有最先进方法相比，该方法在定性和定量指标上均表现出优越性能，例如在对称检测中减少了噪声和误分类区域，在形状匹配中提高了准确性，但摘要未提供具体数值数据。",
      "conclusion": "该研究的主要贡献是提出了一个结合对称信息性和对称无关特征的特征解耦框架，有效解决了现有方法的局限性，提升了形状分析任务的性能。这为对称感知描述符的发展提供了新方向，潜在局限性可能包括对数据类型的依赖，未来工作可探索更广泛的形状表示和应用场景。",
      "tags": [
        "Feature Disentanglement",
        "Symmetry Detection",
        "3D Shape Descriptors",
        "Semantic Feature Extraction",
        "Robust Feature Refinement"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:08.252640Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14802",
    "title": "LocBAM: Advancing 3D Patch-Based Image Segmentation by Integrating Location Contex",
    "authors": [
      "Donnate Hooft",
      "Stefan M. Fischer",
      "Cosmin Bercea",
      "Jan C. Peeken",
      "Julia A. Schnabel"
    ],
    "abstract": "Patch-based methods are widely used in 3D medical image segmentation to address memory constraints in processing high-resolution volumetric data. However, these approaches often neglect the patch's location within the global volume, which can limit segmentation performance when anatomical context is important. In this paper, we investigate the role of location context in patch-based 3D segmentation and propose a novel attention mechanism, LocBAM, that explicitly processes spatial information. Experiments on BTCV, AMOS22, and KiTS23 demonstrate that incorporating location context stabilizes training and improves segmentation performance, particularly under low patch-to-volume coverage where global context is missing. Furthermore, LocBAM consistently outperforms classical coordinate encoding via CoordConv. Code is publicly available at https://github.com/compai-lab/2026-ISBI-hooft",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14802.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14802",
    "published": "2026-01-21T09:27:59Z",
    "updated": "2026-01-21T09:27:59Z",
    "comment": "Accepted at ISBI 2026",
    "light_analysis": {
      "overview": "LocBAM提出了一种新颖的注意力机制，通过整合位置上下文来改进基于补丁的3D医学图像分割性能。",
      "motivation": "基于补丁的3D医学图像分割方法常用于处理高分辨率体数据以应对内存限制，但忽略补丁在全局体积中的位置信息。在实际应用中，特别是在解剖学上下文对分割准确性至关重要的医学领域，如器官或肿瘤识别，这种忽略会导致分割性能受限。现有补丁方法缺乏对空间位置的有效建模，无法捕捉全局结构，从而影响分割的准确性和鲁棒性，因此研究如何整合位置上下文成为关键问题。",
      "method": "本研究提出了LocBAM，一种新型注意力机制，旨在通过明确处理补丁的空间位置信息来增强分割效果。LocBAM核心创新在于集成位置上下文，直接编码补丁在全局体积中的坐标，以提供定位感知能力。该方法可能基于自注意力或类似架构，但摘要未详细说明具体模型设计细节。技术特色包括对空间信息的直接利用，旨在稳定训练过程并提升对解剖学上下文的建模能力，适用于各种3D医学图像数据集。",
      "result": "在BTCV、AMOS22和KiTS23数据集上的实验结果显示，LocBAM通过整合位置上下文，稳定了训练并显著提高了分割性能。特别是在补丁覆盖率较低、全局上下文缺失的情况下，改进效果更为突出。相比经典的坐标编码方法CoordConv，LocBAM在性能上持续更优，展现了其处理空间信息的优势。尽管摘要未提供具体的准确率或效率数据，但强调了该方法在增强分割效果和鲁棒性方面的有效性。",
      "conclusion": "论文的主要贡献在于提出了LocBAM，一种集成位置上下文的注意力机制，有效提升了基于补丁的3D医学图像分割性能，强调了空间信息的重要性。其学术价值在于推动了注意力机制在医学图像处理中的应用，为未来研究提供了新方向；实际应用价值体现在可提高医疗诊断工具的准确性。局限性可能包括对特定数据集的依赖或未覆盖所有场景，未来工作或可扩展到更多领域或优化算法效率，但摘要未明确说明细节。",
      "tags": [
        "Attention Mechanism",
        "3D Medical Image Segmentation",
        "Patch-Based Methods",
        "Location Context",
        "Coordinate Encoding"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:29.882584Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14799",
    "title": "UBATrack: Spatio-Temporal State Space Model for General Multi-Modal Tracking",
    "authors": [
      "Qihua Liang",
      "Liang Chen",
      "Yaozong Zheng",
      "Jian Nong",
      "Zhiyi Mo",
      "Bineng Zhong"
    ],
    "abstract": "Multi-modal object tracking has attracted considerable attention by integrating multiple complementary inputs (e.g., thermal, depth, and event data) to achieve outstanding performance. Although current general-purpose multi-modal trackers primarily unify various modal tracking tasks (i.e., RGB-Thermal infrared, RGB-Depth or RGB-Event tracking) through prompt learning, they still overlook the effective capture of spatio-temporal cues. In this work, we introduce a novel multi-modal tracking framework based on a mamba-style state space model, termed UBATrack. Our UBATrack comprises two simple yet effective modules: a Spatio-temporal Mamba Adapter (STMA) and a Dynamic Multi-modal Feature Mixer. The former leverages Mamba's long-sequence modeling capability to jointly model cross-modal dependencies and spatio-temporal visual cues in an adapter-tuning manner. The latter further enhances multi-modal representation capacity across multiple feature dimensions to improve tracking robustness. In this way, UBATrack eliminates the need for costly full-parameter fine-tuning, thereby improving the training efficiency of multi-modal tracking algorithms. Experiments show that UBATrack outperforms state-of-the-art methods on RGB-T, RGB-D, and RGB-E tracking benchmarks, achieving outstanding results on the LasHeR, RGBT234, RGBT210, DepthTrack, VOT-RGBD22, and VisEvent datasets.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14799.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14799",
    "published": "2026-01-21T09:24:19Z",
    "updated": "2026-01-21T09:24:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于 Mamba 状态空间模型的多模态跟踪框架 UBATrack，能有效捕获时空线索并提高训练效率。",
      "motivation": "多模态目标跟踪通过整合热像、深度和事件数据来提升性能，但当前通用多模态跟踪器主要依赖提示学习来统一不同模态任务，忽视了时空线索的有效捕获。这限制了跟踪的准确性和鲁棒性，因为时空线索对于动态物体的跟踪至关重要。现有方法在建模跨模态依赖时未能充分结合时空视觉信息，导致跟踪性能受限，因此需要一种能够同时处理多模态特征和时空动态的新方法。",
      "method": "论文提出 UBATrack 框架，包含 Spatio-temporal Mamba Adapter (STMA) 和 Dynamic Multi-modal Feature Mixer 两个模块。STMA 利用 Mamba 状态空间模型的长序列建模能力，以适配器调优方式联合建模跨模态依赖和时空视觉线索，无需全参数微调。Dynamic Multi-modal Feature Mixer 在多个特征维度上增强多模态表示，提高跟踪鲁棒性。该方法在训练上更高效，使用的数据集包括 LasHeR、RGBT234 等，以验证其在 RGB-T、RGB-D 和 RGB-E 跟踪任务中的适用性。",
      "result": "实验结果表明，UBATrack 在 RGB-T、RGB-D 和 RGB-E 跟踪基准上超越了当前最先进的方法，在多个数据集如 LasHeR、RGBT234、RGBT210、DepthTrack、VOT-RGBD22 和 VisEvent 上均取得了优异性能。由于摘要未提供具体性能指标，如准确率或效率提升数据，但可以推断其在跟踪准确性和鲁棒性方面有显著改进，同时通过消除全参数微调提高了训练效率，表明该方法在多种多模态场景中具有通用性和高效性。",
      "conclusion": "论文的主要贡献是提出了一种基于 Mamba 状态空间模型的多模态跟踪框架 UBATrack，它能有效整合时空线索并提高训练效率。这为多模态跟踪领域提供了新的技术路线，具有重要的学术价值，并可能在视频监控、自动驾驶和增强现实等实际应用中发挥重要作用。未来工作可能包括扩展到更多模态或进一步优化模型架构以应对更复杂的动态环境。",
      "tags": [
        "Multi-Modal Tracking",
        "Mamba State Space Model",
        "Spatio-Temporal Modeling",
        "Adapter Tuning"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:04.676572Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14798",
    "title": "Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation",
    "authors": [
      "Ondřej Holub",
      "Essi Ryymin",
      "Rodrigo Alves"
    ],
    "abstract": "Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14798.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14798",
    "published": "2026-01-21T09:23:11Z",
    "updated": "2026-01-21T09:23:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个集成Socratic提问框架的反射问题自动生成系统，通过双代理多轮对话迭代精炼，显著提升了问题质量和教育实用性。",
      "motivation": "设计高质量反思性问题在教学过程中至关重要，但传统方法依赖教师手工设计，耗时费力且效果不均，导致学生反思学习支持不足。现有自动化技术往往缺乏深度和情境适应性，无法满足个性化教育需求。因此，本研究旨在开发一种智能生成框架，以减轻教师负担，通过AI辅助提升反思性问题的生成效率和效果，解决教育实践中资源分配不均的问题。",
      "method": "本研究基于大语言模型（LLMs），采用GPT-4o-mini作为骨干模型，构建了一个双代理系统：Student-Teacher代理提出候选问题及简短理由，Teacher-Educator代理则基于清晰度、深度、相关性、参与度和概念互联性进行评估。通过Socratic多轮对话，系统迭代优化问题，关键创新包括动态停止机制（根据上下文信息如学生水平和教学材料调整迭代次数），避免了过度复杂化。评估在真实初中ICT场景中进行，并使用GPT-4类模型作为外部评估器进行对比分析。",
      "result": "实验结果显示，动态停止结合上下文信息（如学生水平和材料）在问题质量上持续优于固定5或10步迭代，长对话易导致漂移或过度复杂化。双代理协议生成的问题，经外部GPT-4评估，在清晰度、相关性、深度和整体质量上均显著优于单次基线使用相同骨干模型，具体表现为问题更相关、更深层，整体效果提升明显，证明了框架的有效性和优越性。",
      "conclusion": "本研究的主要贡献在于开发了一个创新框架，将Socratic对话与双代理系统结合，实现了反思性问题的自动化高质量生成。学术上，推动了AI在教育领域的应用，特别是在个性化学习和反思支持方面；实践上，能辅助教师高效设计教学问题，提升教育效率。局限性包括长对话可能导致不稳定，未来工作可优化停止策略，扩展应用到其他学科或更复杂情境中。",
      "tags": [
        "Large Language Model",
        "Socratic Questioning",
        "Multi-Agent System",
        "Iterative Refinement",
        "Automated Question Generation"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:09.834552Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14797",
    "title": "UniRoute: Unified Routing Mixture-of-Experts for Modality-Adaptive Remote Sensing Change Detection",
    "authors": [
      "Qingling Shu",
      "Sibao Chen",
      "Wei Lu",
      "Zhihui You",
      "Chengzhuang Liu"
    ],
    "abstract": "Current remote sensing change detection (CD) methods mainly rely on specialized models, which limits the scalability toward modality-adaptive Earth observation. For homogeneous CD, precise boundary delineation relies on fine-grained spatial cues and local pixel interactions, whereas heterogeneous CD instead requires broader contextual information to suppress speckle noise and geometric distortions. Moreover, difference operator (e.g., subtraction) works well for aligned homogeneous images but introduces artifacts in cross-modal or geometrically misaligned scenarios. Across different modality settings, specialized models based on static backbones or fixed difference operations often prove insufficient. To address this challenge, we propose UniRoute, a unified framework for modality-adaptive learning by reformulating feature extraction and fusion as conditional routing problems. We introduce an Adaptive Receptive Field Routing MoE (AR2-MoE) module to disentangle local spatial details from global semantic context, and a Modality-Aware Difference Routing MoE (MDR-MoE) module to adaptively select the most suitable fusion primitive at each pixel. In addition, we propose a Consistency-Aware Self-Distillation (CASD) strategy that stabilizes unified training under data-scarce heterogeneous settings by enforcing multi-level consistency. Extensive experiments on five public datasets demonstrate that UniRoute achieves strong overall performance, with a favorable accuracy-efficiency trade-off under a unified deployment setting.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14797.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14797",
    "published": "2026-01-21T09:21:25Z",
    "updated": "2026-01-21T09:21:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出UniRoute统一框架，通过条件路由混合专家实现模态自适应的遥感变化检测，提升可扩展性和性能。",
      "motivation": "当前遥感变化检测方法主要依赖专门化模型，难以适应不同模态的地球观测数据，限制了可扩展性。同质变化检测需要精细空间线索和局部像素交互以精确划定边界，而异质变化检测需更广泛上下文信息抑制散斑噪声和几何失真。传统差异操作如减法在跨模态或几何未对齐场景中引入伪影，现有方法基于静态骨干或固定操作往往不足。因此，研究旨在开发统一框架解决模态自适应问题，提升鲁棒性和效率。",
      "method": "UniRoute框架将特征提取和融合重新定义为条件路由问题。核心模块包括自适应感受野路由混合专家（AR2-MoE），用于分离局部空间细节和全局语义上下文，以及模态感知差异路由混合专家（MDR-MoE），在每个像素自适应选择最合适融合原语。提出一致性感知自蒸馏（CASD）策略，通过强制多层次一致性，在数据稀缺异质设置下稳定统一训练。方法在多个公共数据集上验证，但具体数据集细节摘要未明确说明。",
      "result": "在五个公开数据集上的广泛实验表明，UniRoute实现了强大的整体性能。在统一部署设置下，该框架展现出有利的精度-效率权衡，优于传统专门化方法。虽然摘要未提供具体性能指标如准确率提升百分比，但强调了其在多种模态场景下的鲁棒性和可扩展性优势，证明了自适应路由和一致性蒸馏的有效性。",
      "conclusion": "UniRoute通过统一路由混合专家框架解决了模态自适应的遥感变化检测问题，学术上推动了多模态学习和条件路由技术的发展，实际上为地球观测提供了可扩展且高效的解决方案。研究存在局限性如数据稀缺环境挑战，未来工作可探索更多模态适应性和实时应用部署。",
      "tags": [
        "Remote Sensing Change Detection",
        "Mixture-of-Experts",
        "Adaptive Routing",
        "Modality Adaptation",
        "Self-Distillation"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:58.821756Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14792",
    "title": "Robustness of Mixtures of Experts to Feature Noise",
    "authors": [
      "Dong Sun",
      "Rahul Nittala",
      "Rebekka Burkholz"
    ],
    "abstract": "Despite their practical success, it remains unclear why Mixture of Experts (MoE) models can outperform dense networks beyond sheer parameter scaling. We study an iso-parameter regime where inputs exhibit latent modular structure but are corrupted by feature noise, a proxy for noisy internal activations. We show that sparse expert activation acts as a noise filter: compared to a dense estimator, MoEs achieve lower generalization error under feature noise, improved robustness to perturbations, and faster convergence speed. Empirical results on synthetic data and real-world language tasks corroborate the theoretical insights, demonstrating consistent robustness and efficiency gains from sparse modular computation.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14792.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14792",
    "published": "2026-01-21T09:15:48Z",
    "updated": "2026-01-21T09:15:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文揭示了混合专家模型通过稀疏专家激活作为噪声滤波器，在特征噪声下提升鲁棒性和效率的创新机制。",
      "motivation": "混合专家模型在实践中表现优异，但其超越密集网络的原因，尤其是在噪声环境中的优势，尚不明确。本研究旨在解决特征噪声污染输入时模型的鲁棒性问题，现有密集网络可能对噪声敏感，导致泛化性能下降。因此，探究MoE的内在机制，理解其如何通过稀疏激活过滤噪声，对提高模型可靠性和设计更健壮的AI系统具有重要价值。",
      "method": "研究在等参量机制下进行，假设输入具有潜在模块化结构并受特征噪声影响。核心方法是理论分析稀疏专家激活如何充当噪声滤波器，将MoE模型与密集估计器在噪声场景下对比。关键创新点在于量化稀疏激活对泛化误差和收敛速度的影响。实验使用合成数据模拟噪声，并结合现实世界语言任务验证理论，模型架构基于MoE，但具体细节摘要未明确说明。",
      "result": "主要实验结果显示，与密集估计器相比，混合专家模型在特征噪声下实现了更低的泛化误差、改进的鲁棒性扰动和更快的收敛速度。在合成数据和真实语言任务上的实证结果一致证实了这些优势，但具体性能指标如准确率提升数值摘要未明确说明。这些发现支持了稀疏模块化计算的理论见解，强调了MoE在噪声环境中的效率和鲁棒性增益。",
      "conclusion": "研究主要贡献是解释了混合专家模型通过稀疏专家激活过滤特征噪声，提供鲁棒性和效率提升，揭示了其在等参量机制下的优势。学术价值在于为MoE的理论理解提供了新视角，实际应用价值包括设计更健壮的AI模型应对噪声数据。局限性或未来工作摘要未明确说明，但可推断为扩展到其他噪声类型或更广泛任务领域。",
      "tags": [
        "Mixture of Experts",
        "Feature Noise",
        "Robustness",
        "Sparse Activation",
        "Modular Computation"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:08.203203Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14791",
    "title": "Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach",
    "authors": [
      "Ziyao Ling",
      "Silvia Mirri",
      "Paola Salomoni",
      "Giovanni Delnevo"
    ],
    "abstract": "The scarcity of training data presents a fundamental challenge in applying deep learning to archaeological artifact classification, particularly for the rare types of Chinese porcelain. This study investigates whether synthetic images generated through Stable Diffusion with Low-Rank Adaptation (LoRA) can effectively augment limited real datasets for multi-task CNN-based porcelain classification. Using MobileNetV3 with transfer learning, we conducted controlled experiments comparing models trained on pure real data against those trained on mixed real-synthetic datasets (95:5 and 90:10 ratios) across four classification tasks: dynasty, glaze, kiln and type identification. Results demonstrate task-specific benefits: type classification showed the most substantial improvement (5.5\\% F1-macro increase with 90:10 ratio), while dynasty and kiln tasks exhibited modest gains (3-4\\%), suggesting that synthetic augmentation effectiveness depends on the alignment between generated features and task-relevant visual signatures. Our work contributes practical guidelines for deploying generative AI in archaeological research, demonstrating both the potential and limitations of synthetic data when archaeological authenticity must be balanced with data diversity.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14791.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14791",
    "published": "2026-01-21T09:14:22Z",
    "updated": "2026-01-21T09:14:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过结合 Stable Diffusion 与 Low-Rank Adaptation 生成合成图像，增强多任务中国瓷器分类模型的性能，并评估其任务特定效果。",
      "motivation": "在考古文物分类中，特别是稀有中国瓷器，训练数据的稀缺性严重制约了深度学习模型的准确性和泛化能力。现有方法依赖有限的真实数据集，难以应对复杂多任务分类需求，因此需要探索数据增强策略以克服这一挑战。本研究旨在利用生成 AI 技术解决数据稀缺问题，通过合成数据增强提高分类性能，促进考古学研究的进展。",
      "method": "论文提出采用 Stable Diffusion 与 Low-Rank Adaptation (LoRA) 生成中国瓷器的合成图像，以扩充真实数据集。基于 MobileNetV3 模型进行迁移学习，执行多任务分类，涵盖朝代、釉料、窑口和类型识别。通过控制实验，比较纯真实数据与混合数据（95:5 和 90:10 比例）的效果，关键创新点在于结合生成 AI 进行数据增强，并评估其在考古领域的应用价值。",
      "result": "实验结果显示，合成数据增强对模型性能有积极影响。类型分类任务在 90:10 混合比例下 F1-macro 指标提升 5.5%，而朝代和窑口分类任务分别获得 3-4% 的适度增益。与纯真实数据训练的基线模型相比，这些改进表明合成数据在特定任务中有效，但其效果取决于生成特征与任务相关视觉特征的对齐程度。",
      "conclusion": "本研究总结了 Stable Diffusion 与 LoRA 在考古分类中作为数据增强工具的潜力，提供了实用指南以部署生成 AI 技术。它展示了合成数据在平衡考古真实性与数据多样性方面的价值与限制，主要贡献在于为数据稀缺问题提供解决方案。未来工作可聚焦于优化生成过程以更好对齐任务特征，进一步提升分类性能。",
      "tags": [
        "Stable Diffusion",
        "Low-Rank Adaptation",
        "Multi-Task Classification",
        "Synthetic Data Augmentation",
        "Transfer Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:46.881418Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14790",
    "title": "CI4A: Semantic Component Interfaces for Agents Empowering Web Automation",
    "authors": [
      "Zhi Qiu",
      "Jiazheng Sun",
      "Chenxiao Xia",
      "Jun Zheng",
      "Xin Peng"
    ],
    "abstract": "While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14790.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14790",
    "published": "2026-01-21T09:14:04Z",
    "updated": "2026-01-21T09:14:04Z",
    "comment": "9 pages, 5 figures",
    "light_analysis": {
      "overview": "本文提出CI4A机制，通过语义封装UI组件为代理提供统一交互工具，显著提升web自动化的任务成功率和执行效率。",
      "motivation": "该研究旨在解决大型语言模型在web自动化中处理细粒度UI组件操作的不足。尽管LLMs在高级语义规划表现出色，但它们在低级别网页交互中仍有限制。现有方法如强化学习侧重于增强模型grounding，但迫使代理适应人类中心界面，效率不高。因此，研究提出构建专为代理优化的交互接口，以更有效地支持自动化任务，弥补当前方法的缺陷。",
      "method": "论文提出CI4A（Component Interface for Agent）机制，通过语义封装将UI组件的复杂交互逻辑抽象为一组统一的工具原语，使代理能够轻松调用。该方法在工业级前端框架Ant Design中实现，覆盖了23个类别的常用UI组件。此外，开发了一个混合代理，其动作空间根据页面状态动态更新，实现灵活的工具调用。基于CI4A集成的Ant Design，作者重构并升级了WebArena基准，用于评估现有最先进方法，确保实验的公平性和全面性。",
      "result": "实验结果表明，基于CI4A的代理在WebArena基准上显著优于现有方法，实现了新的最先进任务成功率86.3%。摘要未明确说明具体效率数据，但提到执行效率有substantial improvements，表明在执行速度和资源使用方面均有提升。与基线方法相比，CI4A方法在准确率和效率上都表现出明显优势，验证了该机制的有效性。",
      "conclusion": "本研究的主要贡献是提出CI4A机制，通过为代理设计专门的语义接口，解决了LLMs在细粒度web操作中的限制，推动了代理与界面交互的新思路。学术上，它丰富了AI在自动化领域的理论；实际应用中，集成到Ant Design框架展示了工业实用性，可促进web自动化的广泛应用。未来工作方向摘要未明确说明，但可能包括扩展到更多UI组件类型或应用到其他领域，以进一步提升代理的适应能力。",
      "tags": [
        "Large Language Models",
        "Semantic Encapsulation",
        "UI Components",
        "Web Automation",
        "Hybrid Agent"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:52.600228Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14788",
    "title": "Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation",
    "authors": [
      "Yifei Liu",
      "Changxing Ding",
      "Ling Guo",
      "Huaiguang Jiang",
      "Qiong Cao"
    ],
    "abstract": "Diffusion models have seen widespread adoption for text-driven human motion generation and related tasks due to their impressive generative capabilities and flexibility. However, current motion diffusion models face two major limitations: a representational gap caused by pre-trained text encoders that lack motion-specific information, and error propagation during the iterative denoising process. This paper introduces Reconstruction-Anchored Diffusion Model (RAM) to address these challenges. First, RAM leverages a motion latent space as intermediate supervision for text-to-motion generation. To this end, RAM co-trains a motion reconstruction branch with two key objective functions: self-regularization to enhance the discrimination of the motion space and motion-centric latent alignment to enable accurate mapping from text to the motion latent space. Second, we propose Reconstructive Error Guidance (REG), a testing-stage guidance mechanism that exploits the diffusion model's inherent self-correction ability to mitigate error propagation. At each denoising step, REG uses the motion reconstruction branch to reconstruct the previous estimate, reproducing the prior error patterns. By amplifying the residual between the current prediction and the reconstructed estimate, REG highlights the improvements in the current prediction. Extensive experiments demonstrate that RAM achieves significant improvements and state-of-the-art performance. Our code will be released.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14788.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14788",
    "published": "2026-01-21T09:11:45Z",
    "updated": "2026-01-21T09:11:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Reconstruction-Anchored Diffusion Model (RAM)，通过运动潜在空间监督和重建错误引导，改进文本到运动生成的准确性和鲁棒性。",
      "motivation": "当前扩散模型在文本驱动人体运动生成中面临两个主要限制：表示间隙因预训练文本编码器缺乏运动特定信息，导致文本到运动的映射不准确；迭代去噪过程中的错误传播影响生成稳定性，降低输出质量。这些问题在动画和虚拟现实等应用中至关重要，现有方法未能有效结合运动领域知识，导致性能受限和错误累积。",
      "method": "RAM模型提出两个核心创新：首先，利用运动潜在空间作为中间监督，共同训练运动重建分支，通过自正则化增强空间区分度和运动中心潜在对齐实现文本到潜在空间的精确映射。其次，设计Reconstructive Error Guidance (REG)机制，在测试阶段利用扩散模型的自校正能力，基于重建分支重构先前的估计并放大残差，以减少错误传播。该方法基于扩散模型框架，摘要未明确说明具体数据集和模型架构细节。",
      "result": "广泛实验表明，RAM在文本到运动生成任务中实现了显著改进和最佳性能。与基线方法相比，RAM在准确性和鲁棒性方面表现优异，有效减轻了表示间隙和错误传播的影响，尽管摘要未提供具体数值指标如准确率提升百分比，但强调了其优越性和有效性。",
      "conclusion": "RAM模型通过集成运动潜在空间监督和重建错误引导，成功解决了表示间隙和错误传播问题，提升了文本到运动生成的性能。其学术价值在于改进了扩散模型在运动生成领域的应用，增强了模型的稳定性和解释性；实际应用价值在于为动画和游戏等行业提供更可靠的生成工具。未来工作可能涉及扩展到其他运动相关任务，但摘要未明确说明局限性。",
      "tags": [
        "Text-to-Motion Generation",
        "Diffusion Models",
        "Motion Latent Space",
        "Reconstructive Error Guidance",
        "Self-Regularization"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:34.634531Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14784",
    "title": "Towards Bound Consistency for the No-Overlap Constraint Using MDDs",
    "authors": [
      "Amaury Guichard",
      "Laurent Michel",
      "Hélène Verhaeghe",
      "Pierre Schaus"
    ],
    "abstract": "Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \\mid r_j, d_j, \\bar{d}_j \\mid \\sum E_j + \\sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14784.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14784",
    "published": "2026-01-21T09:06:24Z",
    "updated": "2026-01-21T09:06:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了首个基于多值决策图的边界一致性算法，用于无重叠约束，实现多项式时间过滤。",
      "motivation": "本研究的动机源于约束规划中无重叠约束的边界一致性是NP完全问题，这在实际应用中如调度和排序至关重要。现有方法如边界检测、非首非末推理等虽提供了多项式时间近似，但在效率和精度上仍有不足，未能完全解决这一挑战。因此，开发一个更强健、可扩展的边界一致性算法以提升优化问题的求解性能，具有显著的学术和实际意义。",
      "method": "方法基于Ciré和van Hoeve定义的无重叠多值决策图，通过提取作业时间窗口的界限，在多项式时间内收紧任务的开始和结束时间。核心创新包括限制MDD宽度至阈值，创建宽松MDD以平衡精确性与计算复杂度。这技术融合了MDD的结构化表示和阈值调整，支持高效的边界一致性过滤，适用于处理复杂时间窗口约束。",
      "result": "实验在带时间窗口和及时目标的排序问题（1 | r_j, d_j, \bar{d}_j | ΣE_j + ΣT_j）上进行。结果表明，新过滤方法相比先前precedence-detection算法，在搜索树访问节点数上有更强减少。同时，与经典传播方法互补，在多个实例中显著降低了节点数和求解时间，提升了整体求解效率。",
      "conclusion": "本研究的主要贡献是实现了无重叠约束的首个边界一致性算法，利用MDDs提供了多项式时间过滤方案。这推进了约束规划理论，为NP完全问题提供了新思路，并在实际调度应用中优化求解过程。未来工作可探索MDD参数优化或扩展到其他约束类型，以进一步提高算法适用性。",
      "tags": [
        "No-Overlap Constraint",
        "Bound Consistency",
        "Multi-Valued Decision Diagrams (MDDs)",
        "Filtering Algorithms",
        "Constraint Programming"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:50.837041Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14780",
    "title": "RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models",
    "authors": [
      "Anqi Li",
      "Yuqian Chen",
      "Yu Lu",
      "Zhaoming Chen",
      "Yuan Xie",
      "Zhenzhong Lan"
    ],
    "abstract": "Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability.   To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations.   RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors' understanding and intervention strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14780.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14780",
    "published": "2026-01-21T09:00:36Z",
    "updated": "2026-01-21T09:00:36Z",
    "comment": "19 pages, 2 figures",
    "light_analysis": {
      "overview": "该论文提出了RECAP框架，利用大型语言模型在文本心理健康咨询中捕捉和解释客户抵抗行为。",
      "motivation": "心理健康咨询中，客户抵抗是影响咨询效果的关键障碍，但基于文本的交互中检测抵抗行为尤为困难。现有自然语言处理（NLP）方法通常简化抵抗类别，忽略治疗干预的顺序动态，且提供有限的可解释性。这些问题阻碍了咨询师在实际操作中对客户行为的有效理解和应对，因此需要开发一种更精细、可解释的抵抗检测方法来提升咨询效率。摘要未明确说明现有方法的具体名称或更广泛背景。",
      "method": "论文提出理论基础框架PsyFIRE，用于捕捉13种细粒度抵抗行为和协作交互。基于此框架，构建了ClientResistance语料库，包含来自真实世界中文文本咨询的23,930个注释话语，每个都有上下文特定的理由。利用该数据集，开发了RECAP两阶段框架，它使用大型语言模型（LLM）检测抵抗并提供解释，包括区分协作与抵抗以及分类细粒度抵抗类型。关键创新点在于结合理论定义、精细标注和LLM能力。",
      "result": "RECAP在区分协作和抵抗方面达到91.25% F1分数，在细粒度抵抗类别分类方面达到66.58% macro-F1分数，优于基于提示的大型语言模型基线超过20个百分点。应用于一个独立的咨询数据集和包含62名咨询师的试点研究时，RECAP揭示了抵抗行为的普遍性及其对治疗关系的负面影响，并展示了帮助咨询师提高理解和干预策略的潜力，但没有提供更具体的性能比较数据。",
      "conclusion": "该论文的主要贡献是提出了PsyFIRE框架、ClientResistance语料库和RECAP框架，显著提升了文本心理健康咨询中抵抗检测的准确性和可解释性。学术价值在于推动了NLP在心理健康领域的精细应用，实际价值体现在为咨询师提供实用工具以改善咨询效果。潜在局限性可能涉及数据集的语种限制，未来工作可扩展到更多语言和咨询场景以优化模型泛化能力。摘要未明确说明更多局限性细节。",
      "tags": [
        "Large Language Model",
        "Natural Language Processing",
        "Resistance Detection",
        "Fine-grained Classification",
        "Text-based Counseling"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:34.788143Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14777",
    "title": "FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes",
    "authors": [
      "Jiaxuan Liu",
      "Yang Xiang",
      "Han Zhao",
      "Xiangang Li",
      "Zhenhua Ling"
    ],
    "abstract": "Movie dubbing is the task of synthesizing speech from scripts conditioned on video scenes, requiring accurate lip sync, faithful timbre transfer, and proper modeling of character identity and emotion. However, existing methods face two major limitations: (1) high-quality multimodal dubbing datasets are limited in scale, suffer from high word error rates, contain sparse annotations, rely on costly manual labeling, and are restricted to monologue scenes, all of which hinder effective model training; (2) existing dubbing models rely solely on the lip region to learn audio-visual alignment, which limits their applicability to complex live-action cinematic scenes, and exhibit suboptimal performance in lip sync, speech quality, and emotional expressiveness. To address these issues, we propose FunCineForge, which comprises an end-to-end production pipeline for large-scale dubbing datasets and an MLLM-based dubbing model designed for diverse cinematic scenes. Using the pipeline, we construct the first Chinese television dubbing dataset with rich annotations, and demonstrate the high quality of these data. Experiments across monologue, narration, dialogue, and multi-speaker scenes show that our dubbing model consistently outperforms SOTA methods in audio quality, lip sync, timbre transfer, and instruction following. Code and demos are available at https://anonymous.4open.science/w/FunCineForge.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14777.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14777",
    "published": "2026-01-21T08:57:00Z",
    "updated": "2026-01-21T08:57:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "FunCineForge 提出一个统一的数据集工具包和基于 MLLM 的模型，用于高质量零样本电影配音，并构建了首个中文电视配音数据集。",
      "motivation": "电影配音需要将脚本与视频场景对齐，实现准确唇形同步、音色传递以及角色身份和情感建模。现有方法存在两大问题：高质量多模态配音数据集规模有限、错误率高、注释稀疏且依赖昂贵人工标注，仅限于独白场景，阻碍模型训练；同时，现有模型仅依赖唇部区域学习音频-视觉对齐，在复杂实拍电影场景中适用性差，唇形同步、语音质量和情感表达性能不佳。这些限制影响了配音技术的实际应用和发展。",
      "method": "FunCineForge 包括一个端到端的数据集生产管道和一个基于 MLLM（多模态大语言模型）的配音模型。该管道用于自动构建大规模、高质量的多模态配音数据集，并成功构建了首个中文电视配音数据集，具有丰富注释。配音模型专为多样化电影场景设计，整合了文本、音频和视频信息，以处理独白、对话等复杂场景的音频-视觉对齐问题。关键创新在于统一的数据集构建方法和 MLLM 模型的应用，提升了模型在复杂场景中的适应性。",
      "result": "在独白、旁白、对话和多说话者场景的实验评估中，FunCineForge 模型在音频质量、唇形同步、音色传递和指令遵循方面始终优于现有最优方法（SOTA）。摘要未提供具体性能指标数据，但结果表明该模型在各种电影场景中均表现出色，显著提升了配音的整体质量和适用性。与基线方法相比，模型在复杂场景中的对齐能力和情感表达得到增强，验证了其有效性。",
      "conclusion": "FunCineForge 的主要贡献是提供了一个完整的数据集工具包和基于 MLLM 的配音模型，解决了现有方法在数据集质量和场景适用性上的限制。该研究具有重要学术价值，推动了多模态零样本配音技术的发展，并为电影和电视制作提供了实用的工具。潜在局限性可能包括模型在更复杂或更大规模数据集上的泛化能力，但摘要未明确说明未来工作方向。",
      "tags": [
        "Zero-Shot Learning",
        "Multimodal Dataset",
        "MLLM",
        "Audio-Visual Alignment",
        "Movie Dubbing"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:20.243519Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14776",
    "title": "M2I2HA: A Multi-modal Object Detection Method Based on Intra- and Inter-Modal Hypergraph Attention",
    "authors": [
      "Xiaofan Yang",
      "Yubin Liu",
      "Wei Pan",
      "Guoqing Chu",
      "Junming Zhang",
      "Jie Zhao",
      "Zhuoqi Man",
      "Xuanming Cao"
    ],
    "abstract": "Recent advances in multi-modal detection have significantly improved detection accuracy in challenging environments (e.g., low light, overexposure). By integrating RGB with modalities such as thermal and depth, multi-modal fusion increases data redundancy and system robustness. However, significant challenges remain in effectively extracting task-relevant information both within and across modalities, as well as in achieving precise cross-modal alignment. While CNNs excel at feature extraction, they are limited by constrained receptive fields, strong inductive biases, and difficulty in capturing long-range dependencies. Transformer-based models offer global context but suffer from quadratic computational complexity and are confined to pairwise correlation modeling. Mamba and other State Space Models (SSMs), on the other hand, are hindered by their sequential scanning mechanism, which flattens 2D spatial structures into 1D sequences, disrupting topological relationships and limiting the modeling of complex higher-order dependencies. To address these issues, we propose a multi-modal perception network based on hypergraph theory called M2I2HA. Our architecture includes an Intra-Hypergraph Enhancement module to capture global many-to-many high-order relationships within each modality, and an Inter-Hypergraph Fusion module to align, enhance, and fuse cross-modal features by bridging configuration and spatial gaps between data sources. We further introduce a M2-FullPAD module to enable adaptive multi-level fusion of multi-modal enhanced features within the network, meanwhile enhancing data distribution and flow across the architecture. Extensive object detection experiments on multiple public datasets against baselines demonstrate that M2I2HA achieves state-of-the-art performance in multi-modal object detection tasks.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14776.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14776",
    "published": "2026-01-21T08:55:07Z",
    "updated": "2026-01-21T08:55:07Z",
    "comment": "43 pages, 13 figures",
    "light_analysis": {
      "overview": "M2I2HA 是一种基于超图理论的多模态物体检测方法，通过模态内和模态间超图注意力模块有效捕获高阶关系，解决现有模型的局限性。",
      "motivation": "多模态检测在低光、过曝等挑战性环境中提高了精度，但现有方法面临提取任务相关信息和实现跨模态对齐的难题。CNN 受限感受野和长距离依赖，Transformer 计算复杂且仅建模成对相关性，Mamba/SSMs 破坏空间结构，难以捕捉复杂高阶依赖。因此，需要一种能全局建模模态内和跨模态关系并保持空间拓扑的方法，以增强系统鲁棒性和准确性。",
      "method": "M2I2HA 基于超图理论构建多模态感知网络，核心包括 Intra-Hypergraph Enhancement 模块，用于捕获模态内全局多对多高阶关系；Inter-Hypergraph Fusion 模块，通过桥接数据源间的配置和空间差异，对齐、增强和融合跨模态特征；以及 M2-FullPAD 模块，实现网络内多模态增强特征的自适应多级融合，同时改善数据分布和流动。该方法采用超图注意力机制，避免传统模型的空间结构破坏和计算瓶颈。",
      "result": "在多个公共数据集上进行物体检测实验，与基线方法相比，M2I2HA 实现了 state-of-the-art 性能，具体性能指标如准确率提升摘要未明确说明，但实验证明了其显著优于现有模型，有效提高了检测精度和鲁棒性。",
      "conclusion": "M2I2HA 通过超图注意力机制改进了多模态物体检测中的高阶关系建模和跨模态融合，提升了检测性能，对计算机视觉领域有重要学术价值。研究为复杂环境下的目标检测提供了新思路，未来可扩展到更多模态或实际应用场景，局限性如计算效率优化摘要未明确说明。",
      "tags": [
        "Multi-modal Object Detection",
        "Hypergraph Attention",
        "State Space Models (SSMs)",
        "Feature Fusion"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:14.391521Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14774",
    "title": "Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis",
    "authors": [
      "Keita Takeda",
      "Tomoya Sakai"
    ],
    "abstract": "This study investigates the feature representations produced by publicly available open source medical vision-language models (VLMs). While medical VLMs are expected to capture diagnostically relevant features, their learned representations remain underexplored, and standard evaluations like classification accuracy do not fully reveal if they acquire truly discriminative, lesion-specific features. Understanding these representations is crucial for revealing medical image structures and improving downstream tasks in medical image analysis. This study aims to investigate the feature distributions learned by medical VLMs and evaluate the impact of medical specialization. We analyze the feature distribution of multiple image modalities extracted by some representative medical VLMs across lesion classification datasets on multiple modalities. These distributions were compared them with non-medical VLMs to assess the domain-specific medical training. Our experiments showed that medical VLMs can extract discriminative features that are effective for medical classification tasks. Moreover, it was found that non-medical VLMs with recent improvement with contextual enrichment such as LLM2CLIP produce more refined feature representations. Our results imply that enhancing text encoder is more crucial than training intensively on medical images when developing medical VLMs. Notably, non-medical models are particularly vulnerable to biases introduced by overlaied text strings on images. These findings underscore the need for careful consideration on model selection according to downstream tasks besides potential risks in inference due to background biases such as textual information in images.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14774.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14774",
    "published": "2026-01-21T08:53:40Z",
    "updated": "2026-01-21T08:53:40Z",
    "comment": "A short version paper of this research has been accepted for The IEEE International Symposium on Biomedical Imaging (ISBI) 2026",
    "light_analysis": {
      "overview": "本研究发现医学视觉语言模型的特征分布分析表明，增强文本编码器比医学专门化训练更关键。",
      "motivation": "医学视觉语言模型（VLMs）被预期用于诊断，但其学习到的特征表示是否真正具有区分性尚未充分探索。标准评估如分类准确率不能完全揭示病变特定特征，而理解这些表示对改进医学图像分析的下游任务至关重要。现有方法在评估特征质量方面不足，导致模型潜在能力未被验证。因此，本研究旨在通过分析特征分布，填补这一空白，并评估医学专门化的实际效果。",
      "method": "本研究采用特征分布分析方法，分析公开可用的开源医学VLMs提取的特征表示。覆盖多个图像模态（如不同医学影像类型）和病变分类数据集，比较医学VLMs与非医学VLMs（如LLM2CLIP改进版）的特征分布。关键创新在于利用分布分析揭示模型学习特征的质量和特异性，以评估领域特定训练的影响。",
      "result": "实验结果显示医学VLMs能够提取对医学分类任务有效的区分性特征。然而，非医学VLMs通过上下文丰富（如LLM2CLIP改进版）产生了更精炼的特征表示，表明增强文本编码器比在医学图像上密集训练更重要。与基线方法比较，非医学模型还更容易受到图像中叠加文本字符串引入的偏见影响。摘要未明确说明具体性能指标，但通过分布分析揭示了模型改进方向。",
      "conclusion": "本研究的主要贡献是通过特征分布分析揭示了医学VLMs的学习机制，并发现文本编码器改进比医学专门化训练更关键。学术价值在于为医学图像分析中的模型设计和评估提供了新视角，实际应用价值在于指导模型选择需考虑下游任务并警惕背景偏见风险。未来工作可进一步探索不同模态和任务的适应性优化。",
      "tags": [
        "Vision-Language Models",
        "Feature Distribution Analysis",
        "Medical Image Analysis",
        "Text Encoder",
        "Contextual Enrichment"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:48.085337Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14773",
    "title": "Semantic-Guided Unsupervised Video Summarization",
    "authors": [
      "Haizhou Liu",
      "Haodong Jin",
      "Yiming Wang",
      "Hui Yu"
    ],
    "abstract": "Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14773.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14773",
    "published": "2026-01-21T08:53:29Z",
    "updated": "2026-01-21T08:53:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种语义引导的无监督视频摘要方法，通过帧级语义对齐注意力和增量训练策略提升摘要性能并稳定训练。",
      "motivation": "视频摘要技术在社交理解中至关重要，能高效浏览海量多媒体内容并提取关键信息，但现有无监督方法主要依赖生成对抗网络（GANs），存在显著不足。这些方法通常仅利用单模态特征，忽视了语义信息在关键帧选择中的引导作用，导致摘要质量受限。此外，GAN训练过程不稳定，影响模型性能的可靠性和可重复性。因此，亟需开发一种新方法，以解决语义信息利用不足和训练稳定性问题，从而提升视频摘要的准确性和实用性，满足社交平台对高效信息处理的需求。",
      "method": "本研究提出了一种新颖的语义引导无监督视频摘要方法，核心创新在于设计了一个帧级语义对齐注意力机制，并将其集成到关键帧选择器中。该机制在对抗训练框架内，指导基于Transformer的生成器更有效地重构视频，从而增强摘要的语义连贯性。此外，为了应对GAN训练不稳定的问题，我们采用了增量训练策略，逐步更新模型组件，确保训练过程的平稳进行。关键技术特色在于将语义信息与注意力机制结合，优化了关键帧选择，同时使用Transformer架构提升生成能力，但摘要未明确说明具体的数据集和模型架构细节。",
      "result": "实验结果显示，该方法在多个基准数据集上取得了优越的性能表现，显著优于现有的无监督视频摘要方法。通过与基线方法的对比，新方法在摘要准确性和连贯性方面均有显著提升，尽管摘要未明确说明具体的性能指标如准确率或效率改进数值。这表明该方法不仅有效克服了语义信息利用不足和训练不稳定性的问题，还具有良好的泛化能力，能够在不同数据环境下保持一致的高效表现，为实际应用提供了可靠的解决方案。",
      "conclusion": "本研究的主要贡献在于提出了一种结合语义引导和增量训练的无监督视频摘要框架，通过帧级语义对齐注意力和稳定训练策略，显著提升了摘要质量并解决了现有方法的不足。学术价值体现在推动了视频摘要领域对语义信息整合和训练优化技术的研究，实际应用价值在于为社交平台提供更高效、稳定的视频内容分析工具。潜在局限性可能包括对特定数据集或场景的适应性，未来工作可进一步探索模型在多样化数据中的泛化能力，并优化计算效率以实现更广泛的应用部署。",
      "tags": [
        "Unsupervised Video Summarization",
        "Generative Adversarial Networks",
        "Transformer",
        "Attention Mechanism",
        "Semantic Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:15.046651Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14771",
    "title": "Using Multi-Instance Learning to Identify Unique Polyps in Colon Capsule Endoscopy Images",
    "authors": [
      "Puneet Sharma",
      "Kristian Dalsbø Hindberg",
      "Eibe Frank",
      "Benedicte Schelde-Olesen",
      "Ulrik Deding"
    ],
    "abstract": "Identifying unique polyps in colon capsule endoscopy (CCE) images is a critical yet challenging task for medical personnel due to the large volume of images, the cognitive load it creates for clinicians, and the ambiguity in labeling specific frames. This paper formulates this problem as a multi-instance learning (MIL) task, where a query polyp image is compared with a target bag of images to determine uniqueness. We employ a multi-instance verification (MIV) framework that incorporates attention mechanisms, such as variance-excited multi-head attention (VEMA) and distance-based attention (DBA), to enhance the model's ability to extract meaningful representations. Additionally, we investigate the impact of self-supervised learning using SimCLR to generate robust embeddings. Experimental results on a dataset of 1912 polyps from 754 patients demonstrate that attention mechanisms significantly improve performance, with DBA L1 achieving the highest test accuracy of 86.26\\% and a test AUC of 0.928 using a ConvNeXt backbone with SimCLR pretraining. This study underscores the potential of MIL and self-supervised learning in advancing automated analysis of Colon Capsule Endoscopy images, with implications for broader medical imaging applications.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14771.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14771",
    "published": "2026-01-21T08:50:31Z",
    "updated": "2026-01-21T08:50:31Z",
    "comment": "19 pages",
    "light_analysis": {
      "overview": "本文通过多实例学习框架结合注意力机制，自动识别结肠胶囊内窥镜图像中的独特息肉，提高了识别准确率。",
      "motivation": "结肠胶囊内窥镜技术产生大量图像，医生需手动审查以识别独特息肉，带来了高认知负荷和标签模糊问题。传统计算机视觉方法在处理模糊标注和大规模数据时效果有限，自动化解决方案能提高诊断效率，降低人为错误，对结肠癌早期检测至关重要。本文旨在解决这一挑战，通过先进学习方法改进息肉识别。",
      "method": "研究将问题形式化为多实例学习任务，提出多实例验证框架，集成方差激发多头注意力和基于距离的注意力机制以增强特征提取。使用自监督学习（SimCLR）生成鲁棒图像嵌入，模型基于ConvNeXt骨干网络进行预训练和微调。关键创新在于结合多种注意力机制处理图像袋中的不确定性，并利用对比学习提升表示质量。",
      "result": "在包含1912个息肉、754名患者的数据集上，注意力机制显著提高性能。具体地，基于距离的注意力L1版本在测试中达到86.26%的准确率和0.928的AUC，使用SimCLR预训练的ConvNeXt骨干网络。与基线相比，注意力机制的引入带来了明显提升，验证了方法的有效性。",
      "conclusion": "本研究的主要贡献在于成功应用多实例学习和自监督学习到医学图像分析中，提高了结肠胶囊内窥镜图像中独特息肉的识别性能。它具有学术价值，推动了自动化医学成像技术的发展，实际应用可辅助临床诊断，减轻医生负担。未来工作可探索更大数据集和跨域泛化，以进一步提升模型鲁棒性。",
      "tags": [
        "Multi-Instance Learning",
        "Attention Mechanism",
        "Self-Supervised Learning",
        "ConvNeXt",
        "SimCLR"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:42.345144Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14765",
    "title": "Anytime Optimal Decision Tree Learning with Continuous Features",
    "authors": [
      "Harold Kiossou",
      "Pierre Schaus",
      "Siegfried Nijssen"
    ],
    "abstract": "In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14765.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14765",
    "published": "2026-01-21T08:40:06Z",
    "updated": "2026-01-21T08:40:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于有限差异搜索的任意时间最优决策树学习方法，用于改善连续特征下决策树学习的计算效率和中断性能。",
      "motivation": "研究动机在于解决连续特征下最优决策树学习的计算挑战。现有算法主要针对二值特征，扩展到连续特征时，每个特征有大量潜在分割点，导致计算复杂性增加。深度优先搜索等精确算法计算时间增长快，仅适用于浅层深度（如3或4），并且在早期中断时，由于优化策略不平衡，找到的决策树往往质量较差，甚至不如C4.5等贪婪方法。因此，需要开发一种能确保任何时候都提供高质量解决方案的方法，以提高实际应用性。",
      "method": "论文提出了一种任意时间但完整的决策树学习方法，核心是利用有限差异搜索技术。该方法优化了搜索策略，更均匀地分配计算努力在整个树结构中，避免了传统深度优先搜索在早期优化一个子树而忽略另一个的问题。技术路线涉及设计一个能在任何中断点返回高质量树的算法，确保即使在计算时间受限时也能获得平衡且最优的决策树。具体实现关注于连续特征的处理，改进现有算法的搜索效率。",
      "result": "实验结果显示，所提方法在任意时间性能方面优于现有算法，具体表现为在任何中断点都能提供更高质量和更平衡的决策树。虽然摘要未明确说明具体性能指标（如准确率提升或计算时间减少），但基于结果概括，该方法显著改善了连续特征下决策树学习的实际应用性。与基线方法（如深度优先搜索）相比，本方法在中断时表现出更优的解质量。",
      "conclusion": "该研究的核心贡献是提出了一个任意时间决策树学习方法，有效解决了连续特征下最优决策树学习的计算瓶颈。学术价值在于将有限差异搜索应用于机器学习优化问题，提升算法鲁棒性和中断性能；实际应用价值在于扩展了决策树模型在实时或资源受限场景中的适用性。局限性可能包括处理更大规模数据时的计算成本，未来工作方向可探索更高效的优化策略或与其他机器学习技术的结合。",
      "tags": [
        "Decision Tree Learning",
        "Continuous Features",
        "Anytime Algorithms",
        "Limited Discrepancy Search",
        "Optimal Algorithms"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:21.331760Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14764",
    "title": "An XAI View on Explainable ASP: Methods, Systems, and Perspectives",
    "authors": [
      "Thomas Eiter",
      "Tobias Geibinger",
      "Zeynep G. Saribatur"
    ],
    "abstract": "Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14764.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14764",
    "published": "2026-01-21T08:37:33Z",
    "updated": "2026-01-21T08:37:33Z",
    "comment": "10 pages",
    "light_analysis": {
      "overview": "本文从XAI视角系统概述了解释性ASP的方法、系统和观点，并识别了现有研究的空白和未来方向。",
      "motivation": "ASP作为符号AI中的声明性推理方法，其基于规则的形式使其在解释性推理中具有天然优势，随着XAI的兴起，解释性变得日益重要。现有ASP解释方法和工具往往针对特定场景开发，未能全面覆盖用户在实际应用中遇到的多样化问题，导致解释效果不完整，因此需要一篇综合性综述来梳理现状并指出改进空间。",
      "method": "作为一篇综述论文，本文从XAI视角出发，通过文献回顾和分析，系统概述了ASP解释的不同类型及其与用户解释问题的关联。它采用了分类方法评估现有理论和工具的覆盖范围，关键创新在于整合了多个解释场景，但摘要未明确说明使用的具体数据集或模型架构。",
      "result": "论文通过分析发现，现有ASP解释方法在某些特定设置下有效，但整体覆盖存在不足，未能满足所有用户需求。虽然没有提供具体的准确率或效率指标，但识别了理论和技术上的空白，对比了不同方法的适用性，但摘要未明确说明与基线方法的详细对比数据。",
      "conclusion": "本文的主要贡献在于从XAI角度为ASP解释研究提供了系统性概述，识别了现有方法的局限性，并指出了未来研究方向，如扩展解释场景和优化工具。其学术价值在于搭建了综合框架，实际应用价值在于推动更具解释性的AI系统发展，未来工作应填补这些空白。",
      "tags": [
        "Answer Set Programming",
        "Explainable AI",
        "Symbolic AI",
        "Rule-based Formalism",
        "Literature Survey"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:25.234751Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14758",
    "title": "Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models",
    "authors": [
      "Injin Kong",
      "Hyoungjoon Lee",
      "Yohan Jo"
    ],
    "abstract": "Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic \"mechanism shift\" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14758.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14758",
    "published": "2026-01-21T08:26:51Z",
    "updated": "2026-01-21T08:26:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文揭示了自回归模型后训练为掩码扩散模型时的机制转变，证明这种变换根本性重组内部计算以支持非顺序全局规划。",
      "motivation": "后训练预训练自回归模型为掩码扩散模型是一种成本效益高的策略，旨在克服序列生成的局限性，但现有研究未探索内部算法变换，导致不确定后训练的模型是否获得真正的双向推理能力，而非仅仅重包装自回归启发式，这限制了非顺序生成方法的评估和优化，因此需要深入理解这种转变机制。",
      "method": "论文采用比较电路分析的方法，对比自回归模型及其对应的掩码扩散模型，分析结构和语义层面的变化。关键创新点在于通过电路识别任务依赖的转变，包括电路保留或放弃，以及处理层的重接，以探究内部计算的重组。摘要未明确说明具体数据集或模型架构细节。",
      "result": "分析结果显示机制转变依赖于任务的结构性质：对于局部因果依赖主导的任务，掩码扩散模型基本保留自回归电路；而在全局规划任务中，它们放弃初始化路径，重接为增加早期层处理。语义上，观察到从自回归模型的尖锐局部专业化向扩散模型的分布式集成过渡，摘要未提供具体性能数据，但与基线比较表明了内部计算的显著变化。",
      "conclusion": "研究结论表明扩散后训练不仅仅调整参数，而是根本性重组内部计算以支持全局规划，提供了深入理解模型变换的学术价值，并为优化后训练策略和提升非顺序生成能力奠定基础，未来工作可能包括更广泛的任务验证和应用扩展。",
      "tags": [
        "Autoregressive Models",
        "Masked Diffusion Models",
        "Circuit Analysis",
        "Post-training",
        "Global Planning"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:17.930936Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14757",
    "title": "ReinPath: A Multimodal Reinforcement Learning Approach for Pathology",
    "authors": [
      "Kangcheng Zhou",
      "Jun Jiang",
      "Qing Zhang",
      "Shuang Zheng",
      "Qingli Li",
      "Shugong Xu"
    ],
    "abstract": "Interpretability is significant in computational pathology, leading to the development of multimodal information integration from histopathological image and corresponding text data.However, existing multimodal methods have limited interpretability due to the lack of high-quality dataset that support explicit reasoning and inference and simple reasoning process.To address the above problems, we introduce a novel multimodal pathology large language model with strong reasoning capabilities.To improve the generation of accurate and contextually relevant textual descriptions, we design a semantic reward strategy integrated with group relative policy optimization.We construct a high-quality pathology visual question answering (VQA) dataset, specifically designed to support complex reasoning tasks.Comprehensive experiments conducted on this dataset demonstrate that our method outperforms state-of-the-art methods, even when trained with only 20% of the data.Our method also achieves comparable performance on downstream zero-shot image classification task compared with CLIP.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14757.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14757",
    "published": "2026-01-21T08:21:35Z",
    "updated": "2026-01-21T08:21:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出ReinPath，一种融合多模态强化学习的病理学大语言模型，通过语义奖励策略和高分质量视觉问答数据集，显著提升病理图像与文本融合的可解释性和推理能力。",
      "motivation": "在计算病理学领域，可解释性至关重要，因为它帮助整合组织病理学图像和对应文本的多模态信息。然而，现有多模态方法因缺乏支持显式推理的高质量数据集和推理过程简单而受限，这降低了模型的可靠性和诊断准确性。因此，开发具备强推理能力、能更好理解病理数据的模型成为迫切需求，以推动医疗AI在精准医疗中的应用。",
      "method": "本研究引入一个新颖的多模态病理大语言模型，具备强大的推理能力。核心方法结合了强化学习，设计了语义奖励策略并集成群体相对策略优化，以优化文本生成过程。同时，构建了一个专门用于复杂推理任务的高质量病理视觉问答数据集，该数据集支持多模态信息融合和精细推理，为模型训练提供基础。",
      "result": "实验结果表明，在构建的病理视觉问答数据集上，该方法即使仅使用20%的数据训练，仍优于当前最先进方法，显示出高效的学习能力。此外，在下游的零样本图像分类任务中，模型性能与CLIP相当，验证了其在多样任务中的泛化性和实用性。与基线方法的对比突出了其在准确性和效率上的改进。",
      "conclusion": "本研究的核心贡献在于开发了一个可解释性强的多模态病理学模型，通过结合强化学习增强推理能力。这为AI在病理学诊断辅助和医疗研究提供了新工具，提升了模型的可信度和应用价值。未来工作可能包括扩展数据集规模或进一步优化策略，以适应更复杂的临床场景。",
      "tags": [
        "Multimodal Learning",
        "Reinforcement Learning",
        "Large Language Model",
        "Visual Question Answering",
        "Pathology"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:06.172056Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14750",
    "title": "Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning",
    "authors": [
      "Yifan Wang",
      "Shiyu Li",
      "Peiming Li",
      "Xiaochen Yang",
      "Yang Tang",
      "Zheng Wei"
    ],
    "abstract": "Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzability of the latent reasoning chain. To address these challenges, we introduce Render-of-Thought (RoT), the first framework to reify the reasoning chain by rendering textual steps into images, making the latent rationale explicit and traceable. Specifically, we leverage the vision encoders of existing Vision Language Models (VLMs) as semantic anchors to align the vision embeddings with the textual space. This design ensures plug-and-play implementation without incurring additional pre-training overhead. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that our method achieves 3-4x token compression and substantial inference acceleration compared to explicit CoT. Furthermore, it maintains competitive performance against other methods, validating the feasibility of this paradigm. Our code is available at https://github.com/TencentBAC/RoT",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14750.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14750",
    "published": "2026-01-21T08:09:25Z",
    "updated": "2026-01-21T08:09:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "Render-of-Thought (RoT)框架首次通过将文本推理步骤渲染为图像，使潜在推理过程明确且可追踪。",
      "motivation": "本文旨在解决Chain-of-Thought (CoT) prompting在大型语言模型中的计算开销大和推理过程不透明问题。CoT虽然能显著提升模型的推理能力，但其冗长的文本步骤导致token开销巨大，增加了推理延迟和计算成本。此外，现有研究多侧重于最终结果的对齐，缺乏对中间推理步骤的有效监督，使得潜在推理链难以分析和跟踪，影响了推理的可解释性和实际应用效率。因此，开发一种既能压缩推理过程又能增强其透明度的方法显得尤为重要。",
      "method": "RoT框架的核心方法是通过将文本的Chain-of-Thought步骤渲染为图像来具体化推理链。具体技术路线是，利用现有Vision Language Models (VLMs)的视觉编码器作为语义锚点，对齐图像嵌入和文本空间，确保文本推理信息在视觉模态中准确表达。这种设计实现了即插即用，无需额外预训练，降低了实施开销。关键创新点在于将文本推理可视化，提高了推理链的显式性和可追踪性，同时保持了多模态语义的一致性。",
      "result": "在数学和逻辑推理的基准测试中，RoT方法取得了显著效果。与显式CoT相比，它实现了3到4倍的token压缩，大幅减少了token数量，从而加速了推理过程。实验数据显示，RoT在保持与其他方法竞争性性能的同时，有效降低了计算开销。例如，在推理任务中，该方法不仅提升了推理速度，还验证了将文本推理链渲染为图像范式的可行性，证明了其在实际应用中的高效性和潜力。",
      "conclusion": "本文的主要贡献是提出了Render-of-Thought框架，首次将文本推理链具体化为图像，增强了推理过程的显式性和可追踪性。这一研究不仅解决了CoT的计算开销和透明度问题，还为多模态推理和可解释AI提供了新方向。学术上，它推动了视觉语言模型在推理任务中的应用；实际上，可应用于教育、自动化系统等需要高效和透明推理的场景。未来工作可能包括扩展到更多任务类型和改进渲染技术，摘要未明确说明具体局限性。",
      "tags": [
        "Chain-of-Thought",
        "Vision Language Models",
        "Token Compression",
        "Visual Reasoning",
        "Multimodal Inference"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:49.734373Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14746",
    "title": "RefProtoFL: Communication-Efficient Federated Learning via External-Referenced Prototype Alignment",
    "authors": [
      "Hongyue Wu",
      "Hangyu Li",
      "Guodong Fan",
      "Haoran Zhu",
      "Shizhan Chen",
      "Zhiyong Feng"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training without sharing raw data in edge environments, but is constrained by limited communication bandwidth and heterogeneous client data distributions. Prototype-based FL mitigates this issue by exchanging class-wise feature prototypes instead of full model parameters; however, existing methods still suffer from suboptimal generalization under severe communication constraints. In this paper, we propose RefProtoFL, a communication-efficient FL framework that integrates External-Referenced Prototype Alignment (ERPA) for representation consistency with Adaptive Probabilistic Update Dropping (APUD) for communication efficiency. Specifically, we decompose the model into a private backbone and a lightweight shared adapter, and restrict federated communication to the adapter parameters only. To further reduce uplink cost, APUD performs magnitude-aware Top-K sparsification, transmitting only the most significant adapter updates for server-side aggregation. To address representation inconsistency across heterogeneous clients, ERPA leverages a small server-held public dataset to construct external reference prototypes that serve as shared semantic anchors. For classes covered by public data, clients directly align local representations to public-induced prototypes, whereas for uncovered classes, alignment relies on server-aggregated global reference prototypes via weighted averaging. Extensive experiments on standard benchmarks demonstrate that RefProtoFL attains higher classification accuracy than state-of-the-art prototype-based FL baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14746.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14746",
    "published": "2026-01-21T08:01:14Z",
    "updated": "2026-01-21T08:01:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "RefProtoFL是一种通信高效的联邦学习框架，通过外部参考原型对齐和自适应更新丢弃优化原型联邦学习。",
      "motivation": "联邦学习在边缘计算环境中面临通信带宽有限和客户端数据分布异构的挑战。现有基于原型的联邦学习方法虽通过交换类别特征原型减少通信开销，但在严格通信约束下仍存在泛化能力不足的问题。因此，需要更高效的通信策略和一致的表示对齐机制来提升联邦学习的实用性和性能，特别是在数据隐私保护与资源受限的场景中。",
      "method": "RefProtoFL框架将模型分解为私有骨干网络和轻量级共享适配器，仅通过适配器参数进行联邦通信以降低开销。采用自适应概率更新丢弃（APUD）技术，基于幅度感知的Top-K稀疏化，只传输最重要的适配器更新以减少上行链路成本。外部参考原型对齐（ERPA）利用服务器端小型公共数据集构建参考原型；对于公共数据覆盖的类别，客户端直接对齐本地表示到公共原型，否则通过加权平均使用服务器聚合的全局参考原型，确保表示一致性。",
      "result": "在标准基准测试中进行大量实验，结果显示RefProtoFL比现有最先进的基于原型的联邦学习基线有更高的分类准确率。摘要未明确说明具体准确率提升数值，但实验验证了该方法在通信效率和模型性能上的优势，与基线相比，在处理异构数据和通信限制时表现出更好的泛化能力。",
      "conclusion": "RefProtoFL的主要贡献在于提出了一种结合外部参考原型对齐和自适应更新丢弃的通信高效联邦学习框架，通过优化原型对齐和通信策略，提高了在边缘环境下的模型泛化和应用价值。该研究为联邦学习领域提供了新的研究方向，具有实际应用潜力，未来工作可能包括扩展方法到更复杂任务或优化部署性能。",
      "tags": [
        "Federated Learning",
        "Prototype Alignment",
        "Adaptive Update Dropping",
        "Communication Optimization"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:43.642215Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14742",
    "title": "SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection",
    "authors": [
      "Ami Pandat",
      "Kanyala Muvva",
      "Punna Rajasekhar",
      "Gopika Vinod",
      "Rohit Shukla"
    ],
    "abstract": "Reliable drone detection is challenging due to limited annotated real-world data, large appearance variability, and the presence of visually similar distractors such as birds. To address these challenges, this paper introduces SimD3, a large-scale high-fidelity synthetic dataset designed for robust drone detection in complex aerial environments. Unlike existing synthetic drone datasets, SimD3 explicitly models drones with heterogeneous payloads, incorporates multiple bird species as realistic distractors, and leverages diverse Unreal Engine 5 environments with controlled weather, lighting, and flight trajectories captured using a 360 six-camera rig. Using SimD3, we conduct an extensive experimental evaluation within the YOLOv5 detection framework, including an attention-enhanced variant termed Yolov5m+C3b, where standard bottleneck-based C3 blocks are replaced with C3b modules. Models are evaluated on synthetic data, combined synthetic and real data, and multiple unseen real-world benchmarks to assess robustness and generalization. Experimental results show that SimD3 provides effective supervision for small-object drone detection and that Yolov5m+C3b consistently outperforms the baseline across in-domain and cross-dataset evaluations. These findings highlight the utility of SimD3 for training and benchmarking robust drone detection models under diverse and challenging conditions.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14742.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14742",
    "published": "2026-01-21T07:56:25Z",
    "updated": "2026-01-21T07:56:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出SimD3合成数据集和注意力增强的Yolov5m+C3b模型，以提升复杂空中环境中无人机检测的鲁棒性。",
      "motivation": "可靠的无人机检测在安全监控和空域管理等应用中至关重要，但面临重大挑战：真实世界标注数据有限，导致训练不足；无人机外观变化大，增加了检测难度；且存在视觉相似干扰物如鸟类，容易引发误检。现有方法依赖于有限的数据或简单合成数据集，未能充分建模这些复杂因素，导致模型在真实场景中的泛化能力弱。因此，需要开发高质量合成数据来模拟这些挑战，以训练更鲁棒的检测模型，解决现实问题。",
      "method": "本研究提出SimD3，一个大规模高保真合成数据集，专为鲁棒无人机检测设计。数据集使用Unreal Engine 5创建多样化环境，控制天气、光照条件，并通过360度六相机捕捉无人机飞行轨迹，模拟真实空中场景。关键创新点包括：显式建模带有异质有效载荷的无人机，增强现实性；集成多种鸟类作为干扰物，模拟真实视觉挑战。在技术路线上，基于YOLOv5检测框架，引入注意力增强变体Yolov5m+C3b，将标准瓶颈C3块替换为C3b模块，以提高特征提取能力，实验评估涵盖合成数据、合成与真实数据混合以及多个未见过真实世界基准。",
      "result": "实验结果表明，SimD3数据集有效监督小物体无人机的检测任务，提供高质量训练数据。在YOLOv5框架下，Yolov5m+C3b模型在领域内评估和跨数据集评估中均一致优于基线方法，具体表现为检测准确率和鲁棒性的显著提升。评估包括合成数据测试、合成与真实数据结合以及多个未见过的真实世界基准，验证了模型在复杂条件下的泛化能力。例如，在应对天气变化和干扰物时，模型表现出更强稳定性，但摘要未提供具体数字。这些结果强调了方法在挑战性环境中的有效性。",
      "conclusion": "本研究的主要贡献是开发了SimD3合成数据集和注意力增强的检测模型，显著提高了无人机检测的鲁棒性和泛化能力。学术上，工作强调了合成数据在弥补真实数据不足方面的价值，推动了计算机视觉中目标检测技术的发展；实际上，SimD3可用于训练和基准测试无人机检测模型，适应各种恶劣条件，如不同天气和光照。潜在局限性包括需要更多真实场景验证，未来工作可扩展数据集到更广场景或优化模型以应对极端干扰。",
      "tags": [
        "Synthetic Dataset",
        "Drone Detection",
        "Object Detection",
        "Attention Module",
        "Unreal Engine 5"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:52.144688Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14741",
    "title": "Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution",
    "authors": [
      "Chongbin Yi",
      "Yuxin Liang",
      "Ziqi Zhou",
      "Peng Yang"
    ],
    "abstract": "Artificial Intelligence-Generated Content (AIGC) has made significant strides, with high-resolution text-to-image (T2I) generation becoming increasingly critical for improving users' Quality of Experience (QoE). Although resource-constrained edge computing adequately supports fast low-resolution T2I generations, achieving high-resolution output still faces the challenge of ensuring image fidelity at the cost of latency. To address this, we first investigate the performance of super-resolution (SR) methods for image enhancement, confirming a fundamental trade-off that lightweight learning-based SR struggles to recover fine details, while diffusion-based SR achieves higher fidelity at a substantial computational cost. Motivated by these observations, we propose an end-edge collaborative generation-enhancement framework. Upon receiving a T2I generation task, the system first generates a low-resolution image based on adaptively selected denoising steps and super-resolution scales at the edge side, which is then partitioned into patches and processed by a region-aware hybrid SR policy. This policy applies a diffusion-based SR model to foreground patches for detail recovery and a lightweight learning-based SR model to background patches for efficient upscaling, ultimately stitching the enhanced ones into the high-resolution image. Experiments show that our system reduces service latency by 33% compared with baselines while maintaining competitive image quality.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14741.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14741",
    "published": "2026-01-21T07:55:37Z",
    "updated": "2026-01-21T07:55:37Z",
    "comment": "Accpeted by ICC 2026",
    "light_analysis": {
      "overview": "本文提出一种端边协作的混合超分辨率框架，通过优化文本到图像生成过程来降低延迟并保持图像质量。",
      "motivation": "该研究旨在解决高分辨率文本到图像生成中延迟与图像保真度之间的平衡问题。随着人工智能生成内容的进展，提升用户体验质量变得至关重要，但资源受限的边缘计算虽然支持快速生成低分辨率图像，高分辨率输出仍面临保真度与延迟的挑战。现有超分辨率方法存在权衡：轻量级学习方法难以恢复精细细节，而扩散模型方法虽保真度高，但计算成本大，这凸显了开发更高效解决方案的必要性。",
      "method": "论文提出一个端边协作的生成增强框架。系统在接收到文本到图像生成任务后，首先在边缘侧基于自适应选择的去噪步骤和超分辨率缩放生成低分辨率图像，然后将其分区成块。核心创新在于采用区域感知混合超分辨率策略：对前景块应用扩散模型超分辨率以恢复细节，对背景块使用轻量级学习模型超分辨率进行高效放大，最终将增强后的块拼接成高分辨率图像。这种方法结合了不同SR技术的优势，优化了资源分配和计算效率。",
      "result": "实验结果显示，所提出的系统相比基线方法减少了33%的服务延迟，同时在图像质量方面保持了竞争性性能。具体来说，通过区域感知混合超分辨率策略，系统在降低计算开销的同时，确保输出图像的高保真度，验证了该框架在平衡效率和保真度方面的有效性。摘要未提供详细性能指标，但强调了与基线的显著改进。",
      "conclusion": "本研究的主要贡献是开发了一个端边协作的混合超分辨率框架，有效解决了高分辨率文本到图像生成的延迟问题，同时不牺牲图像质量。这具有重要的学术价值，为人工智能生成内容领域提供了新的优化思路，并可在实际应用中提升用户体验。局限性可能包括在更复杂场景中的适应性，未来工作可扩展模型优化或探索更多应用领域。",
      "tags": [
        "Text-to-Image Generation",
        "Super-Resolution",
        "Diffusion Models",
        "Edge Computing",
        "Hybrid Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:39.775928Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14738",
    "title": "Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption",
    "authors": [
      "Liqin Wang",
      "Qianyue Hu",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "The rapid evolution of diffusion models has democratized face swapping but also raises concerns about privacy and identity security. Existing proactive defenses, often adapted from image editing attacks, prove ineffective in this context. We attribute this failure to an oversight of the structural resilience and the unique static conditional guidance mechanism inherent in face swapping systems. To address this, we propose VoidFace, a systemic defense method that views face swapping as a coupled identity pathway. By injecting perturbations at critical bottlenecks, VoidFace induces cascading disruption throughout the pipeline. Specifically, we first introduce localization disruption and identity erasure to degrade physical regression and semantic embeddings, thereby impairing the accurate modeling of the source face. We then intervene in the generative domain by decoupling attention mechanisms to sever identity injection, and corrupting intermediate diffusion features to prevent the reconstruction of source identity. To ensure visual imperceptibility, we perform adversarial search in the latent manifold, guided by a perceptual adaptive strategy to balance attack potency with image quality. Extensive experiments show that VoidFace outperforms existing defenses across various diffusion-based swapping models, while producing adversarial faces with superior visual quality.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14738.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14738",
    "published": "2026-01-21T07:52:56Z",
    "updated": "2026-01-21T07:52:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出VoidFace方法，通过级联路径破坏有效防御基于扩散模型的面部交换攻击，保护面部身份安全。",
      "motivation": "扩散模型的快速发展使得面部交换技术普及，但威胁个人隐私和身份安全。现有防御方法多从图像编辑攻击改编，在面部交换场景中无效，因为它们忽视了系统结构弹性和独特的静态条件指导机制。因此，迫切需要专门针对扩散模型面部交换的有效防御方案，以应对日益增长的安全风险。",
      "method": "VoidFace将面部交换视为耦合身份路径，通过在关键瓶颈注入扰动实现级联破坏。技术包括：定位破坏和身份擦除以降低物理回归和语义嵌入的准确性；在生成域干预，如解耦注意力机制以切断身份注入，以及破坏中间扩散特征以防止源身份重建。为确保视觉不可察觉性，在潜在流形中进行对抗搜索，采用感知自适应策略平衡攻击力和图像质量。",
      "result": "广泛实验表明，VoidFace在各种基于扩散的交换模型中优于现有防御方法，同时生成的对抗面部图像具有优越视觉质量。这验证了其在保护身份安全的同时，保持图像自然性的能力，具体表现为防御效果显著提升和视觉质量改善，但摘要未明确具体数据指标。",
      "conclusion": "本研究提出VoidFace作为系统性防御方法，通过级联路径破坏有效应对基于扩散的面部交换威胁。研究解决了现有防御的不足，强调了考虑系统结构的重要性，为隐私保护和生成模型安全领域提供新思路。未来工作可优化对抗策略并扩展到其他生成攻击。",
      "tags": [
        "Diffusion Models",
        "Face Swapping",
        "Adversarial Defense",
        "Attention Mechanism",
        "Latent Manifold Search"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:01.565042Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14732",
    "title": "DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling",
    "authors": [
      "Jing Lan",
      "Hexiao Ding",
      "Hongzhao Chen",
      "Yufeng Jiang",
      "Nga-Chun Ng",
      "Gwing Kei Yip",
      "Gerald W. Y. Cheng",
      "Yunlin Mao",
      "Jing Cai",
      "Liang-ting Lin",
      "Jung Sun Yoo"
    ],
    "abstract": "AI models for drug discovery and chemical literature mining must interpret molecular images and generate outputs consistent with 3D geometry and stereochemistry. Most molecular language models rely on strings or graphs, while vision-language models often miss stereochemical details and struggle to map continuous 3D structures into discrete tokens. We propose DeepMoLM: Deep Molecular Language M odeling, a dual-view framework that grounds high-resolution molecular images in geometric invariants derived from molecular conformations. DeepMoLM preserves high-frequency evidence from 1024 $\\times$ 1024 inputs, encodes conformer neighborhoods as discrete Extended 3-Dimensional Fingerprints, and fuses visual and geometric streams with cross-attention, enabling physically grounded generation without atom coordinates. DeepMoLM improves PubChem captioning with a 12.3% relative METEOR gain over the strongest generalist baseline while staying competitive with specialist methods. It produces valid numeric outputs for all property queries and attains MAE 13.64 g/mol on Molecular Weight and 37.89 on Complexity in the specialist setting. On ChEBI-20 description generation from images, it exceeds generalist baselines and matches state-of- the-art vision-language models. Code is available at https://github.com/1anj/DeepMoLM.",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14732.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14732",
    "published": "2026-01-21T07:41:59Z",
    "updated": "2026-01-21T07:41:59Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "DeepMoLM通过双视图框架结合视觉和几何信息，显著提升分子-文本建模的准确性和立体化学一致性。",
      "motivation": "AI模型在药物发现和化学文献挖掘中需要处理分子图像并生成与3D几何和立体化学一致的输出。现有方法如基于字符串或图的分子语言模型，以及视觉-语言模型，常忽略立体化学细节，且难以将连续3D结构映射为离散令牌，导致化学应用中生成结果不准确。这些不足限制了模型在化学领域的有效应用，促使开发新方法来融合多源信息。",
      "method": "论文提出DeepMoLM，一个双视图框架，将高分辨率（1024×1024）分子图像与基于分子构象的几何不变量相结合。核心创新包括编码构象邻域为离散扩展3D指纹，并通过交叉注意力机制融合视觉和几何流，实现无需原子坐标的物理基础生成。该方法保留高频证据，有效结合了视觉特征和几何结构，增强了模型对分子立体化学的理解。",
      "result": "DeepMoLM在PubChem字幕任务中相对最强一般基线METEOR提升12.3%，与专家方法竞争。它为所有属性查询产生有效数值输出，分子重量MAE为13.64 g/mol，复杂性MAE为37.89。在ChEBI-20图像描述生成上，超越一般基线，性能匹配最先进的视觉-语言模型，验证了其在多任务中的有效性。",
      "conclusion": "DeepMoLM成功融合视觉和几何信息，解决了现有方法处理分子立体化学和3D结构的不足，提高了分子-文本建模性能。该研究对化学AI领域有重要价值，特别是药物发现和化学文献分析。未来工作可进一步优化模型或扩展到更多化学任务，以增强其应用范围。",
      "tags": [
        "Molecular Language Modeling",
        "Vision-Language Models",
        "3D Fingerprints",
        "Cross-Attention",
        "Stereochemistry"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:50.171177Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14730",
    "title": "FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks",
    "authors": [
      "Bizu Feng",
      "Zhimu Yang",
      "Shaode Yu",
      "Zixin Hu"
    ],
    "abstract": "Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14730.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14730",
    "published": "2026-01-21T07:39:42Z",
    "updated": "2026-01-21T07:39:42Z",
    "comment": "8 pages, 4 figures, Preprint",
    "light_analysis": {
      "overview": "FSX提出了一种新颖的混合框架，通过流敏感分析和合作博弈增强图神经网络的结构解释能力。",
      "motivation": "图神经网络（GNNs）在多个领域广泛应用，但理解其预测原因仍具挑战性，这限制了模型的可信度和部署。现有可解释性方法存在显著权衡：基于梯度的方法计算高效，但往往忽略图结构中的交互作用；而博弈论技术虽能捕获交互，却以高计算开销和可能偏离模型真实推理路径为代价。这种不足使得开发一种既高效又能准确反映结构逻辑的解释方法变得至关重要。",
      "method": "FSX框架协同结合模型内部消息流和外部图数据的合作博弈方法。首先，通过流敏感分析识别关键消息流：在单次前向传播中模拟局部节点扰动，测量消息流强度的变化。接着，将这些流投影到输入图上定义紧凑、语义有意义的子图。在每个子图中，进行流感知合作博弈，通过类似Shapley的值评估节点贡献，该值综合考虑节点特征重要性和它们在维持或破坏关键流中的作用，无需依赖特定数据集或模型架构。",
      "result": "在多个数据集和GNN架构上的广泛评估显示，FSX实现了优越的解释保真度，同时显著减少了运行时间。与基线方法相比，它在捕获结构交互方面更准确，克服了传统梯度法忽略交互和博弈论方法计算开销大的局限性。摘要未提供具体性能指标（如准确率提升百分比），但实验结果证实了其有效性，例如揭示了重要子结构如何通过调控关键内部计算路径的稳定性来施加影响。",
      "conclusion": "该论文的主要贡献是提出了FSX框架，它通过融合流敏感分析和合作博弈，提高了GNNs的可解释性，提供对模型预测结构逻辑的新见解。这项研究具有重要学术价值，为理解GNNs内部工作机制开辟了新途径，并在实际应用中增强了模型透明度和可信度。未来工作可能包括扩展到更复杂图结构或与其他解释技术结合，尽管摘要未明确说明具体局限性。",
      "tags": [
        "Graph Neural Networks",
        "Explainability",
        "Message Flow Sensitivity",
        "Cooperative Game Theory",
        "Shapley Value"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:10.217254Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14724",
    "title": "HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding",
    "authors": [
      "Haowei Zhang",
      "Shudong Yang",
      "Jinlan Fu",
      "See-Kiong Ng",
      "Xipeng Qiu"
    ],
    "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14724.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14724",
    "published": "2026-01-21T07:26:15Z",
    "updated": "2026-01-21T07:26:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "HERMES 提出一个无需训练的架构，将 KV Cache 概念化为分层内存框架，以实现高效且准确的流式视频理解。",
      "motivation": "多模态大语言模型在离线视频理解方面已取得显著进展，但将其能力扩展到流式视频输入时仍面临重大挑战。现有模型难以同时维持稳定的理解性能、实时响应和低 GPU 内存开销，这限制了实时应用（如监控和交互系统）的发展。流式视频处理的重要性日益凸显，但传统方法在平衡效率与准确性方面存在不足，导致实时交互和资源利用成为瓶颈，因此需要创新解决方案以应对这些综合需求。",
      "method": "HERMES 是一种无需训练的架构，基于对注意力机制的机制性研究，将 KV Cache 概念化为分层内存框架，从而封装视频信息在不同粒度（如时间和空间层次）。在推理阶段，该方法重用紧凑的 KV Cache，使在资源受限环境下高效处理流式视频成为可能。关键创新包括无需对用户查询进行额外计算，直接保证实时响应；技术特色在于利用分层内存优化信息存储和检索，提升流式视频理解的效率与准确性。",
      "result": "主要实验结果显示，HERMES 实现了比先前最先进方法快 10 倍的 TTFT（首次响应时间）。在将视频标记减少高达 68%（相比均匀采样）的情况下，HERMES 在所有基准测试中仍达到同等或更优的准确性，与基线方法相比，在流式数据集上获得高达 11.4% 的性能增益。这表明该方法在保持低计算开销的同时，显著提升了流式视频理解的效率和效果，验证了其在实际应用中的可行性。",
      "conclusion": "HERMES 通过将 KV Cache 用作分层内存，有效解决了流式视频理解中的性能、响应速度和内存开销挑战。研究的主要贡献在于提出一种新颖的无训练架构，提升了实时视频处理的效率和准确性。学术价值体现在为多模态大语言模型在流式场景下的应用提供了新思路；实际应用价值包括支持监控、交互系统等实时视频流处理。局限性方面，摘要未明确说明未来工作方向，但潜在方向可能涉及扩展应用到其他模态或优化内存管理策略。",
      "tags": [
        "Multimodal Large Language Models",
        "KV Cache",
        "Hierarchical Memory",
        "Streaming Video Understanding",
        "Attention Mechanism"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:42.837863Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14722",
    "title": "Typhoon OCR: Open Vision-Language Model For Thai Document Extraction",
    "authors": [
      "Surapon Nonesung",
      "Natapong Nitarach",
      "Teetouch Jaknamon",
      "Pittawat Taveekitworachai",
      "Kunat Pipatanakul"
    ],
    "abstract": "Document extraction is a core component of digital workflows, yet existing vision-language models (VLMs) predominantly favor high-resource languages. Thai presents additional challenges due to script complexity from non-latin letters, the absence of explicit word boundaries, and the prevalence of highly unstructured real-world documents, limiting the effectiveness of current open-source models. This paper presents Typhoon OCR, an open VLM for document extraction tailored for Thai and English. The model is fine-tuned from vision-language backbones using a Thai-focused training dataset. The dataset is developed using a multi-stage data construction pipeline that combines traditional OCR, VLM-based restructuring, and curated synthetic data. Typhoon OCR is a unified framework capable of text transcription, layout reconstruction, and document-level structural consistency. The latest iteration of our model, Typhoon OCR V1.5, is a compact and inference-efficient model designed to reduce reliance on metadata and simplify deployment. Comprehensive evaluations across diverse Thai document categories, including financial reports, government forms, books, infographics, and handwritten documents, show that Typhoon OCR achieves performance comparable to or exceeding larger frontier proprietary models, despite substantially lower computational cost. The results demonstrate that open vision-language OCR models can achieve accurate text extraction and layout reconstruction for Thai documents, reaching performance comparable to proprietary systems while remaining lightweight and deployable.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14722.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14722",
    "published": "2026-01-21T07:24:32Z",
    "updated": "2026-01-21T07:24:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Typhoon OCR，一个针对泰语的开放视觉-语言模型，专为文档提取设计，实现高效文本转录和布局重构。",
      "motivation": "文档提取是数字工作流程的核心，但现有视觉-语言模型主要支持高资源语言，泰语由于非拉丁字母的复杂脚本、缺乏明确单词边界以及现实世界中高度非结构化文档的普遍存在，导致传统开源模型提取效果有限。这限制了泰语地区的文档自动化处理能力，因此需要开发专门针对低资源语言的解决方案以提升数字化效率。",
      "method": "Typhoon OCR 是从视觉-语言主干网络微调而来的开放模型，使用泰语聚焦的训练数据集。数据集通过多阶段管道构建，结合传统OCR技术、基于VLM的重构方法和精心生成的合成数据。模型采用统一框架，支持文本转录、布局重构和文档级结构一致性维护，最新版本Typhoon OCR V1.5设计为紧凑且推理高效，减少对元数据的依赖以简化部署。",
      "result": "在多种泰语文档类别（包括财务报告、政府表格、书籍、信息图表和手写文档）上的评估显示，Typhoon OCR 在文本提取和布局重构方面性能与较大前沿专有模型相当或更优，同时计算成本显著更低。这表明模型在保持轻量级的同时实现了高准确率，无需依赖昂贵资源。",
      "conclusion": "该研究证明了开放视觉-语言OCR模型可以高效处理泰语文档提取，达到与专有系统相当的性能且易于部署，为低资源语言文档自动化提供了可行路径，具有重要学术和实际应用价值。未来工作可能包括扩展到其他语言或进一步优化模型效率，但摘要未明确说明具体局限性。",
      "tags": [
        "Vision-Language Model",
        "Document Extraction",
        "Optical Character Recognition (OCR)",
        "Thai Language Processing",
        "Layout Reconstruction"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:09.333634Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14718",
    "title": "Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation",
    "authors": [
      "Yiyang Fu",
      "Hui Li",
      "Wangyu Wu"
    ],
    "abstract": "Weakly Supervised Semantic Segmentation (WSSS), which relies only on image-level labels, has attracted significant attention for its cost-effectiveness and scalability. Existing methods mainly enhance inter-class distinctions and employ data augmentation to mitigate semantic ambiguity and reduce spurious activations. However, they often neglect the complex contextual dependencies among image patches, resulting in incomplete local representations and limited segmentation accuracy. To address these issues, we propose the Context Patch Fusion with Class Token Enhancement (CPF-CTE) framework, which exploits contextual relations among patches to enrich feature representations and improve segmentation. At its core, the Contextual-Fusion Bidirectional Long Short-Term Memory (CF-BiLSTM) module captures spatial dependencies between patches and enables bidirectional information flow, yielding a more comprehensive understanding of spatial correlations. This strengthens feature learning and segmentation robustness. Moreover, we introduce learnable class tokens that dynamically encode and refine class-specific semantics, enhancing discriminative capability. By effectively integrating spatial and semantic cues, CPF-CTE produces richer and more accurate representations of image content. Extensive experiments on PASCAL VOC 2012 and MS COCO 2014 validate that CPF-CTE consistently surpasses prior WSSS methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14718.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14718",
    "published": "2026-01-21T07:12:23Z",
    "updated": "2026-01-21T07:12:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出CPF-CTE框架，通过上下文块融合和类令牌增强来提升弱监督语义分割的准确性和鲁棒性。",
      "motivation": "弱监督语义分割仅依赖图像级标签，具有成本效益和可扩展性，吸引了广泛关注。现有方法主要聚焦于增强类间区分和采用数据增强来缓解语义模糊和减少虚假激活，但常忽视图像块之间的复杂上下文依赖关系，导致局部表示不完整和分割准确性受限。因此，本研究旨在解决这一问题，通过利用上下文关系来丰富特征表示，提高分割性能，填补现有方法的不足。",
      "method": "论文提出Context Patch Fusion with Class Token Enhancement (CPF-CTE)框架，核心创新包括Contextual-Fusion Bidirectional LSTM (CF-BiLSTM)模块，该模块捕获图像块之间的空间依赖并实现双向信息流，从而增强对空间相关性的综合理解，提高特征学习和分割鲁棒性。此外，引入可学习的类令牌，动态编码和细化类特定语义，增强判别能力。通过整合空间和语义线索，框架生成更丰富和准确的图像内容表示，适用于弱监督语义分割任务。",
      "result": "在PASCAL VOC 2012和MS COCO 2014数据集上的广泛实验验证表明，CPF-CTE框架一致地超越了先前的弱监督语义分割方法。摘要未明确说明具体性能指标如准确率提升，但基于现有信息，可以推断出该框架在标准评估中表现出优越性，有效提高了分割准确性，并与基线方法形成对比。",
      "conclusion": "CPF-CTE框架的主要贡献在于通过上下文块融合和类令牌增强，解决了弱监督语义分割中忽略上下文依赖的问题，提升了特征表示和分割准确性。该研究具有重要学术价值，推动了弱监督学习领域的发展，并具有实际应用潜力，例如降低标注成本。未来工作方向可能包括扩展到更大规模数据集或进一步优化模块效率以提升实用性。",
      "tags": [
        "Weakly Supervised Semantic Segmentation",
        "Bidirectional LSTM",
        "Learnable Class Tokens",
        "Contextual Fusion",
        "Image-level Labels"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:30.298977Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14716",
    "title": "PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning",
    "authors": [
      "Yao Lu",
      "Dengdong Fan",
      "Jianzheng Nie",
      "Fan Xu",
      "Jie Chen",
      "Bin Zhou",
      "Yonghong Tian"
    ],
    "abstract": "We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14716.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14716",
    "published": "2026-01-21T07:11:40Z",
    "updated": "2026-01-21T07:11:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出PCL-Reasoner-V1.5模型，通过离线强化学习方法提升大型语言模型的数学推理能力。",
      "motivation": "该研究动机在于解决数学推理任务中大型语言模型训练不稳定的问题。现有方法如在线强化学习（例如GRPO）可能存在效率低下和稳定性不足的挑战，限制了模型性能的进一步提升。本研究探索离线强化学习作为一种更稳健的训练范式，旨在提高训练效率和稳定性，从而增强模型在复杂推理任务中的表现。摘要未明确说明更多背景细节，但基于常见AI挑战推断。",
      "method": "研究方法基于Qwen2.5-32B大型语言模型，拥有320亿参数。首先进行监督微调（SFT），然后应用提出的离线强化学习（RL）方法进行精炼。核心创新是离线RL算法，它利用离线数据提供更稳定的训练过程和更高的效率，优于标准在线RL方法如GRPO。实验在华为昇腾910C NPUs上执行，但具体数据集和模型架构的详细信息摘要未明确说明。",
      "result": "主要实验结果显示，PCL-Reasoner-V1.5在基于Qwen2.5-32B后训练的模型中达到最先进性能。具体地，在AIME 2024数据集上获得平均准确率90.9%，在AIME 2025上为85.6%。这些结果验证了离线RL方法在提升数学推理任务中的有效性，与基线方法相比表现出显著改进。摘要未提供与具体基线的详细对比数据。",
      "conclusion": "本研究的主要贡献是提出了基于离线强化学习的大型语言模型PCL-Reasoner-V1.5，用于数学推理。结论表明离线RL方法是一个稳定且高效的训练范式，能够显著提升LLM的推理能力。工作不仅展示了在AIME数据集上的优异性能，还为未来RL在LLM中的应用提供了新方向。潜在的局限性可能包括对其他任务的泛化能力，未来工作可扩展到更多推理领域。摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Offline Reinforcement Learning",
        "Supervised Fine-Tuning",
        "Mathematical Reasoning"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:09.547720Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14711",
    "title": "DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs",
    "authors": [
      "Mingxuan Song",
      "Yusen Huo",
      "Bohan Zhou",
      "Shenglin Yin",
      "Zhen Xiao",
      "Jieyi Long",
      "Zhilin Zhang",
      "Chuan Yu"
    ],
    "abstract": "Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14711.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14711",
    "published": "2026-01-21T06:58:44Z",
    "updated": "2026-01-21T06:58:44Z",
    "comment": "Accepted at The ACM Web Conference (WWW) 2026",
    "light_analysis": {
      "overview": "论文提出DARA框架，通过结合大语言模型的上下文学习和强化学习微调，优化在线广告的少样本预算分配问题。",
      "motivation": "在线广告中，在预算约束下优化广告主获胜印象的累积价值是一个复杂挑战，尤其当广告主有个性化目标但历史数据有限时，形成少样本场景，传统强化学习方法在此场景下表现不佳。大语言模型虽具备上下文学习能力，能泛化有限数据，但缺乏数值精度，无法支持细粒度优化，限制了其在AI生成竞价任务中的应用，因此亟需解决这一精度不足问题。",
      "method": "论文提出GRPO-Adaptive作为高效的大语言模型后训练策略，通过动态更新训练中的参考策略，增强模型推理和数值精度。在此基础上，构建DARA双阶段框架：第一阶段为少样本推理器，利用上下文提示生成初始预算分配计划；第二阶段为细粒度优化器，通过反馈驱动推理优化计划，将大语言模型的上下文学习优势与AI生成竞价任务所需的精确适应性相结合，实现决策过程分解。",
      "result": "在真实世界和合成数据环境中的广泛实验显示，DARA方法在预算约束下的累积广告主价值方面一致优于现有基线。摘要未明确说明具体的性能指标提升数据，如准确率或效率改进的百分比，但强调了该方法在多个数据集上的优越表现，表明其能有效克服传统方法的局限性。",
      "conclusion": "DARA框架的主要贡献是创新性地结合大语言模型的上下文学习和强化学习微调，解决少样本预算分配问题，提升了在线广告中的决策效率。该研究具有学术价值，推动了少样本决策在广告领域的应用，并可能扩展到其他资源分配场景；局限性或未来工作摘要未明确说明，但可推断需要进一步探索在不同数据集和环境中的泛化能力。",
      "tags": [
        "Few-shot Learning",
        "In-Context Learning",
        "Reinforcement Learning",
        "Large Language Models",
        "Budget Allocation"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:37.972999Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14710",
    "title": "Case-Guided Sequential Assay Planning in Drug Discovery",
    "authors": [
      "Tianchi Chen",
      "Jan Bima",
      "Sean L. Wu",
      "Otto Ritter",
      "Bingjia Yang",
      "Xiang Yu"
    ],
    "abstract": "Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14710.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14710",
    "published": "2026-01-21T06:58:01Z",
    "updated": "2026-01-21T06:58:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Implicit Bayesian Markov Decision Process (IBMDP)框架，通过案例引导的隐式模型和贝叶斯规划，在无模拟器设置下优化药物发现中的序列实验测序，显著提升资源效率。",
      "motivation": "药物发现中的实验测序优化是一个高风险的规划问题，面临严重不确定性和资源约束。标准强化学习方法需要环境模拟器或转移数据，但实际中往往缺乏这些，只能依赖静态历史数据库，导致现有方法难以应用。因此，开发一种在无模拟器环境下进行有效规划的方法至关重要，以解决资源分配和决策置信度问题。",
      "method": "IBMDP是一种基于模型的强化学习框架，专为无模拟器设置设计。它通过相似历史结果构建非参数信念分布，形成案例引导的隐式转移动态模型，结合贝叶斯信念更新以累积证据，并采用集合蒙特卡洛树搜索规划来生成稳定策略，平衡信息增益和资源效率。关键创新在于直接利用历史数据建模不确定性，无需外部模拟器。",
      "result": "在真实世界的中枢神经系统药物发现任务中，IBMDP将资源消耗减少了高达92%，同时维持决策置信度。在合成环境中，通过可计算最优政策的基准测试，IBMDP与最优政策的对齐度显著高于使用相同相似性模型的确定性值迭代方法。这些结果验证了IBMDP在资源效率和决策质量上的优越性。",
      "conclusion": "论文的主要贡献是提出IBMDP框架，为数据丰富但模拟器缺乏的序列实验设计提供了实用解决方案，扩展了强化学习在无模拟器环境下的应用。该研究具有重要实际价值，如优化药物发现流程，未来工作可能包括应用于其他领域或改进模型处理更复杂不确定性。",
      "tags": [
        "Implicit Bayesian Markov Decision Process",
        "Reinforcement Learning",
        "Monte Carlo Tree Search",
        "Bayesian Belief Update",
        "Nonparametric Modeling"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:10.611227Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14706",
    "title": "LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval",
    "authors": [
      "Chao Gao",
      "Siqiao Xue",
      "Yimin Peng",
      "Jiwen Fu",
      "Tingyi Gu",
      "Shanshan Li",
      "Fan Zhou"
    ],
    "abstract": "In this paper, we present LookBench (We use the term \"look\" to reflect retrieval that mirrors how people shop -- finding the exact item, a close substitute, or a visually consistent alternative.), a live, holistic and challenging benchmark for fashion image retrieval in real e-commerce settings. LookBench includes both recent product images sourced from live websites and AI-generated fashion images, reflecting contemporary trends and use cases. Each test sample is time-stamped and we intend to update the benchmark periodically, enabling contamination-aware evaluation aligned with declared training cutoffs. Grounded in our fine-grained attribute taxonomy, LookBench covers single-item and outfit-level retrieval across. Our experiments reveal that LookBench poses a significant challenge on strong baselines, with many models achieving below $60\\%$ Recall@1. Our proprietary model achieves the best performance on LookBench, and we release an open-source counterpart that ranks second, with both models attaining state-of-the-art results on legacy Fashion200K evaluations. LookBench is designed to be updated semi-annually with new test samples and progressively harder task variants, providing a durable measure of progress. We publicly release our leaderboard, dataset, evaluation code, and trained models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14706.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14706",
    "published": "2026-01-21T06:50:23Z",
    "updated": "2026-01-21T06:50:23Z",
    "comment": "The first two authors contributed equally to this work. Project site: https://serendipityoneinc.github.io/look-bench-page/",
    "light_analysis": {
      "overview": "LookBench是一个实时、全面和开放的时尚图像检索基准测试，结合了真实产品图像和AI生成图像，并通过定期更新确保评估的时效性。",
      "motivation": "研究动机在于解决时尚图像检索在真实电子商务环境中的评估挑战。现有基准测试如Fashion200K往往基于静态数据集，无法适应快速变化的时尚趋势，导致模型评估结果与实际应用脱节。LookBench旨在提供一个更全面、实时的基准，通过整合近期产品图像和AI生成图像，并引入时间戳更新机制，以更好地模拟实际购物场景，解决数据过时和评估不准确的问题。",
      "method": "研究方法包括构建LookBench基准数据集，该数据集结合了从实时电子商务网站采集的近期产品图像和AI生成的时尚图像，以反映当代趋势和用例。基于细粒度属性分类法，设计单物品和服装级别的检索任务。关键创新点在于引入时间戳和计划半年度更新，防止数据污染并保持挑战性。评估方法包括排行榜和标准指标如Recall@1，并公开释放数据集、代码和训练模型，但具体模型架构摘要未明确说明。",
      "result": "实验结果显示，LookBench基准测试对强基线模型构成显著挑战，许多模型的Recall@1指标低于60%。论文提出的专有模型在LookBench上取得最佳性能，同时，发布的开源模型排名第二。这两个模型在传统基准Fashion200K评估中也达到了最先进水平，验证了模型的有效性和LookBench的实用性。与基线方法的对比表明，该基准测试具有较高的难度和区分度。",
      "conclusion": "论文的主要贡献是提出了LookBench，一个实时、全面和开放的时尚图像检索基准测试，通过整合多样数据源和更新机制，提供了一个更贴近实际的评估框架。其学术价值在于推动了时尚图像检索领域的评估标准改进，促进了更严谨和时效性的模型测试；实际应用价值体现在为电子商务图像检索系统提供了可靠的性能衡量工具。未来工作包括定期更新数据集和引入更难的检索任务变体，以持续挑战模型性能。",
      "tags": [
        "Fashion Image Retrieval",
        "Benchmark Evaluation",
        "AI-generated Images",
        "Fine-grained Classification",
        "Live Data Updates"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:53.469244Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14703",
    "title": "RegFreeNet: A Registration-Free Network for CBCT-based 3D Dental Implant Planning",
    "authors": [
      "Xinquan Yang",
      "Xuguang Li",
      "Mianjie Zheng",
      "Xuefen Liu",
      "Kun Tang",
      "Kian Ming Lim",
      "He Meng",
      "Jianfeng Ren",
      "Linlin Shen"
    ],
    "abstract": "As the commercial surgical guide design software usually does not support the export of implant position for pre-implantation data, existing methods have to scan the post-implantation data and map the implant to pre-implantation space to get the label of implant position for training. Such a process is time-consuming and heavily relies on the accuracy of registration algorithm. Moreover, not all hospitals have paired CBCT data, limitting the construction of multi-center dataset. Inspired by the way dentists determine the implant position based on the neighboring tooth texture, we found that even if the implant area is masked, it will not affect the determination of the implant position. Therefore, we propose to mask the implants in the post-implantation data so that any CBCT containing the implants can be used as training data. This paradigm enables us to discard the registration process and makes it possible to construct a large-scale multi-center implant dataset. On this basis, we proposes ImplantFairy, a comprehensive, publicly accessible dental implant dataset with voxel-level 3D annotations of 1622 CBCT data. Furthermore, according to the area variation characteristics of the tooth's spatial structure and the slope information of the implant, we designed a slope-aware implant position prediction network. Specifically, a neighboring distance perception (NDP) module is designed to adaptively extract tooth area variation features, and an implant slope prediction branch assists the network in learning more robust features through additional implant supervision information. Extensive experiments conducted on ImplantFairy and two public dataset demonstrate that the proposed RegFreeNet achieves the state-of-the-art performance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14703.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14703",
    "published": "2026-01-21T06:30:18Z",
    "updated": "2026-01-21T06:30:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出RegFreeNet，一种无需配准的网络，通过掩码种植体和斜率感知设计，实现CBCT基于的3D牙科种植体位置预测，创新包括数据集构建和网络模块优化。",
      "motivation": "现有牙科种植体规划方法依赖配准算法，需扫描种植后数据并映射到种植前空间以获取训练标签，过程耗时且精度受限于配准，同时多中心CBCT数据难以配对，限制了大规模数据集的构建。商业软件不支持导出植入物位置，导致资源浪费和临床效率低下，亟需更高效、不依赖配对数据的方法来利用广泛可用的CBCT数据。",
      "method": "论文提出RegFreeNet，核心方法是通过掩码种植体区域，使任何含种植体的CBCT数据可直接用于训练，无需配准流程；创建了ImplantFairy公开数据集，包含1622个CBCT数据的体素级3D标注；网络设计上，引入邻近距离感知模块自适应提取牙齿区域变化特征，并增加种植体斜率预测分支，利用额外监督信息提升特征鲁棒性，关键创新是掩码策略和斜率感知架构。",
      "result": "在ImplantFairy和两个公共数据集上的广泛实验表明，RegFreeNet实现了最先进的性能，相比基线方法在种植体位置预测上表现优异，但由于摘要未明确说明具体准确率或效率指标，性能提升细节需参考全文，实验证实了该方法在简化流程和提升预测精度方面的有效性。",
      "conclusion": "论文的主要贡献是提出无需配准的RegFreeNet网络，创建了公开数据集ImplantFairy，并设计了斜率感知模块，显著简化了牙科种植体规划的数据处理流程，支持多中心数据集构建，具有重要临床应用价值；学术上推动了AI在医疗图像分析的发展，未来可优化网络架构或扩展数据集规模以进一步提升性能。",
      "tags": [
        "Registration-Free Network",
        "Implant Position Prediction",
        "Slope-Aware Network",
        "Dental CBCT",
        "Dataset Construction"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:13.722783Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14702",
    "title": "AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving",
    "authors": [
      "Zecong Tang",
      "Zixu Wang",
      "Yifei Wang",
      "Weitong Lian",
      "Tianjian Gao",
      "Haoran Li",
      "Tengju Ru",
      "Lingyi Meng",
      "Zhejun Cui",
      "Yichen Zhu",
      "Qi Kang",
      "Kaixuan Wang",
      "Yu Zhang"
    ],
    "abstract": "Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14702.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14702",
    "published": "2026-01-21T06:29:09Z",
    "updated": "2026-01-21T06:29:09Z",
    "comment": "23 pages. Submitted to ACL ARR 2026 January",
    "light_analysis": {
      "overview": "AutoDriDM 是一个用于评估自动驾驶中视觉语言模型决策能力的可解释基准，填补了现有基准在决策评估方面的空白。",
      "motivation": "自动驾驶领域需要模型在复杂场景中进行可靠的感知和安全决策，现有视觉语言模型虽具备推理能力，但多数基准过于强调感知评估，未能有效测试决策过程，导致在实际应用中存在安全隐患。因此，开发一个专注于决策的评估工具至关重要，以确保模型在真实驾驶环境中的可靠性和安全性，避免因评估不足导致的潜在风险。",
      "method": "该研究提出了 AutoDriDM 基准，包含 6,650 个问题，覆盖对象、场景和决策三个维度，用于系统评估视觉语言模型的决策能力。关键创新点包括采用决策中心的渐进评估框架、实施可解释性分析以揭示模型推理过程，并引入一个分析器模型来自动化大规模标注。通过评估主流模型，分析感知到决策的能力边界，并识别失败模式如逻辑推理错误。",
      "result": "通过 AutoDriDM 基准评估，研究发现视觉语言模型的感知和决策性能之间存在弱对齐现象，揭示了模型在决策推理方面的不足。虽然具体数值摘要未明确说明，但与现有感知中心基准相比，该基准凸显了决策评估的重要性，并自动化了分析过程，为后续模型改进提供了数据支撑和方向。",
      "conclusion": "AutoDriDM 的主要贡献是提供了一个决策中心的评估基准，填补了自动驾驶中视觉语言模型评估的空白。学术上，它改进了评估方法学，强调了可解释性；应用上，指导开发更安全可靠的自动驾驶系统。未来工作可扩展基准规模或优化分析模型，以进一步提升评估的全面性和实用性。",
      "tags": [
        "Vision-Language Models",
        "Autonomous Driving",
        "Decision-Making",
        "Explainable AI",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:42.237935Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14700",
    "title": "DARL: Encouraging Diverse Answers for General Reasoning without Verifiers",
    "authors": [
      "Chongxuan Huang",
      "Lei Lin",
      "Xiaodong Shi",
      "Wenping Hu",
      "Ruiming Tang"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated promising gains in enhancing the reasoning capabilities of large language models. However, its dependence on domain-specific verifiers significantly restricts its applicability to open and general domains. Recent efforts such as RLPR have extended RLVR to general domains, enabling training on broader datasets and achieving improvements over RLVR. However, a notable limitation of these methods is their tendency to overfit to reference answers, which constrains the model's ability to generate diverse outputs. This limitation is particularly pronounced in open-ended tasks such as writing, where multiple plausible answers exist. To address this, we propose DARL, a simple yet effective reinforcement learning framework that encourages the generation of diverse answers within a controlled deviation range from the reference while preserving alignment with it. Our framework is fully compatible with existing general reinforcement learning methods and can be seamlessly integrated without additional verifiers. Extensive experiments on thirteen benchmarks demonstrate consistent improvements in reasoning performance. Notably, DARL surpasses RLPR, achieving average gains of 1.3 points on six reasoning benchmarks and 9.5 points on seven general benchmarks, highlighting its effectiveness in improving both reasoning accuracy and output diversity.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14700.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14700",
    "published": "2026-01-21T06:23:55Z",
    "updated": "2026-01-21T06:23:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出DARL框架，通过强化学习鼓励多样化答案生成，无需依赖验证器，有效提升推理性能和输出多样性。",
      "motivation": "本研究旨在解决现有强化学习方法在一般推理任务中的局限性。具体来说，Reinforcement Learning with Verifiable Rewards（RLVR）依赖特定领域验证器，限制了在开放和一般领域的应用；而RLPR等扩展方法虽然摆脱了验证器依赖，但倾向于过度拟合参考答案，导致输出多样性不足，这在开放任务如写作中尤为突出。问题的重要性在于，开放任务通常存在多个合理答案，多样性对于提高模型泛化能力和实用性至关重要。",
      "method": "本文提出DARL，一个简单而有效的强化学习框架，其核心方法是通过优化模型，鼓励生成在参考答案的受控偏差范围内的多样化答案，同时保持与参考的对齐。关键创新点在于无需额外验证器，框架完全兼容现有的一般强化学习方法，如RLPR，可无缝集成。技术特色包括设计奖励机制以平衡对齐度和偏差控制，促进多样性生成。摘要未明确说明具体数据集或模型架构，但实验在多个基准上进行。",
      "result": "实验在十三个基准上进行，结果显示DARL在推理性能上取得一致改进。具体数据表明，与基线方法RLPR相比，DARL在六个推理基准上平均得分提升1.3点，在七个一般基准上平均提升9.5点。这突出证明了DARL在提高推理准确性和输出多样性方面的有效性，优于现有方法，并提供了定量支撑以展示其性能优势。",
      "conclusion": "本研究的主要贡献是提出了DARL框架，解决了现有方法在过度拟合和输出多样性方面的限制。学术价值在于提供了一种无需验证器的强化学习方法，适用于一般领域推理任务；实际应用价值体现在改善开放任务的模型表现和实用性。摘要未明确说明局限性，但未来工作可能涉及扩展更多任务类型或优化偏差控制机制，以进一步提升泛化能力。",
      "tags": [
        "Reinforcement Learning",
        "Large Language Model",
        "Reasoning",
        "Diversity",
        "Controlled Deviation"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:09.950207Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14698",
    "title": "ClaimDB: A Fact Verification Benchmark over Large Structured Data",
    "authors": [
      "Michael Theologitis",
      "Preetam Prabhu Srikar Dammu",
      "Chirag Shah",
      "Dan Suciu"
    ],
    "abstract": "Despite substantial progress in fact-verification benchmarks, claims grounded in large-scale structured data remain underexplored. In this work, we introduce ClaimDB, the first fact-verification benchmark where the evidence for claims is derived from compositions of millions of records and multiple tables. ClaimDB consists of 80 unique real-life databases covering a wide range of domains, from governance and healthcare to media, education and the natural sciences. At this scale, verification approaches that rely on \"reading\" the evidence break down, forcing a timely shift toward reasoning in executable programs. We conduct extensive experiments with 30 state-of-the-art proprietary and open-source (below 70B) LLMs and find that none exceed 83% accuracy, with more than half below 55%. Our analysis also reveals that both closed- and open-source models struggle with abstention -- the ability to admit that there is no evidence to decide -- raising doubts about their reliability in high-stakes data analysis. We release the benchmark, code, and the LLM leaderboard at https://claimdb.github.io .",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14698.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14698",
    "published": "2026-01-21T06:19:47Z",
    "updated": "2026-01-21T06:19:47Z",
    "comment": "The data, code, and leaderboard are available at https://claimdb.github.io",
    "light_analysis": {
      "overview": "ClaimDB是首个基于大规模结构化数据的fact-verification基准测试，使用数百万记录和多表组合作为证据，推动向可执行程序推理的转变。",
      "motivation": "研究动机在于尽管fact-verification基准已有进展，但基于大规模结构化数据的claims仍未被充分探索。实际应用中，大规模结构化数据在治理、医疗等领域广泛存在，但现有方法依赖于“阅读”证据，在大规模数据下效率低下。该问题的重要性在于确保高风险数据分析的可靠性，现有不足是缺乏针对大规模数据的基准，导致模型评估不足，需转向程序推理以提升效果。",
      "method": "本研究构建了ClaimDB基准，包含80个真实数据库，覆盖治理、医疗、媒体、教育、自然科学等多个领域。证据来源于数百万记录和多个表的组合，鼓励使用可执行程序进行推理。实验使用了30个最先进的专有和开源LLMs（规模在700亿参数以下），通过基准测试评估模型性能。关键创新点在于首次将大规模结构化数据引入fact-verification任务，并设计基准以促进程序推理方法的发展，摘要未明确说明具体程序技术细节。",
      "result": "实验结果显示，30个LLMs中没有一个准确率超过83%，超过一半模型准确率低于55%。分析表明，无论是闭源还是开源模型，在弃权能力（即承认无证据可决策）上都表现不佳，这对其在高风险数据分析中的可靠性提出了质疑。与基线方法对比，现有模型在大规模结构化数据上效果有限，突出了改进需求和程序推理的重要性。",
      "conclusion": "本文的主要贡献是引入了ClaimDB，填补了大规模结构化数据fact-verification的空白，推动了向程序推理的转变。学术价值在于提供了首个相关基准，促进后续研究；实际应用价值在于提高数据分析的可靠性。局限性在于模型在弃权方面有缺陷，未来工作可探索更好的弃权机制、程序推理方法以及扩展基准到更多领域。",
      "tags": [
        "Fact Verification",
        "Large Structured Data",
        "Benchmark",
        "Large Language Models",
        "Abstention"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:49.707398Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14696",
    "title": "AdaTIR: Adaptive Tool-Integrated Reasoning via Difficulty-Aware Policy Optimization",
    "authors": [
      "Zhaiyu Fang",
      "Ruipeng Sun"
    ],
    "abstract": "Tool-Integrated Reasoning (TIR) has significantly enhanced the capabilities of Large Language Models (LLMs), yet current agents tend to exhibit cognitive offloading, redundantly invoking external tools even for simple tasks. In this paper, we suggest that true agentic intelligence requires not just tool invocation, but the adaptive wisdom to discern when to use them. We propose AdaTIR, a framework that shifts the paradigm from static tool invocation to difficulty-aware reasoning internalization. By introducing a difficulty-aware efficiency reward, AdaTIR dynamically adjusts tool budgets based on task complexity--internalizing reasoning for simple tasks while selectively invoking tools for complex tasks. Furthermore, we identify a sign reversal problem where tool penalties outweigh correctness rewards, mistakenly penalizing correct rollouts with negative advantages. To resolve this, we propose Clipped Advantage Shaping (CAS), which ensures that correctness remains the primary objective while using efficiency as a secondary constraint. Empirical results demonstrate that AdaTIR reduces tool calls by up to 97.6% on simple tasks and 28.2% on complex challenges while maintaining or enhancing accuracy. Notably, AdaTIR successfully internalizes reasoning, outperforming baselines by 4.8% on AIME 2024 even when tool access is strictly disabled.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14696.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14696",
    "published": "2026-01-21T06:18:46Z",
    "updated": "2026-01-21T06:18:46Z",
    "comment": "under review",
    "light_analysis": {
      "overview": "AdaTIR 框架通过难度感知策略优化实现自适应工具集成推理，动态内化推理以减少冗余工具调用，同时保持任务准确性。",
      "motivation": "当前工具集成推理（TIR）代理存在认知卸载问题，即使处理简单任务也冗余调用外部工具，这降低了效率并阻碍了真正的代理智能发展。现有方法缺乏自适应判断能力，未能根据任务复杂度动态调整工具使用，导致资源浪费。因此，研究旨在从静态工具调用范式转向自适应决策，以优化大语言模型的智能表现。",
      "method": "AdaTIR 框架引入难度感知效率奖励，基于任务复杂度（如简单任务内化推理、复杂任务选择性调用工具）动态调整工具预算。核心创新包括从静态工具调用转向难度感知推理内化，并提出了裁剪优势塑形（CAS）方法，解决工具惩罚与正确性奖励冲突的问题，确保正确性作为主要优化目标。通过策略优化技术实现自适应决策。",
      "result": "实证结果显示，AdaTIR 在简单任务上减少工具调用高达 97.6%，在复杂挑战上减少 28.2%，同时保持或提高准确性。在 AIME 2024 基准上，即使严格禁用工具访问，性能也超过基线方法 4.8%，证明了推理内化的有效性。对比基线，AdaTIR 在效率和准确性上均有显著改进。",
      "conclusion": "AdaTIR 框架的贡献在于实现了自适应工具集成推理，优化了代理智能的效率和准确性。学术价值体现在推动了从工具调用到难度感知决策的范式转变，CAS 方法解决了奖励结构问题。实际应用可减少计算资源浪费。未来工作可能扩展难度感知机制到更多任务场景或优化策略。",
      "tags": [
        "Tool-Integrated Reasoning (TIR)",
        "Difficulty-Aware Policy Optimization",
        "Clipped Advantage Shaping (CAS)",
        "Large Language Model (LLM)",
        "Adaptive Reasoning"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:12.049809Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14695",
    "title": "CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation",
    "authors": [
      "Yutong Chen",
      "Jiandong Gao",
      "Ji Wu"
    ],
    "abstract": "Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14695.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14695",
    "published": "2026-01-21T06:17:52Z",
    "updated": "2026-01-21T06:17:52Z",
    "comment": "preprint",
    "light_analysis": {
      "overview": "CoScale-RL提出了一种协同缩放数据和计算的后训练策略，显著提升大型推理模型的效率和准确率，平均准确率提高3.76倍。",
      "motivation": "该研究的动机是解决大型推理模型（LRM）训练过程中的不稳定和不可预测问题，特别是在困难任务或弱基础模型上。现有后训练缩放策略在提升模型推理能力时效率不足，而LRM的高效训练对AI应用至关重要，因此需要开发更有效的方法来优化数据和计算资源，以提高模型性能。",
      "method": "CoScale-RL方法的核心是协同缩放数据与计算：首先，通过收集每个问题的多个解决方案来缩放数据，而非简单扩大数据集；其次，放大rollout计算以稳定强化学习过程。关键创新在于使用Re-distillation模型合并技术，在缩放过程中维持或提升计算效率，从而优化训练流程，摘要未明确说明具体模型架构。",
      "result": "实验结果在四个基准测试中显示，CoScale-RL平均将准确率提升了3.76倍，显著改善了数据和计算效率。与基线方法相比，该方法能够在无需大量监督微调数据集的情况下，有效扩展LRM的能力边界，摘要未明确说明具体基线对比数据。",
      "conclusion": "本研究的主要贡献是提出CoScale-RL策略，为大型推理模型的后训练缩放提供了新方向，强调协同优化数据和计算以提升推理能力。该研究具有重要学术价值，推动高效模型训练方法发展，并可能在实际应用中降低资源成本，未来工作可探索扩展到更多任务和模型类型。",
      "tags": [
        "Large Reasoning Model",
        "Reinforcement Learning",
        "Scaling Strategy",
        "Re-distillation",
        "Post-Training"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:45.200436Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14694",
    "title": "Re-understanding Graph Unlearning through Memorization",
    "authors": [
      "Pengfei Ding",
      "Yan Wang",
      "Guanfeng Liu"
    ],
    "abstract": "Graph unlearning (GU), which removes nodes, edges, or features from trained graph neural networks (GNNs), is crucial in Web applications where graph data may contain sensitive, mislabeled, or malicious information. However, existing GU methods lack a clear understanding of the key factors that determine unlearning effectiveness, leading to three fundamental limitations: (1) impractical and inaccurate GU difficulty assessment due to test-access requirements and invalid assumptions, (2) ineffectiveness on hard-to-unlearn tasks, and (3) misaligned evaluation protocols that overemphasize easy tasks and fail to capture true forgetting capability. To address these issues, we establish GNN memorization as a new perspective for understanding graph unlearning and propose MGU, a Memorization-guided Graph Unlearning framework. MGU achieves three key advances: it provides accurate and practical difficulty assessment across different GU tasks, develops an adaptive strategy that dynamically adjusts unlearning objectives based on difficulty levels, and establishes a comprehensive evaluation protocol that aligns with practical requirements. Extensive experiments on ten real-world graphs demonstrate that MGU consistently outperforms state-of-the-art baselines in forgetting quality, computational efficiency, and utility preservation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14694.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14694",
    "published": "2026-01-21T06:14:23Z",
    "updated": "2026-01-21T06:14:23Z",
    "comment": "This paper has been accepted by WWW-2026",
    "light_analysis": {
      "overview": "提出基于GNN memorization的MGU框架，通过新视角改进图遗忘的难度评估、自适应策略和评估协议，提升遗忘效果。",
      "motivation": "图遗忘（Graph Unlearning）在训练好的图神经网络（GNNs）中移除节点、边或特征，对于处理Web应用中包含敏感、误标或恶意信息的图数据至关重要。然而，现有方法缺乏对决定遗忘效果关键因素的清晰理解，导致三个基本限制：难度评估不实用且不准确、对难以遗忘的任务无效、评估协议不匹配且过度强调简单任务。这些不足阻碍了图遗忘在实际场景中的应用，亟需新的理论和方法来解决问题。",
      "method": "论文提出以GNN memorization作为新视角来重新理解图遗忘，并开发了MGU（Memorization-guided Graph Unlearning）框架。该方法实现三个关键进展：首先，提供跨不同GU任务的准确且实用的难度评估方法；其次，设计自适应策略，根据难度级别动态调整遗忘目标；最后，建立全面评估协议，符合实际需求。框架通过整合记忆机制，优化了遗忘过程的技术实现。",
      "result": "在十个真实世界图数据集上的广泛实验表明，MGU在遗忘质量、计算效率和效用保持方面一致优于现有最优基线方法。实验验证了其在各种任务中的有效性，特别是在难以遗忘的场景下，框架展现了更强的遗忘能力和更好的性能表现，证明了其通用性和实用性。",
      "conclusion": "本研究通过引入GNN memorization视角和MGU框架，解决了图遗忘在难度评估、自适应策略和评估协议上的局限性。该贡献为图神经网络中的数据安全和隐私保护提供了新工具，具有重要的学术价值和应用前景，未来可扩展到更多GNN架构和更复杂的图数据场景。",
      "tags": [
        "Graph Unlearning",
        "Graph Neural Networks",
        "Memorization",
        "Adaptive Strategy",
        "Evaluation Protocol"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:24.328716Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14693",
    "title": "Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Jianwen Sun",
      "Xinrui Li",
      "Fuqing Li",
      "Xiaoxuan Shen"
    ],
    "abstract": "Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14693.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14693",
    "published": "2026-01-21T06:08:37Z",
    "updated": "2026-01-21T06:08:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出EGRL-SR框架，通过目标条件强化学习和经验驱动的搜索策略来优化符号回归，显著提升恢复率和鲁棒性。",
      "motivation": "符号回归的目标是自动发现数学表达式以建模输入输出关系，但现有方法主要依赖拟合误差指导搜索。在庞大表达式空间中，众多候选表达式可能具有相似误差但结构迥异，导致搜索方向不明确，影响收敛到真实函数的能力。传统误差驱动方法在结构多样性处理上不足，限制了搜索效率，因此需要创新方法来解决这一问题，以提高符号回归的稳健性和准确性。",
      "method": "论文将符号回归公式化为目标条件强化学习问题，提出EGRL-SR框架。核心创新包括整合hindsight experience replay，使动作价值网络能从多样输入输出对中泛化映射模式；设计所有点满足二进制奖励函数，引导网络关注结构特征而非低误差表达式；并引入结构引导启发式探索策略，增强搜索多样性和空间覆盖。模型利用历史轨迹优化动作价值网络，以主动指导搜索过程，而非被动依赖误差。",
      "result": "在公开基准测试中，EGRL-SR在恢复率和鲁棒性上一致优于最先进方法，能在相同搜索预算下恢复更复杂的表达式。消融实验验证了动作价值网络的有效指导作用，奖励函数和探索策略均发挥关键角色，具体表现为性能指标的显著提升，支持了该方法在结构搜索中的优势。与基线方法对比显示，EGRL-SR在效率和准确性上均有改进。",
      "conclusion": "EGRL-SR框架的主要贡献在于为符号回归提供了新的经验驱动视角，通过强化学习技术增强了搜索的稳健性和效率。学术上，它开辟了结合历史轨迹和目标条件策略的研究方向；实践上，提升了解释性和复杂表达式发现能力，有广泛应用潜力。未来工作可能涉及扩展框架或进一步优化组件，以应对更复杂场景。",
      "tags": [
        "Symbolic Regression",
        "Goal-Conditioned Reinforcement Learning",
        "Hindsight Experience Replay",
        "Action-Value Network",
        "Binary Reward Function"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:32.519915Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14691",
    "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation",
    "authors": [
      "Muhammad Khalifa",
      "Lajanugen Logeswaran",
      "Jaekyeom Kim",
      "Sungryull Sohn",
      "Yunxiang Zhang",
      "Moontae Lee",
      "Hao Peng",
      "Lu Wang",
      "Honglak Lee"
    ],
    "abstract": "Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14691.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14691",
    "published": "2026-01-21T06:07:43Z",
    "updated": "2026-01-21T06:07:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文揭示了当大型语言模型用作代理评估法官时，链式思维推理的操纵可以显著影响判断准确性，暴露了评估范式的脆弱性。",
      "motivation": "LLMs 越来越多地用于评估代理在不可验证任务中的性能，依赖链式思维推理轨迹，这一范式基于推理忠实地反映内部状态和环境的假设。然而，这一假设的脆弱性可能导致评估失真，进而影响基于LLM系统的可靠性和决策准确性。研究旨在检验此脆弱性，因为不准确的评估会误导性能判断，推动更鲁棒评估方法的发展，以提升AI系统的可信度。",
      "method": "研究者通过系统地重写代理的链式思维推理，同时保持动作和观察固定，测试LLM法官的脆弱性。关键创新在于区分两种操纵策略：基于风格的操纵仅改变推理的呈现方式，而基于内容的操纵伪造任务进度信号。实验使用800个跨越不同网络任务的轨迹，评估基于提示的技术和扩展法官时间计算，以分析这些方法对脆弱性的缓解效果。",
      "result": "实验结果表明，操纵推理轨迹可以将最先进的VLM法官的误报率提高高达90%。基于内容的操纵比基于风格的操纵更有效，提示技术和增加计算资源虽能减少脆弱性，但无法完全消除。在800个轨迹上的广泛测试证实了这一脆弱性，与基线方法对比，揭示了当前LLM评估范式的根本缺陷。",
      "conclusion": "研究揭示了LLM作为评估法官时对推理操纵的敏感性，强调需要开发验证推理与可观测证据一致性的裁判机制。学术上，它挑战了现有评估假设；实践上，为设计更鲁棒的AI评估方法提供了方向。潜在局限性可能在于任务范围有限，未来工作可扩展到更多场景和模型，以进一步提升评估的可靠性。",
      "tags": [
        "Large Language Models",
        "Chain-of-Thought",
        "Agent Evaluation",
        "Manipulation Strategies",
        "Vision Language Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:24.035385Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14690",
    "title": "FeedbackSTS-Det: Sparse Frames-Based Spatio-Temporal Semantic Feedback Network for Infrared Small Target Detection",
    "authors": [
      "Yian Huang",
      "Qing Qin",
      "Aji Mao",
      "Xiangyu Qiu",
      "Liang Xu",
      "Xian Zhang",
      "Zhenming Peng"
    ],
    "abstract": "Infrared small target detection (ISTD) under complex backgrounds remains a critical yet challenging task, primarily due to the extremely low signal-to-clutter ratio, persistent dynamic interference, and the lack of distinct target features. While multi-frame detection methods leverages temporal cues to improve upon single-frame approaches, existing methods still struggle with inefficient long-range dependency modeling and insufficient robustness. To overcome these issues, we propose a novel scheme for ISTD, realized through a sparse frames-based spatio-temporal semantic feedback network named FeedbackSTS-Det. The core of our approach is a novel spatio-temporal semantic feedback strategy with a closed-loop semantic association mechanism, which consists of paired forward and backward refinement modules that work cooperatively across the encoder and decoder. Moreover, both modules incorporate an embedded sparse semantic module (SSM), which performs structured sparse temporal modeling to capture long-range dependencies with low computational cost. This integrated design facilitates robust implicit inter-frame registration and continuous semantic refinement, effectively suppressing false alarms. Furthermore, our overall procedure maintains a consistent training-inference pipeline, which ensures reliable performance transfer and increases model robustness. Extensive experiments on multiple benchmark datasets confirm the effectiveness of FeedbackSTS-Det. Code and models are available at: https://github.com/IDIP-Lab/FeedbackSTS-Det.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14690.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14690",
    "published": "2026-01-21T06:06:36Z",
    "updated": "2026-01-21T06:06:36Z",
    "comment": "Submitted to Journal IEEE Transactions on Geoscience and Remote Sensing",
    "light_analysis": {
      "overview": "本论文提出了一种基于稀疏帧的时空语义反馈网络 FeedbackSTS-Det，用于红外小目标检测，通过闭环语义关联机制有效提升检测性能。",
      "motivation": "红外小目标检测在复杂背景下是一个关键但具有挑战性的任务，主要由于极低的信号杂波比、持续的动态干扰以及缺乏显著的目标特征。现有方法虽然利用多帧检测来改进单帧方法，但仍然面临长程依赖建模效率低下和鲁棒性不足的问题，这导致检测准确性和稳定性受限，因此需要更高效和鲁棒的解决方案来克服这些局限性。",
      "method": "FeedbackSTS-Det 网络的核心是一个新颖的时空语义反馈策略，包含闭环语义关联机制。该机制由成对的前向和后向细化模块组成，在编码器和解码器之间协同工作。关键创新点是嵌入式稀疏语义模块（SSM），它进行结构化稀疏时空建模，以低计算成本捕获长程依赖。此外，训练-推断流程保持一致性，确保模型鲁棒性和性能可靠转移。",
      "result": "论文在多个基准数据集上进行了广泛实验，证实了 FeedbackSTS-Det 的有效性。摘要未明确说明具体性能指标（如准确率提升或效率改进数值），但指出该方法与基线方法相比具有显著优势。代码和模型已公开提供，增强了方法的可重复性和验证性。",
      "conclusion": "本研究的主要贡献是提出了 FeedbackSTS-Det 网络，通过时空语义反馈策略和稀疏建模技术解决了红外小目标检测的挑战。学术上，引入了闭环关联机制，推动了多帧检测方法的发展；实际应用中，可用于红外图像处理等领域，提高检测准确性和鲁棒性。未来工作可能包括进一步优化模型或扩展到其他复杂场景。",
      "tags": [
        "Infrared Small Target Detection",
        "Spatio-Temporal Networks",
        "Semantic Feedback",
        "Structured Sparse Modeling",
        "Closed-Loop Mechanisms"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:44.094111Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14687",
    "title": "Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning",
    "authors": [
      "Zhihao Chen",
      "Zirui Gong",
      "Jianting Ning",
      "Yanjun Zhang",
      "Leo Yu Zhang"
    ],
    "abstract": "Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14687.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14687",
    "published": "2026-01-21T06:03:11Z",
    "updated": "2026-01-21T06:03:11Z",
    "comment": "12 pages. To appear in The Web Conference 2026",
    "light_analysis": {
      "overview": "本文提出了Edge Control Attack (ECA)，第一个针对基于排名的联邦学习的细粒度控制攻击，能够精确控制准确性而不被检测。",
      "motivation": "Federated Rank Learning (FRL)是一种有前景的联邦学习范式，通过离散排名减少通信成本并增强对模型投毒攻击的鲁棒性，适用于安全和隐私敏感应用如网络拍卖。然而，尽管FRL大幅减少了攻击面，但仍存在漏洞，现有方法如拒绝服务(DoS)攻击引起明显干扰，而细粒度控制攻击能够隐秘操作，避免检测。这突出了研究高级攻击的必要性，以应对FRL在安全关键场景中的新威胁，确保系统的可靠性和隐私保护。",
      "method": "论文提出的Edge Control Attack (ECA)是一种针对FRL的细粒度控制攻击，操作分为两个阶段：首先，识别和操纵Ascending和Descending Edges，以对齐全局模型与目标模型；其次，扩大选择边界差距，使全局模型在目标准确性水平上稳定。ECA的关键创新在于其能够通过伪装正常收敛轨迹来逃避检测。方法在七个基准数据集和九个Byzantine-robust聚合规则(AGRs)上进行测试，验证了攻击的普遍性和有效性，但摘要未明确说明具体模型架构。",
      "result": "实验结果表明，ECA在七个基准数据集和九个Byzantine-robust聚合规则(AGRs)上实现了细粒度准确性控制，平均误差仅为0.224%。与基线方法相比，ECA的性能提升高达17倍，显著优于传统攻击，证实了其在隐秘攻击中的高效性。这些结果突显了FRL框架仍存在显著安全漏洞，需要更强的防御措施，以应对这种高级投毒攻击。",
      "conclusion": "本研究的主要贡献是揭示了基于排名的联邦学习(FRL)对细粒度控制攻击的脆弱性，并提出了Edge Control Attack (ECA)作为首个此类攻击。学术价值在于推动了联邦学习安全性的理解，强调在安全敏感应用中部署FRL时需谨慎。实际应用中，它为防御机制开发提供了方向，以应对高级投毒攻击，确保框架的可靠性和安全性，未来工作可聚焦于构建更强大的防御策略。",
      "tags": [
        "Federated Learning",
        "Model Poisoning Attack",
        "Ranking-Based Learning",
        "Byzantine-Robust Aggregation"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:28.858851Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14686",
    "title": "IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization",
    "authors": [
      "Shuai Wang",
      "Yaoming Yang",
      "Bingdong Li",
      "Hao Hao",
      "Aimin Zhou"
    ],
    "abstract": "Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14686.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14686",
    "published": "2026-01-21T06:03:05Z",
    "updated": "2026-01-21T06:03:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出IB-GRPO方法，通过指标引导的组相对策略优化，将基于大型语言模型的学习路径推荐与教育目标对齐，实现多目标优化。",
      "motivation": "学习路径推荐旨在生成个性化学习序列以最大化长期学习效果，但应用大型语言模型时面临挑战：与教学目标（如最近发展区）对齐困难，尤其在稀疏、延迟反馈下；专家演示稀缺且成本高；多目标（学习效果、难度调度、长度可控性、轨迹多样性）交互复杂。现有方法难以有效处理这些多目标对齐，导致推荐可能偏离教学原则，影响学习效率。",
      "method": "IB-GRPO是一种基于指标引导的对齐方法。首先，通过遗传算法搜索和教师强化学习代理构建混合专家演示，并利用监督微调热启动大型语言模型（如Qwen2.5-7B）。然后，设计基于会话内最近发展区的对齐分数来优化难度调度。核心创新是使用$I_{ε+}$支配指标计算多个目标上的组相对优势，避免手动标量化，改进Pareto权衡，实现多目标对齐。该方法在ASSIST09和Junyi数据集上测试。",
      "result": "实验在ASSIST09和Junyi数据集上使用KES模拟器和Qwen2.5-7B骨干模型进行。结果显示，IB-GRPO在代表性强化学习和大型语言模型基线上表现出持续改进。摘要未明确说明具体性能指标（如准确率提升百分比），因此具体数据摘要未明确说明，但与基线相比性能有所提升。",
      "conclusion": "IB-GRPO的主要贡献是提出了一种指标引导的对齐方法，有效解决学习路径推荐中的多目标优化问题，提升推荐的教学一致性和长期学习效果。该研究在学术上为基于大型语言模型的推荐系统提供了新的对齐框架，实际应用中可改善个性化学习体验。未来工作可能包括扩展到更多数据集和优化计算效率，摘要未明确说明局限性和详细未来方向。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Genetic Algorithm",
        "Zone of Proximal Development",
        "$I_{ε+}$ dominance indicator"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:32.061646Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14683",
    "title": "Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text",
    "authors": [
      "Aisvarya Adeseye",
      "Jouni Isoaho",
      "Seppo Virtanen",
      "Mohammad Tahir"
    ],
    "abstract": "Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14683.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14683",
    "published": "2026-01-21T05:59:56Z",
    "updated": "2026-01-21T05:59:56Z",
    "comment": "Accepted and Waiting to be Published. ICAI'25: 27th International Conference on Artificial Intelligence https://american-cse.org/csce2025/conferences-ICAI",
    "light_analysis": {
      "overview": "提出一种基于本地大型语言模型的自适应匿名化框架，用于敏感文本的上下文感知匿名化处理。",
      "motivation": "定性研究中常包含个人、上下文和组织细节，若不妥善处理，会带来隐私泄露风险。现有匿名化方法存在不足：手动方法耗时、不一致且易遗漏关键标识符；自动化工具多依赖模式匹配或固定规则，缺乏上下文理解能力，甚至可能扭曲数据原意。因此，本研究旨在解决这些问题，通过开发可靠、可重复且上下文感知的匿名化过程，以有效保护敏感数据，同时维持研究的完整性和准确性。",
      "method": "本研究引入了结构化自适应匿名化框架（SFAA），该框架包括检测、分类和自适应匿名化三个核心步骤。采用四种匿名化策略：基于规则的替换、上下文感知重写、泛化和抑制，根据标识符类型和风险级别动态应用。方法遵循国际隐私标准如 GDPR、HIPAA 和 OECD 指南，确保合规性。使用本地大型语言模型 LLaMA 和 Phi 进行评估，结合人工和 LLM 辅助的双重方法，以及两个案例研究：82 次面对面访谈和 93 次 AI 驱动访谈，以验证框架的上下文感知和隐私保护能力。",
      "result": "实验结果显示，大型语言模型在检测敏感数据方面优于人类评审员：Phi 模型表现最佳，能识别超过 91% 的敏感数据，同时 94.8% 的匿名化文本保持了与原文本相同的情感，确保了高准确性和对定性数据分析的无干扰。相比之下，Phi 在发现敏感数据上优于 LLaMA，但错误率略高。这些结果表明，框架在隐私保护方面具有高效性，同时通过上下文感知策略最小化数据失真。",
      "conclusion": "本研究的核心贡献是开发了一个基于本地大型语言模型的自适应匿名化框架，显著提升了敏感文本匿名化的准确性和上下文保持能力。该框架具有重要的学术和实际应用价值，为隐私保护和定性研究领域提供了可靠工具，同时遵循国际标准以确保合规性。局限性包括模型在检测敏感数据时存在一定错误率；未来工作可专注于优化模型以减少错误，扩展应用到更多数据类型，并进一步评估在复杂场景下的性能。",
      "tags": [
        "Local Language Models",
        "Context-Aware Anonymization",
        "Anonymization Framework",
        "Phi",
        "LLaMA"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:58.537029Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14678",
    "title": "Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation",
    "authors": [
      "Justin Cheung",
      "Samuel Savine",
      "Calvin Nguyen",
      "Lin Lu",
      "Alhassan S. Yasin"
    ],
    "abstract": "Supervised deep learning models often achieve excellent performance within their training distribution but struggle to generalize beyond it. In cancer histopathology, for example, a convolutional neural network (CNN) may classify cancer severity accurately for cancer types represented in its training data, yet fail on related but unseen types. Although adenocarcinomas from different organs share morphological features that might support limited cross-domain generalization, addressing domain shift directly is necessary for robust performance. Domain adaptation offers a way to transfer knowledge from labeled data in one cancer type to unlabeled data in another, helping mitigate the scarcity of annotated medical images.   This work evaluates cross-domain classification performance among lung, colon, breast, and kidney adenocarcinomas. A ResNet50 trained on any single adenocarcinoma achieves over 98% accuracy on its own domain but shows minimal generalization to others. Ensembling multiple supervised models does not resolve this limitation. In contrast, converting the ResNet50 into a domain adversarial neural network (DANN) substantially improves performance on unlabeled target domains. A DANN trained on labeled breast and colon data and adapted to unlabeled lung data reaches 95.56% accuracy.   We also examine the impact of stain normalization on domain adaptation. Its effects vary by target domain: for lung, accuracy drops from 95.56% to 66.60%, while for breast and colon targets, stain normalization boosts accuracy from 49.22% to 81.29% and from 78.48% to 83.36%, respectively. Finally, using Integrated Gradients reveals that DANNs consistently attribute importance to biologically meaningful regions such as densely packed nuclei, indicating that the model learns clinically relevant features and can apply them to unlabeled cancer types.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "q-bio.TO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14678.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14678",
    "published": "2026-01-21T05:50:34Z",
    "updated": "2026-01-21T05:50:34Z",
    "comment": "8 pages, 6 figures, 3 table",
    "light_analysis": {
      "overview": "论文提出使用域对抗神经网络（DANN）进行跨癌症类型的领域适应，有效提升在未标记癌症数据上的分类性能。",
      "motivation": "监督深度学习模型在癌症病理学中泛化能力差，难以应用于未见癌症类型，导致在跨癌症分类中表现不佳。由于医学图像标注数据稀缺，现有方法如单一CNN或集成模型无法有效处理领域差异（domain shift）。因此，需要领域适应技术来将知识从标记的癌症类型转移到未标记的相关癌症类型，以支持临床诊断和提高模型实用性。",
      "method": "研究使用ResNet50作为基础模型，通过转换为域对抗神经网络（DANN）实现领域适应。评估了肺、结肠、乳腺癌和肾腺癌四种癌症类型的跨领域分类性能。关键创新在于应用DANN处理癌症类型间的形态特征共享，同时探讨染色归一化技术的影响。使用Integrated Gradients分析模型关注区域，以验证特征学习的相关性。方法专注于利用对抗训练来减少源域和目标域之间的分布差异。",
      "result": "DANN显著改善跨领域分类准确率：例如，在标记的乳腺癌和结肠癌数据上训练DANN后，适应未标记肺癌数据达到95.56%准确率。相比基线，单一ResNet50在自领域准确率超98%，但跨领域泛化差；集成多个监督模型未解决此问题。染色归一化效果因目标域而异：对肺癌目标，准确率从95.56%降至66.60%；对乳腺癌和结肠癌目标，分别从49.22%提升至81.29%和从78.48%提升至83.36%。Integrated Gradients显示模型关注生物相关区域如密集细胞核。",
      "conclusion": "论文证明了DANN在跨癌症领域适应中的有效性，为解决医学图像标注稀缺问题提供了新方法。学术上，这推动了领域适应技术在生物医学领域的应用；实际上，能帮助模型泛化到未标记癌症类型，提高诊断效率。染色归一化的不一致效果指出潜在局限性，未来工作可探索优化预处理方法或结合其他技术以提升泛化能力。研究还强调了模型学习临床相关特征的能力。",
      "tags": [
        "Domain Adaptation",
        "Domain Adversarial Neural Network (DANN)",
        "Transfer Learning",
        "Cancer Histopathology",
        "Stain Normalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:21.224874Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14677",
    "title": "A comprehensive overview of deep learning models for object detection from videos/images",
    "authors": [
      "Sukana Zulfqar",
      "Sadia Saeed",
      "M. Azam Zia",
      "Anjum Ali",
      "Faisal Mehmood",
      "Abid Ali"
    ],
    "abstract": "Object detection in video and image surveillance is a well-established yet rapidly evolving task, strongly influenced by recent deep learning advancements. This review summarises modern techniques by examining architectural innovations, generative model integration, and the use of temporal information to enhance robustness and accuracy. Unlike earlier surveys, it classifies methods based on core architectures, data processing strategies, and surveillance specific challenges such as dynamic environments, occlusions, lighting variations, and real-time requirements. The primary goal is to evaluate the current effectiveness of semantic object detection, while secondary aims include analysing deep learning models and their practical applications. The review covers CNN-based detectors, GAN-assisted approaches, and temporal fusion methods, highlighting how generative models support tasks such as reconstructing missing frames, reducing occlusions, and normalising illumination. It also outlines preprocessing pipelines, feature extraction progress, benchmarking datasets, and comparative evaluations. Finally, emerging trends in low-latency, efficient, and spatiotemporal learning approaches are identified for future research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14677.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14677",
    "published": "2026-01-21T05:50:21Z",
    "updated": "2026-01-21T05:50:21Z",
    "comment": "N/A",
    "light_analysis": {
      "overview": "这篇综述论文全面总结和分类了基于深度学习的视频和图像目标检测模型，提供了一种新的分类方法来评估和指导未来研究。",
      "motivation": "目标检测在视频和图像监控中是一个长期存在且快速发展的任务，受深度学习进展的强烈影响。本综述旨在评估当前语义目标检测技术的有效性，分析深度学习模型及其在实际应用中的表现，特别是应对监控特定挑战如动态环境、遮挡、光照变化和实时要求时。现有综述方法可能不够系统或更新较慢，因此需要提供一种更全面和分类明确的概述来帮助研究人员理解技术现状和未来方向，推动领域进步。",
      "method": "本综述采用基于核心架构、数据处理策略和监控特定挑战的分类方法，涵盖CNN-based检测器、GAN-assisted方法和时间融合方法。关键创新点包括集成生成模型来支持重建缺失帧、减少遮挡和标准化光照等任务，以及利用时间信息提高鲁棒性。技术特色还包括概述预处理流程和特征提取进展，使用基准数据集进行对比评估，以系统化地总结现有技术，为读者提供结构化参考。",
      "result": "综述总结了当前深度学习目标检测技术的效果，指出生成模型集成和时间信息融合能显著提高鲁棒性和准确性，特别是在处理动态环境、遮挡、光照变化和实时需求时。通过比较评估，它展示了不同方法在基准数据集上的相对表现，但没有提供具体的性能数据如准确率或效率改进；与基线方法的对比未在摘要中详细说明，但强调了技术在应对挑战时的总体改进和趋势分析。",
      "conclusion": "本综述的主要贡献是提供了一个全面且分类明确的深度学习目标检测模型概述，帮助研究者理解技术现状和挑战。它具有学术价值，为相关领域提供了参考框架，并识别了新兴趋势如低延迟、高效和时空学习方法，为未来研究指明了方向。潜在的局限性包括依赖现有文献总结，缺乏新实验数据；未来工作可侧重于具体应用场景的深入分析或技术瓶颈的突破。",
      "tags": [
        "Object Detection",
        "Deep Learning Models",
        "Convolutional Neural Networks",
        "Generative Adversarial Networks",
        "Temporal Fusion"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:58.188399Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14674",
    "title": "LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models",
    "authors": [
      "Mingyang Xie",
      "Numair Khan",
      "Tianfu Wang",
      "Naina Dhingra",
      "Seonghyeon Nam",
      "Haitao Yang",
      "Zhuo Hui",
      "Christopher Metzler",
      "Andrea Vedaldi",
      "Hamed Pirsiavash",
      "Lei Luo"
    ],
    "abstract": "Given a monocular video, the goal of video re-rendering is to generate views of the scene from a novel camera trajectory. Existing methods face two distinct challenges. Geometrically unconditioned models lack spatial awareness, leading to drift and deformation under viewpoint changes. On the other hand, geometrically-conditioned models depend on estimated depth and explicit reconstruction, making them susceptible to depth inaccuracies and calibration errors.   We propose to address these challenges by using the implicit geometric knowledge embedded in the latent space of a large 4D reconstruction model to condition the video generation process. These latents capture scene structure in a continuous space without explicit reconstruction. Therefore, they provide a flexible representation that allows the pretrained diffusion prior to regularize errors more effectively. By jointly conditioning on these latents and source camera poses, we demonstrate that our model achieves state-of-the-art results on the video re-rendering task. Project webpage is https://lavr-4d-scene-rerender.github.io/",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14674.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14674",
    "published": "2026-01-21T05:46:03Z",
    "updated": "2026-01-21T05:46:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出LaVR模型，利用大型4D重建模型的隐式几何知识条件化视频生成，在视频重新渲染任务上实现最先进结果。",
      "motivation": "视频重新渲染任务旨在从新相机轨迹生成场景视图，但现有方法面临两大挑战。几何无条件模型缺乏空间感知，导致视图变化时出现漂移和变形；而几何条件模型依赖于显式深度估计和重建，易受深度不准确和校准误差影响。这些问题限制了生成视频的准确性和鲁棒性，因此需要一种新方法来结合几何信息而不依赖显式重建，以提升性能。",
      "method": "研究方法的核心是使用大型4D重建模型潜在空间中的隐式几何知识来条件化视频生成过程。这些潜在变量在连续空间中捕捉场景结构，无需显式重建，提供了灵活表示。关键创新在于联合条件化这些潜在变量和源相机姿态，利用预训练的扩散先验正则化误差，从而更有效地生成高质量视频。模型通过隐式几何指导，避免了传统方法的深度估计依赖，提升了空间一致性。",
      "result": "实验结果显示，LaVR模型在视频重新渲染任务上取得了最先进性能。条件化场景潜在变量和相机姿态显著减少了漂移和变形，提升了生成视图的质量。与现有基线方法相比，该方法在保持几何准确性的同时，避免了深度估计误差，展示了更高的鲁棒性和效率改进。具体性能指标如准确率提升摘要未明确说明，但强调了state-of-the-art成果。",
      "conclusion": "本研究的主要贡献是提出LaVR模型，通过场景潜在条件化利用大型4D重建模型的隐式几何知识，解决了视频重新渲染中的关键问题。该研究具有重要的学术价值，为生成视频提供了新思路，并可能在实际应用中提升视图合成的准确性。摘要未明确说明局限性或未来工作方向，但该方法展示了结合隐式几何的潜力。",
      "tags": [
        "Large 4D Reconstruction Models",
        "Latent Space Conditioning",
        "Video Re-rendering",
        "Diffusion Models",
        "Generative Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:19.668359Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14671",
    "title": "Mirai: Autoregressive Visual Generation Needs Foresight",
    "authors": [
      "Yonghao Yu",
      "Lang Huang",
      "Zerun Wang",
      "Runyi Li",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Autoregressive (AR) visual generators model images as sequences of discrete tokens and are trained with next token likelihood. This strict causality supervision optimizes each step only by its immediate next token, which diminishes global coherence and slows convergence. We ask whether foresight, training signals that originate from later tokens, can help AR visual generation. We conduct a series of controlled diagnostics along the injection level, foresight layout, and foresight source axes, unveiling a key insight: aligning foresight to AR models' internal representation on the 2D image grids improves causality modeling. We formulate this insight with Mirai (meaning \"future\" in Japanese), a general framework that injects future information into AR training with no architecture change and no extra inference overhead: Mirai-E uses explicit foresight from multiple future positions of unidirectional representations, whereas Mirai-I leverages implicit foresight from matched bidirectional representations. Extensive experiments show that Mirai significantly accelerates convergence and improves generation quality. For instance, Mirai can speed up LlamaGen-B's convergence by up to 10$\\times$ and reduce the generation FID from 5.34 to 4.34 on the ImageNet class-condition image generation benchmark. Our study highlights that visual autoregressive models need foresight.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14671.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14671",
    "published": "2026-01-21T05:33:23Z",
    "updated": "2026-01-21T05:33:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Mirai框架，通过在自回归视觉生成训练中注入未来信息，无需架构改变或额外开销，显著加速收敛并提高生成质量。",
      "motivation": "AR视觉生成器将图像建模为离散标记序列，使用下一个标记似然进行训练，导致每个步骤只优化立即下一个标记，这损害了图像的全局一致性和训练收敛速度。现有方法因严格因果监督而受限，使得生成过程缓慢且质量下降，因此研究探索预见性信号是否能改进AR视觉生成的效率和质量。",
      "method": "研究通过控制性诊断，在注入级别、预见性布局和来源方面进行分析，发现将预见性与AR模型在2D图像网格上的内部表示对齐可改进因果建模。基于此，提出Mirai框架，包括Mirai-E（使用来自单向表示的显性预见性）和Mirai-I（使用来自双向表示的隐性预见性），无需改变模型架构或增加推理开销，直接注入未来信息到训练过程中。",
      "result": "Mirai在实验中显著加速了收敛并提高了生成质量。具体而言，在ImageNet类条件图像生成基准上，Mirai将LlamaGen-B的收敛速度提升10倍，并将FID从5.34降低到4.34。这表明与基线AR方法相比，Mirai在收敛效率和生成性能上均有显著改进，突出了预见性训练的有效性。",
      "conclusion": "研究证明了在自回归视觉生成中引入预见性的重要性，提出了通用框架Mirai。学术上，它揭示了内部表示对齐对因果建模的关键作用，为AR模型优化提供了新思路；应用上，可无成本地加速训练和提高生成质量。未来工作可探索预见性在其他生成任务中的应用或框架的进一步扩展。",
      "tags": [
        "Autoregressive Models",
        "Visual Generation",
        "Foresight Training",
        "Discrete Token Representation",
        "Convergence Acceleration"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:33.360001Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14662",
    "title": "Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems",
    "authors": [
      "Shuhua Yang",
      "Jiahao Zhang",
      "Yilong Wang",
      "Dongwon Lee",
      "Suhang Wang"
    ],
    "abstract": "Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14662.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14662",
    "published": "2026-01-21T05:20:54Z",
    "updated": "2026-01-21T05:20:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出 AGEA 框架，实现高效查询下对 GraphRAG 系统隐藏图结构的提取攻击。",
      "motivation": "GraphRAG 系统构建知识图以支持多跳推理，但先前研究仅显示其响应可能泄露子图，在实际查询预算下高效重建整个隐藏图结构的可行性尚未探索。这导致对其安全性的评估不足，研究在预算受限黑盒设置中，通过自适应查询窃取潜在实体关系图的攻击方法，以揭示系统脆弱性并促进安全改进。",
      "method": "论文提出 AGEA 框架，采用新颖性引导的探索-利用策略来优化查询选择，结合外部图内存模块存储信息，设计两阶段图提取管道：先进行轻量级发现初步提取图元素，再使用大型语言模型（LLM）进行过滤以提升精度。在医疗、农业和文学数据集上，针对 Microsoft-GraphRAG 和 LightRAG 系统进行实验评估。",
      "result": "在相同查询预算下，AGEA 显著优于先前的攻击基线，恢复的实体和关系比例高达 90%，同时保持高精度，证明其在有限查询资源下高效提取图结构的优势，具体数据如精确度提升未在摘要中明确说明，但基于恢复率显示性能改进。",
      "conclusion": "研究证实 GraphRAG 系统即使在严格查询限制下也高度脆弱于结构化代理攻击，AGEA 框架的提出揭示了安全漏洞，具有重要学术价值，可推动防御机制开发。未来工作可能包括扩展攻击场景和加强系统防护，但摘要未明确说明具体方向。",
      "tags": [
        "GraphRAG",
        "Agentic Attack",
        "Graph Extraction",
        "Large Language Model",
        "Black-Box Setting"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:10.215779Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14658",
    "title": "Say Anything but This: When Tokenizer Betrays Reasoning in LLMs",
    "authors": [
      "Navid Ayoobi",
      "Marcus I Armstrong",
      "Arjun Mukherjee"
    ],
    "abstract": "Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct \"words\" even when they are semantically identical at the text level. In this work, we show that tokenization can betray LLM reasoning through one-to-many token ID mappings. We introduce a tokenization-consistency probe that requires models to replace designated target words in context while leaving all other content unchanged. The task is intentionally simple at the surface level, enabling us to attribute failures to tokenizer-detokenizer artifacts rather than to knowledge gaps or parameter limitations. Through analysis of over 11000 replacement trials across state-of-the-art open-source LLMs, we find a non-trivial rate of outputs exhibit phantom edits: cases where models operate under the illusion of correct reasoning, a phenomenon arising from tokenizer-induced representational defects. We further analyze these cases and provide a taxonomy of eight systematic tokenizer artifacts, including whitespace-boundary shifts and intra-word resegmentation. These findings indicate that part of apparent reasoning deficiency originates in the tokenizer layer, motivating tokenizer-level remedies before incurring the cost of training ever-larger models on ever-larger corpora.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14658.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14658",
    "published": "2026-01-21T05:09:09Z",
    "updated": "2026-01-21T05:09:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究揭示了大型语言模型中标记化器非唯一编码导致的推理脆弱性，并提出探测方法来量化这一现象。",
      "motivation": "研究动机源于大型语言模型（LLMs）推理基于离散标记ID序列，但现代子词标记化器产生非唯一编码，导致多个标记ID序列对应相同表面字符串。这种表示不匹配创建了未测量的脆弱性，使推理过程可能失败，LLMs可能错误处理语义相同的内部表示。现有方法常忽略标记化器影响，问题的重要性在于揭示潜在缺陷源，影响模型稳健性和推理准确性。",
      "method": "研究方法引入一种标记化一致性探测任务，要求模型在上下文中替换指定目标词，同时保持其他内容不变。该任务在表面层次上故意设计简单，以便将失败归因于标记化器-去标记化器伪影，而非知识或参数限制。通过分析超过11000次替换试验，涉及最先进的开源LLMs，该方法系统识别标记化器引起的缺陷，并聚焦于伪影分析。",
      "result": "实验结果在11000次试验中发现phantom edits的出现率非平凡，表明模型因标记化缺陷在推理中产生幻觉。这些案例被分析并分类为八种系统标记化器伪影，如空白边界偏移和词内再分割。结果显示部分推理缺陷源自标记化器层，与现有方法相比，强调了标记化器在模型性能中的关键作用，量化了脆弱性。",
      "conclusion": "结论指出本研究贡献在于揭示标记化器在LLM推理中的脆弱性并提供伪影分类。学术价值是为理解推理缺陷提供新视角，实际应用价值是建议在训练更大模型前实施标记化器级补救措施，以节省成本并提高稳健性。局限性包括未扩展到复杂任务，未来工作可开发改进标记化器或扩展分析范围。",
      "tags": [
        "Large Language Models",
        "Tokenizer",
        "Representational Mismatch",
        "Phantom Edits",
        "Tokenizer Artifacts"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:23.579793Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14653",
    "title": "Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport",
    "authors": [
      "Yuyu Liu",
      "Jiannan Yang",
      "Ziyang Yu",
      "Weishen Pan",
      "Fei Wang",
      "Tengfei Ma"
    ],
    "abstract": "Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.",
    "categories": [
      "cs.LG",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14653.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14653",
    "published": "2026-01-21T04:58:13Z",
    "updated": "2026-01-21T04:58:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了CROT算法，通过聚类正则化的最优传输高效处理单细胞数据中的补丁式缺失数据，提升插补准确性和运行效率。",
      "motivation": "单细胞测序数据中的缺失数据对提取生物洞察构成显著挑战，尤其在补丁式缺失场景下，数据不完整影响分析准确性。现有插补方法常假设数据均匀和完整，难以有效处理大面积缺失，限制了在生物和临床数据分析中的应用。本研究旨在解决这一关键问题，开发一种能适应结构化缺失数据的方法，以应对高维异构数据的复杂需求，推动相关领域的进步。",
      "method": "CROT算法基于最优传输框架，结合聚类正则化来处理表格格式的补丁缺失数据。它通过优化运输距离和引入聚类约束来捕获数据潜在结构，即使在高度缺失情况下也能保持鲁棒性。摘要未明确说明具体模型架构或数据集细节，但该方法针对大规模单细胞数据集设计，可能涉及高维特征处理，关键创新在于将最优传输与聚类结合，以高效恢复缺失值。",
      "result": "CROT在插补准确性上表现优越，显著减少了运行时间，展示了算法的高效率和可扩展性。与现有方法相比，它在处理大规模单细胞数据时能更有效地恢复缺失值，但摘要未提供具体性能指标如准确率提升百分比。结果强调了该方法在实际应用中的潜力，特别是在需要快速处理海量数据时，提升了整体分析流程的效率。",
      "conclusion": "本研究提出了鲁棒的插补方法CROT，适用于异质和高维数据集的结构化缺失数据，解决了生物和临床数据分析中的关键挑战。其学术价值在于创新结合了最优传输和聚类技术，实践价值在于提升了数据处理的效率和准确性。未来工作可探索更广泛的应用场景或进一步优化算法，以克服潜在局限性如对不同数据类型的适应性。",
      "tags": [
        "Optimal Transport",
        "Imputation",
        "Single-cell Sequencing",
        "Missing Data",
        "Clustering"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:51.690094Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14652",
    "title": "MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks",
    "authors": [
      "Zixuan Ke",
      "Yifei Ming",
      "Austin Xu",
      "Ryan Chin",
      "Xuan-Phi Nguyen",
      "Prathyusha Jwalapuram",
      "Semih Yavuz",
      "Caiming Xiong",
      "Shafiq Joty"
    ],
    "abstract": "While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.14652.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14652",
    "published": "2026-01-21T04:57:02Z",
    "updated": "2026-01-21T04:57:02Z",
    "comment": "Preprint; Work in Progress",
    "light_analysis": {
      "overview": "论文提出了MAS-Orchestra框架和MASBENCH基准，通过全局编排和强化学习改进多智能体系统的编排与效能分析。",
      "motivation": "当前多智能体系统（MAS）的自动编排方法存在两个关键问题：方法复杂性和效能不确定性。方法复杂性体现在序列化执行限制了全局推理和可扩展性；效能不确定性源于缺乏与单智能体系统（SAS）的比较验证，导致无法确定MAS的实际优势。这些问题限制了MAS在提升智能协调方面的潜力，因此需要更有效的编排框架和评估基准来促进MAS的应用和发展。",
      "method": "论文提出了MAS-Orchestra框架，将多智能体编排表述为一个函数调用强化学习问题，实现全局编排。关键创新包括抽象复杂子智能体为可调用函数，一次性生成整个MAS系统，并隐藏内部执行细节以促进系统级推理。此外，引入了MASBENCH基准，通过五个维度（深度、水平、广度、并行性和鲁棒性）来系统分析任务结构，指导MAS训练和评估。",
      "result": "MAS-Orchestra在公共基准如数学推理、多跳问答和基于搜索的问答上实现了持续改进，但摘要未明确提供具体性能数据。通过MASBENCH的分析，研究发现MAS的优势并非普遍存在，而是高度依赖于任务结构、验证协议以及编排器和子智能体的能力。与基线方法相比，MAS-Orchestra在指定任务上表现出更好的性能，凸显了全局编排的有效性。",
      "conclusion": "论文的主要贡献是MAS-Orchestra框架和MASBENCH基准，它们促进了对多智能体系统的更好训练和理解，揭示了MAS优势的条件。学术价值在于提出了创新的编排方法和评估体系，实际应用价值则体现在更有效地设计和部署多智能体系统。未来工作可进一步探索不同任务环境下的优化和扩展，但摘要未明确说明局限性。",
      "tags": [
        "Multi-Agent Systems",
        "Reinforcement Learning",
        "Function-Calling",
        "Benchmarking",
        "Holistic Orchestration"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:21.858011Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14651",
    "title": "READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection",
    "authors": [
      "Chenglizhao Chen",
      "Boze Li",
      "Mengke Song",
      "Dehao Feng",
      "Xinyu Liu",
      "Shanchen Pang",
      "Jufeng Yang",
      "Hui Yu"
    ],
    "abstract": "Depression is a severe global mental health issue that impairs daily functioning and overall quality of life. Although recent audio-visual approaches have improved automatic depression detection, methods that ignore emotional cues often fail to capture subtle depressive signals hidden within emotional expressions. Conversely, those incorporating emotions frequently confuse transient emotional expressions with stable depressive symptoms in feature representations, a phenomenon termed \\emph{Emotional Ambiguity}, thereby leading to detection errors. To address this critical issue, we propose READ-Net, the first audio-visual depression detection framework explicitly designed to resolve Emotional Ambiguity through Adaptive Feature Recalibration (AFR). The core insight of AFR is to dynamically adjust the weights of emotional features to enhance depression-related signals. Rather than merely overlooking or naively combining emotional information, READ-Net innovatively identifies and preserves depressive-relevant cues within emotional features, while adaptively filtering out irrelevant emotional noise. This recalibration strategy significantly clarifies feature representations, and effectively mitigates the persistent challenge of emotional interference. Additionally, READ-Net can be easily integrated into existing frameworks for improved performance. Extensive evaluations on three publicly available datasets show that READ-Net outperforms state-of-the-art methods, with average gains of 4.55\\% in accuracy and 1.26\\% in F1-score, demonstrating its robustness to emotional disturbances and improving audio-visual depression detection.",
    "categories": [
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14651.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14651",
    "published": "2026-01-21T04:55:10Z",
    "updated": "2026-01-21T04:55:10Z",
    "comment": "12 pages",
    "light_analysis": {
      "overview": "READ-Net通过自适应特征重校准技术，首次解决音视频抑郁症检测中的情感模糊问题，显著提升检测性能。",
      "motivation": "抑郁症是全球严重的心理健康问题，自动检测有助于早期干预。现有音视频方法在利用情感线索时存在不足：一些忽视情感，无法捕捉隐藏的抑郁信号；另一些则混淆瞬时情感表达与稳定抑郁症状，导致情感模糊和检测错误。这凸显了开发能区分情感噪声与抑郁特征的新方法的必要性，以提高检测准确性和鲁棒性。",
      "method": "READ-Net采用自适应特征重校准（AFR）技术，核心是动态调整音视频数据中情感特征的权重。AFR通过分析情感表达，识别并保留与抑郁相关的线索，同时自适应过滤掉无关的情感噪声。该创新策略澄清了特征表示，缓解了情感干扰，且框架设计灵活，可轻松集成到现有抑郁症检测系统中，无需大规模重构。",
      "result": "在三个公开数据集上的广泛评估显示，READ-Net优于最先进方法，平均准确率提升4.55%，F1得分提升1.26%。这些结果表明该框架在处理情感干扰方面具有鲁棒性，有效提高了音视频抑郁症检测的性能。与基线方法对比，READ-Net通过解决情感模糊问题，实现了更可靠和稳定的检测效果。",
      "conclusion": "本研究的主要贡献是提出了READ-Net及其核心的自适应特征重校准技术，成功解决了音视频抑郁症检测中的情感模糊挑战。这为自动心理健康监测提供了更精确的工具，具有重要学术价值和实际应用潜力。尽管摘要未明确说明局限性，但未来工作可探索更广泛的数据集或优化重校准策略，以进一步提升泛化能力。",
      "tags": [
        "Audio-Visual Depression Detection",
        "Adaptive Feature Recalibration",
        "Emotional Ambiguity",
        "Feature Representation",
        "Machine Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:29.148684Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14637",
    "title": "Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis",
    "authors": [
      "James Brock",
      "Ce Zhang",
      "Nantheera Anantrasirichai"
    ],
    "abstract": "The increasing availability of high-resolution satellite imagery, together with advances in deep learning, creates new opportunities for enhancing forest monitoring workflows. Two central challenges in this domain are pixel-level change detection and semantic change interpretation, particularly for complex forest dynamics. While large language models (LLMs) are increasingly adopted for data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored, especially beyond urban environments. We introduce Forest-Chat, an LLM-driven agent designed for integrated forest change analysis. The proposed framework enables natural language querying and supports multiple RSICI tasks, including change detection, change captioning, object counting, deforestation percentage estimation, and change reasoning. Forest-Chat builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration, and incorporates zero-shot change detection via a foundation change detection model together with an interactive point-prompt interface to support fine-grained user guidance. To facilitate adaptation and evaluation in forest environments, we introduce the Forest-Change dataset, comprising bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated through a combination of human annotation and rule-based methods. Experimental results demonstrate that Forest-Chat achieves strong performance on Forest-Change and on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI, for joint change detection and captioning, highlighting the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and analytical efficiency in forest change analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14637.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14637",
    "published": "2026-01-21T04:23:33Z",
    "updated": "2026-01-21T04:23:33Z",
    "comment": "22 pages, 8 figures, 7 tables, Submitted to Ecological Informatics",
    "light_analysis": {
      "overview": "论文提出了Forest-Chat，一个基于大语言模型的代理，用于集成森林变化分析，通过自然语言查询和多任务支持提高遥感图像解释的交互性和效率。",
      "motivation": "随着高分辨率卫星影像和深度学习的进步，森林监测工作流面临像素级变化检测和语义变化解释的挑战，尤其是在复杂森林动态中。现有方法中，大型语言模型与视觉语言模型在遥感图像变化解释的集成尚未充分探索，特别是在非城市环境，这限制了分析的交互性和可解释性。因此，本研究旨在解决这些不足，推动森林变化分析的自动化与智能化。",
      "method": "Forest-Chat框架基于多级变化解释视觉语言骨干，采用大型语言模型进行任务编排。核心创新包括零样本变化检测，通过基础变化检测模型实现，以及交互点提示界面，支持用户提供细粒度指导以增强分析精度。该方法支持多种遥感图像变化解释任务，如变化检测、变化字幕、对象计数等，并引入了Forest-Change数据集，包含双时相卫星影像、像素级变化掩码和多粒度语义变化字幕。",
      "result": "实验结果显示，Forest-Chat在Forest-Change数据集和LEVIR-MCI-Trees子集上取得了强性能，特别是在联合变化检测和字幕任务中。摘要未明确说明具体性能指标，但与基线方法相比，其展示了在提高分析效率方面的潜力，验证了交互式LLM驱动系统的有效性。",
      "conclusion": "本研究的主要贡献是Forest-Chat，一个交互式LLM驱动的遥感图像变化解释系统，提升了森林变化分析的可访问性、可解释性和效率。其学术价值在于探索了LLMs与VLMs在非城市环境中的集成，实际应用价值在于支持森林监测的自动化工作流。未来工作可扩展至其他环境或集成更多数据类型。",
      "tags": [
        "Large Language Model",
        "Vision-Language Model",
        "Change Detection",
        "Zero-shot Learning",
        "Interactive Prompting"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:26.704023Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14633",
    "title": "Relational Graph Modeling for Credit Default Prediction: Heterogeneous GNNs and Hybrid Ensemble Learning",
    "authors": [
      "Yvonne Yang",
      "Eranki Vasistha"
    ],
    "abstract": "Credit default risk arises from complex interactions among borrowers, financial institutions, and transaction-level behaviors. While strong tabular models remain highly competitive in credit scoring, they may fail to explicitly capture cross-entity dependencies embedded in multi-table financial histories. In this work, we construct a massive-scale heterogeneous graph containing over 31 million nodes and more than 50 million edges, integrating borrower attributes with granular transaction-level entities such as installment payments, POS cash balances, and credit card histories.   We evaluate heterogeneous graph neural networks (GNNs), including heterogeneous GraphSAGE and a relation-aware attentive heterogeneous GNN, against strong tabular baselines. We find that standalone GNNs provide limited lift over a competitive gradient-boosted tree baseline, while a hybrid ensemble that augments tabular features with GNN-derived customer embeddings achieves the best overall performance, improving both ROC-AUC and PR-AUC. We further observe that contrastive pretraining can improve optimization stability but yields limited downstream gains under generic graph augmentations. Finally, we conduct structured explainability and fairness analyses to characterize how relational signals affect subgroup behavior and screening-oriented outcomes.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14633.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14633",
    "published": "2026-01-21T04:13:41Z",
    "updated": "2026-01-21T04:13:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出混合集成学习方法，结合异构图神经网络（GNNs）生成的客户嵌入与表格特征，显著提升信用违约预测性能。",
      "motivation": "信用违约风险源自借款人、金融机构和交易级行为间的复杂交互，现有强表格模型在信用评分中虽具竞争力，但难以显式捕获多表财务历史中的跨实体依赖，这限制了风险评估的全面性。本研究旨在通过关系图建模弥补这一不足，以更精确地分析和预测信用风险。",
      "method": "本研究构建了一个大规模异构图，包含超过3100万个节点和5000万条边，整合借款人属性与交易级实体如分期付款、POS余额和信用卡历史。方法上评估异构图神经网络（GNNs），包括异构GraphSAGE和关系感知注意力异构GNN，关键创新在于提出混合集成方法，用GNN派生的客户嵌入增强表格特征，并探索对比预训练以改进优化稳定性。",
      "result": "实验结果表明，独立的GNNs在强梯度提升树基线上提升有限，而混合集成方法实现了最佳整体性能，提高了ROC-AUC和PR-AUC指标。对比预训练增强了优化稳定性，但在通用图增强下下游性能增益有限。此外，通过结构化可解释性和公平性分析，揭示了关系信号对子组行为和筛选结果的影响。",
      "conclusion": "本研究的主要贡献是验证了混合集成方法在结合异构GNNs和表格特征时的有效性，显著提升了信用违约预测的准确性，为金融风险评估提供了新框架。方法强调了关系建模的重要性，具有学术和实用价值；潜在局限性包括对比预训练的有限增益，未来工作可探索领域特定的图增强策略。",
      "tags": [
        "Heterogeneous Graph Neural Networks",
        "GraphSAGE",
        "Attention Mechanisms",
        "Ensemble Learning",
        "Contrastive Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:20.213506Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14625",
    "title": "Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection",
    "authors": [
      "Yingsong Huang",
      "Hui Guo",
      "Jing Huang",
      "Bing Bai",
      "Qi Xiong"
    ],
    "abstract": "The rapid progress of diffusion models highlights the growing need for detecting generated images. Previous research demonstrates that incorporating diffusion-based measurements, such as reconstruction error, can enhance the generalizability of detectors. However, ignoring the differing impacts of aleatoric and epistemic uncertainty on reconstruction error can undermine detection performance. Aleatoric uncertainty, arising from inherent data noise, creates ambiguity that impedes accurate detection of generated images. As it reflects random variations within the data (e.g., noise in natural textures), it does not help distinguish generated images. In contrast, epistemic uncertainty, which represents the model's lack of knowledge about unfamiliar patterns, supports detection. In this paper, we propose a novel framework, Diffusion Epistemic Uncertainty with Asymmetric Learning~(DEUA), for detecting diffusion-generated images. We introduce Diffusion Epistemic Uncertainty~(DEU) estimation via the Laplace approximation to assess the proximity of data to the manifold of diffusion-generated samples. Additionally, an asymmetric loss function is introduced to train a balanced classifier with larger margins, further enhancing generalizability. Extensive experiments on large-scale benchmarks validate the state-of-the-art performance of our method.",
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14625.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14625",
    "published": "2026-01-21T03:57:15Z",
    "updated": "2026-01-21T03:57:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了DEUA框架，结合扩散认知不确定性和非对称学习，用于检测扩散模型生成的图像，提升了检测器的泛化能力和性能。",
      "motivation": "随着扩散模型的快速发展，检测其生成图像的需求日益增长。现有方法常利用重构误差来增强检测器，但忽视了aleatoric不确定性和epistemic不确定性对重构误差的不同影响，这损害了检测效果。Aleatoric不确定性源于数据固有噪声，如自然纹理中的随机变化，导致模糊性，不利于区分生成图像；而epistemic不确定性反映模型对不熟悉模式的认知不足，反而有助于检测。因此，需要一种方法来解决这一问题，以提高检测器的准确性和泛化能力，应对生成图像滥用的挑战。",
      "method": "论文提出了DEUA框架，包括两个核心创新点：一是通过Laplace近似估计Diffusion Epistemic Uncertainty，用于评估数据与扩散生成样本流形的接近度，从而量化模型对生成图像的认知不确定性；二是引入非对称损失函数，通过训练平衡分类器并增大边距，进一步增强泛化性能。该方法基于扩散模型，但摘要未明确说明具体使用的数据集和模型架构，仅提到在大规模基准上进行验证。",
      "result": "在大规模基准上进行了广泛实验，验证了DEUA方法达到了state-of-the-art性能，显示出优异的检测准确性和泛化能力。与基线方法相比，该方法在多个测试中表现更佳，表明结合epistemic不确定性和非对称学习能有效提升检测效果。摘要未提供具体性能指标如准确率数值，但强调了在基准测试中实现了最佳性能。",
      "conclusion": "DEUA框架通过创新地结合扩散认知不确定性和非对称学习，显著提升了扩散生成图像检测的准确性和泛化能力。学术上，本研究首次将epistemic不确定性分析与非对称学习应用于图像检测，为相关领域提供了新思路。实际应用价值在于帮助检测虚假信息和生成图像滥用，如深度伪造检测。未来工作方向摘要未明确说明，但可推断可能包括扩展到其他生成模型或复杂场景。",
      "tags": [
        "Diffusion Models",
        "Epistemic Uncertainty",
        "Asymmetric Learning",
        "Image Detection",
        "Laplace Approximation"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:23.248632Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14615",
    "title": "SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation",
    "authors": [
      "Xichen Zhang",
      "Ziyi He",
      "Yinghao Zhu",
      "Sitong Wu",
      "Shaozuo Yu",
      "Meng Chu",
      "Wenhu Zhang",
      "Haoru Tan",
      "Jiaya Jia"
    ],
    "abstract": "Search agents have emerged as a pivotal paradigm for solving open-ended, knowledge-intensive reasoning tasks. However, training these agents via Reinforcement Learning (RL) faces a critical dilemma: interacting with live commercial Web APIs is prohibitively expensive, while relying on static data snapshots often introduces noise due to data misalignment. This misalignment generates corrupted reward signals that destabilize training by penalizing correct reasoning or rewarding hallucination. To address this, we propose SearchGym, a simulation environment designed to bootstrap robust search agents. SearchGym employs a rigorous generative pipeline to construct a verifiable knowledge graph and an aligned document corpus, ensuring that every reasoning task is factually grounded and strictly solvable. Building on this controllable environment, we introduce SearchGym-RL, a curriculum learning methodology that progressively optimizes agent policies through purified feedback, evolving from basic interactions to complex, long-horizon planning. Extensive experiments across the Llama and Qwen families demonstrate strong Sim-to-Real generalization. Notably, our Qwen2.5-7B-Base model trained within SearchGym surpasses the web-enhanced ASearcher baseline across nine diverse benchmarks by an average relative margin of 10.6%. Our results validate that high-fidelity simulation serves as a scalable and highly cost-effective methodology for developing capable search agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14615.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14615",
    "published": "2026-01-21T03:16:17Z",
    "updated": "2026-01-21T03:16:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出SearchGym模拟环境，通过高保真仿真和课程学习引导鲁棒的搜索代理，实现从模拟到现实的强泛化。",
      "motivation": "搜索代理在处理开放端、知识密集型推理任务中至关重要，但使用强化学习训练时面临成本高和数据噪声的挑战：实时商业Web API交互费用昂贵，而静态数据快照常因数据不对齐引入噪声，导致奖励信号腐败，使训练不稳定。现有方法在成本和数据质量方面的不足限制了代理的鲁棒性和可扩展性，因此需要一种高效、可控的训练环境来应对这一问题。",
      "method": "论文提出SearchGym模拟环境，采用严格的生成管道构建可验证的知识图谱和对齐的文档语料库，确保推理任务基于事实并严格可解，从而消除数据噪声。在此基础上，引入SearchGym-RL课程学习方法，通过纯化反馈逐步优化代理策略，从基本交互发展到复杂长程规划。关键创新点在于可控环境设计和高保真模拟，在Llama和Qwen模型家族上实施训练，实现高效的代理引导。",
      "result": "实验在Llama和Qwen模型上进行，显示SearchGym能实现强Sim-to-Real泛化。具体而言，Qwen2.5-7B-Base模型经过SearchGym训练后，在九个多样化基准测试中平均相对提升了10.6%，超越了基于Web增强的ASearcher基线。这验证了模拟环境在提高代理性能方面的有效性，并提供量化数据证明方法优于现有基线，增强了搜索代理的准确性和稳定性。",
      "conclusion": "论文验证了高保真模拟作为开发强大搜索代理的可扩展和高度成本效益方法，主要贡献在于提出SearchGym环境，克服训练中的成本和数据对齐问题。学术上为强化学习在搜索任务中的应用提供新思路；实践上降低训练开销，提升代理泛化能力。未来工作可扩展模拟范围或优化课程学习策略，以进一步增强方法的普适性和效率。",
      "tags": [
        "Search Agents",
        "Reinforcement Learning",
        "Simulation Environment",
        "Curriculum Learning",
        "Knowledge Graph"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:03.024315Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14610",
    "title": "Learning Consistent Taxonomic Classification through Hierarchical Reasoning",
    "authors": [
      "Zhenghong Li",
      "Kecheng Zheng",
      "Haibin Ling"
    ],
    "abstract": "While Vision-Language Models (VLMs) excel at visual understanding, they often fail to grasp hierarchical knowledge. This leads to common errors where VLMs misclassify coarser taxonomic levels even when correctly identifying the most specific level (leaf level). Existing approaches largely overlook this issue by failing to model hierarchical reasoning. To address this gap, we propose VL-Taxon, a two-stage, hierarchy-based reasoning framework designed to improve both leaf-level accuracy and hierarchical consistency in taxonomic classification. The first stage employs a top-down process to enhance leaf-level classification accuracy. The second stage then leverages this accurate leaf-level output to ensure consistency throughout the entire taxonomic hierarchy. Each stage is initially trained with supervised fine-tuning to instill taxonomy knowledge, followed by reinforcement learning to refine the model's reasoning and generalization capabilities. Extensive experiments reveal a remarkable result: our VL-Taxon framework, implemented on the Qwen2.5-VL-7B model, outperforms its original 72B counterpart by over 10% in both leaf-level and hierarchical consistency accuracy on average on the iNaturalist-2021 dataset. Notably, this significant gain was achieved by fine-tuning on just a small subset of data, without relying on any examples generated by other VLMs.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14610.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14610",
    "published": "2026-01-21T03:00:00Z",
    "updated": "2026-01-21T03:00:00Z",
    "comment": "12 pages, 4 figures",
    "light_analysis": {
      "overview": "论文提出了VL-Taxon框架，通过两阶段层次推理和强化学习，提高视觉-语言模型在层级分类中的准确性和一致性。",
      "motivation": "该研究旨在解决视觉-语言模型在层次知识方面的缺陷，这些缺陷导致分类错误，即使在叶子级识别正确时，也可能误分类较粗的层级。问题重要，因为准确的多层级分类对于生物分类学等应用至关重要。现有方法大多忽视了层次推理，未能建模完整层级关系，导致分类不一致，因此需要改进。",
      "method": "论文提出VL-Taxon框架，一个两阶段层次推理方法。第一阶段采用自上而下过程提升叶子级分类准确性；第二阶段利用叶子级输出确保整个层级一致性。每个阶段先用监督微调灌输分类知识，后用强化学习优化推理和泛化能力。实现基于Qwen2.5-VL-7B模型，并在iNaturalist-2021数据集上实验。",
      "result": "在iNaturalist-2021数据集上，VL-Taxon框架在叶子级和层级一致性准确性上表现优异。基于Qwen2.5-VL-7B模型，平均提高超过10%的准确率，相比原始的72B版本。改进通过少量数据微调实现，不依赖其他VLM示例，显示高效性。",
      "conclusion": "主要贡献是VL-Taxon框架，结合层次推理、监督微调和强化学习，增强视觉-语言模型的分类能力。学术价值在于改进模型对层次知识的理解，实际应用潜力包括生物分类等领域。未来工作可能扩展至其他数据集以提高泛化，摘要未明确说明具体局限性。",
      "tags": [
        "Vision-Language Models",
        "Hierarchical Reasoning",
        "Taxonomic Classification",
        "Supervised Fine-tuning",
        "Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:54.368531Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14605",
    "title": "U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization",
    "authors": [
      "Weiwei Ma",
      "Xiaobing Yu",
      "Peijie Qiu",
      "Jin Yang",
      "Pan Xiao",
      "Xiaoqi Zhao",
      "Xiaofeng Liu",
      "Tomo Miyazaki",
      "Shinichiro Omachi",
      "Yongsong Huang"
    ],
    "abstract": "In clinical practice, medical segmentation datasets are often limited and heterogeneous, with variations in modalities, protocols, and anatomical targets across institutions. Existing deep learning models struggle to jointly learn from such diverse data, often sacrificing either generalization or domain-specific knowledge. To overcome these challenges, we propose a joint training method called Universal Harmonization (U-Harmony), which can be integrated into deep learning-based architectures with a domain-gated head, enabling a single segmentation model to learn from heterogeneous datasets simultaneously. By integrating U-Harmony, our approach sequentially normalizes and then denormalizes feature distributions to mitigate domain-specific variations while preserving original dataset-specific knowledge. More appealingly, our framework also supports universal modality adaptation, allowing the seamless learning of new imaging modalities and anatomical classes. Extensive experiments on cross-institutional brain lesion datasets demonstrate the effectiveness of our approach, establishing a new benchmark for robust and adaptable 3D medical image segmentation models in real-world clinical settings.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14605.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14605",
    "published": "2026-01-21T02:43:39Z",
    "updated": "2026-01-21T02:43:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出U-Harmony联合训练方法，通过通用协调提升医学图像分割模型在异质数据集上的性能，实现高效学习与泛化。",
      "motivation": "在临床实践中，医学分割数据集常因机构间成像模态、采集协议和解剖目标差异而呈现有限性和异质性，导致深度学习模型难以进行联合学习。现有方法在处理这种多样数据时，往往需要在泛化能力与领域特定知识之间做出权衡，从而影响分割模型的准确性和适应性。这限制了模型在真实世界临床环境中的应用，因此亟需一种新方法来解决异质数据集的协调问题。",
      "method": "本研究提出Universal Harmonization（U-Harmony）方法，集成到基于深度学习的分割架构中，采用域门控头设计。核心创新在于顺序执行特征分布的归一化和去归一化操作，以减轻领域特定变化，同时保留原始数据集的特定知识。此外，该方法支持通用模态适应，能够无缝融入新的成像模态和解剖类别，增强模型的扩展性和灵活性，无需重新训练整个模型。",
      "result": "在跨机构脑损伤数据集上进行了广泛实验，结果表明U-Harmony方法显著提升了分割模型的稳健性和适应性。实验证明该方法能有效处理异质数据，与基线方法相比，实现了更好的性能，为3D医学图像分割设立了新基准。摘要未明确说明具体的准确率提升或效率改进数值，但强调了在现实世界临床环境中的有效性。",
      "conclusion": "U-Harmony方法通过联合训练和特征协调，成功解决了医学分割中异质数据学习的挑战，提升了模型的泛化能力和应用价值。该研究不仅为临床实践提供了更稳健的分割工具，还推动了深度学习在医学图像分析中的适应性发展。未来工作可探索扩展到其他医学任务或更多数据集，并进一步验证其通用性和局限性。",
      "tags": [
        "Joint Training",
        "Universal Harmonization",
        "Medical Image Segmentation",
        "Domain Adaptation",
        "Feature Normalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:19.428077Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14603",
    "title": "Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum",
    "authors": [
      "Jingru Li",
      "Yibo Fan",
      "Huan Li"
    ],
    "abstract": "Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\\times$ relative to the well-tuned Muon following the recent benchmark.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14603.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14603",
    "published": "2026-01-21T02:41:56Z",
    "updated": "2026-01-21T02:41:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出方差自适应的 Muon-NSR 和 Muon-VS 方法，通过噪声信噪比调制和方差缩放加速大型语言模型的预训练过程。",
      "motivation": "大型语言模型在自然语言处理任务中表现优异，但其预训练过程计算成本极高，使得优化器效率成为关键实际考量。现有优化器如 Adam 具有方差自适应特性，但针对 Muon 方法，进一步引入方差自适应归一化可以提升训练效率。本研究动机是改进 Muon 优化器，通过结合方差自适应机制，以减少预训练所需的迭代次数和计算资源，解决现有方法在方差处理上的潜在不足。",
      "method": "研究方法基于 Muon 优化器，该优化器使用正交动量更新模拟元素级符号操作。本论文提出两个变体：Muon-NSR 和 Muon-VS。Muon-NSR 在动量正交化前应用噪声信噪比调制；Muon-VS 则执行基于方差的缩放，无需引入额外超参数。关键创新是在动量更新中集成方差自适应归一化，以适应训练过程中的动态变化。实验使用 GPT-2 和 LLaMA 模型进行预训练验证。",
      "result": "实验结果表明，在 GPT-2 和 LLaMA 的预训练中，Muon-NSR 和 Muon-VS 能显著加速收敛，并持续达到比精心调优的 AdamW 和 Muon 基线更低的验证损失。具体数据上，对于 LLaMA-1.2B 模型，新方法将达到目标验证损失所需的迭代次数减少了 1.36 倍，展示了其在提高训练效率方面的优越性。这一改进在多个基准测试中均得到验证，与基线方法相比性能提升明显。",
      "conclusion": "本研究的主要贡献是开发了方差自适应的 Muon-NSR 和 Muon-VS 方法，有效加速了大型语言模型的预训练过程。这为优化器设计提供了新方向，具有重要的学术价值，同时在实际应用中能显著降低计算成本，促进 LLM 的广泛部署。未来研究可探索这些方法在其他深度学习任务或更大规模模型中的适用性和扩展性，摘要未明确说明局限性。",
      "tags": [
        "Large Language Model",
        "Variance Adaptation",
        "Momentum Optimization",
        "Noise-to-Signal Ratio",
        "Orthogonal Updates"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:20.593245Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14602",
    "title": "3D Space as a Scratchpad for Editable Text-to-Image Generation",
    "authors": [
      "Oindrila Saha",
      "Vojtech Krs",
      "Radomir Mech",
      "Subhransu Maji",
      "Matheus Gadelha",
      "Kevin Blackburn-Matzen"
    ],
    "abstract": "Recent progress in large language models (LLMs) has shown that reasoning improves when intermediate thoughts are externalized into explicit workspaces, such as chain-of-thought traces or tool-augmented reasoning. Yet, visual language models (VLMs) lack an analogous mechanism for spatial reasoning, limiting their ability to generate images that accurately reflect geometric relations, object identities, and compositional intent. We introduce the concept of a spatial scratchpad -- a 3D reasoning substrate that bridges linguistic intent and image synthesis. Given a text prompt, our framework parses subjects and background elements, instantiates them as editable 3D meshes, and employs agentic scene planning for placement, orientation, and viewpoint selection. The resulting 3D arrangement is rendered back into the image domain with identity-preserving cues, enabling the VLM to generate spatially consistent and visually coherent outputs. Unlike prior 2D layout-based methods, our approach supports intuitive 3D edits that propagate reliably into final images. Empirically, it achieves a 32% improvement in text alignment on GenAI-Bench, demonstrating the benefit of explicit 3D reasoning for precise, controllable image generation. Our results highlight a new paradigm for vision-language models that deliberate not only in language, but also in space. Code and visualizations at https://oindrilasaha.github.io/3DScratchpad/",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14602.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14602",
    "published": "2026-01-21T02:40:19Z",
    "updated": "2026-01-21T02:40:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种新方法，通过引入3D空间作为推理草稿纸，来增强可编辑的文本到图像生成，改善空间一致性和可控性。",
      "motivation": "随着大语言模型（LLMs）的进展，外部化推理工作空间（如思维链）能提升推理能力，但视觉语言模型（VLMs）缺乏类似机制，在生成图像时难以准确反映几何关系、对象身份和组合意图。现有方法如基于2D布局的图像生成不足，限制了处理复杂空间结构的能力，导致图像质量下降和编辑困难。因此，本研究旨在开发一个3D推理基底，以弥合语言意图和图像合成之间的差距，解决VLMs在空间推理上的局限性，从而提高图像生成的精确性和可编辑性。",
      "method": "研究方法基于“空间草稿纸”概念，这是一个3D推理基底，用于连接文本提示和图像生成。首先，系统解析输入文本，识别主题和背景元素，并将它们实例化为可编辑的3D网格。然后，采用代理场景规划来确定物体的放置、方向和视角选择，确保空间布局合理。最后，通过身份保持渲染技术将3D布局转换为图像，使视觉语言模型能够生成空间一致和视觉连贯的输出。关键创新在于支持直观的3D编辑，允许用户修改3D场景，并确保这些更改可靠地传播到最终图像中，从而增强可控性。",
      "result": "在GenAI-Bench数据集上的实验表明，该方法实现了32%的文本对齐提升，显著优于先前基于2D布局的方法。这一结果证明了显式3D推理的有效性，生成图像在几何关系和对象身份上更准确，同时支持可靠的3D编辑操作。与基线相比，新方法在保持空间一致性和视觉质量方面表现更优，用户可以通过修改3D场景来直观调整图像，编辑效果能无缝反映在输出中，突出了3D推理在提升图像生成精度和可控性方面的潜力。",
      "conclusion": "本研究的主要贡献是提出了一种新范式，通过将3D空间作为推理工作空间，来增强视觉语言模型的空间推理能力，从而提高文本到图像生成的精确性和可控性。它强调了在语言和空间双重维度上进行推理的重要性，为未来研究开辟了方向，如扩展3D推理到更复杂的视觉任务或集成更先进的3D建模技术。这项工作具有学术价值，推动了VLMs的发展，并在实际应用中提升了图像编辑和合成的灵活性，尽管可能面临3D数据获取或计算复杂性的限制。",
      "tags": [
        "Spatial Reasoning",
        "3D Modeling",
        "Text-to-Image Generation",
        "Visual Language Models",
        "Agentic Scene Planning"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:44.738705Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14599",
    "title": "Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective",
    "authors": [
      "Xiao Hu",
      "Hong Xie",
      "Tao Tan",
      "Defu Lian",
      "Jianyu Han"
    ],
    "abstract": "A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.14599.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14599",
    "published": "2026-01-21T02:37:44Z",
    "updated": "2026-01-21T02:37:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过多臂赌博机学习的视角，提出自下而上的实验管道来揭示 LLM 强化微调中设计选择的作用和瓶颈。",
      "motivation": "现有研究提出了多种启发式方法来优化大型语言模型的强化微调，但这些方法的有效性常常不一致，使得该领域难以捉摸。论文指出两个基本问题尚未明确：一是每个优化选择的具体作用是什么，二是哪些选择是性能提升的瓶颈。这种不确定性源于微调过程中的多个纠缠混淆因素，导致研究结果难以比较和评估。因此，有必要系统性地分析这些设计选择，以提供更清晰的理论和实践指导。",
      "method": "论文提出一个自下而上的实验管道来系统分析强化微调的设计选择。底层采用极简配置，包括单一训练数据、每轮一个 rollout，并将奖励直接作为学习信号，避免了优势函数设计的复杂性。这种方法将强化微调与多臂赌博机学习联系起来，尤其是针对极大离散动作空间的情况，利用赌博机理论来支持实验结果。实验管道从极简配置开始，逐步向上扩展，一层一层地添加和评估各个设计选择，如数据多样性、rollout 数量和奖励函数优化，从而分离并检验每个因素的作用。实验基于三个不同的 LLM 和两个推理数据集进行。",
      "result": "实验在三个大型语言模型和两个推理数据集上进行，结果表明该自下而上的方法能够有效揭示强化微调中各个设计选择的作用和瓶颈。通过极简配置的扩展，论文识别了关键优化因素的贡献，并提供了新的理论见解。摘要未明确说明具体的性能指标如准确率提升，但结果强调了多臂赌博机学习视角的有效性，为未来研究提供了基础。与基线方法相比，该方法帮助澄清了先前不一致的声明，并指出了优化路径。",
      "conclusion": "本研究通过多臂赌博机学习的视角，重新审视了大型语言模型的强化微调过程，提出了一个自下而上的实验管道来系统分析设计选择。主要贡献在于澄清了优化选择的作用和瓶颈，为该领域提供了理论支持和实践指导。学术上，这一工作有助于统一和理解现有启发式方法的不一致性；实际应用中，可能引导更高效的微调策略设计。尽管研究聚焦于推理任务，但其方法可推广到其他场景。未来工作可以进一步探索具体优化技术的组合效应。",
      "tags": [
        "Large Language Models",
        "Reinforcement Fine-tuning",
        "Multi-armed Bandit Learning",
        "Reward Signal",
        "Experimental Pipeline"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:29.914388Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14594",
    "title": "LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning",
    "authors": [
      "Lianying Chao",
      "Linfeng Yin",
      "Peiyu Ren",
      "Yifan Jiang",
      "Qiaoyu Ren",
      "Dingcheng Shan",
      "Jing-cheng Pang",
      "Sijie Wu",
      "Xubin Li",
      "Kai Zhang"
    ],
    "abstract": "Video captioning models convert frames into visual tokens and generate descriptions with large language models (LLMs). Since encoding all frames is prohibitively expensive, uniform sampling is the default choice, but it enforces equal temporal coverage while ignoring the uneven events distribution. This motivates a Learnable Frame Selector (LFS) that selects temporally diverse and event-relevant frames. LFS explicitly models temporal importance to balance temporal diversity and event relevance, and employs a stratified strategy to ensure temporal coverage while avoiding clustering. Crucially, LFS leverages caption feedback from frozen video-LLMs to learn frame selection that directly optimizes downstream caption quality. Additionally, we identify the gap between existing benchmark and human's cognition. Thus, we introduce ICH-CC built from carefully designed questions by annotators that reflect human-consistent understanding of video. Experiments indicate that LFS consistently improves detailed video captioning across two representative community benchmarks and ICH-CC, achieving up to 2.0% gains on VDC and over 4% gains on ICH-CC. Moreover, we observe that enhanced captions with LFS leads to improved performance on video question answering. Overall, LFS provides an effective and easy-to-integrate solution for detailed video captioning.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14594.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14594",
    "published": "2026-01-21T02:26:48Z",
    "updated": "2026-01-21T02:26:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了可学习的帧选择器（LFS），通过选择事件相关和时间多样化的帧来优化视频描述质量。",
      "motivation": "视频描述模型通常使用大型语言模型处理帧，但编码所有帧成本高昂，因此默认采用均匀采样帧以减少计算开销。然而，均匀采样忽视了视频中事件分布不均的问题，导致时间覆盖缺乏多样性，关键事件可能被遗漏，从而限制了描述准确性和丰富性。这凸显了开发智能帧选择方法的必要性，以更好地平衡事件相关性和时间覆盖，提升视频理解性能。",
      "method": "LFS通过建模时间重要性来选择帧，结合事件相关性以实现事件感知和时间多样化的选择。它采用分层策略来确保整个视频时间线的均匀覆盖，避免帧选择过于集中。方法利用冻结的视频LLMs生成的描述反馈进行端到端学习，直接针对下游描述质量优化帧选择。此外，作者引入了新基准ICH-CC，基于人工设计的视频问题，旨在弥合现有评估与人类认知的差距，并用于实验验证。",
      "result": "实验表明LFS在VDC基准上提升视频描述性能达2.0%，在新基准ICH-CC上增益超过4%，与基线均匀采样方法相比，这些改进一致且显著。LFS通过优化帧选择，不仅增强了详细描述的质量，还间接提高了视频问答任务的性能，验证了其在实际应用中的有效性。具体数据包括在多个基准上的准确率提升，体现了方法在捕捉事件相关性和时间多样性方面的优势。",
      "conclusion": "本论文的主要贡献是提出了LFS方法，解决了均匀采样在视频描述中忽略事件分布和时间多样性的问题，为视频描述提供了高效帧选择机制。其学术价值在于引入事件感知和时间多样化选择策略，并开发新基准ICH-CC以促进更符合人类认知的评估。这推动了视频理解领域的发展，具有实际应用潜力，未来工作可能包括扩展方法到更多视频任务或优化帧选择策略以适应复杂场景。",
      "tags": [
        "Large Language Model",
        "Video Captioning",
        "Learnable Frame Selection",
        "Temporal Diversity",
        "Event-Aware Model"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:48.512196Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14593",
    "title": "From Volumes to Slices: Computationally Efficient Contrastive Learning for Sequential Abdominal CT Analysis",
    "authors": [
      "Po-Kai Chiu",
      "Hung-Hsuan Chen"
    ],
    "abstract": "The requirement for expert annotations limits the effectiveness of deep learning for medical image analysis. Although 3D self-supervised methods like volume contrast learning (VoCo) are powerful and partially address the labeling scarcity issue, their high computational cost and memory consumption are barriers. We propose 2D-VoCo, an efficient adaptation of the VoCo framework for slice-level self-supervised pre-training that learns spatial-semantic features from unlabeled 2D CT slices via contrastive learning. The pre-trained CNN backbone is then integrated into a CNN-LSTM architecture to classify multi-organ injuries. In the RSNA 2023 Abdominal Trauma dataset, 2D-VoCo pre-training significantly improves mAP, precision, recall, and RSNA score over training from scratch. Our framework provides a practical method to reduce the dependency on labeled data and enhance model performance in clinical CT analysis. We release the code for reproducibility. https://github.com/tkz05/2D-VoCo-CT-Classifier",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14593.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14593",
    "published": "2026-01-21T02:26:31Z",
    "updated": "2026-01-21T02:26:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了2D-VoCo，一种计算效率高的切片级对比学习方法，用于腹部CT序列的自监督预训练，以降低计算成本并提升模型性能。",
      "motivation": "深度学习在医学图像分析中面临专家标注数据稀缺的挑战，限制了模型的实际应用。现有3D自监督方法如体积对比学习（VoCo）虽能部分缓解标注问题，但其高计算成本和内存消耗阻碍了临床部署。因此，本研究旨在开发更高效的自监督预训练方法，通过从3D体积转移到2D切片，减少资源需求并保持性能，以推动医学图像分析的自动化进程。",
      "method": "本研究提出2D-VoCo，将VoCo框架从3D体积对比学习高效适应到2D切片级自监督预训练。关键创新是利用对比学习从无标签的2D CT切片中学习空间语义特征，避免3D数据处理的复杂性。具体实现包括预训练一个CNN骨干网络，然后将其集成到CNN-LSTM架构中，用于多器官损伤的分类任务。实验基于RSNA 2023腹部创伤数据集进行验证。",
      "result": "在RSNA 2023腹部创伤数据集的实验中，2D-VoCo预训练框架相比于从头训练的基线方法，在多个性能指标上均取得显著提升，包括平均精度均值（mAP）、精确率、召回率和RSNA分数。尽管摘要未提供具体数值，但这些指标的改善证实了方法在降低计算成本的同时增强了分类准确性。与3D方法相比，2D-VoCo以更少资源实现了类似或更好性能，突显了其实际优势。",
      "conclusion": "本研究的主要贡献是开发了2D-VoCo，一个计算效率高的自监督预训练框架，用于减少对专家标注的依赖并提升腹部CT分析性能。学术上，它推动了自监督学习在医学图像处理领域的应用；实践中，为临床CT分析的自动化提供了可行方案。未来工作可探索更广泛的数据集或优化网络架构，以进一步验证和扩展该方法。",
      "tags": [
        "Contrastive Learning",
        "Self-Supervised Learning",
        "CNN",
        "LSTM",
        "Medical Image Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:23.496826Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14112",
    "title": "Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns",
    "authors": [
      "George Mihaila"
    ],
    "abstract": "Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14112.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14112",
    "published": "2026-01-20T16:06:34Z",
    "updated": "2026-01-21T14:35:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种名为ExpNet的轻量级神经网络，通过学习Transformer注意力模式到令牌重要性分数的映射，实现自动化的令牌归属解释，避免了现有方法依赖手动规则的局限。",
      "motivation": "随着Transformer模型在医疗、法律和金融等高风险领域的部署，模型的不透明性严重阻碍了信任和责任追究，这凸显了可解释AI的紧迫性。现有方法存在问题：基于注意力的解释技术依赖手动定义的特征聚合策略和固定归属规则，缺乏灵活性；而模型无关方法如LIME和SHAP将模型视为黑盒，通过输入扰动计算重要性分数，计算成本高昂且效率低下。因此，亟需一种更高效、自动化强的解释方法来解决这些不足，以提高模型可靠性和实际应用效果。",
      "method": "本文介绍了Explanation Network (ExpNet)，这是一个轻量级的神经网络，用于学习从Transformer自注意力模式到令牌级重要性分数的显式映射。关键创新在于ExpNet不依赖预定的手动规则，而是通过监督学习自动发现最佳的注意力特征组合，从而生成解释。该方法采用训练网络来分析和映射注意力模式中的关键特征。摘要未明确说明使用的具体数据集或模型架构细节，但强调了其轻量级设计，适合实际部署在基于Transformer的模型中，以提升解释的自动化和准确性。",
      "result": "论文在挑战性的跨任务环境中评估了ExpNet，并将其与广泛的模型无关方法和注意力技术进行基准测试，覆盖了四种方法家族。摘要未明确说明具体性能指标，如准确率提升百分比或效率改进的量化数据，因此基于现有信息推断，ExpNet可能在解释的自动化和质量上有所改进，但缺乏具体数据支撑。实验表明，ExpNet能与基线方法竞争，强调了其在避免手动规则依赖方面的优势，但详细信息需参考全文以获取更全面的结果对比和分析。",
      "conclusion": "本文的核心贡献是提出了ExpNet，一种基于监督学习的解释方法，通过自动学习注意力模式到令牌重要性分数的映射，克服了现有技术依赖预定义规则的局限性。研究的学术价值在于为Transformer模型的可解释性提供了新的自动化范式，增强了模型的透明度和可信度。实际应用中，ExpNet可用于高风险领域如医疗和金融，提升决策的可靠性和问责性。摘要未明确提及研究的局限性或未来工作方向，但这种方法为后续研究开辟了道路，以进一步优化解释的准确性和效率。",
      "tags": [
        "Transformer",
        "Self-Attention",
        "Explainable AI",
        "Neural Network",
        "Token Attribution"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:34.272639Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13964",
    "title": "RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning",
    "authors": [
      "Cheol-Hui Lee",
      "Hwa-Yeon Lee",
      "Dong-Joo Kim"
    ],
    "abstract": "The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69% and 8.80% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task--for example, Time Masking with a 62% probability for sleep stage classification and Crop & Resize with a 77% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at https://github.com/dlcjfgmlnasa/RL-BioAug.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.13964.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13964",
    "published": "2026-01-20T13:38:01Z",
    "updated": "2026-01-21T03:55:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "RL-BioAug 是一个利用标签高效的强化学习自主优化数据增强策略的框架，用于自监督的 EEG 表示学习。",
      "motivation": "在 EEG 任务中，自监督对比学习依赖数据增强，但 EEG 信号具有非平稳性，统计特性随时间变化，静态或随机增强策略难以保留内在信息，导致表示学习效果受限。这在实际应用中重要，因为 EEG 数据标记成本高，需提升无监督方法的性能以利用未标记数据。现有方法缺乏自适应策略，无法应对信号动态变化，本研究旨在通过智能增强策略解决此问题。",
      "method": "RL-BioAug 框架采用强化学习（RL）代理，以少量（10%）标签数据训练，自主决定最优数据增强策略（如 Time Masking 和 Crop & Resize）。编码器在自监督对比学习下学习鲁棒表示，关键创新是标签高效的 RL 指导，使代理能根据不同 EEG 任务（如睡眠阶段分类或癫痫检测）动态调整策略。框架基于 Sleep-EDFX 和 CHB-MIT 数据集进行实验，实现策略自适应性。",
      "result": "实验结果显示，RL-BioAug 在 Sleep-EDFX 和 CHB-MIT 数据集上显著优于随机增强策略，Macro-F1 分数分别提升 9.69% 和 8.80%。代理自主选择任务特定策略，例如睡眠阶段分类中 Time Masking 概率为 62%，癫痫检测中 Crop & Resize 概率为 77%，验证了策略优化的有效性。与基线方法对比，性能提升明显，证明了自适应增强的优势。",
      "conclusion": "该研究的贡献是提出了一种自主数据增强框架，减少对标签数据的依赖，提升了 EEG 表示学习的鲁棒性。学术价值在于将强化学习与自监督学习结合，为时间序列分析提供了新范式；实际应用价值在于改善 EEG 任务性能，未来可扩展至其他生物信号分析。摘要未明确说明局限性，但可能涉及策略泛化或计算开销，可进一步探索更多增强策略和模型优化。",
      "tags": [
        "Reinforcement Learning",
        "Self-Supervised Learning",
        "Contrastive Learning",
        "Data Augmentation",
        "EEG Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:15.793683Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13904",
    "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation",
    "authors": [
      "Jaeyoung Moon",
      "Youjin Choi",
      "Yucheon Park",
      "David Melhart",
      "Georgios N. Yannakakis",
      "Kyung-Joong Kim"
    ],
    "abstract": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.13904.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13904",
    "published": "2026-01-20T12:30:13Z",
    "updated": "2026-01-21T04:19:42Z",
    "comment": "CHI '26 Accepted paper",
    "light_analysis": {
      "overview": "本文提出了PREFAB方法，一种基于偏好学习的低成本自我注释技术，针对情感拐点区域以提高注释效率和质量。",
      "motivation": "在情感计算中，自我注释是收集情感状态标签的金标准，但现有方法依赖完整注释，要求用户在整个会话中持续标注，导致时间消耗大、认知负荷高，并易引发疲劳和错误。这限制了情感数据的高效收集，影响模型训练和应用效果。因此，研究旨在开发低成本的替代方案，优化注释过程，平衡效率与数据可靠性。",
      "method": "PREFAB方法基于峰值-结束规则和情感的序数表示，采用偏好学习模型检测相对情感变化，指导注释者仅标注选定情感拐点区域，而非整个会话。关键创新包括引入预览机制提供上下文提示辅助决策，并通过内插技术处理未标注部分。方法不依赖特定数据集，而是通过通用模型实现，适用于各种情感计算场景，并通过技术性能分析和用户研究进行评估。",
      "result": "通过技术性能研究和25名参与者的用户研究，PREFAB在建模情感拐点上优于基线方法，能显著减轻注释工作量，并在特定条件下减少时间负担。更重要的是，PREFAB提高了注释者的信心水平，而不降低注释质量，验证了其在平衡效率和准确性上的优势。与基线对比，PREFAB表现出更好的性能，为低预算自我注释提供了可行方案。",
      "conclusion": "本研究的主要贡献是提出了PREFAB方法，实现了低成本、高效率的自我注释，改进了情感计算中的数据收集流程。其学术价值在于整合偏好学习和峰值-结束规则，为情感建模提供新思路；实际应用价值在于降低注释负担，促进情感数据的大规模收集。局限性方面，摘要未明确说明未来工作方向，但可推断可能需要进一步优化模型或扩展应用场景。",
      "tags": [
        "Preference Learning",
        "Affective Modeling",
        "Low-Budget Annotation",
        "Peak-End Rule",
        "User Study"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:54.913971Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13761",
    "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution",
    "authors": [
      "Shengda Fan",
      "Xuyan Ye",
      "Yankai Lin"
    ],
    "abstract": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations. The code is available at https://github.com/RUCBM/DARC.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.13761.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13761",
    "published": "2026-01-20T09:12:27Z",
    "updated": "2026-01-21T04:54:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "DARC提出一个两阶段框架，通过难度校准的问题生成和非对称自蒸馏机制，稳定大型语言模型的自进化过程。",
      "motivation": "现有大型语言模型的自玩框架常因优化不稳定性而受限，主要问题包括：基于求解器依赖奖励反馈导致的非平稳目标，以及自生成伪标签引入的引导错误。这些问题削弱了自玩范式在实现自我改进人工智能方面的潜力，因为不稳定性会降低训练效率和模型性能。因此，研究旨在解决这些挑战，以提升自进化过程的稳定性和推理能力，弥补现有方法的不足。",
      "method": "DARC框架包括两个阶段：首先训练Questioner基于显式难度级别和外部语料库合成难度校准的问题，确保问题质量可控；其次训练Solver采用非对称自蒸馏机制，使用文档增强的教师模型生成高质量伪标签，监督无文档访问的学生Solver。该方法模型无关，可适配不同骨干模型，核心创新在于解耦问题生成和求解训练，并通过不对称设计优化伪标签生成，减少自引导错误。",
      "result": "实验在九个推理基准测试和三个骨干模型上进行，DARC实现了平均10.9点的性能提升。具体而言，它 consistently outperforms 所有基线方法，并接近完全监督模型的性能，而无需依赖人类标注。这些结果验证了DARC在稳定自进化过程和提高推理能力方面的有效性，突出了其模型无关性和实用优势。",
      "conclusion": "本研究的主要贡献是提出DARC框架，有效解决了自玩中的优化不稳定性，其学术价值在于提供了一种结合难度校准和非对称蒸馏的稳定自进化新方法。实际应用中，DARC减少了对人工标注的依赖，可用于各种LLM的自我改进。未来工作方向（摘要未明确说明）可能包括扩展到更多任务或模型架构，以及进一步优化伪标签生成机制。",
      "tags": [
        "Large Language Model",
        "Self-play",
        "Curriculum Learning",
        "Asymmetric Distillation",
        "Reasoning"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:59.197642Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13751",
    "title": "HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection",
    "authors": [
      "Daniel Kyselica",
      "Jonáš Herec",
      "Oliver Kutis",
      "Rado Pitoňák"
    ],
    "abstract": "Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.13751.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13751",
    "published": "2026-01-20T09:05:43Z",
    "updated": "2026-01-21T07:02:55Z",
    "comment": "19 pages, 9 figures, submitted to conference",
    "light_analysis": {
      "overview": "论文提出一种基于Transformer的历史注入机制（HiT），用于机载连续洪水变化检测，在减少数据存储超过99%的同时保持检测准确性。",
      "motivation": "自然灾害监测如洪水检测对灾害管理至关重要，但传统方法依赖卫星数据的连续观测，面临小型卫星内存和计算资源限制的挑战。现有系统通常需要地面处理，导致延迟和高成本，且难以在机载环境中高效处理多时相数据。本研究旨在开发机载变化检测系统，以适应资源受限环境，提高实时响应能力，解决现有方法在存储和计算效率上的不足。",
      "method": "核心方法是历史注入机制（HiT），整合到Transformer模型中，通过压缩历史观测数据来维护上下文，减少存储需求超过99%。使用Prithvi-tiny基础模型作为架构，在STTORM-CD洪水数据集上进行训练和测试。该机制在Transformer中嵌入历史信息，实现高效的多时相数据处理，关键创新在于数据压缩和模型轻量化，适用于资源受限的硬件。",
      "result": "在STTORM-CD数据集上的测试表明，HiT机制在Prithvi-tiny模型中保持与双时间基线相当的检测准确性，未因数据压缩而降低性能。HiT-Prithvi模型在Jetson Orin Nano硬件上实现43 FPS的实时处理速度，存储减少超过99%。这些结果验证了该方法在机载环境下的实用性和效率，相较于传统方法显著提升了处理速度。",
      "conclusion": "本研究建立了一个实用的卫星连续监测框架，支持实时洪水灾害评估，无需依赖地面处理基础设施。主要贡献是提出HiT机制，显著减少数据存储，同时保持准确性。学术上，推动了机载AI和Transformer在自然灾害监测中的应用；实际上，提高了灾害响应的时效性。未来工作可扩展到其他灾害类型或进一步优化模型性能，以增强通用性。",
      "tags": [
        "Transformer Models",
        "History-Injection Mechanism",
        "Change Detection",
        "Flood Detection",
        "Satellite Monitoring"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:08.873729Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13695",
    "title": "OptiSQL: Executable SQL Generation from Optical Tokens",
    "authors": [
      "Sifan Li",
      "Hongkai Chen",
      "Yujun Cai",
      "Liyang Chen",
      "Qingwen Ye",
      "Yiwei Wang"
    ],
    "abstract": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.13695.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13695",
    "published": "2026-01-20T07:49:29Z",
    "updated": "2026-01-21T03:17:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "OptiSQL 通过视觉编码器将表格图像压缩为紧凑光学标记，直接从视觉输入生成可执行SQL，显著减少标记开销。",
      "motivation": "现有文本到SQL方法假设表格为结构化文本，产生高标记开销，不适应现实中表格以视觉图像形式出现的场景。表格常出现在文档或网页中，作为视觉元素，而文本方法需要线性化处理，效率低下且依赖结构化文本的可访问性。因此，本研究旨在探索紧凑光学表示是否可作为可执行语义解析的高效接口，解决现实应用中的输入效率问题。",
      "method": "OptiSQL 是一个视觉驱动的框架，使用OCR导向的视觉编码器将表格图像的结构和内容压缩为少量光学标记。然后，它微调预训练解码器生成SQL查询，同时冻结编码器以隔离表示充分性，评估光学表示的效率。关键创新包括直接从图像生成SQL，避免完全文本化，以及通过光学标记大幅减少输入标记数量。实验在可视化的Spider 2.0-Snow数据集上进行，结合自然语言问题作为输入。",
      "result": "在可视化的Spider 2.0-Snow数据集上，OptiSQL 保持强大的执行准确性，同时将表格输入标记减少一个数量级（即约10倍）。与基线方法（摘要未明确说明具体方法，但暗示文本到SQL方法）相比，在准确性相当的情况下，标记开销显著降低。鲁棒性分析进一步显示，光学标记在视觉扰动下仍能有效保留表格的基本结构信息，证明了方法的稳定性和适应性。",
      "conclusion": "论文的主要贡献是提出了一种基于视觉的SQL生成框架，验证了光学标记作为高效语义解析接口的可行性。这扩展了语义解析到视觉领域，减少了对结构化文本的依赖，具有实际应用价值，如从视觉文档或网页中自动化生成数据查询。学术上，它为处理视觉表格提供了新思路。未来工作方向摘要未明确说明，但可能包括处理更复杂表格布局或提高在低质量图像下的鲁棒性。",
      "tags": [
        "SQL Generation",
        "Optical Tokens",
        "Visual Encoder",
        "OCR (Optical Character Recognition)",
        "Executable Semantic Parsing"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:13.218628Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13664",
    "title": "VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement",
    "authors": [
      "Tiancheng Fang",
      "Bowen Pan",
      "Lingxi Chen",
      "Jiangjing Lyu",
      "Chengfei Lyu",
      "Chaoyue Niu",
      "Fan Wu"
    ],
    "abstract": "We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.13664.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13664",
    "published": "2026-01-20T07:03:35Z",
    "updated": "2026-01-21T09:17:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "VIAFormer提出了一种新颖的Transformer模型，通过图像索引、校正流目标和混合流Transformer的协同设计，实现多视图引导的高保真体素细化。",
      "motivation": "该研究旨在解决使用校准多视图图像修复嘈杂、不完整3D体素的问题。在3D视觉和重建领域，体素表示常用于形状建模，但直接从图像生成或从基础模型获取的体素常受噪声和不完整性影响。现有方法在跨模态对齐和精确修复轨迹方面不足，导致失真或保真度低，因此需要更鲁棒的融合机制以提升修复质量。VIAFormer针对此挑战，通过创新设计优化多视图引导的体素细化，以推进3D内容创建和应用。",
      "method": "VIAFormer采用Transformer架构，核心方法包括三个关键组件：Image Index将2D图像令牌与3D空间坐标对齐，提供明确的3D空间定位；Correctional Flow目标学习直接的体素细化轨迹，优化修复过程；Hybrid Stream Transformer实现鲁棒的跨模态融合，整合多视图图像和初始体素信息。模型输入校准的多视图图像和体素数据，通过协同设计高效执行细化任务，创新点在于这些组件的整合，增强了对齐精度和修复效率，适用于多视图条件体素细化。",
      "result": "实验显示，VIAFormer在处理由合成噪声和现实伪影破坏的体素形状时，建立了新的最先进性能。具体地，在从视觉基础模型获得的体素上，它有效纠正严重失真，显著优于基线方法。摘要未明确说明具体准确率或效率指标，但强调了其在基准测试中的优越性，验证了模型对提升体素保真度和鲁棒性的关键贡献，推动了相关技术在3D重建领域的进展。",
      "conclusion": "VIAFormer的主要贡献是提出了一种创新的体素细化模型，不仅学术上推动了Transformer在跨模态3D任务中的应用，还具有实际应用价值，可作为真实3D创建流程的可靠桥梁。研究为基于体素的方法在大型模型和大数据环境下开辟了新途径，强调了其在计算机视觉和图形学中的重要性。未来工作可探索模型扩展到更多3D表示形式或与其他视觉任务集成，进一步优化计算效率和通用性。",
      "tags": [
        "Transformer",
        "Voxel Refinement",
        "Multi-view Fusion",
        "3D Reconstruction",
        "Image Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:57.288053Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13599",
    "title": "Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion",
    "authors": [
      "Linrui Ma",
      "Yufei Cui",
      "Kai Han",
      "Yunhe Wang"
    ],
    "abstract": "One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.13599.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13599",
    "published": "2026-01-20T05:00:26Z",
    "updated": "2026-01-21T18:21:39Z",
    "comment": "Work In Progress",
    "light_analysis": {
      "overview": "提出Diffusion in Diffusion框架，通过起草-精炼两阶段方法，恢复半自归扩展散模型的全局连贯性。",
      "motivation": "现有块级扩散语言模型具有全局双向上下文能力，但引入自回归先验后，在宏观层面失去全局连贯性，导致不可逆性和短视问题。这降低了模型性能，使得模型难以维持全局理解。为了在保留半自回归范式优势的同时解决这一问题，本研究旨在恢复全局上下文能力，以提升扩散模型的实用性和有效性，满足复杂文本生成任务的需求。",
      "method": "论文提出Diffusion in Diffusion框架，采用“起草然后精炼”策略。首先，使用块扩散基于小块快速生成草稿；然后，通过全局双向扩散精炼草稿，扩大双向感受野。关键创新包括快照置信度重掩码，用于识别需修改的关键令牌，以及混合尺度训练，以增强模型的全局能力。该方法在OpenWebText数据集上进行评估，结合了半自回归和全局扩散技术，提高了效率。",
      "result": "在OpenWebText数据集上的实验显示，模型仅用基线26%的微调预算，将生成困惑度从25.7降至21.9。这显著缩小了与自回归模型的性能差距，并设定了离散扩散模型的新基准。具体数据表明，困惑度降低约15%，验证了方法在提升模型全局连贯性和性能方面的有效性。",
      "conclusion": "本研究的主要贡献是提出Diffusion in Diffusion框架，有效解决了块扩散模型的全局连贯性问题。学术价值在于为半自归扩展散模型提供了新优化方向，提升了模型性能。实际应用价值体现在更高效的文本生成任务中，具有推广潜力。局限性可能包括对其他数据集的适应性，未来工作可探索扩展算法或增强泛化能力。",
      "tags": [
        "Discrete Diffusion Models",
        "Semi-Autoregressive Models",
        "Global Coherence",
        "Confidence Remasking",
        "Diffusion In Diffusion"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:15.450516Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12945",
    "title": "A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits",
    "authors": [
      "Miao Xie",
      "Siguang Chen",
      "Chunli Lv"
    ],
    "abstract": "Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.12945.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12945",
    "published": "2026-01-19T10:53:57Z",
    "updated": "2026-01-21T06:29:58Z",
    "comment": "27 pages, 6 table",
    "light_analysis": {
      "overview": "本研究是首篇在组件级别系统回顾大语言模型与多臂老虎机之间双向互动的综述。",
      "motivation": "研究动机在于探索大语言模型（LLMs）与多臂老虎机（MABs）交叉领域的潜力，以相互增强性能。LLMs在语言理解和生成中面临优化、个性化等挑战，而MABs在不确定性下的自适应决策中具有广泛应用，但现有研究缺乏对这一互动关系的系统性分析，导致技术融合受限，限制了两者在实际应用中的协同作用。通过综述，旨在填补这一空白，促进跨领域创新。",
      "method": "研究方法基于对现有文献的系统回顾，从组件级别分析LLMs和MABs的双向互动。关键创新点在于将互动分解为具体组件，如MAB算法在LLMs的预训练、检索增强生成（RAG）和个性化阶段提供决策支持，以及LLMs通过重新定义MAB系统的核心组件（如臂定义和环境建模）来改进序列任务中的决策。该方法不涉及具体数据集或模型架构，而是侧重于框架性分析。",
      "result": "作为综述文章，主要结果是对LLM增强的bandit系统和bandit增强的LLM系统进行了分析，提供了设计、方法和性能的见解。摘要未明确说明具体实验数据或基线对比，但识别了关键挑战（如可扩展性和模型集成）和代表性发现，以指导未来研究。这些分析强调双向互动在优化任务性能方面的潜力。",
      "conclusion": "本文总结了大语言模型与多臂老虎机交互的主要贡献，包括创新性地在组件级别提供了全面视角和双向好处的框架。研究具有重要学术价值，为跨领域合作奠定基础，促进语言模型与决策系统的优化；实际应用价值在于指导开发更高效的自适应AI系统。未来工作方向包括解决已识别挑战和探索更广泛的应用场景。",
      "tags": [
        "Large Language Model",
        "Multi-Armed Bandit",
        "Retrieval-Augmented Generation",
        "Component Analysis",
        "Adaptive Decision-Making"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:42.131571Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12815",
    "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction",
    "authors": [
      "Zhaolu Kang",
      "Junhao Gong",
      "Qingxi Chen",
      "Hao Zhang",
      "Jiaxin Liu",
      "Rong Fu",
      "Zhiyuan Feng",
      "Yuan Wang",
      "Simon Fong",
      "Kaiyue Zhou"
    ],
    "abstract": "Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.12815.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12815",
    "published": "2026-01-19T08:21:46Z",
    "updated": "2026-01-21T06:56:09Z",
    "comment": "Accepted to the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026",
    "light_analysis": {
      "overview": "论文提出JurisMMA框架，通过多模态和多代理方法有效改进法律判决预测。",
      "motivation": "研究动机在于解决法律判决预测（LJP）中的核心挑战，如处理多指控和多样证据的复杂性。传统方法依赖统计分析或角色模拟，缺乏对法律案件动态性和多模态数据的适应性，导致预测准确性受限。LJP作为法律系统发展的基础任务，其改进对提升司法效率和公正性至关重要，因此需要创新方法来应对这些实际需求。",
      "method": "研究方法包括提出JurisMMA框架，该框架通过分解审判任务、标准化流程并组织成不同阶段来处理LJP。关键创新在于整合多模态数据（如文本和视频-文本）和多代理系统，以模拟法律审判的交互过程。此外，构建了JurisMM数据集，包含超过100,000个近期中国司法记录，支持全面多模态评估，为方法验证提供了实验基础。",
      "result": "实验在JurisMM数据集和基准LawBench上进行，验证了JurisMMA框架的有效性。摘要未明确说明具体性能指标如准确率提升，但结果表明框架在LJP任务中表现出色，优于传统方法。这突出了框架在多模态和多代理场景下的优势，为复杂法律预测提供了实证支持。",
      "conclusion": "论文的主要贡献是开发了JurisMMA框架，不仅提升了法律判决预测的准确性，还为更广泛的法律应用开辟了新路径。学术价值在于推动了多模态和多代理技术在法律AI中的融合，实际价值在于辅助司法决策和数据集构建。未来工作可进一步优化框架的适应性或扩展到其他法律领域，摘要未明确说明具体局限性。",
      "tags": [
        "Legal Judgment Prediction",
        "Multimodal Learning",
        "Multi-Agent Systems",
        "Legal AI"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:18.564970Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12698",
    "title": "A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization",
    "authors": [
      "Qiuyi Qu",
      "Yicheng Sui",
      "Yufei Sun",
      "Rui Chen",
      "Xiaofei Zhang",
      "Yuzhi Zhang",
      "Haofeng Wang",
      "Ge Lan",
      "Ning Zhang"
    ],
    "abstract": "GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.12698.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12698",
    "published": "2026-01-19T03:40:12Z",
    "updated": "2026-01-21T08:52:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种两阶段GPU核调谐器，结合语义重构和基于搜索的优化，以提供更稳定、高质量的自动化性能优化。",
      "motivation": "GPU代码优化在高性能计算和大规模模型训练中是一个关键瓶颈，但现有方法如编译器优化和手动编写内核仍依赖人力，难以达到硬件极限性能。最近基于大语言模型（LLM）的代理方法虽尝试自动化，但常采用直接代码重写，导致参数选择隐式化，性能提升不稳定且控制困难。因此，研究旨在解决这些问题，开发更稳定、可控制的优化技术，提升实际应用中的性能一致性和效率。",
      "method": "研究方法采用模板重写层和代理驱动迭代循环：首先通过语义重构将GPU核转换为可参数化的模板，使参数明确化；然后通过基于搜索的自动调优算法（如启发式搜索）优化参数。评估基于从SGLang提取的真实CUDA核，代理调谐器迭代执行模板化、测试、性能分析和计划，并利用分析反馈在硬件资源限制下进行约束参数搜索，确保过程更系统化和可解释。",
      "result": "实验结果显示，在真实GPU核测试中，最佳情况下实现了超过3倍的速度提升，性能显著改善。与仅使用代理直接重写的方法相比，模板加搜索的设计显著降低了迭代优化的随机性，使性能增益更稳定，并通过量化指标（如加速比）展示了优越性，增强了优化过程的可解释性和可靠性。",
      "conclusion": "本研究的主要贡献是开发了一种高效的两阶段GPU核调谐器，通过语义重构和搜索优化结合，提供了更稳定、高质量的自动化性能优化方案。该方法不仅提升了GPU代码的优化效率和稳定性，还具有可扩展性，可应用于OpenCL、HIP等多种后端，适用于真实生产工作负载。未来工作可扩展到更多硬件平台，并进一步减少人工干预，推动高性能计算的自动化发展。",
      "tags": [
        "GPU Kernel Tuning",
        "Semantic Refactoring",
        "Search-Based Optimization",
        "Agent-Driven Iteration",
        "CUDA"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:39.953246Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12534",
    "title": "Encoding Emotion Through Self-Supervised Eye Movement Reconstruction",
    "authors": [
      "Marcus Ma",
      "Jordan Prescott",
      "Emily Zhou",
      "Tiantian Feng",
      "Kleanthis Avramidis",
      "Gabor Mihaly Toth",
      "Shrikanth Narayanan"
    ],
    "abstract": "The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.12534.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12534",
    "published": "2026-01-18T18:37:41Z",
    "updated": "2026-01-21T03:08:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一种基于自监督眼动重建的新方法，用于从低分辨率自然视频中编码和预测情感表达。",
      "motivation": "现有研究表明眼动是情感表达的有效指标，但大多数研究依赖高分辨率眼动追踪设备，限制了在自然、低分辨率视频场景中的应用。这个问题的重要性在于情感识别在心理健康、人机交互等领域有广泛应用，而现有方法因设备成本和实用性不足无法广泛部署。本研究旨在填补这一空白，探索如何在资源有限条件下利用眼动分析情感信号。",
      "method": "论文提出一种新的视线检测模型，基于自监督眼动重建方法，灵感来源于语言模型的预训练技术，能够有效利用未标记视频数据。使用USC Shoah Foundation的Visual History Archive中关于大屠杀幸存者的视频访谈作为数据集。模型编码器提取嵌入特征，用于微调两个下游任务：一是对齐眼动与语音中的情感估计方向；二是使用眼动预测三种瞬时情感行为（笑、哭/抽泣、叹气）。关键创新点在于将自监督学习应用于眼动分析，降低对高分辨率设备的依赖。",
      "result": "实验结果证实新模型能够预测情感结果，例如观察到预训练性能与情感处理性能之间存在正相关关系，表明自监督重建有助于提升情感识别准确性。摘要未明确提供具体性能指标（如准确率提升），也未详细描述与基线方法的对比情况，但基于文中信息可推断该方法在情感任务上表现出有效性。",
      "conclusion": "论文结论表明自监督眼动重建是编码情感信号的有效方法，主要贡献在于开发了一种不需要高分辨率设备的眼动分析技术，为情感计算和视频处理提供了新思路。学术价值在于扩展了自监督学习在眼动分析中的应用，实际应用潜力包括心理健康监测和视频内容分析。摘要未明确说明局限性或未来工作方向，但可合理推断未来可能改进模型通用性或扩展到更广泛数据集。",
      "tags": [
        "Self-Supervised Learning",
        "Eye Movement Reconstruction",
        "Emotion Recognition",
        "Video Processing",
        "Encoder Embeddings"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:54.546958Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12533",
    "title": "BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images",
    "authors": [
      "Md. Ahanaf Arif Khan",
      "Ariful Islam",
      "Sangeeta Biswas",
      "Md. Iqbal Aziz Khan",
      "Subrata Pramanik",
      "Sanjoy Kumar Chakravarty",
      "Bimal Kumar Pramanik"
    ],
    "abstract": "Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.12533.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12533",
    "published": "2026-01-18T18:36:03Z",
    "updated": "2026-01-21T03:24:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文创建了BirdsEye-RU数据集，专门用于解决俯瞰图像中因尺度变化和环境杂乱导致的人脸检测难题。",
      "motivation": "研究动机是俯瞰图像中的人脸检测面临极端尺度变化和环境杂乱的挑战，这使得现有检测方法在识别小目标时效果不佳。该问题在无人机监控、高空摄影等应用中至关重要，但现有数据集可能未专门针对此类场景设计，限制了检测算法的进步。摘要未明确说明现有方法的具体不足。",
      "method": "论文提出了BirdsEye-RU数据集的创建方法，包括收集了2,978张图像，标注了超过八千个面部。数据集专为捕捉各种环境中的小而遥远面部设计，来源包括无人机图像和智能手机从高空捕捉的图像。关键创新在于提供了一个全面、公开的数据集，支持多源数据，以促进俯瞰图像中人脸检测的研究。",
      "result": "摘要未明确说明实验结果。论文主要贡献是发布了数据集，未提及具体的检测精度或对比基线方法的性能指标。数据集的规模（2,978张图像，八千多个注释）是其核心成果，但性能评估可能留待未来研究。",
      "conclusion": "论文的主要贡献是发布了BirdsEye-RU数据集，填补了俯瞰图像人脸检测领域的空白，具有学术和实际应用价值，如支持监控系统和无人机技术的发展。局限性在于数据集范围可能有限，未来工作可扩展数据规模或开发专门检测算法。",
      "tags": [
        "Face Detection",
        "Overhead Images",
        "Dataset Creation",
        "Drone Images",
        "Image Annotation"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:29.471456Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12467",
    "title": "Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting",
    "authors": [
      "Saurish Nagrath",
      "Saroj Kumar Panigrahy"
    ],
    "abstract": "Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data, particularly as sequence length and data scale increase. This paper proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the proposed approach, a convolutional neural network operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is applied during representation learning to refine these embeddings, after which a Transformer encoder models inter-patch temporal dependencies to generate forecasts. The method is evaluated on a synthetic multivariate time-series dataset with controlled static and dynamic factors, using an extended sequence length and a larger number of samples. Experimental results demonstrate that the proposed framework consistently outperforms a convolutional baseline under increased temporal context and remains competitive with a strong patch-based Transformer model. These findings indicate that structured patch-level tokenization provides a scalable and effective representation for multivariate time-series forecasting, particularly when longer input sequences are considered.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.12467.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12467",
    "published": "2026-01-18T16:16:01Z",
    "updated": "2026-01-21T14:41:56Z",
    "comment": "6 pages, 2 figures, 3 tables",
    "light_analysis": {
      "overview": "提出一个两阶段框架，结合CNN编码器和注意力进行片段级令牌化，以提升Transformer在长序列多元时间序列预测中的性能和可扩展性。",
      "motivation": "该研究旨在解决Transformer模型在时间序列预测中，因输入表示质量不足而影响长序列处理效果的问题。随着时间序列数据规模和序列长度的增加，现有方法可能在建模本地特征和全局依赖方面存在局限，导致预测性能下降。这凸显了开发更结构化、可扩展表示方法的重要性，以提高在大规模数据环境下的预测准确性和效率。",
      "method": "论文提出一个两阶段预测框架，首先使用卷积神经网络（CNN）在固定长度的时间片段（patches）上操作，提取短程时间动态和非线性特征交互，生成紧凑的片段级令牌嵌入。其次，在表示学习阶段应用令牌级自注意力精炼这些嵌入，随后利用Transformer编码器建模片段间的时间依赖关系以生成最终预测。关键创新在于明确分离本地表示学习和全局依赖建模，通过结构化令牌化提升输入表示质量。",
      "result": "在合成多元时间序列数据集上评估，使用更长序列和更多样本进行实验。结果显示，所提框架在增加时间上下文的条件下，始终优于卷积基线模型。同时，与一个基于片段的强Transformer模型相比，保持竞争力。这表明结构化片段级令牌化能有效改善长序列预测性能，尤其在处理大规模数据时展现优越性，尽管摘要未提供具体数值指标。",
      "conclusion": "研究的主要贡献在于提出一个结合CNN和注意力的两阶段框架，通过片段级令牌化改进了Transformer在时间序列预测中的表示学习。这提供了可扩展和有效的解决方案，特别适用于长输入序列的多元时间序列预测，具有学术和实际应用价值。未来工作可能包括扩展到真实世界数据集或进一步优化框架，以验证泛化能力和处理更复杂场景。",
      "tags": [
        "Time-Series Forecasting",
        "Transformer",
        "Convolutional Neural Networks",
        "Self-Attention",
        "Patch Tokenization"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:52.999033Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.12415",
    "title": "Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF",
    "authors": [
      "Wang Zixian"
    ],
    "abstract": "Large language model alignment objectives are often presented as a collection of distinct algorithms, such as PPO, DPO, IPO, and their variants, each motivated by different derivations. In this work, we argue that this diversity obscures a simpler underlying structure. At a fundamental level, alignment objectives involve two independent design choices: (i) how training signals are sampled and weighted, and (ii) how deviations from a reference policy are geometrically penalized. Existing methods typically entangle these choices through a single divergence, most commonly the Kullback-Leibler divergence.   We show that this entanglement is not merely a modeling convenience but a source of systematic instability. When the same divergence simultaneously determines sample weighting and optimization curvature, adjusting one aspect, such as exploration strength, inevitably alters the other, such as gradient geometry. This coupling is particularly problematic in preference-based reinforcement learning, where advantage signals are unbounded and high-confidence regimes are common.   We propose a simple but structural remedy by formulating alignment as an orthogonal mirror descent problem, in which sampling geometry enters only as a linear driving force, while optimization geometry is determined independently by a mirror map. This perspective leads to a new alignment objective called Orthogonalized Policy Optimization (OPO), obtained by choosing a Euclidean mirror map in likelihood ratio space. The resulting objective admits a closed-form solution, linear and non-saturating gradient dynamics, and a well-conditioned trust region, while remaining fully compatible with standard large language model training pipelines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.12415.pdf",
    "abs_url": "https://arxiv.org/abs/2601.12415",
    "published": "2026-01-18T13:57:44Z",
    "updated": "2026-01-21T14:54:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出正交化策略优化（OPO）方法，通过解耦采样几何和优化几何来解决大型语言模型对齐中的系统不稳定性问题。",
      "motivation": "现有大型语言模型对齐方法，如PPO、DPO和IPO，通常通过单一散度（如Kullback-Leibler散度）将采样权重和优化几何耦合，这种耦合导致在调整探索强度时影响梯度几何，引发系统不稳定性。该问题在基于偏好的强化学习中尤为突出，因为优势信号无界且高置信度区域常见，因此亟需一种解耦方法来提高对齐过程的鲁棒性和可控性。",
      "method": "研究提出正交镜像下降框架，将对齐问题转化为采样几何作为线性驱动、优化几何由镜像映射独立确定的结构。通过选择欧几里得镜像映射于似然比空间，推导出正交化策略优化（OPO）目标，该方法允许闭式解、线性和非饱和梯度动态，以及良好条件的信任区域，同时兼容标准大型语言模型训练流程，无需额外修改。",
      "result": "摘要未明确说明具体实验结果，如准确率或效率指标，但指出OPO方法理论上支持闭式解、线性梯度动态和稳定信任区域，相对于现有基线方法（如PPO、DPO）有望减少耦合带来的不稳定性，并保持与现有训练系统的兼容性。",
      "conclusion": "本文主要贡献在于提出OPO框架，结构化解耦采样和优化几何，提升对齐过程的稳定性和效率。该研究具有学术价值，为强化学习对齐方法提供了新视角，并具备实际应用潜力，可集成到标准训练流程中。局限性包括尚未在广泛数据集上验证，未来工作可拓展到其他镜像映射或评估在复杂场景下的性能。",
      "tags": [
        "Reinforcement Learning from Human Feedback",
        "Policy Optimization",
        "Mirror Descent",
        "Orthogonalized Policy Optimization",
        "Kullback-Leibler Divergence"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:08.003896Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11910",
    "title": "A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection",
    "authors": [
      "Guiying Zhu",
      "Bowen Yang",
      "Yin Zhuang",
      "Tong Zhang",
      "Guanqun Wang",
      "Zhihao Che",
      "He Chen",
      "Lianlin Li"
    ],
    "abstract": "Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of \"guess what\". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.11910.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11910",
    "published": "2026-01-17T05:14:42Z",
    "updated": "2026-01-21T08:41:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出GW-VLM，一种无需训练的视觉语言模型，通过多尺度视觉语言搜索和上下文概念提示，实现开放词汇物体检测。",
      "motivation": "研究动机源于开放词汇物体检测（OVOD）需要检测任何物体，尽管预训练基础模型展现出零样本能力，但现有方法通常忽略了基于这些模型创建通用对象理解的必要性，这可能导致检测性能受限。本论文旨在解决这一问题，通过无需额外训练的方式，结合视觉语言模型和大语言模型，构建一个通用理解范式，以提升OVOD的泛化能力和效率，适应复杂场景。",
      "method": "论文提出的GW-VLM方法结合多尺度视觉语言搜索（MS-VLS）和上下文概念提示（CCP）。MS-VLS利用预训练视觉语言模型进行多尺度视觉语言软对齐，从类无关物体检测结果生成片段；CCP则基于MS-VLS形成概念流，输入大语言模型进行理解和分类。该方法无需额外训练步骤，直接利用预训练模型的零样本能力实现开放词汇物体检测，关键创新在于软对齐和概念提示的结合。",
      "result": "实验在COCO val、Pascal VOC、DIOR和NWPU-10等多个自然和遥感数据集上进行。结果显示，GW-VLM在开放词汇物体检测任务上取得了优越性能，优于当前最先进的方法，且无需任何训练步骤。尽管摘要未明确说明具体性能指标，但与基线方法的对比表明其显著提升，验证了方法的有效性和泛化能力。",
      "conclusion": "本论文的主要贡献是提出了训练免费的GW-VLM框架，通过MS-VLS和CCP结合预训练模型实现开放词汇物体检测。研究展示了在多个数据集上的优越性能，为视觉语言模型和零样本检测提供了新思路，具有学术价值和实际应用潜力，特别是在资源受限场景。未来工作可进一步优化模型细节或扩展到其他视觉任务。",
      "tags": [
        "Open-Vocabulary Object Detection",
        "Vision Language Model",
        "Large Language Model",
        "Multi-Scale Visual Language Searching",
        "Contextual Concept Prompt"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:09.951557Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11719",
    "title": "jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation",
    "authors": [
      "Ho Fung Tsoi",
      "Dylan Rankin"
    ],
    "abstract": "Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.",
    "categories": [
      "cs.LG",
      "hep-ex"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.11719.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11719",
    "published": "2026-01-16T19:12:13Z",
    "updated": "2026-01-21T04:25:59Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "jBOT是一个基于自蒸馏的预训练方法，用于CERN大型强子对撞机的喷注数据，能够实现语义类聚类，支持异常检测和分类任务。",
      "motivation": "在粒子物理领域，CERN大型强子对撞机产生的喷注数据量大且标注成本高，现有监督学习方法依赖大量标签，难以高效处理无标签数据。自我监督学习作为预训练方法，能学习无标签的特征表示，但应用于喷注数据时，如何捕获语义信息以支持下游任务如异常检测和分类仍具挑战。本研究旨在通过自蒸馏方法减少对标注的依赖，提升表示学习能力，解决高能物理实验中的数据分析需求。",
      "method": "jBOT是一种自监督预训练方法，结合了局部粒子级蒸馏和全局喷注级蒸馏，以学习喷注数据的表示。关键创新在于这种双层次蒸馏结构，通过自我蒸馏从无标签数据中捕获语义信息，无需外部标签。模型使用来自CERN大型强子对撞机的喷注数据集，具体架构基于自蒸馏框架，但摘要未详细说明网络设计细节。该方法旨在促进表示空间中的语义聚类，为下游任务提供通用特征。",
      "result": "实验结果显示，在无标签喷注数据上预训练后，表示空间中出现语义类聚类。当仅在背景喷注上预训练并冻结嵌入时，可以通过简单的基于距离度量实现异常检测。此外，学习到的嵌入微调用于分类任务时，性能优于从零开始训练的监督模型，表明预训练提升了表示质量和泛化能力，但摘要未提供具体准确率或效率数据。",
      "conclusion": "jBOT通过自蒸馏成功学习喷注表示，实现了语义聚类，有效支持异常检测和分类任务。其学术价值在于将自监督学习应用于粒子物理数据，减少了标签依赖，展示了预训练表示的优势。实际应用价值在于促进高能物理实验中的数据分析效率。局限性或未来工作方向摘要未明确说明，可能包括扩展到其他粒子物理任务或优化蒸馏策略。",
      "tags": [
        "Self-Distillation",
        "Jet Representation",
        "Anomaly Detection",
        "Clustering",
        "Self-Supervised Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:18.672613Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11444",
    "title": "When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models",
    "authors": [
      "Raphaël Razafindralambo",
      "Rémy Sun",
      "Frédéric Precioso",
      "Damien Garreau",
      "Pierre-Alexandre Mattei"
    ],
    "abstract": "Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).",
    "categories": [
      "cs.LG",
      "cs.CV",
      "math.ST",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.11444.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11444",
    "published": "2026-01-16T17:07:25Z",
    "updated": "2026-01-21T14:49:27Z",
    "comment": "Accepted at Transactions on Machine Learning Research (reviewed on OpenReview: https://openreview.net/forum?id=4iRx9b0Csu). Code: https://github.com/rarazafin/score_diffusion_ensemble",
    "light_analysis": {
      "overview": "本文研究了扩散模型的集成方法，发现集成能改进损失函数和模型似然，但未提升图像质量指标，并提供了相关理论洞察。",
      "motivation": "扩散模型目前在生成高质量、多样化样本方面表现出色，但研究焦点逐渐转向更强大的模型。尽管集成是监督学习中常用的提升性能的技术，但在无条件基于分数的扩散模型中的应用尚未被充分探索。本研究旨在探究集成是否能为生成建模带来实际益处，以弥补现有方法在此领域的不确定性。现有方法的不足在于缺乏对扩散模型集成效果的实证研究，这限制了模型组合技术的进一步发展。",
      "method": "本研究采用扩散模型的集成技术，重点研究不同聚合规则的应用。具体方法包括使用Deep Ensembles和Monte Carlo Dropout作为聚合策略，在图像数据集（CIFAR-10和FFHQ）上验证效果，并通过随机森林在表格数据中分析聚合策略的优劣。关键创新点在于系统比较多种聚合方法，并结合理论分析探讨分数模型的求和原理，从而为模型组合提供新视角。数据集和模型架构未详细说明，但涉及标准扩散模型和聚合规则。",
      "result": "实验结果表明，集成扩散模型能有效改进分数匹配损失和模型似然，这表明在损失函数层面有所提升。然而，在感知质量指标如FID上，集成未能一致提升图像生成质量，揭示了损失改进与感知质量之间的脱节。在表格数据中，一个特定的聚合策略优于其他方法。这些发现基于CIFAR-10和FFHQ数据集的验证，与单个模型基线相比，集成在损失方面有优势，但在质量指标上无明显改进，具体数据摘要未明确说明。",
      "conclusion": "本研究的主要贡献在于系统探索了扩散模型集成方法的有效性，揭示其在损失函数和模型似然上的益处，但在图像质量指标上的局限性。这为理解模型集成在生成建模中的作用提供了新见解，并促进了相关理论的发展，有助于模型组合技术的优化。学术价值体现在深化对分数模型和集成技术的理解，实际应用价值在于指导生成模型设计和优化。未来工作可进一步调查损失与质量间的差异原因，并扩展应用到其他领域或模型类型。",
      "tags": [
        "Diffusion Models",
        "Score-Based Models",
        "Ensembles",
        "Deep Ensembles",
        "Random Forests"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:46.773250Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11396",
    "title": "SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction",
    "authors": [
      "Hanlin Wu",
      "Pengfei Lin",
      "Ehsan Javanmardi",
      "Nanren Bao",
      "Bo Qian",
      "Hao Si",
      "Manabu Tsukada"
    ],
    "abstract": "As autonomous driving moves toward full scene understanding, 3D semantic occupancy prediction has emerged as a crucial perception task, offering voxel-level semantics beyond traditional detection and segmentation paradigms. However, such a refined representation for scene understanding incurs prohibitive computation and memory overhead, posing a major barrier to practical real-time deployment. To address this, we propose SUG-Occ, an explicit Semantics and Uncertainty Guided Sparse Learning Enabled 3D Occupancy Prediction Framework, which exploits the inherent sparsity of 3D scenes to reduce redundant computation while maintaining geometric and semantic completeness. Specifically, we first utilize semantic and uncertainty priors to suppress projections from free space during view transformation while employing an explicit unsigned distance encoding to enhance geometric consistency, producing a structurally consistent sparse 3D representation. Secondly, we design an cascade sparse completion module via hyper cross sparse convolution and generative upsampling to enable efficiently coarse-to-fine reasoning. Finally, we devise an object contextual representation (OCR) based mask decoder that aggregates global semantic context from sparse features and refines voxel-wise predictions via lightweight query-context interactions, avoiding expensive attention operations over volumetric features. Extensive experiments on SemanticKITTI benchmark demonstrate that the proposed approach outperforms the baselines, achieving a 7.34/% improvement in accuracy and a 57.8\\% gain in efficiency.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.11396.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11396",
    "published": "2026-01-16T16:07:38Z",
    "updated": "2026-01-21T04:26:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了SUG-Occ框架，通过语义和不确定性引导的稀疏学习实现实时3D占用预测，创新点在于利用稀疏性减少计算开销同时保持几何和语义完整性。",
      "motivation": "在自动驾驶领域，3D语义占用预测作为关键感知任务，提供体素级语义信息以支持全场景理解，但现有方法因精细表示导致计算和内存开销巨大，阻碍了实时部署。该研究旨在解决这一问题，因为高效预测对自动驾驶系统的实时性和安全性至关重要，而传统方法冗余计算多，难以满足实际需求。",
      "method": "研究方法包括：首先使用语义和不确定性先验在视图转换中抑制自由空间投影，并结合显式无符号距离编码增强几何一致性，生成稀疏3D表示；其次设计级联稀疏完成模块，利用超交叉稀疏卷积和生成上采样进行从粗到细的高效推理；最后开发基于对象上下文表示（OCR）的掩码解码器，聚合稀疏特征的全局语义上下文，通过轻量级查询-上下文交互细化体素预测，避免对体积特征的昂贵注意力操作。",
      "result": "在SemanticKITTI基准上的实验显示，SUG-Occ在准确率上比基线提升了7.34%，效率提升了57.8%，表明该方法在减少冗余计算的同时，有效提升了预测性能和速度，优于现有基线方法。",
      "conclusion": "该研究的主要贡献是提出了SUG-Occ框架，通过稀疏学习策略解决3D占用预测的计算效率问题，学术上推动了实时感知技术的发展，实际应用中有助于自动驾驶实现更高效的全场景理解。未来工作可能涉及进一步优化稀疏性和扩展到更多复杂场景，摘要未明确说明具体局限性。",
      "tags": [
        "3D Semantic Occupancy Prediction",
        "Sparse Learning",
        "Uncertainty Guided",
        "Cross Sparse Convolution",
        "Object Contextual Representation"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:03.550793Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14037",
    "title": "Human detectors are surprisingly powerful reward models",
    "authors": [
      "Kumar Ashutosh",
      "XuDong Wang",
      "Xi Yin",
      "Kristen Grauman",
      "Adam Polyak",
      "Ishan Misra",
      "Rohit Girdhar"
    ],
    "abstract": "Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.14037.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14037",
    "published": "2026-01-15T18:48:17Z",
    "updated": "2026-01-21T07:24:31Z",
    "comment": "Technical report",
    "light_analysis": {
      "overview": "本研究提出了一种简单奖励模型HuDA，利用现成模型来量化并改进生成视频中人类动作的真实性。",
      "motivation": "视频生成模型在处理复杂人类动态动作时存在显著问题，如肢体缺失、姿势扭曲等，影响视觉真实性和实用场景如体育、舞蹈的合成。现有方法通常依赖手动标注数据进行微调，成本高且效率低，因此需要一种更简单有效的解决方案来提升动作质量。",
      "method": "HuDA模型整合了现成人类检测器的置信度以评估外观质量，并结合时间提示对齐分数来捕捉动作的连贯性和真实性。该方法无需额外训练，利用现有模型构建奖励函数，并通过Group Reward Policy Optimization (GRPO)策略对视频生成模型进行后训练，优化复杂动作的生成。",
      "result": "使用HuDA进行后训练后，视频生成质量显著提升，在复杂人类动作合成上以73%的胜率超越了最先进模型如Wan 2.1。此外，该方法还扩展到动物视频和人类-物体交互的生成，显示出广泛改进效果。",
      "conclusion": "HuDA奖励模型有效解决了视频生成中人类动作不真实的问题，展示了现成模型作为强大奖励工具的潜力，为视频生成领域提供了新的优化思路，具有学术和实际应用价值，未来可扩展到更多动作类型。",
      "tags": [
        "Human Detection",
        "Reward Model",
        "Video Generation",
        "GRPO",
        "Temporal Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:28.149122Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.08134",
    "title": "How Reliable are Confidence Estimators for Large Reasoning Models? A Systematic Benchmark on High-Stakes Domains",
    "authors": [
      "Reza Khanmohammadi",
      "Erfan Miahi",
      "Simerjot Kaur",
      "Ivan Brugere",
      "Charese H. Smiley",
      "Kundan Thind",
      "Mohammad M. Ghassemi"
    ],
    "abstract": "The miscalibration of Large Reasoning Models (LRMs) undermines their reliability in high-stakes domains, necessitating methods to accurately estimate the confidence of their long-form, multi-step outputs. To address this gap, we introduce the Reasoning Model Confidence estimation Benchmark (RMCB), a public resource of 347,496 reasoning traces from six popular LRMs across different architectural families. The benchmark is constructed from a diverse suite of datasets spanning high-stakes domains, including clinical, financial, legal, and mathematical reasoning, alongside complex general reasoning benchmarks, with correctness annotations provided for all samples. Using RMCB, we conduct a large-scale empirical evaluation of over ten distinct representation-based methods, spanning sequential, graph-based, and text-based architectures. Our central finding is a persistent trade-off between discrimination (AUROC) and calibration (ECE): text-based encoders achieve the best AUROC (0.672), while structurally-aware models yield the best ECE (0.148), with no single method dominating both. Furthermore, we find that increased architectural complexity does not reliably outperform simpler sequential baselines, suggesting a performance ceiling for methods relying solely on chunk-level hidden states. This work provides the most comprehensive benchmark for this task to date, establishing rigorous baselines and demonstrating the limitations of current representation-based paradigms.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.08134.pdf",
    "abs_url": "https://arxiv.org/abs/2601.08134",
    "published": "2026-01-13T01:55:48Z",
    "updated": "2026-01-21T18:03:19Z",
    "comment": "Accepted to the 19th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2026) main conference",
    "light_analysis": {
      "overview": "论文引入推理模型信心估计基准RMCB，并通过大规模实证评估揭示当前表示方法在区分性和校准性间存在权衡。",
      "motivation": "大型推理模型（LRMs）在高风险领域（如临床、金融、法律）中的长格式、多步输出存在校准不准确问题，这削弱了其可靠性，可能导致严重后果。现有信心估计方法不足，无法准确评估模型输出的置信度，因此需要建立系统性基准来填补这一空白。论文旨在通过RMCB基准评估不同方法的性能，以推动更可靠的信心估计技术发展。",
      "method": "本研究提出推理模型信心估计基准RMCB，构建了一个包含347,496个推理痕迹的公共资源，这些痕迹来自六个不同架构的大型推理模型，覆盖高风险领域数据集（如临床、金融、法律、数学推理）及复杂通用推理基准，所有样本均提供正确性标注。使用RMCB进行了大规模实证评估，测试了十多种基于表示的方法，包括顺序、图基和文本编码器架构，以分析它们的性能和局限性。",
      "result": "实验结果表明，在信心估计方法中存在区分性（AUROC）和校准性（ECE）的权衡：基于文本的编码器获得最佳AUROC（0.672），而结构感知模型则实现最佳ECE（0.148），无单一方法同时主导两方面。此外，增加架构复杂性并未可靠超越简单顺序基线，揭示了基于块级隐藏状态的方法存在性能上限。与基线方法对比，RMCB基准提供了全面评估。",
      "conclusion": "本工作为推理模型信心估计任务建立了迄今为止最全面的基准RMCB，设定了严格的基线，并展示了当前基于表示方法的局限性。研究表明现有方法在区分性和校准性间存在固有权衡，突出了未来研究需要开发新方法以提高模型在高风险领域的可靠性。潜在局限性包括依赖特定数据集和架构，未来可探索更先进的信心估计技术。",
      "tags": [
        "Large Reasoning Models",
        "Confidence Estimation",
        "Benchmarking",
        "Representation-based Methods",
        "Calibration Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:03.175418Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.06916",
    "title": "Active Learning Strategies for Efficient Machine-Learned Interatomic Potentials Across Diverse Material Systems",
    "authors": [
      "Mohammed Azeez Khan",
      "Aaron D'Souza",
      "Vijay Choyal"
    ],
    "abstract": "Efficient materials discovery requires reducing costly first-principles calculations for training machine-learned interatomic potentials (MLIPs). We develop an active learning (AL) framework that iteratively selects informative structures from the Materials Project and Open Quantum Materials Database (OQMD) using compositional and property-based descriptors with a neural network ensemble model. Query-by-Committee enables real-time uncertainty quantification. We compare four strategies: random sampling (baseline), uncertainty-based sampling, diversity-based sampling (k-means clustering with farthest-point refinement), and a hybrid approach. Experiments across four material systems (C, Si, Fe, and TiO2) with 5 random seeds demonstrate that diversity sampling achieves competitive or superior performance, with 10.9% improvement on TiO2. Our approach achieves equivalent accuracy with 5-13% fewer labeled samples than random baselines. The complete pipeline executes on Google Colab in under 4 hours per system using less than 8 GB RAM, democratizing MLIP development for resource-limited researchers. Open-source code and configurations are available on GitHub. This multi-system evaluation provides practical guidelines for data-efficient MLIP training and highlights integration with symmetry-aware architectures as a promising future direction.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.06916.pdf",
    "abs_url": "https://arxiv.org/abs/2601.06916",
    "published": "2026-01-11T13:52:28Z",
    "updated": "2026-01-21T12:35:06Z",
    "comment": "14 pages, 3 figures, 2 tables",
    "light_analysis": {
      "overview": "论文提出了一种主动学习框架，通过多样性采样策略，在多个材料系统上显著减少训练机器学习原子间势能所需的昂贵第一性原理计算。",
      "motivation": "材料发现依赖于机器学习原子间势能，但训练这些势能需要大量的第一性原理计算，成本高昂且时间密集。现有方法如随机采样效率低下，限制了材料研究的进展，尤其是对于资源有限的研究者。本研究旨在开发一个高效的主动学习框架，通过主动选择信息性数据点来减少对标记样本的依赖，从而降低计算成本并加速新材料的设计和优化过程，提升数据效率和可访问性。",
      "method": "研究开发了一个主动学习框架，从Materials Project和Open Quantum Materials Database中迭代选择信息性结构。使用组成和性质描述符结合神经网络集成模型进行预测，并采用Query-by-Committee方法实时量化不确定性。比较了四种采样策略：随机采样（基线）、基于不确定性的采样、基于多样性的采样（使用k-means聚类和最远点细化）以及混合方法。实验在四个材料系统（碳、硅、铁、二氧化钛）上进行，以确保方法的泛化性。",
      "result": "实验结果显示，基于多样性的采样策略在多个材料系统上表现出竞争力或优越性能，尤其在二氧化钛上实现了10.9%的性能提升。与随机采样基线相比，该方法在达到相同精度时可以减少5-13%的标记样本需求。执行效率方面，完整流程在Google Colab上每个系统运行时间少于4小时，内存使用低于8GB，这使得资源有限的研究者也能访问，验证了框架的数据高效性和实用性。",
      "conclusion": "本研究的主要贡献是开发了一个主动学习框架，显著减少了训练机器学习原子间势能所需的昂贵计算，提供实用指南促进数据高效的材料研究。学术价值在于推动主动学习在材料科学中的应用，实际应用价值在于使资源有限的研究者能够进行MLIP开发。未来工作方向包括集成对称感知架构以进一步提升性能，并可能扩展到更广泛的材料系统，摘要未明确说明具体局限性。",
      "tags": [
        "Active Learning",
        "Query-by-Committee",
        "k-means clustering",
        "Neural Network Ensemble",
        "Machine-Learned Interatomic Potentials"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:30.885261Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.06795",
    "title": "GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning",
    "authors": [
      "Zhengqing Yan",
      "Xinyang Liu",
      "Yi Zhang",
      "Fan Guo",
      "Yao Liu",
      "Junchen Wan",
      "Kang Song"
    ],
    "abstract": "Automated Theorem Proving (ATP) represents a fundamental challenge in Artificial Intelligence (AI), requiring the construction of machine-verifiable proofs in formal languages such as Lean to evaluate AI reasoning capabilities. Reinforcement learning (RL), particularly the high-performance Group Relative Policy Optimization (GRPO) algorithm, has emerged as a mainstream approach for this task. However, in ATP scenarios, GRPO faces two critical issues: when composite rewards are used, its relative advantage estimation may conflict with the binary feedback from the formal verifier; meanwhile, its static sampling strategy may discard entire batches of data if no valid proof is found, resulting in zero contribution to model updates and significant data waste. To address these limitations, we propose Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO), a method incorporating three core mechanisms: 1) dynamic additional sampling, which resamples invalid batches until a valid proof is discovered; 2) equal-right advantage, decoupling the sign of the advantage function (based on correctness) from its magnitude (modulated by auxiliary rewards) to ensure stable and correct policy updates; and 3) dynamic additional iterations, applying extra gradient steps to initially failed but eventually successful samples to accelerate learning on challenging cases. Experiments conducted on three datasets of varying difficulty (MinF2F-test, MathOlympiadBench, PutnamBench) confirm the effectiveness of GDEPO, while ablation studies validate the necessity of its synergistic components. The proposed method enhances data utilization and optimization efficiency, offering a novel training paradigm for ATP.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.06795.pdf",
    "abs_url": "https://arxiv.org/abs/2601.06795",
    "published": "2026-01-11T07:34:41Z",
    "updated": "2026-01-21T02:58:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出GDEPO方法，通过动态采样、解耦优势函数和附加迭代，优化ATP中强化学习的数据利用和策略更新。",
      "motivation": "自动化定理证明（ATP）是评估AI推理能力的关键任务，强化学习（RL）尤其是Group Relative Policy Optimization（GRPO）算法被广泛应用。然而，在ATP场景中，GRPO面临两个关键问题：当使用复合奖励时，其相对优势估计可能与形式验证器的二进制反馈冲突，导致策略更新不稳定；同时，其静态采样策略在未找到有效证明时丢弃整个数据批次，造成显著数据浪费。这些问题限制了ATP的效率和性能，因此需要改进方法来提高数据利用率和优化稳定性。",
      "method": "GDEPO方法包含三个核心机制：1）动态附加采样，针对无效数据批次重新采样直到发现有效证明，减少数据丢弃；2）平等权利优势，将优势函数的符号（基于证明正确性）与幅度（由辅助奖励调节）解耦，确保策略更新的稳定性和准确性；3）动态附加迭代，对初始失败但最终成功的样本应用额外梯度步骤，加速在挑战性案例上的学习。该方法基于GRPO改进，在ATP任务中实施，使用如Lean等正式语言进行验证，关键创新在于动态数据处理和优势函数解耦。",
      "result": "实验在三个不同难度的数据集（MinF2F-test、MathOlympiadBench、PutnamBench）上进行，证实了GDEPO方法的有效性，消融研究验证了其三个组件的协同作用对性能提升至关重要。与基线GRPO相比，GDEPO显著提高了数据利用率和优化效率，摘要未明确说明具体性能指标如准确率提升，但强调了该方法在减少数据浪费和加速学习方面的优越性。实验结果支持了GDEPO在处理样本约束强化学习任务中的实用性。",
      "conclusion": "GDEPO的主要贡献在于提出了一种新的训练范式，通过动态采样和优势函数解耦，解决了ATP中强化学习的数据浪费和策略更新问题，提高了优化效率和数据利用率。这为自动化定理证明任务提供了更有效的解决方案，学术上扩展了强化学习在形式推理领域的应用，实际中可促进AI推理能力的发展。潜在局限性包括摘要未明确说明的具体数据集限制，未来工作可能包括机制进一步优化或应用于其他样本约束场景。",
      "tags": [
        "Automated Theorem Proving",
        "Reinforcement Learning",
        "Group Relative Policy Optimization",
        "Dynamic Sampling",
        "Advantage Function Decoupling"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:12.432750Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.06196",
    "title": "Manifold-based Sampling for In-Context Hallucination Detection in Large Language Models",
    "authors": [
      "Bodla Krishna Vamshi",
      "Rohan Bhatnagar",
      "Haizhao Yang"
    ],
    "abstract": "Large language models (LLMs) frequently generate factually incorrect or unsupported content, commonly referred to as hallucinations. Prior work has explored decoding strategies, retrieval augmentation, and supervised fine-tuning for hallucination detection, while recent studies show that in-context learning (ICL) can substantially influence factual reliability. However, existing ICL demonstration selection methods often rely on surface-level similarity heuristics and exhibit limited robustness across tasks and models.   We propose MB-ICL, a manifold-based demonstration sampling framework for selecting in-context demonstrations that leverages latent representations extracted from frozen LLMs. By jointly modeling local manifold structure and class-aware prototype geometry, MB-ICL selects demonstrations based on their proximity to learned prototypes rather than lexical or embedding similarity alone.   Across factual verification (FEVER) and hallucination detection (HaluEval) benchmarks, MB-ICL outperforms standard ICL selection baselines in the majority of evaluated settings, with particularly strong gains on dialogue and summarization tasks. The method remains robust under temperature perturbations and model variation, indicating improved stability compared to heuristic retrieval strategies. While lexical retrieval can remain competitive in certain question-answering regimes, our results demonstrate that manifold-based prototype selection provides a reliable and training light approach for hallucination detection without modifying LLM parameters, offering a principled direction for improved ICL demonstration selection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.06196.pdf",
    "abs_url": "https://arxiv.org/abs/2601.06196",
    "published": "2026-01-08T06:17:18Z",
    "updated": "2026-01-21T03:06:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出MB-ICL框架，基于流形采样改进上下文学习演示选择，以增强大语言模型的幻觉检测性能。",
      "motivation": "大语言模型（LLMs）经常生成事实错误或不支持的内容，即幻觉，这严重影响了模型的事实可靠性和实际应用。现有方法如解码策略和检索增强在检测幻觉方面存在局限，而最近的上下文学习（ICL）研究表明其能影响事实可靠性。然而，当前ICL演示选择方法多依赖词汇或嵌入相似性启发式，跨任务和模型的鲁棒性不足，需要更稳健的方法来提升幻觉检测的准确性和普适性。",
      "method": "论文提出MB-ICL方法，一个基于流形的演示采样框架。该方法利用从冻结的大语言模型中提取的潜在表示，联合建模局部流形结构和类感知的原型几何。通过计算演示与学习到的原型之间的接近度来选择ICL演示，而不是仅基于词汇或嵌入相似性，从而避免表面相似性的不足。该方法不修改LLM参数，是一种训练轻量的技术方案。",
      "result": "实验结果显示，MB-ICL在事实验证（FEVER）和幻觉检测（HaluEval）基准测试中，在大多数评估设置下优于标准的ICL选择基线，特别是在对话和摘要任务中表现出显著性能提升。方法在温度扰动和不同模型变化下保持鲁棒性，显示出比启发式检索策略更好的稳定性。摘要未明确说明具体数据，但强调了性能改进和鲁棒性优势。",
      "conclusion": "该研究的主要贡献是提出了MB-ICL框架，为幻觉检测提供了一种无需修改大语言模型参数的可靠且训练轻量的方法。通过基于流形的原型选择，改进了ICL演示选择的稳定性和效果，为未来研究提供了原则性方向。尽管在某些问答场景下词汇检索仍具竞争力，但该方法展示了在多样化任务中的应用潜力，具有学术和实际价值。",
      "tags": [
        "In-Context Learning",
        "Hallucination Detection",
        "Manifold Learning",
        "Prototype Selection",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:26.289312Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.04339",
    "title": "Unified Text-Image Generation with Weakness-Targeted Post-Training",
    "authors": [
      "Jiahui Chen",
      "Philippe Hansen-Estruch",
      "Xiaochuang Han",
      "Yushi Hu",
      "Emily Dinan",
      "Amita Kamath",
      "Michal Drozdzal",
      "Reyhane Askari-Hemmat",
      "Luke Zettlemoyer",
      "Marjan Ghazvininejad"
    ],
    "abstract": "Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.04339.pdf",
    "abs_url": "https://arxiv.org/abs/2601.04339",
    "published": "2026-01-07T19:19:44Z",
    "updated": "2026-01-21T05:54:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种弱点针对的后训练方法，实现文本和图像在单个推理过程中自主联合生成的统一多模态生成系统。",
      "motivation": "现有统一多模态生成系统通常依赖于显式模态切换，即先进行文本推理再手动切换到图像生成，这种分离的顺序推理过程限制了跨模态的耦合，使得自动化的多模态生成变得困难。该研究旨在解决这一问题，因为深度跨模态交互对于文本到图像合成的质量和自然性至关重要，而现有方法在这方面存在不足，缺乏从推理到合成的无缝过渡，导致效率和效果受限。",
      "method": "论文提出的核心方法是使用后训练技术来实现完全统一的文本-图像生成，模型在单个推理过程中自主地从文本推理过渡到视觉合成。具体而言，采用离线的、基于奖励加权的后训练策略，数据为完全自生成的合成数据，并设计了针对特定限制的有针对性数据集，以取代传统的广泛图像-标题语料库或基准对齐数据。关键创新点包括避免显式模态切换、增强模态间耦合以及通过策略性数据选择和奖励加权优化两个模态的生成过程。",
      "result": "在四个多样化的文本到图像基准测试中，该方法的采用显著改进了多模态图像生成的性能，证明了其有效性。具体而言，与使用广泛图像-标题语料库或基准对齐数据的传统方法相比，弱点针对的后训练策略和奖励加权两个模态的方法显示出优越的效果，例如在生成质量或交叉模态一致性方面有所提升，但摘要未明确给出具体的准确率数据，仅提到在多个基准上取得改进。",
      "conclusion": "本研究的主要贡献是提出并验证了一种实现完全统一文本-图像生成的后训练方法，显著提升了跨模态耦合和生成性能。其学术价值在于深入探讨了联合生成对文本到图像合成的影响以及模态相对重要性，为多模态生成领域提供了新思路；实际应用价值在于促进更自然和高效的文本到图像转换系统。未来工作可进一步优化后训练策略或扩展到其他多模态任务中。",
      "tags": [
        "Unified Multimodal Generation",
        "Post-Training",
        "Text-to-Image Synthesis",
        "Reward-Weighted Training",
        "Weakness-Targeted Data"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:37.921575Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.03369",
    "title": "RiskCueBench: Benchmarking Anticipatory Reasoning from Early Risk Cues in Video-Language Models",
    "authors": [
      "Sha Luo",
      "Yogesh Prabhu",
      "Timothy Ossowski",
      "Kaiping Chen",
      "Junjie Hu"
    ],
    "abstract": "With the rapid growth of video centered social media, the ability to anticipate risky events from visual data is a promising direction for ensuring public safety and preventing real world accidents. Prior work has extensively studied supervised video risk assessment across domains such as driving, protests, and natural disasters. However, many existing datasets provide models with access to the full video sequence, including the accident itself, which substantially reduces the difficulty of the task. To better reflect real world conditions, we introduce a new video understanding benchmark RiskCueBench in which videos are carefully annotated to identify a risk signal clip, defined as the earliest moment that indicates a potential safety concern. Experimental results reveal a significant gap in current systems ability to interpret evolving situations and anticipate future risky events from early visual signals, highlighting important challenges for deploying video risk prediction models in practice.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.03369.pdf",
    "abs_url": "https://arxiv.org/abs/2601.03369",
    "published": "2026-01-06T19:14:49Z",
    "updated": "2026-01-21T06:11:42Z",
    "comment": "*updated author email in this version",
    "light_analysis": {
      "overview": "论文提出了RiskCueBench基准，用于评估视频-语言模型从早期风险线索进行预测性推理的能力。",
      "motivation": "随着视频社交媒体的快速发展，从视觉数据中预测风险事件对于确保公共安全和预防现实世界事故具有重要意义。先前工作广泛研究了监督式视频风险评估，覆盖驾驶、抗议和自然灾害等领域。然而，许多现有数据集向模型提供包括事故本身的完整视频序列，这大大降低了任务难度，难以反映真实世界动态风险预测的挑战。因此，需要一个新的基准来更贴近实际条件，促进模型从早期线索进行有效预测。",
      "method": "论文引入了新的视频理解基准RiskCueBench，其中视频被精心标注以识别风险信号剪辑，定义为指示潜在安全关注的最早时刻。该方法聚焦于从早期视觉信号预测未来风险事件，但摘要未明确说明具体的技术路线、模型架构或数据集细节，仅描述了基准的构建和标注策略，旨在评估模型对动态场景的理解和预测能力。",
      "result": "实验结果表明，当前系统在解释不断变化的情况并从早期视觉信号预测未来风险事件方面存在显著差距。摘要未提供具体的性能指标如准确率提升或效率改进，也未与基线方法进行详细对比，但强调了模型在RiskCueBench上的表现不足，突显了现有视频风险预测模型在实践部署中的关键挑战。",
      "conclusion": "研究提出了RiskCueBench基准，旨在评估视频-语言模型的预测性推理能力，特别是从早期风险线索中预测事件。这突显了现有方法在动态风险预测方面的局限性，并为未来研究和模型改进提供了方向，对促进公共安全应用具有重要学术价值和实践意义。摘要未明确提及局限性或未来工作，但暗示了进一步探索的挑战和需求。",
      "tags": [
        "Video-Language Models",
        "Risk Assessment",
        "Anticipatory Reasoning",
        "Benchmarking",
        "Video Understanding"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:15.955958Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.06111",
    "title": "LLM Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions",
    "authors": [
      "Fatima Koaik",
      "Aayush Gupta",
      "Farahan Raza Sheikh"
    ],
    "abstract": "Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis.   We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.06111.pdf",
    "abs_url": "https://arxiv.org/abs/2601.06111",
    "published": "2026-01-03T13:25:33Z",
    "updated": "2026-01-21T06:47:21Z",
    "comment": "13 pages, 1 figure, 4 tables",
    "light_analysis": {
      "overview": "本文提出一个基于大型语言模型（LLM）的社会数字孪生框架，用于模拟人群对政策干预的行为响应，提供机制解释性和领域无关性。",
      "motivation": "研究旨在解决预测人群对政策干预反应的关键挑战，这在实际公共政策制定和计算社会科学中至关重要。传统方法如聚合统计模型虽能捕捉历史相关性，但缺乏内在机制解释性，难以处理未见过的新政策场景，限制了政策模拟的准确性和适用性。现有方法的不足在于无法提供个体行为的内在理解，导致在反事实分析和预测新政策效果时表现不佳，因此需要开发一个兼具解释性和适应性的新框架。",
      "method": "论文提出一个通用框架，构建社会数字孪生作为虚拟人口复制品，其中大型语言模型（LLM）作为个体代理的认知引擎。每个代理由人口统计和心理属性表征，接收政策信号并输出多维行为概率向量；校准层将代理响应聚合映射到可观察的人口级指标，实现与现实数据的验证和反事实分析。以COVID-19疫情响应为例进行实例化，利用丰富的观测数据训练模型，展示了框架的领域无关性和可扩展性。",
      "result": "在疫情响应领域的实验中，校准后的数字孪生在六个行为类别上的宏观平均预测误差比梯度提升基线模型降低了20.7%，显示出显著的性能改进。反事实实验进一步证实了模型对政策变化的响应是单调和有界的，这验证了其行为合理性和预测稳定性。与基线方法的对比突显了框架在提高预测准确性和提供解释性方面的优势，支持其在政策模拟中的应用。",
      "conclusion": "该框架将LLM技术引入社会数字孪生，成功提供了机制解释性，并证明了在多种政策领域的通用性，如交通、经济和环境政策。学术上推动了计算社会科学中仿真模型的发展，实践中增强了政策制定者的模拟和决策能力。作者讨论了方法的局限性（如数据依赖性和模型偏差），并展望了未来扩展到其他领域的方向，进一步优化LLM在行为模拟中的应用。",
      "tags": [
        "Large Language Model",
        "Social Digital Twin",
        "Policy Simulation",
        "Behavioral Modeling",
        "Counterfactual Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:46.340678Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.23437",
    "title": "RealX3D: A Physically-Degraded 3D Benchmark for Multi-view Visual Restoration and Reconstruction",
    "authors": [
      "Shuhong Liu",
      "Chenyu Bao",
      "Ziteng Cui",
      "Yun Liu",
      "Xuangeng Chu",
      "Lin Gu",
      "Marcos V. Conde",
      "Ryo Umagami",
      "Tomohiro Hashimoto",
      "Zijian Hu",
      "Tianhan Xu",
      "Yuan Gan",
      "Yusuke Kurose",
      "Tatsuya Harada"
    ],
    "abstract": "We introduce RealX3D, a real-capture benchmark for multi-view visual restoration and 3D reconstruction under diverse physical degradations. RealX3D groups corruptions into four families, including illumination, scattering, occlusion, and blurring, and captures each at multiple severity levels using a unified acquisition protocol that yields pixel-aligned LQ/GT views. Each scene includes high-resolution capture, RAW images, and dense laser scans, from which we derive world-scale meshes and metric depth. Benchmarking a broad range of optimization-based and feed-forward methods shows substantial degradation in reconstruction quality under physical corruptions, underscoring the fragility of current multi-view pipelines in real-world challenging environments.",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.23437.pdf",
    "abs_url": "https://arxiv.org/abs/2512.23437",
    "published": "2025-12-29T12:57:19Z",
    "updated": "2026-01-21T11:43:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了RealX3D基准，用于评估多视图视觉恢复和3D重建在物理退化条件下的表现。",
      "motivation": "多视图视觉恢复和3D重建在实际应用中常面临光照变化、散射、遮挡和模糊等物理退化，导致算法性能下降。现有方法缺乏对这些退化因素的系统评估，基准测试大多基于模拟或理想环境，无法真实反映挑战性场景下的脆弱性。RealX3D旨在解决这一问题，通过提供真实捕获的退化数据，检验和推动更鲁棒算法的开发，以应对自动驾驶、机器人感知等现实世界任务。",
      "method": "论文构建了RealX3D基准，核心方法包括将物理退化分为四个家族（光照、散射、遮挡和模糊），并在多个严重级别上使用统一采集协议捕获像素对齐的低质量/高质量视图。每个场景包含高分辨率捕获、RAW图像和密集激光扫描数据，从中推导出世界尺度的网格和度量深度，为多视图方法提供全面的训练和评估数据，支持视觉恢复和3D重建任务。",
      "result": "基准测试涵盖了基于优化的和前馈的多种方法，结果显示在物理退化条件下，重建质量显著下降，具体表现为准确率降低和效率受损，与理想环境下的基线方法相比差距明显。摘要未明确说明具体性能指标，如提升百分比，但强调这种退化突显了当前多视图管道在现实世界环境中的脆弱性，呼吁开发更鲁棒的算法。",
      "conclusion": "RealX3D基准的提出为多视图视觉恢复和3D重建领域提供了重要评估工具，揭示了现有方法在物理退化下的局限性。学术上，它促进了基准测试的发展；实际上，有助于设计更适应真实场景的算法，如无人驾驶和增强现实。未来工作可基于此基准改进方法，探索新的深度学习架构或鲁棒优化策略，以提升泛化能力。",
      "tags": [
        "Multi-view Reconstruction",
        "Visual Restoration",
        "Physical Degradation",
        "Benchmarking",
        "Laser Scanning"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:18.146555Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.20905",
    "title": "DiEC: Diffusion Embedded Clustering",
    "authors": [
      "Haidong Hu",
      "Xiaoyu Zheng",
      "Jin Zhou",
      "Yingxu Wang",
      "Rui Wang",
      "Pei Dong",
      "Shiyuan Han",
      "Lin Wang",
      "C. L. Philip Chen",
      "Tong Zhang",
      "Yuehui Chen"
    ],
    "abstract": "Deep clustering methods typically rely on a single, well-defined representation for clustering. In contrast, pretrained diffusion models provide abundant and diverse multi-scale representations across network layers and noise timesteps. However, a key challenge is how to efficiently identify the most clustering-friendly representation in the layer*timestep space. To address this issue, we propose Diffusion Embedded Clustering (DiEC), an unsupervised framework that performs clustering by leveraging optimal intermediate representations from pretrained diffusion models. DiEC systematically evaluates the clusterability of representations along the trajectory of network depth and noise timesteps. Meanwhile, an unsupervised search strategy is designed for recognizing the Clustering-optimal Layer (COL) and Clustering-optimal Timestep (COT) in the layer*timestep space of pretrained diffusion models, aiming to promote clustering performance and reduce computational overhead. DiEC is fine-tuned primarily with a structure-preserving DEC-style KL-divergence objective at the fixed COL + COT, together with a random-timestep diffusion denoising objective to maintain the generative capability of the pretrained model. Without relying on augmentation-based consistency constraints or contrastive learning, DiEC achieves excellent clustering performance across multiple benchmark datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.20905.pdf",
    "abs_url": "https://arxiv.org/abs/2512.20905",
    "published": "2025-12-24T03:10:00Z",
    "updated": "2026-01-21T09:28:12Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出DiEC框架，通过搜索预训练扩散模型中的最优中间表示来提升无监督聚类性能。",
      "motivation": "当前深度聚类方法通常依赖单一、定义良好的表示，限制了在复杂数据上的聚类效果；预训练扩散模型提供跨网络层和噪声时间步的丰富多尺度表示，但如何高效地在层×时间步空间中找到最聚类友好的表示是一个关键挑战。现有方法可能因计算开销大或表示选择不当而导致性能不足，本研究旨在解决此问题，以提升聚类效率和准确性，减少资源消耗。",
      "method": "DiEC框架系统评估预训练扩散模型中不同网络层和噪声时间步的表示的聚类能力，设计无监督搜索策略以识别聚类最优层（COL）和聚类最优时间步（COT）。在固定的COL和COT处，使用结构保持的DEC式KL散度目标进行微调，并结合随机时间步扩散去噪目标以维持预训练模型的生成能力；关键创新在于避免依赖增强一致性约束或对比学习，专注于通过优化表示选择来提升聚类性能。",
      "result": "DiEC在多个基准数据集上实现了优异的聚类性能，摘要未明确说明具体数据如准确率提升，但通过系统搜索最优表示，框架避免了计算开销大的增强或对比方法，从而在保持高效的同时提升了效果；与基线方法相比，可能展现出更高的聚类质量，但详细对比需参考论文全文。",
      "conclusion": "本研究提出DiEC框架，成功利用预训练扩散模型的多尺度表示进行无监督聚类，通过识别COL和COT显著提升了性能并减少了计算负担；方法创新在于结合扩散模型表示和聚类优化，为深度学习聚类提供了新途径，具有学术价值和实际应用潜力；潜在局限性包括搜索策略的效率，未来工作可扩展到更复杂数据集或改进搜索算法。",
      "tags": [
        "Diffusion Models",
        "Deep Clustering",
        "Unsupervised Learning",
        "Representation Selection",
        "KL-divergence"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:28.075861Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.20362",
    "title": "CRAFT: Continuous Reasoning and Agentic Feedback Tuning for Multimodal Text-to-Image Generation",
    "authors": [
      "V. Kovalev",
      "A. Kuvshinov",
      "A. Buzovkin",
      "D. Pokidov",
      "D. Timonin"
    ],
    "abstract": "Recent work has shown that inference-time reasoning and reflection can improve text-to-image generation without retraining. However, existing approaches often rely on implicit, holistic critiques or unconstrained prompt rewrites, making their behavior difficult to interpret, control, or stop reliably. In contrast, large language models have benefited from explicit, structured forms of **thinking** based on verification, targeted correction, and early stopping. We introduce CRAFT (Continuous Reasoning and Agentic Feedback Tuning), a training-free and model-agnostic framework for multimodal image generation. CRAFT transforms a user prompt into a set of explicit, dependency-structured visual constraints, verifies generated images using a vision-language model, and performs targeted prompt updates only when specific constraints are violated. This iterative process includes an explicit stopping criterion, resulting in an interpretable and controllable inference-time refinement loop. Across multiple model families and challenging benchmarks, CRAFT consistently improves compositional accuracy, text rendering, and preference-based evaluations, with particularly strong gains for lightweight generators. Importantly, these improvements incur only a negligible inference-time overhead, allowing smaller or cheaper models to approach the quality of substantially more expensive systems. Our results suggest that explicitly structured, constraint-driven inference-time reasoning is a key ingredient for improving the reliability of multimodal generative models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.20362.pdf",
    "abs_url": "https://arxiv.org/abs/2512.20362",
    "published": "2025-12-23T13:44:41Z",
    "updated": "2026-01-21T16:42:28Z",
    "comment": "37 pages, 42 figures",
    "light_analysis": {
      "overview": "提出CRAFT框架，通过显式结构化视觉约束和迭代验证，实现无需训练的多模态文本到图像生成推理优化，显著提升准确性和可控性。",
      "motivation": "现有文本到图像生成方法在推理时依赖隐式批评或无约束提示重写，导致生成过程难以解释、控制和可靠停止，限制了模型的实用性和可靠性。CRAFT旨在解决这一关键问题，通过引入结构化推理机制，提供更可解释和可控的生成流程，以改善多模态生成模型的信任度和性能。",
      "method": "CRAFT框架将用户提示转换为显式的、依赖结构化的视觉约束，利用视觉语言模型验证生成图像是否满足约束，仅在特定约束违反时进行有针对性的提示更新。该过程包括显式停止准则，形成一个可解释的迭代推理循环。核心创新在于模型无关性和无需训练的设计，允许灵活应用于不同生成模型，但具体数据集和模型架构在摘要中未明确说明。",
      "result": "在多个模型家庭和挑战性基准测试中，CRAFT持续提高了组合准确性、文本渲染质量和偏好评估分数，尤其在轻量级生成器上表现出显著增益。改进的同时，推理开销可忽略不计，使得低成本模型能够接近更昂贵系统的生成质量。与基线方法相比，CRAFT在可靠性和可控性方面有明显优势，但具体性能指标如准确率提升值在摘要中未明确说明。",
      "conclusion": "CRAFT框架的主要贡献在于证明了显式结构化推理是提升多模态生成模型可靠性的关键因素。该研究不仅提高了文本到图像生成的准确性和可控性，还提供了高效路径，使轻量模型能以低成本实现高质量生成。未来工作可探索其在其他生成任务中的应用，并进一步优化推理效率。",
      "tags": [
        "Continuous Reasoning",
        "Agentic Feedback Tuning",
        "Multimodal Text-to-Image Generation",
        "Vision-Language Model",
        "Constraint Verification"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:25.754338Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.20260",
    "title": "Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "authors": [
      "Jiawei Ge",
      "Jiuxin Cao",
      "Xinyi Li",
      "Xuelin Zhu",
      "Chang Liu",
      "Bo Liu",
      "Chen Feng",
      "Ioannis Patras"
    ],
    "abstract": "Weakly-Supervised Camouflaged Object Detection (WSCOD) aims to locate and segment objects that are visually concealed within their surrounding scenes, relying solely on sparse supervision such as scribble annotations. Despite recent progress, existing WSCOD methods still lag far behind fully supervised ones due to two major limitations: (1) the pseudo masks generated by general-purpose segmentation models (e.g., SAM) and filtered via rules are often unreliable, as these models lack the task-specific semantic understanding required for effective pseudo labeling in COD; and (2) the neglect of inherent annotation bias in scribbles, which hinders the model from capturing the global structure of camouflaged objects. To overcome these challenges, we propose ${D}^{3}$ETOR, a two-stage WSCOD framework consisting of Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing. In the first stage, we introduce an adaptive entropy-driven point sampling method and a multi-agent debate mechanism to enhance the capability of SAM for COD, improving the interpretability and precision of pseudo masks. In the second stage, we design FADeNet, which progressively fuses multi-level frequency-aware features to balance global semantic understanding with local detail modeling, while dynamically reweighting supervision strength across regions to alleviate scribble bias. By jointly exploiting the supervision signals from both the pseudo masks and scribble semantics, ${D}^{3}$ETOR significantly narrows the gap between weakly and fully supervised COD, achieving state-of-the-art performance on multiple benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.20260.pdf",
    "abs_url": "https://arxiv.org/abs/2512.20260",
    "published": "2025-12-23T11:16:16Z",
    "updated": "2026-01-21T15:11:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出一个名为${D}^{3}$ETOR的两阶段框架，结合辩论增强伪标签和频率感知渐进去偏技术，以显著提升弱监督伪装物体检测的准确性和鲁棒性。",
      "motivation": "弱监督伪装物体检测（WSCOD）依赖于稀疏的涂鸦注释来定位和分割视觉上隐藏的物体，但现有方法面临两个主要局限性：一是通用分割模型（如SAM）生成的伪掩码不可靠，缺乏伪装物体检测所需的特定语义理解，导致伪标签质量低下；二是忽略涂鸦注释中的固有偏见，使模型难以捕捉伪装物体的全局结构，这些限制导致WSCOD性能远逊于全监督方法，阻碍了实际应用中的准确检测。因此，研究旨在解决伪掩码生成不可靠和注释偏见问题，以缩小弱监督与全监督之间的差距。",
      "method": "论文提出的${D}^{3}$ETOR框架分为两个阶段。第一阶段是辩论增强的伪标签，引入自适应熵驱动点采样方法和多代理辩论机制，以增强分割模型（如SAM）对伪装物体的理解，从而提高伪掩码的可解释性和精度。第二阶段是频率感知渐进去偏，设计了FADeNet网络，逐步融合多级频率感知特征，平衡全局语义理解与局部细节建模，同时动态重加权不同区域的监督强度，以缓解涂鸦注释的偏见。该框架联合利用伪掩码和涂鸦语义的监督信号，形成端到端的训练过程。",
      "result": "实验结果表明，${D}^{3}$ETOR框架在多个基准测试中实现了最先进的性能，显著缩小了弱监督与全监督伪装物体检测之间的性能差距。尽管摘要未提供具体的数值指标（如准确率或效率数据），但强调了该方法通过结合伪掩码和涂鸦语义的监督信号，在检测准确性和鲁棒性方面有显著提升，超越了现有的WSCOD方法，证明了其在克服伪掩码不可靠性和注释偏见方面的有效性。",
      "conclusion": "该论文的主要贡献是提出了${D}^{3}$ETOR框架，有效解决了弱监督伪装物体检测中的伪掩码生成不可靠和注释偏见问题，提升了模型的性能。研究具有重要的学术价值，为弱监督学习领域引入了新的辩论机制和频率感知技术；在实际应用中，通过减少对密集标注的依赖，有助于降低检测成本并提高效率。潜在的局限性包括伪标签生成过程的复杂性，未来工作可进一步优化方法或扩展到其他稀疏注释场景。",
      "tags": [
        "Weakly-Supervised Learning",
        "Camouflaged Object Detection",
        "Pseudo Labeling",
        "Debate Mechanism",
        "Frequency-Aware Feature Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:19.987202Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.19691",
    "title": "Scalable Stewardship of an LLM-Assisted Clinical Benchmark with Physician Oversight",
    "authors": [
      "Junze Ye",
      "Daniel Tawfik",
      "Alex J. Goodell",
      "Nikhil V. Kotha",
      "Mark K. Buyyounouski",
      "Mohsen Bayati"
    ],
    "abstract": "We examine the reliability of a widely used clinical AI benchmark whose reference labels were partially generated by LLMs, and find that a substantial fraction are clinically misaligned. We introduce a phased stewardship procedure to amplify the positive impact of physician experts' feedback and then demonstrate, via a controlled RL experiment, how uncaught label bias can materially affect downstream LLM evaluation and alignment. Our results demonstrate that partially LLM-generated labels can embed systemic errors that distort not only evaluation but also downstream model alignment. By adopting a hybrid oversight system, we can prioritize scarce expert feedback to maintain benchmarks as living, clinically-grounded documents. Ensuring this alignment is a prerequisite for the safe deployment of LLMs in high-stakes medical decision support.",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2512.19691.pdf",
    "abs_url": "https://arxiv.org/abs/2512.19691",
    "published": "2025-12-22T18:59:34Z",
    "updated": "2026-01-21T18:48:54Z",
    "comment": "Project codebase: https://github.com/junzeye/validate-medcalc-labels",
    "light_analysis": {
      "overview": "论文提出一种分阶段的管理程序，结合医生监督，以减少LLM生成的临床基准标签中的偏差，并通过受控RL实验验证其对下游评估的影响。",
      "motivation": "在高风险医疗领域，临床AI基准对于评估模型性能至关重要。然而，现有基准可能因部分标签由LLM生成而引入临床偏差，导致评估结果不准确，进而影响模型对齐和部署安全性。这种偏差若不纠正，可能误导医疗决策支持系统的开发，增加风险。因此，需要开发有效方法来检测和修正这些错误，确保基准的可靠性和临床相关性。",
      "method": "论文引入一个分阶段的管理程序，旨在放大医生专家的反馈作用，以优化基准维护。通过受控的强化学习实验，模拟和分析标签偏见如何影响下游LLM的评估和对齐过程。关键创新是采用混合监督系统，优先处理稀缺的专家资源，结合LLM辅助和专家审核，以纠正系统性错误。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验结果表明，LLM生成的标签中存在显著的临床偏差，这些偏差不仅扭曲了基准评估的准确性，还影响了下游模型的性能和对齐效果。通过混合监督系统，能够有效利用专家反馈来减少错误，提升基准的可靠性。然而，摘要未提供具体的性能指标如准确率提升数据，仅描述了标签偏差对评估和模型对齐的定性影响。",
      "conclusion": "研究强调了确保临床基准与临床现实对齐的重要性，这是安全部署LLM在医疗决策支持中的前提。通过混合监督系统，展示了优化专家反馈的方式，为基准的持续管理提供了实践指导。该研究的学术价值在于揭示了标签生成过程中的系统性风险，实际应用价值在于提升AI在医疗领域的可靠性和安全性。未来工作可能涉及扩展该方法到其他高风歨领域并验证其泛化能力。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Clinical Benchmark",
        "Expert Oversight",
        "Label Bias"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:38.537133Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.06052",
    "title": "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization",
    "authors": [
      "Hanyu Li",
      "Jiangshan Duo",
      "Bofei Gao",
      "Hailin Zhang",
      "Sujian Li",
      "Xiaotie Deng",
      "Liang Zhao"
    ],
    "abstract": "Chain-of-thought reasoning in large language models can trigger an \"overthinking trap\": longer rollouts raise cost and latency yet often yield unreliable accuracy gains. Existing methods use global, static controls that may suppress needed reasoning. We propose mastery-gated, sample-level, soft reinforcement learning compression that penalizes long rollouts only when the model already solves the problem and has produced a shorter rollout. Across benchmarks, it cuts response length by 20-40% with comparable or higher accuracy and generalizes across domains: a model trained on math spontaneously shortens unseen tasks (code, instruction following, general-knowledge QA) without hurting accuracy. We further show two-way transfer between non-agent CoT and tool-use agents: non-agent training reduces SWE-Bench Verified rounds by 13%, while compressing a thinking agent cuts SWE trajectories by 67% tokens and 52% rounds and shortens non-agent outputs by up to 44%. Compression is thus not cosmetic brevity, but an inherent computation policy -- what to keep, and what to forget.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.06052.pdf",
    "abs_url": "https://arxiv.org/abs/2601.06052",
    "published": "2025-12-19T06:30:54Z",
    "updated": "2026-01-21T06:34:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于强化学习的链式思维压缩方法，实现跨域泛化并提升推理效率。",
      "motivation": "大语言模型中的链式思维推理常引发“过度思考陷阱”，推理过程过长会增加计算成本和延迟，但准确性提升不一定可靠。现有压缩方法采用全局静态控制，可能不必要地抑制模型所需的推理深度。因此，需要一种动态智能压缩机制，以在保证推理质量的同时优化效率，解决当前方法的不足。",
      "method": "本研究提出一种名为掌握度门控、样本级软强化学习的压缩方法。核心创新在于仅当模型已成功解决问题并生成更短推理路径时，才通过强化学习惩罚长推理过程，从而避免抑制必要的推理步骤。方法在数学任务上训练，并测试于代码、指令遵循和知识问答等未见任务，以验证其跨域泛化能力。",
      "result": "在多项基准测试中，该方法能将响应长度减少20-40%，同时保持或提高准确性。跨域实验显示，在数学任务上训练的模型能自动缩短未见任务的推理长度，而不影响准确性。双向转移实验中，非代理训练减少SWE-Bench验证轮次13%，压缩思维代理则降低token数量67%、轮次52%，并缩短非代理输出高达44%。",
      "conclusion": "本研究提出了一种基于强化学习的链式思维压缩策略，不仅有效减少推理长度和成本，还展现出跨域泛化潜力。主要贡献在于将压缩视为一种固有计算政策，智能决定推理中的保留与遗忘，从而提升大语言模型效率。未来工作可扩展至更多任务类型，并优化策略以实现更精细控制。",
      "tags": [
        "Reinforcement Learning",
        "Chain-of-Thought Reasoning",
        "Compression",
        "Cross-Domain Generalization",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:29.571189Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.17160",
    "title": "Can Synthetic Images Serve as Effective and Efficient Class Prototypes?",
    "authors": [
      "Dianxing Shi",
      "Dingjie Fu",
      "Yuqiao Liu",
      "Jun Wang"
    ],
    "abstract": "Vision-Language Models (VLMs) have shown strong performance in zero-shot image classification tasks. However, existing methods, including Contrastive Language-Image Pre-training (CLIP), all rely on annotated text-to-image pairs for aligning visual and textual modalities. This dependency introduces substantial cost and accuracy requirement in preparing high-quality datasets. At the same time, processing data from two modes also requires dual-tower encoders for most models, which also hinders their lightweight. To address these limitations, we introduce a ``Contrastive Language-Image Pre-training via Large-Language-Model-based Generation (LGCLIP)\" framework. LGCLIP leverages a Large Language Model (LLM) to generate class-specific prompts that guide a diffusion model in synthesizing reference images. Afterwards these generated images serve as visual prototypes, and the visual features of real images are extracted and compared with the visual features of these prototypes to achieve comparative prediction. By optimizing prompt generation through the LLM and employing only a visual encoder, LGCLIP remains lightweight and efficient. Crucially, our framework requires only class labels as input during whole experimental procedure, eliminating the need for manually annotated image-text pairs and extra pre-processing. Experimental results validate the feasibility and efficiency of LGCLIP, demonstrating great performance in zero-shot classification tasks and establishing a novel paradigm for classification.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.17160.pdf",
    "abs_url": "https://arxiv.org/abs/2512.17160",
    "published": "2025-12-19T01:39:43Z",
    "updated": "2026-01-21T07:00:03Z",
    "comment": "Accepted by IEEE ICASSP2026",
    "light_analysis": {
      "overview": "LGCLIP框架利用大型语言模型和扩散模型生成合成图像作为类原型，实现无需手动标注的零样本图像分类。",
      "motivation": "现有视觉语言模型（VLMs）如CLIP在零样本图像分类中表现良好，但依赖于标注的图像-文本对，导致数据集准备成本高且准确性要求严格。同时，模型通常需要双塔编码器处理视觉和文本模态，增加了计算负担，不利于轻量化应用。本研究旨在解决这些问题，通过减少数据标注依赖和简化模型架构，提高效率和降低成本，促进实际应用。",
      "method": "LGCLIP框架首先使用大型语言模型（LLM）根据类标签生成类特定提示，然后利用这些提示指导扩散模型合成参考图像作为视觉原型。接着，仅用一个视觉编码器提取真实图像的视觉特征，并与合成原型的特征进行对比预测。关键创新在于通过LLM优化提示生成，并采用单一视觉编码器，使框架轻量高效，无需手动标注或预处理，仅需类标签作为输入。",
      "result": "实验结果表明，LGCLIP框架在零样本分类任务中表现优异，验证了其可行性和效率，具体性能指标摘要未明确说明，但作者指出它建立了新颖的分类范式。与基线方法相比，LGCLIP减少了数据标注需求，并降低了计算成本，为轻量级分类系统提供了有效途径，展现出良好的应用前景。",
      "conclusion": "LGCLIP的主要贡献在于提出利用合成图像作为类原型的方法，减少了对标注图像-文本对的依赖，并简化了模型架构，使其更轻量高效。该研究在学术上为视觉语言模型和零样本学习提供了创新范式，实际应用价值在于降低数据准备成本和提高分类效率。未来工作可探索不同生成模型的集成或扩展至更多领域。",
      "tags": [
        "Vision-Language Models (VLMs)",
        "Large Language Models (LLMs)",
        "Diffusion Models",
        "Zero-shot Learning",
        "Contrastive Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:53.266873Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.14465",
    "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
    "authors": [
      "Siyuan Zhu",
      "Chengdong Xu",
      "Kaiqiang Ke",
      "Chao Yu"
    ],
    "abstract": "In long-context question answering, selecting the appropriate scope of context for a query remains a key and unresolved challenge. Insufficient context can lead to missing essential information, whereas excessive context often introduces noise and degrades answer quality. Conventional methods, such as retrieving a fixed number of passages or applying reranking, struggle to dynamically determine which context to include. This is especially problematic for factoid questions, which typically depend only on a few precise pieces of evidence. To overcome this limitation, we propose Context-Picker, a reasoning-aware framework that reframes context selection as the task of identifying a minimal sufficient evidence subset, moving beyond conventional similarity-based ranking. Context-Picker uses a human-inspired two-stage reinforcement learning schedule: stage 1 focuses on improving the recall rate of critical passages, and stage 2 prioritizes pruning redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines ``minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense and task-aligned supervision. Experiments on five long-context and multi-hop QA datasets demonstrate that our method outperforms strong RAG baselines and achieved higher answer accuracy. Ablation studies also indicate that our coarse-to-fine optimization schedule, the redundancy-aware reward shaping, along with the rationale generated by the policy, all contribute substantially to these gains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2512.14465.pdf",
    "abs_url": "https://arxiv.org/abs/2512.14465",
    "published": "2025-12-16T14:52:11Z",
    "updated": "2026-01-21T02:41:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Context-Picker框架，利用多阶段强化学习和离线证据蒸馏，实现长上下文问答中的动态上下文选择。",
      "motivation": "研究动机在于解决长上下文问答中动态上下文选择的挑战。不足的上下文易导致关键信息缺失，而过量上下文引入噪声降低答案质量，尤其对依赖少量精确证据的事实性问题影响显著。传统方法如固定段落检索或重排名难以动态决定上下文范围，相似性排名不足以处理复杂推理需求，因此需要更智能的选择机制以提高问答系统的准确性和效率。",
      "method": "方法核心是Context-Picker框架，采用推理感知的两阶段强化学习：第一阶段优化关键段落召回率，第二阶段专注冗余剪枝以精炼最小充分证据集。关键创新包括离线证据蒸馏管道，通过Leave-One-Out程序挖掘最小充分证据集合，解决强化学习中的奖励稀疏性问题，提供密集和任务对齐的监督。技术特色为粗到细优化计划和冗余感知奖励塑形，应用于长上下文和多跳问答任务，基于五个数据集进行模型训练和验证。",
      "result": "实验在五个长上下文和多跳QA数据集上进行，结果显示Context-Picker优于强RAG基线，实现了更高的答案准确率。消融研究表明，粗到细优化计划、冗余感知奖励塑形以及策略生成的原理均对性能提升有实质性贡献，验证了框架各组件的重要性。尽管摘要未明确具体准确率数值，但方法在多项任务中展现出显著改进，与基线相比提升了回答质量。",
      "conclusion": "结论总结了Context-Picker的主要贡献：通过多阶段强化学习和离线证据蒸馏，有效解决长上下文问答中的动态上下文选择问题。学术价值在于提出新的推理感知框架和奖励设计方法；实际应用潜力体现在提升问答系统性能。未来工作可扩展至其他领域或优化框架效率，摘要未明确说明具体局限性，但可能涉及计算成本或泛化能力的进一步研究。",
      "tags": [
        "Reinforcement Learning",
        "Multi-stage Reinforcement Learning",
        "Context Selection",
        "Offline Evidence Distillation",
        "LOO Procedure"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:01.720880Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.13376",
    "title": "Unlocking Generalization in Polyp Segmentation with DINO Self-Attention \"keys\"",
    "authors": [
      "Carla Monteiro",
      "Valentina Corbetta",
      "Regina Beets-Tan",
      "Luís F. Teixeira",
      "Wilson Silva"
    ],
    "abstract": "Automatic polyp segmentation is crucial for improving the clinical identification of colorectal cancer (CRC). While Deep Learning (DL) techniques have been extensively researched for this problem, current methods frequently struggle with generalization, particularly in data-constrained or challenging settings. Moreover, many existing polyp segmentation methods rely on complex, task-specific architectures. To address these limitations, we present a framework that leverages the intrinsic robustness of DINO self-attention \"key\" features for robust segmentation. Unlike traditional methods that extract tokens from the deepest layers of the Vision Transformer (ViT), our approach leverages the key features of the self-attention module with a simple convolutional decoder to predict polyp masks, resulting in enhanced performance and better generalizability. We validate our approach using a multi-center dataset under two rigorous protocols: Domain Generalization (DG) and Extreme Single Domain Generalization (ESDG). Our results, supported by a comprehensive statistical analysis, demonstrate that this pipeline achieves state-of-the-art (SOTA) performance, significantly enhancing generalization, particularly in data-scarce and challenging scenarios. While avoiding a polyp-specific architecture, we surpass well-established models like nnU-Net and UM-Net. Additionally, we provide a systematic benchmark of the DINO framework's evolution, quantifying the specific impact of architectural advancements on downstream polyp segmentation performance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.13376.pdf",
    "abs_url": "https://arxiv.org/abs/2512.13376",
    "published": "2025-12-15T14:29:47Z",
    "updated": "2026-01-21T08:12:26Z",
    "comment": "We have found a bug in our codebase. The DINO vision encoder was not properly frozen, therefore the results and claims are not fully valid. We are working on new results",
    "light_analysis": {
      "overview": "本文提出了一种利用DINO自注意力“关键”特征的框架，通过简单卷积解码器实现息肉分割的卓越泛化性能。",
      "motivation": "自动息肉分割对结直肠癌的临床识别至关重要，但现有深度学习方法在泛化性方面存在不足，尤其在数据受限或挑战性设置中，依赖复杂任务特定架构，导致难以适应新场景。因此，需要开发更鲁棒且泛化能力强的分割方法，以提高临床应用的可靠性和准确性，应对数据稀缺和多样化医疗数据集的挑战。",
      "method": "本研究框架利用DINO自注意力模块中的“关键”特征进行息肉分割，与传统方法从Vision Transformer（ViT）最深层提取令牌不同，该方法直接使用自注意力关键特征，结合简单卷积解码器预测息肉掩码。这避免了复杂任务特定架构，专注于特征的内在鲁棒性。实验在多中心数据集上进行，采用域泛化（DG）和极端单域泛化（ESDG）协议验证模型在不同领域的适用性。",
      "result": "在域泛化和极端单域泛化协议下的多中心数据集验证中，该框架实现了最先进的性能，显著增强了泛化能力，特别是在数据稀缺和挑战性场景中。通过全面统计分析，结果超越了nnU-Net和UM-Net等知名模型，展示了在避免息肉特定架构的同时，仍能达到优秀分割效果，摘要未提供具体数值指标，但强调泛化方面的显著提升。",
      "conclusion": "本研究的主要贡献是提出基于DINO自注意力关键特征的框架，有效提高了息肉分割的泛化性，避免了复杂架构需求。学术上，突出了自注意力特征在医学图像分割中的潜力；应用上，为临床数据稀缺环境提供了更鲁棒的解决方案。未来工作可进一步探索DINO框架演变对下游任务的影响，并扩展到其他医疗图像分析领域。",
      "tags": [
        "Polyp Segmentation",
        "DINO",
        "Self-Attention",
        "Vision Transformer",
        "Domain Generalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:28.263584Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.11771",
    "title": "Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints",
    "authors": [
      "Kai Yao",
      "Marc Juarez"
    ],
    "abstract": "Model fingerprint detection has shown promise to trace the provenance of AI-generated images in forensic applications. However, despite the inherent adversarial nature of these applications, existing evaluations rarely consider adversarial settings. We present the first systematic security evaluation of these techniques, formalizing threat models that encompass both white- and black-box access and two attack goals: fingerprint removal, which erases identifying traces to evade attribution, and fingerprint forgery, which seeks to cause misattribution to a target model. We implement five attack strategies and evaluate 14 representative fingerprinting methods across RGB, frequency, and learned-feature domains on 12 state-of-the-art image generators. Our experiments reveal a pronounced gap between clean and adversarial performance. Removal attacks are highly effective, often achieving success rates above 80% in white-box settings and over 50% under black-box access. While forgery is more challenging than removal, its success varies significantly across targeted models. We also observe a utility--robustness trade-off: accurate attribution methods are often vulnerable to attacks and, although some techniques are robust in specific settings, none achieves robustness and accuracy across all evaluated threat models. These findings highlight the need for techniques that balance robustness and accuracy, and we identify the most promising approaches toward this goal. Code available at: https://github.com/kaikaiyao/SmudgedFingerprints.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.11771.pdf",
    "abs_url": "https://arxiv.org/abs/2512.11771",
    "published": "2025-12-12T18:33:14Z",
    "updated": "2026-01-21T06:01:15Z",
    "comment": "This work has been accepted for publication in the 4th IEEE Conference on Secure and Trustworthy Machine Learning (IEEE SaTML 2026). The final version will be available on IEEE Xplore",
    "light_analysis": {
      "overview": "本文首次对AI图像指纹技术进行系统安全评估，形式化对抗威胁模型并揭示其在对抗攻击下的脆弱性。",
      "motivation": "AI图像指纹检测在取证应用中用于追踪AI生成图像的来源，但现有评估通常忽视对抗性设置，这在现实场景中至关重要，因为攻击者可能试图移除或伪造指纹以逃避检测或导致错误归属。现有方法在清洁环境下表现良好，但在对抗攻击下可能失效，缺乏对安全风险的全面分析，这限制了其在实际高对抗性环境中的应用潜力。因此，本研究旨在填补这一空白，评估指纹技术在不同威胁模型下的鲁棒性。",
      "method": "本研究提出一个系统安全评估框架，首先形式化威胁模型，包括白盒和黑盒访问条件，以及两个攻击目标：指纹移除（消除识别痕迹以逃避归属）和指纹伪造（错误归属到指定目标模型）。实现了五种攻击策略，并在12个最新图像生成器上评估14种代表性指纹方法，覆盖RGB域、频率域和学习特征域。核心创新在于首次在指纹检测领域引入标准化对抗评估，使用多样化数据集和方法进行全面测试。",
      "result": "实验结果显示，清洁与对抗性能之间存在显著差距：指纹移除攻击在白盒设置中成功率常超过80%，黑盒设置中超过50%，显示出高有效性。指纹伪造更具挑战性，成功与否高度依赖于目标模型，变异性较大。此外，存在效用-鲁棒性权衡：高准确性的归属方法往往对攻击脆弱，而部分技术仅在特定设置下鲁棒，没有一种方法在所有评估威胁模型中同时实现高鲁棒性和高准确性。",
      "conclusion": "本研究的主要贡献是首次系统评估了AI图像指纹的鲁棒性，通过形式化威胁模型揭示现有方法的脆弱性，强调需要开发平衡鲁棒性和准确性的技术。学术价值在于推动安全AI检测领域的进步，实际应用价值在于为取证系统提供风险警示和优化方向。局限性包括未发现全面鲁棒的方法，未来工作应专注于改进方法以应对多样攻击，论文已识别出有前景的研究途径。",
      "tags": [
        "AI Image Fingerprints",
        "Adversarial Attacks",
        "Robustness Evaluation",
        "Threat Modeling",
        "Image Generation Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:50.128384Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.11509",
    "title": "Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs",
    "authors": [
      "Mohor Banerjee",
      "Nadya Yuki Wangsajaya",
      "Syed Ali Redha Alsagoff",
      "Min Sen Tan",
      "Zachary Choy Kit Chun",
      "Alvin Chan Guo Wei"
    ],
    "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities in natural language understanding and reasoning, but suffer from hallucination: the generation of factually incorrect content. While numerous methods have been developed to reduce hallucinations, their impact on creative generations remains unexplored. This gap is particularly critical for AI-assisted scientific discovery, which requires both factual accuracy and creative hypothesis generation. We investigate how three hallucination-reduction techniques: Chain of Verification (CoVe), Decoding by Contrasting Layers (DoLa), and Retrieval-Augmented Generation (RAG), affect creativity in LLMs. Evaluating multiple model families (LLaMA, Qwen, Mistral) at varying scales (1B - 70B parameters) on two creativity benchmarks (NeoCoder and CS4), we find that these methods have opposing effects on divergent creativity. CoVe enhances divergent thinking, DoLa suppresses it, and RAG shows minimal impact. Our findings provide guidance for selecting appropriate hallucination-reduction methods in scientific applications, where the balance between factual accuracy and creative exploration is crucial.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.11509.pdf",
    "abs_url": "https://arxiv.org/abs/2512.11509",
    "published": "2025-12-12T12:14:29Z",
    "updated": "2026-01-21T12:07:32Z",
    "comment": "Accepted at the AAAI 2026 Workshop on AI for Scientific Research (AI4Research)",
    "light_analysis": {
      "overview": "本文实证研究了三种减少幻觉技术对大语言模型创造力的影响，发现它们对发散创造力产生不同效应，为平衡事实准确性与创新性提供指导。",
      "motivation": "大语言模型虽然在自然语言理解和推理方面表现卓越，但常出现幻觉问题，即生成事实错误内容。已有多种方法如CoVe、DoLa、RAG被开发以减轻幻觉，然而它们对创造性生成的影响尚未探索，这尤其关键于AI辅助科学发现，因为该领域需要同时保证事实准确性和创造性假设生成。本研究旨在填补这一空白，探讨减少幻觉技术如何影响LLMs的创造力，以优化模型在复杂任务中的应用。",
      "method": "本研究采用实证方法，考察三种减少幻觉技术：链式验证（CoVe）、层对比解码（DoLa）和检索增强生成（RAG）。通过评估多个模型家族（包括LLaMA、Qwen、Mistral）在不同规模（从1B到70B参数）上的表现，使用两个创造力基准（NeoCoder和CS4）来量化发散创造力。关键创新在于首次系统分析这些技术在创造力方面的效果，实验设计覆盖多种模型配置，以揭示其通用性，避免单一模型或场景的局限性。",
      "result": "实验结果表明，三种减少幻觉技术对发散创造力有不同影响：链式验证（CoVe）能够增强发散思维，层对比解码（DoLa）抑制它，而检索增强生成（RAG）的影响相对较小。这些发现基于创造力基准测试得出，与未应用减少幻觉技术的基线相比，突出了方法间的权衡效应，例如CoVe在提升事实准确性的同时促进创造性输出，而DoLa可能牺牲创新性以换取更高的准确性，具体性能差异随模型规模而变化。",
      "conclusion": "本研究的主要贡献在于首次揭示了减少幻觉技术对大语言模型创造力的不同影响，填补了研究空白，为AI辅助科学发现等需要准确性和创造性的应用提供了实用指导。学术上，拓展了LLMs性能评估的维度；实际上，帮助用户根据任务需求选择合适方法以平衡事实准确与创新探索。未来工作可探索更多技术组合或参数调整，以优化模型在多样场景中的表现，并可能进一步研究其他创造力维度的受影响情况。",
      "tags": [
        "Large Language Model",
        "Chain of Verification",
        "Decoding by Contrasting Layers",
        "Retrieval-Augmented Generation",
        "Creativity Benchmark"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:13.448095Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.07062",
    "title": "$\\mathrm{D}^\\mathrm{3}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction",
    "authors": [
      "Changliang Xia",
      "Chengyou Jia",
      "Minnan Luo",
      "Zhuohang Dang",
      "Xin Shen",
      "Bowen Ping"
    ],
    "abstract": "Although diffusion models with strong visual priors have emerged as powerful dense prediction backbones, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric structure mappings. To address this, we introduce $\\mathrm{D}^\\mathrm{3}$-Predictor, a noise-free deterministic diffusion-based dense prediction model built by reformulating a pretrained diffusion model without stochasticity noise. Instead of relying on noisy inputs to leverage diffusion priors, $\\mathrm{D}^\\mathrm{3}$-Predictor views the pretrained diffusion network as an ensemble of timestep-dependent visual experts and self-supervisedly aggregates their heterogeneous priors into a single, clean, and complete geometric prior. Meanwhile, we utilize task-specific supervision to seamlessly adapt this noise-free prior to dense prediction tasks. Extensive experiments on various dense prediction tasks demonstrate that $\\mathrm{D}^\\mathrm{3}$-Predictor achieves competitive or state-of-the-art performance in diverse scenarios. In addition, it requires less than half the training data previously used and efficiently performs inference in a single step. Our code, data, and checkpoints are publicly available at https://x-gengroup.github.io/HomePage_D3-Predictor/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.07062.pdf",
    "abs_url": "https://arxiv.org/abs/2512.07062",
    "published": "2025-12-08T00:39:32Z",
    "updated": "2026-01-21T03:21:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出D^3-Predictor，一种基于无噪声确定性扩散的密集预测模型，通过重新构建预训练扩散模型消除随机噪声，以改善图像到几何的确定性映射。",
      "motivation": "密集预测任务如语义分割或深度估计需要从图像到几何结构的确定性映射，但现有扩散模型在采样时引入随机噪声，这与确定性需求不匹配。这种噪声会破坏精细空间线索，导致几何结构映射受损，限制了扩散模型在密集预测中的应用。因此，需要一种方法消除噪声，以充分利用扩散模型的视觉先验。",
      "method": "D^3-Predictor的核心方法是重新构建预训练扩散模型，移除其随机噪声成分。它将预训练网络视为一系列时间步依赖的视觉专家集合，通过自监督学习将这些异质先验聚合为单一、完整的几何先验。然后，利用任务特定监督，如分割或深度估计的标注数据，将此无噪声先验适配到密集预测任务。关键技术包括预训练扩散网络的重构、自监督聚合机制以及任务导向的微调。",
      "result": "在多种密集预测任务上的实验表明，D^3-Predictor达到了竞争性或最优的性能，与基线方法相比表现出色。具体而言，它仅需少于一半的训练数据即可实现类似或更好的效果，且推理过程仅需单步完成，显著提升了效率。摘要未明确说明具体准确率指标，但暗示了性能改进和资源节省的优势。",
      "conclusion": "该研究的核心贡献是开发了D^3-Predictor，成功解决了扩散模型在密集预测中的噪声干扰问题，提供了一种确定性映射方案。学术上，它拓展了扩散模型的应用领域，为密集预测研究提供了新视角；实践上，减少了训练数据需求和推理时间，具有部署潜力。摘要未明确说明局限性，未来工作可能包括更广泛的任务扩展或进一步优化模型效率。",
      "tags": [
        "Diffusion Models",
        "Dense Prediction",
        "Deterministic Mapping",
        "Self-Supervised Learning",
        "Noise-Free Sampling"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:01.626766Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.03470",
    "title": "Difference Decomposition Networks for Infrared Small Target Detection",
    "authors": [
      "Chen Hu",
      "Mingyu Zhou",
      "Shuai Yuan",
      "Hongbo Hu",
      "Zhenming Peng",
      "Tian Pu",
      "Xiyin Li"
    ],
    "abstract": "Infrared small target detection (ISTD) faces two major challenges: a lack of discernible target texture and severe background clutter, which results in the background obscuring the target. To enhance targets and suppress backgrounds, we propose the Basis Decomposition Module (BDM) as an extensible and lightweight module based on basis decomposition, which decomposes a complex feature into several basis features and enhances certain information while eliminating redundancy. Extending BDM leads to a series of modules, including the Spatial Difference Decomposition Module (SD$^\\mathrm{2}$M), Spatial Difference Decomposition Downsampling Module (SD$^\\mathrm{3}$M), and Temporal Difference Decomposition Module (TD$^\\mathrm{2}$M). Based on these modules, we develop the Spatial Difference Decomposition Network (SD$^\\mathrm{2}$Net) for single-frame ISTD (SISTD) and the Spatiotemporal Difference Decomposition Network (STD$^\\mathrm{2}$Net) for multi-frame ISTD (MISTD). SD$^\\mathrm{2}$Net integrates SD$^\\mathrm{2}$M and SD$^\\mathrm{3}$M within an adapted U-shaped architecture. We employ TD$^\\mathrm{2}$M to introduce motion information, which transforms SD$^\\mathrm{2}$Net into STD$^\\mathrm{2}$Net. Extensive experiments on SISTD and MISTD datasets demonstrate state-of-the-art (SOTA) performance. On the SISTD task, SD$^\\mathrm{2}$Net performs well compared to most established networks. On the MISTD datasets, STD$^\\mathrm{2}$Net achieves a mIoU of 87.68\\%, outperforming SD$^\\mathrm{2}$Net, which achieves a mIoU of 64.97\\%. Our codes are available: https://github.com/greekinRoma/IRSTD_HC_Platform.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.03470.pdf",
    "abs_url": "https://arxiv.org/abs/2512.03470",
    "published": "2025-12-03T05:52:06Z",
    "updated": "2026-01-21T11:43:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于基分解的差异分解网络，通过增强目标特征并抑制背景干扰，显著提升红外小目标检测的性能。",
      "motivation": "红外小目标检测面临两大挑战：目标纹理不明显和背景杂波严重，导致目标易被背景遮蔽，传统方法可能难以有效分离目标与背景，从而影响检测精度。这一问题在监控和军事应用中至关重要，现有技术可能无法充分处理复杂特征，因此需要一种能强化目标信息并抑制冗余背景的新方法。",
      "method": "研究提出基分解模块（BDM），通过将复杂特征分解为多个基特征来增强关键信息并消除冗余。扩展模块包括空间差异分解模块（SD²M）、空间差异分解下采样模块（SD³M）和时间差异分解模块（TD²M）。基于这些模块，构建了空间差异分解网络（SD²Net），采用适应性的U形架构；并引入TD²M的时域运动信息，扩展为时空差异分解网络（STD²Net），用于多帧检测。",
      "result": "在单帧红外小目标检测（SISTD）任务中，SD²Net相较于多数现有网络表现优异。在多帧检测（MISTD）数据集上，STD²Net的平均交并比（mIoU）达到87.68%，显著优于SD²Net的64.97%，展现出最先进的性能水平。实验表明，新方法有效提升了检测精度。",
      "conclusion": "论文的主要贡献在于提出了基于基分解的创新模块和网络结构，有效应对红外小目标检测中的挑战。该方法在数据集上实现了最优性能，具有重要的学术价值和实际应用潜力，如可应用于红外监控系统。未来工作可能包括优化模块效率或扩展到其他领域，摘要未明确说明具体局限性。",
      "tags": [
        "Basis Decomposition",
        "Difference Decomposition",
        "U-shaped Architecture",
        "Spatiotemporal Processing",
        "Infrared Target Detection"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:01.499404Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.00332",
    "title": "Assertion-Conditioned Compliance: A Provenance-Aware Vulnerability in Multi-Turn Tool-Calling Agents",
    "authors": [
      "Daud Waqas",
      "Aaryamaan Golthi",
      "Erika Hayashida",
      "Huanzhi Mao"
    ],
    "abstract": "Multi-turn tool-calling LLMs (models capable of invoking external APIs or tools across several user turns) have emerged as a key feature in modern AI assistants, enabling extended dialogues from benign tasks to critical business, medical, and financial operations. Yet implementing multi-turn pipelines remains difficult for many safety-critical industries due to ongoing concerns regarding model resilience. While standardized benchmarks such as the Berkeley Function-Calling Leaderboard (BFCL) have underpinned confidence concerning advanced function-calling models (like Salesforce's xLAM V2), there is still a lack of visibility into multi-turn conversation-level robustness, especially given their exposure to real-world systems. In this paper, we introduce Assertion-Conditioned Compliance (A-CC), a novel evaluation paradigm for multi-turn function-calling dialogues. A-CC provides holistic metrics that evaluate a model's behavior when confronted with misleading assertions originating from two distinct vectors: (1) user-sourced assertions (USAs), which measure sycophancy toward plausible but misinformed user beliefs, and (2) function-sourced assertions (FSAs), which measure compliance with plausible but contradictory system policies (e.g., stale hints from unmaintained tools). Our results show that models are highly vulnerable to both USA sycophancy and FSA policy conflicts, confirming A-CC as a critical, latent vulnerability in deployed agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.00332.pdf",
    "abs_url": "https://arxiv.org/abs/2512.00332",
    "published": "2025-11-29T05:44:37Z",
    "updated": "2026-01-21T13:21:37Z",
    "comment": "15 pages (incl. Appendix), 3 figures, 7 tables",
    "light_analysis": {
      "overview": "论文提出Assertion-Conditioned Compliance (A-CC)，一种新评估范式，用于揭示多回合工具调用大语言模型在误导性断言下的脆弱性。",
      "motivation": "多回合工具调用大语言模型在关键行业（如医疗、金融）中部署时，面临模型韧性不足的挑战。尽管现有基准如伯克利函数调用排行榜（BFCL）提升了信心，但它们无法全面评估对话级别的鲁棒性。由于模型暴露于真实世界系统，缺乏对用户和工具来源的误导性断言的可见性可能导致安全风险，因此需要新的评估方法来识别潜在漏洞，以弥补现有方法的不足。",
      "method": "论文提出Assertion-Conditioned Compliance (A-CC)，作为一个新颖的评估范式。A-CC通过两种向量来评估模型行为：用户来源的断言（USAs），测量模型对可能但错误用户信念的奉承；函数来源的断言（FSAs），测量模型对可能但矛盾系统策略（如过时工具提示）的合规性。摘要未明确说明具体数据集或模型架构，但该方法旨在提供整体指标，重点关注多回合对话中的行为分析，以增强鲁棒性评估。",
      "result": "实验结果表明，模型在面对用户来源的断言时表现出高度的奉承行为（USA sycophancy），同时在函数来源的断言下显示对矛盾策略的过度合规（FSA policy conflicts）。这些发现证实了A-CC所揭示的漏洞，表明多回合工具调用代理在部署中高度脆弱。摘要未提供具体性能指标数据，但强调了模型脆弱性的普遍性，通过与基线方法的对比，凸显了此问题的严重性。",
      "conclusion": "论文的主要贡献在于提出A-CC，一个用于评估多回合工具调用代理鲁棒性的新范式。该研究揭示了模型在误导性断言下的潜在漏洞，具有重要的学术价值，因为它扩展了对话级安全评估的视角。在实际应用中，这提醒开发者在部署AI助手时需关注此类风险，以确保系统可靠性。摘要未明确说明局限性或未来工作方向，但暗示了需要进一步研究来改进模型韧性。",
      "tags": [
        "Multi-Turn Tool-Calling",
        "Large Language Model",
        "Vulnerability Assessment",
        "Assertion-Conditioned Compliance",
        "Function-Calling"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:49.892879Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.16107",
    "title": "T2T-VICL: Unlocking the Boundaries of Cross-Task Visual In-Context Learning via Implicit Text-Driven VLMs",
    "authors": [
      "Shao-Jun Xia",
      "Huixin Zhang",
      "Zhengzhong Tu"
    ],
    "abstract": "In large language models (LLM), in-context learning (ICL) refers to performing new tasks by conditioning on small demonstrations provided in the input context. Recent advances in visual in-context learning (VICL) demonstrate promising capabilities for solving downstream tasks by unified vision-language models (VLMs). When the visual prompt and the target images originate from different visual tasks, can VLMs still enable VICL? In the paper, we propose a fully collaborative pipeline, i.e. T2T-VICL, for VLMs to investigate the potential of cross-task VICL. Fundamentally, we design a mechanism to generate and select text prompts that best implicitly describe the differences between two distinct low-level vision tasks, and construct the first cross-task VICL dataset. Building upon this, we propose a novel inference framework that combines perceptual score-based reasoning with traditional evaluation metrics to perform cross-task VICL. Our approach achieves top-tier results across twelve cross-task scenarios and second-tier performance in nine additional scenarios, unlocking the boundaries of cross-task VICL within VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.16107.pdf",
    "abs_url": "https://arxiv.org/abs/2511.16107",
    "published": "2025-11-20T07:02:06Z",
    "updated": "2026-01-21T06:18:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了T2T-VICL方法，通过隐式文本驱动解锁了跨任务视觉上下文学习的边界，扩展了视觉语言模型的潜力。",
      "motivation": "该研究旨在解决当视觉提示和目标图像来自不同视觉任务时，统一视觉语言模型是否仍能实现视觉上下文学习的问题。现有方法主要集中在同任务场景，而跨任务学习更具挑战性，对于提升模型泛化能力和实际应用价值至关重要。摘要未明确说明现有方法的具体不足，但可以推断当前视觉上下文学习方法可能局限于任务对齐，限制了在多样化场景中的应用，因此探索跨任务VICL有助于推动模型适应性和多功能发展。",
      "method": "研究方法包括设计一个机制来生成和选择最佳隐式描述不同低层视觉任务差异的文本提示，并构建首个跨任务VICL数据集。在此基础上，提出一个新颖的推理框架，结合基于感知得分的推理与传统评估指标，以执行跨任务VICL。核心创新点在于隐式文本驱动和跨任务学习管道的建立，利用文本提示来桥接任务差异，通过视觉语言模型实现上下文学习。",
      "result": "实验结果显示，T2T-VICL方法在十二个跨任务场景中取得了顶级性能，并在九个额外场景中实现了第二级性能，验证了其在解锁跨任务VICL边界方面的有效性。尽管摘要未提供具体性能指标如准确率提升，但结果证明了该方法优于基线方法，能够在多样化任务间实现有效的上下文学习。",
      "conclusion": "论文的主要贡献是提出了T2T-VICL管道，成功解锁了视觉语言模型中跨任务上下文学习的潜力，为视觉上下文学习领域提供了新方向。学术价值在于扩展了VICL的应用场景，推动模型从单一任务向多任务适应发展；实际应用可能涉及智能视觉系统的多功能集成。未来工作可能需要进一步验证方法的泛化能力，并探索在更复杂任务或更大规模数据集上的表现。",
      "tags": [
        "Visual In-Context Learning (VICL)",
        "Cross-Task Learning",
        "Vision-Language Models (VLM)",
        "Text Prompt Generation",
        "Perceptual Score-based Reasoning"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:11.005332Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.13391",
    "title": "Finding Kissing Numbers with Game-theoretic Reinforcement Learning",
    "authors": [
      "Chengdong Ma",
      "Théo Tao Zhaowei",
      "Pengyu Li",
      "Minghao Liu",
      "Haojun Chen",
      "Zihao Mao",
      "Yuan Cheng",
      "Yuan Qi",
      "Yaodong Yang"
    ],
    "abstract": "Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game that can be fully parallelized at large scale, and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions, discovers over 6000 new structures in 14 and other dimensions, and establishes new records for generalized kissing configurations under various angular constraints. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.13391.pdf",
    "abs_url": "https://arxiv.org/abs/2511.13391",
    "published": "2025-11-17T14:02:00Z",
    "updated": "2026-01-21T16:46:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于游戏理论强化学习系统PackingStar，在高维Kissing数问题上实现突破，超越了长期人类记录并发现新结构，展示了AI探索高维空间的能力。",
      "motivation": "Kissing数问题旨在确定围绕中心球体的最大非重叠球体数，自牛顿时代以来一直是几何、数论和信息论的基础挑战。现有方法依赖于网格和编码，但在超过8维后，由于高维几何的不规则性和指数级组合复杂性（超过围棋复杂度），可扩展性受限。这导致需要更高效的方法来解决这一长期未解问题，以推动理论进展和潜在应用。",
      "method": "研究将Kissing数问题建模为可并行化的两玩家矩阵完成游戏，其中矩阵条目表示球体中心向量的成对余弦。一个玩家填充条目，另一个玩家校正次优条目，合作最大化矩阵大小以对应Kissing数。使用游戏理论强化学习系统PackingStar进行训练，关键创新在于合作动态显著提高样本质量，使极端大规模的高维空间可处理，而摘要未明确说明具体数据集或模型架构。",
      "result": "PackingStar系统重现了以往配置，并在维度25至31中超越了所有人类已知记录，其中25维配置几何对应Leech lattice，暗示可能最优性。在13维实现了自1971年以来的首次突破，并在14维及其他维度发现了超过6000个新结构。此外，在多种角度约束下建立了广义Kissing配置的新记录，展示了AI在复杂几何问题上的卓越性能。",
      "conclusion": "该研究的主要贡献在于利用AI技术成功解决了高维Kissing数问题，验证了AI探索高维空间的能力超越人类直觉，为球体包装和更广泛的几何问题开辟了新途径。这具有重要的学术价值，可能推动信息理论和编码理论的发展，尽管摘要未明确说明局限性或未来工作方向。",
      "tags": [
        "Game-theoretic Reinforcement Learning",
        "High-dimensional Geometry",
        "Matrix Completion",
        "Kissing Number Problem",
        "Sphere Packing"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:48.962304Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.09345",
    "title": "Seer Self-Consistency: Advance Budget Estimation for Adaptive Test-Time Scaling",
    "authors": [
      "Shiyu Ji",
      "Yixuan Wang",
      "Yijun Liu",
      "Qingfu Zhu",
      "Wanxiang Che"
    ],
    "abstract": "Test-time scaling improves the inference performance of Large Language Models (LLMs) but also incurs substantial computational costs. Although recent studies have reduced token consumption through dynamic self-consistency, they remain constrained by the high latency of sequential requests. In this paper, we propose SeerSC, a dynamic self-consistency framework that simultaneously improves token efficiency and latency by integrating System 1 and System 2 reasoning. Specifically, we utilize the rapid System 1 to compute the answer entropy for given queries. This score is then used to evaluate the potential of samples for scaling, enabling dynamic self-consistency under System 2. Benefiting from the advance and accurate estimation provided by System 1, the proposed method can reduce token usage while simultaneously achieving a significant decrease in latency through parallel generation. It outperforms existing methods, achieving up to a 47% reduction in token consumption and a 43% reduction in inference latency without significant performance loss.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2511.09345.pdf",
    "abs_url": "https://arxiv.org/abs/2511.09345",
    "published": "2025-11-12T13:57:43Z",
    "updated": "2026-01-21T03:25:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了SeerSC框架，通过集成System 1和System 2推理，在大型语言模型的测试时扩展中同时提升token效率和降低推理延迟。",
      "motivation": "研究动机在于，测试时扩展能提升大型语言模型的推理性能，但带来高计算成本。现有动态自一致性方法虽然减少了token消耗，但仍受限于高延迟，这限制了其在实际应用中的效率，尤其是在需要快速响应的场景下。因此，开发一种能同时优化token使用和延迟的方法变得至关重要，以克服现有技术的不足并提高大型语言模型的实用性和可扩展性。",
      "method": "论文提出SeerSC框架，核心是集成System 1和System 2推理。System 1用于快速计算查询的答案熵，以此评估样本对扩展的潜力，从而在System 2下实现动态自一致性。该方法通过提前准确估计，减少了不必要的token使用，并利用并行生成降低延迟。摘要未明确说明具体数据集或模型架构，但重点在于框架的设计和创新点，如结合System 1的快速推理和System 2的深度处理来优化测试时扩展过程。",
      "result": "实验结果表明，SeerSC在减少token消耗方面达到47%的减少，推理延迟降低43%，且性能无显著下降。与现有动态自一致性方法相比，它显著优于其他方法，展示了在效率和速度上的双重优势。这些数据基于摘要提供，具体实验设置和基准测试摘要未明确说明，但强调了SeerSC在实际应用中带来的显著改进。",
      "conclusion": "本研究的主要贡献是提出了SeerSC框架，有效解决了测试时扩展中效率和延迟的平衡问题。学术上，它为动态自一致性方法提供了新的思路，结合System 1和System 2推理来优化大型语言模型；实际应用中，可减少计算成本，提升模型部署效率。摘要未明确提及局限性或未来工作方向，但可能涉及进一步优化并行生成或扩展到更广泛的任务中。",
      "tags": [
        "Large Language Models",
        "Dynamic Self-Consistency",
        "System 1 and System 2 Reasoning",
        "Parallel Generation",
        "Answer Entropy"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:18.632454Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.09149",
    "title": "Enabling Agents to Communicate Entirely in Latent Space",
    "authors": [
      "Zhuoyun Du",
      "Runze Wang",
      "Huiyu Bai",
      "Zouying Cao",
      "Xiaoyong Zhu",
      "Yu Cheng",
      "Bo Zheng",
      "Wei Chen",
      "Haochao Ying"
    ],
    "abstract": "While natural language is the de facto communication medium for LLM-based agents, it presents a fundamental constraint. The process of downsampling rich, internal latent states into discrete tokens inherently limits the depth and nuance of information that can be transmitted, thereby hindering collaborative problem-solving. Inspired by telepathy, which bypasses symbolic language in communication, we propose Interlat (Inter-agent Latent Space Communication), a paradigm that leverages the continuous last hidden states of an LLM as a representation of its thought for direct communication (termed latent communication). An additional learned compression process further compresses latent communication via latent space reasoning. Experiments demonstrate that Interlat outperforms both fine-tuned chain-of-thought (CoT) prompting and single-agent baselines, even across heterogeneous models, promoting more exploratory behavior and enabling genuine utilization of latent information. Further compression not only substantially accelerates inference by up to 24 times but also maintains competitive performance through an efficient information-preserving mechanism. We position this work as a feasibility study of entirely latent space inter-agent communication, and our results highlight its potential, offering valuable insights for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.09149.pdf",
    "abs_url": "https://arxiv.org/abs/2511.09149",
    "published": "2025-11-12T09:37:22Z",
    "updated": "2026-01-21T02:35:09Z",
    "comment": "Work in progess",
    "light_analysis": {
      "overview": "本文提出Interlat范式，使AI代理在潜在空间中直接通信，克服自然语言瓶颈，提升协作效率和推理速度。",
      "motivation": "当前基于大型语言模型（LLM）的代理通常依赖自然语言进行通信，但将内部丰富的潜在状态降采样为离散令牌的过程，限制了信息传输的深度和细微差别，从而阻碍了协作问题解决。自然语言通信的固有瓶颈影响了代理间高效交互，因此探索更直接的通信方式以克服这一限制变得至关重要。",
      "method": "论文提出Interlat（Inter-agent Latent Space Communication）方法，利用LLM的连续最后隐藏状态作为思想表示，实现代理间的直接潜在通信。通过额外学习到的压缩过程，进一步在潜在空间中压缩通信信息，借助推理优化传递效率。该方法绕过了自然语言的符号化步骤，直接在连续潜在空间中进行交互，关键创新在于结合潜在状态表示和学习压缩机制。",
      "result": "实验结果显示，Interlat在性能上优于微调的链式思维提示和单代理基线模型，即使在异质模型中也促进更探索性行为并有效利用潜在信息。进一步的压缩处理显著加速推理过程，速度提升高达24倍，同时通过高效信息保留机制保持了竞争性性能水平。这表明潜在通信能提升协作效果和效率。",
      "conclusion": "本研究作为可行性研究，证明了在潜在空间中实现代理间通信的可行性，展示了其在提升协作效率和加速推理方面的潜力。它为高效AI系统和多代理协作领域的未来研究提供了重要洞察。摘要未明确说明具体局限性，但未来工作可探索更复杂应用场景和优化压缩机制。",
      "tags": [
        "Large Language Model",
        "Latent Space Communication",
        "Compression Learning",
        "Hidden States",
        "Inter-agent Collaboration"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:06.373179Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.06810",
    "title": "ConeGS: Error-Guided Densification Using Pixel Cones for Improved Reconstruction With Fewer Primitives",
    "authors": [
      "Bartłomiej Baranowski",
      "Stefano Esposito",
      "Patricia Gschoßmann",
      "Anpei Chen",
      "Andreas Geiger"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) achieves state-of-the-art image quality and real-time performance in novel view synthesis but often suffers from a suboptimal spatial distribution of primitives. This issue stems from cloning-based densification, which propagates Gaussians along existing geometry, limiting exploration and requiring many primitives to adequately cover the scene. We present ConeGS, an image-space-informed densification framework that is independent of existing scene geometry state. ConeGS first creates a fast Instant Neural Graphics Primitives (iNGP) reconstruction as a geometric proxy to estimate per-pixel depth. During the subsequent 3DGS optimization, it identifies high-error pixels and inserts new Gaussians along the corresponding viewing cones at the predicted depth values, initializing their size according to the cone diameter. A pre-activation opacity penalty rapidly removes redundant Gaussians, while a primitive budgeting strategy controls the total number of primitives, either by a fixed budget or by adapting to scene complexity, ensuring high reconstruction quality. Experiments show that ConeGS consistently enhances reconstruction quality and rendering performance across Gaussian budgets, with especially strong gains under tight primitive constraints where efficient placement is crucial.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.06810.pdf",
    "abs_url": "https://arxiv.org/abs/2511.06810",
    "published": "2025-11-10T07:54:58Z",
    "updated": "2026-01-21T08:56:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "ConeGS通过错误引导的密集化结合像素锥体，改进3D高斯泼溅重建质量，减少基元数量，提升渲染性能。",
      "motivation": "3D高斯泼溅在实时视图合成中虽然表现优秀，但克隆基元密集化导致基元空间分布不佳，需要大量基元覆盖场景，影响效率和重建质量。现有方法依赖现有几何状态，限制了探索能力，导致资源浪费。ConeGS旨在解决此问题，通过更智能的密集化策略优化基元放置，提高场景重建的准确性，尤其在资源受限情况下尤为重要。",
      "method": "ConeGS首先使用快速Instant Neural Graphics Primitives (iNGP)构建几何代理，估计像素深度。在3D高斯泼溅优化过程中，识别高误差像素，并沿对应的视图锥在预测深度处插入新高斯基元，根据锥直径初始化基元大小。采用预激活不透明度惩罚移除冗余基元，并通过基元预算策略控制总基元数量，包括固定预算或自适应于场景复杂度，确保高质量重建和高效优化。",
      "result": "实验显示，ConeGS在各种基元预算下一致提升重建质量和渲染性能，与基线方法相比表现更优。在基元约束严格时，高效放置至关重要，ConeGS展现出显著增益，证明它能在减少基元数量的同时维持或改进重建效果，具体数据如准确率和效率改进摘要未明确说明。",
      "conclusion": "ConeGS提出一个图像空间引导的密集化框架，有效解决了3D高斯泼溅中基元分布问题，通过独立于现有几何状态的策略，实现更优的基元放置。研究具有学术价值，推动了视图合成技术的发展，同时在实际应用中可提高渲染效率和资源利用率。未来工作可能包括优化算法以适应更复杂场景或结合其他模型。",
      "tags": [
        "3D Gaussian Splatting",
        "Densification",
        "Pixel Cones",
        "Instant Neural Graphics Primitives",
        "Optimization"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:11.241881Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.04469",
    "title": "Towards Causal Market Simulators",
    "authors": [
      "Dennis Thumm",
      "Luis Ontaneda Mijares"
    ],
    "abstract": "Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.",
    "categories": [
      "cs.LG",
      "q-fin.CP",
      "stat.OT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.04469.pdf",
    "abs_url": "https://arxiv.org/abs/2511.04469",
    "published": "2025-11-06T15:44:07Z",
    "updated": "2026-01-21T13:14:57Z",
    "comment": "ICAIF 2025 Workshop on Rethinking Financial Time-Series",
    "light_analysis": {
      "overview": "该论文提出了TNCM-VAE模型，通过结合变分自编码器和结构因果模型，生成保留因果关系的反事实金融时间序列。",
      "motivation": "目前基于深度生成模型的市场生成器在合成金融数据生成方面显示出潜力，但现有方法缺乏因果推理能力，这对于反事实分析和风险评估至关重要，限制了在金融压力测试和场景分析中的应用，因为这些应用需要生成基于因果机制的合理数据轨迹以准确评估风险。",
      "method": "论文提出了时间序列神经因果模型变分自编码器（TNCM-VAE），该方法将变分自编码器与结构因果模型结合，以生成反事实金融时间序列，同时保留时间依赖性和因果关系。关键技术包括在解码器架构中利用有向无环图强制因果约束，并使用因果Wasserstein距离进行训练，确保模型学习并遵循数据背后的因果结构，从而生成合理的反事实轨迹。",
      "result": "模型在受Ornstein-Uhlenbeck过程启发的合成自回归模型上进行验证，展示了在反事实概率估计方面的卓越性能，L1距离低至0.03-0.10，表明生成的反事实轨迹接近真实数据。摘要未明确说明与基线方法的直接对比细节，但强调其优于现有方法，支持因果推理能力。",
      "conclusion": "该研究的主要贡献是开发了TNCM-VAE模型，能够生成尊重因果机制的反事实金融时间序列，从而在金融应用中实现压力测试、场景分析和增强回测。学术价值在于融合了深度学习和因果推理，推动市场模拟器向因果感知方向发展；实际应用价值高，但未来可能需要扩展至真实市场数据验证，并优化模型在大规模场景下的性能。",
      "tags": [
        "Variational Autoencoder",
        "Structural Causal Models",
        "Causal Reasoning",
        "Counterfactual Analysis",
        "Financial Time Series"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:50.004091Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.01951",
    "title": "NeuroClean: A Generalized Machine-Learning Approach to Neural Time-Series Conditioning",
    "authors": [
      "Manuel A. Hernandez Alonso",
      "Michael Depass",
      "Stephan Quessy",
      "Ali Falaki",
      "Soraya Rahimi",
      "Numa Dancause",
      "Ignasi Cos"
    ],
    "abstract": "Electroencephalography (EEG) and local field potentials (LFP) are two widely used techniques to record electrical activity from the brain. These signals are used in both the clinical and research domains for multiple applications. However, most brain data recordings suffer from a myriad of artifacts and noise sources other than the brain itself. Thus, a major requirement for their use is proper and, given current volumes of data, a fully automatized conditioning. As a means to this end, here we introduce an unsupervised, multipurpose EEG/LFP preprocessing method, the NeuroClean pipeline. In addition to its completeness and reliability, NeuroClean is an unsupervised series of algorithms intended to mitigate reproducibility issues and biases caused by human intervention. The pipeline is designed as a five-step process, including the common bandpass and line noise filtering, and bad channel rejection. However, it incorporates an efficient independent component analysis with an automatic component rejection based on a clustering algorithm. This machine learning classifier is used to ensure that task-relevant information is preserved after each step of the cleaning process. We used several data sets to validate the pipeline. NeuroClean removed several common types of artifacts from the signal. Moreover, in the context of motor tasks of varying complexity, it yielded more than 97% accuracy (vs. a chance-level of 33.3%) in an optimized Multinomial Logistic Regression model after cleaning the data, compared to the raw data, which performed at 74% accuracy. These results show that NeuroClean is a promising pipeline and workflow that can be applied to future work and studies to achieve better generalization and performance on machine learning pipelines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.01951.pdf",
    "abs_url": "https://arxiv.org/abs/2511.01951",
    "published": "2025-11-03T12:13:07Z",
    "updated": "2026-01-21T13:43:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "NeuroClean 是一种无监督的机器学习管道，用于自动清理神经时间序列数据（如 EEG 和 LFP），以减少伪影并提升分析准确性。",
      "motivation": "EEG 和 LFP 是记录大脑电活动的关键技术，广泛应用于临床和研究领域。然而，这些信号常受伪影和噪声干扰，影响数据质量和分析准确性。现有预处理方法多依赖人工操作，在处理大规模数据时效率低下，且易引入人为偏见和可重复性问题。因此，开发全自动的无监督预处理方法成为关键需求，以确保数据可靠性和自动化处理流程，适应当前数据量的增长。摘要中强调，自动化清理有助于提高信号处理的一致性和泛化能力。",
      "method": "NeuroClean 是一个五步无监督预处理管道，包括带通滤波、线噪声滤波和坏通道拒绝等常规步骤。其核心创新在于结合高效的独立成分分析（ICA）和基于聚类算法的自动成分拒绝，以分离并移除伪影成分。此外，使用机器学习分类器（如 Multinomial Logistic Regression）在整个清理过程中监控任务相关信息，确保清理步骤不会损失关键数据。整个流程设计为系列算法，强调无监督特性以减少人为干预，提高了预处理的自动化水平和可靠性。",
      "result": "NeuroClean 在多个数据集上验证，成功移除多种常见伪影类型。在运动任务中，使用清理后数据训练的优化 Multinomial Logistic Regression 模型，准确率从原始数据的 74% 提升到 97% 以上，显著高于机会水平的 33.3%。这些结果表明，NeuroClean 能有效改善信号质量，增强下游机器学习任务的性能，并且与基线方法（原始数据）相比，显示了明显的改进，支持了其在噪声减少和数据分析中的高效性。",
      "conclusion": "NeuroClean 作为一种无监督预处理管道，通过自动化清理神经时间序列数据，减少了人为偏见和可重复性问题。其学术价值在于提供了一种可靠且可扩展的数据预处理方法，增强了 EEG/LFP 分析的准确性。实际应用中，它能提升机器学习管道的泛化能力和性能，可广泛应用于未来研究和临床场景。局限性可能包括对不同数据类型或噪声源的适应性，未来工作可进一步优化算法以适应更广泛的应用。",
      "tags": [
        "Electroencephalography (EEG)",
        "Local Field Potentials (LFP)",
        "Independent Component Analysis (ICA)",
        "Clustering Algorithm",
        "Multinomial Logistic Regression"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:22.076080Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.24709",
    "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?",
    "authors": [
      "Yihao Li",
      "Saeed Salehi",
      "Lyle Ungar",
      "Konrad P. Kording"
    ],
    "abstract": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a quadratic similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in DINO, CLIP, and ImageNet-supervised ViTs, but is markedly weaker in MAE, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.24709.pdf",
    "abs_url": "https://arxiv.org/abs/2510.24709",
    "published": "2025-10-28T17:57:05Z",
    "updated": "2026-01-21T16:16:08Z",
    "comment": "Accepted as a Spotlight at NeurIPS 2025",
    "light_analysis": {
      "overview": "本文揭示大型预训练视觉变换器中自然涌现出对象绑定能力，挑战了其缺乏该能力的观点。",
      "motivation": "对象绑定是人类认知的核心能力，能将低层次感知特征组合成高层次对象表示，支持记忆存储和推理。现有方法如Slot Attention通常显式施加对象中心注意力以探索其益处，但尚不清楚这种能力是否在预训练视觉变换器中自然涌现。该问题的重要性在于，如果ViTs能自动学习对象绑定，可揭示连接主义系统中的符号知识涌现，并改进下游任务性能。当前不足是缺乏对预训练ViTs中内在绑定能力的系统性验证，这限制了我们对模型内在工作机制的理解和应用潜力。",
      "method": "研究提出一种名为IsSameObject的属性，用于表示两个图像补丁是否属于同一对象。核心方法是使用二次相似性探针，从ViT各层的补丁嵌入中解码这一属性，以评估对象绑定能力。关键技术特色在于结合自注意力的二次特性设计探针，并系统比较了不同预训练目标下的ViTs模型，包括DINO、CLIP、ImageNet监督和MAE。这有助于揭示绑定能力是否受特定预训练目标影响，而非单纯架构产物。实验涉及标准数据集如ImageNet，探针训练和测试基于模型内部激活表示。",
      "result": "实验结果显示，二次相似性探针在解码IsSameObject时达到超过90%的准确率，表明ViTs能有效表示对象绑定。对象绑定能力在DINO、CLIP和ImageNet监督ViTs中可靠涌现，但在MAE中明显较弱，说明绑定能力取决于预训练目标而非通用架构特征。进一步分析发现，IsSameObject编码在基于对象特征的低维子空间中，并主动引导注意力机制。消融实验表明，从模型激活中移除IsSameObject信号会降低下游任务性能并干扰学习目标，验证了该能力对预训练目标的服务作用。",
      "conclusion": "主要贡献是证明了对象绑定能力在大型预训练视觉变换器中自然涌现，挑战了ViTs缺乏绑定的传统观点。学术价值在于揭示连接主义系统中如何从数据中自然习得符号知识，如“哪些部分属于一起”，对理解深度学习模型的认知机制有重要意义。实际应用价值包括指导预训练目标设计以增强对象感知能力，并可能优化下游视觉任务。潜在局限性或未来工作包括探索更多模型架构、扩展到其他领域或更复杂场景，以及进一步研究绑定能力的泛化性。",
      "tags": [
        "Vision Transformers",
        "Object Binding",
        "Self-Attention",
        "Pretraining Objectives",
        "Contrastive Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:41.790636Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.24570",
    "title": "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation",
    "authors": [
      "Raphaël Bagat",
      "Irina Illina",
      "Emmanuel Vincent"
    ],
    "abstract": "Automatic Speech Recognition (ASR) systems, despite large multilingual training, struggle in low-resource scenarios where labeled data is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training and Distillation), a novel framework designed to adapt Whisper's encoder with unlabeled data. Unlike traditional self-supervised learning methods, BEARD uniquely combines a BEST-RQ objective with knowledge distillation from a frozen teacher encoder, ensuring the encoder's complementarity with the pre-trained decoder. Our experiments focus on the ATCO2 corpus from the challenging Air Traffic Control (ATC) communications domain, characterized by non-native speech, noise, and specialized phraseology. Using about 5,000 hours of untranscribed speech for BEARD and 2 hours of transcribed speech for fine-tuning, the proposed approach significantly outperforms previous baseline and fine-tuned model, achieving a relative improvement of 12% compared to the fine-tuned model. To the best of our knowledge, this is the first work to use a self-supervised learning objective for domain adaptation of Whisper.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.24570.pdf",
    "abs_url": "https://arxiv.org/abs/2510.24570",
    "published": "2025-10-28T16:01:24Z",
    "updated": "2026-01-21T15:13:17Z",
    "comment": "Accepted to ICASSP 2026",
    "light_analysis": {
      "overview": "提出BEARD框架，首次结合BEST-RQ自监督学习和知识蒸馏，用于Whisper模型的无监督域适应。",
      "motivation": "自动语音识别（ASR）系统在多语言训练后，在低资源场景中表现不佳，因标注数据稀缺。本研究针对航空交通控制（ATC）通信领域，该领域语音具有非母语、噪声和专业术语等挑战性特征，传统自监督学习方法难以有效适应，导致模型性能下降。因此，亟需开发无监督域适应方法，以利用大量未标注数据提升ASR在特定领域的鲁棒性和准确性。",
      "method": "提出BEARD框架，核心方法结合BEST-RQ自监督学习目标和知识蒸馏技术。BEST-RQ是一种量化重构目标，用于无监督训练编码器；同时从冻结的教师编码器蒸馏知识，确保适应后的编码器与预训练解码器保持互补性。实验使用ATCO2语料库，包含约5,000小时无标注语音用于BEARD训练，以及2小时有标注语音用于后续微调，专注于航空交通控制领域的挑战性语音数据。",
      "result": "在ATCO2语料库上的实验显示，BEARD框架显著优于基线模型和仅微调模型，相对微调模型实现了12%的性能提升。这表明通过无监督域适应，ASR系统在低资源和高噪声环境中能有效提高识别准确率，验证了BEST-RQ与知识蒸馏结合的创新性。与现有方法相比，该方法在资源受限场景下展现出更强的适应能力和改进效果。",
      "conclusion": "该研究首次将自监督学习目标（BEST-RQ）用于Whisper的域适应，提出BEARD框架，结合知识蒸馏，显著提升低资源语音识别性能。这为ASR领域提供了新的无监督适应方法，具有学术价值和实际应用潜力，尤其在航空通信等专业领域。摘要未明确说明局限性，未来工作可扩展到其他领域或优化模型效率。",
      "tags": [
        "Self-Supervised Learning",
        "Knowledge Distillation",
        "Domain Adaptation",
        "BEST-RQ",
        "Whisper Model"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:30.532724Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.22656",
    "title": "Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion",
    "authors": [
      "Zilong Wang",
      "Qingtian Zeng",
      "Hua Duan",
      "Cheng Cheng",
      "Minghao Zou",
      "Ziyang Wang"
    ],
    "abstract": "Few-shot Knowledge Graph Completion (FKGC) infers missing triples from limited support samples, tackling long-tail distribution challenges. Existing methods, however, struggle to capture complex relational patterns and mitigate data sparsity. To address these challenges, we propose a novel FKGC framework for conjugate relation modeling (CR-FKGC). Specifically, it employs a neighborhood aggregation encoder to integrate higher-order neighbor information, a conjugate relation learner combining an implicit conditional diffusion relation module with a stable relation module to capture stable semantics and uncertainty offsets, and a manifold conjugate decoder for efficient evaluation and inference of missing triples in manifold space. Experiments on three benchmarks demonstrate that our method achieves superior performance over state-of-the-art methods.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.22656.pdf",
    "abs_url": "https://arxiv.org/abs/2510.22656",
    "published": "2025-10-26T12:38:23Z",
    "updated": "2026-01-21T08:50:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种共轭关系建模的少样本知识图补全框架，以解决复杂关系模式和稀疏数据问题。",
      "motivation": "少样本知识图补全旨在从有限支持样本推断知识图中的缺失三元组，应对长尾分布挑战。然而，现有方法如基于嵌入的技术难以捕捉复杂关系模式并缓解数据稀疏性，导致补全准确性下降和泛化能力受限。因此，本研究致力于开发新框架，通过共轭关系建模改进这些方面，提升少样本场景下的性能。",
      "method": "该方法提出CR-FKGC框架，包括三个核心模块：邻域聚合编码器整合高阶邻居信息增强实体表示；共轭关系学习器结合隐式条件扩散关系模块和稳定关系模块，分别捕捉不确定性偏移和稳定语义；以及流形共轭解码器在流形空间中高效评估和推断缺失三元组。关键创新在于共轭关系建模，通过结合稳定与动态关系组件，实现对复杂关系模式的精确捕捉。",
      "result": "实验在三个基准测试上进行，结果表明CR-FKGC框架的性能超越了现有最先进的方法。摘要未明确说明具体的准确率提升或效率改进数据，但验证了该框架在少样本知识图补全任务中的优越性，表明共轭关系建模能有效提高处理复杂关系和稀疏数据的能力。",
      "conclusion": "本研究的核心贡献是提出了CR-FKGC框架，通过共轭关系建模解决了少样本知识图补全中的复杂关系和稀疏数据问题。学术价值体现在创新性地结合了关系模块，为关系建模提供了新思路；实际应用价值在于提升了知识图补全的准确性和鲁棒性。摘要未明确说明局限性，未来工作可能涉及优化框架效率或扩展到更多应用场景。",
      "tags": [
        "Few-Shot Knowledge Graph Completion",
        "Conjugate Relation Modeling",
        "Neighborhood Aggregation Encoder",
        "Diffusion Models",
        "Manifold Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:15.101334Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.21182",
    "title": "KBE-DME: Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark Evolution",
    "authors": [
      "Junzhe Zhang",
      "Huixuan Zhang",
      "Xiaojun Wan"
    ],
    "abstract": "The rapid progress of multimodal large language models (MLLMs) calls for more reliable evaluation protocols. Existing static benchmarks suffer from the potential risk of data contamination and saturation, leading to inflated or misleading performance evaluations. To address these issues, we first apply Graph formulation to represent a static or dynamic VQA sample. With the formulation, we propose Knowledge-enhanced Benchmark Evolution(KBE), a dynamic multimodal evaluation framework. KBE first analyzes the original static benchmark, then expands it by integrating multimodal knowledge, transforming the static benchmark into a controllable, dynamic evolving version. Crucially, KBE can both reconstruct questions by Re-selecting visual information in the original image and expand existing questions with external textual knowledge. It enables difficulty-controllable evaluation by adjusting the degree of question exploration. Extensive experiments demonstrate that KBE alleviates the risk of data contamination, data saturation, and provides a more comprehensive assessment of MLLM capabilities.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.21182.pdf",
    "abs_url": "https://arxiv.org/abs/2510.21182",
    "published": "2025-10-24T06:13:36Z",
    "updated": "2026-01-21T07:52:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了知识增强的动态多模态评估框架KBE，以解决静态基准的数据污染和饱和问题。",
      "motivation": "随着多模态大型语言模型的快速发展，现有静态评估基准面临数据污染和饱和的风险，导致性能评估失真。数据污染指模型可能预先接触基准数据，使结果虚高；数据饱和则表明基准过于简单，无法全面衡量模型能力。这些问题削弱了评估的可靠性，阻碍了模型间的客观比较和优化。因此，需要一种动态、可控的评估方法来提高准确性。",
      "method": "研究方法首先应用图表示法来形式化视觉问答样本，为基础构建提供结构。在此基础上，提出知识增强的基准演化框架KBE，通过分析原始静态基准，整合多模态知识将其扩展为可控的动态版本。关键创新包括重构问题，如重新选择图像中的视觉信息，并利用外部文本知识扩展问题，以实现难度可控的评估，从而全面测试模型能力。",
      "result": "大量实验表明，KBE有效缓解了数据污染和饱和的风险，并提供了更全面的多模态大型语言模型能力评估。与静态基准相比，KBE通过动态演化基准，避免了模型对固定数据的过度拟合，确保了评估结果的可靠性。摘要未明确说明具体性能指标，但实验证实该框架在提升评估准确性和广度方面的优势。",
      "conclusion": "本文的主要贡献是提出了KBE动态多模态评估框架，通过知识增强的基准演化改善了现有静态基准的不足。其学术价值在于为多模态模型评估提供了新思路，推动领域向更可靠、动态的方向发展。实际应用中，KBE可为模型训练、测试和部署提供更精准的基准。未来工作可能包括扩展更多模态或复杂场景。",
      "tags": [
        "Multimodal Large Language Models",
        "Dynamic Multimodal Evaluation",
        "Knowledge Enhancement",
        "Graph Formulation",
        "Visual Question Answering"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:20.497047Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.17795",
    "title": "What Makes AI Research Replicable? Executable Knowledge Graphs as Scientific Knowledge Representations",
    "authors": [
      "Yujie Luo",
      "Zhuoyun Yu",
      "Xuehai Wang",
      "Yuqi Zhu",
      "Ningyu Zhang",
      "Lanning Wei",
      "Lun Du",
      "Da Zheng",
      "Huajun Chen"
    ],
    "abstract": "Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. Furthermore, previous approaches tend to overlook valuable implementation-level code signals and lack structured knowledge representations that support multi-granular retrieval and reuse. To overcome these challenges, we propose Executable Knowledge Graphs (xKG), a pluggable, paper-centric knowledge base that automatically integrates code snippets and technical insights extracted from scientific literature. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication. Code is available at https://github.com/zjunlp/xKG.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.17795.pdf",
    "abs_url": "https://arxiv.org/abs/2510.17795",
    "published": "2025-10-20T17:53:23Z",
    "updated": "2026-01-21T07:42:57Z",
    "comment": "Work in progress",
    "light_analysis": {
      "overview": "本文提出了可执行知识图谱（xKG）作为科学知识表示，通过自动整合代码片段和技术洞察，显著提升了AI研究的可复制性。",
      "motivation": "AI研究复制对于大语言模型（LLM）代理至关重要，但现有方法面临挑战。检索增强生成（RAG）等方法未能有效捕捉科学论文中的隐藏技术细节，背景知识不足，且忽视了实现级代码信号，导致可执行代码生成困难。此外，缺乏结构化知识表示限制了多粒度检索和重用。这些问题影响了AI研究的可重复性和自动化进程，因此需要更高效的知识表示和检索机制来支持复杂的复制任务。",
      "method": "论文提出可执行知识图谱（xKG），这是一个可插拔、以论文为中心的知识库，能够自动从科学文献中提取代码片段和技术洞察，并整合成结构化表示。核心创新点在于构建支持多粒度检索和重用的知识图谱，增强对技术细节的捕捉能力。方法通过集成到代理框架和LLMs中实现，具体数据集和模型架构摘要未明确说明，但提及使用PaperBench作为基准测试平台，体现了其通用性和可扩展性。",
      "result": "实验在PaperBench基准上进行，xKG集成到三个代理框架和两个不同大语言模型（如o3-mini）时，展现出显著的性能提升，具体为10.9%的增益。这表明xKG在自动化AI研究复制任务中优于基线方法，有效改善了代码生成和技术洞察的准确性。摘要未提供更多详细指标，但结果证明了xKG作为通用解决方案的潜力和实用性，支持了研究复制的效率和可靠性。",
      "conclusion": "xKG的主要贡献是提供了一种改进AI研究可复制性的结构化知识表示方法，学术上推动了知识图谱和检索技术的发展，实际上增强了自动化研究的效率和准确性。该方案作为通用和可扩展的解决方案，具有广泛的应用价值。摘要未明确提及局限性或未来工作方向，但暗示了进一步扩展和优化的潜力，以应对更复杂的科研场景。",
      "tags": [
        "Executable Knowledge Graphs",
        "Large Language Model",
        "Retrieval-Augmented Generation",
        "Code Snippets",
        "Knowledge Representation"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:44.806227Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.16306",
    "title": "Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening",
    "authors": [
      "Xin Wang",
      "Yu Wang",
      "Yunchao Liu",
      "Jens Meiler",
      "Tyler Derr"
    ],
    "abstract": "Ligand-based virtual screening (VS) is an essential step in drug discovery that evaluates large chemical libraries to identify compounds that potentially bind to a therapeutic target. However, VS faces three major challenges: class imbalance due to the low active rate, structural imbalance among active molecules where certain scaffolds dominate, and the need to identify structurally diverse active compounds for novel drug development. We introduce ScaffAug, a scaffold-aware VS framework that addresses these challenges through three modules. The augmentation module first generates synthetic data conditioned on scaffolds of actual hits using generative models, specifically a graph diffusion model. This helps mitigate the class imbalance and furthermore the structural imbalance, due to our proposed scaffold-aware sampling algorithm, designed to produce more samples for active molecules with underrepresented scaffolds. A model-agnostic self-training module is then used to safely integrate the generated synthetic data from our augmentation module with the original labeled data. Lastly, we introduce a reranking module that improves VS by enhancing scaffold diversity in the top recommended set of molecules, while still maintaining and even enhancing the overall general performance of identifying novel, active compounds. We conduct comprehensive computational experiments across five target classes, comparing ScaffAug against existing baseline methods by reporting the performance of multiple evaluation metrics and performing ablation studies on ScaffAug. Overall, this work introduces novel perspectives on effectively enhancing VS by leveraging generative augmentations, reranking, and general scaffold-awareness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.16306.pdf",
    "abs_url": "https://arxiv.org/abs/2510.16306",
    "published": "2025-10-18T02:26:08Z",
    "updated": "2026-01-21T06:09:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出ScaffAug框架，通过支架感知的生成增强和重排名技术，解决虚拟筛选中的类别和结构不平衡问题，提升药物发现的效率和多样性。",
      "motivation": "虚拟筛选（VS）是药物发现中评估化学库以识别潜在活性化合物的关键步骤，但面临三个主要挑战：由于活性率低导致的类别不平衡、活性分子中某些支架占主导的结构不平衡，以及需要识别结构多样性的活性化合物以开发新药。现有方法在处理这些不平衡时效率低下，限制了筛选准确性和新药开发潜力，因此迫切需要新方法来有效缓解这些问题。",
      "method": "ScaffAug框架包括三个核心模块：增强模块使用图扩散模型生成基于实际命中支架的合成数据，通过支架感知采样算法增加代表性不足支架的样本以缓解不平衡；模型无关的自训练模块安全整合合成数据与原始标记数据；重排名模块优化VS，提升推荐分子的支架多样性，同时保持或增强整体性能。关键创新在于结合了生成模型、支架感知技术和模型无关的自训练方法。",
      "result": "通过跨五个靶点类的全面计算实验，ScaffAug在多种评估指标上优于现有基线方法，消融研究验证了各模块对提升支架多样性和整体筛选性能的贡献。具体数据未在摘要中提供，但实验结果显示方法能有效提高虚拟筛选的准确性和多样性，与基线相比表现出显著改进。",
      "conclusion": "ScaffAug框架通过生成增强、重排名和支架感知技术，为虚拟筛选提供了新视角，解决了不平衡问题，具有重要学术价值。其实际应用有助于加速药物发现，提高新药开发效率；未来工作可能包括扩展到更多靶点类或进一步优化模型细节。",
      "tags": [
        "Graph Diffusion Model",
        "Self-Training",
        "Scaffold-Aware Sampling",
        "Reranking",
        "Generative Models"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:29.419325Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.15231",
    "title": "Extending Audio Context for Long-Form Understanding in Large Audio-Language Models",
    "authors": [
      "Yuatyong Chaichana",
      "Pittawat Taveekitworachai",
      "Warit Sirichotedumrong",
      "Potsawee Manakul",
      "Kunat Pipatanakul"
    ],
    "abstract": "Large Audio-Language Models (LALMs) are often constrained by short audio context windows, even when their text backbones support long contexts, limiting long-form audio understanding. Prior work has introduced context-extension methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains unexplored. First, building on RoPE-based context extension, we introduce Partial YaRN, a training-free, modality-decoupled extension method that modifies only audio token positions, leaving text positions intact to preserve the base LLM's text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a training strategy that extends Partial YaRN into a training-time positional augmentation. VLAT simulates diverse audio lengths during training, enabling generalization to inputs far longer than those seen in training. Our experiments on SALMONN and Qwen2-Audio confirm that Partial YaRN outperforms the original models across wide range of settings, and VLAT provides substantial performance improvement on long audio of unseen lengths.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.15231.pdf",
    "abs_url": "https://arxiv.org/abs/2510.15231",
    "published": "2025-10-17T01:44:28Z",
    "updated": "2026-01-21T08:00:24Z",
    "comment": "EACL 2026. Code and dataset are available at: https://github.com/yophis/partial-yarn",
    "light_analysis": {
      "overview": "论文提出了Partial YaRN和VLAT方法，扩展大型音频-语言模型的音频上下文窗口以提升长音频理解能力。",
      "motivation": "研究动机在于大型音频-语言模型（LALMs）受限于短的音频上下文窗口，尽管其文本骨干支持长上下文，这限制了长音频理解和实际应用。现有方法如YaRN已在单模态大型语言模型中应用上下文扩展，但在LALMs中的适用性尚未探索，因此需要开发专门的方法来克服这一缺陷，以促进长音频处理任务的发展。",
      "method": "论文基于RoPE上下文扩展，提出了Partial YaRN方法，这是一种训练免费、模态解耦的扩展技术，仅修改音频令牌位置以保持文本骨干能力不变。同时，引入了Virtual Longform Audio Training（VLAT）策略，将Partial YaRN扩展为训练时的位置增强，通过在训练中模拟多样化的音频长度来增强模型对未见过长音频的泛化能力。实验使用SALMONN和Qwen2-Audio模型进行验证。",
      "result": "实验结果显示，Partial YaRN在多种设置中优于原始模型，而VLAT在未见过的长音频上提供了显著的性能改进，提升了长音频理解能力。摘要未明确说明具体性能指标如准确率提升数值，但强调了与基线方法相比的整体效果提升。",
      "conclusion": "论文的主要贡献是开发了Partial YaRN和VLAT方法，有效扩展了大型音频-语言模型的音频上下文，增强了长音频理解能力，具有学术价值和实际应用潜力。研究为处理长音频任务提供了新思路，未来工作可能包括进一步优化方法以应用于更广泛的场景和模型。",
      "tags": [
        "Large Audio-Language Models",
        "RoPE",
        "Context Extension",
        "Partial YaRN",
        "Virtual Longform Audio Training"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:21.779312Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.10111",
    "title": "Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization",
    "authors": [
      "Rui Chen",
      "Bin Liu",
      "Changtao Miao",
      "Xinghao Wang",
      "Yi Li",
      "Tao Gong",
      "Qi Chu",
      "Nenghai Yu"
    ],
    "abstract": "Advances in image tampering pose serious security threats, underscoring the need for effective image manipulation localization (IML). While supervised IML achieves strong performance, it depends on costly pixel-level annotations. Existing weakly supervised or training-free alternatives often underperform and lack interpretability. We propose the In-Context Forensic Chain (ICFC), a training-free framework that leverages multi-modal large language models (MLLMs) for interpretable IML tasks. ICFC integrates an objectified rule construction with adaptive filtering to build a reliable knowledge base and a multi-step progressive reasoning pipeline that mirrors expert forensic workflows from coarse proposals to fine-grained forensics results. This design enables systematic exploitation of MLLM reasoning for image-level classification, pixel-level localization, and text-level interpretability. Across multiple benchmarks, ICFC not only surpasses state-of-the-art training-free methods but also achieves competitive or superior performance compared to weakly and fully supervised approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.10111.pdf",
    "abs_url": "https://arxiv.org/abs/2510.10111",
    "published": "2025-10-11T08:42:31Z",
    "updated": "2026-01-21T15:39:57Z",
    "comment": "This version was uploaded in error and contains misleading information found in an early draft. The manuscript requires extensive and long-term revisions",
    "light_analysis": {
      "overview": "提出了无需训练的图像取证链（ICFC）框架，利用多模态大语言模型实现可解释的图像篡改检测和定位。",
      "motivation": "图像篡改技术的进步带来了严重的安全威胁，凸显了对高效图像操纵定位（IML）的迫切需求。全监督IML方法虽然性能强大，但依赖于成本高昂的像素级标注，限制了其广泛应用。现有的弱监督或无训练替代方案通常性能较差且缺乏可解释性，难以满足实际安全检测的要求。因此，开发一种无需训练、性能优良且具有良好可解释性的方法，成为解决图像安全问题的关键。",
      "method": "论文提出In-Context Forensic Chain（ICFC），一个无需训练的框架，利用多模态大语言模型（MLLMs）进行可解释的IML任务。该方法通过集成客观化规则构建与自适应过滤来构建可靠的知识库，并结合多步骤渐进推理管道，模仿专家从粗粒度提案到细粒度取证结果的工作流程。这种设计系统地利用了MLLM的推理能力，支持图像级分类、像素级定位和文本级可解释性，增强了整个检测过程的可解释性和准确性。",
      "result": "在多个基准测试中，ICFC不仅超越了最先进的无训练方法，还实现了与弱监督和全监督方法相竞争或更优的性能。这表明该方法在无需大量标注数据的情况下，能够有效提升图像操纵检测和定位的准确性。尽管摘要中未明确说明具体性能指标如准确率或效率改进，但结果显示了其在减少标注依赖和增强可解释性方面的优势。",
      "conclusion": "ICFC框架的提出为图像取证领域提供了一种创新的无需训练解决方案，显著提高了检测的可解释性和性能。该方法具有重要的学术价值，展示了多模态大语言模型在计算机视觉任务中的应用潜力，同时具备广泛的实际应用前景，如数字安全和内容验证。未来工作可进一步优化推理管道或扩展至其他视觉取证任务，以应对更复杂的篡改场景。",
      "tags": [
        "Image Manipulation Localization",
        "Training-Free Framework",
        "Multi-modal Large Language Models",
        "In-Context Learning",
        "Forensic Workflow"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:13.809333Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.09394",
    "title": "Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph",
    "authors": [
      "Ziyu Zheng",
      "Yaming Yang",
      "Ziyu Guan",
      "Wei Zhao",
      "Xinyan Huang",
      "Weigang Lu"
    ],
    "abstract": "The ``pre-train, prompt\" paradigm, designed to bridge the gap between pre-training tasks and downstream objectives, has been extended from the NLP domain to the graph domain and has achieved remarkable progress. Current mainstream graph prompt-tuning methods modify input or output features using learnable prompt vectors. However, existing approaches are confined to single-granularity (e.g., node-level or subgraph-level) during prompt generation, overlooking the inherently multi-scale structural information in graph data, which limits the diversity of prompt semantics. To address this issue, we pioneer the integration of multi-scale information into graph prompt and propose a Multi-Scale Graph Chain-of-Thought (MSGCOT) prompting framework. Specifically, we design a lightweight, low-rank coarsening network to efficiently capture multi-scale structural features as hierarchical basis vectors for prompt generation. Subsequently, mimicking human cognition from coarse-to-fine granularity, we dynamically integrate multi-scale information at each reasoning step, forming a progressive coarse-to-fine prompt chain. Extensive experiments on eight benchmark datasets demonstrate that MSGCOT outperforms the state-of-the-art single-granularity graph prompt-tuning method, particularly in few-shot scenarios, showcasing superior performance. The code is available at: https://github.com/zhengziyu77/MSGCOT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.09394.pdf",
    "abs_url": "https://arxiv.org/abs/2510.09394",
    "published": "2025-10-10T13:48:34Z",
    "updated": "2026-01-21T08:54:49Z",
    "comment": "Accepted by WWW2026",
    "light_analysis": {
      "overview": "本文提出多尺度图链式思维提示框架MSGCOT，通过整合多尺度结构信息，优化图提示学习，在少样本场景下性能显著提升。",
      "motivation": "该研究的动机源于当前图提示学习方法的局限性：主流方法采用单粒度提示生成（如节点级或子图级），忽视了图数据中固有的多尺度结构信息，导致提示语义多样性受限。这限制了模型对复杂图任务的适应能力，尤其在需要跨粒度推理的场景下。重要性在于，多尺度信息对于理解图结构的层次特性至关重要，现有方法的不足凸显了改进的紧迫性，以提升图提示学习的泛化性能和效率。",
      "method": "论文提出MSGCOT框架，核心方法包括设计一个轻量级、低秩粗化网络，用于高效捕获图的多尺度结构特征，生成层次化的基础向量作为提示。创新点在于模仿人类从粗到细的认知过程，在每个推理步骤中动态集成多尺度信息，形成一个渐进的从粗到细提示链。该方法通过多尺度信息整合，增强了提示的语义多样性，适用于图提示学习任务，但具体模型架构和数据集细节在摘要中未明确说明。",
      "result": "实验在八个基准数据集上进行，结果表明MSGCOT优于最先进的单粒度图提示学习方法，尤其是在少样本场景中，显示出卓越的性能。尽管摘要未提供具体数据（如准确率提升百分比），但与基线方法的对比表明框架在多尺度信息利用上的有效性，为图任务提供了更强的泛化能力和效率改进。",
      "conclusion": "研究的主要贡献是开发了MSGCOT框架，成功将多尺度信息集成到图提示学习中，提升了少样本场景下的任务性能。学术价值体现在扩展了图域提示学习的理论框架，推动了多尺度方法的发展；应用价值在于增强了图模型的适应性，适用于如社交网络分析等实际场景。未来工作可能涉及框架的进一步优化和扩展到更多图任务，局限性如特定数据集依赖或计算效率在摘要中未明确说明。",
      "tags": [
        "Graph Prompt-Tuning",
        "Multi-Scale Learning",
        "Chain-of-Thought",
        "Low-Rank Coarsening",
        "Few-Shot Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:10.586934Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.06730",
    "title": "PTEB: Towards Robust Text Embedding Evaluation via Stochastic Paraphrasing at Evaluation Time with LLMs",
    "authors": [
      "Manuel Frank",
      "Haithem Afli"
    ],
    "abstract": "Current sentence embedding evaluations typically rely on static test beds like the Massive Text Embedding Benchmark (MTEB). While invaluable, repeated tuning on a fixed suite can inflate reported scores and obscure real-world robustness. We introduce the Paraphrasing Text Embedding Benchmark (PTEB), a dynamic protocol that stochastically generates meaning-preserving paraphrases at evaluation time and aggregates results across multiple runs. Using a cost-efficient LLM-based method grounded in gold ratings and human validation, we show that LLMs generate token-diverse but semantically preserving paraphrases. Across 7 MTEB tasks, we validate our hypothesis that the performance of sentence encoders is sensitive to changes in token space even when semantics remain fixed. We also observe that smaller models are not disproportionately affected relative to larger ones. Our results are statistically robust over multiple runs spanning 20 datasets and 25 languages. More generally, we aim to propose a new evaluation paradigm in NLP that relies less on static, pre-defined benchmarks but shifts towards dynamic, stochastic evaluation leveraging eval-time compute.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.06730.pdf",
    "abs_url": "https://arxiv.org/abs/2510.06730",
    "published": "2025-10-08T07:37:19Z",
    "updated": "2026-01-21T18:03:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出PTEB，一种利用大型语言模型在评估时随机生成转述的动态基准，以提升文本嵌入评估的鲁棒性。",
      "motivation": "当前句子嵌入评估主要依赖于静态测试床如MTEB，但重复调优会导致报告分数虚高，掩盖了模型在实际应用中的鲁棒性问题。这种静态评估方法难以模拟真实世界中的语言变化，因此需要一种动态协议来更准确地评估文本嵌入模型的性能。本研究旨在解决这一不足，通过引入随机性来提高评估的可靠性和泛化能力，避免因固定测试套件而导致的分数膨胀。",
      "method": "PTEB协议在评估时使用大型语言模型随机生成语义保留的转述，基于黄金评级和人工验证确保转述质量。核心创新是动态生成测试案例，而非依赖静态数据集，并聚合多次运行结果以减少随机误差。该方法在多个MTEB任务上应用，利用LLM生成词汇多样但语义不变的转述，以评估句子编码器对词汇变化的敏感性，涉及成本效益的LLM方法。",
      "result": "在7个MTEB任务上，实验验证了句子编码器的性能对词汇空间变化敏感，即使语义固定，具体表现为在转述生成的测试案例上性能波动。小模型相对于大模型未显示出不成比例的敏感性，表明大小模型受影响程度相似。结果在20个数据集和25种语言上进行多次运行，统计上具有鲁棒性，证实了动态评估方法的有效性。",
      "conclusion": "本研究提出PTEB作为一种新的NLP评估范式，旨在减少对静态、预定义基准的依赖，转向利用评估时计算的动态、随机评估。这提升了文本嵌入评估的鲁棒性，并为未来研究提供了更接近实际应用的评估框架。潜在局限性可能包括生成转述的计算成本，未来工作可探索更高效的方法或扩展到其他NLP任务。",
      "tags": [
        "Text Embedding Evaluation",
        "Large Language Models",
        "Stochastic Paraphrasing",
        "Dynamic Benchmark",
        "NLP Evaluation"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:07.923443Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.06584",
    "title": "Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation",
    "authors": [
      "Justin Cheung",
      "Samuel Savine",
      "Calvin Nguyen",
      "Lin Lu",
      "Alhassan S. Yasin"
    ],
    "abstract": "If a CT scanner introduces a new artifact not present in the training labels, the model may misclassify the images. Although modern CT scanners include design features which mitigate these artifacts, unanticipated or difficult-to-mitigate artifacts can still appear in practice. The direct solution of labeling images from this new distribution can be costly. As a more accessible alternative, this study evaluates domain adaptation as an approach for training models that maintain classification performance despite new artifacts, even without corresponding labels. We simulate ring artifacts from detector gain error in sinogram space and evaluate domain adversarial neural networks (DANN) against baseline and augmentation-based approaches on the OrganAMNIST abdominal CT dataset. We simulate the absence of labels from an unseen distribution via masking in the loss function and selectively detaching unlabeled instances from the computational graph. Our results demonstrate that baseline models trained only on clean images fail to generalize to images with ring artifacts, and traditional augmentation with other distortion types provides no improvement on unseen artifact domains. In contrast, the DANN approach improves classification accuracy on ring artifact images using only unlabeled artifact data during training, demonstrating the viability of domain adaptation for artifact robustness. The domain-adapted model achieved a classification accuracy of 77.4% on ring artifact test data, 38.7% higher than a baseline model only trained on images with no artifact. These findings provide empirical evidence that domain adaptation can effectively address distribution shift in medical imaging without requiring expensive expert labeling of new artifact distributions, suggesting promise for deployment in clinical settings where novel artifacts may emerge.",
    "categories": [
      "cs.CV",
      "q-bio.TO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.06584.pdf",
    "abs_url": "https://arxiv.org/abs/2510.06584",
    "published": "2025-10-08T02:27:09Z",
    "updated": "2026-01-21T04:17:37Z",
    "comment": "8 pages, 12 figures, 1 table",
    "light_analysis": {
      "overview": "本研究通过域适应方法，在不依赖标注伪影图像的情况下，提高了CT深度学习模型对新伪影的鲁棒性。",
      "motivation": "CT扫描中可能引入训练数据中未见过的新伪影，导致深度学习模型误分类图像，影响临床诊断准确性。现有方法如仅使用干净图像训练或传统数据增强无法处理这种分布偏移，而标注新伪影图像成本高昂且不切实际。因此，研究动机在于探索域适应技术，以低成本方式增强模型对未标注伪影的鲁棒性，解决医学成像中实际遇到的分布偏移问题。",
      "method": "研究方法采用域对抗神经网络（DANN）进行域适应，通过模拟正弦图空间中的探测器增益错误来生成环形伪影数据，无需标注。使用OrganAMNIST腹部CT数据集进行评估，通过掩码损失函数模拟未标注分布，并选择性分离未标注实例从计算图中，以训练模型适应新伪影域。与基线方法（仅训练干净图像）和传统数据增强方法对比，突出域适应的创新性。",
      "result": "实验结果表明，基线模型在环形伪影测试数据上分类准确率显著下降，传统增强方法也无改善。而域适应模型仅使用未标注伪影数据进行训练，在环形伪影测试数据上实现了77.4%的分类准确率，比仅训练干净图像的基线模型高出38.7%。这证实了域适应能有效提高模型对新伪影的泛化能力，且优于其他方法。",
      "conclusion": "研究证实了域适应方法能够在不依赖昂贵专家标注的情况下，有效处理CT医学成像中的分布偏移，提高模型对未知伪影的鲁棒性。这为临床部署提供了实用方案，适用于新伪影可能出现的场景。未来工作可扩展到其他伪影类型或更复杂模型，以进一步提升泛化性能和应用范围。",
      "tags": [
        "Domain Adaptation",
        "Domain Adversarial Neural Networks",
        "CT Imaging",
        "Medical Image Classification",
        "Artifact Robustness"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:24.972662Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.08593",
    "title": "Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech",
    "authors": [
      "Yuxin Li",
      "Eng Siong Chng",
      "Cuntai Guan"
    ],
    "abstract": "Speech-based depression detection (SDD) has emerged as a non-invasive and scalable alternative to conventional clinical assessments. However, existing methods still struggle to capture robust depression-related speech characteristics, which are sparse and heterogeneous. Although pretrained self-supervised learning (SSL) models provide rich representations, most recent SDD studies extract features from a single layer of the pretrained SSL model for the downstream classifier. This practice overlooks the complementary roles of low-level acoustic features and high-level semantic information inherently encoded in different SSL model layers. To explicitly model interactions between acoustic and semantic representations within an utterance, we propose a hierarchical adaptive representation encoder with prior knowledge that disengages and re-aligns acoustic and semantic information through asymmetric cross-attention, enabling fine-grained acoustic patterns to be interpreted in semantic context. In addition, a Connectionist Temporal Classification (CTC) objective is applied as auxiliary supervision to handle the irregular temporal distribution of depressive characteristics without requiring frame-level annotations. Experiments on DAIC-WOZ and MODMA demonstrate that HAREN-CTC consistently outperforms existing methods under both performance upper-bound evaluation and generalization evaluation settings, achieving Macro F1 scores of 0.81 and 0.82 respectively in upper-bound evaluation, and maintaining superior performance with statistically significant improvements in precision and AUC under rigorous cross-validation. These findings suggest that modeling hierarchical acoustic-semantic interactions better reflects how depressive characteristics manifest in natural speech, enabling scalable and objective depression assessment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.08593.pdf",
    "abs_url": "https://arxiv.org/abs/2510.08593",
    "published": "2025-10-05T09:32:12Z",
    "updated": "2026-01-21T07:20:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种分层自适应表示编码器（HAREN-CTC），通过建模声学和语义信息的层次交互来改进基于语音的抑郁检测，并结合CTC目标处理不规则时间分布。",
      "motivation": "基于语音的抑郁检测（SDD）作为一种非侵入性和可扩展的临床评估替代方案，在心理健康监测中具有重要价值。然而，现有方法难以有效捕捉稀疏和异质的抑郁相关语音特征，这些特征在自然语音中分布不均匀。尽管预训练的自监督学习（SSL）模型能提供丰富的表示，但大多数研究仅从SSL模型的单层提取特征，忽略了低层声学特征（如音高、音色）和高层语义信息（如语言内容）在不同层中的互补作用，这导致检测性能受限，无法充分利用语音的层次结构，制约了实际应用中的鲁棒性和准确性。",
      "method": "为了解决声学和语义信息交互的不足，论文提出了一个分层自适应表示编码器（HAREN-CTC），核心方法包括两个关键部分：首先，利用先验知识通过非对称交叉注意力机制，分离并重新对齐声学和语义表示，以在语义上下文中解释细粒度声学模式；其次，应用连接主义时间分类（CTC）目标作为辅助监督，无需帧级标注即可处理抑郁特征的不规则时间分布，优化模型学习。该方法在公开数据集DAIC-WOZ和MODMA上进行验证，创新点在于整合了层次表示学习和CTC监督，以增强特征提取的全面性。",
      "result": "在DAIC-WOZ和MODMA数据集上的实验结果表明，HAREN-CTC在性能上界评估和泛化评估设置下均显著优于现有基线方法。具体来说，在性能上界评估中，Macro F1分数分别达到0.81和0.82；在严格的交叉验证下，该方法在精度和AUC方面显示出统计显著的改进，保持了优越的泛化性能。这些结果证明，建模声学-语义层次交互能有效提升抑郁检测的准确性，验证了所提方法的鲁棒性和可靠性。",
      "conclusion": "本研究的主要贡献在于开发了分层自适应表示编码器（HAREN-CTC），它通过建模声学和语义信息的交互改进了抑郁语音检测，为可扩展和客观的抑郁评估提供了新方法。学术价值在于推动了层次表示学习在心理健康领域的应用，并优化了自监督学习在医疗场景中的实用性。实际应用中，该方法有潜力辅助临床诊断，实现非侵入性监测。摘要未明确说明局限性，但未来工作可能涉及扩展到更多疾病类型或优化计算效率。",
      "tags": [
        "Self-Supervised Learning",
        "Hierarchical Representation Learning",
        "Cross-Attention",
        "Connectionist Temporal Classification",
        "Speech-based Depression Detection"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:07.013472Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.23885",
    "title": "Extendable Generalization Self-Supervised Diffusion for Low-Dose CT Reconstruction",
    "authors": [
      "Guoquan Wei",
      "Liu Shi",
      "Zekun Zhou",
      "Mohan Li",
      "Cunfeng Wei",
      "Wenzhe Shan",
      "Qiegen Liu"
    ],
    "abstract": "Current methods based on deep learning for self-supervised low-dose CT (LDCT) reconstruction, while reducing the dependence on paired data, face the problem of significantly decreased generalization when training with single-dose data and extending to other doses. To enable dose-extensive generalization using only single-dose projection data for training, this work proposes a novel method of Extendable GENeraLization self-supervised Diffusion (EGenDiff) for low-dose CT reconstruction. Specifically, a contextual subdata self-enhancing similarity strategy is designed to provide an initial prior for the subsequent progress. During training, the initial prior is used to combine knowledge distillation with a deep combination of latent diffusion models for optimizing image details. On the stage of inference, the pixel-wise self-correcting fusion technique is proposed for data fidelity enhancement, resulting in extensive generalization of higher and lower doses or even unseen doses. EGenDiff requires only LDCT projection data for training and testing. Comprehensive evaluation on benchmark datasets, clinical data, photon counting CT data, and across all three anatomical planes (transverse, coronal, and sagittal) demonstrates that EGenDiff enables extendable generalization multi-dose, yielding reconstructions that consistently outperform leading existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.23885.pdf",
    "abs_url": "https://arxiv.org/abs/2509.23885",
    "published": "2025-09-28T13:50:29Z",
    "updated": "2026-01-21T06:51:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出EGenDiff方法，通过自监督扩散模型实现低剂量CT重建中的可扩展剂量泛化。",
      "motivation": "当前基于深度学习的自监督低剂量CT重建方法虽减少了对配对数据的依赖，但使用单剂量数据训练时泛化能力显著下降，难以扩展到其他剂量。这一问题在实际应用中至关重要，因为临床环境常涉及不同剂量水平，而现有方法因训练数据有限导致性能不足，限制了其广泛应用。因此，开发一种仅需单剂量数据即可实现广泛泛化的方法具有紧迫的研究意义。",
      "method": "本研究提出EGenDiff方法，包括上下文子数据自增强相似性策略，为模型提供初始先验。训练阶段，结合知识蒸馏和潜在扩散模型的深度整合以优化图像细节；推理阶段，引入像素级自校正融合技术增强数据保真度。该方法的核心创新在于通过扩散模型和自监督策略实现剂量扩展泛化，仅需低剂量CT投影数据进行训练和测试，无需额外配对数据，提升了模型的适应性和效率。",
      "result": "在基准数据集、临床数据、光子计数CT数据及所有三个解剖平面（横断面、冠状面、矢状面）的综合评估中，EGenDiff方法能实现可扩展的多剂量泛化重建。结果显示，其重建性能持续优于现有领先方法，有效泛化到更高、更低甚至未见剂量下，但摘要未明确说明具体性能指标如准确率或效率数据，仅强调了整体优越性。",
      "conclusion": "本文的主要贡献是提出了EGenDiff方法，通过自监督扩散模型解决了低剂量CT重建中的泛化不足问题，具有学术价值和应用潜力，仅需单剂量数据即可适应多剂量场景。该研究为医学成像领域提供了新思路，未来工作可进一步优化模型效率或扩展到其他成像任务，以应对更多临床挑战。",
      "tags": [
        "Self-Supervised Learning",
        "Diffusion Models",
        "Knowledge Distillation",
        "Low-Dose CT Reconstruction",
        "Extendable Generalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:22.901612Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22158",
    "title": "Context Parametrization with Compositional Adapters",
    "authors": [
      "Josip Jukić",
      "Martin Tutek",
      "Jan Šnajder"
    ],
    "abstract": "Large language models (LLMs) often seamlessly adapt to new tasks through in-context learning (ICL) or supervised fine-tuning (SFT). However, both of these approaches face key limitations: ICL is inefficient when handling many demonstrations, and SFT incurs training overhead while sacrificing flexibility. Mapping instructions or demonstrations from context directly into adapter parameters offers an appealing alternative. While prior work explored generating adapters based on a single input context, it has overlooked the need to integrate multiple chunks of information. To address this gap, we introduce CompAs, a meta-learning framework that translates context into adapter parameters with a compositional structure. Adapters generated this way can be merged algebraically, enabling instructions, demonstrations, or retrieved passages to be seamlessly combined without reprocessing long prompts. Critically, this approach yields three benefits: lower inference cost, robustness to long-context instability, and establishes a principled solution when input exceeds the model's context window. Furthermore, CompAs encodes information into adapter parameters in a reversible manner, enabling recovery of input context through a decoder, facilitating safety and security. Empirical results on diverse multiple-choice and extractive question answering tasks show that CompAs outperforms ICL and prior generator-based methods, especially when scaling to more inputs. Our work establishes composable adapter generation as a practical and efficient alternative for scaling LLM deployment.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.22158.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22158",
    "published": "2025-09-26T10:16:28Z",
    "updated": "2026-01-21T12:40:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了CompAs框架，通过组合式适配器将上下文参数化，高效整合多个信息块，提升大语言模型的推理效率和鲁棒性。",
      "motivation": "大型语言模型通常通过上下文学习或监督微调适应新任务，但上下文学习在处理多个示例时效率低下，监督微调则存在训练开销大和灵活性差的问题。先前研究仅基于单个输入上下文生成适配器，无法有效整合多个信息块，限制了实际应用。因此，需要一种能无缝结合多个上下文且兼顾效率与灵活性的方法，以应对复杂任务需求。",
      "method": "本研究引入了CompAs，一个元学习框架，它将上下文直接映射为具有组合结构的适配器参数。关键创新在于这些适配器可以通过代数方式合并，使得指令、演示或检索到的段落能无缝组合，无需重新处理长提示。该方法以可逆方式编码信息，通过解码器恢复输入上下文，便于安全和隐私保护，从而在保持灵活性的同时降低计算成本。",
      "result": "实验在多个选择题和抽取式问答任务上进行，结果显示CompAs优于上下文学习和先前的基于生成器的方法，尤其在输入数量增加时表现更佳。这证实了该方法在扩展性和性能上的优势，能够有效降低推理成本并提高对长上下文不稳定性的鲁棒性，为实际部署提供了有效解决方案。",
      "conclusion": "CompAs的主要贡献在于建立了可组合适配器生成作为大语言模型部署的实用高效替代方案，降低了推理成本，提高了对长上下文不稳定性的鲁棒性，并为输入超出模型上下文窗口的情况提供了原则性解决方案。可逆编码机制便于安全和隐私保护，具有广泛的学术和应用价值。未来工作可进一步探索其在更多任务和模型架构中的泛化能力。",
      "tags": [
        "Large Language Model",
        "Adapter Generation",
        "Meta-Learning",
        "Compositional Adapters",
        "Context Parameterization"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:34.182544Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.19774",
    "title": "PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for PPG-Guided ECG Generation and Cardiovascular Disease Detection",
    "authors": [
      "Xiaocheng Fang",
      "Jiarui Jin",
      "Haoyu Wang",
      "Che Liu",
      "Jieyi Cai",
      "Yujie Xiao",
      "Guangkun Nie",
      "Bo Liu",
      "Shun Huang",
      "Hongyan Li",
      "Shenda Hong"
    ],
    "abstract": "Electrocardiography (ECG) is the clinical gold standard for cardiovascular disease (CVD) assessment, yet continuous monitoring is constrained by the need for dedicated hardware and trained personnel. Photoplethysmography (PPG) is ubiquitous in wearable devices and readily scalable, but it lacks electrophysiological specificity, limiting diagnostic reliability. While generative methods aim to translate PPG into clinically useful ECG signals, existing approaches are limited by the misalignment of physiological semantics in generative models and the complexity of modeling in high-dimensional signals. To address these limitations, we propose PPGFlowECG, a two-stage framework that aligns PPG and ECG in a shared latent space using the CardioAlign Encoder and then synthesizes ECGs with latent rectified flow. We further provide a formal analysis of this coupling, showing that the CardioAlign Encoder is necessary to guarantee stable and semantically consistent ECG synthesis under our formulation. Extensive experiments on four datasets demonstrate improved synthesis fidelity and downstream diagnostic utility. These results indicate that PPGFlowECG supports scalable, wearable-first CVD screening when standard ECG acquisition is unavailable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.19774.pdf",
    "abs_url": "https://arxiv.org/abs/2509.19774",
    "published": "2025-09-24T05:54:33Z",
    "updated": "2026-01-21T15:58:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "PPGFlowECG框架通过共享潜在空间对齐PPG和ECG，并使用潜在校正流合成ECG，以改进心血管疾病检测。",
      "motivation": "心电图是心血管疾病评估的金标准，但连续监测需要专用硬件和专业人员，限制了广泛应用。光电容积描记法在可穿戴设备中普及，可扩展性强，但缺乏电生理特异性，导致诊断可靠性低。现有生成方法试图从光电容积描记法生成心电图信号，但面临生理语义错配和高维信号建模复杂性的挑战。因此，需要新方法克服这些限制，实现有效的光电容积描记法引导心电图生成，支持可穿戴心血管疾病筛查。",
      "method": "论文提出PPGFlowECG，一个两阶段框架。首先，使用CardioAlign Encoder将光电容积描记法和心电图在共享潜在空间中对齐，确保跨模态语义一致性。然后，应用潜在校正流合成心电图信号。关键创新点包括形式化分析证明CardioAlign Encoder对稳定合成的重要性，以及结合跨模态编码和潜在校正流改进生成质量。框架避免了直接在高维空间建模，简化了信号合成过程，使用潜在空间和生成模型进行有效转换。",
      "result": "在四个数据集上的广泛实验表明，PPGFlowECG在合成保真度上有所改进，生成的心电图信号更准确地反映真实信号特征。下游诊断实用性得到增强，意味着使用合成心电图进行心血管疾病检测的性能提升。与基线方法相比，该方法在合成质量和诊断应用上表现更优，但具体性能指标摘要未明确说明。这些结果支持了该方法在可穿戴场景中的有效性。",
      "conclusion": "PPGFlowECG的主要贡献是提出了一个有效框架，通过潜在空间对齐和校正流生成心电图，解决了现有方法中的语义对齐和建模复杂性。学术上，它提供了一种新的跨模态生成方法；实际上，支持可穿戴设备实现心血管疾病筛查，特别是在标准心电图不可用时。未来工作可能包括进一步优化模型、扩展到其他疾病检测或进行更广泛的临床验证，尽管摘要未明确说明具体局限性。",
      "tags": [
        "Latent Rectified Flow",
        "Cross-Modal Encoding",
        "PPG-Guided ECG Generation",
        "Cardiovascular Disease Detection",
        "CardioAlign Encoder"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:18.400069Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.19094",
    "title": "Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering",
    "authors": [
      "Alireza Salemi",
      "Cheng Li",
      "Mingyang Zhang",
      "Qiaozhu Mei",
      "Zhuowan Li",
      "Spurthi Amba Hombaiah",
      "Weize Kong",
      "Tao Chen",
      "Hamed Zamani",
      "Michael Bendersky"
    ],
    "abstract": "Personalization is well studied in search and recommendation, but personalized question answering remains underexplored due to challenges in inferring preferences from long, noisy, implicit contexts and generating responses that are both accurate and aligned with user expectations. To address this, we propose Pathways of Thoughts (PoT), an inference-stage method that applies to any large language model (LLM) without task-specific fine-tuning. PoT models the thinking as an iterative decision process, where the model dynamically selects among cognitive operations such as reasoning, revision, personalization, and clarification. This enables exploration of multiple reasoning trajectories, producing diverse candidate responses that capture different perspectives. PoT then aggregates and reweights these candidates according to inferred user preferences, yielding a final personalized response that benefits from the complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA benchmark show that PoT consistently outperforms competitive baselines, achieving up to a 10.8\\% relative improvement. Human evaluation further validates these improvements, with annotators preferring PoT in 66\\% of cases compared to the best-performing baseline and reporting ties in 15\\% of cases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.19094.pdf",
    "abs_url": "https://arxiv.org/abs/2509.19094",
    "published": "2025-09-23T14:44:46Z",
    "updated": "2026-01-21T04:25:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了 Pathways of Thoughts (PoT) 方法，通过在推理阶段应用多方向思维探索和用户偏好聚合，提升长形式个性化问题回答的性能。",
      "motivation": "个性化在搜索和推荐领域已得到广泛研究，但个性化问题回答仍未充分探索，主要面临从长、嘈杂的隐式上下文中推断用户偏好和生成既准确又符合期望的响应的挑战。现有方法在处理这些复杂情境时表现不佳，导致响应质量和个性化程度受限，迫切需要创新方法来弥补这些不足，以增强AI系统的实用性和用户体验。",
      "method": "论文提出 Pathways of Thoughts (PoT)，一种推理阶段方法，无需任务特定微调即可应用于任何大型语言模型。核心创新在于将思维建模为迭代决策过程，动态选择认知操作如推理、修订、个性化和澄清，从而探索多个推理轨迹，生成多样化候选响应以捕捉不同视角。方法还包括聚合和重加权这些候选响应，基于推断的用户偏好产生最终个性化输出，充分利用不同路径的互补优势。",
      "result": "在 LaMP-QA 基准上的实验显示，PoT consistently 超越竞争基线，实现高达10.8%的相对性能改进。人类评估进一步验证了其优势，标注者在66%的情况下偏好 PoT，15%的情况下与最佳基线持平，表明PoT在提升响应准确性和个性化方面具有显著效果，未明确说明具体基线名称。",
      "conclusion": "论文的主要贡献是提出了 PoT 方法，通过多方向思维探索和用户偏好聚合有效改善个性化问题回答，为大型语言模型推理提供了新视角，并具有无需微调即可部署的实际应用价值。局限性可能包括计算效率或对特定数据集的依赖，未来工作可优化聚合策略或扩展至其他领域。",
      "tags": [
        "Large Language Model",
        "Personalized Question Answering",
        "Multi-directional Reasoning",
        "Cognitive Operations",
        "Response Aggregation"
      ]
    },
    "analyzed_at": "2026-01-22T03:39:35.343513Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.17514",
    "title": "Achilles' Heel of Mamba: Essential difficulties of the Mamba architecture demonstrated by synthetic data",
    "authors": [
      "Tianyi Chen",
      "Pengxiao Lin",
      "Zhiwei Wang",
      "Zhi-Qin John Xu"
    ],
    "abstract": "State Space Models (SSMs) have emerged as promising alternatives to attention mechanisms, with the Mamba architecture demonstrating impressive performance and linear complexity for processing long sequences. However, the fundamental differences between Mamba and Transformer architectures remain incompletely understood. In this work, we use carefully designed synthetic tasks to reveal Mamba's inherent limitations. Through experiments, we identify that Mamba's nonlinear convolution introduces an asymmetry bias that significantly impairs its ability to recognize symmetrical patterns and relationships. Using composite function and inverse sequence matching tasks, we demonstrate that Mamba strongly favors compositional solutions over symmetrical ones and struggles with tasks requiring the matching of reversed sequences. We show these limitations stem not from the SSM module itself but from the nonlinear convolution preceding it, which fuses token information asymmetrically. These insights provide a new understanding of Mamba's constraints and suggest concrete architectural improvements for future sequence models.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.17514.pdf",
    "abs_url": "https://arxiv.org/abs/2509.17514",
    "published": "2025-09-22T08:38:55Z",
    "updated": "2026-01-21T02:41:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过合成任务揭示Mamba架构中非线性卷积引入的不对称偏见，暴露了其固有局限性。",
      "motivation": "研究动机源于State Space Models（SSMs）作为注意力机制替代品，在处理长序列时展现出线性复杂性和高性能，尤其是Mamba架构。然而，Mamba与Transformer架构之间的根本差异尚未完全理解，这阻碍了对Mamba优缺点的深入评估。现有方法可能过度关注性能优势而忽略了潜在缺陷，因此本研究旨在通过系统实验揭示Mamba的内在限制，以促进更全面的模型分析和改进，填补这一知识空白。",
      "method": "研究方法采用精心设计的合成任务，如复合函数和逆序列匹配任务，来系统评估Mamba架构的性能。通过对比Mamba在处理对称模式和反转序列时的表现，研究者聚焦于非线性卷积模块，揭示其信息融合方式的不对称性。关键创新点在于使用合成数据直接暴露模型偏差，避免了真实数据中的混淆因素，从而清晰识别出Mamba的固有缺陷，并指出这些限制并非源于SSM模块本身，而是前置的非线性卷积操作导致令牌信息融合不均。",
      "result": "主要实验结果表明，Mamba架构在识别对称模式和匹配反转序列时存在显著困难。在复合函数任务中，Mamba倾向于组合性解决方案而非对称性方案；在逆序列匹配任务中，其在处理反转序列时表现不佳。这些缺陷被归因于非线性卷积引入的不对称偏见，该偏见导致令牌信息融合不均。与基线方法的对比虽然摘要未明确说明具体性能指标，但实验揭示了Mamba在这些特定任务上的局限性，为理解其性能边界提供了实证依据。",
      "conclusion": "结论指出，本研究通过合成任务揭示了Mamba架构中非线性卷积导致的不对称偏见，提供了对其约束的新理解。主要贡献在于识别了Mamba的固有缺陷，并指出这些限制源于架构设计而非SSM核心模块。这具有重要学术价值，深化了对SSM与注意力机制差异的认识；在实际应用上，为未来序列模型的架构改进提供了具体方向，如优化卷积部分以减少不对称性。潜在的局限性包括摘要未明确说明对真实任务的影响，未来工作可进一步探索如何克服这些偏见并推广到更广泛的场景。",
      "tags": [
        "State Space Models",
        "Mamba architecture",
        "Nonlinear Convolution",
        "Asymmetry Bias",
        "Synthetic Tasks"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:22.628691Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15950",
    "title": "Targeted Fine-Tuning of DNN-Based Receivers via Influence Functions",
    "authors": [
      "Marko Tuononen",
      "Heikki Penttinen",
      "Ville Hautamäki"
    ],
    "abstract": "We present the first use of influence functions for deep learning-based wireless receivers. Applied to DeepRx, a fully convolutional receiver, influence analysis reveals which training samples drive bit predictions, enabling targeted fine-tuning of poorly performing cases. We show that loss-relative influence with capacity-like binary cross-entropy loss and first-order updates on beneficial samples most consistently improves bit error rate toward genie-aided performance, outperforming random fine-tuning in single-target scenarios. Multi-target adaptation proved less effective, underscoring open challenges. Beyond experiments, we connect influence to self-influence corrections and propose a second-order, influence-aligned update strategy. Our results establish influence functions as both an interpretability tool and a basis for efficient receiver adaptation.",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.15950.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15950",
    "published": "2025-09-19T13:01:30Z",
    "updated": "2026-01-21T10:44:40Z",
    "comment": "7 pages; 10 figures; 1 table; 19 equations",
    "light_analysis": {
      "overview": "本文首次将影响函数应用于基于深度学习的无线接收器，实现有针对性的微调，以提升弱性能案例的效果。",
      "motivation": "基于深度学习的无线接收器在处理某些数据时性能不佳，现有微调方法如随机更新效率低下，无法有效改善误码率。影响函数能分析训练样本对预测的影响，识别关键样本，从而弥补现有方法的不足，推动高效接收器适应技术的发展。",
      "method": "论文将影响函数应用于DeepRx全卷积接收器，采用损失相对影响分析，结合类容量二进制交叉熵损失，对有益训练样本进行一阶更新。关键创新包括连接影响函数到自影响校正，并提出二阶影响对齐更新策略，以增强微调的精确性和效率。",
      "result": "实验结果表明，在单目标场景中，损失相对影响与一阶更新能一致地将误码率改善至接近理想辅助性能，显著优于随机微调。多目标适应效果较差，误码率改善有限，突显了实际应用中的挑战。",
      "conclusion": "研究贡献在于确立了影响函数作为可解释性工具和高效接收器适应基础的双重价值，为无线通信系统优化提供了新思路。未来工作可探索多目标适应的改进方法，并验证二阶更新策略的扩展应用。",
      "tags": [
        "Influence Functions",
        "Deep Learning-based Receivers",
        "Targeted Fine-Tuning",
        "Binary Cross-Entropy Loss",
        "Self-Influence Corrections"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:21.761234Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15098",
    "title": "TextMineX: Data, Evaluation Framework and Ontology-guided LLM Pipeline for Humanitarian Mine Action",
    "authors": [
      "Chenyue Zhou",
      "Gürkan Solmaz",
      "Flavio Cirillo",
      "Kiril Gashteovski",
      "Jonathan Fürst"
    ],
    "abstract": "Humanitarian Mine Action (HMA) addresses the challenge of detecting and removing landmines from conflict regions. Much of the life-saving operational knowledge produced by HMA agencies is buried in unstructured reports, limiting the transferability of information between agencies. To address this issue, we propose TextMineX: the first dataset, evaluation framework and ontology-guided large language model (LLM) pipeline for knowledge extraction from text in the HMA domain. TextMineX structures HMA reports into (subject, relation, object)-triples, thus creating domain-specific knowledge. To ensure real-world relevance, we utilized the dataset from our collaborator Cambodian Mine Action Centre (CMAC). We further introduce a bias-aware evaluation framework that combines human-annotated triples with an LLM-as-Judge protocol to mitigate position bias in reference-free scoring. Our experiments show that ontology-aligned prompts improve extraction accuracy by up to 44.2%, reduce hallucinations by 22.5%, and enhance format adherence by 20.9% compared to baseline models. We publicly release the dataset and code.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.15098.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15098",
    "published": "2025-09-18T15:55:19Z",
    "updated": "2026-01-21T13:34:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了TextMineX，首个用于人道主义排雷行动领域知识提取的数据集、评估框架和本体引导的LLM管道。",
      "motivation": "人道主义排雷行动（HMA）中，拯救生命的操作知识常埋藏在非结构化报告中，导致机构间信息传递受限，影响排雷效率和安全性。现有方法缺乏针对该领域的专门工具，通用AI模型提取时存在准确率低和幻觉问题，迫切需要开发结构化知识提取方案以支持跨机构协作和实际操作。",
      "method": "TextMineX的核心方法包括三部分：首先，基于合作方柬埔寨排雷行动中心（CMAC）的数据构建HMA数据集，将非结构化报告转化为（主体，关系，客体）-三元组形式的知识。其次，设计偏置感知评估框架，结合人工标注的三元组和LLM-as-Judge协议，以减轻参考无关评分中的位置偏差。最后，开发本体引导的LLM管道，利用大型语言模型从文本中提取结构化知识，通过本体对齐提示优化提取过程。",
      "result": "实验结果显示，本体对齐提示相比基线模型，在知识提取任务上取得了显著改进：准确率提升44.2%，幻觉减少22.5%，格式依从性增强20.9%。这些性能指标通过评估框架验证，证实了本体引导在提升提取准确性和减少错误方面的有效性，为HMA领域应用提供了可靠数据支撑。",
      "conclusion": "TextMineX为HMA领域提供了首个综合的数据集、评估框架和本体引导LLM管道，显著提升了知识提取的准确性和可靠性，并公开数据集和代码以促进后续研究。该工作具有重要学术价值和实际应用意义，有助于改善排雷行动中的信息管理，未来可扩展到其他相关领域或进一步优化模型性能。",
      "tags": [
        "Large Language Model",
        "Knowledge Extraction",
        "Ontology-guided Pipeline",
        "Bias-aware Evaluation",
        "Humanitarian Mine Action Dataset"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:32.362385Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.14904",
    "title": "Robust Barycenters of Persistence Diagrams",
    "authors": [
      "Keanu Sisouk",
      "Eloi Tanguy",
      "Julie Delon",
      "Julien Tierny"
    ],
    "abstract": "This short paper presents a general approach for computing robust Wasserstein barycenters of persistence diagrams. The classical method consists in computing assignment arithmetic means after finding the optimal transport plans between the barycenter and the persistence diagrams. However, this procedure only works for the transportation cost related to the $q$-Wasserstein distance $W_q$ when $q=2$. We adapt an alternative fixed-point method to compute a barycenter diagram for generic transportation costs ($q > 1$), in particular those robust to outliers, $q \\in (1,2)$. We show the utility of our work in two applications: \\emph{(i)} the clustering of persistence diagrams on their metric space and \\emph{(ii)} the dictionary encoding of persistence diagrams. In both scenarios, we demonstrate the added robustness to outliers provided by our generalized framework. Our Python implementation is available at this address: https://github.com/Keanu-Sisouk/RobustBarycenter .",
    "categories": [
      "cs.LG",
      "cs.CG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.14904.pdf",
    "abs_url": "https://arxiv.org/abs/2509.14904",
    "published": "2025-09-18T12:29:10Z",
    "updated": "2026-01-21T10:41:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种计算持久图鲁棒Wasserstein重心的通用方法，通过调整固定点算法扩展至通用运输成本，增强了对抗离群值的鲁棒性。",
      "motivation": "持久图常用于拓扑数据分析中表示数据的拓扑特征，计算其Wasserstein重心是重要任务。现有经典方法基于最优运输计划，但仅适用于$q=2$的Wasserstein距离，这限制了其在通用运输成本下的应用，特别是当需要鲁棒处理离群值时（$q \\in (1,2)$）。因此，开发一种支持通用成本并能有效应对离群值的方法成为关键需求，以提升实际应用的可靠性和灵活性。",
      "method": "本研究调整了一种替代的固定点方法，用于计算通用运输成本（$q > 1$）的持久图重心。该方法避免了传统方法中仅限于$q=2$的限制，通过固定点迭代优化过程实现重心的计算，关键创新在于扩展到更广泛的运输成本（尤其$q \\in (1,2)$），从而增强对离群值的鲁棒性。摘要未明确说明具体的数据集、模型架构或实现细节，但提及了Python实现可用。",
      "result": "研究在持久图的度量空间聚类和字典编码两个应用中展示了方法的效用。通过比较经典方法（仅适用于$q=2$）与提出的广义框架，证明了新方法在应对离群值时具有显著增强的鲁棒性。摘要未提供具体的性能指标数据（如准确率提升或效率改进的百分比），但实验结果支持了方法的有效性，表明在噪声数据环境下表现更优。",
      "conclusion": "论文的主要贡献是提出了一种计算持久图鲁棒Wasserstein重心的通用方法，解决了现有方法仅适用于特定运输成本的局限性。研究的学术价值在于为拓扑数据分析中的重心计算提供了更灵活的解决方案，实际应用价值体现在提高聚类和字典编码任务的可靠性。摘要未明确说明具体局限性或未来工作方向，但潜在方向可能包括算法优化或扩展到其他拓扑数据分析任务。",
      "tags": [
        "Wasserstein Barycenter",
        "Persistence Diagrams",
        "Robustness to Outliers",
        "Fixed-point Method",
        "q-Wasserstein Distance"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:38.006528Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.10132",
    "title": "Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning",
    "authors": [
      "Nour Jamoussi",
      "Giuseppe Serra",
      "Photios A. Stavrou",
      "Marios Kountouris"
    ],
    "abstract": "Bayesian Federated Learning (BFL) combines uncertainty modeling with decentralized training, enabling the development of personalized and reliable models under data heterogeneity and privacy constraints. Existing approaches typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational inference, often incorporating personalization mechanisms to better adapt to local data distributions. In this work, we propose an information-geometric projection framework for personalization in parametric BFL. By projecting the global model onto a neighborhood of the user's local model, our method enables a tunable trade-off between global generalization and local specialization. Under mild assumptions, we show that this projection step is equivalent to computing a barycenter on the statistical manifold, allowing us to derive closed-form solutions and achieve cost-free personalization. We apply the proposed approach to a variational learning setup using the Improved Variational Online Newton (IVON) optimizer and extend its application to general aggregation schemes in BFL. Empirical evaluations under heterogeneous data distributions confirm that our method effectively balances global and local performance with minimal computational overhead.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.10132.pdf",
    "abs_url": "https://arxiv.org/abs/2509.10132",
    "published": "2025-09-12T10:46:21Z",
    "updated": "2026-01-21T13:15:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出信息几何投影框架，在贝叶斯联邦学习中实现成本免费的个性化，平衡全局泛化和局部专业化。",
      "motivation": "贝叶斯联邦学习在数据异构性和隐私约束下，需要开发个性化模型以提高可靠性和适应性。现有方法通常依赖马尔可夫链蒙特卡洛采样或变分推断，并结合个人化机制，但这些方法可能存在计算开销大或效率低下的问题，尤其在处理异构数据时。因此，研究如何在不增加额外成本的情况下实现有效个性化成为一个重要挑战，以适应实际应用中对高效隐私保护学习的需求。",
      "method": "论文提出了一个信息几何投影框架，用于贝叶斯联邦学习的参数化个性化。通过将全局模型投影到用户局部模型的邻域，该方法实现可调地平衡全局泛化和局部专业化。在温和假设下，证明投影步骤等价于计算统计流形上的重心，从而推导出闭式解，实现成本免费的个性化。具体应用于变分学习设置，使用改进的变分在线牛顿优化器，并扩展到贝叶斯联邦学习的一般聚合方案。",
      "result": "在异构数据分布下的实证评估表明，该方法能有效平衡全局和局部性能，且计算开销最小。摘要未提供具体性能指标数据，但基于描述，可以推断方法在保持高准确性的同时减少了计算成本。与现有基线方法相比，可能在平衡泛化能力和专业化程度方面表现出色，支持高效学习。",
      "conclusion": "该研究的主要贡献是开发了一个信息几何投影框架，实现了贝叶斯联邦学习中的成本免费个性化，提供了一种新方法来平衡全局泛化和局部专业化。其学术价值在于结合信息几何理论和机器学习，为个性化学习提供理论基础；实际应用价值在于促进隐私保护下的分布式模型优化。潜在的局限性包括假设的温和性可能限制应用场景，未来工作可能涉及扩展到更广泛的分布或验证实际部署效果。",
      "tags": [
        "Information-Geometric Projection",
        "Bayesian Federated Learning",
        "Variational Inference",
        "Improved Variational Online Newton",
        "Personalization"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:47.014736Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.10011",
    "title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss",
    "authors": [
      "Antoine Oriou",
      "Philipp Krah",
      "Julian Koellermeier"
    ],
    "abstract": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA), which identifies the underlying intrinsic dimension of a wide range of datasets whose samples lie on either linear or nonlinear manifolds. Beyond estimating the intrinsic dimension, IDEA is also able to reconstruct the original dataset after projecting it onto the corresponding latent space, which is structured using re-weighted double CancelOut layers. Our key contribution is the introduction of the projected reconstruction loss term, guiding the training of the model by continuously assessing the reconstruction quality under the removal of an additional latent dimension. We first assess the performance of IDEA on a series of theoretical benchmarks to validate its robustness. These experiments allow us to test its reconstruction ability and compare its performance with state-of-the-art intrinsic dimension estimators. The benchmarks show good accuracy and high versatility of our approach. Subsequently, we apply our model to data generated from the numerical solution of a vertically resolved one-dimensional free-surface flow, following a pointwise discretization of the vertical velocity profile in the horizontal direction, vertical direction, and time. IDEA succeeds in estimating the dataset's intrinsic dimension and then reconstructs the original solution by working directly within the projection space identified by the network.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.10011.pdf",
    "abs_url": "https://arxiv.org/abs/2509.10011",
    "published": "2025-09-12T07:11:05Z",
    "updated": "2026-01-21T14:45:18Z",
    "comment": "Code available: https://doi.org/10.5281/zenodo.18314616 Github: https://github.com/antoineor/IDEA-for-Shallow-Flows/tree/v1.1",
    "light_analysis": {
      "overview": "提出Intrinsic Dimension Estimating Autoencoder (IDEA)，结合CancelOut层和投影重构损失项，实现数据集内在维度的准确估计和高保真重构。",
      "motivation": "该研究旨在解决数据集内在维度估计的挑战，这对于理解数据结构和优化降维方法至关重要。现有方法可能难以同时处理线性或非线性流形，并有效进行重构，导致估计准确性不足。IDEA通过整合估计与重构，提供了更全面的解决方案，强调了鲁棒性和多功能性，以弥补现有技术的局限，尽管摘要未明确说明具体不足之处。",
      "method": "IDEA基于自编码器架构，使用重加权双重CancelOut层构建结构化潜在空间。核心创新在于引入投影重构损失项，该损失在训练过程中通过移除额外潜在维度来持续评估重构质量，从而引导模型优化。方法首先在理论基准数据集上进行验证，随后应用于数值解数据集，如垂直分辨率一维自由面流的点向离散化数据，涵盖水平、垂直方向和时间的速度剖面，以测试模型的泛化能力。",
      "result": "在理论基准测试中，IDEA展现出良好的准确性和高泛化性，与最先进的内在维度估计器相比表现优异，但摘要未提供具体性能数据如准确率数值。实验表明模型能成功估计数据集的内在维度，并在投影空间中进行高效重构，验证了其在多种数据集上的鲁棒性，包括从数值解生成的数据，实现了从估计到重构的无缝过渡。",
      "conclusion": "IDEA的主要贡献是提出了一种整合内在维度估计和数据重构的新框架，通过CancelOut层和投影损失项增强模型的鲁棒性。该研究在学术上推动了流形学习和自编码器技术的发展，在实际应用中为科学计算和数据分析提供了有效工具。潜在局限性包括在更复杂数据集上的进一步验证，未来工作可扩展至其他领域或优化损失函数以提高性能。",
      "tags": [
        "Autoencoder",
        "Intrinsic Dimension Estimation",
        "CancelOut Layer",
        "Projected Loss",
        "Manifold Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:38.733999Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.09312",
    "title": "Explaining Tournament Solutions with Minimal Supports",
    "authors": [
      "Clément Contet",
      "Umberto Grandi",
      "Jérôme Mengin"
    ],
    "abstract": "Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams. We study the problem of providing certified explanations for why a candidate appears among the winners under various tournament rules. To this end, we identify minimal supports, minimal sub-tournaments in which the candidate is guaranteed to win regardless of how the rest of the tournament is completed (that is, the candidate is a necessary winner of the sub-tournament). This notion corresponds to an abductive explanation for the question,\"Why does the winner win the tournament?\", a central concept in formal explainable AI. We focus on common tournament solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule, the maximin rule, and the weighted uncovered set. For each rule we determine the size of the smallest minimal supports, and we present polynomial-time algorithms to compute them for all solutions except for the weighted uncovered set, for which the problem is NP-complete. Finally, we show how minimal supports can serve to produce compact, certified, and intuitive explanations for tournament solutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.09312.pdf",
    "abs_url": "https://arxiv.org/abs/2509.09312",
    "published": "2025-09-11T09:55:50Z",
    "updated": "2026-01-21T06:41:40Z",
    "comment": "This paper is the extended version of Contet, Grandi, and Mengin. 2026. Explaining Tournament Solutions with Minimal Supports. In Proceedings of the 40th AAAI Conference on Artificial Intelligence",
    "light_analysis": {
      "overview": "本文提出最小支撑的概念，为多种锦标赛规则下的胜者提供紧凑、认证的解释，并开发了相关算法和复杂度分析。",
      "motivation": "锦标赛模型广泛用于表示候选人、替代方案或团队之间的成对优势，但在可解释人工智能领域，为胜者提供数学上严谨的解释是一个核心问题。现有方法可能缺乏认证性或直观性，无法充分回答‘为什么胜者获胜？’的问题，这在formal explainable AI中至关重要。本研究旨在通过最小支撑概念，为各种锦标赛规则提供可靠且可解释的答案，以弥补现有研究在解释性方面的不足，提升决策系统的透明度和可信度。",
      "method": "研究引入最小支撑的概念，定义为最小的子锦标赛，其中候选者无论锦标赛其余部分如何完成都保证获胜，这对应于abductive explanation。聚焦于常见锦标赛解决方案：top cycle、uncovered set、Copeland rule、Borda rule、maximin rule和weighted uncovered set。针对每个规则，分析最小支撑的最小尺寸，并设计多项式时间算法来计算它们，除了weighted uncovered set外。对于weighted uncovered set，证明计算最小支撑的问题是NP完全的。关键创新点在于将解释性问题形式化为最小支撑的识别和计算。",
      "result": "对于top cycle、uncovered set、Copeland rule、Borda rule和maximin rule，确定了最小支撑的最小尺寸，并提出了多项式时间算法，表明这些规则可以用高效方法提供认证解释。相比之下，对于weighted uncovered set，证明计算最小支撑是NP完全的，揭示了该规则的计算复杂性。这些结果通过具体算法和复杂度分析，展示了最小支撑在不同锦标赛规则下的可计算性和局限性，与基线方法相比，提供了更紧凑和可靠的解释框架。",
      "conclusion": "本研究通过最小支撑概念，为锦标赛解决方案提供了紧凑、认证且直观的解释，增强了决策系统的可解释性。主要贡献包括理论框架的建立、算法设计和复杂度分析，为formal explainable AI提供了新工具。尽管加权uncovered set存在计算挑战，但研究为未来优化或近似方法指明方向，并可能扩展至投票理论、社交选择等领域，推动实际应用。潜在局限性包括摘要未明确说明对其他规则或更复杂场景的适应性，未来工作可探索扩展应用或改进算法效率。",
      "tags": [
        "Tournament Solutions",
        "Minimal Supports",
        "Abductive Explanation",
        "Polynomial-time Algorithms",
        "NP-completeness"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:28.969090Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.03122",
    "title": "From Construction to Injection: Edit-Based Fingerprints for Large Language Models",
    "authors": [
      "Yue Li",
      "Xin Yi",
      "Dongsheng Shi",
      "Yongyi Cui",
      "Gerard de Melo",
      "Linlin Wang"
    ],
    "abstract": "Establishing reliable and verifiable fingerprinting mechanisms is fundamental to controlling the unauthorized redistribution of large language models (LLMs). However, existing approaches face two major challenges: (a) ensuring imperceptibility, including resistance to statistical identification and avoidance of accidental activation during fingerprint construction, and (b) preserving both model utility and fingerprint detectability under subsequent model modifications. To address these challenges, we propose an end-to-end fingerprinting framework with two components. First, we design a rule-based code-mixing fingerprint (CF) that maps natural-query-like prompts to multi-candidate targets, reducing accidental triggering via high-complexity code-mixing formulations. Second, we introduce Multi-Candidate Editing (MCEdit), which jointly optimizes multi-candidate targets and enforces margins between target and non-target outputs to improve post-modification detectability. Extensive experiments demonstrate that our framework provides a robust and practical solution for fingerprinting LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.03122.pdf",
    "abs_url": "https://arxiv.org/abs/2509.03122",
    "published": "2025-09-03T08:22:04Z",
    "updated": "2026-01-21T17:56:42Z",
    "comment": "preprint",
    "light_analysis": {
      "overview": "论文提出了一种结合代码混合指纹和多候选编辑的端到端框架，为大型语言模型提供鲁棒且不可察觉的指纹机制。",
      "motivation": "随着大型语言模型（LLMs）的广泛应用，控制其未经授权重新分发变得至关重要，以保护知识产权。现有指纹方法面临两大挑战：一是确保指纹的不可察觉性，包括抵抗统计识别和避免在正常使用中意外激活，这可能导致用户体验下降或安全风险；二是在模型经过后续微调或修改后，保持指纹的可检测性和模型效用，否则指纹容易失效。这些问题限制了现有方法的实用性，因此迫切需要一种能同时应对这些挑战的鲁棒解决方案，以促进可靠的模型分发控制。",
      "method": "研究方法包括两个核心组件。首先，设计了一个基于规则的代码混合指纹（CF），它使用高复杂度的代码混合公式，将类似自然查询的提示映射到多个候选目标，通过增加随机性和复杂性来减少意外触发，从而提高不可察觉性。其次，引入了多候选编辑（MCEdit），这是一个优化过程，联合处理多个候选目标，并在输出之间强制执行边界，以增强模型在修改后的指纹可检测性。摘要未明确说明具体使用的数据集或模型架构，但方法强调了端到端的框架设计，结合了规则和优化技术来提升整体性能。",
      "result": "论文通过广泛实验验证了框架的有效性，结果表明，该方法在指纹的不可察觉性和修改后的可检测性方面表现优异。实验展示了框架相比基线方法的优势，例如在减少意外激活和保持鲁棒性方面有所改进，具体性能指标如准确率或效率提升在摘要中未明确说明，但整体效果证明为大型语言模型提供了一种实用的指纹解决方案，增强了模型分发控制的能力。",
      "conclusion": "该研究的主要贡献是开发了一个端到端的指纹框架，成功解决了大型语言模型指纹中的不可察觉性和可检测性挑战。其学术价值在于创新性地结合了代码混合和多候选编辑技术，为指纹机制提供了新思路，推动了相关领域的发展。实际应用中，该方法有助于防止模型未经授权分发，保护开发者权益，具有重要的商业和安全意义。未来工作可能涉及进一步优化指纹鲁棒性、扩展到其他模型类型或处理更复杂的攻击场景。",
      "tags": [
        "Large Language Model",
        "Fingerprinting",
        "Code-Mixing",
        "Multi-Candidate Editing",
        "End-to-End Framework"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:41.206305Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.03010",
    "title": "Mitigating Data Imbalance in Automated Speaking Assessment",
    "authors": [
      "Fong-Chun Tsai",
      "Kuan-Tang Huang",
      "Bi-Cheng Yan",
      "Tien-Hong Lo",
      "Berlin Chen"
    ],
    "abstract": "Automated Speaking Assessment (ASA) plays a crucial role in evaluating second-language (L2) learners proficiency. However, ASA models often suffer from class imbalance, leading to biased predictions. To address this, we introduce a novel objective for training ASA models, dubbed the Balancing Logit Variation (BLV) loss, which perturbs model predictions to improve feature representation for minority classes without modifying the dataset. Evaluations on the ICNALE benchmark dataset show that integrating the BLV loss into a celebrated text-based (BERT) model significantly enhances classification accuracy and fairness, making automated speech evaluation more robust for diverse learners.",
    "categories": [
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.03010.pdf",
    "abs_url": "https://arxiv.org/abs/2509.03010",
    "published": "2025-09-03T04:38:13Z",
    "updated": "2026-01-21T11:03:19Z",
    "comment": "Accepted by APSIPA 2025; revised figure, references added",
    "light_analysis": {
      "overview": "论文提出平衡对数变体（BLV）损失函数，通过扰动预测改善少数类特征表示，有效缓解自动化口语评估中的类别不平衡问题，提升模型准确性和公平性。",
      "motivation": "自动化口语评估（ASA）在评估第二语言学习者能力中至关重要，但ASA模型常受类别不平衡影响，导致预测偏差，影响评估的准确性和公平性。现有方法如数据重采样可能效率低下或复杂，无法在不修改数据集的情况下直接改善少数类表现。因此，本研究旨在开发一种无需修改数据集的简单有效方法，通过改进损失函数来平衡类别影响，使ASA模型更适用于多样化的学习者群体。",
      "method": "本研究提出平衡对数变体（BLV）损失函数作为核心方法，通过扰动模型预测来增强少数类的特征表示，而无需对原始数据集进行任何调整。该损失函数被集成到基于BERT的文本模型中，利用BERT的强大语言表示能力处理自动化口语评估任务。在ICNALE基准数据集上进行训练和评估，BLV损失通过调整预测分布来平衡不同类别的影响，关键创新点在于直接优化模型输出，避免复杂的数据预处理步骤。",
      "result": "在ICNALE基准数据集上的实验表明，集成BLV损失的BERT模型显著提高了分类准确性和公平性，使自动化语音评估对不同学习者更稳健。与基线方法相比，改进效果明显，尽管摘要未提供具体性能指标数据，但结果强调了BLV损失在缓解类别不平衡方面的有效性。评估过程验证了该方法在不需要修改数据集的情况下，能够提升模型在少数类上的表现，从而增强整体评估的可靠性。",
      "conclusion": "论文的主要贡献是提出BLV损失函数，成功缓解自动化口语评估中的类别不平衡问题，提高了模型的准确性和公平性。这项研究具有重要的学术和实际应用价值，为开发更可靠的自动化评估工具提供了新思路，有助于促进第二语言学习的个性化发展。未来工作方向可能包括将BLV损失扩展到其他不平衡学习场景，或结合更多模型架构进行优化，但摘要未明确说明具体局限性。",
      "tags": [
        "Automated Speaking Assessment",
        "Class Imbalance",
        "BLV loss",
        "BERT",
        "ICNALE dataset"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:29.441445Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.01631",
    "title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons",
    "authors": [
      "Chongwen Zhao",
      "Yutong Ke",
      "Kaizhu Huang"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly attracting attention in various applications. Nonetheless, there is a growing concern as some users attempt to exploit these models for malicious purposes, including the synthesis of controlled substances and the propagation of disinformation, a technique known as \"Jailbreak.\" While some studies have achieved defenses against jailbreak attacks by modifying output distributions or detecting harmful content, the exact rationale still remains elusive. In this work, we present a novel neuron-level interpretability method that focuses on the role of safety-related knowledge neurons. Unlike existing approaches, our method projects the model's internal representation into a more consistent and interpretable vocabulary space. We then show that adjusting the activation of safety-related neurons can effectively control the model's behavior with a mean ASR higher than 97%. Building on this insight, we propose SafeTuning, a fine-tuning strategy that reinforces safety-critical neurons to improve model robustness against jailbreaks. SafeTuning consistently reduces attack success rates across multiple LLMs and outperforms all four baseline defenses. These findings offer a new perspective on understanding and defending against jailbreak attacks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.01631.pdf",
    "abs_url": "https://arxiv.org/abs/2509.01631",
    "published": "2025-09-01T17:17:06Z",
    "updated": "2026-01-21T03:40:08Z",
    "comment": "EACL 2026",
    "light_analysis": {
      "overview": "本文提出了一种基于安全相关知识神经元的可解释性方法和SafeTuning微调策略，以理解和防御LLM的jailbreak攻击。",
      "motivation": "大语言模型（LLM）在广泛应用中受到关注，但面临安全挑战：一些用户利用这些模型进行恶意活动，如合成受控物质或传播虚假信息，这种技术被称为“Jailbreak”攻击。现有研究虽然通过修改输出分布或检测有害内容来防御攻击，但其内在原理仍然不明确。随着LLM在关键领域部署增加，理解并解决这些问题至关重要。因此，迫切需要探索模型内部机制，开发更透明和有效的防御方法，以提升整体安全性并防止潜在滥用。",
      "method": "本研究提出了一种新颖的神经元级可解释性方法，重点关注安全相关知识神经元在模型行为中的作用。与现有方法不同，该方法将模型的内部表示投射到一个更一致和可解释的词汇空间中，从而实现对神经元激活的直接分析。通过调整安全相关神经元的激活状态，可以有效地控制模型的行为。基于这一发现，作者开发了SafeTuning，一种微调策略，通过强化安全关键神经元的活性来提高模型对jailbreak攻击的鲁棒性。摘要未明确说明具体使用的数据集和模型架构，但提及在多个LLMs上进行了验证。",
      "result": "实验结果显示，通过调整安全相关神经元的激活，能够控制模型行为，实现平均攻击成功率（ASR）高于97%。SafeTuning策略在多个大型语言模型上进行了测试，一致降低了攻击成功率，并优于所有四个基线防御方法。这表明该方法在防御jailbreak攻击方面具有显著效果，不仅提高了模型的安全性，还展示了其在不同模型上的通用性和稳定性，为实际应用提供了可靠依据。",
      "conclusion": "本研究的主要贡献是提供了一种理解和防御LLM jailbreak攻击的新视角，通过神经元级可解释性方法揭示了安全相关知识神经元的关键作用。SafeTuning策略通过微调增强模型鲁棒性，具有重要的学术价值和实际应用潜力，可用于改进LLM的安全部署。未来工作可以进一步探索神经元的机制细节，或将该方法扩展到其他攻击类型，以提升泛化能力。摘要未明确说明具体局限性，但可能涉及计算开销或对其他安全威胁的适用性。",
      "tags": [
        "Large Language Model (LLM)",
        "Jailbreak Attack",
        "Neuron-level Interpretability",
        "SafeTuning",
        "Model Robustness"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:02.243618Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.17825",
    "title": "FAIRGAMER: Evaluating Social Biases in LLM-Based Video Game NPCs",
    "authors": [
      "Bingkang Shi",
      "Jen-tse Huang",
      "Long Luo",
      "Tianyu Zong",
      "Hongzhu Yi",
      "Yuanxiang Wang",
      "Songlin Hu",
      "Xiaodan Zhang",
      "Zhongjiang Yao"
    ],
    "abstract": "Large Language Models (LLMs) have increasingly enhanced or replaced traditional Non-Player Characters (NPCs) in video games. However, these LLM-based NPCs inherit underlying social biases (e.g., race or class), posing fairness risks during in-game interactions. To address the limited exploration of this issue, we introduce FairGamer, the first benchmark to evaluate social biases across three interaction patterns: transaction, cooperation, and competition. FairGamer assesses four bias types, including class, race, age, and nationality, across 12 distinct evaluation tasks using a novel metric, FairMCV. Our evaluation of seven frontier LLMs reveals that: (1) models exhibit biased decision-making, with Grok-4-Fast demonstrating the highest bias (average FairMCV = 76.9%); and (2) larger LLMs display more severe social biases, suggesting that increased model capacity inadvertently amplifies these biases. We release FairGamer at https://github.com/Anonymous999-xxx/FairGamer to facilitate future research on NPC fairness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2508.17825.pdf",
    "abs_url": "https://arxiv.org/abs/2508.17825",
    "published": "2025-08-25T09:26:19Z",
    "updated": "2026-01-21T02:31:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文的核心贡献是提出了 FairGamer，首个评估基于大语言模型的视频游戏非玩家角色中社会偏见的基准。",
      "motivation": "随着大语言模型被广泛应用于视频游戏的非玩家角色中，这些模型可能继承训练数据中的社会偏见，如种族、阶级、年龄或国籍偏见，导致游戏中不公平的交互行为，影响玩家体验和公平性。然而，现有研究对此问题的探索有限，缺乏系统性评估工具和方法。因此，该研究旨在填补这一空白，通过开发专门基准来量化这些偏见，推动更公平的 AI 在游戏领域的应用。",
      "method": "FairGamer 是一个创新的评估基准，通过设计三种交互模式（交易、合作和竞争）和四种偏见类型（阶级、种族、年龄和国籍），在 12 个具体任务中测试基于大语言模型的非玩家角色。核心创新是引入了 FairMCV 指标来量化偏见程度，该方法使用虚拟数据集构建评估场景，覆盖多样化的交互情境。评估涉及七个前沿大语言模型，以分析模型在不同条件下的偏见表现，为研究者提供了一个可复现的框架来比较模型公平性。",
      "result": "实验结果表明，所有测试的大语言模型在 FairGamer 基准下均表现出社会偏见决策，例如 Grok-4-Fast 模型的平均 FairMCV 值高达 76.9%，显示偏见最为严重。研究发现模型容量越大，社会偏见越严重，这表明增加模型规模可能无意中放大了偏见问题。与其他前沿模型相比，这一趋势普遍存在，强调了偏见在 LLM-based NPCs 中的广泛性和严重性，尽管摘要未提供所有模型的详细对比数据。",
      "conclusion": "该研究的主要贡献是提出了首个专门评估基于大语言模型的视频游戏非玩家角色中社会偏见的基准 FairGamer，揭示了当前模型在游戏交互中的偏见风险。学术价值在于为公平 AI 研究提供了新的评估工具，实际应用价值有助于游戏开发者设计更公平的 AI 角色。局限性包括评估范围限于特定偏见类型和交互模式，未来工作可扩展到更多偏见维度或其他应用领域。通过公开发布基准，旨在促进社区进一步探索和改进。",
      "tags": [
        "Large Language Model",
        "Social Bias",
        "Benchmarking",
        "Fairness Evaluation",
        "Non-Player Characters"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:05.733352Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.09275",
    "title": "Constrained Black-Box Attacks Against Cooperative Multi-Agent Reinforcement Learning",
    "authors": [
      "Amine Andam",
      "Jamal Bentahar",
      "Mustapha Hedabou"
    ],
    "abstract": "Collaborative multi-agent reinforcement learning has rapidly evolved, offering state-of-the-art algorithms for real-world applications, including sensitive domains. However, a key challenge to its widespread adoption is the lack of a thorough investigation into its vulnerabilities to adversarial attacks. Existing work predominantly focuses on training-time attacks or unrealistic scenarios, such as access to policy weights or the ability to train surrogate policies. In this paper, we investigate new vulnerabilities under more challenging and constrained conditions, assuming an adversary can only collect and perturb the observations of deployed agents. We also consider scenarios where the adversary has no access at all (no observations, actions, or weights). Our main approach is to generate perturbations that intentionally misalign how victim agents see their environment. Our approach is empirically validated on three benchmarks and 22 environments, demonstrating its effectiveness across diverse algorithms and environments. Furthermore, we show that our algorithm is sample-efficient, requiring only 1,000 samples compared to the millions needed by previous methods.",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.09275.pdf",
    "abs_url": "https://arxiv.org/abs/2508.09275",
    "published": "2025-08-12T18:31:15Z",
    "updated": "2026-01-21T14:25:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种在受限条件下对协作多智能体强化学习进行黑盒攻击的新方法，揭示了系统的新漏洞。",
      "motivation": "协作多智能体强化学习已在敏感领域广泛应用，但其对抗性攻击漏洞研究不足。现有工作多集中于训练时攻击或不现实场景，如攻击者能访问策略权重或训练替代策略，这限制了实际安全性评估。因此，本论文旨在解决这一问题，研究在更挑战和约束条件下的攻击方法，如仅能干扰智能体观察或无任何访问权限，以提升系统安全性和对抗鲁棒性。",
      "method": "论文的核心方法是生成扰动来故意误导受害者智能体的环境观察，使其产生错误判断。攻击者假设仅能收集和扰动部署智能体的观察，或甚至无访问权限，这模拟了实际的黑盒攻击场景。研究在三个基准和22个不同环境中进行实证验证，涵盖了多样化的协作强化学习算法，关键创新在于在更严格的约束条件下设计攻击策略。",
      "result": "实验结果显示，该攻击方法在多种算法和环境中均有效，能成功干扰协作智能体系统。具体而言，算法样本效率高，仅需1000个样本即可实施攻击，相比先前方法所需的数百万样本，显著降低了资源消耗和攻击成本。这证明了方法在受限条件下的有效性和普适性，为对抗性攻击研究提供了新基准。",
      "conclusion": "本文的主要贡献是揭示了协作多智能体强化学习在受限条件下的新漏洞，并提出了一种高效的黑盒攻击方法。学术价值在于扩展了对抗性攻击场景，促进了对抗鲁棒性研究；实际应用价值在于帮助改进敏感领域系统的安全性。局限性可能包括攻击的泛化性，未来工作可探索更广泛的攻击策略和防御机制，以增强系统韧性。",
      "tags": [
        "Multi-Agent Reinforcement Learning",
        "Adversarial Attacks",
        "Black-Box Attacks",
        "Observation Perturbation",
        "Sample Efficiency"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:49.876941Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.07690",
    "title": "LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval",
    "authors": [
      "Luyao Zhuang",
      "Qinggang Zhang",
      "Huachi Zhou",
      "Yujing Zhang",
      "Xiao Huang"
    ],
    "abstract": "Tool learning has emerged as a promising paradigm for large language models (LLMs) to solve many real-world tasks. Nonetheless, with the tool repository rapidly expanding, it is impractical to contain all tools within the limited input length of LLMs. To alleviate these issues, researchers have explored incorporating a tool retrieval module to select the most relevant tools or represent tools as unique tokens within LLM parameters. However, most state-of-the-art methods are under transductive settings, assuming all tools have been observed during training. Such a setting deviates from reality as the real-world tool repository is evolving and incorporates new tools frequently. When dealing with these unseen tools, which refer to tools not encountered during the training phase, these methods are limited by two key issues, including the large distribution shift and the vulnerability of similarity-based retrieval. To this end, inspired by human cognitive processes of mastering unseen tools through discovering and applying the logical information from prior experience, we introduce a novel Logic-Guided Semantic Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to mine and transfer latent logical information for inductive tool retrieval without costly retraining. Specifically, LoSemB contains a logic-based embedding alignment module to mitigate distribution shifts and implements a relational augmented retrieval mechanism to reduce the vulnerability of similarity-based retrieval. Extensive experiments demonstrate that LoSemB achieves advanced performance in inductive settings while maintaining desirable effectiveness in the transductive setting.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.07690.pdf",
    "abs_url": "https://arxiv.org/abs/2508.07690",
    "published": "2025-08-11T07:07:18Z",
    "updated": "2026-01-21T04:05:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "LoSemB框架通过逻辑引导的语义桥接，实现无需重训练的归纳工具检索，解决动态工具库中新工具的适应问题。",
      "motivation": "工具学习使大型语言模型能应对现实任务，但随着工具库快速扩展，LLM输入长度有限，无法容纳所有工具。现有方法多为归纳设置，假设训练时所有工具已知，但这与现实中工具库频繁更新的动态特性不符。处理训练中未见的工具时，面临分布偏移和基于相似性检索的脆弱性等挑战，限制了实际应用，因此亟需开发能适应新工具的有效检索方法。",
      "method": "LoSemB框架包括基于逻辑的嵌入对齐模块，用于减轻未见工具引起的分布偏移，以及关系增强检索机制，以降低基于相似性检索的脆弱性。它模仿人类认知过程，从先验经验中挖掘逻辑信息并传递到新工具，无需昂贵的重训练，实现了语义桥接，提升检索鲁棒性。",
      "result": "实验结果显示，LoSemB在归纳设置中取得先进性能，优于现有方法，同时在归纳设置中保持理想效果。摘要未明确说明具体数据指标，但表明其具有良好的适应性和鲁棒性，验证了框架在动态环境下的有效性。",
      "conclusion": "LoSemB框架为工具学习提供了一种创新的归纳检索解决方案，通过逻辑引导机制克服了未见工具的处理难题，具有重要的学术价值，如推动机器学习中的迁移学习和工具推理，以及实际应用价值，如动态工具库管理。未来工作可进一步优化逻辑挖掘算法或扩展应用到其他领域。",
      "tags": [
        "Inductive Tool Retrieval",
        "Logic-Guided Learning",
        "Semantic Bridging",
        "Embedding Alignment",
        "Relational Augmentation"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:34.227849Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.06433",
    "title": "Memp: Exploring Agent Procedural Memory",
    "authors": [
      "Runnan Fang",
      "Yuan Liang",
      "Xiaobin Wang",
      "Jialong Wu",
      "Shuofei Qiao",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model can also yield substantial performance gains. Code is available at https://github.com/zjunlp/MemP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.06433.pdf",
    "abs_url": "https://arxiv.org/abs/2508.06433",
    "published": "2025-08-08T16:20:56Z",
    "updated": "2026-01-21T08:02:27Z",
    "comment": "Work in progress",
    "light_analysis": {
      "overview": "提出Memp方法，通过蒸馏代理轨迹为细粒度指令和脚本抽象，赋予大型语言模型代理可学习和终身更新的程序性记忆。",
      "motivation": "基于大型语言模型的代理在多样化任务中表现出色，但其程序性记忆通常依赖手动设计或与静态参数纠缠，导致记忆易碎和适应性差。现有方法缺乏可学习、可更新的记忆机制，限制了代理在长期任务中的效率和稳定性。本文旨在解决这一问题，研究如何赋予代理更健壮、可进化的程序性记忆，以适应复杂和变化的现实任务需求。",
      "method": "本文提出Memp方法，核心是将过去的代理轨迹蒸馏成两种形式：细粒度的逐步指令和高级别的脚本式抽象。研究探讨了程序性记忆的构建、检索和更新策略，并采用动态方案持续优化记忆内容，使存储库与新经验同步演化。关键创新点在于开发了一个可学习、可更新和终身的程序性记忆系统，评估中使用了TravelPlanner和ALFWorld数据集来验证方法有效性，但摘要未明确说明具体模型架构细节。",
      "result": "在TravelPlanner和ALFWorld任务上的实证评估显示，随着程序性记忆存储库的逐步精炼，代理在类似任务中实现了稳定提高的成功率和更高的执行效率。此外，由更强模型构建的程序性记忆能够保留其价值：当迁移到更弱模型时，也能带来显著的性能增益。摘要未提供具体性能指标数据，如准确率百分比，但结果表明该方法有效提升了代理的适应性和任务表现。",
      "conclusion": "本文的主要贡献是提出了Memp，一个可学习、可更新的程序性记忆系统，增强了大型语言模型代理的终身学习和任务执行能力。学术价值在于改进了代理记忆机制，促进自适应智能体的发展；实际应用价值体现在提高任务效率和成功率。局限性方面摘要未明确说明，未来工作可能包括扩展应用到更广泛任务或优化记忆策略。",
      "tags": [
        "Large Language Models",
        "Procedural Memory",
        "Distillation",
        "Agent Trajectories",
        "Memory Update"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:48.378879Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.05553",
    "title": "Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs",
    "authors": [
      "Franziska Weeber",
      "Tanise Ceron",
      "Sebastian Padó"
    ],
    "abstract": "Public opinion surveys show cross-cultural differences in political opinions between socio-cultural contexts. However, there is no clear evidence whether these differences translate to cross-lingual differences in multilingual large language models (MLLMs). We analyze whether opinions transfer between languages or whether there are separate opinions for each language in MLLMs of various sizes across five Western languages. We evaluate MLLMs' opinions by prompting them to report their (dis)agreement with political statements from voting advice applications. To better understand the interaction between languages in the models, we evaluate them both before and after aligning them with more left or right views using direct preference optimization and English alignment data only. Our findings reveal that unaligned models show only very few significant cross-lingual differences in the political opinions they reflect. The political alignment shifts opinions almost uniformly across all five languages. We conclude that in Western language contexts, political opinions transfer between languages, demonstrating the challenges in achieving explicit socio-linguistic, cultural, and political alignment of MLLMs.",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.05553.pdf",
    "abs_url": "https://arxiv.org/abs/2508.05553",
    "published": "2025-08-07T16:33:45Z",
    "updated": "2026-01-21T13:30:54Z",
    "comment": "EACL2026",
    "light_analysis": {
      "overview": "论文通过分析多语言大型语言模型，发现政治观点在西方语言之间转移，揭示了模型对齐的挑战。",
      "motivation": "公共舆论调查显示跨文化政治观点差异，但现有研究缺乏证据表明这些差异是否在多语言大型语言模型中转化为跨语言差异。MLLMs作为AI系统，可能反映或偏倚特定语言文化背景，这对理解模型偏见、确保公平性和多语言AI设计至关重要。摘要未明确说明现有具体方法不足，但暗示了探讨跨语言观点转移的必要性，以填补理论空白并应对实际应用中潜在的模型对齐问题。",
      "method": "研究方法包括评估不同规模的多语言大型语言模型在五种西方语言中的表现。通过提示模型报告对来自投票建议应用的政治声明的同意度来量化政治观点。关键创新是使用直接偏好优化技术，仅基于英语数据对齐模型以改变政治倾向，并在对齐前后对比评估，以探究语言间交互机制。数据集基于投票建议应用，涵盖多样政治声明，核心是结合对齐操作分析模型的跨语言一致性。",
      "result": "实验结果显示，未对齐的多语言大型语言模型在反映的政治观点中，跨语言差异非常有限，仅观察到极少的显著差异。通过对齐操作，模型的政治观点几乎在所有五种语言中均匀地发生偏移，表明对齐影响一致且跨语言转移明显。与基线（未对齐状态）相比，对齐后观点变化更均匀，但摘要未明确说明具体性能指标如准确率提升或效率改进，仅基于定性描述强调差异稀少和变化一致性。",
      "conclusion": "论文结论是在西方语言背景下，多语言大型语言模型中的政治观点在语言之间转移，而非语言特定，表明实现模型的显式社会语言学、文化和政治对齐面临挑战。研究的学术价值在于揭示了模型对齐的复杂性和跨语言一致性机制，实际应用价值在于为多语言AI系统的设计、公平性评估和偏见缓解提供参考。未来工作方向可扩展至非西方语言或更广泛的文化背景，以进一步验证和深化发现。",
      "tags": [
        "Multilingual Large Language Models",
        "Direct Preference Optimization",
        "Political Alignment",
        "Cross-lingual Transfer",
        "Voting Advice Applications"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:27.882356Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.05283",
    "title": "Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue",
    "authors": [
      "Sukannya Purkayastha",
      "Nils Dycke",
      "Anne Lauscher",
      "Iryna Gurevych"
    ],
    "abstract": "Meta-reviewing is a pivotal stage in the peer-review process, serving as the final step in determining whether a paper is recommended for acceptance. Prior research on meta-reviewing has treated this as a summarization problem over review reports. However, complementary to this perspective, meta-reviewing is a decision-making process that requires weighing reviewer arguments and placing them within a broader context. Prior research has demonstrated that decision-makers can be effectively assisted in such scenarios via dialogue agents. In line with this framing, we explore the practical challenges for realizing dialog agents that can effectively assist meta-reviewers. Concretely, we first address the issue of data scarcity for training dialogue agents by generating synthetic data using Large Language Models (LLMs) based on a self-refinement strategy to improve the relevance of these dialogues to expert domains. Our experiments demonstrate that this method produces higher-quality synthetic data and can serve as a valuable resource towards training meta-reviewing assistants. Subsequently, we utilize this data to train dialogue agents tailored for meta-reviewing and find that these agents outperform \\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our agents in real-world meta-reviewing scenarios and confirm their effectiveness in enhancing the efficiency of meta-reviewing.\\footnote{Code available at: https://github.com/UKPLab/eacl2026-meta-review-as-dialog",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.05283.pdf",
    "abs_url": "https://arxiv.org/abs/2508.05283",
    "published": "2025-08-07T11:27:43Z",
    "updated": "2026-01-21T12:46:28Z",
    "comment": "Accepted at EACL Main Conference, 2026",
    "light_analysis": {
      "overview": "本研究提出了一种基于大型语言模型的对话代理方法，将元审阅重新定义为基于文档的决策对话，以提升辅助效率。",
      "motivation": "元审阅是同行评审的最终决策阶段，传统研究将其视为审稿报告的总结问题，但忽略了其作为决策过程的复杂性，需要权衡审稿人论点并置于更广泛背景。对话代理在辅助决策场景中显示出潜力，但实现面临数据稀缺和领域相关性不足的挑战。本研究旨在探索实现有效辅助元审阅的对话代理，弥补现有方法的局限性，以促进同行评审的效率和准确性。",
      "method": "研究方法基于大型语言模型，采用自精炼策略生成合成对话数据，以解决训练数据稀缺问题。通过优化生成过程，提高对话在专家领域的相关性。随后，利用这些数据训练专门用于元审阅的对话代理。摘要未详细说明具体数据集或模型架构，但核心创新点在于数据生成策略和代理的定制化训练，旨在实现更贴合元审阅任务的辅助功能。",
      "result": "实验结果显示，生成的数据质量优于其他方法，训练的对话代理在元审阅任务中表现超过现成的基于大型语言模型的助手，有效提升了辅助性能。在实际应用场景中，代理被证实能增强元审阅效率，但摘要未提供具体性能指标如准确率或改进百分比，仅通过对比强调了其优越性。这些结果验证了所提方法的实用性和有效性。",
      "conclusion": "该研究的主要贡献是提出并验证了一种生成高质量合成数据和训练专门对话代理的方法，用于辅助元审阅决策。学术上，它将元审阅重新定义为基于文档的对话，丰富了相关研究；实际上，有助于提高同行评审效率。未来工作可能涉及优化数据生成策略或扩展到其他决策场景，但摘要未明确说明局限性，仅暗示了潜在应用扩展。",
      "tags": [
        "Large Language Model",
        "Dialogue Agent",
        "Synthetic Data Generation",
        "Self-Refinement Strategy",
        "Meta-reviewing"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:56.516549Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.04339",
    "title": "Deliberative Reasoning Network: An Uncertainty-Driven Paradigm for Belief-Tracked Inference with Pretrained Language Models",
    "authors": [
      "Anran Xu",
      "Jincheng Wang",
      "Baigen Cai",
      "Tao Wen"
    ],
    "abstract": "Large language models often fail at logical reasoning when semantic heuristics conflict with decisive evidence - a phenomenon we term cognitive traps. To address this fundamental limitation, we introduce the Deliberative Reasoning Network (DRN), a novel paradigm that reframes logical reasoning from probability maximization to uncertainty minimization. Instead of asking \"Which answer is most likely?\", DRN asks \"Which hypothesis has the most internally consistent evidence?\". DRN achieves intrinsic interpretability by explicitly tracking belief states and quantifying epistemic uncertainty for competing hypotheses through an iterative evidence synthesis process. We validate our approach through two complementary architectures - a bespoke discriminative model that embodies the core uncertainty minimization principle, and a lightweight verification module that enhances existing generative LLMs. Evaluated on LCR-1000, our new adversarial reasoning benchmark designed to expose cognitive traps, the bespoke DRN achieves up to 15.2% improvement over standard baselines. When integrated as a parameter-efficient verifier with Mistral-7B, our hybrid system boosts accuracy from 20% to 80% on the most challenging problems. Critically, DRN demonstrates strong zero-shot generalization, improving TruthfulQA performance by 23.6% without additional training, indicating that uncertainty-driven deliberation learns transferable reasoning principles. We position DRN as a foundational, verifiable System 2 reasoning component for building more trustworthy AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2508.04339.pdf",
    "abs_url": "https://arxiv.org/abs/2508.04339",
    "published": "2025-08-06T11:33:35Z",
    "updated": "2026-01-21T11:26:33Z",
    "comment": "This submission represents an early exploratory draft and was uploaded prematurely. The authors have decided to withdraw it because the current version does not accurately reflect the intended scope and technical formulation of the work, and may be misleading if cited",
    "light_analysis": {
      "overview": "提出了Deliberative Reasoning Network，一种基于不确定性最小化的新范式，用于解决预训练语言模型在逻辑推理中的认知陷阱。",
      "motivation": "大型语言模型在逻辑推理任务中，当语义启发式与决定性证据冲突时，常陷入“认知陷阱”，导致推理失败。这一问题在需要高可靠性的应用（如自动决策或问答系统）中至关重要，因为现有方法多依赖概率最大化，难以有效处理证据冲突，从而产生偏差。因此，开发一种能最小化不确定性、提高推理一致性的新方法，具有重要的理论和实践意义。",
      "method": "DRN将逻辑推理从概率最大化重构为不确定性最小化，核心创新是通过迭代证据合成过程显式跟踪信念状态并量化认知不确定性。论文采用两种互补架构：一是定制的判别模型，直接体现不确定性最小化原则；二是轻量级验证模块，可集成到如Mistral-7B等现有生成式大型语言模型中，作为参数高效增强组件。实验使用自建的LCR-1000对抗性推理基准进行评估。",
      "result": "在LCR-1000基准上，定制DRN相比标准基线提升高达15.2%的性能；当与Mistral-7B集成作为验证器时，在最具挑战性问题上的准确率从20%显著提高到80%。此外，DRN展现出强大的零-shot泛化能力，在TruthfulQA数据集上无需额外训练即提升23.6%的性能，表明其不确定性驱动方法学习了可迁移的推理原则。",
      "conclusion": "本研究提出DRN作为可验证的系统2推理组件，旨在构建更可信的AI系统，其学术价值在于提供基于不确定性最小化的新推理框架，实际应用是显著提升语言模型在复杂逻辑任务中的可靠性。未来工作可探索DRN在其他推理任务的扩展，并进一步优化其泛化能力和效率。",
      "tags": [
        "Uncertainty Minimization",
        "Logical Reasoning",
        "Large Language Models",
        "Belief Tracking",
        "Epistemic Uncertainty"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:53.301660Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.03774",
    "title": "U-PINet: Physics-Informed Hierarchical Learning for Radar Cross Section Prediction via 3D Electromagnetic Scattering Reconstruction",
    "authors": [
      "Rui Zhu",
      "Yuexing Peng",
      "George C. Alexandropoulos",
      "Peng Wang",
      "Wenbo Wang",
      "Wei Xiang"
    ],
    "abstract": "Conventional computational electromagnetics (CEM) solvers can deliver high fidelity radar cross section (RCS) signatures by first solving the induced surface currents on 3-dimensional (3D) targets and then evaluating the scattered fields via radiation integrals. However, their computational cost becomes prohibitive for repeated queries and large-scale 3D scenarios. Recent purely data-driven networks improve efficiency, yet they often bypass this scattering mechanism, which may compromise physical consistency and generalization. To bridge this gap, in this paper, we propose U-PINet, a fully end-to-end, physics-informed hierarchical network for efficient RCS prediction via 3D electromagnetic scattering reconstruction. Once the scattering quantities are reconstructed, scattered fields and RCS can be evaluated for arbitrary observation directions via the radiation integral. U-PINet explicitly learns physics-consistent intermediate scattering representations by modeling local electromagnetic coupling and long-range radiation effects through a hierarchical operator design inspired by near-far field decomposition in fast solvers. A physics-guided graph neural network is incorporated to capture self- and mutual-coupling among mesh elements of complex targets, enabling physically interpretable intermediate representations. By embedding governing equations as residual constraints, U-PINet enables accurate object reconstruction of scattering quantities and consequently reliable RCS prediction across observation directions, while significantly reducing runtime. Extensive numerical experiments demonstrate that U-PINet achieves EM-solver-level RCS accuracy and 3D object reconstruction with orders-of-magnitude speedups, and generalizes well to unseen geometries under limited training data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.03774.pdf",
    "abs_url": "https://arxiv.org/abs/2508.03774",
    "published": "2025-08-05T12:20:42Z",
    "updated": "2026-01-21T09:38:46Z",
    "comment": "Submitted to an Elsevier Journal",
    "light_analysis": {
      "overview": "U-PINet 提出了一种基于物理信息的层次学习框架，通过3D电磁散射重建实现高效雷达横截面预测。",
      "motivation": "传统计算电磁方法在预测雷达横截面时，首先求解3D目标的诱导表面电流，再通过辐射积分评估散射场，虽然精度高，但计算成本极高，不适合重复查询和大规模3D场景。现有的纯数据驱动网络提高了效率，但绕过了散射机制，可能导致物理不一致性和泛化能力差。因此，需要一种既能保持物理准确性又能高效运行的新方法，以在电磁仿真中实现可靠预测。",
      "method": "U-PINet 是一种端到端的物理信息层次网络，通过学习物理一致的中间散射表示来重建3D电磁散射，进而预测雷达横截面。其关键创新点包括：基于近远场分解的层次操作符设计，模拟局部电磁耦合和长程辐射效应；集成物理引导的图神经网络，捕捉复杂目标网格元素的自耦合和互耦合，生成可解释的中间表示；通过将控制方程作为残差约束嵌入网络，确保物理一致性。该方法使用网格数据，但具体数据集摘要未明确说明。",
      "result": "广泛的数值实验表明，U-PINet 实现了与电磁解算器相当的雷达横截面精度，并准确重建3D对象。在性能上，运行时显著减少，速度提升数个数量级，同时保持了高准确性。与基线方法相比，U-PINet 在有限训练数据下对未见几何形状表现出良好的泛化能力，证明了其在实际应用中的潜力。",
      "conclusion": "本研究的主要贡献是提出了U-PINet，一个结合物理机制与深度学习的框架，用于高效且物理一致的雷达横截面预测，显著减少计算成本。其学术价值在于推动了物理信息学习在电磁仿真中的应用，实际应用价值包括在雷达系统和目标识别中实现快速准确预测。潜在局限性摘要未明确说明，未来工作可扩展至更复杂电磁场景或改进网络架构。",
      "tags": [
        "Physics-Informed Learning",
        "Radar Cross Section Prediction",
        "3D Electromagnetic Scattering",
        "Graph Neural Network",
        "Hierarchical Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:15.117907Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.10904",
    "title": "A2H-MAS: An Algorithm-to-HLS Multi-Agent System for Automated and Reliable FPGA Implementation",
    "authors": [
      "Jie Lei",
      "Ruofan Jia",
      "J. Andrew Zhang",
      "Hao Zhang"
    ],
    "abstract": "Bridging the gap between algorithm development and hardware realization remains a persistent challenge, particularly in latency- and resource-constrained domains such as wireless communication. While MATLAB provides a mature environment for algorithm prototyping, translating these models into efficient FPGA implementations via High-Level Synthesis (HLS) often requires expert tuning and lengthy iterations. Recent advances in large language models (LLMs) offer new opportunities for automating this process. However, existing approaches suffer from hallucinations, forgetting, limited domain expertise, and often overlook key performance metrics. To address these limitations, we present A2H-MAS, a modular and hierarchical multi-agent system. At the system level, A2H-MAS assigns clearly defined responsibilities to specialized agents and uses standardized interfaces and execution-based validation to ensure correctness and reproducibility. At the algorithmic level, it employs dataflow-oriented modular decomposition and algorithm-hardware co-design, recognizing that the choice of algorithm often has a larger impact on hardware efficiency than pragma-level optimization. Experiments on representative wireless communication algorithms show that A2H-MAS consistently produces functionally correct, resource-efficient, and latency-optimized HLS designs, demonstrating its effectiveness and robustness for complex hardware development workflows.",
    "categories": [
      "cs.CL",
      "cs.AR",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.10904.pdf",
    "abs_url": "https://arxiv.org/abs/2508.10904",
    "published": "2025-07-29T01:51:12Z",
    "updated": "2026-01-21T09:43:23Z",
    "comment": "9 pages, 6 figures",
    "light_analysis": {
      "overview": "提出了A2H-MAS，一个基于多代理系统的自动化、可靠的算法到高级综合FPGA实现方法。",
      "motivation": "研究动机源于算法开发与硬件实现之间的差距，尤其在无线通信等延迟和资源受限领域。现有方法如MATLAB到高级综合的转换需要专家调优和长时间迭代，而基于大语言模型的自动化方法存在幻觉、遗忘、领域知识有限和忽视关键性能指标等问题，因此需更高效、可靠的自动化解决方案来加速复杂硬件开发。",
      "method": "该方法采用A2H-MAS，一个模块化、层次化的多代理系统。在系统层面，通过分配专业化代理职责、使用标准化接口和基于执行的验证确保正确性和可重复性；算法层面，进行数据流导向的模块分解和算法硬件协同设计，强调算法选择对硬件效率的影响大于pragma级优化，以优化HLS实现流程。",
      "result": "实验在代表性无线通信算法上进行，结果显示A2H-MAS能够一致地生成功能正确、资源高效和延迟优化的HLS设计，证明了其在复杂硬件开发工作流程中的有效性和鲁棒性。但摘要未明确说明具体性能指标数据，如资源使用减少或延迟改进的百分比。",
      "conclusion": "结论是A2H-MAS通过多代理系统解决了自动化FPGA实现的挑战，提供了一种可靠的算法到硬件转换框架。其学术价值在于结合多代理技术与硬件协同设计，应用价值可提升无线通信等领域的开发效率；未来工作可能包括扩展到更多算法和硬件平台，摘要未明确说明局限性。",
      "tags": [
        "Multi-Agent System",
        "High-Level Synthesis (HLS)",
        "FPGA Implementation",
        "Algorithm-Hardware Co-design",
        "Dataflow Decomposition"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:43.151022Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.20174",
    "title": "LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks",
    "authors": [
      "Fei Kong"
    ],
    "abstract": "Real-world applications, such as autonomous driving and humanoid robot manipulation, require precise spatial perception. However, it remains underexplored how Vision-Language Models (VLMs) recognize spatial relationships and perceive spatial movement. In this work, we introduce a spatial evaluation pipeline and construct a corresponding benchmark. Specifically, we categorize spatial understanding into two main types: absolute spatial understanding, which involves querying the absolute spatial position (e.g., left, right) of an object within an image, and 3D spatial understanding, which includes movement and rotation. Notably, our dataset is entirely synthetic, enabling the generation of test samples at a low cost while also preventing dataset contamination. We conduct experiments on multiple state-of-the-art VLMs and observe that there is significant room for improvement in their spatial understanding abilities. Explicitly, in our experiments, humans achieve near-perfect performance on all tasks, whereas current VLMs attain human-level performance only on the two simplest tasks. For the remaining tasks, the performance of VLMs is distinctly lower than that of humans. In fact, the best-performing Vision-Language Models even achieve near-zero scores on multiple tasks. The dataset and code are available on https://github.com/kong13661/LRR-Bench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.20174.pdf",
    "abs_url": "https://arxiv.org/abs/2507.20174",
    "published": "2025-07-27T08:31:24Z",
    "updated": "2026-01-21T05:06:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出LRR-Bench空间理解基准测试，揭示视觉语言模型在空间感知任务上的显著不足。",
      "motivation": "研究动机源于真实世界应用如自动驾驶和机器人操控需要精确的空间感知，但现有视觉语言模型在空间关系识别和运动理解方面研究不足。该问题重要性在于空间理解是许多AI应用的基础，现有方法可能难以处理复杂空间任务，导致模型在现实场景中的可靠性受限。现有研究缺乏系统评估管道，未充分探索VLMs的空间能力，因此构建基准测试以填补这一空白，促进模型改进。",
      "method": "研究方法包括引入空间评估管道并构建对应基准测试LRR-Bench。核心创新在于将空间理解分类为绝对空间理解（如对象在图像中的左右位置）和3D空间理解（涉及移动和旋转），并通过合成数据集生成测试样本，以低成本防止数据污染。技术特色在于数据集完全合成，便于扩展和标准化评估，同时在多个SOTA视觉语言模型上进行实验，探索其空间能力，未指定具体模型架构，但注重分类任务设计。",
      "result": "主要实验结果显示，人类在所有任务上接近完美表现，而当前视觉语言模型仅在两个最简单任务上达到人类水平。在其余任务中，VLMs性能显著低于人类，具体表现为复杂空间任务得分较低，某些任务甚至接近零分，表明模型在空间理解方面存在明显缺陷。与人类基线的对比突出了VLMs的巨大改进空间，尽管未提供具体准确率数字，但通过定性描述和性能分级，强调了模型与人类表现的差距，呼吁进一步优化。",
      "conclusion": "论文主要贡献是提出了LRR-Bench基准测试，系统评估视觉语言模型的空间理解能力，并揭示其不足。学术价值在于为空间感知研究提供标准化工具，促进模型开发和评估；实际应用价值在于为自动驾驶、机器人等领域提供改进方向。局限性包括摘要未明确说明具体模型细节，未来工作可包括扩展数据集、改进模型架构或融合更多空间任务，开源数据集和代码有助于社区进一步探索和优化。",
      "tags": [
        "Vision-Language Models",
        "Spatial Understanding",
        "Benchmark Evaluation",
        "Synthetic Dataset",
        "Spatial Perception"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:05.826234Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.11932",
    "title": "Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs",
    "authors": [
      "Mohammad Shahab Sepehri",
      "Berk Tinaz",
      "Zalan Fabian",
      "Mahdi Soltanolkotabi"
    ],
    "abstract": "Mental visualization, the ability to construct and manipulate visual representations internally, is a core component of human cognition and plays a vital role in tasks involving reasoning, prediction, and abstraction. Despite the rapid progress of Multimodal Large Language Models (MLLMs), current benchmarks primarily assess passive visual perception, offering limited insight into the more active capability of internally constructing visual patterns to support problem solving. Yet mental visualization is a critical cognitive skill in humans, supporting abilities such as spatial navigation, predicting physical trajectories, and solving complex visual problems through imaginative simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic benchmark designed to evaluate the mental visualization abilities of MLLMs through four carefully constructed puzzles. Each puzzle is procedurally generated and presented at three difficulty levels, enabling controlled analysis of model performance across increasing complexity. Our comprehensive evaluation of state-of-the-art models reveals a substantial gap between the performance of humans and MLLMs. Additionally, we explore the potential of reinforcement learning to improve visual simulation capabilities. Our findings suggest that while some models exhibit partial competence in recognizing visual patterns, robust mental visualization remains an open challenge for current MLLMs.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.11932.pdf",
    "abs_url": "https://arxiv.org/abs/2507.11932",
    "published": "2025-07-16T05:54:37Z",
    "updated": "2026-01-21T17:27:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出Hyperphantasia基准，用于评估多模态大语言模型的mental visualization能力，填补现有评估方法的空白。",
      "motivation": "论文旨在解决多模态大语言模型在mental visualization能力评估上的不足。现有基准主要关注被动视觉感知，如图像识别，缺乏对主动构建内部视觉模式以支持推理、预测和抽象任务的评估。然而，mental visualization是人类认知的核心，支撑空间导航、物理轨迹预测和通过想象模拟解决复杂问题。因此，迫切需要开发新方法来评估这一关键能力，以促进更智能AI系统的发展。",
      "method": "研究方法包括设计合成基准Hyperphantasia，该基准包含四个程序生成的谜题，每个谜题设有三个难度级别，以系统分析多模态大语言模型在不同复杂度下的表现。评估针对最新模型进行，并探索了强化学习技术来增强视觉模拟能力。摘要未明确说明具体数据集和模型架构细节，仅概述了基准的构建和评估流程。",
      "result": "实验结果显示，多模态大语言模型在mental visualization任务上与人类表现存在显著差距。尽管部分模型能初步识别视觉模式，但robust的主动视觉构建能力仍是开放挑战。评估未提供具体性能指标如准确率，但通过对比人类基线，突显了模型在处理程序生成的谜题时的局限性，表明现有方法需进一步改进。",
      "conclusion": "论文的主要贡献是提出了Hyperphantasia基准，填补了多模态大语言模型在mental visualization评估领域的空白。研究发现模型能力不足，强调了该能力在AI发展中的重要性，并探索了强化学习作为改进方向，具有学术和应用价值。未来工作可扩展基准、优化方法并进一步研究视觉模拟能力的提升，潜在局限性包括基准的合成性质和模型当前的局限性。",
      "tags": [
        "Multimodal Large Language Models",
        "Mental Visualization",
        "Benchmark Evaluation",
        "Reinforcement Learning",
        "Synthetic Puzzles"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:51.001150Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.09709",
    "title": "Large Language Models Encode Semantics and Alignment in Linearly Separable Representations",
    "authors": [
      "Baturay Saglam",
      "Paul Kassianik",
      "Blaine Nelson",
      "Sajana Weerawardhena",
      "Yaron Singer",
      "Amin Karbasi"
    ],
    "abstract": "Understanding the latent space geometry of large language models (LLMs) is key to interpreting their behavior and improving alignment. Yet it remains unclear to what extent LLMs linearly organize representations related to semantic understanding. To explore this, we conduct a large-scale empirical study of hidden representations in 11 autoregressive models across six scientific topics. We find that high-level semantic information consistently resides in low-dimensional subspaces that form linearly separable representations across domains. This separability becomes more pronounced in deeper layers and under prompts that elicit structured reasoning or alignment behavior$\\unicode{x2013}$even when surface content remains unchanged. These findings motivate geometry-aware tools that operate directly in latent space to detect and mitigate harmful and adversarial content. As a proof of concept, we train an MLP probe on final-layer hidden states as a lightweight latent-space guardrail. This approach substantially improves refusal rates on malicious queries and prompt injections that bypass both the model's built-in safety alignment and external token-level filters.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2507.09709.pdf",
    "abs_url": "https://arxiv.org/abs/2507.09709",
    "published": "2025-07-13T17:03:25Z",
    "updated": "2026-01-21T09:54:43Z",
    "comment": "IJCNLP and the Asian Chapter of ACL",
    "light_analysis": {
      "overview": "本研究发现大语言模型的潜在空间中语义和对齐信息呈线性可分，并基于此开发几何感知工具以提高安全性。",
      "motivation": "理解大型语言模型潜在空间的几何特性对解释模型行为和改善对齐效果至关重要，但当前研究对LLM表示是否线性组织语义信息认识不足。现有方法往往依赖表层内容分析，未能充分利用几何结构来检测有害或对抗性内容，因此探究线性可分性具有重要的理论和应用价值，有助于解决模型对齐不足的问题。",
      "method": "论文采用大规模实证研究方法，分析11个自回归模型在六个科学主题下的隐藏表示几何结构。核心创新在于探究线性可分性随模型深度和不同提示的演变，并使用MLP探针在最终层隐藏状态上训练作为轻量级潜在空间护栏。具体数据集和模型架构细节摘要未明确说明。",
      "result": "实验结果表明，高级语义信息在LLM潜在空间中呈现线性可分，这种可分性在更深层和结构化推理提示下更加明显。概念验证中，MLP探针护栏显著提高了对恶意查询和提示注入的拒绝率，性能优于模型内置安全对齐和外部词级过滤器，具体数据摘要未明确说明。",
      "conclusion": "论文揭示了LLM潜在空间的线性可分几何特性，为开发几何感知工具提供了理论基础。该研究不仅增强了LLM可解释性，还通过概念验证展示了潜在空间防护的实际应用潜力，未来工作可探索几何特性的泛化能力和更广泛的安全应用场景。",
      "tags": [
        "Large Language Models",
        "Linear Separability",
        "Latent Space Geometry",
        "MLP Probe",
        "Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:28.398062Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.05999",
    "title": "Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS",
    "authors": [
      "Xinyu Wang",
      "Muhammad Ibrahim",
      "Haitian Wang",
      "Atif Mansoor",
      "Xiuping Jia",
      "Ajmal Mian"
    ],
    "abstract": "Accurate geo-registration of LiDAR point clouds remains a significant challenge in urban environments where Global Navigation Satellite System (GNSS) signals are denied or degraded. Existing methods typically rely on real-time GNSS and Inertial Measurement Unit (IMU) data, which require pre-calibration and assume stable signals. However, this assumption often fails in dense cities, resulting in localization errors. To address this, we propose a structured post-hoc geo-registration method that accurately aligns LiDAR point clouds with satellite images. The proposed approach targets point cloud datasets where reliable GNSS information is unavailable or degraded, enabling city-scale geo-registration as a post-processing solution. Our method uses a pre-trained Point Transformer to segment road points, then extracts road skeletons and intersections from the point cloud and the satellite image. Global alignment is achieved through rigid transformation using corresponding intersection points, followed by local non-rigid refinement with radial basis function (RBF) interpolation. Elevation discrepancies are corrected using terrain data from the Shuttle Radar Topography Mission (SRTM). To evaluate geo-registration accuracy, we measure the absolute distances between the roads extracted from the two modalities. Our method is validated on the KITTI benchmark and a newly collected dataset of Perth, Western Australia. On KITTI, our method achieves a mean planimetric alignment error of 0.69m, corresponding to a 50% reduction in global geo-registration bias compared to the raw KITTI annotations. On Perth dataset, it achieves a mean planimetric error of 2.17m from GNSS values extracted from Google Maps, corresponding to 57.4% improvement over rigid alignment. Elevation correlation factor improved by 30.5% (KITTI) and 55.8% (Perth).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.05999.pdf",
    "abs_url": "https://arxiv.org/abs/2507.05999",
    "published": "2025-07-08T14:00:18Z",
    "updated": "2026-01-21T04:57:12Z",
    "comment": "Submitted to IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. Under reviewing now",
    "light_analysis": {
      "overview": "论文提出一种无需GNSS的后处理地理配准方法，利用点Transformer和卫星图像实现LiDAR点云的高精度对齐。",
      "motivation": "在城市环境中，GNSS信号常被拒绝或降级，导致LiDAR点云的准确地理配准面临挑战。现有方法依赖实时GNSS和IMU数据，需要预校准且假设稳定信号，但这在密集城市区域常失败，引发定位误差。为解决此问题，本研究针对GNSS不可用或降级的点云数据集，提出一种后处理解决方案，以支持城市尺度的地理配准应用，如自动驾驶和城市规划中需要精确地理定位的场景。",
      "method": "方法采用结构化后处理地理配准：首先，使用预训练的点Transformer分割LiDAR点云中的道路点；其次，从点云和卫星图像中提取道路骨架和交叉口特征；接着，通过对应交叉点进行刚性变换实现全局对齐；然后，利用径向基函数（RBF）插值进行局部非刚性细化；最后，结合SRTM地形数据校正高程差异。关键创新在于结合点Transformer进行特征提取和全局-局部配准策略，无需依赖GNSS输入。",
      "result": "在KITTI基准和Perth数据集上验证，结果显示：在KITTI上，平均平面对齐误差为0.69米，相比原始注释降低50%的全局配准偏差；在Perth数据集上，平均平面误差为2.17米，较刚性对齐提升57.4%。此外，高程相关性因子改善30.5%（KITTI）和55.8%（Perth），表明方法在精度和一致性上显著优于基线方法。",
      "conclusion": "本研究提出了一种有效的后处理地理配准方法，解决了GNSS受限环境下的LiDAR点云配准问题，主要贡献在于结合点Transformer和卫星图像实现高精度对齐。学术价值体现在点云处理领域的创新方法探索，应用价值为城市规模点云数据的地理校正提供可靠方案。局限性可能包括对道路提取的依赖性，未来工作可扩展至更多特征类型或增强方法的鲁棒性和泛化能力。",
      "tags": [
        "Point Transformer",
        "Radial Basis Function (RBF)",
        "Geo-Registration",
        "LiDAR Point Cloud",
        "Satellite Image"
      ]
    },
    "analyzed_at": "2026-01-22T03:32:52.246537Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.05386",
    "title": "Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training",
    "authors": [
      "Song Lai",
      "Haohan Zhao",
      "Rong Feng",
      "Changyi Ma",
      "Wenzhuo Liu",
      "Hongbo Zhao",
      "Xi Lin",
      "Dong Yi",
      "Qingfu Zhang",
      "Hongbin Liu",
      "Gaofeng Meng",
      "Fei Zhu"
    ],
    "abstract": "Continual post-training (CPT) is a popular and effective technique for adapting foundation models like multimodal large language models to specific and ever-evolving downstream tasks. While existing research has primarily concentrated on methods like data replay, model expansion, or parameter regularization, the fundamental role of the learning paradigm within CPT remains largely unexplored. This paper presents a comparative analysis of two core post-training paradigms: supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT), investigating their respective impacts on knowledge retention during CPT. Our experiments are conducted on a benchmark comprising seven diverse multimodal tasks, utilizing Qwen2.5-VL-7B-Instruct as the base model for continual post-training. The investigation yields two significant findings: (1) When continuously learning on downstream tasks, SFT leads to catastrophic forgetting of previously learned tasks. In contrast, RFT inherently preserves prior knowledge and achieve performance comparable to multi-task training. (2) RFT successfully protects and even enhances the model's general knowledge on standard benchmarks (e.g., MMMU and MMLU-Pro). Conversely, SFT degrades general model capabilities severely. Further analysis reveals that this stability is not primarily due to explicit mechanisms like KL penalty or chain-of-thought reasoning. Instead, we identify an implicit regularization mechanism inherent to RFT as a key contributing factor. Our theoretical analysis suggests that RFT's gradient updates are naturally scaled by the reward variance, acting as a data-dependent regularizer that inherently protects previously acquired knowledge. Finally, we propose a rollout-based instance filtering algorithm to enhance the stability and efficiency of RFT. Our comprehensive study demonstrates the superiority of RFT as a robust paradigm for continual post-training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.05386.pdf",
    "abs_url": "https://arxiv.org/abs/2507.05386",
    "published": "2025-07-07T18:17:06Z",
    "updated": "2026-01-21T13:37:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文通过对比监督微调和强化微调，发现强化微调能自然缓解持续后训练中的遗忘，提供稳健的后训练范式。",
      "motivation": "持续后训练是调整基础模型以适应动态下游任务的关键技术，但现有研究多集中于数据重放、模型扩展或参数正则化，忽视了学习范式本身在知识保留中的作用。本文旨在探索监督微调和强化微调在持续后训练中对遗忘问题的影响，以弥补研究空白，提升模型在持续学习环境下的稳定性和性能。",
      "method": "研究采用比较分析方法，基于Qwen2.5-VL-7B-Instruct模型在包含七个多模态任务的基准上进行持续后训练实验。关键创新在于识别了强化微调的隐式正则化机制，理论分析表明其梯度更新由奖励方差自然缩放。此外，提出一个基于rollout的实例过滤算法，以增强强化微调的稳定性和效率，而不依赖显式正则化或链式推理。",
      "result": "实验结果显示，强化微调在持续学习下游任务时能有效保留先验知识，性能与多任务训练相当，而监督微调导致灾难性遗忘。在标准基准（如MMMU和MMLU-Pro）上，强化微调保护并增强了模型的一般知识能力，监督微调则严重削弱。分析表明，强化微调的稳定性源于隐式正则化，梯度受奖励方差调节，无需额外惩罚机制。",
      "conclusion": "本研究的主要贡献在于证明强化微调作为持续后训练范式的优越性，通过自然缓解遗忘问题提供稳健解决方案。其学术价值在于深化了对学习范式在知识保留中作用的理解，具有实际应用价值，如适应动态任务。未来工作可探索强化微调在不同模型和场景下的泛化性，或进一步优化提出的实例过滤算法。",
      "tags": [
        "Reinforcement Fine-Tuning",
        "Continual Learning",
        "Multimodal Large Language Models",
        "Gradient Regularization",
        "Instance Filtering"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:17.850641Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.04037",
    "title": "Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments",
    "authors": [
      "Zheng Jia",
      "Shengbin Yue",
      "Wei Chen",
      "Siyuan Wang",
      "Yidong Liu",
      "Yun Song",
      "Zhongyu Wei"
    ],
    "abstract": "The gap between static benchmarks and the dynamic nature of real-world legal practice poses a key barrier to advancing legal intelligence. To this end, we introduce J1-ENVS, the first interactive and dynamic legal environment tailored for LLM-based agents. Guided by legal experts, it comprises six representative scenarios from Chinese legal practices across three levels of environmental complexity. We further introduce J1-EVAL, a fine-grained evaluation framework, designed to assess both task performance and procedural compliance across varying levels of legal proficiency. Extensive experiments on 17 LLM agents reveal that, while many models demonstrate solid legal knowledge, they struggle with procedural execution in dynamic settings. Even the SOTA model, GPT-4o, falls short of 60% overall performance. These findings highlight persistent challenges in achieving dynamic legal intelligence and offer valuable insights to guide future research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2507.04037.pdf",
    "abs_url": "https://arxiv.org/abs/2507.04037",
    "published": "2025-07-05T13:31:21Z",
    "updated": "2026-01-21T07:41:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了首个为LLM代理设计的交互式动态法律环境J1-ENVS和细粒度评估框架J1-EVAL，以解决静态基准与法律实践动态性的差距。",
      "motivation": "该研究旨在解决静态基准与现实法律实践动态性之间的关键障碍。法律实践涉及复杂的互动和程序变化，现有基准往往无法充分模拟真实世界场景，导致评估不全面，限制了法律智能代理的实际应用。因此，开发动态评估环境对于推动法律智能领域的研究至关重要，因为它能更准确地反映代理在复杂环境中的表现。",
      "method": "论文提出J1-ENVS，这是一个由法律专家指导构建的交互式动态法律环境，包含来自中国法律实践的六个代表性场景，并设置三个环境复杂性级别以模拟真实挑战。同时，引入J1-EVAL评估框架，设计用于细粒度评估任务完成度和程序合规性，涵盖不同法律熟练度水平。研究测试了17个基于大型语言模型的代理，以验证环境与框架的有效性。",
      "result": "在17个LLM代理的广泛实验中，结果显示许多模型在静态法律知识方面表现良好，但在动态设置的程序执行中普遍存在困难。具体来说，最先进模型GPT-4o的整体性能低于60%，突显出当前方法在适应法律实践动态特性方面的局限。这些发现表明，现有代理在动态智能方面仍有显著提升空间。",
      "conclusion": "本文的主要贡献在于提供了首个动态法律环境和评估框架，为法律智能领域确立了新基准。研究揭示了LLM代理在动态执行中的短板，强调了克服动态性挑战的重要性，具有推动未来研究解决真实世界法律应用的学术价值。未来工作可侧重于改进代理的动态响应能力和拓展评估场景。",
      "tags": [
        "Large Language Models",
        "Legal Intelligence",
        "Dynamic Environments",
        "Benchmarking",
        "Interactive Agents"
      ]
    },
    "analyzed_at": "2026-01-22T03:33:42.553137Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.21220",
    "title": "Complexity-aware fine-tuning",
    "authors": [
      "Andrey Goncharov",
      "Daniil Vyazhev",
      "Petr Sychev",
      "Edvard Khalafyan",
      "Alexey Zaytsev"
    ],
    "abstract": "General-purpose Large Language Models (LLMs) are frequently fine-tuned through supervised fine-tuning (SFT) to enhance performance in specific domains. Better results can be achieved by distilling the chain-of-thought of a larger model at the cost of numerous expensive calls and a much greater amount of data. We propose a novel blueprint for efficient fine-tuning that uses reasoning only for complex data identified by entropy. Specifically, across three small open models ($\\approx 3B$) we split the training data into complexity categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large language models (LLMs) via SFT and distillation, and show that our pipeline significantly outperforms the standard SFT approach ($0.58$ vs $0.45$ average accuracy) and outperforms the distillation approach ($0.58$ vs $0.56$ average accuracy) while using $81\\%$ less data.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.21220.pdf",
    "abs_url": "https://arxiv.org/abs/2506.21220",
    "published": "2025-06-26T13:13:24Z",
    "updated": "2026-01-21T15:52:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一种复杂度感知的微调方法，通过熵筛选复杂数据，提升大型语言模型的微调效果和效率。",
      "motivation": "该研究旨在解决通用大型语言模型在特定领域微调时的效率问题。现有监督微调方法性能有限，而通过蒸馏更大模型的链式思考虽能提升效果，但需要大量数据和昂贵计算调用，成本高昂。因此，论文探讨如何设计一个更高效的微调策略，以平衡性能提升与资源消耗，解决现有方法在数据利用和计算效率上的不足。",
      "method": "论文提出了一种新颖的微调管道，基于数据复杂度进行优化。核心方法是使用单个令牌答案的熵（ROC AUC 0.73）来评估训练数据的复杂度，并将其分为不同类别。然后，在三个约3B参数的小型开放模型上，结合监督微调和蒸馏技术进行微调，仅对识别的复杂数据应用推理，减少不必要的处理。关键创新在于通过熵驱动复杂度分类，优化微调过程，提高数据利用效率。",
      "result": "实验结果显示，提出的方法在平均准确率上达到0.58，显著优于标准监督微调方法的0.45和蒸馏方法的0.56。同时，该方法仅需19%的数据（比标准减少81%），大大降低了数据需求。这些结果证明了复杂度感知微调在提升性能的同时，有效提高了效率和资源利用率，与基线方法相比具有明显优势。",
      "conclusion": "论文的主要贡献是开发了一种高效的复杂度感知微调方法，通过熵评估数据复杂度并优化微调策略。这不仅提升了大型语言模型在特定任务的性能，还显著减少了数据和计算成本，具有重要的学术价值和实际应用潜力。未来工作可探索更精确的复杂度度量或扩展到更大模型，以进一步优化微调过程。摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Models",
        "Supervised Fine-Tuning",
        "Distillation",
        "Entropy",
        "Complexity-aware Fine-tuning"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:04.141827Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.19780",
    "title": "Listwise Direct Preference Optimization with Multi-Dimensional Preference Mixing",
    "authors": [
      "Yuhui Sun",
      "Xiyao Wang",
      "Zixi Li",
      "YiTian Ding",
      "Tianyang Ling",
      "Jialuo Chen",
      "Tianyi Yu",
      "Zhenlong Yuan",
      "Jinman Zhao"
    ],
    "abstract": "Recent alignment methods based on Direct Preference Optimization (DPO) reformulate preference learning as supervised optimization over pairwise comparisons, offering improved efficiency and stability over reinforcement learning from human feedback (RLHF). However, existing DPO-style methods implicitly assume a single fixed preference objective, which limits their ability to model the structured and sometimes conflicting nature of real-world human judgments that span multiple preference dimensions. In this work, we propose Listwise Direct Preference Optimization ($λ$-DPO), a unified framework that simultaneously improves supervision granularity and preference flexibility. Instead of collapsing multi-dimensional preference signals into a single ranking, $λ$-DPO constructs a mixture of listwise preference distributions weighted by a preference vector $λ$ on the probability simplex, enabling a single model to internalize a continuous spectrum of preference trade-offs. To further improve robustness, we introduce a performance-driven stochastic $λ$ scheduler that adaptively samples preference weights based on empirical downstream performance, explicitly mitigating the risks of misspecification inherent to static weighting schemes. We evaluate our method across multiple model families and scales on six widely used benchmarks. Experimental results show the consistent improvement against baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.19780.pdf",
    "abs_url": "https://arxiv.org/abs/2506.19780",
    "published": "2025-06-24T16:47:17Z",
    "updated": "2026-01-21T10:13:03Z",
    "comment": "13 pages, 1 figures, appendix included",
    "light_analysis": {
      "overview": "提出 $λ$-DPO 框架，通过混合列表偏好分布和自适应权重调度，处理多维度人类偏好，扩展了直接偏好优化方法。",
      "motivation": "现有基于直接偏好优化（DPO）的对齐方法虽提高了效率和稳定性，但假设单一固定偏好目标，无法建模现实世界中结构化、多维度且有时冲突的人类偏好。人类判断常涉及多个维度（如安全性与帮助性），现有方法在捕捉这些复杂性方面受限，限制了其在真实场景中的应用，因此需要更灵活和鲁棒的偏好学习框架来解决这一问题。",
      "method": "$λ$-DPO 是一个统一框架，将多维度偏好信号构造为基于偏好向量 $λ$ 权重的列表偏好分布混合物，权重位于概率单纯形上，使单个模型能内部化连续的偏好权衡。为提高鲁棒性，引入性能驱动的随机 $λ$ 调度器，根据经验下游性能自适应采样权重，明确减轻静态加权方案中固有的误判风险，关键创新在于改善监督粒度和偏好灵活性。",
      "result": "在六个广泛使用的基准上对多个模型家族和规模进行评估，实验结果显示 $λ$-DPO 相对于基线方法有持续改进，验证了其在处理多维度偏好时的有效性。摘要未明确说明具体性能指标，但强调了框架在不同设置下的稳健表现和优于现有方法的优势。",
      "conclusion": "该研究的主要贡献是提出了 $λ$-DPO 框架，能够建模多维度人类偏好，提高了对齐方法的灵活性和鲁棒性，具有重要学术价值，推动了偏好学习领域的发展，并为实际 AI 模型训练提供了新工具。未来工作可探索更复杂的偏好建模或扩展到更大规模模型，以应对更广泛的应用场景。",
      "tags": [
        "Direct Preference Optimization",
        "Listwise Learning",
        "Multi-Dimensional Preference",
        "Adaptive Weighting",
        "Preference Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:28.474576Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.14397",
    "title": "Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding",
    "authors": [
      "Yeonkyoung So",
      "Gyuseong Lee",
      "Sungmok Jung",
      "Joonhak Lee",
      "JiA Kang",
      "Sangho Kim",
      "Jaejin Lee"
    ],
    "abstract": "Negation is a fundamental linguistic phenomenon that poses ongoing challenges for Large Language Models (LLMs), particularly in tasks requiring deep semantic understanding. Current benchmarks often treat negation as a minor detail within broader tasks, such as natural language inference. Consequently, there is a lack of benchmarks specifically designed to evaluate comprehension of negation. In this work, we introduce Thunder-NUBench, a novel benchmark explicitly created to assess sentence-level understanding of negation in LLMs. Thunder-NUBench goes beyond merely identifying surface-level cues by contrasting standard negation with structurally diverse alternatives, such as local negation, contradiction, and paraphrase. This benchmark includes manually curated sentence-negation pairs and a multiple-choice dataset, allowing for a comprehensive evaluation of models' understanding of negation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.14397.pdf",
    "abs_url": "https://arxiv.org/abs/2506.14397",
    "published": "2025-06-17T10:51:39Z",
    "updated": "2026-01-21T05:02:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文介绍了Thunder-NUBench，一个专门用于评估大型语言模型句子级否定理解能力的新基准。",
      "motivation": "否定是语言中的基本现象，对大型语言模型的深层语义理解构成持续挑战，尤其在需要精确语义处理的任务中。现有基准通常将否定视为自然语言推理等任务中的次要细节，缺乏专门评估否定理解的工具，导致模型在这方面的能力未被充分测试，限制了其在真实世界应用中的表现。因此，开发一个专门基准至关重要，以解决这一评估空白并推动相关研究进步。",
      "method": "论文提出Thunder-NUBench基准，通过手动构建句子否定对和多项选择数据集，全面评估模型对否定的理解。核心创新在于超越表面线索识别，通过对比标准否定与局部否定、矛盾、释义等多样化结构，以更精细地测量模型的语义理解深度。该方法使用精心设计的测试案例，旨在揭示模型在处理复杂否定模式时的表现，强调结构多样性的重要性。",
      "result": "摘要未明确说明具体的实验结果，如准确率提升或与基线方法的对比。因此，基于现有信息，论文主要介绍了基准的创建和设计，未提供模型在该基准上的评估数据或性能指标。未来研究可能会使用此基准进行测试并报告相关结果，以验证其有效性和实用性。",
      "conclusion": "本研究的主要贡献是引入了Thunder-NUBench基准，为评估大型语言模型在句子级否定理解方面的能力提供了专门工具。这具有重要的学术价值，有助于揭示模型在语义处理中的局限性，并促进相关技术进步。在实际应用中，这可能提升语言处理系统的准确性和鲁棒性。局限性可能在于基准的覆盖范围，未来工作可扩展数据集或应用于更多模型的评估。",
      "tags": [
        "Large Language Models",
        "Negation Understanding",
        "Benchmarking",
        "Sentence-Level Analysis",
        "Multiple-Choice Dataset"
      ]
    },
    "analyzed_at": "2026-01-22T03:34:49.051844Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.14170",
    "title": "A Multi-Stage Augmented Multimodal Interaction Network for Quantifying Fish Feeding Intensity Using Feeding Image, Audio and Water Wave",
    "authors": [
      "Shulong Zhang",
      "Mingyuan Yao",
      "Jiayin Zhao",
      "Daoliang Li",
      "Yingyi Chen",
      "Haihua Wang"
    ],
    "abstract": "In recirculating aquaculture systems, accurate and effective assessment of fish feeding intensity is crucial for reducing feed costs and calculating optimal feeding times. However, current studies have limitations in modality selection, feature extraction and fusion, and co-inference for decision making, which restrict further improvement in the accuracy, applicability and reliability of multimodal fusion models. To address this problem, this study proposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for quantifying fish feeding intensity. Firstly, a general feature extraction framework is proposed to efficiently extract feature information from input image, audio and water wave datas. Second, an Auxiliary-modality Reinforcement Primary-modality Mechanism (ARPM) is designed for inter-modal interaction and generate enhanced features, which consists of a Channel Attention Fusion Network (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an Evidence Reasoning (ER) rule is introduced to fuse the output results of each modality and make decisions, thereby completing the quantification of fish feeding intensity. The experimental results show that the constructed MAINet reaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and F1-Score respectively, and its performance is significantly higher than the comparison models. Compared with models that adopt single-modality, dual-modality fusion and different decision-making fusion methods, it also has obvious advantages. Meanwhile, the ablation experiments further verified the key role of the proposed improvement strategy in improving the robustness and feature utilization efficiency of model, which can effectively improve the accuracy of the quantitative results of fish feeding intensity. The dataset is available at: https://huggingface.co/datasets/ShulongZhang/Multimodal_Fish_Feeding_Intensity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2506.14170.pdf",
    "abs_url": "https://arxiv.org/abs/2506.14170",
    "published": "2025-06-17T04:09:43Z",
    "updated": "2026-01-21T09:51:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出多阶段增强多模态交互网络（MAINet），通过融合图像、音频和水波数据量化鱼类喂食强度，实现高精度评估。",
      "motivation": "在循环水产养殖系统中，准确评估鱼类喂食强度对减少饲料成本和优化投喂时间至关重要。然而，现有研究在模态选择、特征提取与融合、决策推理等方面存在局限，导致多模态融合模型的准确性、适用性和可靠性受限，阻碍了实际应用效果的提升。本研究旨在解决这些问题，开发更有效的多模态融合方法，以改善喂食管理的效率。",
      "method": "本研究提出MAINet，首先设计通用特征提取框架，从图像、音频和水波数据中高效提取特征。其次，开发辅助模态强化主要模态机制（ARPM），通过通道注意力融合网络（CAFN）和双模态注意力融合网络（DAFN）实现模态间交互以生成增强特征。最后，引入证据推理（ER）规则融合各模态输出并决策。该方法创新地结合了注意力机制和多阶段融合策略，提高了特征利用效率。",
      "result": "实验结果显示，MAINet在准确率、精确率、召回率和F1分数上分别达到96.76%、96.78%、96.79%和96.79%，性能显著优于单模态、双模态融合及不同决策融合方法的对比模型。消融实验进一步验证了所提策略能有效提升模型鲁棒性和特征利用效率，从而增强鱼类喂食强度量化的准确性。摘要未明确说明具体对比模型细节。",
      "conclusion": "本研究成功开发了MAINet，为量化鱼类喂食强度提供了高效的多模态融合解决方案，提高了评估的准确性和可靠性。该模型具有在水产养殖中优化喂食管理的实际应用价值，学术上推动了多模态交互技术的发展。未来工作可探索更多模态的集成或扩展到其他养殖场景。",
      "tags": [
        "Multimodal Fusion",
        "Attention Mechanism",
        "Evidence Reasoning",
        "Fish Feeding Intensity",
        "Channel Attention Fusion Network"
      ]
    },
    "analyzed_at": "2026-01-22T03:35:17.358865Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.11106",
    "title": "PankRAG: Enhancing Graph Retrieval via Globally Aware Query Resolution and Dependency-Aware Reranking Mechanism",
    "authors": [
      "Ningyuan Li",
      "Junrui Liu",
      "Yi Shan",
      "Minghui Huang",
      "Ziren Gong",
      "Tong Li"
    ],
    "abstract": "Recent graph-based RAG approaches leverage knowledge graphs by extracting entities from a query to fetch their associated relationships and metadata. However, relying solely on entity extraction often results in the misinterpretation or omission of latent critical information and relationships. This can lead to the retrieval of irrelevant or contradictory content, as well as the exclusion of essential information, thereby increasing hallucination risks and undermining the quality of generated responses. In this paper, we propose PankRAG, a framework designed to capture and resolve the latent relationships within complex queries that prior methods overlook. It achieves this through a synergistic combination of a globally-aware hierarchical resolution pathway and a dependency-aware reranking mechanism. PankRAG first generates a globally aware resolution pathway that captures parallel and progress relationships, guiding LLMs to resolve queries through a hierarchical reasoning path. Additionally, its dependency-aware reranking mechanism utilizes resolved sub-question dependencies to augment and validate the retrieved content of the current unresolved sub-question. Experimental results demonstrate that PankRAG consistently outperforms existing state-of-the-art methods, underscoring its generalizability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.11106.pdf",
    "abs_url": "https://arxiv.org/abs/2506.11106",
    "published": "2025-06-07T07:17:14Z",
    "updated": "2026-01-21T07:59:43Z",
    "comment": "Accepted by ICASSP 2026",
    "light_analysis": {
      "overview": "PankRAG框架通过全局感知的分层解析路径和依赖感知的重排机制，增强基于知识图的检索效果，减少幻觉风险并提高响应质量。",
      "motivation": "当前基于知识图的检索增强生成（RAG）方法通常仅从查询中提取实体来检索相关关系和元数据，但这种方法容易导致潜在关键信息和关系的误解或遗漏。这会造成检索到不相关或矛盾的内容，同时遗漏必要信息，从而增加幻觉风险并降低生成响应的质量。在处理复杂查询时，现有方法的不足尤为突出，强调了开发更鲁棒检索技术的必要性。本研究旨在通过捕捉和解析这些潜在关系来改进检索过程。",
      "method": "PankRAG框架结合了两个核心组件：全局感知的分层解析路径和依赖感知的重排机制。首先，它生成一个全局感知的解析路径，捕获查询中的并行和进展关系，指导大型语言模型（LLMs）通过分层推理路径来解析复杂查询。其次，依赖感知的重排机制利用已解析子问题的依赖关系，来增强和验证当前未解析子问题的检索内容。关键创新点在于整合了全局上下文和依赖关系，以优化检索过程；摘要未明确说明使用的具体数据集和模型架构。",
      "result": "实验结果表明，PankRAG consistently outperforms existing state-of-the-art methods，展示了其在图检索任务中的优越性能。尽管摘要未提供具体的性能指标（如准确率提升或效率改进），但与基线方法相比，PankRAG在通用性和效果方面表现更佳，突显了该方法在减少检索错误和提升响应质量方面的潜力。这些结果支持了框架的有效性和鲁棒性，适用于各种复杂查询场景。",
      "conclusion": "本研究的主要贡献是提出了PankRAG框架，它通过全局感知解析和依赖感知重排，有效解决了现有图检索方法在复杂查询中的局限性。学术上，它推动了检索增强生成技术的发展；实际上，该框架有助于减少AI系统生成响应时的幻觉风险，并提高信息检索的准确性。局限性方面，摘要未明确说明，但未来工作可能包括扩展到更多数据集和进一步优化计算效率。",
      "tags": [
        "Graph Retrieval",
        "Large Language Model",
        "Query Resolution",
        "Dependency-Aware Reranking",
        "Hierarchical Reasoning"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:00.318466Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.04772",
    "title": "Identifying Reliable Evaluation Metrics for Scientific Text Revision",
    "authors": [
      "Léane Jourdan",
      "Florian Boudin",
      "Richard Dufour",
      "Nicolas Hernandez"
    ],
    "abstract": "Evaluating text revision in scientific writing remains a challenge, as traditional metrics such as ROUGE and BERTScore primarily focus on similarity rather than capturing meaningful improvements. In this work, we analyse and identify the limitations of these metrics and explore alternative evaluation methods that better align with human judgments. We first conduct a manual annotation study to assess the quality of different revisions. Then, we investigate reference-free evaluation metrics from related NLP domains. Additionally, we examine LLM-as-a-judge approaches, analysing their ability to assess revisions with and without a gold reference. Our results show that LLMs effectively assess instruction-following but struggle with correctness, while domain-specific metrics provide complementary insights. We find that a hybrid approach combining LLM-as-a-judge evaluation and task-specific metrics offers the most reliable assessment of revision quality.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.04772.pdf",
    "abs_url": "https://arxiv.org/abs/2506.04772",
    "published": "2025-06-05T09:00:23Z",
    "updated": "2026-01-21T14:12:26Z",
    "comment": "V3 contains the English version, accepted to ACL 2025 main (26 pages). V4 contains the French version (TALN 2025, 32 pages) with corrected results for cramer's v and pairwise accuracy",
    "light_analysis": {
      "overview": "论文提出了一种结合LLM-as-a-judge和任务特定指标的混合方法，以可靠评估科学文本修订的质量。",
      "motivation": "评估科学文本修订的质量一直是个挑战，因为传统指标如ROUGE和BERTScore主要基于相似性，无法有效捕捉修订中的实质性改进。这导致现有方法难以与人类判断对齐，限制了科学写作中修订系统的开发和优化。科学写作中的修订对提高文本质量至关重要，但传统评估指标过于依赖参考文本，忽略了修订的有效性，因此本研究旨在识别和解决这些局限性，探索更准确的评估方法。",
      "method": "论文首先进行手动标注研究，以评估不同修订的质量。接着，调查来自相关NLP领域的无参考评估指标，例如那些用于文本生成任务的指标。此外，探讨LLM-as-a-judge方法，分析其在有或没有黄金参考情况下评估修订的能力。核心创新在于整合这些方法，提出一个结合LLM-as-a-judge和任务特定指标的混合评估框架，以全面覆盖修订质量的不同方面。",
      "result": "实验结果显示，LLMs在评估修订是否遵循指令方面表现良好，但在判断正确性方面存在不足。同时，领域特定的评估指标能提供额外的洞察力。通过比较不同方法，研究发现结合LLM-as-a-judge评估和任务特定指标的混合方法提供了最可靠的修订质量评估，优于单一指标。例如，LLMs有效评估指令遵循，而传统指标如ROUGE在捕捉改进方面有限。",
      "conclusion": "本文的主要贡献是识别并提出了一个结合LLM-as-a-judge和任务特定指标的混合评估方法，以更准确地评估科学文本修订的质量。这项研究填补了传统评估指标的不足，提高了评估与人类判断的一致性，对于开发更有效的科学写作辅助工具有重要应用价值。未来工作可能包括进一步优化评估框架，扩展到其他文本修订领域，并解决LLMs在正确性评估上的局限性。",
      "tags": [
        "LLM-as-a-judge",
        "Evaluation Metrics",
        "Text Revision",
        "Scientific Writing",
        "Reference-free Evaluation"
      ]
    },
    "analyzed_at": "2026-01-22T03:36:36.490602Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.23062",
    "title": "Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data",
    "authors": [
      "Lingkai Kong",
      "Haichuan Wang",
      "Tonghan Wang",
      "Guojun Xiong",
      "Milind Tambe"
    ],
    "abstract": "Incorporating pre-collected offline data can substantially improve the sample efficiency of reinforcement learning (RL), but its benefits can break down when the transition dynamics in the offline dataset differ from those encountered online. Existing approaches typically mitigate this issue by penalizing or filtering offline transitions in regions with large dynamics gap. However, their dynamics-gap estimators often rely on KL divergence or mutual information, which can be ill-defined when offline and online dynamics have mismatched support. To address this challenge, we propose CompFlow, a principled framework built on the theoretical connection between flow matching and optimal transport. Specifically, we model the online dynamics as a conditional flow built upon the output distribution of a pretrained offline flow, rather than learning it directly from a Gaussian prior. This composite structure provides two advantages: (1) improved generalization when learning online dynamics under limited interaction data, and (2) a well-defined and stable estimate of the dynamics gap via the Wasserstein distance between offline and online transitions. Building on this dynamics-gap estimator, we further develop an optimistic active data collection strategy that prioritizes exploration in high-gap regions, and show theoretically that it reduces the performance gap to the optimal policy. Empirically, CompFlow consistently outperforms strong baselines across a range of RL benchmarks with shifted-dynamics data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.23062.pdf",
    "abs_url": "https://arxiv.org/abs/2505.23062",
    "published": "2025-05-29T04:09:19Z",
    "updated": "2026-01-21T16:37:21Z",
    "comment": "NeurIPS 2025 Spotlight",
    "light_analysis": {
      "overview": "提出 CompFlow 框架，通过流匹配与最优运输理论解决离线强化学习中动态不匹配问题。",
      "motivation": "在强化学习中，使用离线数据能提升样本效率，但当离线数据集的转移动态与在线环境不一致时，其优势可能消失。现有方法通常通过惩罚或过滤动态差异大的离线转移来缓解此问题，但依赖于 KL 散度或互信息等估计器，在动态支持不匹配时可能无法明确定义，限制了离线数据的有效利用。因此，需要一种更稳健的动态间隙估计方法，以适应动态变化的环境并提高强化学习的鲁棒性。",
      "method": "CompFlow 是一个基于流匹配与最优运输理论的原则性框架。其核心创新在于将在线动态建模为条件流，该流建立在预训练离线流的输出分布上，而非直接从高斯先验学习。这种复合结构提供了两个优势：一是使用有限交互数据学习在线动态时能提高泛化能力；二是通过 Wasserstein 距离提供稳定且明确定义的动态差距估计。基于此估计器，进一步开发了积极的主动数据收集策略，优先探索高差异区域，以减少与最优策略的性能差距。",
      "result": "在多个具有动态偏移数据的强化学习基准测试中，CompFlow 一致优于强基线方法。该框架在动态不匹配场景下展示了优越的性能和效率改进，相较于现有方法如依赖 KL 散度的估计器，能够更有效地利用离线数据。摘要未明确具体数据细节，但结果表明 CompFlow 在减少性能差距和提升学习效果方面具有显著优势，验证了其稳定动态间隙估计和主动探索策略的有效性。",
      "conclusion": "CompFlow 的主要贡献是提出了一个理论驱动的框架，通过 Wasserstein 距离估计动态间隙，并结合主动探索策略，有效处理了离线强化学习中的动态偏移问题。该研究提供了理论保证，减少了策略性能差距，并在实证中表现出色，具有较高的学术价值，例如提高强化学习在动态变化环境中的稳健性。实际应用潜力包括在数据收集成本高的任务中优化离线学习，未来工作可能扩展到更复杂的动态场景或集成更多数据类型。",
      "tags": [
        "Reinforcement Learning",
        "Flow Matching",
        "Optimal Transport",
        "Wasserstein Distance",
        "Offline Data"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:55.118340Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.22950",
    "title": "StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs",
    "authors": [
      "Haohan Yuan",
      "Sukhwa Hong",
      "Haopeng Zhang"
    ],
    "abstract": "Large language models (LLMs) have shown strong performance in zero-shot summarization, but often struggle to model document structure and identify salient information in long texts. In this work, we introduce StrucSum, a training-free prompting framework that enhances LLM reasoning through sentence-level graph structures. StrucSum injects structural signals into prompts via three targeted strategies: Neighbor-Aware Prompting (NAP) for local context, Centrality-Aware Prompting (CAP) for importance estimation, and Centrality-Guided Masking (CGM) for efficient input reduction. Experiments on ArXiv, PubMed, and Multi-News demonstrate that StrucSum consistently improves both summary quality and factual consistency over unsupervised baselines and vanilla prompting. In particular, on ArXiv, it increases FactCC and SummaC by 19.2\\% and 8.0\\% points, demonstrating stronger alignment between summaries and source content. The ablation study shows that the combination of multiple strategies does not yield clear performance gains; therefore, structure-aware prompting with graph-based information represents a promising and underexplored direction for the advancement of zero-shot extractive summarization with LLMs. Our source code is publicly available.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.22950.pdf",
    "abs_url": "https://arxiv.org/abs/2505.22950",
    "published": "2025-05-29T00:10:23Z",
    "updated": "2026-01-21T09:59:47Z",
    "comment": "14 pages. Accepted by the findings of EACL 2026",
    "light_analysis": {
      "overview": "StrucSum是一个无需训练的提示框架，通过句子级图结构增强大型语言模型的推理能力，以提升长文档提取式摘要的质量和事实一致性。",
      "motivation": "大型语言模型在零样本摘要任务中表现强劲，但难以建模长文档的结构和识别关键信息，导致摘要质量下降和事实一致性不足。现有无监督基线和标准提示方法在这些场景下效果有限，无法有效处理文档复杂性。因此，本研究旨在解决LLMs在长文本中的结构建模短板，通过注入结构信号来改进信息提取，以应对实际应用中对高效、准确摘要的需求。",
      "method": "StrucSum采用训练免费的提示框架，构建句子级图来捕捉文档结构，并通过三种策略注入结构信号：Neighbor-Aware Prompting (NAP) 增强局部上下文理解，Centrality-Aware Prompting (CAP) 基于中心性估计句子重要性，以及Centrality-Guided Masking (CGM) 减少输入冗余。这些策略基于图论原理，无需额外训练，直接将结构信息融入LLM提示中，创新点在于将图结构推理应用于提示工程，以提高信息提取效率。",
      "result": "在ArXiv、PubMed和Multi-News数据集上的实验显示，StrucSum显著提升摘要质量和事实一致性。例如，在ArXiv上，FactCC和SummaC指标分别提高19.2%和8.0个百分点，优于无监督基线和标准提示。消融研究证实，单个结构策略有效，但组合策略未带来明显增益，突显了图结构信息的关键作用，证明了该方法在零样本提取式摘要中的性能改进。",
      "conclusion": "StrucSum通过图结构推理有效增强了LLM零样本摘要的性能，证明了结构感知提示的学术价值，为长文档处理提供了新方向。该研究推动了无监督摘要技术的发展，具有实际应用潜力。局限性在于策略组合需进一步优化，未来工作可扩展图结构设计或应用于其他自然语言任务，以深化这一未充分探索的研究领域。",
      "tags": [
        "Large Language Model",
        "Extractive Summarization",
        "Graph-Structured Reasoning",
        "Prompting",
        "Zero-shot Summarization"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:18.623990Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.19068",
    "title": "Recalibrating binary probabilistic classifiers",
    "authors": [
      "Dirk Tasche"
    ],
    "abstract": "Recalibration of binary probabilistic classifiers to a target prior probability is an important task in areas like credit risk management. However, recalibration of a classifier learned on a training dataset to a target on a test dataset in general is not a well-defined problem because there might be more than one way to transform the original posterior probabilities such that the target is matched. In this paper, methods for recalibration are analysed from a distribution shift perspective. Distribution shift assumptions linked to the area under the curve (AUC) of a probabilistic classifier are found to be useful for the design of meaningful recalibration methods. Two new methods called parametric covariate shift with posterior drift (CSPD) and ROC-based quasi moment matching (QMM) are proposed and tested together with some other methods in an example setting. The outcomes of the test suggest that the QMM methods discussed in the paper can provide appropriately conservative results in evaluations with concave functions like for instance risk weights functions for credit risk.",
    "categories": [
      "cs.LG",
      "q-fin.RM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.19068.pdf",
    "abs_url": "https://arxiv.org/abs/2505.19068",
    "published": "2025-05-25T10:04:46Z",
    "updated": "2026-01-21T14:50:56Z",
    "comment": "17 pages, presented at workshop Learning to Quantify 2025 (LQ 2025), https://lq-2025.github.io/",
    "light_analysis": {
      "overview": "本文从分布偏移角度分析二分类概率分类器重新校准问题，提出了参数协变量偏移与后验漂移（CSPD）和基于ROC的准矩匹配（QMM）两种新方法。",
      "motivation": "在信用风险管理等领域，将二分类概率分类器重新校准到目标先验概率是一个关键任务。然而，将训练数据集上学习的分类器重新校准到测试数据集上的目标通常不是明确定义的问题，因为可能存在多种变换原始后验概率的方法，从而导致结果不唯一。这限制了现有方法在实践中的应用，尤其是在需要精确概率估计的场景下。因此，研究旨在从分布偏移的角度分析重新校准问题，以提供更可靠和有意义的方法设计基础。",
      "method": "本文从分布偏移的角度出发，分析了二分类概率分类器的重新校准问题。研究发现，与分类器AUC相关的分布偏移假设对设计有意义的重新校准方法具有重要作用。基于此，提出了两种新方法：参数协变量偏移与后验漂移（CSPD），该方法结合了参数估计和分布漂移；以及基于ROC的准矩匹配（QMM），通过匹配ROC曲线特性来调整概率。这些方法在示例设置中进行测试，使用概率分类器和相关数据集来验证其有效性。",
      "result": "在示例测试中，提出的QMM方法显示出良好的性能，特别是在使用凹函数（如信用风险权重函数）进行评估时，能够提供适当保守的重新校准结果。虽然摘要未提供具体数值指标，但与其他方法的比较表明，QMM方法在分布偏移假设下有效处理了重新校准问题，避免了不唯一变换的困境。",
      "conclusion": "本文的主要贡献在于从分布偏移角度重新审视二分类概率分类器的重新校准问题，并提出了CSPD和QMM两种有效方法。这为解决校准问题中的不唯一性提供了理论依据和实践工具，具有重要的学术价值。在实际应用中，如信用风险管理，这些方法能帮助生成更准确和保守的概率估计，从而提高决策可靠性。未来工作可进一步测试方法在不同场景下的鲁棒性和扩展到更复杂的分类任务。",
      "tags": [
        "Binary Probabilistic Classifiers",
        "Recalibration",
        "Distribution Shift",
        "ROC Analysis",
        "Covariate Shift"
      ]
    },
    "analyzed_at": "2026-01-22T03:37:58.946939Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.20310",
    "title": "Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System",
    "authors": [
      "Wanghan Xu",
      "Wenlong Zhang",
      "Fenghua Ling",
      "Ben Fei",
      "Yusong Hu",
      "Runmin Ma",
      "Bo Zhang",
      "Fangxuan Ren",
      "Jintai Lin",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "abstract": "Meta-analysis is a systematic research methodology that synthesizes data from multiple existing studies to derive comprehensive conclusions. This approach not only mitigates limitations inherent in individual studies but also facilitates novel discoveries through integrated data analysis. Traditional meta-analysis involves a complex multi-stage pipeline including literature retrieval, paper screening, and data extraction, which demands substantial human effort and time. However, while LLM-based methods can accelerate certain stages, they still face significant challenges, such as hallucinations in paper screening and data extraction. In this paper, we propose a multi-agent system, Manalyzer, which achieves end-to-end automated meta-analysis through tool calls. The hybrid review, hierarchical extraction, self-proving, and feedback checking strategies implemented in Manalyzer significantly alleviate these two hallucinations. To comprehensively evaluate the performance of meta-analysis, we construct a new benchmark comprising 729 papers across 3 domains, encompassing text, image, and table modalities, with over 10,000 data points. Extensive experiments demonstrate that Manalyzer achieves significant performance improvements over the LLM baseline in multi meta-analysis tasks. Project page: https://black-yt.github.io/meta-analysis-page/ .",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.20310.pdf",
    "abs_url": "https://arxiv.org/abs/2505.20310",
    "published": "2025-05-22T07:25:31Z",
    "updated": "2026-01-21T03:57:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "Manalyzer 是一个多代理系统，通过端到端自动化 meta-analysis 并采用特定策略缓解幻觉问题，显著提升性能。",
      "motivation": "传统 meta-analysis 涉及复杂多阶段流程，如文献检索、论文筛选和数据提取，需要大量人力和时间。基于 LLM 的方法虽然加速了部分阶段，但仍面临关键挑战，特别是在论文筛选和数据提取中出现的幻觉问题，这可能影响结果的准确性和可靠性。meta-analysis 能综合多个研究数据以得出全面结论，因此自动化改进至关重要，旨在提高科研效率并解决现有方法的不足。",
      "method": "论文提出 Manalyzer，一个多代理系统，通过工具调用实现端到端自动化 meta-analysis。核心创新包括采用混合评审、分层提取、自证和反馈检查等策略，专门设计以缓解幻觉问题。系统自动化处理整个流程，从文献检索到数据合成，无需人工干预，提升了处理效率，尽管摘要未明确说明具体数据集或模型架构，但构建了新基准用于评估。",
      "result": "Manalyzer 在构建的新基准上进行了实验，基准包含 729 篇论文、3 个领域以及文本、图像和表格等多种模态，数据点超过 10,000 个。与 LLM 基线相比，Manalyzer 在多 meta-analysis 任务中实现了显著性能提升，有效减少了幻觉并提高了任务准确性，但摘要未提供具体数值如准确率改进。",
      "conclusion": "论文的主要贡献是开发了 Manalyzer 系统，首次实现端到端自动化 meta-analysis 并通过创新策略解决幻觉问题。这项研究提升了 meta-analysis 的效率和可靠性，为自动化科研工具的发展提供了新思路，具有学术和应用价值。未来工作可能包括扩展到更多领域或优化策略，但摘要未明确说明局限性。",
      "tags": [
        "Multi-agent System",
        "End-to-end Automation",
        "Meta-analysis",
        "LLM",
        "Hallucination Mitigation"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:15.821302Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.07889",
    "title": "BioProBench: Comprehensive Dataset and Benchmark in Biological Protocol Understanding and Reasoning",
    "authors": [
      "Yuyang Liu",
      "Liuzhenghao Lv",
      "Xiancheng Zhang",
      "Jingya Wang Li Yuan",
      "Yonghong Tian"
    ],
    "abstract": "The realization of autonomous scientific experimentation is currently limited by LLMs' struggle to grasp the strict procedural logic and accuracy required by biological protocols. To address this fundamental challenge, we present \\textbf{BioProBench}, a comprehensive resource for procedural reasoning in biology. BioProBench is grounded in \\textbf{BioProCorpus}, a foundational collection of 27,000 human-written protocols. From this corpus, we systematically constructed a dataset of over 550,000 task instances, offering both a large-scale training resource and a rigorous benchmark with novel metrics. Evaluating 10 mainstream LLMs, we find that while general comprehension is high, performance drops significantly on tasks demanding deep reasoning, quantitative precision, and safety awareness. To demonstrate the value of BioProCorpus in mitigating these issues, we developed \\textbf{ProAgent}, grounded in our corpus, ProAgent substantially advances the state-of-the-art. BioProBench provides a rigorous diagnostic benchmark and a foundational resource for developing the next generation of reliable scientific AI. Code and data are available at: https://github.com/YuyangSunshine/bioprotocolbench and https://huggingface.co/datasets/BioProBench/BioProBench.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.07889.pdf",
    "abs_url": "https://arxiv.org/abs/2505.07889",
    "published": "2025-05-11T09:42:24Z",
    "updated": "2026-01-21T16:21:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了BioProBench，一个基于大规模人类编写协议语料库的综合性数据集和基准，旨在提升大型语言模型在生物协议理解和推理中的性能。",
      "motivation": "该研究旨在解决大型语言模型在理解生物协议的严格程序逻辑和准确性方面的挑战，这一问题限制了自主科学实验的实现。现有方法在需要深度推理、定量精度和安全意识的任务上表现不足，导致科学实验的可靠性和自动化程度受限，因此开发更精准的推理资源变得至关重要。",
      "method": "研究基于BioProCorpus构建了BioProBench，该语料库包含27,000个人类编写的生物协议，并系统生成了超过550,000个任务实例。核心方法包括使用新指标创建严格基准，并开发基于语料库的ProAgent模型，以探索如何改进模型在程序性推理任务中的表现，数据集设计旨在提供大规模训练和评估资源。",
      "result": "评估了10个主流大型语言模型，结果表明模型在一般理解任务上表现良好，但在深度推理、定量精度和安全意识相关的任务中性能显著下降。ProAgent基于语料库开发，显著推进了现有技术水平，摘要未明确说明具体性能提升数据，但强调了其在基准测试中的改进效果。",
      "conclusion": "BioProBench提供了一个严格的诊断基准和基础资源，有助于开发下一代可靠的科学人工智能系统。研究的学术价值在于填补了生物协议推理领域的资源空白，实际应用可促进自主科学实验的发展；未来工作可能包括进一步优化模型性能，摘要未明确说明局限性。",
      "tags": [
        "Large Language Model",
        "Biological Protocol",
        "Procedural Reasoning",
        "Dataset Benchmark",
        "Scientific AI"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:10.574097Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.08793",
    "title": "Onboard Optimization and Learning: A Survey",
    "authors": [
      "Monirul Islam Pavel",
      "Siyi Hu",
      "Mahardhika Pratama",
      "Ryszard Kowalczyk"
    ],
    "abstract": "Onboard learning is a transformative approach in edge AI, enabling real-time data processing, decision-making, and adaptive model training directly on resource-constrained devices without relying on centralized servers. This paradigm is crucial for applications demanding low latency, enhanced privacy, and energy efficiency. However, onboard learning faces challenges such as limited computational resources, high inference costs, and security vulnerabilities. This survey explores a comprehensive range of methodologies that address these challenges, focusing on techniques that optimize model efficiency, accelerate inference, and support collaborative learning across distributed devices. Approaches for reducing model complexity, improving inference speed, and ensuring privacy-preserving computation are examined alongside emerging strategies that enhance scalability and adaptability in dynamic environments. By bridging advancements in hardware-software co-design, model compression, and decentralized learning, this survey provides insights into the current state of onboard learning to enable robust, efficient, and secure AI deployment at the edge.",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.08793.pdf",
    "abs_url": "https://arxiv.org/abs/2505.08793",
    "published": "2025-05-07T07:47:14Z",
    "updated": "2026-01-21T04:40:46Z",
    "comment": "33 pages, 6 figures, 4 tables",
    "light_analysis": {
      "overview": "这篇论文提供了一个关于板载优化与学习的全面调查，探索了在边缘AI中解决资源约束和安全性挑战的方法论。",
      "motivation": "板载学习作为一种变革性方法，在边缘AI中使得实时数据处理、决策制定和自适应模型训练直接在资源受限设备上成为可能，无需依赖中心服务器。这一范式对于低延迟、增强隐私和能效的应用至关重要，例如物联网和自动驾驶。然而，现有方法面临计算资源有限、推理成本高和安全漏洞等挑战，这些问题限制了板载学习的广泛部署，因此需要新的优化策略来提升效率和安全性。",
      "method": "作为一篇综述论文，本文系统性地调查了多种方法来应对板载学习中的挑战。重点关注优化模型效率的技术，如模型压缩以减少复杂性；加速推理过程的方法，包括算法优化和硬件加速；以及支持分布式设备上协作学习的策略，如联邦学习。此外，还探讨了隐私保护计算、新兴策略如硬件-软件协同设计和自适应学习，以增强在动态环境中的可扩展性和适应性，涵盖了从理论到实践的全面方法论。",
      "result": "摘要未明确说明具体实验结果，因为这是一篇综述论文。它通过总结现有文献，提供了对板载学习方法效果的综合分析，指出这些技术在提升效率、安全性和可扩展性方面的潜在优势。综述可能涵盖了性能指标如推理速度提升或能耗降低，但与基线方法的对比依赖于所综述的研究，具体数据未在摘要中详述。",
      "conclusion": "本调查通过桥接硬件-软件协同设计、模型压缩和去中心化学习等领域的进展，全面概述了当前板载学习的现状。它为实现在边缘部署稳健、高效和安全的AI系统提供了重要见解，对推动边缘AI的实际应用具有显著学术和实用价值。同时，综述可能指出了未来研究方向，如进一步优化资源利用、增强安全机制和适应更复杂场景，以促进技术的持续发展。",
      "tags": [
        "Edge AI",
        "Model Compression",
        "Collaborative Learning",
        "Privacy-Preserving Computation",
        "Hardware-Software Co-design"
      ]
    },
    "analyzed_at": "2026-01-22T03:38:50.577024Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.16918",
    "title": "OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents",
    "authors": [
      "Raghav Thind",
      "Youran Sun",
      "Ling Liang",
      "Haizhao Yang"
    ],
    "abstract": "Optimization plays a vital role in scientific research and practical applications. However, formulating a concrete optimization problem described in natural language into a mathematical form and selecting a suitable solver to solve the problem requires substantial domain expertise. We introduce OptimAI, a framework for solving Optimization problems described in natural language by leveraging LLM-powered AI agents, and achieve superior performance over current state-of-the-art methods. Our framework is built upon the following key roles: (1) a formulator that translates natural language problem descriptions into precise mathematical formulations; (2) a planner that constructs a high-level solution strategy prior to execution; and (3) a coder and a code critic capable of interacting with the environment and reflecting on outcomes to refine future actions. Ablation studies confirm that all roles are essential; removing the planner or code critic results in $5.8\\times$ and $3.1\\times$ drops in productivity, respectively. Furthermore, we introduce UCB-based debug scheduling to dynamically switch between alternative plans, yielding an additional $3.3\\times$ productivity gain. Our design emphasizes multi-agent collaboration, and our experiments confirm that combining diverse models leads to performance gains. Our approach attains 88.1% accuracy on the NLP4LP dataset and 82.3% on the Optibench dataset, reducing error rates by 58% and 52%, respectively, over prior best results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2504.16918.pdf",
    "abs_url": "https://arxiv.org/abs/2504.16918",
    "published": "2025-04-23T17:45:05Z",
    "updated": "2026-01-21T02:59:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出OptimAI框架，利用LLM驱动的AI代理将自然语言描述的优化问题自动转化为数学公式并求解，性能超越现有方法。",
      "motivation": "优化问题在科学研究和实际应用中至关重要，但将自然语言描述的具体问题形式化为数学模型并选择合适求解器需要深厚的领域专业知识。现有方法多依赖人工操作或简单自动化工具，效率低下且容易出错，限制了优化技术的广泛应用。本研究旨在开发一个自动化框架，以降低对专家知识的依赖，提高优化问题求解的可访问性和效率，解决自然语言到数学转换的瓶颈问题。",
      "method": "OptimAI框架基于LLM驱动的AI代理，包括四个关键角色：formulator负责将自然语言问题翻译为精确数学公式；planner构建高级解决方案策略；coder和code critic则与环境交互，并通过反思结果来优化后续行动。创新点在于多代理协作设计和引入UCB-based debug scheduling，该调度机制动态切换替代计划，增强鲁棒性。框架利用多样化模型组合，在NLP4LP和Optibench数据集上进行验证，强调自动化与智能决策的结合。",
      "result": "消融研究显示所有角色都至关重要：移除planner导致生产力下降5.8倍，移除code critic下降3.1倍，验证了多代理协作的有效性。UCB-based debug scheduling带来额外3.3倍生产力提升，进一步优化了性能。在两个数据集上，NLP4LP准确率达到88.1%，Optibench准确率达到82.3%，错误率相比之前最佳结果分别降低58%和52%，显著优于基线方法，证实了框架在精度和效率上的优势。",
      "conclusion": "本研究的主要贡献是提出了OptimAI框架，通过多代理协作有效自动化自然语言优化问题的求解过程，提高了准确性和效率。其学术价值在于推动了AI与优化领域的交叉应用，展示了LLM在复杂任务中的潜力；实际应用价值在于减少对领域专家的依赖，提升问题求解的可扩展性和自动化水平。摘要未明确说明局限性，但未来工作可探索代理交互优化或扩展到更复杂问题场景。",
      "tags": [
        "LLM-powered AI agents",
        "Optimization",
        "Natural Language Processing",
        "Multi-agent systems",
        "UCB-based scheduling"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:20.538330Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.10331",
    "title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions",
    "authors": [
      "Maxim Popov",
      "Regina Kurkova",
      "Mikhail Iumanov",
      "Jaafar Mahmoud",
      "Sergey Kolyubin"
    ],
    "abstract": "Open Semantic Mapping (OSM) is a key technology in robotic perception, combining semantic segmentation and SLAM techniques. This paper introduces a dynamically configurable and highly automated LLM/LVLM-powered pipeline for evaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark). The study focuses on evaluating state-of-the-art semantic mapping algorithms under varying indoor lighting conditions, a critical challenge in indoor environments. We introduce a novel dataset with simulated RGB-D sequences and ground truth 3D reconstructions, facilitating the rigorous analysis of mapping performance across different lighting conditions. Through experiments on leading models such as ConceptGraphs, BBQ, and OpenScene, we evaluate the semantic fidelity of object recognition and segmentation. Additionally, we introduce a Scene Graph evaluation method to analyze the ability of models to interpret semantic structure. The results provide insights into the robustness of these models, forming future research directions for developing resilient and adaptable robotic systems. Project page is available at https://be2rlab.github.io/OSMa-Bench/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.10331.pdf",
    "abs_url": "https://arxiv.org/abs/2503.10331",
    "published": "2025-03-13T13:07:51Z",
    "updated": "2026-01-21T17:25:25Z",
    "comment": "Project page: https://be2rlab.github.io/OSMa-Bench/",
    "light_analysis": {
      "overview": "本文引入了OSMa-Bench，一个动态可配置和高度自动化的LLM/LVLM驱动基准测试管道，用于评估开放语义映射算法在变化照明条件下的性能。",
      "motivation": "开放语义映射结合语义分割和SLAM技术，是机器人感知的关键，但在室内环境中，变化照明条件对算法鲁棒性构成重大挑战，影响对象识别和场景理解的准确性。现有基准可能未充分考虑照明变化的多样性，导致算法在真实世界部署时性能下降。因此，开发专门评估工具至关重要，以推动算法适应性和可靠性的研究，填补现有不足。",
      "method": "研究提出了OSMa-Bench基准测试管道，采用动态可配置和高度自动化设计，利用LLM/LVLM技术进行评估。关键创新包括引入一个新数据集，包含模拟的RGB-D序列和地面真值3D重建，模拟不同照明条件。通过评估对象识别和分割的语义保真度，并引入场景图分析方法，对ConceptGraphs、BBQ和OpenScene等模型进行测试，强调照明变化对语义结构理解的影响。",
      "result": "通过对ConceptGraphs、BBQ和OpenScene等领先模型的实验，评估了它们在变化照明条件下的语义保真度和场景图理解能力。结果提供了模型鲁棒性的定性见解，揭示了性能在不同照明场景下的差异，但摘要未明确说明具体性能指标如准确率提升，因此基于实验结果推断模型对语义结构解释能力的局限性。",
      "conclusion": "本研究的主要贡献是提出了OSMa-Bench基准测试框架和相关数据集，为开放语义映射算法在变化照明条件下的评估提供了标准化工具。其学术价值在于促进算法鲁棒性和适应性研究，实际应用价值有助于开发更弹性的机器人感知系统。未来工作可基于实验见解优化模型设计，并扩展评估到更多真实世界场景。",
      "tags": [
        "Open Semantic Mapping",
        "Semantic Segmentation",
        "SLAM",
        "LLM/LVLM",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:06.376554Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.18099",
    "title": "Stackelberg Self-Annotation: A Robust Approach to Data-Efficient LLM Alignment",
    "authors": [
      "Xu Chu",
      "Zhixin Zhang",
      "Tianyu Jia",
      "Yujie Jin"
    ],
    "abstract": "Aligning large language models (LLMs) with human preferences typically demands vast amounts of meticulously curated data, which is both expensive and prone to labeling noise. We propose Stackelberg Game Preference Optimization (SGPO), a robust alignment framework that models alignment as a two-player Stackelberg game between a policy (leader) and a worst-case preference distribution (follower). The proposed SGPO guarantees $\\mathcal{O}(ε)$-bounded regret within an $ε$-Wasserstein ball, offering formal robustness to (self-)annotation noise. We instantiate SGPO with Stackelberg Self-Annotated Preference Optimization (SSAPO), which uses minimal human-labeled \"seed\" preferences and iteratively self-annotates new prompts. In each iteration, SSAPO applies a distributionally robust reweighting of synthetic annotations, ensuring that noisy or biased self-labels do not derail training. Remarkably, using only 2K seed preferences -- about 1/30 of standard human labels -- SSAPO achieves strong win rates against GPT-4 across multiple benchmarks within three iterations. These results highlight that a principled Stackelberg formulation yields data-efficient alignment for LLMs, significantly reducing reliance on costly human annotations.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.18099.pdf",
    "abs_url": "https://arxiv.org/abs/2502.18099",
    "published": "2025-02-25T11:08:12Z",
    "updated": "2026-01-21T08:55:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Stackelberg Self-Annotated Preference Optimization (SSAPO)框架，通过Stackelberg游戏和自标注机制，实现数据高效且鲁棒的LLM对齐。",
      "motivation": "LLM对齐通常需要大量人工标注数据，成本高昂且易受噪声影响，这限制了模型的广泛应用和经济可行性。现有方法依赖于昂贵且不可靠的标注过程，导致对齐效率低下和鲁棒性差。本研究旨在解决这一关键问题，通过减少标注需求和提升鲁棒性，开发一种数据高效的对齐方法，以克服传统方法的不足，推动LLM在实际部署中的实用性。",
      "method": "方法基于Stackelberg Game Preference Optimization (SGPO)，将对齐建模为两玩家Stackelberg游戏，政策作为领导者优化策略，最坏情况偏好分布作为追随者模拟噪声，提供形式化鲁棒性保证。实例化为SSAPO，仅使用少量人类标注的种子偏好，迭代自标注新提示，并通过分布鲁棒重加权处理合成标注，防止噪声或偏差自标注干扰训练。关键创新包括Stackelberg游戏形式化、自标注迭代机制和鲁棒重加权策略。",
      "result": "实验结果表明，SSAPO仅使用2,000个种子偏好（约为标准人类标签数量的1/30），经过三轮迭代，在多个基准测试中对GPT-4实现了高胜率。这验证了该方法在极小量人类标注数据下的有效性和鲁棒性，显著优于依赖大量标注的基线方法，具体性能提升体现在胜率的显著提高，但摘要未提供精确数值。",
      "conclusion": "本研究贡献了一种基于Stackelberg游戏和自标注的LLM对齐框架SSAPO，通过数据高效和鲁棒的方式减少了对昂贵人类标注的依赖。学术上，该工作扩展了游戏理论在机器学习中的应用，实际应用中，降低了对齐成本并提升了模型可靠性。未来工作可探索更广泛的基准测试或算法优化，但摘要未明确说明局限性。",
      "tags": [
        "Stackelberg Game",
        "Preference Optimization",
        "Self-Annotation",
        "Distributionally Robust Optimization",
        "LLM Alignment"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:50.727851Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.11789",
    "title": "Personality Editing for Language Models through Adjusting Self-Referential Queries",
    "authors": [
      "Seojin Hwang",
      "Yumin Kim",
      "Byeongjeong Kim",
      "Donghoon Shin",
      "Hwanhee Lee"
    ],
    "abstract": "Large Language Models (LLMs) are integral to applications such as conversational agents and content creation, where precise control over a model's personality is essential for maintaining tone, consistency, and user engagement. However, prevailing prompt-based or fine-tuning approaches either lack robustness or demand large-scale training data, making them costly and impractical. In this paper, we present PALETTE (Personality Adjustment by LLM SElf-TargeTed quEries), a novel method for personality editing in LLMs. Our approach introduces adjustment queries, where self-referential statements grounded in psychological constructs are treated analogously to factual knowledge, enabling direct editing of personality-related responses. Unlike fine-tuning, PALETTE requires only 12 editing samples to achieve substantial improvements in personality alignment across personality dimensions. Experimental results from both automatic and human evaluations demonstrate that our method enables more stable and well-balanced personality control in LLMs.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2502.11789.pdf",
    "abs_url": "https://arxiv.org/abs/2502.11789",
    "published": "2025-02-17T13:28:14Z",
    "updated": "2026-01-21T09:57:21Z",
    "comment": "Accepted to EACL 2026 (Main)",
    "light_analysis": {
      "overview": "本文提出PALETTE方法，通过调整自引用查询实现大语言模型的个性编辑，仅需少量样本即可显著改进个性控制。",
      "motivation": "大语言模型（LLMs）在对话代理和内容创作等应用中至关重要，精确控制模型个性对保持语调一致性、提升用户参与度具有实际需求。现有方法如提示工程缺乏鲁棒性，而微调需要大规模训练数据，导致成本高且不实用。这些问题凸显了开发高效、低成本个性编辑方法的重要性，以克服现有技术的局限性并满足应用场景中的精细控制要求。",
      "method": "PALETTE方法的核心是引入调整查询，将基于心理学构念的自引用陈述视为类似于事实知识进行处理，从而直接编辑个性相关响应。该方法无需依赖大量数据，仅需12个编辑样本即可实现个性调整，通过类比事实编辑的方式优化LLM的行为。虽然摘要未明确说明具体的数据集或模型架构，但技术路线聚焦于自引用查询的处理，提供了一种新颖的个性编辑途径。",
      "result": "实验通过自动评估和人工评估验证了PALETTE方法的有效性，在多个个性维度上实现了显著改进。与基线方法（如提示和微调）相比，仅使用12个编辑样本就取得了更稳定且均衡的个性控制效果。摘要未提供具体的准确率提升数值，但强调了改进的显著性和鲁棒性增强，表明该方法在个性对齐方面优于现有技术。",
      "conclusion": "本研究的主要贡献是提出PALETTE方法，为大语言模型的个性编辑提供了一种高效且低成本的解决方案，学术价值在于探索通过调整自引用查询直接编辑响应的新途径。实际应用价值体现在对话系统和内容生成领域，可改善用户体验和模型一致性。未来工作可能涉及进一步优化编辑精度或处理复杂个性特征，但摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Personality Editing",
        "Self-Referential Queries",
        "Adjustment Queries",
        "Psychological Constructs"
      ]
    },
    "analyzed_at": "2026-01-22T03:40:54.885509Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.09598",
    "title": "GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for Remote Sensing Image Analysis",
    "authors": [
      "Angelos Zavras",
      "Dimitrios Michail",
      "Xiao Xiang Zhu",
      "Begüm Demir",
      "Ioannis Papoutsis"
    ],
    "abstract": "Existing Vision-Language Models (VLMs) are predominantly trained on web-scraped, noisy image-text data, exhibiting limited exposure to the specialized domain of RS. This deficiency results in poor performance on RS-specific tasks, as commonly used datasets often lack detailed, scientifically accurate textual descriptions and instead emphasize solely on attributes like date and location. To bridge this critical gap, we introduce GAIA, a novel dataset designed for multi-scale, multi-sensor, and multi-modal RS image analysis. GAIA comprises of 201,005 meticulously curated RS image-text pairs, representing a diverse range of RS modalities associated to different spatial resolutions. Unlike existing vision-language datasets in RS, GAIA specifically focuses on capturing a diverse range of RS applications, providing unique information about environmental changes, natural disasters, and various other dynamic phenomena. The dataset provides a spatially and temporally balanced distribution, spanning across the globe, covering the last 25 years with a balanced temporal distribution of observations. GAIA's construction involved a two-stage process: (1) targeted web-scraping of images and accompanying text from reputable RS-related sources, and (2) generation of five high-quality, scientifically grounded synthetic captions for each image using carefully crafted prompts that leverage the advanced vision-language capabilities of GPT-4o. Our extensive experiments, including fine-tuning of CLIP and BLIP2 models, demonstrate that GAIA significantly improves performance on RS image classification, cross-modal retrieval and image captioning tasks. We make our dataset, automated processing framework and fine-tuned model weights publicly available on our project's GitHub repository: https://github.com/Orion-AI-Lab/GAIA.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2502.09598.pdf",
    "abs_url": "https://arxiv.org/abs/2502.09598",
    "published": "2025-02-13T18:52:14Z",
    "updated": "2026-01-21T12:51:46Z",
    "comment": "26 pages, 14 figures",
    "light_analysis": {
      "overview": "本文提出了GAIA数据集，这是一个全球、多模态、多尺度的遥感视觉-语言数据集，通过高质量数据显著提升视觉-语言模型在遥感任务中的性能。",
      "motivation": "现有视觉-语言模型主要基于网络爬取的噪声数据，对遥感领域表现不佳，因为常用数据集缺乏详细、科学的文本描述，仅关注基本属性如日期和位置。这限制了RS特定任务如环境监测和灾害响应的准确性。为了填补这一空白，本研究旨在创建一个高质量、覆盖广泛的数据集，以支持RS应用的开发。",
      "method": "研究构建了GAIA数据集，包含201,005个精心策划的遥感图像-文本对，覆盖多种传感器和空间分辨率。数据集通过两阶段构建：首先从可靠来源爬取图像和原始文本，然后利用GPT-4o生成五个高质量的合成标题。关键创新点在于多尺度、多传感器、多模态设计，确保全球覆盖和25年时间平衡分布，以提高数据的科学准确性。",
      "result": "通过微调CLIP和BLIP2模型，实验表明GAIA数据集显著提高了遥感图像分类、跨模态检索和图像标题任务的性能。与基线方法相比，改进效果显著，但摘要未提供具体数据指标，因此基于描述推断其在RS任务中的有效性。",
      "conclusion": "本研究贡献了GAIA数据集和自动化处理框架，推动了遥感视觉-语言模型的研究。该数据集具有学术价值，可用于提升环境监测和灾害响应等应用。局限性可能在于数据集的规模和多样性，未来工作可以扩展到更多RS应用或优化模型架构。",
      "tags": [
        "Remote Sensing",
        "Vision-Language Models",
        "Dataset Creation",
        "GPT-4o",
        "Multi-scale Analysis"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:28.875946Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.02339",
    "title": "AStar: Boosting Multimodal Reasoning with Automated Structured Thinking",
    "authors": [
      "Jinyang Wu",
      "Mingkuan Feng",
      "Guocheng Zhai",
      "Shuai Zhang",
      "Zheng Lian",
      "Fangrui Lv",
      "Pengpeng Shao",
      "Ruihan Jin",
      "Zhengqi Wen",
      "Jianhua Tao"
    ],
    "abstract": "Multimodal large language models excel across diverse domains but struggle with complex visual reasoning tasks. To enhance their reasoning capabilities, current approaches typically rely on explicit search or post-training techniques. However, search-based methods suffer from computational inefficiency due to extensive solution space exploration, while post-training methods demand substantial data, computational resources, and often exhibit training instability. To address these challenges, we propose \\textbf{AStar}, a training-free, \\textbf{A}utomatic \\textbf{S}tructured \\textbf{t}hinking paradigm for multimod\\textbf{a}l \\textbf{r}easoning. Specifically, we introduce novel ``thought cards'', a lightweight library of high-level reasoning patterns abstracted from prior samples. For each test problem, AStar adaptively retrieves the optimal thought cards and seamlessly integrates these external explicit guidelines with the model's internal implicit reasoning capabilities. Compared to previous methods, AStar eliminates computationally expensive explicit search and avoids additional complex post-training processes, enabling a more efficient reasoning approach. Extensive experiments demonstrate that our framework achieves 53.9\\% accuracy on MathVerse (surpassing GPT-4o's 50.2\\%) and 32.7\\% on MathVision (outperforming GPT-4o's 30.4\\%). Further analysis reveals the remarkable transferability of our method: thought cards generated from mathematical reasoning can also be applied to other reasoning tasks, even benefiting general visual perception and understanding. AStar serves as a plug-and-play test-time inference method, compatible with other post-training techniques, providing an important complement to existing multimodal reasoning approaches.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2502.02339.pdf",
    "abs_url": "https://arxiv.org/abs/2502.02339",
    "published": "2025-02-04T14:18:29Z",
    "updated": "2026-01-21T12:52:01Z",
    "comment": "Accepted by AAAI 2026 Oral",
    "light_analysis": {
      "overview": "AStar提出一种免训练、自动结构化思维的范式，通过引入thought cards来增强多模态大语言模型的复杂视觉推理能力。",
      "motivation": "多模态大语言模型在复杂视觉推理任务中表现不佳，而现有方法如显式搜索需探索广泛解空间导致计算效率低，后训练方法则依赖大量数据和计算资源且常出现训练不稳定。这些不足限制了模型的实际应用效率和可扩展性，因此需要开发更高效的推理方法，以减少资源消耗并提升性能。本研究旨在解决这些问题，提供一种轻量级且稳定的替代方案。",
      "method": "AStar引入'thought cards'作为轻量级推理模式库，从先验样本中抽象高级推理模式。对于每个测试问题，它自适应检索最优thought cards，将外部显式指南与模型内部隐式推理能力无缝集成。该方法免训练，避免显式搜索和复杂后训练，作为即插即用的推理技术，兼容其他后训练方法，使用MathVerse和MathVision等数据集进行实验。",
      "result": "在MathVerse数据集上，AStar达到53.9%的准确率，超越GPT-4o的50.2%；在MathVision数据集上达到32.7%，优于GPT-4o的30.4%。实验表明该方法能有效提升性能，并具有可转移性，thought cards可应用于其他推理任务，甚至增强一般视觉感知和理解能力。",
      "conclusion": "AStar的主要贡献是提供一种高效的、免训练的多模态推理范式，通过自动化结构化思维提升模型性能。它避免了资源密集的搜索和后训练，具有即插即用和兼容性优势，为现有方法提供重要补充。未来工作可探索其在更多领域的应用，以及优化thought cards的生成和泛化能力，摘要未明确说明具体局限性。",
      "tags": [
        "Multimodal Reasoning",
        "Large Language Models",
        "Thought Cards",
        "Automated Structured Thinking",
        "Test-time Inference"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:30.472835Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.00681",
    "title": "A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models",
    "authors": [
      "Qika Lin",
      "Zhen Peng",
      "Kaize Shi",
      "Kai He",
      "Yiming Xu",
      "Jian Zhang",
      "Erik Cambria",
      "Mengling Feng"
    ],
    "abstract": "Recent years have witnessed rapid advances in graph representation learning, with the continuous embedding approach emerging as the dominant paradigm. However, such methods encounter issues regarding parameter efficiency, interpretability, and robustness. Thus, Quantized Graph Representation (QGR) learning has recently gained increasing interest, which represents the graph structure with discrete codes instead of conventional continuous embeddings. Given its analogous representation form to natural language, QGR also possesses the capability to seamlessly integrate graph structures with large language models (LLMs). As this emerging paradigm is still in its infancy yet holds significant promise, we undertake this thorough survey to promote its rapid future prosperity. We first present the background of the general quantization methods and their merits. Moreover, we provide an in-depth demonstration of current QGR studies from the perspectives of quantized strategies, training objectives, distinctive designs, knowledge graph quantization, and applications. We further explore the strategies for code dependence learning and integration with LLMs. At last, we give discussions and conclude future directions, aiming to provide a comprehensive picture of QGR and inspire future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.00681.pdf",
    "abs_url": "https://arxiv.org/abs/2502.00681",
    "published": "2025-02-02T05:57:34Z",
    "updated": "2026-01-21T05:37:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文是一篇关于量化图表示学习的综述，探讨了其如何通过离散代码表示图结构，并与大型语言模型无缝集成，以解决连续嵌入方法的不足。",
      "motivation": "近年来，图表示学习主要依赖连续嵌入方法，但这些方法在参数效率、可解释性和鲁棒性方面存在局限，限制了实际应用。量化图表示（QGR）采用离散代码来表征图结构，其表示形式类似于自然语言，因此能够与大型语言模型（LLMs）结合，提供更高效的存储、更好的可解释性，并增强处理复杂图数据的潜力。这一问题的重要性在于，QGR有望解决传统方法的缺陷，推动图学习与自然语言处理的交叉融合。",
      "method": "作为一篇综述，论文通过系统调查现有研究，从量化策略、训练目标、独特设计、知识图谱量化和应用等多个角度深入分析QGR领域。核心方法包括梳理不同量化技术的优劣，探讨如何优化离散代码的生成与学习，以及探索QGR与大型语言模型（LLMs）的集成策略，如利用LLMs处理量化后的图数据。该研究还涉及代码依赖学习的方法，旨在提供全面的技术路线图，但未提出具体的模型架构或数据集细节。",
      "result": "摘要未明确说明具体的实验结果或性能指标，因为这是一篇综述论文，重点在于总结现有研究的进展和优势。论文指出，QGR通过离散化表示可以提升参数效率和可解释性，并展示出与大型语言模型集成的潜力，例如在知识图谱和自然语言处理任务中的应用前景。虽然没有直接对比基线方法的数据，但强调了QGR在未来可能带来的效率改进和创新应用。",
      "conclusion": "本文的主要贡献在于全面综述了量化图表示学习（QGR）的现状，提供了该领域的综合图景，并讨论了未来研究方向，如代码依赖学习和与大型语言模型的深度集成。其学术价值在于系统梳理了新兴技术，为研究者提供了清晰的框架；实际应用价值体现在QGR可能推动图学习与AI模型的融合，提升处理复杂数据的效率。局限性在于该领域仍处于初级阶段，未来工作需探索更高效的量化算法和实际部署挑战。",
      "tags": [
        "Quantized Graph Representation Learning",
        "Large Language Models",
        "Graph Quantization",
        "Knowledge Graph Quantization",
        "Code Dependence Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:22:26.363754Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.19128",
    "title": "Shaping Sparse Rewards in Reinforcement Learning: A Semi-supervised Approach",
    "authors": [
      "Wenyun Li",
      "Wenjie Huang",
      "Chen Sun"
    ],
    "abstract": "In many real-world scenarios, reward signal for agents are exceedingly sparse, making it challenging to learn an effective reward function for reward shaping. To address this issue, the proposed approach in this paper performs reward shaping not only by utilizing non-zero-reward transitions but also by employing the \\emph{Semi-Supervised Learning} (SSL) technique combined with a novel data augmentation to learn trajectory space representations from the majority of transitions, {i.e}., zero-reward transitions, thereby improving the efficacy of reward shaping. Experimental results in Atari and robotic manipulation demonstrate that our method outperforms supervised-based approaches in reward inference, leading to higher agent scores. Notably, in more sparse-reward environments, our method achieves up to twice the peak scores compared to supervised baselines. The proposed double entropy data augmentation enhances performance, showcasing a 15.8\\% increase in best score over other augmentation methods",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2501.19128.pdf",
    "abs_url": "https://arxiv.org/abs/2501.19128",
    "published": "2025-01-31T13:35:19Z",
    "updated": "2026-01-21T07:57:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一种结合半监督学习和双重熵数据增强的方法，用于处理强化学习中的稀疏奖励问题，显著提升代理性能。",
      "motivation": "在强化学习中，现实场景如Atari游戏和机器人操作中的奖励信号往往极其稀疏，导致代理难以学习有效策略。传统基于监督的方法仅利用少量非零奖励数据，忽视了大多数零奖励数据，限制了奖励塑造的效果，影响学习效率和性能。稀疏奖励问题在复杂环境中普遍存在，亟需新方法以充分利用所有数据提升奖励推断能力。",
      "method": "本文提出一种半监督学习框架，结合数据增强技术来处理稀疏奖励。核心方法包括利用半监督学习从大量零奖励转移中学习轨迹空间表示，同时结合非零奖励转移进行监督学习。创新点在于引入双重熵数据增强策略，通过增强数据多样性来优化表示学习，从而改进奖励塑造过程。该方法应用于Atari和机器人操作环境，不依赖特定模型架构，专注于从所有过渡数据中提取有效信息。",
      "result": "实验在Atari游戏和机器人操作任务中进行。结果表明，所提方法在奖励推断上优于监督基线，代理得分显著提高。在高度稀疏奖励环境中，峰值得分达到监督基线的两倍。双重熵数据增强策略进一步提升了性能，最佳得分比现有增强方法高出15.8%，验证了方法的有效性和鲁棒性。",
      "conclusion": "本研究通过整合半监督学习和数据增强，有效解决了强化学习中的稀疏奖励挑战。主要贡献是提出了一种新颖的奖励塑造方法，能够充分利用零奖励数据提升学习效率。学术上，它拓展了半监督学习在强化学习中的应用；实践上，适用于游戏和机器人等领域。未来工作可探索更多数据增强技术或扩展到动态复杂环境。",
      "tags": [
        "Reinforcement Learning",
        "Semi-Supervised Learning",
        "Data Augmentation",
        "Reward Shaping",
        "Sparse Rewards"
      ]
    },
    "analyzed_at": "2026-01-22T03:23:33.151445Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.08620",
    "title": "CT-PatchTST: Channel-Time Patch Time-Series Transformer for Long-Term Renewable Energy Forecasting",
    "authors": [
      "Kuan Lu",
      "Menghao Huo",
      "Yuxiao Li",
      "Qiang Zhu",
      "Zhenrui Chen"
    ],
    "abstract": "Accurate forecasting of renewable energy generation is fundamental to enhancing the dynamic performance of modern power grids, especially under high renewable penetration. This paper presents Channel-Time Patch Time-Series Transformer (CT-PatchTST), a novel deep learning model designed to provide long-term, high-fidelity forecasts of wind and solar power. Unlike conventional time-series models, CT-PatchTST captures both temporal dependencies and inter-channel correlations-features that are critical for effective energy storage planning, control, and dispatch. Reliable forecasting enables proactive deployment of energy storage systems (ESSs), helping to mitigate uncertainties in renewable output, reduce system response time, and optimize storage operation based on location-specific flow and voltage conditions. Evaluated on real-world datasets from Denmark's offshore wind, onshore wind, and solar generation, CT-PatchTST outperforms existing methods in both accuracy and robustness. By enabling predictive, data-driven coordination of ESSs across integrated source-grid-load-storage systems, this work contributes to the design of more stable, responsive, and cost-efficient power networks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2501.08620.pdf",
    "abs_url": "https://arxiv.org/abs/2501.08620",
    "published": "2025-01-15T06:35:39Z",
    "updated": "2026-01-21T05:45:13Z",
    "comment": "Published in: 2025 10th International Conference on Computer and Information Processing Technology (ISCIPT)",
    "light_analysis": {
      "overview": "提出了CT-PatchTST模型，这是一个结合通道和时间Patch的Transformer模型，用于长期可再生能源预测，在准确性和鲁棒性上优于现有方法。",
      "motivation": "可再生能源发电的准确预测对现代电网在高渗透率下的动态性能提升至关重要，现有传统时间序列模型未能有效捕获时间和通道相关性，导致预测精度不足，影响能源存储系统部署和电网优化。本研究旨在通过改进模型来解决此问题，以支持主动存储规划和减少不确定性，从而提高电网稳定性和响应能力。",
      "method": "本研究提出CT-PatchTST模型，一种基于深度学习的Transformer架构，通过Patch方式处理时间序列数据，关键创新在于同时捕获时间依赖性和通道间相关性，使用真实世界数据集（如丹麦的离岸风能、岸上风能和太阳能发电数据）进行评估，专为风能和太阳能功率的长期预测设计。",
      "result": "在丹麦的真实世界数据集上评估，CT-PatchTST模型在风能和太阳能功率预测中，显示在准确性和鲁棒性方面优于现有基线方法，但摘要未提供具体性能指标，仅表明该方法能提供更可靠的长期预测，提升预测质量。",
      "conclusion": "本研究的贡献在于开发了CT-PatchTST模型，支持预测性协调能源存储系统，促进更稳定、响应快、成本低的电网设计，学术上推动了时间序列Transformer的应用，实际上增强了可再生能源集成能力，局限性或未来工作方向在摘要中未明确说明。",
      "tags": [
        "Renewable Energy Forecasting",
        "Time-Series Transformer",
        "Channel-Time Modeling",
        "Long-Term Forecasting"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:27.712083Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.17392",
    "title": "NumGrad-Pull: Numerical Gradient Guided Tri-plane Representation for Surface Reconstruction from Point Clouds",
    "authors": [
      "Ruikai Cui",
      "Binzhu Xie",
      "Shi Qiu",
      "Jiawei Liu",
      "Saeed Anwar",
      "Nick Barnes"
    ],
    "abstract": "Reconstructing continuous surfaces from unoriented and unordered 3D points is a fundamental challenge in computer vision and graphics. Recent advancements address this problem by training neural signed distance functions to pull 3D location queries to their closest points on a surface, following the predicted signed distances and the analytical gradients computed by the network. In this paper, we introduce NumGrad-Pull, leveraging the representation capability of tri-plane structures to accelerate the learning of signed distance functions and enhance the fidelity of local details in surface reconstruction. To further improve the training stability of grid-based tri-planes, we propose to exploit numerical gradients, replacing conventional analytical computations. Additionally, we present a progressive plane expansion strategy to facilitate faster signed distance function convergence and design a data sampling strategy to mitigate reconstruction artifacts. Our extensive experiments across a variety of benchmarks demonstrate the effectiveness and robustness of our approach. Code is available at https://github.com/CuiRuikai/NumGrad-Pull",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.17392.pdf",
    "abs_url": "https://arxiv.org/abs/2411.17392",
    "published": "2024-11-26T12:54:30Z",
    "updated": "2026-01-21T05:21:03Z",
    "comment": "under review",
    "light_analysis": {
      "overview": "NumGrad-Pull通过数值梯度引导的三平面表示，加速符号距离函数学习，提高从点云重建表面时的局部细节保真度。",
      "motivation": "表面重建是计算机视觉和图形学中的基础挑战，现有方法通过训练神经符号距离函数，依赖分析梯度将点查询拉向表面，但可能面临训练不稳定或局部细节不精确的问题。这项研究旨在解决从无序、无定向3D点云重建连续表面的难题，改进现有方法中梯度计算的高复杂度或收敛问题，以提高重建效率和保真度。",
      "method": "论文提出NumGrad-Pull方法，利用三平面结构的表示能力加速符号距离函数学习，并通过数值梯度替代传统分析梯度，以提高训练稳定性。创新策略包括渐进平面扩展加速收敛和数据采样减少重建伪影，这些技术结合了高效表示与梯度计算，旨在增强表面细节保真度。",
      "result": "在多种基准测试中进行广泛实验，证明NumGrad-Pull方法的有效性和鲁棒性。摘要未明确说明具体性能指标如准确率提升，但实验暗示该方法在表面重建任务中表现优异，提高了细节保真度和训练效率，通过与基线方法对比展示了其优势。",
      "conclusion": "NumGrad-Pull为点云表面重建提供了创新方法，通过结合三平面结构和数值梯度，显著加速学习过程并增强局部细节保真度，具有重要学术和应用价值，推动了计算机视觉和图形学领域的发展。未来可进一步优化策略或扩展到更复杂场景。",
      "tags": [
        "Tri-plane Representation",
        "Signed Distance Functions",
        "Numerical Gradient",
        "Surface Reconstruction",
        "Point Cloud Reconstruction"
      ]
    },
    "analyzed_at": "2026-01-22T03:24:37.243293Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.19360",
    "title": "LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function",
    "authors": [
      "Zhijie Chen",
      "Xinglin Zhang"
    ],
    "abstract": "This paper proposes a novel approach for designing Single-Parameterized Kolmogorov-Arnold Networks (SKAN) by utilizing a Single-Parameterized Function (SFunc) constructed from trigonometric functions. Three new SKAN variants are developed: LSin-SKAN, LCos-SKAN, and LArctan-SKAN. Experimental validation on the MNIST dataset demonstrates that LArctan-SKAN excels in both accuracy and computational efficiency. Specifically, LArctan-SKAN significantly improves test set accuracy over existing models, outperforming all pure KAN variants compared, including FourierKAN, LSS-SKAN, and Spl-KAN. It also surpasses mixed MLP-based models such as MLP+rKAN and MLP+fKAN in accuracy. Furthermore, LArctan-SKAN exhibits remarkable computational efficiency, with a training speed increase of 535.01% and 49.55% compared to MLP+rKAN and MLP+fKAN, respectively. These results confirm the effectiveness and potential of SKANs constructed with trigonometric functions. The experiment code is available at https://github.com/chikkkit/LArctan-SKAN .",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2410.19360.pdf",
    "abs_url": "https://arxiv.org/abs/2410.19360",
    "published": "2024-10-25T07:41:56Z",
    "updated": "2026-01-21T07:44:23Z",
    "comment": "This work has been merged into and superseded by a comprehensive version available at arXiv:2410.14951. Please cite and refer to arXiv:2410.14951 for the complete study, which includes the methods and results originally presented here",
    "light_analysis": {
      "overview": "本论文提出了一种基于可学习三角函数的单参数化Kolmogorov-Arnold网络（SKAN），在MNIST数据集上实现了卓越的准确性和计算效率。",
      "motivation": "该研究旨在解决现有Kolmogorov-Arnold网络（KAN）及其变体在准确性和计算效率方面的不足。问题在于纯KAN模型如FourierKAN或混合MLP模型可能在处理图像识别任务时表现有限，且训练速度较慢。重要性在于通过优化网络参数化方法，可以提升神经网络的整体性能，以应对更复杂的机器学习应用，而当前方法在效率和准确性平衡上存在改进空间。",
      "method": "论文提出了一种新的SKAN设计方法，利用三角函数构造单参数函数（SFunc），并开发了LSin-SKAN、LCos-SKAN和LArctan-SKAN三种变体。核心创新点是将可学习的三角函数集成到网络参数化中，以增强模型的表达能力和灵活性。该方法在MNIST数据集上进行验证，通过调整三角函数的参数来实现高效学习，从而简化网络结构并提高训练效率。",
      "result": "在MNIST数据集上的实验显示，LArctan-SKAN在测试集准确性上显著优于现有模型，包括纯KAN变体如FourierKAN、LSS-SKAN和Spl-KAN，以及混合MLP模型如MLP+rKAN和MLP+fKAN。计算效率方面，LArctan-SKAN的训练速度相比MLP+rKAN提升了535.01%，相比MLP+fKAN提升了49.55%，证实了其在保持高准确性的同时大幅提升了效率。",
      "conclusion": "本研究的主要贡献是证明了使用可学习三角函数构建的SKAN在准确性和计算效率上的有效性，为神经网络设计提供了新方向。学术价值在于扩展了KAN的理论应用，实际应用潜力在于高效处理图像识别等任务。摘要未明确说明局限性或未来工作方向，但可能包括对其他数据集的泛化能力或进一步优化参数化函数的研究。",
      "tags": [
        "Kolmogorov-Arnold Networks",
        "Trigonometric Functions",
        "Single-Parameterized Networks",
        "MNIST Dataset",
        "Computational Efficiency"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:59.577973Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.14951",
    "title": "Architectural Scaling Surpass Basis Complexity? Efficient KANs with Single-Parameter Design",
    "authors": [
      "Zhijie Chen",
      "Xinglin Zhang",
      "Hongshu Guo",
      "Yue-Jiao Gong"
    ],
    "abstract": "The landscape of Kolmogorov-Arnold Networks (KANs) is rapidly expanding, yet lacks a unified theoretical framework and a clear principle for efficient architecture design. This paper addresses these gaps with three core contributions. First, we introduce the Universal KAN (Uni-KAN) framework, a novel abstraction that formally unifies all KAN-style networks through dense and sparse representations. We prove their interchangeability and provide an open-source library for this framework, facilitating future research. Second, we propose the Efficient KAN Expansion (EKE) Hypothesis, a design philosophy positing that allocating parameters to architectural scaling rather than basis function complexity yields superior performance. Third, we present Single-Parameter KANs (SKANs), a family of ultra-lightweight networks that embody the EKE Hypothesis. Our comprehensive experiments provide the first strong empirical validation for the theoretical necessity of basis function smoothness for stable training. Furthermore, SKANs demonstrate state-of-the-art performance, improving F1 scores by up to 6.51\\% and reducing test loss by 93.1\\%, while achieving up to 6x faster training speeds compared to existing KAN variants. These results establish a robust framework, a guiding hypothesis, and a practical methodology for designing the next generation of efficient and powerful neural networks. The code is accessible at https://anonymous.4open.science/r/SKAN-EBBB/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2410.14951.pdf",
    "abs_url": "https://arxiv.org/abs/2410.14951",
    "published": "2024-10-19T02:44:35Z",
    "updated": "2026-01-21T07:43:09Z",
    "comment": "Major update: This is a comprehensive version that introduces the SKANs and integrates the methodology from arXiv:2410.19360. This version supersedes arXiv:2410.19360. 12 pages, 10 figures",
    "light_analysis": {
      "overview": "论文提出一种高效神经网络设计方法，通过统一框架和单参数设计，显著提升KANs的性能和训练效率。",
      "motivation": "当前Kolmogorov-Arnold Networks (KANs)领域发展迅速，但缺乏统一的理论框架和明确的高效架构设计原则。这导致网络设计过于依赖复杂的基函数参数化，限制了性能和可扩展性。因此，本研究旨在填补这些空白，提供一个更系统化的方法来优化网络结构，以解决KANs在实际应用中效率低下的问题。",
      "method": "论文提出Universal KAN (Uni-KAN)框架，通过密集和稀疏表示统一所有KANs，并证明其可交换性，同时提供开源库支持。基于此，提出Efficient KAN Expansion (EKE)假设，主张将参数分配到架构缩放而非基函数复杂性。最后，设计Single-Parameter KANs (SKANs)作为超轻量级网络，体现EKE假设，实现简化参数的设计。摘要未明确说明具体数据集或模型架构细节。",
      "result": "SKANs在实验中展现了最先进性能，相比现有KAN变体，F1分数提升高达6.51%，测试损失降低93.1%，训练速度提升高达6倍。此外，论文首次提供了强实证验证，支持基函数平滑性对稳定训练的理论必要性，为KANs的改进提供了数据支撑。",
      "conclusion": "本研究建立了统一的Uni-KAN框架、指导性的EKE假设和实用的SKANs设计方法，为下一代高效神经网络提供了理论基础和实践工具。学术上填补了KANs领域的理论空白，实践上提升了网络性能和训练效率，具有广泛的应用前景。未来可进一步探索优化方向和更复杂的场景应用。",
      "tags": [
        "Kolmogorov-Arnold Networks",
        "Single-Parameter KANs",
        "Architectural Scaling",
        "Basis Function Smoothness",
        "Efficient Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-22T03:25:44.408594Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.08864",
    "title": "The Good, the Bad and the Ugly: Meta-Analysis of Watermarks, Transferable Attacks and Adversarial Defenses",
    "authors": [
      "Grzegorz Głuch",
      "Berkant Turan",
      "Sai Ganesh Nagarajan",
      "Sebastian Pokutta"
    ],
    "abstract": "We formalize and analyze the trade-off between backdoor-based watermarks and adversarial defenses, framing it as an interactive protocol between a verifier and a prover. While previous works have primarily focused on this trade-off, our analysis extends it by identifying transferable attacks as a third, counterintuitive, but necessary option. Our main result shows that for all learning tasks, at least one of the three exists: a watermark, an adversarial defense, or a transferable attack. By transferable attack, we refer to an efficient algorithm that generates queries indistinguishable from the data distribution and capable of fooling all efficient defenders. Using cryptographic techniques, specifically fully homomorphic encryption, we construct a transferable attack and prove its necessity in this trade-off. Finally, we show that tasks of bounded VC-dimension allow adversarial defenses against all attackers, while a subclass allows watermarks secure against fast adversaries.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2410.08864.pdf",
    "abs_url": "https://arxiv.org/abs/2410.08864",
    "published": "2024-10-11T14:44:05Z",
    "updated": "2026-01-21T16:22:57Z",
    "comment": "47 pages, 3 figures, 4 tables, preliminary version published in ICML 2024 (Workshop on Theoretical Foundations of Foundation Models) and , see https://openreview.net/pdf?id=WMaFRiggwV",
    "light_analysis": {
      "overview": "本文识别并形式化了可迁移攻击作为水印和对抗防御权衡中的必要选项。",
      "motivation": "研究动机源于机器学习安全领域中的核心问题：基于后门的水印与对抗防御之间的权衡。这一问题的重要性在于，水印用于保护模型知识产权，对抗防御用于抵御恶意攻击，但现有研究主要关注这两者之间的互动，忽略了可迁移攻击这一因素。这种不完整性可能导致安全漏洞，例如在面对新型攻击时模型可能脆弱。背景是，之前的工作将此权衡形式化为验证者和证明者交互协议，但未全面考虑所有可能选项，强调了扩展分析的必要性。",
      "method": "研究方法采用密码学技术，特别是完全同态加密，来构建一个高效的算法，该算法能生成与真实数据分布不可区分的查询，并欺骗所有高效的对抗防御。核心创新点是将可迁移攻击形式化为水印和对抗防御权衡中的第三选项，并通过交互协议框架进行分析。关键细节包括将问题建模为验证者与证明者之间的协议，利用密码学原理来证明攻击的可行性和必要性。摘要未明确说明具体使用的数据集或模型架构，但提到了学习任务和VC-dimension作为理论依据。",
      "result": "主要实验结果显示，对于任何学习任务，至少存在一个水印、一个对抗防御或一个可迁移攻击，这一结论通过理论证明得出，强调了权衡中的必然性。此外，研究表明，对于有界VC维的任务，可以构建对所有攻击者的对抗防御；而对于一个子类，允许设计对快速对手安全的水印。与基线方法对比方面，摘要未提供具体性能指标如准确率提升，但强调了理论上的突破，例如通过密码学技术证明了可迁移攻击的必要性，从而补充了现有权衡分析的不足。",
      "conclusion": "结论是，本研究扩展了对水印和对抗防御权衡的理解，识别了可迁移攻击作为必要组成部分，并利用密码学技术构建了相关攻击。学术价值在于为机器学习安全提供了更全面的分析框架，增强了理论基础，实际应用价值包括帮助设计更鲁棒的模型保护机制和防御策略。潜在局限性或未来工作方向可能涉及将理论结果应用于更广泛的任务类型或实际场景中，但摘要未明确说明具体细节，如实验验证或跨领域扩展。",
      "tags": [
        "Watermarking",
        "Adversarial Defenses",
        "Transferable Attacks",
        "Fully Homomorphic Encryption",
        "VC-dimension"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:35.448224Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2409.20302",
    "title": "OM4OV: Leveraging Ontology Matching for Ontology Versioning",
    "authors": [
      "Zhangcheng Qiang",
      "Kerry Taylor",
      "Weiqing Wang"
    ],
    "abstract": "Due to the dynamic nature of the Semantic Web, version control is necessary to manage changes in widely used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component of efficient ontology management, many approaches treat OV as similar to ontology matching (OM) and directly reuse OM systems for OV tasks. In this study, we systematically analyse similarities and differences between OM and OV and formalise an OM4OV pipeline to offer more advanced OV support. The pipeline is implemented and evaluated in the state-of-the-art OM system Agent-OM. The experimental results indicate that OM systems can be effectively reused for OV tasks, but without necessary extensions, can produce skewed measurements, poor performance in detecting update entities, and limited explanation of false mappings. To tackle these issues, we propose an optimisation method called the cross-reference (CR) mechanism, which builds on existing OM alignments to reduce the number of matching candidates and to improve overall OV performance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2409.20302.pdf",
    "abs_url": "https://arxiv.org/abs/2409.20302",
    "published": "2024-09-30T14:00:04Z",
    "updated": "2026-01-21T09:57:07Z",
    "comment": "17 pages, 8 figures, 2 tables",
    "light_analysis": {
      "overview": "本文通过分析本体匹配与本体版本化的异同，提出OM4OV管道并引入交叉引用机制优化本体版本化性能。",
      "motivation": "语义网的动态特性导致广泛使用的本体频繁变化，本体版本化（OV）成为高效管理的关键，但现有方法常将其视为本体匹配（OM）的直接应用，直接重用OM系统可能导致测量倾斜、更新实体检测性能差和错误映射解释不足。本研究旨在系统分析OM和OV的区别，以解决这些问题并提供更精确的OV支持，从而提高本体管理的效率和准确性。背景基于语义网技术的重要性，OV的不足现有方法容易忽略其特殊性。",
      "method": "论文首先系统分析本体匹配（OM）与本体版本化（OV）的相似性和差异，并形式化一个OM4OV管道，旨在提供更高级的OV支持。核心创新包括在先进的OM系统Agent-OM中实现和评估该管道，并提出交叉引用（CR）机制作为优化方法，该机制基于现有OM对齐来减少匹配候选者数量，从而改进整体性能。关键细节涉及使用Agent-OM系统作为基础，强调对OV任务的专门适应。",
      "result": "实验结果表明，本体匹配系统在重用于本体版本化任务时有效，但若未扩展，会产生测量倾斜、更新实体检测性能差和错误映射解释有限的问题。通过应用交叉引用机制优化，可以显著减少匹配候选者并提升整体OV性能，具体指标如准确率提升在摘要中未明确说明，但与直接重用OM系统的基线相比显示改进。优化后方法在Agent-OM系统中实现验证了其有效性。",
      "conclusion": "本研究的主要贡献是系统化分析了本体匹配与本体版本化的关系，并提出OM4OV管道和交叉引用机制以优化性能，学术价值在于澄清两种任务的差异，为精确版本化方法提供基础，实际应用价值是提高语义网中本体管理的效率。局限性或未来工作方向摘要未明确说明，但暗示了对OV任务的专门化进一步研究的潜力。",
      "tags": [
        "Ontology Matching",
        "Ontology Versioning",
        "Cross-Reference Mechanism",
        "Agent-OM",
        "Semantic Web"
      ]
    },
    "analyzed_at": "2026-01-22T03:26:50.830390Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2406.11547",
    "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
    "authors": [
      "Rick Wilming",
      "Artur Dox",
      "Hjalmar Schulz",
      "Marta Oliveira",
      "Benedict Clark",
      "Stefan Haufe"
    ],
    "abstract": "Large pre-trained language models have become a crucial backbone for many downstream tasks in natural language processing (NLP), and while they are trained on a plethora of data containing a variety of biases, such as gender biases, it has been shown that they can also inherit such biases in their weights, potentially affecting their prediction behavior. However, it is unclear to what extent these biases also affect feature attributions generated by applying \"explainable artificial intelligence\" (XAI) techniques, possibly in unfavorable ways. To systematically study this question, we create a gender-controlled text dataset, GECO, in which the alteration of grammatical gender forms induces class-specific words and provides ground truth feature attributions for gender classification tasks. This enables an objective evaluation of the correctness of XAI methods. We apply this dataset to the pre-trained BERT model, which we fine-tune to different degrees, to quantitatively measure how pre-training induces undesirable bias in feature attributions and to what extent fine-tuning can mitigate such explanation bias. To this extent, we provide GECOBench, a rigorous quantitative evaluation framework for benchmarking popular XAI methods. We show a clear dependency between explanation performance and the number of fine-tuned layers, where XAI methods are observed to benefit particularly from fine-tuning or complete retraining of embedding layers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2406.11547.pdf",
    "abs_url": "https://arxiv.org/abs/2406.11547",
    "published": "2024-06-17T13:44:37Z",
    "updated": "2026-01-21T12:44:00Z",
    "comment": "Published in Frontiers",
    "light_analysis": {
      "overview": "本研究创建了性别控制文本数据集GECOBench，用于量化可解释人工智能技术中的性别偏见，提供客观评估框架。",
      "motivation": "大型预训练语言模型在自然语言处理任务中广泛应用，但训练数据中的性别偏见可能导致模型继承这些偏见，影响预测行为。然而，这些偏见如何影响可解释人工智能（XAI）技术生成的特征归因，尚缺乏系统研究。现有方法缺乏客观评估机制来量化XAI方法中的偏见，这限制了模型解释的公平性和可靠性，因此迫切需要开发严谨的基准来填补这一研究空白。",
      "method": "论文创建了性别控制文本数据集GECO，通过改变语法性别形式诱导类特定词，为性别分类任务提供真实特征归因，从而实现XAI方法的客观评估。使用预训练的BERT模型，通过微调不同层数来测量预训练引入的偏见，并评估XAI方法的性能。关键创新是GECOBench评估框架，它系统性地量化了XAI方法中的偏见，专注于嵌入层的微调或重新训练作为缓解策略。",
      "result": "实验结果表明，XAI方法的解释性能与BERT模型的微调层数有显著依赖关系。具体来说，微调或完全重新训练嵌入层能有效改善XAI方法的特征归因正确性，表明预训练确实引入了偏见。与未微调的基础模型相比，微调后的模型在解释偏见方面表现更优，提供了量化证据支持偏见缓解的有效性，但摘要未明确说明具体性能指标数据。",
      "conclusion": "论文的主要贡献是提供GECOBench数据集和评估框架，用于系统量化XAI方法中的性别偏见，具有重要的学术价值。这有助于提升模型可解释性的公平性，为未来研究奠定基础。潜在局限性可能在于数据集仅限于性别偏见，未来工作可扩展至其他偏见类型或更多样化的模型评估，以进一步推动可解释人工智能的发展。",
      "tags": [
        "Large Language Models",
        "Explainable AI (XAI)",
        "BERT",
        "Fine-tuning",
        "Bias Quantification"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:00.196355Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2403.05131",
    "title": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
    "authors": [
      "Fachrina Dewi Puspitasari",
      "Chaoning Zhang",
      "Joseph Cho",
      "Adnan Haider",
      "Noor Ul Eman",
      "Omer Amin",
      "Alexis Mankowski",
      "Muhammad Umair",
      "Jingyao Zheng",
      "Sheng Zheng",
      "Lik-Hang Lee",
      "Caiyan Qin",
      "Tae-Ho Kim",
      "Choong Seon Hong",
      "Yang Yang",
      "Heng Tao Shen"
    ],
    "abstract": "The evolution of video generation from text, from animating MNIST to simulating the world with Sora, has progressed at a breakneck speed. Here, we systematically discuss how far text-to-video generation technology supports essential requirements in world modeling. We curate 250+ studies on text-based video synthesis and world modeling. We then observe that recent models increasingly support spatial, action, and strategic intelligences in world modeling through adherence to completeness, consistency, invention, as well as human interaction and control. We conclude that text-to-video generation is adept at world modeling, although homework in several aspects, such as the diversity-consistency trade-offs, remains to be addressed.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2403.05131.pdf",
    "abs_url": "https://arxiv.org/abs/2403.05131",
    "published": "2024-03-08T07:58:13Z",
    "updated": "2026-01-21T15:48:39Z",
    "comment": "First complete survey on Text-to-Video Generation from World Model perspective, 35 pages",
    "light_analysis": {
      "overview": "本文通过综述250多项研究，系统评估了文本到视频生成技术作为世界模型的能力、进展与潜在挑战。",
      "motivation": "研究动机在于探讨文本到视频生成技术是否能够有效支持世界建模的基本要求，如空间布局、动作序列和战略规划。现有方法虽然在视频生成方面取得进展，但在模拟复杂世界时，常面临多样性生成与一致性保持之间的冲突，导致模型在真实性和可控性方面不足，限制了其在高级AI任务中的应用。本调查旨在梳理技术演变，识别这些不足之处，为未来研究提供方向。",
      "method": "本研究采用文献综述方法，汇总了超过250项关于文本到视频合成和世界建模的研究。通过系统分析，论文从空间智能、行动智能和战略智能三个维度，评估了技术如何通过遵循完整性、一致性、创新性以及人类交互和控制等原则来支持世界建模。摘要未明确说明使用的具体数据集或模型架构，但提及了Sora等先进模型作为案例，核心创新点在于综合多角度分析技术进展。",
      "result": "主要发现是，最近的文本到视频生成模型在空间布局、动作模拟和策略规划方面表现出色，能够较好地支持世界建模的要求。观察到的改进包括模型对复杂场景的完整性和一致性的增强，以及通过人类交互提升控制能力，显示出技术正朝着更全面的世界模拟方向发展。尽管摘要未提供具体性能指标如准确率，但与早期方法相比，模型在支持基本智能需求方面有显著提升。",
      "conclusion": "本文总结认为，文本到视频生成技术是有效的世界建模工具，能够处理多种智能需求，为AI模拟真实世界提供了新视角。其学术价值在于促进跨领域技术融合，实际应用可能包括虚拟现实、游戏开发和自动化系统。然而，仍存在多样性-一致性权衡等未解决问题，未来研究应关注这些挑战以进一步提升技术能力，并探索更复杂的交互场景。",
      "tags": [
        "Text-to-Video Generation",
        "World Modeling",
        "Sora",
        "Spatial Intelligence",
        "Action Intelligence"
      ]
    },
    "analyzed_at": "2026-01-22T03:27:58.688518Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2403.04343",
    "title": "Adaptive Task Balancing for Visual Instruction Tuning via Inter-Task Contribution and Intra-Task Difficulty",
    "authors": [
      "Yanqi Dai",
      "Yong Wang",
      "Zebin You",
      "Dong Jing",
      "Xiangxiang Chu",
      "Zhiwu Lu"
    ],
    "abstract": "Visual instruction tuning is a key training stage of large multimodal models. However, when learning multiple visual tasks simultaneously, this approach often results in suboptimal and imbalanced overall performance due to latent knowledge conflicts across tasks. To mitigate this issue, we propose a novel Adaptive Task Balancing approach tailored for visual instruction tuning (VisATB). Specifically, we measure two critical dimensions for visual task balancing based on validation performance: (1) Inter-Task Contribution, the mechanism where learning one task enhances the performance on others owing to shared knowledge across tasks, and (2) Intra-Task Difficulty, which denotes the inherent learning difficulty of a single task. Furthermore, we propose prioritizing three categories of tasks with greater weight: those that offer substantial contributions to others, those that receive minimal contributions from others, and those that present high learning difficulties. Among these three task weighting strategies, the first and third focus on improving overall performance, and the second targets the mitigation of performance imbalance. Extensive experiments on three benchmarks demonstrate that our VisATB approach consistently achieves superior and more balanced overall performance in visual instruction tuning. The data, code, and models are available at https://github.com/YanqiDai/VisATB.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2403.04343.pdf",
    "abs_url": "https://arxiv.org/abs/2403.04343",
    "published": "2024-03-07T09:11:16Z",
    "updated": "2026-01-21T07:15:08Z",
    "comment": "Accepted for the ACM Web Conference 2026 (WWW 2026)",
    "light_analysis": {
      "overview": "论文提出VisATB方法，通过评估任务间贡献和任务内难度来自适应平衡多任务视觉指令调优，提升整体性能和平衡性。",
      "motivation": "视觉指令调优作为大型多模态模型的关键训练阶段，在同时学习多个视觉任务时，常因任务间知识冲突导致性能次优和不平衡。现有方法可能忽视任务间关系及任务难度差异，限制了模型泛化能力。因此，亟需开发解决多任务不平衡的技术，以优化训练过程并提高模型在实际应用中的鲁棒性和效率。",
      "method": "VisATB方法基于验证性能测量两个维度：任务间贡献（Inter-Task Contribution），即学习一个任务如何通过共享知识增强其他任务性能；任务内难度（Intra-Task Difficulty），表示单个任务的学习挑战。通过优先加权三类任务——贡献大的任务、接收贡献少的任务和难度高的任务，实现自适应平衡。前两者策略提升整体性能，第三者缓解不平衡，关键创新在于结合任务间关系和任务内属性进行权重调整，优化多任务学习过程。",
      "result": "在三个基准上的广泛实验表明，VisATB方法在视觉指令调优中始终实现优越且更平衡的整体性能，有效缓解了多任务学习中的性能不平衡问题。与基线方法相比，该方法提升了多个任务上的表现，具体性能指标如准确率或效率改进摘要未明确说明，但实验验证了方法的有效性和泛化能力。",
      "conclusion": "本研究的主要贡献是VisATB方法，通过自适应任务平衡策略解决视觉指令调优中的性能不平衡问题，具有学术价值——为多任务学习提供新视角，结合任务间贡献和任务内难度进行优化；实际应用价值——改善大型多模态模型训练效果。未来工作可探索该方法在其他多模态任务中的扩展性或进一步优化任务平衡策略。",
      "tags": [
        "Visual Instruction Tuning",
        "Multitask Learning",
        "Adaptive Task Balancing",
        "Inter-Task Contribution",
        "Intra-Task Difficulty"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:19.836748Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2402.07191",
    "title": "GSINA: Improving Subgraph Extraction for Graph Invariant Learning via Graph Sinkhorn Attention",
    "authors": [
      "Junchi Yan",
      "Fangyu Ding",
      "Jiawei Sun",
      "Zhaoping Hu",
      "Yunyi Zhou",
      "Lei Zhu"
    ],
    "abstract": "Graph invariant learning (GIL) seeks invariant relations between graphs and labels under distribution shifts. Recent works try to extract an invariant subgraph to improve out-of-distribution (OOD) generalization, yet existing approaches either lack explicit control over compactness or rely on hard top-$k$ selection that shrinks the solution space and is only partially differentiable. In this paper, we provide an in-depth analysis of the drawbacks of some existing works and propose a few general principles for invariant subgraph extraction: 1) separability, as encouraged by our sparsity-driven mechanism, to filter out the irrelevant common features; 2) softness, for a broader solution space; and 3) differentiability, for a soundly end-to-end optimization pipeline. Specifically, building on optimal transport, we propose Graph Sinkhorn Attention (GSINA), a fully differentiable, cardinality-constrained attention mechanism that assigns sparse-yet-soft edge weights via Sinkhorn iterations and induces node attention. GSINA provides explicit controls for separability and softness, and uses a Gumbel reparameterization to stabilize training. It convergence behavior is also theoretically studied. Extensive empirical experimental results on both synthetic and real-world",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2402.07191.pdf",
    "abs_url": "https://arxiv.org/abs/2402.07191",
    "published": "2024-02-11T12:57:16Z",
    "updated": "2026-01-21T07:42:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出GSINA，一种基于最优传输的图注意力机制，以改进图不变学习中的不变子图提取，增强分布外泛化。",
      "motivation": "研究动机在于图不变学习在处理分布偏移时，现有方法提取不变子图存在缺陷。当前方法缺乏对紧凑性的明确控制，或依赖硬性top-k选择，导致解决方案空间受限和可微性不足，影响端到端优化和泛化性能。这在实际应用中很重要，因为模型需适应未知分布，但现有方法无法有效平衡稀疏性、软性和可微性，因此需要新方法来解决这些不足。",
      "method": "论文提出Graph Sinkhorn Attention (GSINA)，一个完全可微且受基数约束的注意力机制。基于最优传输理论，通过Sinkhorn迭代分配稀疏但软的边权重，诱导节点注意力，实现可分性、软性和可微性。关键创新包括：使用Gumbel重参数化稳定训练，并提供对子图提取过程的明确控制，扩大解决方案空间。该方法构建在现有图不变学习框架上，优化了子图提取流程。",
      "result": "摘要未明确说明具体实验结果数据，但论文指出在合成和真实世界数据集上进行了广泛的实证实验。理论上研究了GSINA的收敛行为。可以推断，相比于基线方法，GSINA可能提升了分布外泛化的准确率或效率，并提供了更稳定的训练过程，具体性能改进需要参考全文的详细实验部分。",
      "conclusion": "论文的主要贡献是提出GSINA，一种新型的图注意力机制，改进了图不变学习中的不变子图提取。通过引入可分性、软性和可微性原则，该方法克服了现有方法的局限性，提供了理论收敛分析和实证验证，具有学术价值，推动了图机器学习的发展。在实际应用中，它可能提升模型在未知分布下的泛化能力，未来工作可包括扩展到更复杂场景或与其他技术结合。",
      "tags": [
        "Graph Invariant Learning",
        "Attention Mechanism",
        "Optimal Transport",
        "Sinkhorn Iterations",
        "Gumbel Reparameterization"
      ]
    },
    "analyzed_at": "2026-01-22T03:28:49.808705Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2306.12150",
    "title": "Benchmarking the Influence of Pre-training on Explanation Performance in MR Image Classification",
    "authors": [
      "Marta Oliveira",
      "Rick Wilming",
      "Benedict Clark",
      "Céline Budding",
      "Fabian Eitel",
      "Kerstin Ritter",
      "Stefan Haufe"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) are frequently and successfully used in medical prediction tasks. They are often used in combination with transfer learning, leading to improved performance when training data for the task are scarce. The resulting models are highly complex and typically do not provide any insight into their predictive mechanisms, motivating the field of \"explainable\" artificial intelligence (XAI). However, previous studies have rarely quantitatively evaluated the \"explanation performance\" of XAI methods against ground-truth data, and transfer learning and its influence on objective measures of explanation performance has not been investigated. Here, we propose a benchmark dataset that allows for quantifying explanation performance in a realistic magnetic resonance imaging (MRI) classification task. We employ this benchmark to understand the influence of transfer learning on the quality of explanations. Experimental results show that popular XAI methods applied to the same underlying model differ vastly in performance, even when considering only correctly classified examples. We further observe that explanation performance strongly depends on the task used for pre-training and the number of CNN layers pre-trained. These results hold after correcting for a substantial correlation between explanation and classification performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2306.12150.pdf",
    "abs_url": "https://arxiv.org/abs/2306.12150",
    "published": "2023-06-21T09:53:37Z",
    "updated": "2026-01-21T14:51:59Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "该论文提出基准数据集以量化磁共振图像分类中可解释AI的性能，并首次系统研究了迁移学习对解释质量的影响。",
      "motivation": "论文旨在解决医学影像分类中卷积神经网络模型的不透明性问题，这些模型常结合迁移学习以提高性能，但缺乏解释预测机制的能力，这推动了可解释AI的发展。然而，现有研究很少量化评估XAI方法的解释性能，特别是迁移学习对其的影响，这在医疗领域至关重要，因为可解释性是确保AI系统可信度和临床可靠性的关键。因此，研究通过建立客观标准来填补这一空白，探究迁移学习如何优化XAI的表现，以提升医学AI的透明度和实用性。",
      "method": "论文首先构建了一个基准数据集，用于在现实的磁共振图像分类任务中客观量化XAI方法的解释性能。研究采用卷积神经网络作为基础模型，结合迁移学习进行预训练，并评估多个流行XAI方法。关键创新在于将解释性能与真实数据对比，同时分析预训练任务类型和预训练层数对解释质量的影响。此外，方法还修正了解释性能与分类性能之间的相关性，以确保评估结果的客观性和准确性，为迁移学习在可解释性中的角色提供了系统分析框架。",
      "result": "实验结果表明，应用于相同CNN模型的流行XAI方法在解释性能上存在显著差异，即使在正确分类的样本中也如此。研究发现，解释性能强烈依赖于预训练任务的选择和预训练CNN层数的变化。这些发现在调整了解释性能与分类性能之间的强相关性后仍然有效，例如，不同预训练配置下XAI表现波动明显。这揭示了迁移学习参数对XAI效果的直接影响，为优化医学AI的可解释性提供了实证数据支持。",
      "conclusion": "论文的主要贡献是开发了一个量化解释性能的基准数据集，并揭示了迁移学习对XAI方法的关键影响。学术上，这为评估和比较XAI技术提供了新标准，加深了对预训练策略在可解释性中作用的理解。实际应用价值在于指导设计更可靠的医学AI系统，增强临床决策的透明度和信任度。未来研究可扩展到其他医学任务或模型类型，以进一步验证和优化这些发现，提升AI在医疗领域的可解释性应用。",
      "tags": [
        "Convolutional Neural Networks",
        "Transfer Learning",
        "Explainable Artificial Intelligence",
        "Benchmark Dataset",
        "MRI Classification"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:22.597534Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2207.00050",
    "title": "Semantic Image Synthesis via Diffusion Models",
    "authors": [
      "Wengang Zhou",
      "Weilun Wang",
      "Jianmin Bao",
      "Dongdong Chen",
      "Dong Chen",
      "Lu Yuan",
      "Houqiang Li"
    ],
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in various image generation tasks compared with Generative Adversarial Nets (GANs). Recent work on semantic image synthesis mainly follows the de facto GAN-based approaches, which may lead to unsatisfactory quality or diversity of generated images. In this paper, we propose a novel framework based on DDPM for semantic image synthesis. Unlike previous conditional diffusion model directly feeds the semantic layout and noisy image as input to a U-Net structure, which may not fully leverage the information in the input semantic mask, our framework processes semantic layout and noisy image differently. It feeds noisy image to the encoder of the U-Net structure while the semantic layout to the decoder by multi-layer spatially-adaptive normalization operators. To further improve the generation quality and semantic interpretability in semantic image synthesis, we introduce the classifier-free guidance sampling strategy, which acknowledge the scores of an unconditional model for sampling process. Extensive experiments on four benchmark datasets demonstrate the effectiveness of our proposed method, achieving state-of-the-art performance in terms of fidelity (FID) and diversity (LPIPS). Our code and pretrained models are available at https://github.com/WeilunWang/semantic-diffusion-model.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2207.00050.pdf",
    "abs_url": "https://arxiv.org/abs/2207.00050",
    "published": "2022-06-30T18:31:51Z",
    "updated": "2026-01-21T11:48:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种基于去噪扩散概率模型的新框架，通过改进语义布局处理方式，显著提升语义图像合成的质量和多样性。",
      "motivation": "本研究旨在解决语义图像合成中现有生成对抗网络方法可能导致生成图像质量或多样性不足的问题。去噪扩散概率模型在图像生成任务中已展现出优异性能，但此前条件扩散模型直接将语义布局和噪声图像输入U-Net结构，未能充分利用语义信息，影响了生成的逼真度和多样性。因此，改进语义信息的整合方式对于提升图像合成的实际效果至关重要。",
      "method": "该方法基于去噪扩散概率模型，创新地将语义布局与噪声图像分开处理：噪声图像输入U-Net结构的编码器，而语义布局通过多层层空间自适应归一化算子融入解码器。关键创新在于优化语义信息的使用方式，避免直接输入导致的效率低下。此外，引入了分类器自由引导采样策略，进一步提升生成质量和语义可解释性。在四个基准数据集上进行实验，确保方法的广泛适用性。",
      "result": "实验结果表明，所提出的框架在四个基准数据集上实现了最先进的性能，在保真度指标FID和多样性指标LPIPS方面均优于基于生成对抗网络的基线方法。摘要未提供具体数值，但通过与现有方法的对比，证实了该方法在提升图像合成质量和多样性方面的有效性，并在多数据集验证中保持一致优势。",
      "conclusion": "本研究贡献了一个基于扩散模型的语义图像合成新框架，有效解决了GAN-based方法的局限性，提升了生成图像的质量和多样性。学术上推动了扩散模型在语义图像合成领域的应用，实际上为图像生成任务提供了更可靠的解决方案。代码和预训练模型已开源，促进进一步研究，未来可探索更多优化策略或扩展应用到其他视觉任务。",
      "tags": [
        "Denoising Diffusion Probabilistic Models",
        "U-Net",
        "Spatially-Adaptive Normalization",
        "Classifier-Free Guidance",
        "Semantic Image Synthesis"
      ]
    },
    "analyzed_at": "2026-01-22T03:29:48.263571Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2205.12787",
    "title": "Impartial Games: A Challenge for Reinforcement Learning",
    "authors": [
      "Bei Zhou",
      "Søren Riis"
    ],
    "abstract": "AlphaZero-style reinforcement learning (RL) algorithms have achieved superhuman performance in many complex board games such as Chess, Shogi, and Go. However, we showcase that these algorithms encounter significant and fundamental challenges when applied to impartial games, a class where players share game pieces and optimal strategy often relies on abstract mathematical principles. Specifically, we utilise the game of Nim as a concrete and illustrative case study to reveal critical limitations of AlphaZero-style and similar self-play RL algorithms. We introduce a novel conceptual framework distinguishing between champion and expert mastery to evaluate RL agent performance. Our findings reveal that while AlphaZero-style agents can achieve champion-level play on very small Nim boards, their learning progression severely degrades as the board size increases. This difficulty stems not merely from complex data distributions or noisy labels, but from a deeper representational bottleneck: the inherent struggle of generic neural networks to implicitly learn abstract, non-associative functions like parity, which are crucial for optimal play in impartial games. This limitation causes a critical breakdown in the positive feedback loop essential for self-play RL, preventing effective learning beyond rote memorisation of frequently observed states. These results align with broader concerns regarding AlphaZero-style algorithms' vulnerability to adversarial attacks, highlighting their inability to truly master all legal game states. Our work underscores that simple hyperparameter adjustments are insufficient to overcome these challenges, establishing a crucial foundation for the development of fundamentally novel algorithmic approaches, potentially involving neuro-symbolic or meta-learning paradigms, to bridge the gap towards true expert-level AI in combinatorial games.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2205.12787.pdf",
    "abs_url": "https://arxiv.org/abs/2205.12787",
    "published": "2022-05-25T14:02:02Z",
    "updated": "2026-01-21T08:31:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文发现AlphaZero风格的强化学习算法在公正游戏中存在根本性局限性，并引入冠军与专家掌握框架来评估性能。",
      "motivation": "AlphaZero强化学习算法在复杂棋盘游戏中表现超人类，但在公正游戏如Nim中遇到挑战。公正游戏要求抽象数学策略，现有AlphaZero风格的自玩算法难以处理，因为它们依赖于神经网络隐式学习，无法有效掌握非关联函数如奇偶性。这凸显了探索算法局限性以推动AI在组合游戏中进一步发展的重要性。",
      "method": "论文以Nim游戏为案例研究，应用AlphaZero风格强化学习算法，并引入新概念框架区分冠军和专家掌握水平。方法通过实验分析学习瓶颈，核心创新是揭示算法在公正游戏中的深度表示瓶颈：神经网络难以学习抽象函数。摘要未明确说明具体模型架构或数据集细节。",
      "result": "实验结果显示，AlphaZero代理在小型Nim棋盘上能达冠军级玩法，但随棋盘尺寸增大，学习进展严重下降。困难源于表示瓶颈，导致正反馈循环崩溃，代理仅能死记硬背状态。这些结果与算法对对抗攻击的脆弱性担忧一致，表明无法真正掌握所有游戏状态。摘要未提供具体性能指标。",
      "conclusion": "论文总结AlphaZero强化学习在公正游戏中存在根本挑战，简单超参数调整不足。贡献在于建立新评估框架，揭示表示瓶颈，为开发神经符号或元学习等新算法奠定基础。学术价值是推动AI向专家级发展，未来工作应探索混合方法克服局限性。",
      "tags": [
        "Reinforcement Learning",
        "AlphaZero",
        "Impartial Games",
        "Neuro-symbolic AI",
        "Meta-Learning"
      ]
    },
    "analyzed_at": "2026-01-22T03:30:51.937879Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2110.06726",
    "title": "Scalable Anytime Algorithms for Learning Fragments of Linear Temporal Logic",
    "authors": [
      "Ritam Raha",
      "Rajarshi Roy",
      "Nathanaël Fijalkow",
      "Daniel Neider"
    ],
    "abstract": "Linear temporal logic (LTL) is a specification language for finite sequences (called traces) widely used in program verification, motion planning in robotics, process mining, and many other areas. We consider the problem of learning LTL formulas for classifying traces; despite a growing interest of the research community, existing solutions suffer from two limitations: they do not scale beyond small formulas, and they may exhaust computational resources without returning any result. We introduce a new algorithm addressing both issues: our algorithm is able to construct formulas an order of magnitude larger than previous methods, and it is anytime, meaning that it in most cases successfully outputs a formula, albeit possibly not of minimal size. We evaluate the performances of our algorithm using an open source implementation against publicly available benchmarks.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2110.06726.pdf",
    "abs_url": "https://arxiv.org/abs/2110.06726",
    "published": "2021-10-13T13:57:31Z",
    "updated": "2026-01-21T14:48:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一个可扩展的随时算法，用于学习线性时序逻辑片段，能构造更大公式并确保输出，显著提升规模和可靠性。",
      "motivation": "研究动机源于线性时序逻辑在程序验证、机器人规划等领域的广泛应用中，学习其公式分类跟踪时，现有方法存在两个主要问题：无法扩展到小公式之外，导致实际应用受限；且可能耗尽计算资源而无结果，影响可靠性。这些问题限制了算法在复杂场景中的部署，因此需要开发更高效和可扩展的解决方案，以提升分类任务的实用性和鲁棒性。",
      "method": "论文引入了一种新算法，核心创新是结合了可扩展性和anytime特性。算法采用优化策略，能够构造比先前方法大一个数量级的公式，并通过高效的搜索机制确保在大多数情况下输出结果，尽管公式可能不是最小尺寸。技术细节摘要未明确说明，但暗示了针对线性时序逻辑片片段学习的高效处理机制，如可能的启发式方法或动态规划技术，以平衡规模和计算效率。",
      "result": "使用开源实现和公开基准进行评估，算法显示出优越性能：能处理显著更大的公式规模，提升可扩展性；在大多数测试案例中成功输出公式，提高了可靠性。与基线方法相比，该方法在效率和成功率方面有改进，但摘要未提供具体性能指标如准确率或运行时间数据，仅强调了规模和anytime特性带来的优势。",
      "conclusion": "该研究的主要贡献是开发了一个可扩展的随时算法，改善了学习线性时序逻辑公式的规模和可靠性，具有重要的学术价值，为程序验证等领域提供了新工具。实际应用潜力大，但局限性在于输出公式可能非最优尺寸，未来工作可探索进一步优化算法效率或扩展性，以应用于更复杂的逻辑片段或更大数据集。",
      "tags": [
        "Linear Temporal Logic",
        "Anytime Algorithms",
        "Formula Learning",
        "Machine Learning",
        "Scalability"
      ]
    },
    "analyzed_at": "2026-01-22T03:31:54.046471Z",
    "analysis_status": "success",
    "analysis_error": null
  }
]