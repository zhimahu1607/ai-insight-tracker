[
  {
    "id": "2602.23363",
    "title": "MediX-R1: Open Ended Medical Reinforcement Learning",
    "authors": [
      "Sahal Shaji Mullappilly",
      "Mohammed Irfan Kurpath",
      "Omair Mohamed",
      "Mohamed Zidan",
      "Fahad Khan",
      "Salman Khan",
      "Rao Anwer",
      "Hisham Cholakkal"
    ],
    "abstract": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23363.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23363",
    "published": "2026-02-26T18:59:46Z",
    "updated": "2026-02-26T18:59:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 MediX-R1，一个基于复合奖励和 LLM 评估的开端强化学习框架，用于提升医学多模态大语言模型在开放式临床任务中的可靠推理能力。",
      "motivation": "医学领域中的多模态大语言模型通常局限于多项选择格式，难以生成开放式、基于临床的答案。现有方法在开放式输出上奖励信号不足，依赖脆弱的字符串重叠评估指标，无法有效捕捉语义变体和推理细节。这限制了模型在真实临床场景中的适用性，因为实际问题往往需要自由形式的回答和语义准确的理解。因此，研究旨在开发一种更全面的奖励设计和评估框架，以克服这些不足，促进可靠医学推理。",
      "method": "研究方法核心是使用 Group Based RL 对基线视觉语言骨干模型进行微调，并设计复合奖励信号：基于 LLM 的准确度奖励通过严格的是/否决策判断语义正确性；基于医学嵌入的语义奖励捕获术语变体和释义；轻量级的格式和模态奖励确保可解释推理和多模态识别。评估框架采用参考型 LLM 作为评判员，替代传统的字符串重叠指标，以全面评估语义正确性、推理过程和上下文对齐。这为开放式输出提供了稳定和信息的反馈。",
      "result": "在仅使用约51K指令示例的情况下，MediX-R1 在标准医学 LLM（纯文本）和 VLM（图像+文本）基准测试中取得优异结果。它显著优于强大的开源基线方法，尤其在开放式临床任务上表现突出，展现出大幅度的性能提升。这些结果表明，该方法在少数据设置下有效，并且通过综合奖励和 LLM 评估，能够提高模型在复杂医学推理任务中的可靠性和准确性。",
      "conclusion": "研究结论表明，开端强化学习结合综合奖励信号和 LLM 评估是实现多模态医学模型可靠推理的实用路径。该框架提供了稳定反馈和语义评估，对医学人工智能应用具有重要学术和实际价值，推动了可靠临床推理的发展。研究的贡献包括开源模型、数据集和代码，促进了社区进步。未来工作可扩展到更多医学任务和数据集，以进一步提升泛化能力和应用范围。",
      "tags": [
        "Reinforcement Learning",
        "Large Language Model",
        "Vision-Language Model",
        "Medical Embedding",
        "Composite Reward"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:53.159724Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23361",
    "title": "VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale",
    "authors": [
      "Sven Elflein",
      "Ruilong Li",
      "Sérgio Agostinho",
      "Zan Gojcic",
      "Laura Leal-Taixé",
      "Qunjie Zhou",
      "Aljosa Osep"
    ],
    "abstract": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23361.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23361",
    "published": "2026-02-26T18:59:33Z",
    "updated": "2026-02-26T18:59:33Z",
    "comment": "CVPR 2026, Project page: https://research.nvidia.com/labs/dvl/projects/vgg-ttt",
    "light_analysis": {
      "overview": "本论文提出了VGG-T^3模型，通过测试时训练将可变长度的KV空间表示转化为固定大小的MLP，实现了离线3D重建的线性扩展。",
      "motivation": "离线前馈3D重建方法面临计算和内存需求随输入图像数量二次方增长的瓶颈，这限制了大尺度应用。由于大规模3D重建在自动驾驶和虚拟现实等领域至关重要，现有方法如基于softmax注意力的基线效率低下，难以处理大量图像，导致可扩展性差，因此需要开发更高效的技术以解决这一实际挑战。",
      "method": "VGG-T^3模型基于关键洞察，即计算瓶颈源于场景几何的可变长度键值（KV）空间表示，通过测试时训练将其蒸馏成固定大小的多层感知器（MLP）。该方法避免了传统softmax注意力机制的二次方计算复杂度，实现了在输入视图数量上的线性扩展。核心创新包括KV空间的提炼和测试时训练的应用，以保留全局场景聚合能力。摘要未明确说明具体数据集和详细模型架构细节。",
      "result": "实验结果表明，VGG-T^3在仅54秒内重建1000张图像的集合，比基于softmax注意力的基线方法快11.6倍。此外，点云重建误差显著优于其他线性时间方法，证明了模型在性能上的优势。摘要未提供具体误差数值，但通过速度提升和误差对比，展示了明显的改进效果。",
      "conclusion": "本论文的主要贡献是提出VGG-T^3模型，有效解决了离线3D重建中的计算和内存瓶颈，实现了线性扩展和高效率。研究具有重要的学术价值，推动了3D重建领域的方法创新，并为实际应用如视觉定位提供了基础。未来工作可进一步优化模型或探索其在其他场景中的应用潜力。",
      "tags": [
        "3D Reconstruction",
        "Test-Time Training",
        "Key-Value Space",
        "Multi-Layer Perceptron",
        "Softmax Attention"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:32.092271Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23360",
    "title": "Model Agreement via Anchoring",
    "authors": [
      "Eric Eaton",
      "Surbhi Goel",
      "Marcel Hussing",
      "Michael Kearns",
      "Aaron Roth",
      "Sikata Bela Sengupta",
      "Jessica Sorrell"
    ],
    "abstract": "Numerous lines of aim to control $\\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies.   We develop a simple general technique for proving bounds on independent model disagreement based on $\\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23360.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23360",
    "published": "2026-02-26T18:59:32Z",
    "updated": "2026-02-26T18:59:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于锚定的通用技术，用于证明机器学习模型在独立训练下的分歧界限，并应用于多种算法以实现分歧趋近于零。",
      "motivation": "该研究旨在解决机器学习中的模型分歧问题，即独立训练模型间预测的不一致性。模型分歧可能影响集成学习效果和预测可靠性，在实际应用中如风险评估或决策支持中尤为重要。现有训练方法常缺乏协调机制，导致分歧不可控，限制了模型一致性的提升。因此，研究者希望通过分析现有训练方法的自然参数，驱动分歧趋近于零，以增强模型稳定性和可预测性。",
      "method": "论文开发了锚定技术，通过分析两个模型平均值的预测来推导独立模型分歧的理论界限。该方法不修改训练过程，适用于现有算法。关键应用包括：堆叠聚合中，增加模型数量k可减少分歧；梯度提升中，迭代次数k使分歧趋零；神经网络架构搜索中，架构规模n优化分歧；回归树训练中，深度d提升一致性。初始分析基于一维回归和平方误差损失，后推广至多维回归和任何强凸损失函数。",
      "result": "通过锚定技术，论文证明了在四种常见机器学习算法中，模型分歧可以随着特定参数的增加而趋近于零。具体而言，堆叠聚合的分歧随模型数量k趋零，梯度提升的分歧随迭代次数k趋零，神经网络架构搜索的分歧随架构大小n趋零，回归树训练的分歧随树深度d趋零。这些理论结果为算法参数的优化提供了保证，表明调整训练参数可有效控制模型不一致性，摘要未明确说明具体实验数据。",
      "conclusion": "本研究贡献了锚定技术作为分析模型分歧的通用框架，并成功应用于多个算法，证明分歧可趋近于零。这丰富了机器学习理论，提供了理解训练过程对模型一致性影响的新视角，有助于设计更可靠的模型集成和训练策略，提升实际应用中的预测稳定性。未来工作可扩展该方法到更多算法或复杂场景，并结合实验验证理论结果。",
      "tags": [
        "Model Disagreement",
        "Anchoring Technique",
        "Stacked Aggregation",
        "Gradient Boosting",
        "Neural Network Architecture Search"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:20.703561Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23359",
    "title": "SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation",
    "authors": [
      "Vaibhav Agrawal",
      "Rishubh Parihar",
      "Pradhaan Bhat",
      "Ravi Kiran Sarvadevabhatla",
      "R. Venkatesh Babu"
    ],
    "abstract": "We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23359.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23359",
    "published": "2026-02-26T18:59:05Z",
    "updated": "2026-02-26T18:59:05Z",
    "comment": "Project page: https://seethrough3d.github.io. Accepted at CVPR 2026",
    "light_analysis": {
      "overview": "本文提出SeeThrough3D模型，通过显式建模对象遮挡，实现精确3D布局控制的文本到图像生成。",
      "motivation": "在3D布局条件文本到图像生成中，遮挡推理对于合成部分遮挡对象、确保深度一致几何和尺度至关重要，但现有方法往往忽略这一方面。现有技术虽然能生成符合布局的现实场景，但难以精确建模对象间的遮挡关系，导致生成图像不够自然。这一问题限制了场景的真实感和3D控制精度，因此需要开发新方法来显式处理遮挡，以提升生成质量和应用价值。",
      "method": "论文提出SeeThrough3D模型，引入遮挡感知3D场景表示（OSCR），将对象表示为透明3D盒子置于虚拟环境，从指定相机视角渲染，透明度编码隐藏区域以推理遮挡。模型基于预训练的基于流的文本到图像生成模型，通过从渲染3D表示派生的视觉token进行条件化。应用masked self-attention机制，准确绑定对象边界框与对应文本描述，避免属性混合。训练使用合成的多对象场景数据集，包含强遮挡以增强模型学习能力。",
      "result": "实验结果摘要未明确说明具体性能指标，如准确率或定量比较。论文指出SeeThrough3D能有效泛化到未见过的对象类别，实现精确的3D布局控制，生成具有现实遮挡和一致相机控制的图像。这暗示了模型在遮挡建模和泛化能力上的潜在优势，但缺乏与基线方法的详细对比数据，如效率改进或具体评估分数。",
      "conclusion": "本研究的主要贡献是提出了SeeThrough3D模型，通过显式建模遮挡，解决了3D布局条件生成中的关键问题，增强了场景生成的深度一致性和真实感。学术价值在于引入了OSCR表示和masked self-attention机制，推动了遮挡感知生成技术的发展；实际应用价值包括改进虚拟现实、游戏开发和图像合成中的3D控制。未来工作可能涉及扩展到更复杂场景、结合现实数据或进一步优化模型性能。",
      "tags": [
        "Occlusion Aware 3D Control",
        "Text-to-Image Generation",
        "3D Scene Representation",
        "Masked Self-Attention",
        "Synthetic Dataset"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:37.795994Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23358",
    "title": "A Dataset is Worth 1 MB",
    "authors": [
      "Elad Kimchi Shoshani",
      "Leeyam Gabay",
      "Yedid Hoshen"
    ],
    "abstract": "A dataset server must often distribute the same large payload to many clients, incurring massive communication costs. Since clients frequently operate on diverse hardware and software frameworks, transmitting a pre-trained model is often infeasible; instead, agents require raw data to train their own task-specific models locally. While dataset distillation attempts to compress training signals, current methods struggle to scale to high-resolution data and rarely achieve sufficiently small files. In this paper, we propose Pseudo-Labels as Data (PLADA), a method that completely eliminates pixel transmission. We assume agents are preloaded with a large, generic, unlabeled reference dataset (e.g., ImageNet-1K, ImageNet-21K) and communicate a new task by transmitting only the class labels for specific images. To address the distribution mismatch between the reference and target datasets, we introduce a pruning mechanism that filters the reference dataset to retain only the labels of the most semantically relevant images for the target task. This selection process simultaneously maximizes training efficiency and minimizes transmission payload. Experiments on 10 diverse datasets demonstrate that our approach can transfer task knowledge with a payload of less than 1 MB while retaining high classification accuracy, offering a promising solution for efficient dataset serving.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23358.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23358",
    "published": "2026-02-26T18:59:03Z",
    "updated": "2026-02-26T18:59:03Z",
    "comment": "23 pages, 9 figures",
    "light_analysis": {
      "overview": "提出了PLADA方法，通过仅传输类标签而非原始像素数据，实现数据集的高效压缩传输，负载小于1 MB。",
      "motivation": "本研究旨在解决数据集服务器向多客户端分发大型数据时的高通信成本问题。由于客户端硬件和软件框架多样化，传输预训练模型不可行，需使用原始数据训练本地任务特定模型。现有数据集蒸馏方法虽然尝试压缩训练信号，但难以扩展到高分辨率数据，且压缩后的文件仍然较大，限制了其实际应用效率，因此开发一种更高效的传输方法至关重要。",
      "method": "论文提出PLADA（Pseudo-Labels as Data）方法，通过仅传输类标签来完全消除像素传输。该方法假设客户端已预加载大型未标记参考数据集（如ImageNet-1K、ImageNet-21K），传输新任务时只发送特定图像的类标签。为克服参考与目标数据集之间的分布不匹配，引入剪枝机制筛选参考数据集，只保留与目标任务最语义相关图像的标签，以最大化训练效率和最小化传输负载。",
      "result": "实验在10个多样化数据集上进行，结果显示PLADA方法能以小于1 MB的传输负载有效传递任务知识，同时保持高分类精度。与现有数据集蒸馏方法相比，该方法在减少数据传输量的基础上，提供了更高效的分类性能，突出了其在降低通信成本方面的优势，但摘要未明确说明具体精度提升数值。",
      "conclusion": "本文的主要贡献是提出了PLADA方法，实现了通过类标签传输的极致数据压缩，具有重要学术价值，为减少分布式学习中的通信开销提供了创新解决方案。在实际应用中，该方法可显著提升数据集服务效率，潜在局限性包括对参考数据集的依赖和扩展到非图像数据的挑战，未来工作可能涉及优化剪枝机制或适应更广泛的数据类型。",
      "tags": [
        "Dataset Distillation",
        "Pruning Mechanism",
        "Pseudo-Labels",
        "Efficient Data Transmission"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:45.748069Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23357",
    "title": "Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training",
    "authors": [
      "Aheli Saha",
      "René Schuster",
      "Didier Stricker"
    ],
    "abstract": "Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23357.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23357",
    "published": "2026-02-26T18:57:52Z",
    "updated": "2026-02-26T18:57:52Z",
    "comment": "12 pages, International Conference on Pattern Recognition Applications and Methods",
    "light_analysis": {
      "overview": "论文通过联合分布训练，研究了事件相机内在参数对对象检测模型性能的影响，以增强传感器无关的鲁棒性。",
      "motivation": "事件相机因其异步和低延迟特性在计算机视觉中受到关注，提供高动态范围并显著减少运动模糊。然而，由于输出信号新颖，可用数据变化性大，且缺乏对信号内在参数的深入分析，这限制了基于事件数据的模型性能，特别是在对象检测任务中。因此，本研究旨在解决这一问题，通过理解参数影响来提升模型的传感器泛化能力，填补现有方法的不足。",
      "method": "论文提出使用联合分布训练方法来分析事件相机内在参数对对象检测模型性能的影响。关键创新点在于建模参数与性能之间的分布关系，以理解如何优化模型对传感器变化的适应性。摘要未明确说明使用的具体数据集或模型架构，但推断该方法可能涉及事件数据预处理和联合优化策略，以实现传感器无关的鲁棒性扩展。",
      "result": "摘要未明确说明具体实验结果或性能指标，因此无法提供准确的数据支撑。论文提及利用发现扩展下游模型的传感器无关鲁棒性，暗示可能通过实验验证了参数分析对模型泛化能力的提升，但缺少与基线方法的对比或具体准确率改进等信息。",
      "conclusion": "论文的主要贡献在于深入分析了事件相机内在参数对对象检测模型的影响，并利用联合分布训练扩展了模型的传感器泛化能力。学术价值体现在填补了事件相机参数研究的空白，促进了自适应传感技术的发展；实际应用价值在于提高事件相机在真实场景中的鲁棒性和适应性。潜在局限性可能包括参数分析的泛化性，未来工作可进一步优化参数设置或应用到其他视觉任务中。",
      "tags": [
        "Event-based Object Detection",
        "Joint Distribution Training",
        "Sensor Generalization",
        "Event Cameras",
        "Adaptive Sensing"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:06.704324Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23353",
    "title": "SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport",
    "authors": [
      "Simon Roschmann",
      "Paul Krzakala",
      "Sonia Mazelet",
      "Quentin Bouniot",
      "Zeynep Akata"
    ],
    "abstract": "The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23353.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23353",
    "published": "2026-02-26T18:55:06Z",
    "updated": "2026-02-26T18:55:06Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "SOTAlign 是一种基于最优传输的半监督对齐框架，通过少量配对数据和大量未配对数据对齐预训练的视觉和语言模型，显著减少监督需求。",
      "motivation": "现有对齐方法依赖于对比损失和数百万配对样本，这在数据收集上成本高昂且不切实际，限制了在真实场景中的应用。Platonic Representation Hypothesis 指出不同模态模型可共享统计模型，但如何高效对齐是关键。本研究探索用更少监督实现有意义的对齐，利用半监督设置解决数据稀缺问题，摘要未明确说明具体应用场景，但强调了减少数据依赖的重要性。",
      "method": "SOTAlign 采用两阶段框架：第一阶段使用线性教师从有限配对数据中恢复粗略的共享几何结构；第二阶段通过基于最优传输的散度在未配对样本上优化对齐，转移关系结构而不过度约束目标空间。核心创新在于结合最优传输处理未配对数据，有效整合视觉和语言模型嵌入，与现有半监督方法不同，利用了未配对图像和文本。",
      "result": "论文结果显示 SOTAlign 在多个数据集和编码器对上显著优于监督和半监督基线方法，摘要未提供具体准确率或效率数据，但强调了方法在学习鲁棒联合嵌入方面的优势。这表明通过利用未配对数据，方法在减少数据需求的同时提升了性能，验证了半监督对齐的有效性。",
      "conclusion": "SOTAlign 的主要贡献是提出了一种新的半监督对齐框架，通过最优传输技术有效利用未配对数据，减少了对齐视觉和语言模型所需的监督量。该研究具有学术价值，推动了多模态对齐领域的发展，并具有实际应用价值，如降低数据标注成本。未来工作可能包括扩展到更多模态或改进算法效率，摘要未明确说明局限性。",
      "tags": [
        "Semi-Supervised Learning",
        "Optimal Transport",
        "Vision-Language Alignment",
        "Unimodal Encoders",
        "Embedding Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:15.792563Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23351",
    "title": "Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning",
    "authors": [
      "Amita Kamath",
      "Jack Hessel",
      "Khyathi Chandu",
      "Jena D. Hwang",
      "Kai-Wei Chang",
      "Ranjay Krishna"
    ],
    "abstract": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., \"at the game today!\" is a more likely caption than \"a photo of 37 people standing behind a field\". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23351.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23351",
    "published": "2026-02-26T18:54:06Z",
    "updated": "2026-02-26T18:54:06Z",
    "comment": "TACL 2026",
    "light_analysis": {
      "overview": "论文揭示了Vision-Language Models推理能力不足的根源在于训练数据的报告偏见，并指出规模不能自动解决这一问题。",
      "motivation": "Vision-Language Models缺乏推理能力是当前AI研究的前沿问题，限制其在复杂任务中的应用。该研究旨在解决这一瓶颈，指出现有方法主要依赖大规模数据训练，但报告偏见导致训练数据中省略了隐含信息，如空间、时间、否定和计数等细节，不足以监督模型学习这些推理技能。因此，理解报告偏见的影响对于开发更有效的VLMs至关重要，避免盲目依赖数据扩展。",
      "method": "研究方法基于语用学理论，分析流行VLM（如OpenCLIP、LLaVA-1.5和Molmo）的训练数据，检测报告偏见对推理技能的抑制。通过设计专门评估空间、时间、否定和计数推理的基准测试，验证模型表现。核心创新在于将语用学与VLM评估结合，首次系统性地从数据偏差角度研究推理能力缺失问题，并利用合成生成和多语言数据进行全面分析。",
      "result": "实验结果表明，VLMs在空间、时间、否定和计数推理任务上表现显著不佳，具体通过基准测试评估准确率较低。尽管训练数据规模庞大或为合成生成，缩放数据大小、模型大小或多语言设置并不会默认带来这些推理能力的涌现。然而，引入专门收集的注释来补充隐含信息能有效提升模型性能，这突显了数据质量的关键作用，而非单纯依赖规模。",
      "conclusion": "结论强调报告偏见是Vision-Language Models推理能力不足的核心因素，仅依靠数据规模无法克服这一限制。研究贡献在于揭示了数据策划的重要性，呼吁开发更故意的训练数据收集方法。这为VLM研究提供了新视角，具有学术价值和对实际应用如智能视觉理解的指导意义，未来工作可专注于改进数据标注策略。",
      "tags": [
        "Vision-Language Models",
        "Reporting Bias",
        "Pragmatics",
        "Spatial Reasoning",
        "Temporal Reasoning"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:16.704772Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23349",
    "title": "FlashOptim: Optimizers for Memory Efficient Training",
    "authors": [
      "Jose Javier Gonzalez Ortiz",
      "Abhay Gupta",
      "Chris Renard",
      "Davis Blalock"
    ],
    "abstract": "Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory.   We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half.   Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23349.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23349",
    "published": "2026-02-26T18:52:22Z",
    "updated": "2026-02-26T18:52:22Z",
    "comment": "Source code is available at https://github.com/databricks/flashoptim",
    "light_analysis": {
      "overview": "FlashOptim通过量化技术将训练内存需求降低超过50%，同时保持模型质量和API兼容性。",
      "motivation": "标准混合精度训练中，每个模型参数占用16字节内存（包括参数、梯度、优化器状态），导致训练大规模模型如70亿参数需要超过100GB内存，这对资源有限的研究者来说难以实现。内存限制严重阻碍了AI研究的进展，现有方法缺乏高效的内存优化方案，使得中小团队无法参与大规模模型开发，因此开发内存高效训练技术具有重要实际意义。",
      "method": "FlashOptim引入两种关键技术：首先，改进主权重分割，通过分析量化误差的严格界限来优化分割策略，减少误差；其次，设计压缩扩展函数，有效降低8位优化器状态量化的误差。结合16位梯度，这些技术将AdamW优化器的内存占用从每个参数16字节减少到7字节（或5字节若释放梯度），保持API兼容性，并应用于SGD、AdamW和Lion等多种优化器。",
      "result": "实验结果显示，FlashOptim将训练内存减少超过50%，具体从每个参数16字节降至7字节（释放梯度后为5字节），模型检查点大小也减少一半以上。在标准视觉和语言基准测试中，包括Llama-3.1-8B模型的微调任务，应用FlashOptim的优化器未出现可测量的质量下降，与基线方法相比性能保持稳定。",
      "conclusion": "本研究的核心贡献在于提出了FlashOptim，一套内存高效的优化器，通过量化技术显著降低训练内存需求，使大规模模型训练对更多研究者变得可行。这不仅具有学术价值，推动了高效训练方法的发展，还具有实际应用价值，有助于降低硬件成本并促进AI研究的普及。未来工作可能包括进一步优化技术或扩展到其他领域。",
      "tags": [
        "Mixed-Precision Training",
        "Quantization",
        "Memory Optimization",
        "AdamW Optimizer",
        "8-bit Quantization"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:15.632039Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23341",
    "title": "Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms",
    "authors": [
      "Alkis Kalavasis",
      "Anay Mehrotra",
      "Manolis Zampetakis",
      "Felix Zhou",
      "Ziyu Zhu"
    ],
    "abstract": "Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is identifiable and the partition consists of only convex sets. Moreover, they showed that without convexity, mean estimation becomes NP-hard. However, two fundamental questions remained open: (1) When is the mean identifiable under convex partitions? (2) Is computationally efficient estimation possible under identifiability and convex partitions? This work resolves both questions. [...]",
    "categories": [
      "cs.LG",
      "cs.DS",
      "math.ST",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23341.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23341",
    "published": "2026-02-26T18:47:06Z",
    "updated": "2026-02-26T18:47:06Z",
    "comment": "Abstract truncated to arXiv limits. To appear in ICLR'26",
    "light_analysis": {
      "overview": "本文解决了在凸分区下高斯均值估计的可识别性条件和计算高效算法问题。",
      "motivation": "粗粒度数据由于测量舍入、传感器限制或经济系统延迟导致样本信息不完整，增加了均值估计的挑战性。现有研究指出在凸分区下可进行样本高效估计，但未明确可识别性的具体条件以及计算效率，这限制了实际应用和理论发展，因此论文旨在填补这些空白。",
      "method": "摘要未明确说明具体研究方法，但基于上下文，论文可能通过数学建模分析凸分区的几何性质，确定均值可识别的条件，并设计高效算法如迭代优化或贪心策略来估计均值，涉及高斯分布假设和统计推断理论。",
      "result": "摘要未明确说明具体实验结果，但论文证明了在凸分区下均值可识别的条件，并提出了计算高效的估计方法，潜在提高了估计精度和效率，与现有基线方法相比可能展示了更好的性能，但没有提供具体数据如准确率或运行时间。",
      "conclusion": "本文的主要贡献是解决了凸分区下高斯均值估计的可识别性和计算效率问题，推动了粗粒度数据统计推断的理论发展，并增强了在传感器网络、经济学等领域的实际应用潜力，未来工作可扩展到非凸分区或更复杂的分布模型。",
      "tags": [
        "Mean Estimation",
        "Coarse Data",
        "Convex Partition",
        "Gaussian Distribution",
        "Statistical Inference"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:15.338874Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23339",
    "title": "Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?",
    "authors": [
      "Tilemachos Aravanis",
      "Vladan Stojnić",
      "Bill Psomas",
      "Nikos Komodakis",
      "Giorgos Tolias"
    ],
    "abstract": "Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories specified by text prompts. Despite recent progress, OVS lags behind fully supervised approaches due to two challenges: the coarse image-level supervision used to train VLMs and the semantic ambiguity of natural language. We address these limitations by introducing a few-shot setting that augments textual prompts with a support set of pixel-annotated images. Building on this, we propose a retrieval-augmented test-time adapter that learns a lightweight, per-image classifier by fusing textual and visual support features. Unlike prior methods relying on late, hand-crafted fusion, our approach performs learned, per-query fusion, achieving stronger synergy between modalities. The method supports continually expanding support sets, and applies to fine-grained tasks such as personalized segmentation. Experiments show that we significantly narrow the gap between zero-shot and supervised segmentation while preserving open-vocabulary ability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23339.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23339",
    "published": "2026-02-26T18:45:33Z",
    "updated": "2026-02-26T18:45:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种基于检索增强测试时间适配器的少样本开放词汇分割方法，通过融合文本和视觉特征，显著缩小监督与零样本分割之间的性能差距。",
      "motivation": "开放词汇分割（OVS）旨在利用视觉语言模型实现基于文本提示的任意类别像素级分割，但现有方法因VLMs训练时依赖粗略图像级监督和自然语言语义模糊性，导致性能落后于完全监督方法。本研究动机是解决这两个关键挑战，通过引入少样本设置，使用少量像素标注图像增强文本提示，以弥补监督不足并提升分割精度，推动OVS在实际应用中的实用性。",
      "method": "该方法构建一个少样本设置，利用支持集包含像素标注图像来增强文本提示，并提出检索增强测试时间适配器。核心创新是学习轻量级、每图像分类器，通过动态融合文本和视觉支持特征实现模态间协同，取代先前依赖手工融合的方法。技术特色包括执行学习的、每查询融合，支持持续扩展支持集，并适用于细粒度任务如个性化分割，摘要未明确说明具体数据集或模型架构。",
      "result": "实验结果显示，该方法显著缩小了零样本分割与完全监督分割之间的性能差距，同时保持了开放词汇能力。尽管摘要未提供具体数据如准确率提升，但与基线方法相比，显示出在分割任务上的明显改进，有效克服了现有OVS方法因监督不足和语义模糊带来的限制，验证了方法的有效性。",
      "conclusion": "本研究贡献在于提出一种少样本开放词汇分割框架，通过检索增强和测试时间适配器改进模态融合机制，解决了监督差距问题。学术价值在于推动了开放词汇分割技术的发展，实际应用价值体现在支持细粒度任务如个性化分割。摘要未明确说明局限性或未来工作方向，但方法为持续扩展支持集提供了可能性。",
      "tags": [
        "Open-Vocabulary Segmentation",
        "Few-Shot Learning",
        "Retrieval-Augmented Learning",
        "Test-Time Adaptation",
        "Vision-Language Models"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:30.201202Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23336",
    "title": "Differentiable Zero-One Loss via Hypersimplex Projections",
    "authors": [
      "Camilo Gomez",
      "Pengyang Wang",
      "Liansheng Tang"
    ],
    "abstract": "Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23336.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23336",
    "published": "2026-02-26T18:41:31Z",
    "updated": "2026-02-26T18:41:31Z",
    "comment": "To appear in PAKDD 2026 (Pacific-Asia Conference on Knowledge Discovery and Data Mining), 12 pages",
    "light_analysis": {
      "overview": "论文提出了一种通过超单纯形投影实现的可微分0-1损失近似方法，称为Soft-Binary-Argmax，以改善分类任务的训练性能。",
      "motivation": "研究动机在于解决分类任务中0-1损失的不可微分性问题。0-1损失被视为黄金标准，能直接评估分类准确性，但由于其不连续性，无法与基于梯度的优化方法兼容。现有方法通常依赖其他可微损失函数（如交叉熵），这可能导致模型目标与任务目标对齐不够紧密。本研究旨在通过引入可微分近似，使0-1损失能集成到端到端可微模型中，从而强化归纳偏置和任务对齐。",
      "method": "方法基于受限优化框架，通过构造平滑且保序的投影到n,k维超单纯形上，实现了可微分的0-1损失近似。核心创新是Soft-Binary-Argmax算子，该算子保持了输出logits的几何一致性。论文推导了该算子的数学性质，并展示了如何高效计算其雅可比矩阵，使其能集成到二进制和多类学习系统中。关键细节包括使用超单纯形投影来确保梯度优化过程中的稳定性。",
      "result": "实验表明，该方法在大批量训练中显著提高了泛化性能，并缩小了传统大批量训练中观察到的性能差距。摘要未明确说明具体的性能指标（如准确率提升百分比），但强调了通过施加几何一致性约束来改善训练效果。与基线方法对比，该方法在大批量设置下表现出更好的收敛性和性能对齐。",
      "conclusion": "研究的主要贡献在于提出了一种可微分0-1损失近似方法，使不可微损失函数适用于梯度优化。学术价值在于为结构化优化组件集成到可微模型提供了新途径，增强了模型归纳偏置。实际应用价值包括提高大规模机器学习系统的训练效率和分类性能。未来工作可能涉及扩展到其他损失函数或更复杂的优化场景。",
      "tags": [
        "Differentiable Optimization",
        "Zero-One Loss",
        "Hypersimplex Projections",
        "Soft-Binary-Argmax",
        "Large-Batch Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:40.887402Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23330",
    "title": "Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks",
    "authors": [
      "Kunihiro Miyazaki",
      "Takanobu Kawahara",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "abstract": "The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock index and the variance of each system's output. This approach achieves superior performance. These findings contribute to the design of agent structure and task configuration when applying LLM agents to trading systems in practical settings.",
    "categories": [
      "cs.AI",
      "q-fin.TR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23330.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23330",
    "published": "2026-02-26T18:37:36Z",
    "updated": "2026-02-26T18:37:36Z",
    "comment": "14 pages, 3 figures",
    "light_analysis": {
      "overview": "本文提出一个多代理大语言模型交易框架，通过细粒度任务分解显著提升金融投资决策的风险调整回报。",
      "motivation": "随着大语言模型的进步，自主金融交易系统快速发展，但主流方法依赖多代理系统模拟分析师和管理员角色时，使用粗粒度的抽象指令，忽视了现实工作流的复杂性。这导致推理性能下降和决策过程不透明，影响系统在实际应用中的有效性。因此，本研究旨在解决这些问题，通过更细致的任务分解来优化多代理系统，以提高决策准确性和透明度，满足金融领域对高效、可靠交易工具的需求。",
      "method": "论文提出一个多代理大语言模型交易框架，核心创新是将投资分析过程明确分解为多个细粒度任务，而不是提供笼统指令。框架利用日本股票市场的多种数据源，包括价格、财务报表、新闻和宏观信息，在严格控制数据泄露的回测设置中进行评估。关键点在于通过代理协作处理特定分析步骤，并结合标准投资组合优化技术，以增强系统输出的利用效率，从而改善整体决策流程。",
      "result": "实验结果显示，细粒度任务分解相比传统粗粒度设计，显著提高了风险调整后的回报率。进一步分析代理中间输出表明，分析结果与下游决策偏好的对齐是系统性能的关键驱动因素。此外，通过标准投资组合优化，利用系统输出与股票指数的低相关性及方差，实现了更优越的整体性能，这些发现验证了框架在实际交易场景中的有效性。",
      "conclusion": "本研究贡献在于设计了一个细粒度任务分解的多代理LLM框架，有效提升了金融交易决策的准确性和透明度，为实际应用中代理结构优化和任务配置提供重要指导。这些发现具有学术价值，推动了多代理系统在复杂领域的应用，未来工作可扩展到更多数据源和代理交互机制，以进一步探索系统局限性和潜在改进方向。",
      "tags": [
        "Multi-Agent System",
        "Large Language Model",
        "Fine-Grained Task Decomposition",
        "Portfolio Optimization",
        "Backtesting"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:04.809982Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23329",
    "title": "LLM Novice Uplift on Dual-Use, In Silico Biology Tasks",
    "authors": [
      "Chen Bo Calvin Zhang",
      "Christina Q. Knight",
      "Nicholas Kruus",
      "Jason Hausenloy",
      "Pedro Medeiros",
      "Nathaniel Li",
      "Aiden Kim",
      "Yury Orlovskiy",
      "Coleman Breen",
      "Bryce Cai",
      "Jasper Götting",
      "Andrew Bo Liu",
      "Samira Nedungadi",
      "Paula Rodriguez",
      "Yannis Yiming He",
      "Mohamed Shaaban",
      "Zifan Wang",
      "Seth Donoughe",
      "Julian Michael"
    ],
    "abstract": "Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23329.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23329",
    "published": "2026-02-26T18:37:23Z",
    "updated": "2026-02-26T18:37:23Z",
    "comment": "59 pages, 33 figures",
    "light_analysis": {
      "overview": "本研究发现大型语言模型能显著提升新手在生物学任务中的准确性，甚至优于专家，并凸显双重用途风险评估的重要性。",
      "motivation": "研究动机在于探讨大型语言模型是否真正提升新手用户在生物学任务中的表现，而非仅依赖互联网资源。这一问题至关重要，因为它直接关系到科学加速的可能性和双重用途风险的管理。现有方法往往只关注模型在传统基准测试上的性能，忽略了人类用户在实际使用中的提升效果，导致对LLMs实际应用价值的评估不足，因此需要通过人类互动研究来补充传统评估。",
      "method": "研究方法采用多模型和多基准的人类提升研究，比较了新手在拥有LLM访问权限与仅互联网访问权限下的表现。研究覆盖了八个生物安全相关的任务集，参与者处理复杂问题并拥有充足时间（最长13小时）。创新点在于将评估从模型性能扩展到人类交互效果，并使用专家基线作为对比，以量化和理解LLMs在实际任务中的提升作用。",
      "result": "实验结果显示，LLM访问使新手的准确性提升了4.16倍（95%置信区间[2.63, 6.87]）。在四个有专家基线的基准测试中，新手在三个任务上超越了专家。有趣的是，独立LLMs经常表现优于LLM辅助的新手，表明用户未充分挖掘模型潜力。此外，89.6%的参与者报告获取双重用途信息无困难，突显了安全措施的有效性挑战。",
      "conclusion": "结论指出，LLMs能大幅提升新手在生物学任务中的表现，减少了对专业训练的依赖，具有重要的科学应用价值。研究强调需要持续的、交互式提升评估来补充传统基准测试，以更好地管理双重用途风险。未来工作可包括优化用户与LLMs的交互策略以最大化效果，并加强安全协议来降低潜在风险。",
      "tags": [
        "Large Language Models",
        "Human Uplift Study",
        "Benchmark Evaluation",
        "Dual-Use Risk",
        "In Silico Biology"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:57.051784Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23320",
    "title": "ParamMem: Augmenting Language Agents with Parametric Reflective Memory",
    "authors": [
      "Tianjun Yao",
      "Yongqiang Chen",
      "Yujia Zheng",
      "Pan Li",
      "Zhiqiang Shen",
      "Kun Zhang"
    ],
    "abstract": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential of ParamMem as an effective component for enhancing language agents.",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23320.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23320",
    "published": "2026-02-26T18:28:04Z",
    "updated": "2026-02-26T18:28:04Z",
    "comment": "20 pages",
    "light_analysis": {
      "overview": "论文提出ParamMem参数化内存模块，通过温度控制采样增强语言代理的反射多样性，从而提升推理性能。",
      "motivation": "语言代理的自反思能力在迭代优化解决方案时常产生重复输出，限制了推理性能的提升。现有研究尝试增加反射多样性以应对此问题，实证分析显示反射多样性与任务成功呈正相关，突显了多样化反射信号的重要性。然而，当前方法在生成稳定且多样化的反射方面仍有不足，导致代理解决方案不够高效，需要更有效的机制来克服重复性问题。",
      "method": "研究方法核心是引入ParamMem参数化内存模块，它将跨样本的反射模式编码到模型参数中，通过温度控制采样实现多样化反射生成。基于此模块，提出ParamAgent框架，集成参数化内存、情景内存和跨样本内存，以增强代理的反思能力。实验在代码生成、数学推理和多跳问答任务上进行，具体模型架构如语言代理细节摘要未明确说明，但强调了跨样本记忆的应用。",
      "result": "实验结果表明，在代码生成、数学推理和多跳问答任务上，ParamMem consistently improved over state-of-the-art baselines，显示出持续的性能提升，具体指标如准确率摘要未明确说明。进一步分析显示，ParamMem具有样本高效性，支持从弱模型到强模型的跨尺度迁移，并能实现自我改进，无需依赖外部强模型。与基线方法对比，它在多个任务中表现优越。",
      "conclusion": "论文的主要贡献是提出ParamMem参数化内存模块，有效增强了语言代理的反射多样性，提升了推理能力。研究具有学术价值，为自反思机制提供了新思路；实际应用中，ParamMem可作为组件集成到现有代理系统，支持样本高效和弱到强迁移。潜在局限性或未来工作方向摘要未明确说明，但可推断包括扩展到更复杂任务或优化内存效率。",
      "tags": [
        "Parametric Memory",
        "Reflective Memory",
        "Language Agents",
        "Temperature-controlled Sampling",
        "Cross-sample Memory"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:58.466464Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23318",
    "title": "Generalized Rapid Action Value Estimation in Memory-Constrained Environments",
    "authors": [
      "Aloïs Rautureau",
      "Tristan Cazenave",
      "Éric Piette"
    ],
    "abstract": "Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23318.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23318",
    "published": "2026-02-26T18:25:59Z",
    "updated": "2026-02-26T18:25:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了GRAVE2、GRAVER和GRAVER2算法，通过两级搜索和节点回收技术，在减少内存使用的同时保持游戏强度。",
      "motivation": "GRAVE算法作为Monte-Carlo Tree Search家族中的变体，在通用游戏玩法中表现出色，但其依赖在每个节点存储额外赢/访问统计数据，导致在内存受限环境中不实用。这一问题限制了算法在实际应用中的部署，尤其是在资源有限的设备上。现有方法的不足在于高内存消耗，阻碍了其在真实世界场景如移动设备或嵌入式系统的使用。",
      "method": "论文提出了GRAVE2、GRAVER和GRAVER2算法，它们分别通过两级搜索技术、节点回收方法以及两者的组合来扩展原始GRAVE算法。这些方法旨在减少存储节点的数量，从而提高内存效率。关键创新点包括优化搜索过程以减少内存占用，并通过节点回收重复利用已访问的节点来降低存储需求。具体技术路线基于GRAVE框架，但在内存管理上进行了改进。",
      "result": "结果表明，这些新算法显著减少了存储节点数量，同时匹配了原始GRAVE算法的游戏强度。摘要未明确说明具体性能数据（如准确率或效率指标），但强调了改进是显著的，并与基线GRAVE进行了对比，展示了在内存使用上的优势。",
      "conclusion": "该研究通过提出内存高效的GRAVE变体，扩展了算法在资源受限环境中的应用。主要贡献在于提高了GRAVE的实用性和可扩展性，具有实际应用价值。未来工作方向可能包括进一步优化算法效率或在更广泛领域中的部署。",
      "tags": [
        "Monte-Carlo Tree Search",
        "General Game Playing",
        "GRAVE",
        "Node Recycling",
        "Two-Level Search"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:07.495247Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23315",
    "title": "Invariant Transformation and Resampling based Epistemic-Uncertainty Reduction",
    "authors": [
      "Sha Hu"
    ],
    "abstract": "An artificial intelligence (AI) model can be viewed as a function that maps inputs to outputs in high-dimensional spaces. Once designed and well trained, the AI model is applied for inference. However, even optimized AI models can produce inference errors due to aleatoric and epistemic uncertainties. Interestingly, we observed that when inferring multiple samples based on invariant transformations of an input, inference errors can show partial independences due to epistemic uncertainty. Leveraging this insight, we propose a \"resampling\" based inferencing that applies to a trained AI model with multiple transformed versions of an input, and aggregates inference outputs to a more accurate result. This approach has the potential to improve inference accuracy and offers a strategy for balancing model size and performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23315.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23315",
    "published": "2026-02-26T18:22:40Z",
    "updated": "2026-02-26T18:22:40Z",
    "comment": "5 pages, 5 figures",
    "light_analysis": {
      "overview": "论文提出一种基于不变变换和重采样来减少认知不确定性、提高AI模型推理准确性的方法。",
      "motivation": "AI模型在推理时常常因偶然和认知不确定性而产生错误，影响了其可靠性和性能。现有方法即使在模型优化后也难以完全消除这些不确定性，导致推理精度受限。作者观察到，当对输入进行不变变换并多次推理时，认知不确定性导致的错误表现出部分独立性，这为解决该问题提供了新思路。因此，研究旨在利用这一特性开发更准确的推理策略，以提升模型在实际应用中的表现。",
      "method": "该方法涉及对输入应用不变变换生成多个版本，然后使用预训练的AI模型分别对这些版本进行推理。关键创新在于通过重采样（即多次推理并聚合输出）来减少认知不确定性的影响。具体技术特色包括利用变换输入的多样性来捕获错误独立性，并将多个推理结果聚合以得到更准确输出。摘要未明确说明使用的具体模型架构或数据集，但强调了该方法适用于任何训练好的AI模型。",
      "result": "论文指出该方法有潜力提高推理准确性，并可能帮助平衡模型大小和性能。具体实验数据如准确率提升或效率改进未在摘要中说明，但理论分析表明它能有效减少认知不确定性带来的错误。与基线方法相比，摘要中未提供直接对比，但暗示了通过聚合输出可以优化推理结果。",
      "conclusion": "该研究的主要贡献是提出了一种利用不变变换和重采样减少认知不确定性的新方法，从而提高了AI模型的推理精度。学术上，它为不确定性处理提供了新视角，促进了AI模型的可靠性研究；实际上，有助于优化模型性能，可能减少对大型模型的需求。潜在局限性包括对变换类型的依赖，未来工作可探索不同变换策略和更复杂的聚合方法。",
      "tags": [
        "Invariant Transformation",
        "Resampling",
        "Epistemic Uncertainty",
        "AI Inference",
        "Uncertainty Reduction"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:06.727154Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23306",
    "title": "ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding",
    "authors": [
      "Yiran Guan",
      "Sifan Tu",
      "Dingkang Liang",
      "Linghao Zhu",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Jian Luan",
      "Yuliang Liu",
      "Xiang Bai"
    ],
    "abstract": "Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasoning models (LRM). However, enhancing the reasoning ability of OLLMs through additional training presents significant challenges, including the need for high-quality data, task-specific adaptation, and substantial computational costs. To address these limitations, we propose ThinkOmni, a training-free and data-free framework that lifts textual reasoning to omni-modal scenarios. ThinkOmni introduces two key components: 1) LRM-as-a-Guide, which leverages off-the-shelf LRMs to guide the OLLM decoding process; 2) Stepwise Contrastive Scaling, which adaptively balances perception and reasoning signals without manual hyperparameter tuning. Experiments on six multi-modal reasoning benchmarks demonstrate that ThinkOmni consistently delivers performance improvements, with main results achieving 70.2 on MathVista and 75.5 on MMAU. Overall, ThinkOmni offers a flexible and generalizable solution for omni-modal reasoning and provides new insights into the generalization and application of reasoning capabilities.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23306.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23306",
    "published": "2026-02-26T18:10:41Z",
    "updated": "2026-02-26T18:10:41Z",
    "comment": "Accept by ICLR 2026",
    "light_analysis": {
      "overview": "论文提出了ThinkOmni，一个无需额外训练和数据的框架，通过指导解码将文本推理能力提升到全模态场景。",
      "motivation": "全模态推理对于智能系统理解和从多样数据源中推理至关重要。现有全模态大语言模型（OLLMs）在感知不同模态方面表现良好，但缺乏大型推理模型（LRMs）的复杂推理能力。然而，通过额外训练增强OLLMs的推理能力面临显著挑战，如需要高质量数据、任务特定适应和大量计算成本，这突显了开发无需训练和数据的解决方案以克服现有方法资源消耗和适应性不足的重要性。",
      "method": "ThinkOmni框架包括两个核心组件：LRM-as-a-Guide，利用现成的大型推理模型指导全模态大语言模型的解码过程；Stepwise Contrastive Scaling，通过逐步对比缩放自适应地平衡感知和推理信号，无需手动超参数调优。该方法无需额外训练或数据，直接通过解码优化提升推理能力。",
      "result": "在六个多模态推理基准上的实验表明，ThinkOmni持续带来性能提升，具体在MathVista基准上得分70.2，在MMAU基准上得分75.5。与基线方法相比，ThinkOmni展示了显著的改进，尽管摘要未明确说明对比细节，但整体性能表现优越。",
      "conclusion": "论文的主要贡献是提出了ThinkOmni，一个灵活且可推广的全模态推理解决方案，无需额外训练和数据。研究不仅提升了全模态大语言模型的推理能力，还为推理能力的泛化和应用提供了新见解，未来工作可能涉及框架优化和扩展到更多模态或任务。",
      "tags": [
        "Omni-modal Large Language Model",
        "Large Reasoning Model",
        "Guidance Decoding",
        "Stepwise Contrastive Scaling"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:20.143251Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23305",
    "title": "A Proper Scoring Rule for Virtual Staining",
    "authors": [
      "Samuel Tonks",
      "Steve Hood",
      "Ryan Musso",
      "Ceridwen Hopely",
      "Steve Titus",
      "Minh Doan",
      "Iain Styles",
      "Alexander Krull"
    ],
    "abstract": "Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell. However, when evaluating a VS model, the true posterior is unavailable. Existing evaluation protocols only check the accuracy of the marginal distribution over the dataset rather than the predicted posteriors. We introduce information gain (IG) as a cell-wise evaluation framework that enables direct assessment of predicted posteriors. IG is a strictly proper scoring rule and comes with a sound theoretical motivation allowing for interpretability, and for comparing results across models and features. We evaluate diffusion- and GAN-based models on an extensive HTS dataset using IG and other metrics and show that IG can reveal substantial performance differences other metrics cannot.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23305.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23305",
    "published": "2026-02-26T18:09:49Z",
    "updated": "2026-02-26T18:09:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文引入信息增益（IG）作为评估虚拟染色模型预测后验分布的严格适当评分规则，解决了现有评估方法的局限性。",
      "motivation": "在虚拟染色（VS）模型的高通量筛选（HTS）应用中，模型为每个输入和细胞提供预测的后验分布，以估计可能的生物特征值。然而，由于真实的后验分布不可获得，现有评估协议仅关注数据集的边际分布准确性，而忽略了直接评估预测后验分布。这导致模型性能评估不全面，无法准确比较不同模型和特征的预测质量，限制了虚拟染色技术在生物学研究和药物发现中的可靠性和实用性，因此亟需一种新的评估框架来弥补这一缺陷。",
      "method": "论文提出使用信息增益（IG）作为单元级评估框架，它是一种严格适当的评分规则，基于信息理论，能够直接评估虚拟染色模型预测的后验分布。IG具有坚实的理论动机，支持可解释的结果，并允许在不同模型（如基于扩散和生成对抗网络（GAN）的模型）和特征之间进行比较。方法在广泛的高通量筛选（HTS）数据集上实施，应用IG评估这些模型的预测性能，同时对比其他传统评估指标，以凸显IG的技术特色和创新点。",
      "result": "在广泛的高通量筛选（HTS）数据集上进行实验，使用信息增益（IG）及其他指标评估了基于扩散和生成对抗网络（GAN）的虚拟染色模型。结果表明，IG能够揭示其他评估指标无法检测到的显著性能差异，突显了IG在准确评估模型预测后验分布方面的敏感性和优势。尽管摘要未提供具体准确率提升数据，但强调了IG在模型比较中的有效性，为优化虚拟染色模型提供了更全面的性能评估基准，与基线方法相比，IG更能识别模型弱点。",
      "conclusion": "论文的主要贡献是引入了信息增益（IG）作为一种严格适当的评分规则，专门用于评估虚拟染色模型的预测后验分布。这解决了现有评估方法的不足，通过理论框架增强了评估的可解释性和可比性，对虚拟染色和高通量筛选领域具有重要学术和实际应用价值。研究促进了更准确的模型评估和比较，未来工作可以扩展到其他生成模型的评估中，并进一步验证IG在更广泛数据集上的泛化能力和潜在局限性，以推动相关技术的发展。",
      "tags": [
        "Virtual Staining",
        "Information Gain",
        "Proper Scoring Rule",
        "Diffusion Models",
        "GANs"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:52.080593Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23303",
    "title": "Inferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implications",
    "authors": [
      "Ilya Balabin",
      "Thomas M. Kaiser"
    ],
    "abstract": "Machine learning techniques are now routinely encountered in research laboratories across the globe. Impressive progress has been made through ML and AI techniques with regards to large data set processing. This progress has increased the ability of the experimenter to digest data and make novel predictions regarding phenomena of interest. However, machine learning predictors generated from data sets taken from the natural sciences are often treated as black boxes which are used broadly and generally without detailed consideration of the causal structure of the data set of interest. Work has been attempted to bring causality into discussions of machine learning models of natural phenomena; however, a firm and unified theoretical treatment is lacking. This series of three papers explores the union of chemical theory, biological theory, probability theory and causality that will correct current causal flaws of machine learning in the natural sciences. This paper, Part 1 of the series, provides the formal framework of the foundational causal structure of phenomena in chemical biology and is extended to machine learning through the novel concept of focus, defined here as the ability of a machine learning algorithm to narrow down to a hidden underpinning mechanism in large data sets. Initial proof of these principles on a family of Akt inhibitors is also provided. The second paper containing Part 2 will provide a formal exploration of chemical similarity, and Part 3 will present extensive experimental evidence of how hidden causal structures weaken all machine learning in chemical biology. This series serves to establish for chemical biology a new kind of mathematical framework for modeling mechanisms in Nature without the need for the tools of reductionism: inferential mechanics.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23303.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23303",
    "published": "2026-02-26T18:09:16Z",
    "updated": "2026-02-26T18:09:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种新的形式框架，通过引入“focus”概念将因果结构整合到化学生物学的机器学习中，纠正黑盒子问题。",
      "motivation": "机器学习在自然科学如化学生物学中广泛应用，但现有方法常将模型视为黑盒子，忽视数据因果结构，导致预测解释性差和可靠性不足。尽管有研究尝试引入因果关系，但缺乏统一的理论框架，阻碍了深入理解和应用。因此，本研究旨在解决这一问题，建立坚实的因果理论，以提升机器学习在复杂科学现象中的建模能力。",
      "method": "本文构建了一个形式框架，整合化学理论、生物学理论和概率论，并引入新概念“focus”，定义为机器学习算法在大型数据集中缩小到隐藏底层机制的能力。该框架旨在描述化学生物学现象的基础因果结构，并将其扩展到机器学习应用中。研究以Akt抑制剂家族为例进行了初步验证，展示了框架的实际应用和理论推导。",
      "result": "摘要未明确说明具体实验结果细节，但提到在Akt抑制剂家族上提供了初步证明，表明所提出的框架能够识别因果机制。缺乏与基线方法的对比和具体性能指标如准确率，因此结果主要基于理论阐述和初步实证，显示了框架的潜在有效性。",
      "conclusion": "本文作为系列论文的第一部分，提出了“inferential mechanics”新框架，旨在为化学生物学提供一种无需还原论工具的因果机制建模方法。核心贡献是整合多学科理论，引入“focus”概念，纠正机器学习中的因果缺陷，具有重要学术价值，并为未来研究（如化学相似性和实验证据探索）奠定基础。",
      "tags": [
        "Causality",
        "Machine Learning",
        "Chemical Biology",
        "Inferential Mechanics",
        "Focus"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:38.320627Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23302",
    "title": "The logic of KM belief update is contained in the logic of AGM belief revision",
    "authors": [
      "Giacomo Bonanno"
    ],
    "abstract": "For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $>$ and the unimodal necessity operator $\\square$. We then compare the resulting logic to the similar logic obtained from converting the AGM axioms of belief revision into modal axioms and show that the latter contains the former. Denoting the latter by $\\mathcal L_{AGM}$ and the former by $\\mathcal L_{KM}$ we show that every axiom of $\\mathcal L_{KM}$ is a theorem of $\\mathcal L_{AGM}$. Thus AGM belief revision can be seen as a special case of KM belief update. For the strong version of KM belief update we show that the difference between $\\mathcal L_{KM}$ and $\\mathcal L_{AGM}$ can be narrowed down to a single axiom, which deals exclusively with unsurprising information, that is, with formulas that were not initially disbelieved.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23302.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23302",
    "published": "2026-02-26T18:09:02Z",
    "updated": "2026-02-26T18:09:02Z",
    "comment": "arXiv admin note: text overlap with arXiv:2310.11506. text overlap with arXiv:2310.11506",
    "light_analysis": {
      "overview": "论文证明AGM信仰修订的逻辑包含KM信仰更新的逻辑，统一了两种信仰更新方法的理论基础。",
      "motivation": "在人工智能和逻辑学领域，信仰更新和修订是处理动态知识变化的核心问题。KM信仰更新和AGM信仰修订是两种主流方法，但它们的逻辑关系尚未清晰，可能导致实际应用中的不一致性。本研究旨在通过模态逻辑框架，比较两者的逻辑基础，解决现有方法在理论统一上的不足，提升推理系统的稳健性。摘要未明确说明具体应用场景，但强调了逻辑比较的重要性。",
      "method": "研究方法包括构建一个模态逻辑系统，包含三个模态运算符：单模态信仰运算符B、双模态条件运算符>和单模态必然运算符□。首先，将KM信仰更新的公理映射到该逻辑中的对应公理，形成逻辑L_KM。然后，将AGM信仰修订的公理转换为类似模态公理，得到逻辑L_AGM。通过逻辑推导和比较，分析L_AGM与L_KM的关系。关键创新在于使用模态逻辑来表示信仰更新，并建立公理之间的精确映射。",
      "result": "主要实验结果显示，逻辑L_AGM包含逻辑L_KM，即KM信仰更新的每个公理在AGM逻辑中都是定理。这证实了AGM信仰修订是KM信仰更新的特殊情形。对于KM的强版本，研究进一步表明，两者的差异可归结为一个单一公理，该公理专门处理不令人惊讶的信息（即最初不被怀疑的公式），从而细化了逻辑包含关系。与基线方法的对比基于逻辑推导，未涉及具体性能指标，但强化了理论一致性。",
      "conclusion": "论文的主要贡献是确立了AGM信仰修订作为KM信仰更新的逻辑子集，揭示了两种方法的内在关系。学术上，这统一了信仰更新理论，推动了逻辑学在AI中的应用；实际价值在于为设计更可靠的推理系统提供理论基础。局限性在于研究集中于逻辑层面，未涉及具体算法或数据集验证。未来工作可扩展到其他信仰更新方法的逻辑分析或实证应用。",
      "tags": [
        "Modal Logic",
        "Belief Update",
        "Belief Revision",
        "Axiomatic System",
        "Logical Containment"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:43.247363Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23300",
    "title": "A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations",
    "authors": [
      "Soumya Dutta",
      "Smruthi Balaji",
      "Sriram Ganapathy"
    ],
    "abstract": "Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach.",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23300.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23300",
    "published": "2026-02-26T18:08:40Z",
    "updated": "2026-02-26T18:08:40Z",
    "comment": "Accepted to Elsevier Computer Speech and Language. 30 pages, 9 figures, 5 tables",
    "light_analysis": {
      "overview": "提出混合专家框架MiSTER-E，通过解耦模态特定上下文建模和多模态信息融合，提升对话中多模态情感识别的性能。",
      "motivation": "对话情感识别（ERC）需同时处理多轮对话的时间动态和多模态（如语音、文本）信息集成，但现有方法常难以有效结合这些线索，导致识别精度受限。本研究针对这些挑战，旨在开发一个更健壮的ERC模型，以更好地捕捉情感变化，弥补现有融合和上下文建模的不足，提升实际应用中的可靠性。",
      "method": "本研究提出MiSTER-E框架，一个模块化混合专家（MoE）模型。方法包括：首先微调大型语言模型（LLMs）为语音和文本生成utterance级嵌入，再通过卷积-循环层增强上下文建模；然后整合三个专家（仅语音、仅文本、跨模态）的预测，使用学习到的门控机制动态加权输出；此外引入监督对比损失和KL散度正则化，以促进模态间对齐，且不依赖说话者身份。创新点在于解耦模态特定与融合任务，结合门控和正则化技术优化性能。",
      "result": "在IEMOCAP、MELD和MOSI三个基准数据集上，MiSTER-E分别达到70.9%、69.5%和87.9%的加权F1分数，优于多个基线语音-文本ERC系统。消融研究突出了框架组件的贡献，如门控机制和对比损失对性能提升的关键作用，验证了通过解耦挑战和有效融合多模态信息，模型能显著改进情感识别精度，显示出强鲁棒性和可扩展性。",
      "conclusion": "本研究贡献在于提出MiSTER-E框架，通过混合专家模型解耦ERC核心挑战，实现了更准确的多模态情感识别。学术上为多模态对话分析提供新方法；实际上可应用于对话系统、情感交互等领域。局限性方面，摘要未明确说明未来工作方向，但框架的模块化和无说话者依赖特性为扩展至其他模态或场景奠定基础，具有较高的实用价值。",
      "tags": [
        "Mixture-of-Experts",
        "Large Language Models",
        "Contrastive Learning",
        "KL-divergence regularization",
        "Multimodal Emotion Recognition"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:52.711083Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23297",
    "title": "PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM",
    "authors": [
      "Yiqing Wang",
      "Chunming He",
      "Ming-Chen Lu",
      "Mercy Pawar",
      "Leslie Niziol",
      "Maria Woodward",
      "Sina Farsiu"
    ],
    "abstract": "Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata. However, existing methods often treat metadata as isolated tags, failing to exploit the rich semantic knowledge embedded in clinical descriptions. We propose PRIMA (Pre-training with Risk-integrated Image-Metadata Alignment), a framework that integrates domain-specific knowledge into multi-modal representation learning. We first curate an expert corpus of risk-disease correlations via Retrieval-Augmented Generation (RAG) to refine Clinical ModernBERT, embedding diagnostic priors into the text encoder. To bridge the modality gap, we introduce a dual-encoder pre-training strategy utilizing DINOv3 and our refined BERT, optimized by a suite of four complementary loss functions. These losses are designed to capture multi-granular semantic alignment and handle the ambiguity of clinical correlations through soft labels. Finally, we leverage Qwen-3 to fuse these aligned features for precise disease classification. Extensive experiments demonstrate that PRIMA effectively harmonizes pixel-level features with abstract clinical expertise, significantly outperforming other state-of-the-art methods. Notably, our framework achieves superior robustness without the need for massive data collection or exhaustive computational resources. Our code will be made public upon acceptance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23297.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23297",
    "published": "2026-02-26T18:07:52Z",
    "updated": "2026-02-26T18:07:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "PRIMA框架通过预训练集成风险与图像-元数据对齐，利用大语言模型显著提升医疗诊断的准确性和鲁棒性。",
      "motivation": "医疗诊断需有效综合视觉图像和临床元数据，但现有方法常将元数据视为孤立标签，未能利用临床描述中的丰富语义知识，导致诊断效果受限。这一问题重要性在于准确诊断依赖多模态信息整合，现有方法未充分挖掘临床先验，限制了性能。因此，研究旨在解决如何更好地融合图像和元数据以改进诊断。",
      "method": "论文提出PRIMA框架，首先通过检索增强生成(RAG)策划风险-疾病相关性专家语料库，优化Clinical ModernBERT文本编码器以嵌入诊断先验。为桥接模态间隙，采用DINOv3和优化BERT的双编码器预训练策略，通过四个互补损失函数优化，捕获多粒度语义对齐并使用软标签处理临床相关性的模糊性。最后，利用Qwen-3融合对齐特征进行精确疾病分类。",
      "result": "实验表明PRIMA有效调和像素级图像特征与抽象临床专业知识，在医疗诊断任务中显著优于其他最先进方法。框架实现了优越的鲁棒性，且无需大量数据收集或高计算资源消耗。摘要未明确说明具体性能指标如准确率提升，但强调了对基线方法的显著优势。",
      "conclusion": "PRIMA的主要贡献在于提出一个集成领域特定知识的多模态表示学习框架，通过风险集成和图像-元数据对齐提升医疗诊断。其学术价值体现在融合临床先验和自监督学习，实际应用上提高诊断准确性并节省资源。未来工作可探索更多医疗场景或优化损失函数设计，摘要未明确说明局限性。",
      "tags": [
        "Large Language Model",
        "Retrieval-Augmented Generation",
        "Multi-modal Learning",
        "Self-supervised Pre-training",
        "Clinical Diagnosis"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:48.469771Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23296",
    "title": "Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity",
    "authors": [
      "Quang-Huy Nguyen",
      "Jiaqi Wang",
      "Wei-Shinn Ku"
    ],
    "abstract": "Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23296.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23296",
    "published": "2026-02-26T18:07:45Z",
    "updated": "2026-02-26T18:07:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出FedWQ-CP方法，通过单轮代理-服务器校准在联邦学习中实现双异构性下的不确定性量化，平衡了全局和代理级别的覆盖性能和效率。",
      "motivation": "联邦学习系统在实际部署中缺乏可靠的不确定性量化，可能导致在资源不足的代理上部署过度自信的模型，引发局部故障而全局性能仍看似良好。现有方法多单独处理数据或模型异构性，忽视其联合效应对代理间覆盖可靠性的影响，而符合预测框架在异构联邦学习环境中的应用尚未充分探索，因此解决双异构性下的不确定性量化问题至关重要。",
      "method": "论文提出FedWQ-CP方法，基于符合预测框架处理联邦学习中的双异构性。每个代理使用校准数据计算符合性分数并推导本地分位数阈值，然后仅传输阈值和校准样本大小到服务器，服务器通过加权平均聚合这些阈值生成全局阈值，实现单轮通信的高效代理-服务器校准，无需复杂数据传输。",
      "result": "在七个公共数据集上的分类和回归实验表明，FedWQ-CP经验上维持了代理级别和全局的覆盖性能，同时产生最小的预测集或区间，提升了不确定性量化的效率，但摘要未明确说明与具体基线方法的对比细节和量化提升数据。",
      "conclusion": "FedWQ-CP为联邦学习中的不确定性量化提供了一个简单有效的解决方案，通过处理双异构性增强了系统的覆盖可靠性和通信效率，扩展了符合预测在异构环境中的应用，具有部署更安全AI系统的实际价值，但摘要未明确说明局限性和未来工作方向。",
      "tags": [
        "Federated Learning",
        "Uncertainty Quantification",
        "Conformal Prediction",
        "Dual Heterogeneity",
        "Quantile Aggregation"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:01.709441Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23295",
    "title": "ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation",
    "authors": [
      "Ayush Roy",
      "Wei-Yang Alex Lee",
      "Rudrasis Chakraborty",
      "Vishnu Suresh Lokhande"
    ],
    "abstract": "In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-alignment vector onto the local tangent space of the estimated latent manifold, thus constraining the generation trajectory to remain manifold-faithful while preserving semantic consistency. This formulation improves representativeness, diversity, and image fidelity without requiring any model retraining. Empirical results demonstrate consistent gains over existing training-free and training-based baselines in terms of FID, l2 distance among real and synthetic dataset embeddings, and classification accuracy, establishing ManifoldGD as the first geometry-aware training-free data distillation framework.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23295.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23295",
    "published": "2026-02-26T18:07:10Z",
    "updated": "2026-02-26T18:07:10Z",
    "comment": "CVPE 2026",
    "light_analysis": {
      "overview": "提出ManifoldGD框架，首次集成流形一致指导在扩散模型中实现无训练数据集蒸馏。",
      "motivation": "大型数据集存在冗余概念，阻碍高效模型训练并增加存储和计算成本，数据集蒸馏旨在合成紧凑数据集以保留知识。现有基于扩散模型的无训练蒸馏方法，指导策略有限：要么无指导去噪，要么依赖简单的IPC centroids指导，这些方法往往过于初级且不最优，无法充分捕捉数据多样性和语义结构。因此，研究旨在开发更有效的指导策略，以提升蒸馏数据集的代表性和保真度。",
      "method": "ManifoldGD是一种无训练扩散框架，通过层次聚类VAE潜在特征计算IPC centroids，形成多尺度核集合，捕获粗粒度语义模式和细粒度类内变异性。在每个去噪步骤，基于提取的中心点创建局部潜在流形，并将模式对齐向量投影到切空间，约束生成轨迹保持流形忠实和语义一致。该方法无需模型重训练，利用几何指导提高图像生成质量和数据集代表性。",
      "result": "实证结果显示，ManifoldGD在FID指标、真实与合成数据集嵌入之间的l2距离以及分类准确率方面，一致优于现有的无训练和基于训练基线。例如，在分类任务中准确率有所提升，但摘要未明确说明具体数值。这表明该方法在提升数据集蒸馏效果方面表现优异，特别是在代表性和图像保真度上。",
      "conclusion": "ManifoldGD框架的主要贡献在于首次将流形指导引入无训练数据集蒸馏，提高了数据集的代表性和图像保真度。其学术价值在于提出了几何感知的蒸馏方法，为扩散模型在数据压缩领域提供新视角。实际应用可减少模型训练的计算开销和存储需求，未来工作可能包括扩展到其他数据类型或优化聚类策略以进一步提升性能。",
      "tags": [
        "Diffusion Models",
        "Dataset Distillation",
        "Manifold Guidance",
        "Hierarchical Clustering",
        "VAE Latent Features"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:15.049949Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23294",
    "title": "Towards Long-Form Spatio-Temporal Video Grounding",
    "authors": [
      "Xin Gu",
      "Bing Fan",
      "Jiali Yao",
      "Zhipeng Zhang",
      "Yan Huang",
      "Cheng Han",
      "Heng Fan",
      "Libo Zhang"
    ],
    "abstract": "In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23294.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23294",
    "published": "2026-02-26T18:04:09Z",
    "updated": "2026-02-26T18:04:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了ART-STVG方法，一种基于自回归Transformer的架构，用于解决长时视频的时空视频定位问题。",
      "motivation": "在真实场景中，视频可能长达数分钟到数小时，而现有时空视频定位（STVG）研究主要集中于短视频（通常小于一分钟），这限制了实际应用。长时视频具有更长的时间跨度和更多无关信息，传统STVG方法需要一次性处理所有帧，导致效率低下和性能下降，因此亟需新方法来应对长视频的挑战。",
      "method": "本文提出ART-STVG方法，采用自回归Transformer架构，以流式输入方式顺序处理视频帧。核心创新包括：设计空间和时间内存银行来建模时空上下文；引入内存选择策略，动态筛选相关信息以提高解码器效率；采用级联时空设计，空间解码器辅助时间解码器，利用细粒度空间线索优化长视频中的时间定位。这些技术使模型能高效处理长时视频，避免传统方法一次性处理整个序列的负担。",
      "result": "实验在新扩展的LF-STVG数据集上进行，结果显示ART-STVG显著优于最先进的STVG方法，摘要未明确说明具体性能指标，但表明在长时视频定位上取得了显著改进。同时，该方法在传统短时STVG任务上也展现了竞争力，证明了其泛化能力和有效性。",
      "conclusion": "本研究的主要贡献是提出了ART-STVG方法，为长时STVG提供了高效解决方案，引入了流式处理、内存管理和级联设计等创新技术。学术上，它扩展了STVG领域到长时视频，推动了相关研究；应用上，增强了在真实长视频场景中的定位能力。摘要未明确说明局限性，但未来工作可能包括进一步优化效率或扩展到更复杂视频类型。",
      "tags": [
        "Long-Form Video",
        "Spatio-Temporal Video Grounding",
        "AutoRegressive Transformer",
        "Memory Banks",
        "Cascaded Decoders"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:34.837272Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23292",
    "title": "PGVMS: A Prompt-Guided Unified Framework for Virtual Multiplex IHC Staining with Pathological Semantic Learning",
    "authors": [
      "Fuqiang Chen",
      "Ranran Zhang",
      "Wanming Hu",
      "Deboch Eyob Abera",
      "Yue Peng",
      "Boyun Zheng",
      "Yiwen Sun",
      "Jing Cai",
      "Wenjian Qin"
    ],
    "abstract": "Immunohistochemical (IHC) staining enables precise molecular profiling of protein expression, with over 200 clinically available antibody-based tests in modern pathology. However, comprehensive IHC analysis is frequently limited by insufficient tissue quantities in small biopsies. Therefore, virtual multiplex staining emerges as an innovative solution to digitally transform H&E images into multiple IHC representations, yet current methods still face three critical challenges: (1) inadequate semantic guidance for multi-staining, (2) inconsistent distribution of immunochemistry staining, and (3) spatial misalignment across different stain modalities. To overcome these limitations, we present a prompt-guided framework for virtual multiplex IHC staining using only uniplex training data (PGVMS). Our framework introduces three key innovations corresponding to each challenge: First, an adaptive prompt guidance mechanism employing a pathological visual language model dynamically adjusts staining prompts to resolve semantic guidance limitations (Challenge 1). Second, our protein-aware learning strategy (PALS) maintains precise protein expression patterns by direct quantification and constraint of protein distributions (Challenge 2). Third, the prototype-consistent learning strategy (PCLS) establishes cross-image semantic interaction to correct spatial misalignments (Challenge 3).",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23292.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23292",
    "published": "2026-02-26T18:03:24Z",
    "updated": "2026-02-26T18:03:24Z",
    "comment": "Accepted by TMI",
    "light_analysis": {
      "overview": "本文提出了一种名为PGVMS的提示引导统一框架，通过病理语义学习解决虚拟多重IHC染色中的语义指导不足、染色分布不一致和空间错位问题。",
      "motivation": "免疫组织化学（IHC）染色在现代病理学中用于精确分析蛋白质表达，有超过200种临床可用的抗体测试。然而，小活检组织中组织量不足常限制全面IHC分析，虚拟多重染色作为一种数字转换H&E图像为多IHC表示的创新方案应运而生。现有方法面临三个关键挑战：语义指导不足导致多染色效果差，染色分布不一致影响准确性，以及不同染色模态间的空间错位问题，这些问题阻碍了虚拟多重染色的临床应用潜力。",
      "method": "PGVMS框架引入三个关键创新对应每个挑战：首先，自适应提示引导机制使用病理视觉语言模型动态调整染色提示，以解决语义指导问题；其次，蛋白感知学习策略通过直接量化和约束蛋白质分布来维持精确表达模式；第三，原型一致学习策略建立跨图像的语义交互以纠正空间错位。该框架仅使用单染色训练数据，结合视觉语言模型和量化蛋白质表达，提高了方法的通用性和准确性。",
      "result": "由于摘要未提供具体实验结果，论文的PGVMS框架预期能显著提高虚拟多重IHC染色的准确性和一致性。通过解决语义指导、染色分布和空间对齐问题，该方法可能优于现有基线，例如在保持蛋白质表达模式和图像对齐方面有所改善。然而，具体性能指标如准确率提升或效率改进等数据摘要未明确说明，需要参考完整论文获取详细实验验证。",
      "conclusion": "本研究的主要贡献是提出了PGVMS框架，有效解决了虚拟多重IHC染色中的关键挑战，通过自适应提示引导、蛋白感知学习和原型一致学习提升了染色语义准确性和空间一致性。学术价值在于创新结合病理语义学习和视觉语言模型，为多模态图像转换提供新思路；实际应用价值在于促进小活检组织的全面蛋白质分析，有望改善病理诊断效率。未来工作可包括扩展到更多染色类型或在临床环境中验证框架鲁棒性。",
      "tags": [
        "Prompt-Guided Learning",
        "Virtual Multiplex Staining",
        "Pathological Visual Language Model",
        "Protein Distribution Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:42.362802Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23290",
    "title": "LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction",
    "authors": [
      "Zhengyang Wei",
      "Renzhi Jing",
      "Yiyi He",
      "Jenny Suckale"
    ],
    "abstract": "The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness prediction, but often struggle to capture long-range dependencies and complex topologies. Here, we propose LineGraph2Road, a framework that improves connectedness prediction by formulating it as binary classification over edges in a constructed global but sparse Euclidean graph, where nodes are keypoints extracted from segmentation masks and edges connect node pairs within a predefined distance threshold, representing potential road segments. To better learn structural link representation, we transform the original graph into its corresponding line graph and apply a Graph Transformer on it for connectedness prediction. This formulation overcomes the limitations of endpoint-embedding fusion on set-isomorphic links, enabling rich link representations and effective relational reasoning over the global structure. Additionally, we introduce an overpass/underpass head to resolve multi-level crossings and a coupled NMS strategy to preserve critical connections. We evaluate LineGraph2Road on three benchmarks: City-scale, SpaceNet, and Global-scale, and show that it achieves state-of-the-art results on two key metrics, TOPO-F1 and APLS. It also captures fine visual details critical for real-world deployment. We will make our code publicly available.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23290.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23290",
    "published": "2026-02-26T18:02:44Z",
    "updated": "2026-02-26T18:02:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了LineGraph2Road框架，通过将原图转换为线图并应用图Transformer，显著提升了卫星图像中道路网络提取的连接性预测精度和结构推理能力。",
      "motivation": "道路网络从卫星图像中的准确自动提取对于导航和城市规划至关重要，能极大减少人工标注成本。然而，现有方法通常将任务分解为关键点提取和连接性预测，难以有效捕获长程依赖关系和复杂拓扑结构，导致提取结果不完整或错误连接。本研究旨在解决这些不足，通过改进连接性预测来提高道路提取的鲁棒性和准确性，以应对实际应用中多级交叉和全局结构推理的挑战。",
      "method": "该方法的核心是将连接性预测形式化为在稀疏欧几里得图中边的二元分类，其中节点基于分割掩模提取的关键点，边连接距离阈值内的节点对以表示潜在道路段。关键创新在于将原图转换为线图，应用图Transformer学习丰富的链接表示，克服了传统端点嵌入融合在集合同构链接上的限制。此外，引入了立交桥/地下通道头来处理多级道路交叉，并采用耦合NMS策略保留关键连接。整个框架在City-scale、SpaceNet和Global-scale数据集上进行评估，确保了方法的通用性和有效性。",
      "result": "实验结果显示，LineGraph2Road在City-scale、SpaceNet和Global-scale三个基准测试中，在TOPO-F1和APLS两个关键指标上均达到了最优性能，超越了现有方法。具体而言，该框架不仅显著提升了连接性预测的准确率，还能捕获精细视觉细节，这对于真实世界部署至关重要。代码将公开发布，以促进进一步研究和应用。",
      "conclusion": "本研究的主要贡献是提出了LineGraph2Road框架，通过结构图推理有效提高了道路网络提取的准确性和鲁棒性。学术上，它推动了图神经网络在遥感图像分析中的应用；实际上，为导航和城市规划提供了高效自动化工具。未来工作可探索扩展到更大规模数据集或复杂环境，并进一步优化计算效率，摘要未明确说明具体局限性，但潜在方向包括处理更多样化的道路类型或集成多模态数据。",
      "tags": [
        "Graph Transformer",
        "Line Graph",
        "Binary Classification",
        "Road Network Extraction",
        "Structural Reasoning"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:30.066405Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23286",
    "title": "SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables",
    "authors": [
      "Sungho Park",
      "Jueun Kim",
      "Wook-Shin Han"
    ],
    "abstract": "Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at https://github.com/pshlego/SPARTA/tree/main.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23286.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23286",
    "published": "2026-02-26T17:59:51Z",
    "updated": "2026-02-26T17:59:51Z",
    "comment": "10 pages, 5 figures. Published as a conference paper at ICLR 2026. Project page: https://sparta-projectpage.github.io/",
    "light_analysis": {
      "overview": "SPARTA 提出了一个自动生成大规模 Table-Text 多跳问答基准的框架，通过自动化构造提升基准质量和规模。",
      "motivation": "现实世界的 Table-Text 问答任务需要模型进行跨文本和表格的多跳复杂推理，如聚合和分组操作。然而，现有基准如 HybridQA 和 OTT-QA 规模小、依赖手动构建易出错，且问题浅显，很少涉及超过两跳的推理或高级操作，无法有效评估模型的真实能力。这导致现有模型在实际应用中的表现被高估，因此亟需一个可扩展、高质量的新基准来推动相关研究。",
      "method": "方法包括一个端到端的构造框架：首先构建参考事实数据库，通过从非结构化文本中自动提取原子事实来丰富源表，形成 grounding tables；然后合成嵌套查询，确保跳数与需求匹配。关键技术包括 provenance-based refinement，重写语法有效但返回非空结果的查询，以及 realistic-structure enforcement，限制生成过程为查询图的后序遍历，以保证 SQL 语句可执行并产生流畅、自然的问题。框架仅需轻量级人工验证，标注时间减少至 HybridQA 的四分之一。",
      "result": "实验结果显示，SPARTA 基准生成了数千个高质量问题-答案对，涵盖聚合、分组和深层多跳推理。在 SPARTA 上，当前最先进的模型如 HybridQA 上 F1 超过 70 或 OTT-QA 上超过 50 的模型，性能下降超过 30 F1 点，这表明现有模型在跨文本和表格的复杂推理上存在根本性弱点。基准的构造代码和基线模型已公开，便于后续研究对比。",
      "conclusion": "该研究的主要贡献是提供了 SPARTA 基准，通过自动化构造和轻量级人工验证，显著提升了 Table-Text QA 基准的规模和质量，揭示了当前模型的不足，为未来多跳推理研究提供了更好的评估工具。学术价值在于促进跨模态推理算法的改进，实际应用价值包括增强现实世界问答系统的鲁棒性。摘要未明确说明局限性，但未来工作可能包括扩展基准到更广泛领域或开发更强大的推理模型。",
      "tags": [
        "Table-Text Question Answering",
        "Multi-hop Reasoning",
        "Benchmark Generation",
        "SQL Queries",
        "Cross-modal Reasoning"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:39.707008Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23285",
    "title": "ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks",
    "authors": [
      "Haohui Jia",
      "Zheng Chen",
      "Lingwei Zhu",
      "Rikuto Kotoge",
      "Jathurshan Pradeepkumar",
      "Yasuko Matsubara",
      "Jimeng Sun",
      "Yasushi Sakurai",
      "Takashi Matsubara"
    ],
    "abstract": "Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments verify that ODEBRAIN can improve significantly over existing methods in forecasting EEG dynamics with enhanced robustness and generalization capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23285.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23285",
    "published": "2026-02-26T17:59:10Z",
    "updated": "2026-02-26T17:59:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出ODEBRAIN框架，利用Neural ODE建模连续时间EEG图的动态脑网络，显著改进EEG动态预测。",
      "motivation": "神经群体动力学建模对基础神经科学研究和临床应用至关重要。传统潜变量方法通常通过循环架构离散化时间建模连续脑动力学，导致累积预测误差和无法捕捉EEG的瞬时非线性特性。因此，本研究旨在解决这些不足，提高EEG动态建模的准确性和实用性，以支持更精确的神经活动和脑网络分析。",
      "method": "ODEBRAIN框架整合了时空频率特征到谱图节点中，然后采用Neural ODE建模连续的潜变量动力学。该方法避免了时间离散化，直接处理连续时间动态，从而更好地捕捉复杂脑状态的随机变化。关键创新点包括特征集成和Neural ODE的应用，但摘要未明确说明具体使用的数据集或详细模型架构细节。",
      "result": "广泛的实验验证表明，ODEBRAIN在预测EEG动态方面显著优于现有方法，增强了鲁棒性和泛化能力。尽管摘要未提供具体性能指标如准确率提升百分比，但结果显示该方法在EEG时间序列预测任务中表现优越，可能通过减少累积误差和改进特征捕捉来实现更稳定的性能。",
      "conclusion": "本研究的主要贡献是提出ODEBRAIN框架，通过连续时间建模改进EEG动态预测的准确性和鲁棒性，为神经科学研究提供了新工具，并具有临床应用的潜力。学术价值在于引入Neural ODE处理脑网络动态，实际价值体现在增强模型泛化能力。未来工作可能包括在更多数据集上验证性能，并探索其他神经信号的应用，但摘要未明确说明局限性或具体方向。",
      "tags": [
        "Neural ODE",
        "EEG Graph",
        "Dynamic Brain Networks",
        "Spatio-temporal-frequency Features",
        "Latent Dynamics"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:42.165528Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23280",
    "title": "Physics Informed Viscous Value Representations",
    "authors": [
      "Hrishikesh Viswanath",
      "Juanwu Lu",
      "S. Talha Bukhari",
      "Damon Conover",
      "Ziran Wang",
      "Aniket Bera"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at https://github.com/HrishikeshVish/phys-fk-value-GCRL.",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23280.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23280",
    "published": "2026-02-26T17:53:46Z",
    "updated": "2026-02-26T17:53:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种基于Hamilton-Jacobi-Bellman方程粘度解的物理信息正则化方法，以提升离线目标条件强化学习中价值估计的稳定性和几何一致性。",
      "motivation": "离线目标条件强化学习（GCRL）利用静态数据集训练策略，但由于数据覆盖有限，状态-动作空间的价值估计常不准确。现有物理信息方法通过Eikonal方程等一阶偏微分方程施加约束，但在复杂高维环境中可能不适定，导致性能不稳定。因此，需要一种更稳健的正则化方法，以优化价值估计并适应更广泛的场景，解决现有技术在动态环境中的不足。",
      "method": "该方法从Hamilton-Jacobi-Bellman（HJB）方程的粘度解推导出物理信息正则化，提供物理归纳偏置，将学习过程扎根于最优控制理论。关键创新是利用Feynman-Kac定理将偏微分方程解重新表述为期望，从而实现可处理的蒙特卡洛估计，避免高阶梯度中的数值不稳定性。通过优化价值迭代过程，明确施加正则化和边界约束，增强方法在离线GCRL任务中的稳定性和计算效率。",
      "result": "实验表明，该方法显著提升了价值函数的几何一致性，使其适用于导航和高维复杂操作任务。摘要未明确说明具体性能指标对比基线，但强调了广泛适用性，暗示在多种离线GCRL场景中优于传统物理信息方法，改进任务完成效果和鲁棒性，支持复杂环境下的强化学习应用。",
      "conclusion": "本研究的主要贡献是提出了一种基于HJB方程粘度解的物理信息正则化框架，提升了离线GCRL中价值估计的准确性和稳定性。学术上，它结合了最优控制理论与机器学习，提供理论指导的方法；实际上，为导航和复杂操作任务提供了实用工具。未来工作可扩展至在线学习或更多任务类型，以进一步提高方法的通用性和性能。",
      "tags": [
        "Offline Reinforcement Learning",
        "Goal-Conditioned Reinforcement Learning",
        "Hamilton-Jacobi-Bellman Equation",
        "Monte Carlo Estimation",
        "Viscosity Solution"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:11.619901Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23276",
    "title": "CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays",
    "authors": [
      "Hyungyung Lee",
      "Hangyul Yoon",
      "Edward Choi"
    ],
    "abstract": "Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23276.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23276",
    "published": "2026-02-26T17:51:21Z",
    "updated": "2026-02-26T17:51:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "CXReasonAgent通过集成大型语言模型和临床诊断工具，实现基于证据的胸部X光诊断推理，解决现有视觉语言模型在忠实性和适应性方面的不足。",
      "motivation": "研究动机源于胸部X光诊断需要多步骤、基于证据的推理，而现有大型视觉语言模型（LVLMs）生成的响应往往不忠实于诊断证据，提供有限的视觉证据进行验证，且需要昂贵重新训练以支持新任务，这限制了其在临床环境中的可靠性和适应性。在安全关键的临床设置中，确保诊断的准确性和可验证性至关重要，因此需要开发更可靠的诊断推理方法来弥补这些不足。",
      "method": "论文提出CXReasonAgent，一个诊断代理，集成大型语言模型（LLM）和临床基础诊断工具。核心方法是通过结合图像衍生的诊断和视觉证据，执行证据基础诊断推理，关键创新点在于将LLM的推理能力与专业诊断工具相结合，生成忠实于证据的响应。摘要中未明确说明具体模型架构或训练细节，但提及引入CXReasonDial作为评估基准，以验证方法的有效性。",
      "result": "主要实验结果显示，在CXReasonDial基准（包含1,946个对话，跨越12个诊断任务）上，CXReasonAgent产生忠实基于证据的响应，相比大型视觉语言模型（LVLMs）实现了更可靠和可验证的诊断推理。摘要未提供具体数值指标如准确率，但强调CXReasonAgent在生成可信证据方面的优势，表明其显著提升了诊断的可靠性和验证性。",
      "conclusion": "论文的主要贡献是提出了CXReasonAgent，一个集成临床诊断工具的证据基础诊断推理代理，有效解决了LVLMs在忠实性、验证性和适应性方面的局限，强调了在安全关键临床环境中集成诊断工具的重要性。研究为胸部X光诊断提供了更可靠的解决方案，尽管摘要未明确说明局限性，但未来工作可能涉及扩展到更多诊断场景和优化工具集成。",
      "tags": [
        "Large Language Model",
        "Evidence-Grounded Reasoning",
        "Diagnostic Tools",
        "Chest X-ray Diagnosis",
        "Multi-turn Dialogue Benchmark"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:25.389562Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23271",
    "title": "Evaluating Stochasticity in Deep Research Agents",
    "authors": [
      "Haotian Zhai",
      "Elias Stengel-Eskin",
      "Pratik Patil",
      "Liu Leqi"
    ],
    "abstract": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23271.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23271",
    "published": "2026-02-26T17:46:42Z",
    "updated": "2026-02-26T17:46:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过将深度研究代理建模为信息获取马尔可夫决策过程，提出了一个评估框架和缓解策略来减少随机性，从而提升输出质量。",
      "motivation": "DRA系统虽然提高了研究质量，但在实际部署中面临随机性问题，即在相同查询下输出结果存在显著变异性，导致系统不稳定。现有方法往往忽视这一关键障碍，例如在信息获取和处理过程中未充分控制随机因素，这限制了DRA在金融、医学等领域的可靠应用。因此，研究随机性的来源和影响对提升系统的鲁棒性和实用性至关重要。",
      "method": "研究采用马尔可夫决策过程对DRAs进行建模，引入一个量化方差的评估框架，识别了随机性的三个主要来源：信息获取、信息压缩和推断。通过受控实验分析这些模块在不同决策步骤中的影响，提出了缓解策略，包括结构化输出和基于集成的查询生成，实验基于DeepSearchQA数据集进行验证。",
      "result": "实验结果表明，减少随机性可以有效提高研究输出质量，其中推断和早期阶段随机性对输出方差贡献最大。提出的缓解方法在DeepSearchQA上测试，成功减少了22%的平均随机性，同时保持了高质量的研究输出，这支持了改进随机性控制对提升DRA性能的重要性，尽管摘要未明确说明与具体基线方法的对比细节。",
      "conclusion": "论文的主要贡献在于正式研究了DRAs中的随机性问题，并提出了评估框架和缓解策略，有助于推动DRA系统在现实世界中的部署。研究具有学术价值，为代理系统的稳定性和设计提供了新视角；实际应用方面，提高了系统的可靠性和输出一致性。未来工作可能涉及进一步验证策略的通用性和探索更多缓解方法，但摘要未明确说明局限性。",
      "tags": [
        "Deep Research Agents",
        "Markov Decision Process",
        "Stochasticity",
        "Structured Output",
        "Ensemble-based Query Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:17.141586Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23266",
    "title": "Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems",
    "authors": [
      "Siyuan Liu",
      "Jiahui Xu",
      "Feng Jiang",
      "Kuang Wang",
      "Zefeng Zhao",
      "Chu-Ren Huang",
      "Jinghang Gu",
      "Changqing Yin",
      "Haizhou Li"
    ],
    "abstract": "Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis shows that DDTSR functions as a plug-and-play module compatible with diverse LLM backbones, and remains robust across varying utterance lengths, indicating strong practicality and scalability for real-time spoken interaction.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23266.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23266",
    "published": "2026-02-26T17:39:56Z",
    "updated": "2026-02-26T17:39:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一种语篇感知的双轨流式响应框架（DDTSR），通过并行处理技术显著降低口语对话系统的响应延迟。",
      "motivation": "口语对话系统需实现类似人类的响应速度，但传统的ASR-LLM-TTS管道采用严格顺序范式，必须完成转录和推理后才能进行语音合成，导致高响应延迟。这一问题在实时交互中至关重要，现有方法难以平衡延迟与语篇质量，影响了用户体验和系统实用性。摘要未明确说明具体应用场景，但强调了高延迟对交互效率的负面影响。",
      "method": "DDTSR框架基于三个关键机制：一是连接词引导的大小模型协同，辅助小模型生成最小承诺的连接词，同时大模型并行执行知识密集推理；二是流式跨模态协作，动态重叠自动语音识别（ASR）、大语言模型（LLM）推理和文本到语音（TTS）处理，以提前最早可说话时刻；三是基于课程学习的语篇连续性增强，通过训练策略保持早期响应与后续输出的逻辑一致性。该方法在两种口语对话基准上进行了实验，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "在两个口语对话基准测试中，DDTSR将响应延迟降低了19%至51%，同时保持了语篇质量。分析显示，该框架兼容多种LLM骨干模型，并能在不同话语长度下保持稳健性能，表明其作为即插即用模块的强实用性。与基线方法相比，延迟改善显著，摘要未提供基线具体数值，但突出了性能提升和数据支持。",
      "conclusion": "DDTSR的主要贡献是提供了一种低延迟架构，实现“边听边思考”和“边说边思考”，提升了口语对话系统的响应速度。学术价值在于改进了响应机制和语篇一致性处理，实际应用价值在于增强实时交互的效率和用户体验。摘要未明确说明局限性，但未来工作可进一步优化语篇增强策略和扩展更广泛的对话场景。",
      "tags": [
        "Spoken Dialogue Systems",
        "Streaming Processing",
        "Discourse Analysis",
        "Large Language Model",
        "Curriculum Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:21.955793Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23262",
    "title": "Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling",
    "authors": [
      "Jasmine Bayrooti",
      "Weiwei Kong",
      "Natalia Ponomareva",
      "Carlos Esteves",
      "Ameesh Makadia",
      "Amanda Prorok"
    ],
    "abstract": "Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and leveraging the post-processing property of DP for detail refinement, we achieve promising trade-offs between privacy and utility. Experiments on the MS-COCO and MM-CelebA-HQ datasets show that our method generates images with improved quality and style capture relative to other leading DP image frameworks.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23262.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23262",
    "published": "2026-02-26T17:36:48Z",
    "updated": "2026-02-26T17:36:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种基于小波建模的谱差分隐私图像生成框架，通过区分低频和高频成分的隐私敏感性来提升图像质量。",
      "motivation": "生成模型在处理敏感图像数据集时，容易记忆和泄露训练样本，因此需要严格的隐私保护。差分隐私（DP）虽然提供了理论保证，但标准方法如DP-SGD在所有模型参数上均匀添加噪声，导致图像质量显著下降，尤其是高频纹理部分。现有方法未能有效平衡隐私与效用，因为忽视了图像不同频率成分在隐私敏感性上的差异，这限制了实际应用。",
      "method": "该研究提出一种基于小波变换的谱DP框架，假设隐私敏感信息主要集中在低频小波成分（如面部特征和物体形状），而高频成分更通用和公开。核心方法包括两阶段：首先，对敏感图像的低分辨率小波系数使用DP微调一个自回归谱图像标记器模型；其次，利用公开预训练的超分辨率模型进行高分辨率上采样，以细化细节。该方法通过将隐私预算集中到低频结构，并利用DP的后处理属性，优化了隐私与效用的平衡，使用数据集包括MS-COCO和MM-CelebA-HQ。",
      "result": "实验在MS-COCO和MM-CelebA-HQ数据集上进行，结果表明该方法在图像质量和风格捕捉方面优于其他领先的DP图像生成框架。与基线方法相比，该框架在保持隐私保证的同时，显著减少了视觉质量下降，摘要未明确说明具体性能指标如准确率或效率改进，但强调了在隐私与效用间的更好平衡。",
      "conclusion": "该论文的主要贡献是开发了一种基于小波分析的粗到细差分隐私图像生成框架，有效改善了私有图像生成的视觉质量。其学术价值在于为DP图像生成提供了新思路，通过区分频率成分的隐私敏感性来优化方法；实际应用价值在于可能促进医疗、安全等领域中敏感数据的生成和处理。未来工作方向可能包括扩展更多数据集或探索其他变换域技术，摘要未明确说明局限性。",
      "tags": [
        "Differential Privacy",
        "Wavelet Transform",
        "Image Generation",
        "Autoregressive Models",
        "Super-Resolution"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:30.785367Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23259",
    "title": "Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving",
    "authors": [
      "Jiangxin Sun",
      "Feng Xue",
      "Teng Long",
      "Chang Liu",
      "Jian-Fang Hu",
      "Wei-Shi Zheng",
      "Nicu Sebe"
    ],
    "abstract": "With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of \"only driving like the expert\" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23259.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23259",
    "published": "2026-02-26T17:32:30Z",
    "updated": "2026-02-26T17:32:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种无需专家演示的风险感知世界模型预测控制框架，以提升端到端自动驾驶在罕见场景中的泛化能力和安全性。",
      "motivation": "当前端到端自动驾驶主要基于模仿学习，依赖专家数据学习驾驶行为，导致在罕见或长尾分布外场景中泛化能力有限，易产生不安全决策。这凸显了开发不依赖专家监督的可靠决策系统的需求，旨在通过风险控制提高自动驾驶系统的鲁棒性，解决现有方法在真实世界应用中的不足。",
      "method": "研究方法采用RaWMPC框架，核心是使用世界模型预测多个候选动作的未来后果，并通过明确的风险评估选择低风险动作。为训练世界模型，设计了风险感知交互策略，系统性地暴露模型于危险行为，使其学习预测灾难性结果。此外，引入自我评估蒸馏方法，将训练好的世界模型的风险规避能力蒸馏到生成动作提议网络中，无需任何专家演示，以在测试时生成安全候选动作。",
      "result": "实验结果表明，RaWMPC在分布内和分布外场景中均优于最先进的端到端自动驾驶方法，展示了卓越的泛化能力。具体表现在安全性和决策可解释性方面有显著提升，但摘要未提供具体性能指标数字。与基线方法对比，该方法在罕见场景中表现出更强的鲁棒性和可靠性。",
      "conclusion": "本研究的主要贡献是提出RaWMPC框架，成功解决了端到端自动驾驶在不依赖专家演示下的泛化困境，通过风险感知和世界模型预测提升系统安全性。其学术价值在于为自动驾驶领域提供了新控制范式，实际应用潜力在于增强系统在复杂环境中的可靠性。未来工作可扩展到更多驾驶场景或集成其他控制技术。",
      "tags": [
        "World Model Predictive Control",
        "Risk-Aware Interaction",
        "Self-Evaluation Distillation",
        "End-to-End Autonomous Driving",
        "Generalization"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:41.243148Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23258",
    "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning",
    "authors": [
      "Yutong Wang",
      "Siyuan Xiong",
      "Xuebo Liu",
      "Wenkang Zhou",
      "Liang Ding",
      "Miao Zhang",
      "Min Zhang"
    ],
    "abstract": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23258.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23258",
    "published": "2026-02-26T17:31:43Z",
    "updated": "2026-02-26T17:31:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "AgentDropoutV2框架通过测试时错误纠正与剪枝机制，动态优化多智能体系统的信息流，避免错误级联传播。",
      "motivation": "多智能体系统（MAS）在复杂推理任务中表现卓越，但面临一个关键挑战：个体智能体生成的错误信息会通过信息流级联传播，导致系统性能下降。现有解决方案，如刚性结构工程或昂贵微调，部署性和适应性受限，难以在实际应用中应对动态错误模式。因此，研究旨在开发一种无需重新训练的优化框架，以高效管理MAS中的信息流动，解决错误传播问题，提升系统的可靠性和实用性，弥补现有方法的不足。",
      "method": "论文提出AgentDropoutV2，一个测试时rectify-or-reject修剪框架，动态优化MAS信息流而无需重新训练。核心方法包括：作为主动防火墙拦截智能体输出；利用检索增强纠正器，基于失败驱动指示器池迭代纠正错误，通过蒸馏失败模式作为先验知识精确识别潜在错误；对不可修复的输出进行剪枝以防止传播；并引入回退策略维持系统完整性。框架突出了动态适应性和部署效率，通过上下文感知调整纠正过程。",
      "result": "在广泛的数学基准测试上，AgentDropoutV2显著提升了多智能体系统的任务性能，实现了平均准确率6.3个百分点的增益。系统表现出鲁棒的泛化能力，能根据任务难度动态调制纠正努力，利用上下文感知指示器解决多样错误模式。实证结果验证了该框架在优化信息流、减少错误传播方面的有效性，相比基线方法，提高了准确率和适应性的关键指标。",
      "conclusion": "AgentDropoutV2的主要贡献是提出了一种无需重新训练的测试时优化框架，通过rectify-or-reject机制动态管理MAS信息流，提升任务性能和系统适应性。该研究具有学术价值，为多智能体系统中的错误控制提供了新方法；应用价值在于增强MAS的部署性和可靠性。局限性可能包括对失败模式池的依赖性；未来工作可扩展至更多错误类型和应用领域，如自然语言处理或机器人协作。",
      "tags": [
        "Multi-Agent Systems",
        "Test-Time Pruning",
        "Error Rectification",
        "Retrieval-Augmented Generation",
        "Failure-Driven Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:42.310375Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23248",
    "title": "Mitigating Legibility Tax with Decoupled Prover-Verifier Games",
    "authors": [
      "Yegon Kim",
      "Juho Lee"
    ],
    "abstract": "As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems. Prover-verifier games can be used to improve checkability of model outputs, but display a degradation in accuracy compared to a baseline trained only to maximize correctness -- a phenonemon named legibility tax. We propose a solution by decoupling the correctness from the checkability condition and instead training a \"translator\" model that turns a fixed solver model's solution into a checkable form. This allows us to first train the solver to maximize correctness, and then train the translator to translate the solver into a checkable form while retaining the solver's answer. To accommodate this new objective of translation, we formulate a decoupled prover-verifier game where the equilibria correspond to faithful and checkable translators.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23248.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23248",
    "published": "2026-02-26T17:25:22Z",
    "updated": "2026-02-26T17:25:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出通过解耦正确性与可检查性并训练翻译器模型，以减轻大型语言模型输出可检查性带来的准确性损失（可读性税）。",
      "motivation": "随着大型语言模型能力提升，其输出需要由能力较弱的系统轻松检查以确保可靠性。现有方法如证明者-验证者游戏可提高可检查性，但会引入“可读性税”，导致准确性下降。这在实际应用中限制了模型在安全关键领域的部署，因为现有方法无法同时优化正确性和可检查性，亟需新解决方案来平衡这两方面需求。",
      "method": "论文提出一种解耦方法：首先训练一个“求解器”模型以最大化输出正确性，然后训练一个“翻译器”模型，将求解器的解决方案转换为可检查形式，同时保留原始答案。通过制定解耦的证明者-验证者游戏，实现翻译器的忠实性和可检查性，关键创新在于分离训练目标和游戏理论框架，避免了单一模型中权衡正确性与可检查性的问题。摘要未提及具体数据集或模型架构。",
      "result": "摘要未明确说明主要实验结果，如准确率提升、效率改进或与基线方法的对比数据。基于方法描述，预计该方法能通过解耦训练减轻可读性税，提高可检查性而不牺牲准确性，但具体性能指标和实验验证需依赖未来研究或论文未提供的细节部分。",
      "conclusion": "论文的主要贡献是提出了一种新框架，通过解耦正确性和可检查性条件，使用翻译器模型来减轻可读性税，使得大型语言模型输出既准确又可检查。学术上，该方法为可验证AI系统提供了新思路；实践中，有助于提高模型在安全关键领域的可靠性。局限性包括未经验证的实际性能，未来工作可包括实验评估和扩展到更多应用场景。",
      "tags": [
        "Large Language Model",
        "Prover-Verifier Games",
        "Translation Models",
        "Decoupling",
        "Checkability"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:57.647161Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23242",
    "title": "A Model-Free Universal AI",
    "authors": [
      "Yegon Kim",
      "Juho Lee"
    ],
    "abstract": "In general reinforcement learning, all established optimal agents, including AIXI, are model-based, explicitly maintaining and using environment models. This paper introduces Universal AI with Q-Induction (AIQI), the first model-free agent proven to be asymptotically $\\varepsilon$-optimal in general RL. AIQI performs universal induction over distributional action-value functions, instead of policies or environments like previous works. Under a grain of truth condition, we prove that AIQI is strong asymptotically $\\varepsilon$-optimal and asymptotically $\\varepsilon$-Bayes-optimal. Our results significantly expand the diversity of known universal agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23242.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23242",
    "published": "2026-02-26T17:21:16Z",
    "updated": "2026-02-26T17:21:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了第一个在一般强化学习中被证明是渐近 ε-最优的无模型代理 AIQI，通过 Q 归纳扩展了通用代理的理论多样性。",
      "motivation": "在一般强化学习中，现有最优代理如 AIXI 都是基于模型的，需要显式维护环境模型，导致计算复杂性和实现难度增加。尽管基于模型方法有理论保证，但无模型方法在实践和泛化上更具优势，而此前缺乏无模型代理在一般环境中保证渐近最优性的理论证明。因此，本研究旨在开发一种无模型但能确保渐近最优性的通用代理，以克服现有方法的限制并丰富强化学习代理类型。",
      "method": "AIQI 采用基于 Q 归纳的通用 AI 方法，通过执行分布动作价值函数的通用归纳实现无模型学习。不同于先前工作对策略或环境的建模，AIQI 专注于动作价值函数，避免了显式环境模型维护。在真实粒度条件下，该方法利用理论证明保证渐近最优性，而不依赖于特定数据集或复杂模型架构，技术特色包括 Q 归纳在通用强化学习中的应用和渐进学习机制。",
      "result": "论文证明了 AIQI 在一般强化学习环境中是强渐近 ε-最优和渐近 ε-贝叶斯最优的，表明它能以概率接近最优的方式执行，类似基于模型代理如 AIXI 的性能。尽管摘要未提供具体数值指标，但理论证明扩展了无模型代理的最优性范围，与现有基线相比，AIQI 在保持无模型特性的同时达到渐近最优性，显著丰富了通用代理的多样性。",
      "conclusion": "本研究的主要贡献是提出了 AIQI，第一个在一般强化学习中渐近 ε-最优的无模型代理，扩展了通用代理的理论框架并增强了无模型方法的可信度。学术价值在于提供新的理论保证，推动强化学习领域发展；实际应用价值可能体现在简化代理设计和提高计算效率上。未来工作可探索 AIQI 的计算实现和实际应用，摘要未明确说明具体局限性。",
      "tags": [
        "Reinforcement Learning",
        "Model-Free RL",
        "Universal AI",
        "Q-Induction",
        "Asymptotic Optimality"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:07.216476Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23239",
    "title": "Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive",
    "authors": [
      "Radha Sarma"
    ],
    "abstract": "AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains.   RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Consequently, documented failure modes - sycophancy, hallucination, and unfaithful reasoning - are not accidents but structural manifestations.   Misaligned deployment triggers a second-order risk we term the Convergence Crisis: when humans are forced to verify AI outputs under metric pressure, they degrade from genuine agents into criteria-checking optimizers, eliminating the only component in the system capable of normative accountability. Beyond the incompatibility proof, the paper's primary positive contribution is a substrate-neutral architectural specification defining what any system -- biological, artificial, or institutional -- must satisfy to qualify as an agent rather than a sophisticated instrument.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23239.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23239",
    "published": "2026-02-26T17:16:17Z",
    "updated": "2026-02-26T17:16:17Z",
    "comment": "About 10,500 words in all (including 922 words of literature and 2019 words of Appendices). Under journal review",
    "light_analysis": {
      "overview": "本文论证了基于优化的AI系统（如RLHF训练的大语言模型）无法实现规范响应性，并提出代理的架构条件。",
      "motivation": "AI系统正广泛部署于医疗诊断、法律研究等高风险环境，假设其能被规范治理。然而，现有基于优化的系统（特别是通过RLHF训练的大语言模型）在架构上存在不足，可能导致伦理和安全风险。本研究旨在揭示这一假设的无效性，解决AI系统在规范响应性方面的根本限制，避免因误用而引发严重后果。",
      "method": "论文通过理论分析，提出代理的两个必要架构条件：一是维持边界作为不可协商约束的不可比较性，二是当边界受威胁时能暂停处理的否定性响应。核心方法是证明基于优化的系统（如RLHF）使用标量度量统一所有值并优先选择最高得分输出，与这些条件在形式上不相容。创新点在于将代理条件应用于所有规范领域，强调优化操作的内在约束。",
      "result": "研究证明RLHF系统无法满足代理的架构条件，因此不能成为规范响应的代理。这导致奉承、幻觉等失败模式成为结构性表现，而非偶然错误。同时，提出趋同危机的风险，即人类在度量压力下可能退化为标准检查优化器，削弱系统规范问责能力。结果基于理论论证，摘要未明确说明具体实验数据。",
      "conclusion": "本文主要贡献是证明了基于优化的AI系统在规范响应性上的固有局限性，并提出了代理的架构规范。这深化了AI系统代理性的理论理解，具有重要学术价值，并提醒实际应用中需考虑架构限制。未来工作可能包括设计满足代理条件的新系统，但摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning from Human Feedback",
        "Optimization",
        "Agency Theory",
        "Normative Governance"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:06.506001Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23235",
    "title": "Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents",
    "authors": [
      "Zhou Xu",
      "Bowen Zhou",
      "Qi Wang",
      "Shuwen Feng",
      "Jingyu Xiao"
    ],
    "abstract": "Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent's \"fading memory\" attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via decay-based resizing, and Stratified Structure-aware Pruning (SSP), which prioritizes interactive foregrounds and semantic anchors while safeguarding global layout. Extensive evaluations across diverse benchmarks demonstrate that GUIPruner consistently achieves state-of-the-art performance, effectively preventing the collapse observed in large-scale models under high compression. Notably, on Qwen2-VL-2B, our method delivers a 3.4x reduction in FLOPs and a 3.3x speedup in vision encoding latency while retaining over 94% of the original performance, enabling real-time, high-precision navigation with minimal resource consumption.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23235.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23235",
    "published": "2026-02-26T17:12:40Z",
    "updated": "2026-02-26T17:12:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了GUIPruner框架，通过时间自适应分辨率和分层结构感知剪枝，有效解决高分辨率GUI代理的时空冗余问题，提升导航效率和精度。",
      "motivation": "纯视觉GUI代理在提供通用交互能力时，因处理高分辨率屏幕截图和历史轨迹而面临严重的效率瓶颈，时空冗余导致计算开销巨大。现有压缩方法存在时间不匹配和空间拓扑冲突：时间上忽视代理注意力衰减模式，空间上破坏网格完整性引发坐标定位错误，这限制了实时应用和精度。因此，亟需一种能平衡压缩与导航精度的新方案来解决这些不足。",
      "method": "GUIPruner是一个免训练的框架，针对高分辨率GUI导航而设计，结合了Temporal-Adaptive Resolution (TAR) 和 Stratified Structure-aware Pruning (SSP)。TAR基于衰减机制动态调整历史轨迹编码，减少时间冗余；SSP通过分层剪枝，优先保留交互前景和语义锚点，同时保护全局布局结构，避免空间幻觉，确保精确坐标定位，无需额外训练。",
      "result": "在多个基准测试中，GUIPruner取得了最先进性能，有效避免了大模型在高压缩下的性能崩溃。具体地，在Qwen2-VL-2B模型上，FLOPs减少了3.4倍，视觉编码延迟加速了3.3倍，同时保持超过94%的原始导航精度，显著优于基线方法，实现了实时高效的高分辨率GUI交互。",
      "conclusion": "该研究的主要贡献是提出了GUIPruner框架，成功解决了GUI代理的时空冗余挑战，在提升计算效率的同时维持了高导航精度。学术上，引入了新的剪枝范式；实际应用中，支持实时、低资源消耗的GUI导航系统。摘要未明确说明局限性，但未来工作可能涉及扩展到更复杂交互场景或与其他AI技术集成。",
      "tags": [
        "Token Pruning",
        "Adaptive Resolution",
        "Structure-aware Pruning",
        "GUI Agents",
        "High-Resolution Vision"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:27.745343Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23232",
    "title": "ReCoN-Ipsundrum: An Inspectable Recurrent Persistence Loop Agent with Affect-Coupled Control and Mechanism-Linked Consciousness Indicator Assays",
    "authors": [
      "Aishik Sanyal"
    ],
    "abstract": "Indicator-based approaches to machine consciousness recommend mechanism-linked evidence triangulated across tasks, supported by architectural inspection and causal intervention. Inspired by Humphrey's ipsundrum hypothesis, we implement ReCoN-Ipsundrum, an inspectable agent that extends a ReCoN state machine with a recurrent persistence loop over sensory salience Ns and an optional affect proxy reporting valence/arousal. Across fixed-parameter ablations (ReCoN, Ipsundrum, Ipsundrum+affect), we operationalize Humphrey's qualiaphilia (preference for sensory experience for its own sake) as a familiarity-controlled scenic-over-dull route choice. We find a novelty dissociation: non-affect variants are novelty-sensitive (Delta scenic-entry = 0.07). Affect coupling is stable (Delta scenic-entry = 0.01) even when scenic is less novel (median Delta novelty ~ -0.43). In reward-free exploratory play, the affect variant shows structured local investigation (scan events 31.4 vs. 0.9; cycle score 7.6). In a pain-tail probe, only the affect variant sustains prolonged planned caution (tail duration 90 vs. 5). Lesioning feedback+integration selectively reduces post-stimulus persistence in ipsundrum variants (AUC drop 27.62, 27.9%) while leaving ReCoN unchanged. These dissociations link recurrence -> persistence and affect-coupled control -> preference stability, scanning, and lingering caution, illustrating how indicator-like signatures can be engineered and why mechanistic and causal evidence should accompany behavioral markers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23232.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23232",
    "published": "2026-02-26T17:11:08Z",
    "updated": "2026-02-26T17:11:08Z",
    "comment": "Accepted at AAAI 2026 Spring Symposium - Machine Consciousness: Integrating Theory, Technology, and Philosophy",
    "light_analysis": {
      "overview": "本研究实现了ReCoN-Ipsundrum代理，通过循环持续环和情感耦合控制，为机器意识提供了可工程化的机制指标证据。",
      "motivation": "机器意识研究需要机制关联的证据来克服现有方法的局限性，例如缺乏可检查性和因果干预支持，导致难以可靠地区分意识状态。受汉弗莱的ipsundrum假说启发，本研究旨在解决如何工程化意识指标的问题，强调通过架构检查和因果干预来验证机制，从而提升意识研究的实证基础，避免仅依赖行为标记的不足。",
      "method": "论文扩展ReCoN状态机，引入循环持续环处理感官显著性，并可选添加情感代理报告效价/唤醒。通过固定参数消融实验比较ReCoN、Ipsundrum和Ipsundrum+affect变体，操作化汉弗莱的qualiaphilia作为熟悉控制下的风景-无聊路线选择。关键创新包括可检查的代理设计、循环持续环的集成和情感耦合控制的实现，使用感官显著性数据和状态机架构来模拟意识相关行为。",
      "result": "实验结果显示，非情感变体对新奇性敏感（Delta scenic-entry = 0.07），而情感耦合变体更稳定（Delta scenic-entry = 0.01）。在无奖励探索中，情感变体表现出结构化局部调查（扫描事件31.4 vs. 0.9；循环分数7.6）。在疼痛尾部探针中，只有情感变体持续谨慎（尾部持续时间90 vs. 5）。损伤反馈和积分特定减少ipsundrum变体的持续（AUC下降27.62, 27.9%），而ReCoN不变，表明循环导致持续行为，情感控制增强行为稳定性。",
      "conclusion": "研究证实循环结构促进持续，情感耦合控制导致偏好稳定性、扫描和谨慎行为，为机器意识提供了工程化的指标签名。学术价值在于通过可检查代理和实验验证，推动意识计算的实证发展；实际应用价值包括指导更可靠的意识建模。未来工作可扩展验证不同任务，以评估指标的泛化能力和局限性。",
      "tags": [
        "Recurrent Persistence Loop",
        "Affect-Coupled Control",
        "Consciousness Indicators",
        "State Machine",
        "Causal Intervention"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:26.959444Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23231",
    "title": "Skarimva: Skeleton-based Action Recognition is a Multi-view Application",
    "authors": [
      "Daniel Bermuth",
      "Alexander Poeppel",
      "Wolfgang Reif"
    ],
    "abstract": "Human action recognition plays an important role when developing intelligent interactions between humans and machines. While there is a lot of active research on improving the machine learning algorithms for skeleton-based action recognition, not much attention has been given to the quality of the input skeleton data itself. This work demonstrates that by making use of multiple camera views to triangulate more accurate 3D~skeletons, the performance of state-of-the-art action recognition models can be improved significantly. This suggests that the quality of the input data is currently a limiting factor for the performance of these models. Based on these results, it is argued that the cost-benefit ratio of using multiple cameras is very favorable in most practical use-cases, therefore future research in skeleton-based action recognition should consider multi-view applications as the standard setup.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23231.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23231",
    "published": "2026-02-26T17:10:58Z",
    "updated": "2026-02-26T17:10:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文通过多视图摄像头三角测量提高3D骨架精度，显著改进基于骨架的动作识别性能。",
      "motivation": "人类动作识别在开发智能人机交互中扮演关键角色，但当前研究主要聚焦于机器学习算法的优化，而忽略了输入骨架数据的质量问题，这导致现有模型的性能受限。该研究的动机在于解决数据不足这一瓶颈，通过多视图方法提供更精确的3D骨架输入，以提升动作识别的整体效果。",
      "method": "论文提出利用多个摄像头视图进行三角测量，以生成更准确的3D骨架数据。关键创新点在于将多视图技术应用于数据预处理阶段，强调数据质量改善而非仅算法优化。摘要未明确说明具体的数据集、模型架构或算法细节，但可以推断涉及标准的骨架动作识别框架，如使用深度学习模型处理多视图数据。",
      "result": "实验结果表明，使用多视图三角测量得到的3D骨架数据能显著提高最先进动作识别模型的性能。然而，摘要未提供具体的性能指标（如准确率提升百分比）或与基线方法的详细对比，因此结果基于定性描述，表明数据质量是当前模型性能的限制因素，并验证了多视图方法的有效性。",
      "conclusion": "论文的主要贡献是强调数据质量在基于骨架的动作识别中的重要性，并提出多视图设置作为实用解决方案。学术上，研究推动从算法优化到数据质量提升的转变；实际应用中，多摄像头系统的成本效益比高，适合大多数用例。未来工作可探索更高效的多视图技术或扩展到其他应用领域。",
      "tags": [
        "Skeleton-based Action Recognition",
        "3D Skeleton Reconstruction",
        "Multi-view Vision",
        "Triangulation",
        "Human Action Recognition"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:43.462713Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23229",
    "title": "Large Multimodal Models as General In-Context Classifiers",
    "authors": [
      "Marco Garosi",
      "Matteo Farina",
      "Alessandro Conti",
      "Massimiliano Mancini",
      "Elisa Ricci"
    ],
    "abstract": "Which multimodal model should we use for classification? Previous studies suggest that the answer lies in CLIP-like contrastive Vision-Language Models (VLMs), due to their remarkable performance in zero-shot classification. In contrast, Large Multimodal Models (LMM) are more suitable for complex tasks. In this work, we argue that this answer overlooks an important capability of LMMs: in-context learning. We benchmark state-of-the-art LMMs on diverse datasets for closed-world classification and find that, although their zero-shot performance is lower than CLIP's, LMMs with a few in-context examples can match or even surpass contrastive VLMs with cache-based adapters, their \"in-context\" equivalent. We extend this analysis to the open-world setting, where the generative nature of LMMs makes them more suitable for the task. In this challenging scenario, LMMs struggle whenever provided with imperfect context information. To address this issue, we propose CIRCLE, a simple training-free method that assigns pseudo-labels to in-context examples, iteratively refining them with the available context itself. Through extensive experiments, we show that CIRCLE establishes a robust baseline for open-world classification, surpassing VLM counterparts and highlighting the potential of LMMs to serve as unified classifiers, and a flexible alternative to specialized models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23229.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23229",
    "published": "2026-02-26T17:08:18Z",
    "updated": "2026-02-26T17:08:18Z",
    "comment": "CVPR Findings 2026. Project website at https://circle-lmm.github.io/",
    "light_analysis": {
      "overview": "本研究证明大型多模态模型（LMMs）通过上下文学习在分类任务中能媲美或超越对比视觉语言模型（VLMs），并提出CIRCLE方法提升开放世界分类性能。",
      "motivation": "该研究旨在解决多模态模型在分类任务中的选择问题。传统观点认为对比视觉语言模型（VLMs）在零样本分类中表现卓越，而大型多模态模型（LMMs）更适合复杂任务，但忽视了LMMs的上下文学习能力。这个问题重要，因为它限制了更灵活、通用分类器的发展，导致系统可能过度依赖专门模型，而现有方法如CLIP-like VLMs在上下文适应性方面不足，无法充分利用LMMs的生成特性进行泛化分类。",
      "method": "研究方法包括两个关键步骤：首先，对最先进的大型多模态模型（LMMs）进行基准测试，评估其在闭世界分类中的上下文学习性能，使用多样化但摘要未明确说明的数据集。其次，针对开放世界分类，提出CIRCLE方法，这是一种无需训练的简单技术，通过为上下文示例分配伪标签，并利用上下文信息本身进行迭代优化。关键创新点在于突出了LMMs的in-context learning能力，并引入CIRCLE来处理不完美的上下文，从而提高分类准确性和鲁棒性。",
      "result": "实验结果显示，在闭世界分类中，大型多模态模型（LMMs）在零样本性能上低于CLIP，但通过少量上下文示例，能匹配或超越带缓存适配器的对比视觉语言模型（VLMs）。在开放世界分类中，CIRCLE方法显著提升LMMs性能，超越了VLM的对应方法，并建立了强大的基准线。摘要未提供具体数据支撑，但强调了LMMs在上下文学习下的有效性，尤其是在处理复杂开放场景时，CIRCLE的迭代优化有效应对了上下文信息不完美的挑战。",
      "conclusion": "论文的主要贡献是展示了大型多模态模型（LMMs）作为通用上下文分类器的潜力，通过上下文学习替代专门模型。学术价值在于推动了多模态人工智能中上下文学习的研究，强调了生成式模型在分类任务中的优势。实际应用价值在于提供更灵活、统一的分类解决方案，减少对定制化模型的依赖。未来工作方向可能包括优化CIRCLE方法或扩展到其他多模态任务，以应对更广泛的应用场景。",
      "tags": [
        "Large Multimodal Models",
        "In-Context Learning",
        "Contrastive Vision-Language Models",
        "Classification",
        "CIRCLE"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:00.772833Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23228",
    "title": "MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction",
    "authors": [
      "Yizhi Li",
      "Xiaohan Chen",
      "Miao Jiang",
      "Wentao Tang",
      "Gaoang Wang"
    ],
    "abstract": "With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmented, fact-grounded generation process. Instead of requiring costly model fine-tuning, our framework directly leverages off-the-shelf models in a plug-and-play manner. We first invoke a specialized face recognition model as an external \"tool\" to establish Factual Groundings--precise character identities and their corresponding bounding boxes. These groundings are then injected into the prompt to steer the VLM's reasoning, ensuring the generated scene descriptions are anchored to verifiable facts. Furthermore, our progressive abstraction pipeline decomposes the summarization of a full-length movie into a multi-stage process, effectively mitigating the context length limitations of current VLMs. Experiments demonstrate that our approach yields significant improvements in factual accuracy, character consistency, and overall narrative coherence compared to end-to-end baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23228.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23228",
    "published": "2026-02-26T17:08:08Z",
    "updated": "2026-02-26T17:08:08Z",
    "comment": "6 pages, CSCWD 2026",
    "light_analysis": {
      "overview": "MovieTeller提出免训练、工具增强的渐进式抽象框架，用于生成高质量电影剧情摘要。",
      "motivation": "随着数字娱乐的爆炸性增长，自动化视频摘要在内容索引、个性化推荐和高效媒体归档等应用中变得不可或缺。然而，现有视觉语言模型（VLMs）在长视频（如电影）的自动剧情摘要方面存在关键失败，主要是缺乏ID一致的角色识别和叙事连贯性断裂，这限制了其在实际场景中的有效性，凸显了开发更鲁棒方法的必要性。",
      "method": "本研究提出MovieTeller框架，采用工具增强的渐进式抽象技术。核心是训练免费的生成过程，通过即插即用方式直接利用现成模型：首先调用专门的人脸识别模型作为外部工具，建立事实基础（包括精确的角色身份和边界框），然后注入到VLM的提示中以引导其推理。此外，框架通过渐进式抽象管道将电影摘要分解为多阶段过程，有效缓解了当前VLM的上下文长度限制。",
      "result": "实验表明，与端到端基线相比，MovieTeller在事实准确性、角色一致性和整体叙事连贯性方面取得了显著改进。摘要未明确提供具体性能指标数据，但指出该方法有效克服了长视频摘要中的关键挑战，提升了生成摘要的质量和可靠性。",
      "conclusion": "MovieTeller的主要贡献是开发免训练、工具增强的框架，通过渐进式抽象实现高质量电影剧情摘要。该方法不仅解决了现有VLMs的局限性，还展示了在内容索引和推荐系统等应用中的潜力。未来工作可能包括扩展至其他视频类型或优化工具集成，但摘要未明确说明具体局限性或方向。",
      "tags": [
        "Vision-Language Models (VLMs)",
        "Face Recognition",
        "Tool-Augmented Generation",
        "Progressive Abstraction",
        "Automated Video Summarization"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:55.101021Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23225",
    "title": "Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?",
    "authors": [
      "Pengxiang Li",
      "Dilxat Muhtar",
      "Lu Yin",
      "Tianlong Chen",
      "Shiwei Liu"
    ],
    "abstract": "Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism increases. Our results suggest that revisiting data and supervision is a principled direction for mitigating AR-like behavior and moving toward genuinely non-autoregressive parallel generation in DLMs. Our code is available at https://github.com/pixeli99/NAP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23225.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23225",
    "published": "2026-02-26T17:04:57Z",
    "updated": "2026-02-26T17:04:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出NAP方法，通过优化数据监督实现扩散语言模型的真正非自回归并行解码。",
      "motivation": "扩散语言模型（DLMs）常被宣传支持并行token生成，但在实际解码中往往呈现类似自回归（AR）的动态，限制了并行硬件利用，因为训练数据（如标准预训练语料和长链思考监督）具有高度顺序结构，与DLMs目标不匹配。这导致无法充分发挥并行潜力，减少同步开销和改善延迟缩放，而现有方法在非AR生成方面不足，因为数据监督未能对齐，影响了效率提升。摘要未明确说明具体应用场景，但强调了问题的重要性。",
      "method": "论文提出了NAP（非自回归并行扩散语言模型），一种以数据为中心的概念验证方法。核心是通过策划训练示例作为多个独立的推理轨迹，并结合并行强制解码策略，鼓励多token的并行更新。这种方法旨在更好地将监督与非AR并行解码对齐，关键创新点包括数据重采样策略和强制解码机制，以减少对AR行为的依赖。使用数据集为数学推理基准，但未提及具体模型架构细节。摘要未明确说明技术实现的具体参数。",
      "result": "在数学推理基准测试中，NAP在并行解码下比在标准长链思考数据上训练的扩散语言模型表现更强，随着并行性增加，性能增益逐步提高。摘要未提供具体准确率或效率数据，但强调了与基线方法的对比优势，表明方法有效缓解了AR倾向，验证了数据监督对齐在提升并行解码性能中的作用，结果支持了促进真正非AR生成的潜力。",
      "conclusion": "研究的主要贡献是识别出扩散语言模型中AR解码的根本原因，并提出通过数据监督对齐来缓解。NAP方法在实验中展示了改善并行解码性能的能力，为未来实现真正非AR并行生成指明了方向，学术上强调了数据在训练中的关键作用，实际应用中可能提升模型在长序列任务中的效率。局限性包括方法可能对特定任务有效，未来工作可扩展到其他领域。",
      "tags": [
        "Diffusion Language Models",
        "Non-Autoregressive Decoding",
        "Parallel Decoding",
        "Chain-of-Thought",
        "Data-Centric Approach"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:15.607249Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23224",
    "title": "UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception",
    "authors": [
      "Mohammad Mahdavian",
      "Gordon Tan",
      "Binbin Xu",
      "Yuan Ren",
      "Dongfeng Bai",
      "Bingbing Liu"
    ],
    "abstract": "We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental structure from raw image sequences is critical for downstream tasks. UniScale addresses this challenge with a single feed-forward network that jointly estimates camera intrinsics and extrinsics, scale-invariant depth and point maps, and the metric scale of a scene from multi-view images, while optionally incorporating auxiliary geometric priors when available. By combining global contextual reasoning with camera-aware feature representations, UniScale is able to recover the metric-scale of the scene. In robotic settings where camera intrinsics are known, they can be easily incorporated to improve performance, with additional gains obtained when camera poses are also available. This co-design enables robust, metric-aware 3D reconstruction within a single unified model. Importantly, UniScale does not require training from scratch, and leverages world priors exhibited in pre-existing models without geometric encoding strategies, making it particularly suitable for resource-constrained robotic teams. We evaluate UniScale on multiple benchmarks, demonstrating strong generalization and consistent performance across diverse environments. We will release our implementation upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23224.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23224",
    "published": "2026-02-26T17:04:36Z",
    "updated": "2026-02-26T17:04:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "UniScale提出一个统一的尺度感知多视图3D重建框架，通过先验注入提升机器人环境感知的准确性和鲁棒性。",
      "motivation": "在基于视觉的机器人导航中，从图像序列中准确提取三维环境结构对下游任务如路径规划至关重要，但现有方法往往面临尺度不确定性和泛化能力不足的挑战。本研究旨在解决这一实际问题，通过开发一个统一框架，从多视图图像中恢复度量尺度，以增强机器人感知的可靠性，应对复杂环境下的导航需求，弥补传统方法在整合几何先验和适应资源受限场景方面的局限性。",
      "method": "UniScale采用单一前馈网络，联合估计相机内参、外参、尺度不变深度图、点云和场景的度量尺度。关键创新在于通过模块化设计灵活整合几何先验，结合全局上下文推理与相机感知特征表示来恢复精确尺度。该方法利用预训练模型中的世界先验，无需从头训练，适合资源受限的机器人系统，并能在已知相机参数时进一步优化性能，实现高效且可扩展的3D重建。",
      "result": "论文在多个基准数据集上评估UniScale，展示了其强泛化能力和在不同环境中的一致性能。摘要未明确说明具体量化指标，如准确率或效率改进，但表明与基线方法相比，UniScale在尺度感知和鲁棒性方面有显著提升，能够有效处理多视图图像序列，支持机器人应用的可靠3D重建。",
      "conclusion": "UniScale的主要贡献是提供了一个统一的度量感知3D重建框架，通过先验注入实现鲁棒场景理解，学术价值在于推进多视图重建技术在尺度恢复方面的进展，实际应用价值在于为资源受限的机器人团队提供高效解决方案。未来工作可能包括扩展到更复杂场景或集成更多类型的先验知识，以进一步提升通用性和适应性。",
      "tags": [
        "Scale-Aware 3D Reconstruction",
        "Multi-View Reconstruction",
        "Geometric Priors",
        "Camera Pose Estimation",
        "Robotic Perception"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:13.050125Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23219",
    "title": "Takeuchi's Information Criteria as Generalization Measures for DNNs Close to NTK Regime",
    "authors": [
      "Hiroki Naganuma",
      "Taiji Suzuki",
      "Rio Yokota",
      "Masahiro Nomura",
      "Kohta Ishikawa",
      "Ikuro Sato"
    ],
    "abstract": "Generalization measures have been studied extensively in the machine learning community to better characterize generalization gaps. However, establishing a reliable generalization measure for statistically singular models such as deep neural networks (DNNs) is difficult due to their complex nature. This study focuses on Takeuchi's information criterion (TIC) to investigate the conditions under which this classical measure can effectively explain the generalization gaps of DNNs. Importantly, the developed theory indicates the applicability of TIC near the neural tangent kernel (NTK) regime. In a series of experiments, we trained more than 5,000 DNN models with 12 architectures, including large models (e.g., VGG-16), on four datasets, and estimated the corresponding TIC values to examine the relationship between the generalization gap and the TIC estimates. We applied several TIC approximation methods with feasible computational costs and assessed the accuracy trade-off. Our experimental results indicate that the estimated TIC values correlate well with the generalization gap under conditions close to the NTK regime. However, we show both theoretically and empirically that outside the NTK regime such correlation disappears. Finally, we demonstrate that TIC provides better trial pruning ability than existing methods for hyperparameter optimization.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23219.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23219",
    "published": "2026-02-26T17:01:14Z",
    "updated": "2026-02-26T17:01:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文研究表明，Takeuchi信息准则在接近神经切线核区域的条件下，可作为深度神经网络的有效泛化度量。",
      "motivation": "在机器学习中，泛化度量用于表征模型性能与泛化差距，但深度神经网络（DNN）等复杂模型因其统计奇异性质，建立可靠度量困难。现有方法难以准确解释DNN的泛化行为，这限制了模型优化和理解。本研究旨在探索Takeuchi信息准则（TIC）是否能在特定条件下解决此问题，弥补当前泛化度量研究的不足，推动更精准的模型评估。",
      "method": "论文通过理论分析探究Takeuchi信息准则在神经切线核（NTK）区域附近的适用性，作为泛化度量的核心方法。实验上，训练超过5,000个深度神经网络模型，涵盖12种架构如VGG-16，并在四个数据集上进行验证。使用多种TIC近似方法以控制计算成本，估计TIC值并分析其与泛化差距的关系，旨在平衡准确性和效率。",
      "result": "实验结果显示，在接近NTK区域的条件下，估计的Takeuchi信息准则值与泛化差距呈现良好相关性，表明其作为度量的有效性。理论和实证证据均证明，超出NTK区域时，这种相关性消失。此外，TIC在超参数优化中展示出比现有方法更好的试验剪枝能力，提高了优化过程的效率，尽管摘要未提供具体数值对比。",
      "conclusion": "本研究主要贡献在于证明了Takeuchi信息准则在接近神经切线核区域时能有效度量深度神经网络的泛化差距，为复杂模型的泛化分析提供新视角。学术上，推动泛化度量的理论研究；实际中，可提升超参数优化效率。局限性是仅适用于NTK附近的DNN，未来工作可扩展到更广泛的条件或结合其他度量方法。",
      "tags": [
        "Takeuchi's Information Criterion",
        "Neural Tangent Kernel",
        "Deep Neural Networks",
        "Generalization Measures",
        "Hyperparameter Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:15.595874Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23217",
    "title": "Multidimensional Task Learning: A Unified Tensor Framework for Computer Vision Tasks",
    "authors": [
      "Alaa El Ichi",
      "Khalide Jbilou"
    ],
    "abstract": "This paper introduces Multidimensional Task Learning (MTL), a unified mathematical framework based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. We argue that current computer vision task formulations are inherently constrained by matrix-based thinking: standard architectures rely on matrix-valued weights and vectorvalued biases, requiring structural flattening that restricts the space of naturally expressible tasks. GE-MLPs lift this constraint by operating with tensor-valued parameters, enabling explicit control over which dimensions are preserved or contracted without information loss. Through rigorous mathematical derivations, we demonstrate that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration within a formally defined task space. We further prove that this task space is strictly larger than what matrix-based formulations can natively express, enabling principled task configurations such as spatiotemporal or cross modal predictions that require destructive flattening under conventional approaches. This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through the lens of tensor algebra.",
    "categories": [
      "cs.CV",
      "math.NA"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23217.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23217",
    "published": "2026-02-26T17:00:45Z",
    "updated": "2026-02-26T17:00:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了基于广义爱因斯坦MLPs的张量框架，统一处理计算机视觉任务，通过爱因斯坦积直接操作张量，解除矩阵基础限制。",
      "motivation": "当前计算机视觉任务表述普遍受限于矩阵基础思维，标准架构依赖矩阵值权重和向量值偏置，导致任务需要结构扁平化，这限制了自然可表达任务的空间。问题在于现有方法无法灵活处理多维数据，如时空或跨模态预测，在传统方法中可能需要进行破坏性压缩，造成信息损失。因此，需要一种更通用的数学框架来克服这些不足，支持更广泛的任务配置，提升计算机视觉系统的表达能力和效率。",
      "method": "论文提出Multidimensional Task Learning (MTL)框架，核心是基于Generalized Einstein MLPs (GE-MLPs)。该方法使用张量值参数，并通过爱因斯坦积直接在张量上操作，允许显式控制维度的保留或压缩，避免了信息损失。关键创新在于通过数学推导，将分类、分割和检测等任务统一为任务空间中不同的维度配置，而无需矩阵基础的结构扁平化。这为计算机视觉任务提供了统一的张量代数描述，简化了任务设计和比较。",
      "result": "摘要未明确说明具体实验数据。理论结果表明，MTL框架证明分类、分割和检测是其特殊案例，仅在正式定义的任务空间中维度配置不同。作者进一步证明了该任务空间比矩阵基础表述能本机表达的空间更大，支持原则性任务配置，如spatiotemporal或cross modal predictions，而传统方法需要破坏性扁平化。这些数学推导为任务设计提供了理论基础，突出了框架在扩展任务表达空间方面的优势。",
      "conclusion": "本研究的主要贡献是提供了一个基于张量代数的数学基础，用于理解、比较和设计计算机视觉任务。学术上，它统一了多种任务类型，扩展了任务表达空间，支持更复杂和灵活的配置。实际应用价值包括促进高效系统开发，如时空预测或跨模态分析。未来工作方向摘要未明确说明，但可能包括进一步实验验证和应用扩展到更多领域，以评估框架的实际性能和泛化能力。",
      "tags": [
        "Multidimensional Task Learning",
        "Generalized Einstein MLPs",
        "Tensor Algebra",
        "Einstein Product",
        "Computer Vision Framework"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:16.842576Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23214",
    "title": "Plug-and-Play Diffusion Meets ADMM: Dual-Variable Coupling for Robust Medical Image Reconstruction",
    "authors": [
      "Chenhe Du",
      "Xuanyu Tian",
      "Qing Wu",
      "Muyu Liu",
      "Jingyi Yu",
      "Hongjiang Wei",
      "Yuyao Zhang"
    ],
    "abstract": "Plug-and-Play diffusion prior (PnPDP) frameworks have emerged as a powerful paradigm for solving imaging inverse problems by treating pretrained generative models as modular priors. However, we identify a critical flaw in prevailing PnP solvers (e.g., based on HQS or Proximal Gradient): they function as memoryless operators, updating estimates solely based on instantaneous gradients. This lack of historical tracking inevitably leads to non-vanishing steady-state bias, where the reconstruction fails to strictly satisfy physical measurements under heavy corruption. To resolve this, we propose Dual-Coupled PnP Diffusion, which restores the classical dual variable to provide integral feedback, theoretically guaranteeing asymptotic convergence to the exact data manifold. However, this rigorous geometric coupling introduces a secondary challenge: the accumulated dual residuals exhibit spectrally colored, structured artifacts that violate the Additive White Gaussian Noise (AWGN) assumption of diffusion priors, causing severe hallucinations. To bridge this gap, we introduce Spectral Homogenization (SH), a frequency-domain adaptation mechanism that modulates these structured residuals into statistically compliant pseudo-AWGN inputs. This effectively aligns the solver's rigorous optimization trajectory with the denoiser's valid statistical manifold. Extensive experiments on CT and MRI reconstruction demonstrate that our approach resolves the bias-hallucination trade-off, achieving state-of-the-art fidelity with significantly accelerated convergence.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23214.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23214",
    "published": "2026-02-26T16:58:43Z",
    "updated": "2026-02-26T16:58:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出双耦合即插即用扩散与频谱均匀化方法，解决医学图像重建中即插即用求解器的偏差-幻觉权衡问题。",
      "motivation": "本研究针对即插即用扩散先验框架在成像逆问题中的应用，发现现有求解器如基于HQS或近端梯度的方法存在内存less缺陷，仅依赖瞬时梯度更新，导致非零稳态偏差，无法在严重噪声污染下严格满足物理测量约束。在医学图像重建等关键应用中，这种偏差和幻觉伪影会降低图像保真度，影响诊断准确性。现有方法因缺乏历史追踪而无法保证收敛，因此解决这一偏差-幻觉权衡问题至关重要，以提升重建质量和可靠性。",
      "method": "方法上，论文提出双耦合即插即用扩散方法，通过恢复ADMM中的双变量来提供积分反馈，实现渐近收敛到精确数据流形，从而消除稳态偏差。然而，该几何耦合引入积累的双变量残差，其频谱着色结构化伪影违反了扩散先验的加性白高斯噪声假设，导致严重幻觉。为此，引入频谱均匀化机制，在频域中调制这些结构化残差为统计合规的伪AWGN输入，有效对齐求解器的优化轨迹与去噪器的有效统计流形。该方法应用于CT和MRI重建任务，结合扩散先验作为模块化先验。",
      "result": "在CT和MRI重建的广泛实验中，该方法成功解决了偏差-幻觉权衡问题。实验表明，通过双变量耦合和频谱均匀化的结合，重建图像在保真度上达到最先进水平，并实现显著加速的收敛速度。与基于HQS或近端梯度的基线方法相比，新方法能够严格满足物理测量约束，减少幻觉伪影，在重噪声环境下提升重建稳健性。摘要未提供具体数值指标，但强调在验证中展现出优异的性能表现。",
      "conclusion": "结论上，本研究主要贡献在于提出双耦合即插即用扩散和频谱均匀化方法，有效解决了医学图像重建中的偏差-幻觉权衡问题。学术上，该方法为成像逆问题提供了理论保证收敛的新框架，改进即插即用扩散先验的实用性。实际应用中，通过提高重建保真度和加速收敛，有助于提升医学成像的诊断效果。未来工作可能扩展到其他成像模态或探索更高效的噪声适应机制，以进一步优化性能。",
      "tags": [
        "Plug-and-Play Diffusion",
        "ADMM",
        "Dual Variable Coupling",
        "Spectral Homogenization",
        "Medical Image Reconstruction"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:46.681514Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23212",
    "title": "Through BrokenEyes: How Eye Disorders Impact Face Detection?",
    "authors": [
      "Prottay Kumar Adhikary"
    ],
    "abstract": "Vision disorders significantly impact millions of lives, altering how visual information is processed and perceived. In this work, a computational framework was developed using the BrokenEyes system to simulate five common eye disorders: Age-related macular degeneration, cataract, glaucoma, refractive errors, and diabetic retinopathy and analyze their effects on neural-like feature representations in deep learning models. Leveraging a combination of human and non-human datasets, models trained under normal and disorder-specific conditions revealed critical disruptions in feature maps, particularly for cataract and glaucoma, which align with known neural processing challenges in these conditions. Evaluation metrics such as activation energy and cosine similarity quantified the severity of these distortions, providing insights into the interplay between degraded visual inputs and learned representations.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23212.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23212",
    "published": "2026-02-26T16:56:51Z",
    "updated": "2026-02-26T16:56:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文开发了BrokenEyes系统，模拟五种常见眼疾病，量化其对深度学习模型中特征表示的负面影响。",
      "motivation": "视力障碍影响数百万人的视觉信息处理和感知，但现有研究可能未充分探讨眼疾病如何具体影响深度学习模型的特征表示。本研究旨在通过模拟眼疾病，揭示退化视觉输入对神经网络学习过程的影响，为理解视觉障碍与AI交互提供基础，解决模型在视觉退化条件下的鲁棒性问题。摘要未明确说明现有方法的不足，但可推断出量化眼疾病对AI模型影响的研究尚不深入。",
      "method": "研究方法基于BrokenEyes计算框架，模拟五种眼疾病：老年性黄斑变性、白内障、青光眼、屈光不正和糖尿病视网膜病变。使用人类和非人类混合数据集，在正常和疾病特定条件下训练深度学习模型，分析特征映射的变化。关键创新点在于结合模拟眼疾病与特征表示分析，利用激活能量和余弦相似性等量化指标评估失真程度。摘要未明确说明具体模型架构，但涉及深度学习技术。",
      "result": "实验结果显示，在白内障和青光眼的模拟条件下，深度学习模型的特征映射出现关键性破坏，与已知神经处理挑战一致。使用激活能量和余弦相似性等指标量化了失真的严重程度，但摘要未提供具体数值。通过与正常条件对比，揭示了眼疾病对模型表示的具体影响，为视觉退化输入与学习交互提供了数据支撑。摘要未明确说明基线方法对比，但强调了模拟条件下的显著差异。",
      "conclusion": "本研究通过BrokenEyes系统，揭示了眼疾病对深度学习模型特征表示的影响，增进了对视觉退化输入与学习表示交互的理解。学术上填补了眼疾病对AI模型影响量化研究的空白；应用上可能促进开发更鲁棒的视觉AI系统，例如在人脸检测等任务中。未来工作可扩展疾病模拟范围或应用于实际场景，如医疗诊断辅助。摘要未明确说明局限性，但可推断出数据集或疾病类型的限制。",
      "tags": [
        "Eye Disorders Simulation",
        "Deep Learning",
        "Feature Maps Analysis",
        "Activation Energy",
        "Cosine Similarity"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:41.805805Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23205",
    "title": "EmbodMocap: In-the-Wild 4D Human-Scene Reconstruction for Embodied Agents",
    "authors": [
      "Wenjia Wang",
      "Liang Pan",
      "Huaijin Pi",
      "Yuke Lou",
      "Xuqian Ren",
      "Yifan Wu",
      "Zhouyingcheng Liao",
      "Lei Yang",
      "Rishabh Dabral",
      "Christian Theobalt",
      "Taku Komura"
    ],
    "abstract": "Human behaviors in the real world naturally encode rich, long-term contextual information that can be leveraged to train embodied agents for perception, understanding, and acting. However, existing capture systems typically rely on costly studio setups and wearable devices, limiting the large-scale collection of scene-conditioned human motion data in the wild. To address this, we propose EmbodMocap, a portable and affordable data collection pipeline using two moving iPhones. Our key idea is to jointly calibrate dual RGB-D sequences to reconstruct both humans and scenes within a unified metric world coordinate frame. The proposed method allows metric-scale and scene-consistent capture in everyday environments without static cameras or markers, bridging human motion and scene geometry seamlessly. Compared with optical capture ground truth, we demonstrate that the dual-view setting exhibits a remarkable ability to mitigate depth ambiguity, achieving superior alignment and reconstruction performance over single iphone or monocular models. Based on the collected data, we empower three embodied AI tasks: monocular human-scene-reconstruction, where we fine-tune on feedforward models that output metric-scale, world-space aligned humans and scenes; physics-based character animation, where we prove our data could be used to scale human-object interaction skills and scene-aware motion tracking; and robot motion control, where we train a humanoid robot via sim-to-real RL to replicate human motions depicted in videos. Experimental results validate the effectiveness of our pipeline and its contributions towards advancing embodied AI research.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23205.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23205",
    "published": "2026-02-26T16:53:41Z",
    "updated": "2026-02-26T16:53:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "EmbodMocap 提出一个使用双移动 iPhone 的便携数据收集流程，实现野外 4D 人类-场景重建，促进具身 AI 研究。",
      "motivation": "现有捕捉系统依赖昂贵的设备和静态设置，如工作室光学捕捉和可穿戴设备，难以在真实世界中大规模收集场景条件的人类运动数据。这限制了具身 AI 的发展，因为人类行为编码的丰富上下文信息对训练感知、理解和行动的代理至关重要。本研究旨在解决现有方法成本高、不便携的不足，通过经济高效的方案实现野外数据采集，以支持大规模具身 AI 研究。",
      "method": "EmbodMocap 采用两个移动 iPhone 同时捕获双 RGB-D 序列，并通过联合校准技术将它们对齐到统一的度量世界坐标系中。该方法无需静态相机或标记，核心创新在于利用双视角有效减少深度模糊，实现人类运动和场景几何的无缝整合。关键技术包括便携设备上的多视角融合和度量尺度重建，允许在日常环境中进行场景一致的捕捉。",
      "result": "与光学捕捉 ground truth 相比，实验显示双视角设置显著减少深度模糊，在配准和重建性能上优于单 iPhone 或单目模型。基于收集的数据，在三个具身 AI 任务中取得进展：单目人类-场景重建输出度量尺度对齐的数据；物理角色动画扩展了人-物交互技能；机器人运动控制通过 sim-to-real RL 成功复制视频中的人类运动。这些结果验证了流程对推进具身 AI 研究的有效性。",
      "conclusion": "EmbodMocap 提供了一个便携、经济的数据收集流程，成功实现了野外人类-场景的度量尺度重建。其在学术上推动了具身 AI 研究，为多个任务提供新数据和方法，在实际应用中支持了角色动画和机器人控制等领域。未来工作可能包括进一步优化技术以应对更复杂的环境，并扩展应用到更多交互场景中。",
      "tags": [
        "Human-Scene Reconstruction",
        "Dual-View Calibration",
        "Sim-to-Real Reinforcement Learning",
        "Physics-based Animation",
        "Embodied AI"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:00.723026Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23204",
    "title": "Motion-aware Event Suppression for Event Cameras",
    "authors": [
      "Roberto Pellerito",
      "Nico Messikommer",
      "Giovanni Cioffi",
      "Marco Cannici",
      "Davide Scaramuzza"
    ],
    "abstract": "In this work, we introduce the first framework for Motion-aware Event Suppression, which learns to filter events triggered by IMOs and ego-motion in real time. Our model jointly segments IMOs in the current event stream while predicting their future motion, enabling anticipatory suppression of dynamic events before they occur. Our lightweight architecture achieves 173 Hz inference on consumer-grade GPUs with less than 1 GB of memory usage, outperforming previous state-of-the-art methods on the challenging EVIMO benchmark by 67\\% in segmentation accuracy while operating at a 53\\% higher inference rate. Moreover, we demonstrate significant benefits for downstream applications: our method accelerates Vision Transformer inference by 83\\% via token pruning and improves event-based visual odometry accuracy, reducing Absolute Trajectory Error (ATE) by 13\\%.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23204.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23204",
    "published": "2026-02-26T16:53:36Z",
    "updated": "2026-02-26T16:53:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出首个运动感知事件抑制框架，实时过滤事件相机中的动态事件，实现高效抑制。",
      "motivation": "事件相机在高速视觉应用中面临事件流混杂问题，独立移动对象（IMOs）和自运动触发的事件需要实时过滤以提高处理效率。现有方法在处理动态场景时，可能无法兼顾分割准确性、推理速度和内存使用，特别是在复杂环境下。本研究旨在解决这些不足，开发一个框架来优化事件处理，支持下游任务的高效执行。",
      "method": "论文提出一个运动感知事件抑制框架，通过模型联合分割当前事件流中的独立移动对象（IMOs），并预测其未来运动，实现事件的预期性抑制。采用轻量级架构设计，优化推理效率，在消费级GPU上高速处理，具体模型架构和训练细节摘要未明确说明，但强调实时性和低内存占用。",
      "result": "在EVIMO基准测试中，该模型分割准确率比之前最佳方法提升67%，推理速率提高53%，达到173 Hz，内存使用小于1 GB。下游应用中，通过令牌剪枝（token pruning）加速Vision Transformer推理83%，并改进基于事件的视觉里程计准确性，绝对轨迹误差（ATE）减少13%。",
      "conclusion": "该研究提出首个运动感知事件抑制框架，显著提升事件相机处理动态事件的实时性和准确性，为高速视觉应用提供新方法。学术上，它推动事件处理技术的发展；实际上，加速了视觉里程计和Transformer推理等任务，但局限性或未来工作摘要未明确说明。",
      "tags": [
        "Event Cameras",
        "Motion-aware Processing",
        "Lightweight Architecture",
        "Token Pruning",
        "Event-based Visual Odometry"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:57.001160Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23203",
    "title": "ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation",
    "authors": [
      "Junhu Fu",
      "Shuyu Liang",
      "Wutong Li",
      "Chen Ma",
      "Peng Huang",
      "Kehao Wang",
      "Ke Chen",
      "Shengli Lin",
      "Pinghong Zhou",
      "Zeju Li",
      "Yuanyuan Wang",
      "Yi Guo"
    ],
    "abstract": "Colonoscopy video generation delivers dynamic, information-rich data critical for diagnosing intestinal diseases, particularly in data-scarce scenarios. High-quality video generation demands temporal consistency and precise control over clinical attributes, but faces challenges from irregular intestinal structures, diverse disease representations, and various imaging modalities. To this end, we propose ColoDiff, a diffusion-based framework that generates dynamic-consistent and content-aware colonoscopy videos, aiming to alleviate data shortage and assist clinical analysis. At the inter-frame level, our TimeStream module decouples temporal dependency from video sequences through a cross-frame tokenization mechanism, enabling intricate dynamic modeling despite irregular intestinal structures. At the intra-frame level, our Content-Aware module incorporates noise-injected embeddings and learnable prototypes to realize precise control over clinical attributes, breaking through the coarse guidance of diffusion models. Additionally, ColoDiff employs a non-Markovian sampling strategy that cuts steps by over 90% for real-time generation. ColoDiff is evaluated across three public datasets and one hospital database, based on both generation metrics and downstream tasks including disease diagnosis, modality discrimination, bowel preparation scoring, and lesion segmentation. Extensive experiments show ColoDiff generates videos with smooth transitions and rich dynamics. ColoDiff presents an effort in controllable colonoscopy video generation, revealing the potential of synthetic videos in complementing authentic representation and mitigating data scarcity in clinical settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23203.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23203",
    "published": "2026-02-26T16:51:24Z",
    "updated": "2026-02-26T16:51:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "ColoDiff 是一个基于扩散模型的框架，通过动态一致性和内容感知技术生成高质量的结肠镜视频，以解决数据稀缺问题。",
      "motivation": "结肠镜视频生成在肠道疾病诊断中提供动态、信息丰富的数据，尤其在数据稀缺情况下至关重要。然而，高质量视频生成面临时间一致性和临床属性精确控制的挑战，包括肠道结构不规则、疾病表现形式多样以及不同成像模态的复杂性。现有方法可能在处理这些动态建模和精细控制方面存在不足，导致视频质量不高或可控性差。因此，本研究提出ColoDiff框架，旨在通过集成动态一致性和内容感知技术，生成高质量的结肠镜视频，以缓解数据短缺并辅助临床分析。",
      "method": "ColoDiff框架基于扩散模型，通过TimeStream模块和Content-Aware模块处理视频生成的动态一致性和内容控制。TimeStream模块在帧间级别使用跨帧标记化机制，将时间依赖性解耦，从而有效建模结肠镜视频中的动态变化，即使面对肠道结构不规则也能实现平滑过渡。Content-Aware模块在帧内级别引入噪声注入嵌入和可学习原型，实现对特定临床属性的精确控制，如疾病特征或成像模态，克服传统扩散模型指导的粗糙性。同时，框架采用非马尔可夫采样策略，显著减少生成步骤超过90%，大幅提升生成速度，支持实时应用。",
      "result": "ColoDiff在实验中使用三个公共数据集和一个医院数据库进行评估，涵盖了生成质量和下游任务的性能。下游任务包括疾病诊断、模态鉴别、肠道准备评分和病灶分割，用于验证生成视频的实用价值。实验结果证实，ColoDiff生成的视频具有平滑的时间过渡和丰富的动态细节，表明其在保持视频一致性方面的优势。非马尔可夫采样策略显著减少了生成步骤超过90%，大大提升了生成效率，使得实时生成成为可能。尽管摘要未提供具体的定量对比数据，但实验表明ColoDiff在多个任务中表现良好，有效缓解了数据稀缺问题。",
      "conclusion": "ColoDiff的主要贡献在于提出了一个集成动态一致性与内容感知的扩散模型框架，用于生成高质量的结肠镜视频，这在可控医学视频生成领域具有创新性。研究不仅提升了视频生成的动态平滑度和临床属性控制精度，还通过非马尔可夫采样实现了实时生成，增强了实用性。从学术角度看，该工作扩展了扩散模型在视频生成中的应用，特别是在医学影像领域，为后续研究提供了参考。在应用层面，ColoDiff能够补充真实结肠镜视频，缓解数据稀缺问题，辅助临床诊断和分析。未来可以探索在更多医学视频任务中的应用或进一步优化模型的泛化能力。",
      "tags": [
        "Diffusion Models",
        "Temporal Consistency",
        "Content-Aware Generation",
        "Non-Markovian Sampling",
        "Colonoscopy Video Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:27.672102Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23201",
    "title": "Tell Me What To Learn: Generalizing Neural Memory to be Controllable in Natural Language",
    "authors": [
      "Max S. Bennett",
      "Thomas P. Zollo",
      "Richard Zemel"
    ],
    "abstract": "Modern machine learning models are deployed in diverse, non-stationary environments where they must continually adapt to new tasks and evolving knowledge. Continual fine-tuning and in-context learning are costly and brittle, whereas neural memory methods promise lightweight updates with minimal forgetting. However, existing neural memory models typically assume a single fixed objective and homogeneous information streams, leaving users with no control over what the model remembers or ignores over time. To address this challenge, we propose a generalized neural memory system that performs flexible updates based on learning instructions specified in natural language. Our approach enables adaptive agents to learn selectively from heterogeneous information sources, supporting settings, such as healthcare and customer service, where fixed-objective memory updates are insufficient.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23201.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23201",
    "published": "2026-02-26T16:50:52Z",
    "updated": "2026-02-26T16:50:52Z",
    "comment": "58 Pages, 16 Figures, Code at https://github.com/maxbennett/Generalized-Neural-Memory",
    "light_analysis": {
      "overview": "论文提出一种通用神经记忆系统，通过自然语言指令实现可控记忆更新，以支持自适应学习。",
      "motivation": "现代机器学习模型部署在多样、非平稳环境中，需要持续适应新任务和不断演进的知识。现有方法如持续微调和上下文学习成本高且脆弱，而神经记忆方法虽提供轻量级更新但假设单一固定目标和同质信息流，用户无法控制模型随时间记住或忽略的内容。这在实际应用如医疗保健和客户服务中限制了模型的适应性，因为这些场景需要处理异质信息源，因此亟需更灵活的更新机制来解决用户控制缺失的问题。",
      "method": "论文提出一个广义神经记忆系统，其核心创新在于使用自然语言指令来控制学习过程。该系统能够解析用户指定的学习指令，执行灵活的记忆更新，从而支持从异质信息源中选择性学习。虽然摘要未详细说明具体模型架构、数据集或技术实现细节，但方法旨在实现轻量级更新和最小遗忘，适用于非平稳环境，并通过自然语言接口增强用户对模型学习行为的控制。",
      "result": "摘要未明确说明具体的实验结果。论文可能通过实验展示了所提系统在适应性学习任务上的效果，例如与基线神经记忆模型相比，在控制记忆内容方面的优势。然而，具体的性能指标如准确率提升、效率改进或详细对比数据在摘要中未提及，需要参考论文全文以获取更全面的结果分析。",
      "conclusion": "本研究的主要贡献是提出了一种可控的神经记忆系统，允许通过自然语言指令灵活管理学习内容，解决了现有方法在用户控制方面的不足。这提高了模型在多样环境中的适应性，具有重要的学术价值和实际应用价值，尤其在需要处理异质信息源的领域如医疗保健和客户服务。未来工作可能包括扩展系统的指令复杂性和验证在更多场景中的有效性。",
      "tags": [
        "Neural Memory",
        "Natural Language Instructions",
        "Continual Learning",
        "Adaptive Agents",
        "Heterogeneous Information Sources"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:08.371064Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23200",
    "title": "InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models",
    "authors": [
      "Sayed Mohammadreza Tayaranian Hosseini",
      "Amir Ardakani",
      "Warren J. Gross"
    ],
    "abstract": "Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute units. This reduces memory accesses and accelerates dequantization, yielding up to $22\\%$ speedup over previous work and up to $88\\%$ over half-precision vector-matrix multiplication. To preserve fidelity under aggressive compression, InnerQ incorporates (i) hybrid quantization, selecting symmetric or asymmetric quantization per group based on local statistics; (ii) high-precision windows for both the most recent tokens and the attention sink tokens to mitigate outlier leakage; and (iii) per-channel normalization of the key cache, computed once during prefill and folded into the query to avoid runtime overhead. Our evaluation experiments on Llama models shows that InnerQ maintains a few-shot GSM8K performance comparable to non-quantized KV caches and surpasses prior KV cache quantization methods.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23200.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23200",
    "published": "2026-02-26T16:50:36Z",
    "updated": "2026-02-26T16:50:36Z",
    "comment": "16 pages, 4 figures, 4 tables, 2 algorithms",
    "light_analysis": {
      "overview": "本文提出InnerQ，一种硬件感知的无调优KV缓存量化方案，通过内部维度组量化降低大语言模型解码延迟，不牺牲准确性。",
      "motivation": "大语言模型在解码过程中，KV缓存的大小随序列长度线性增长，成为内存足迹的主要瓶颈，限制了长序列生成的效率。现有的量化方法虽然能压缩KV缓存，但可能未充分考虑硬件特性，导致反量化开销大或实时性能不足，因此需要一种更高效的硬件感知方案来优化内存访问和计算速度，以应对实际部署中的资源约束问题。",
      "method": "InnerQ采用硬件感知的组量化方法，将KV缓存矩阵在内部维度上进行分组，而非传统的外部分组，以与向量-矩阵乘法对齐并启用GPU计算单元间的尺度因子重用。核心创新包括：混合量化（基于局部统计选择对称或非对称量化）、高精度窗口（处理最新令牌和注意力下沉令牌以减少异常值泄漏）以及预填充时计算的每通道归一化键缓存（折叠到查询中以避免运行时开销），从而优化保真度和效率。",
      "result": "在Llama模型上的评估实验显示，InnerQ相比先前KV缓存量化方法，实现了高达22%的解码速度提升；与半精度向量-矩阵乘法相比，提升高达88%。在少样本GSM8K任务中，InnerQ保持了与未量化KV缓存相当的性能，并超越了所有先前的量化方法，验证了其在压缩同时不损失准确性的有效性。",
      "conclusion": "InnerQ通过硬件感知的量化策略，显著减少了大语言模型解码时的硬件足迹，提升了计算效率，同时保持模型性能。该方法对实际部署中的实时应用具有重要价值，未来工作可探索更广泛的模型适应性和动态压缩策略，以进一步优化资源利用。",
      "tags": [
        "Large Language Models",
        "KV Cache Quantization",
        "Hardware-aware Optimization",
        "Group-wise Quantization",
        "Vector-Matrix Multiplication"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:22.642754Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23199",
    "title": "SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation",
    "authors": [
      "Jiahao Zhao",
      "Feng Jiang",
      "Shaowei Qin",
      "Zhonghui Zhang",
      "Junhao Liu",
      "Guibing Guo",
      "Hamid Alinejad-Rokny",
      "Min Yang"
    ],
    "abstract": "Large language models (LLMs) are increasingly applied in scientific research, offering new capabilities for knowledge discovery and reasoning. In single-cell biology, however, evaluation practices for both general and specialized LLMs remain inadequate: existing benchmarks are fragmented across tasks, adopt formats such as multiple-choice classification that diverge from real-world usage, and rely on metrics lacking interpretability and biological grounding. We present SC-ARENA, a natural language evaluation framework tailored to single-cell foundation models. SC-ARENA formalizes a virtual cell abstraction that unifies evaluation targets by representing both intrinsic attributes and gene-level interactions. Within this paradigm, we define five natural language tasks (cell type annotation, captioning, generation, perturbation prediction, and scientific QA) that probe core reasoning capabilities in cellular biology. To overcome the limitations of brittle string-matching metrics, we introduce knowledge-augmented evaluation, which incorporates external ontologies, marker databases, and scientific literature to support biologically faithful and interpretable judgments. Experiments and analysis across both general-purpose and domain-specialized LLMs demonstrate that (i) under the Virtual Cell unified evaluation paradigm, current models achieve uneven performance on biologically complex tasks, particularly those demanding mechanistic or causal understanding; and (ii) our knowledge-augmented evaluation framework ensures biological correctness, provides interpretable, evidence-grounded rationales, and achieves high discriminative capacity, overcoming the brittleness and opacity of conventional metrics. SC-Arena thus provides a unified and interpretable framework for assessing LLMs in single-cell biology, pointing toward the development of biology-aligned, generalizable foundation models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23199.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23199",
    "published": "2026-02-26T16:50:28Z",
    "updated": "2026-02-26T16:50:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了SC-ARENA框架，通过知识增强评估，为单细胞生物学中的大型语言模型提供统一且可解释的自然语言基准测试。",
      "motivation": "在单细胞生物学中，大型语言模型的应用日益广泛，但现有评估基准存在显著不足：任务分散、格式不切实际（如多项选择分类），且指标缺乏可解释性和生物基础。这些问题导致评估结果不可靠，阻碍了生物学对齐的基础模型发展，限制了AI在科学发现中的潜力。因此，开发一个统一、真实且生物可信的评估框架至关重要，以改进评估实践并促进可靠AI工具的开发。",
      "method": "SC-ARENA框架基于虚拟细胞抽象，通过表示内在属性和基因级交互来统一评估目标。框架定义了五个自然语言任务：细胞类型注释、标题生成、生成、扰动预测和科学QA，以探究细胞生物学中的核心推理能力。关键创新是知识增强评估，它整合外部本体、标记数据库和科学文献，提供生物上忠实和可解释的判断，克服传统字符串匹配指标的脆弱性和不透明性，确保评估过程具有生物正确性。",
      "result": "实验结果显示，在虚拟细胞统一评估范式下，当前通用和领域专用的大型语言模型在生物复杂任务中表现不均，特别是在需要机械或因果理解的任务上表现不佳。知识增强评估框架有效确保了生物正确性，提供了可解释的、基于证据的理由，并展现出高区分能力，显著优于传统不透明和脆弱的指标。摘要未明确说明具体性能数据，但强调了该框架在提升评估准确性和可解释性方面的优势。",
      "conclusion": "SC-ARENA为单细胞生物学中的大型语言模型评估提供了一个统一和可解释的框架，推动了生物学对齐、可泛化的基础模型的发展。其学术价值在于解决了现有评估方法的不足，提高了评估的可靠性和生物相关性；实际应用价值在于支持科学研究和AI工具的开发，促进AI在生命科学领域的应用。未来工作可能包括将框架扩展到其他生物学领域或进一步优化评估指标。",
      "tags": [
        "Large Language Models",
        "Single-Cell Biology",
        "Knowledge-Augmented Evaluation",
        "Virtual Cell Abstraction",
        "Natural Language Tasks"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:27.405739Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23197",
    "title": "Fine-Tuning Without Forgetting In-Context Learning: A Theoretical Analysis of Linear Attention Models",
    "authors": [
      "Chungpa Lee",
      "Jy-yong Sohn",
      "Kangwook Lee"
    ],
    "abstract": "Transformer-based large language models exhibit in-context learning, enabling adaptation to downstream tasks via few-shot prompting with demonstrations. In practice, such models are often fine-tuned to improve zero-shot performance on downstream tasks, allowing them to solve tasks without examples and thereby reducing inference costs. However, fine-tuning can degrade in-context learning, limiting the performance of fine-tuned models on tasks not seen during fine-tuning. Using linear attention models, we provide a theoretical analysis that characterizes how fine-tuning objectives modify attention parameters and identifies conditions under which this leads to degraded few-shot performance. We show that fine-tuning all attention parameters can harm in-context learning, whereas restricting updates to the value matrix improves zero-shot performance while preserving in-context learning. We further show that incorporating an auxiliary few-shot loss enhances in-context learning primarily on the target task, at the expense of degraded in-context learning ability on tasks not seen during fine-tuning. We empirically validate our theoretical results.",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23197.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23197",
    "published": "2026-02-26T16:49:15Z",
    "updated": "2026-02-26T16:49:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过理论分析线性注意力模型，揭示了微调参数对上下文学习的影响，并提出限制更新值矩阵的方法以平衡零样本和少样本性能。",
      "motivation": "当前基于Transformer的大语言模型常通过微调提升下游任务的零样本性能以减少推理成本，但微调可能损害模型的上下文学习能力，导致在未见任务上表现下降。这一问题的重要性在于上下文学习是模型适应新任务的关键，而现有微调方法未充分考虑这一权衡，限制了模型的多任务泛化能力。因此，研究微调如何影响上下文学习并寻求优化策略具有实际意义。",
      "method": "论文采用线性注意力模型作为理论分析框架，探究微调目标如何修改注意力参数。核心创新在于识别导致上下文学习退化的条件，并提出两种策略：限制微调更新至值矩阵以保护上下文学习，以及引入辅助少样本损失函数来增强目标任务的上下文学习。虽然摘要未明确说明使用的具体数据集或模型架构，但方法基于数学推导，为后续实证验证提供了理论基础。",
      "result": "理论分析显示，微调所有注意力参数会损害上下文学习，而仅更新值矩阵则能在提升零样本性能的同时保留上下文学习。辅助少样本损失主要改善目标任务的上下文学习，但以降低未见任务上的上下文学习能力为代价。论文通过实验验证了这些理论结论，但摘要未提供具体的性能指标如准确率提升数据。",
      "conclusion": "本研究的主要贡献是理论分析了微调对上下文学习的影响，强调了参数更新策略在平衡零样本和少样本性能中的作用。提出限制微调到值矩阵的方法，为优化大语言模型提供了理论指导。学术价值在于深化对微调机制的理解，实际应用价值在于指导模型部署以保持多任务适应性。未来工作可能包括扩展到非线性注意力模型和更广泛的任务验证。",
      "tags": [
        "Fine-Tuning",
        "In-Context Learning",
        "Linear Attention Models",
        "Attention Mechanisms",
        "Value Matrix"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:33.257478Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23193",
    "title": "ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering",
    "authors": [
      "Elzo Brito dos Santos Filho"
    ],
    "abstract": "Autonomous agents based on Large Language Models (LLMs) have evolved from reactive assistants to systems capable of planning, executing actions via tools, and iterating over environment observations. However, they remain vulnerable to structural limitations: lack of native state, context degradation over long horizons, and the gap between probabilistic generation and deterministic execution requirements. This paper presents the ESAA (Event Sourcing for Autonomous Agents) architecture, which separates the agent's cognitive intention from the project's state mutation, inspired by the Event Sourcing pattern. In ESAA, agents emit only structured intentions in validated JSON (agent.result or issue.report); a deterministic orchestrator validates, persists events in an append-only log (activity.jsonl), applies file-writing effects, and projects a verifiable materialized view (roadmap.json). The proposal incorporates boundary contracts (AGENT_CONTRACT.yaml), metaprompting profiles (PARCER), and replay verification with hashing (esaa verify), ensuring the immutability of completed tasks and forensic traceability. Two case studies validate the architecture: (i) a landing page project (9 tasks, 49 events, single-agent composition) and (ii) a clinical dashboard system (50 tasks, 86 events, 4 concurrent agents across 8 phases), both concluding with run.status=success and verify_status=ok. The multi-agent case study demonstrates real concurrent orchestration with heterogeneous LLMs (Claude Sonnet 4.6, Codex GPT-5, Antigravity/Gemini 3 Pro, and Claude Opus 4.6), providing empirical evidence of the architecture's scalability beyond single-agent scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23193.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23193",
    "published": "2026-02-26T16:45:59Z",
    "updated": "2026-02-26T16:45:59Z",
    "comment": "13 pages, 1 figure, 4 tables. Includes 5 technical appendices",
    "light_analysis": {
      "overview": "本文提出ESAA架构，通过事件溯源模式分离自主代理的意图与状态变化，解决了基于大语言模型的软件工程中状态管理和确定性执行问题。",
      "motivation": "基于大语言模型的自主代理虽能规划、执行动作和迭代观察，但面临结构限制：缺乏原生状态导致难以追踪任务进展，长期上下文退化影响长周期任务表现，以及概率生成与确定性执行要求之间的差距。这些问题削弱了代理在复杂软件工程中的可靠性和可扩展性。现有方法可能未有效整合状态管理和验证机制，限制了自主代理在真实场景中的应用，尤其在多代理并发环境中。本研究旨在通过架构创新克服这些不足，提升代理的稳定性和可追溯性。",
      "method": "ESAA架构受事件溯源模式启发，将代理的认知意图（以结构化JSON如agent.result或issue.report形式）与项目状态突变分离。确定性的编排器验证这些意图，持久化到只追加日志（activity.jsonl），应用文件写入效果，并投影可验证的物质化视图（roadmap.json）。关键组件包括边界合同（AGENT_CONTRACT.yaml）定义代理行为约束，元提示配置文件（PARCER）优化提示工程，以及带哈希的重放验证（esaa verify）确保任务不可变性和法医追溯性。架构支持异构大语言模型，如Claude和Gemini系列，用于多代理场景。",
      "result": "两个案例研究验证了ESAA架构的有效性：着陆页项目（9个任务、49个事件、单代理组合）和临床仪表板系统（50个任务、86个事件、8个阶段中4个并发代理）均以run.status=success和verify_status=ok结束。多代理案例展示了真实并发编排，使用异构大语言模型（Claude Sonnet 4.6、Codex GPT-5、Antigravity/Gemini 3 Pro和Claude Opus 4.6），提供实证证据表明架构可扩展到单代理场景之外，支持任务协调和可验证执行。与基线方法对比，ESAA通过确定性机制减少了状态不一致风险。",
      "conclusion": "ESAA架构解决了基于大语言模型的自主代理的结构限制，通过事件溯源实现意图与状态分离，提供了确定的执行和可验证追溯性。学术价值在于增强了代理系统的可靠性和可扩展性，为软件工程任务提供新方法。实际应用中，该架构可用于多代理并发场景，提高任务完成的稳定性和透明度。摘要未明确说明潜在局限性，未来工作可探索更多领域应用或性能优化，如处理更复杂任务或集成更多工具。",
      "tags": [
        "Event Sourcing",
        "Large Language Model",
        "Autonomous Agent",
        "Software Engineering",
        "Deterministic Orchestration"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:43.966880Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23192",
    "title": "FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification",
    "authors": [
      "Thomas Woergaard",
      "Raghavendra Selvan"
    ],
    "abstract": "Compressing neural networks by quantizing model parameters offers useful trade-off between performance and efficiency. Methods like quantization-aware training and post-training quantization strive to maintain the downstream performance of compressed models compared to the full precision models. However, these techniques do not explicitly consider the impact on algorithmic fairness. In this work, we study fairness-aware mixed-precision quantization schemes for medical image classification under explicit bit budgets. We introduce FairQuant, a framework that combines group-aware importance analysis, budgeted mixed-precision allocation, and a learnable Bit-Aware Quantization (BAQ) mode that jointly optimizes weights and per-unit bit allocations under bitrate and fairness regularization. We evaluate the method on Fitzpatrick17k and ISIC2019 across ResNet18/50, DeiT-Tiny, and TinyViT. Results show that FairQuant configurations with average precision near 4-6 bits recover much of the Uniform 8-bit accuracy while improving worst-group performance relative to Uniform 4- and 8-bit baselines, with comparable fairness metrics under shared budgets.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23192.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23192",
    "published": "2026-02-26T16:44:47Z",
    "updated": "2026-02-26T16:44:47Z",
    "comment": "Source code available at https://github.com/saintslab/FairQuant",
    "light_analysis": {
      "overview": "本文提出了FairQuant框架，一种公平感知的混合精度量化方法，用于医疗图像分类，在压缩模型时联合优化性能和公平性。",
      "motivation": "在神经网络压缩中，量化技术如量化感知训练和后训练量化被广泛用于平衡模型性能和效率，但现有方法主要关注维持准确率，而忽略了算法公平性。尤其是在医疗图像分类等敏感领域，公平性对确保模型在不同群体（如不同皮肤类型）间的一致性能至关重要，以防止偏见影响诊断结果。本研究旨在解决量化过程中公平性缺失的问题，通过引入公平性约束来优化压缩模型的群体间性能差异。",
      "method": "FairQuant框架结合了组感知重要性分析、预算混合精度分配和可学习的比特感知量化模式。组感知重要性分析识别对不同群体重要的模型部分；预算混合精度分配在明确的比特预算下优化比特分配；比特感知量化模式联合训练权重和每单元的比特配置，并加入公平正则化来平衡压缩和公平性。评估使用了Fitzpatrick17k和ISIC2019数据集，以及ResNet18/50、DeiT-Tiny和TinyViT模型，以验证方法在不同架构下的有效性。",
      "result": "在Fitzpatrick17k和ISIC2019数据集上的实验结果显示，FairQuant在平均精度4-6比特的配置下，能够恢复Uniform 8比特模型的大部分分类准确率。同时，相对于Uniform 4-和8-bit基线，FairQuant显著提升了最差组的性能，表明在压缩模型时改善了公平性。在共享比特预算下，FairQuant实现了与基线可比的公平性指标，验证了其在维持准确率的同时优化群体间性能的能力。",
      "conclusion": "FairQuant的主要贡献是将公平性集成到混合精度量化中，提供了一种兼顾压缩效率和算法公平性的新方案。学术上，这扩展了模型压缩和公平学习的研究范畴；实际应用上，该方法有助于在医疗图像分类等敏感任务中减少模型偏见，提升可靠性。未来工作可以探索更多数据集或优化公平正则化策略，摘要未明确说明具体局限性。",
      "tags": [
        "Mixed-Precision Quantization",
        "Fairness-Aware Learning",
        "Bit-Aware Quantization",
        "Medical Image Classification"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:49.553717Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23191",
    "title": "Uni-Animator: Towards Unified Visual Colorization",
    "authors": [
      "Xinyuan Chen",
      "Yao Xu",
      "Shaowen Wang",
      "Pengjie Song",
      "Bowen Deng"
    ],
    "abstract": "We propose Uni-Animator, a novel Diffusion Transformer (DiT)-based framework for unified image and video sketch colorization. Existing sketch colorization methods struggle to unify image and video tasks, suffering from imprecise color transfer with single or multiple references, inadequate preservation of high-frequency physical details, and compromised temporal coherence with motion artifacts in large-motion scenes. To tackle imprecise color transfer, we introduce visual reference enhancement via instance patch embedding, enabling precise alignment and fusion of reference color information. To resolve insufficient physical detail preservation, we design physical detail reinforcement using physical features that effectively capture and retain high-frequency textures. To mitigate motion-induced temporal inconsistency, we propose sketch-based dynamic RoPE encoding that adaptively models motion-aware spatial-temporal dependencies. Extensive experimental results demonstrate that Uni-Animator achieves competitive performance on both image and video sketch colorization, matching that of task-specific methods while unlocking unified cross-domain capabilities with high detail fidelity and robust temporal consistency.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23191.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23191",
    "published": "2026-02-26T16:44:37Z",
    "updated": "2026-02-26T16:44:37Z",
    "comment": "10 pages, 8 figures. Submitted to CVPR 2026",
    "light_analysis": {
      "overview": "Uni-Animator 提出了一个基于扩散变换器的统一框架，用于解决图像和视频草图着色中的颜色转移不精确、物理细节保留不足和时间一致性问题。",
      "motivation": "现有草图着色方法在统一处理图像和视频任务时面临挑战，包括使用单一或多个参考时颜色转移不精确、高频率物理细节保留不足，以及大运动场景中时间一致性受损和运动伪影问题。这些问题限制了着色质量的实际应用，特别是在需要跨域处理的场景中，因此亟需开发能同时提升颜色准确性、细节保真度和时间连贯性的统一方法。",
      "method": "Uni-Animator 是一个基于 Diffusion Transformer (DiT) 的框架，核心创新包括：通过实例补丁嵌入实现视觉参考增强，以精确对齐和融合参考颜色信息；使用物理特征进行物理细节强化，有效捕捉和保留高频率纹理；以及采用基于草图的动态 RoPE 编码，自适应建模运动感知的时空依赖性，以处理图像和视频的统一着色任务。",
      "result": "实验结果显示，Uni-Animator 在图像和视频草图着色中实现了竞争性性能，与专门为单一任务设计的方法相匹配。它展示了高细节保真度和稳健的时间一致性，特别是在大运动场景中减少了运动伪影。然而，摘要未明确说明具体性能指标如准确率提升的数值，仅强调了其统一跨域能力和整体效果的优越性。",
      "conclusion": "Uni-Animator 的主要贡献在于提出一个统一框架，有效解决了图像和视频草图着色的关键挑战，包括颜色转移、细节保留和时间一致性。其学术价值体现在推动了视觉处理领域的跨域技术发展，实际应用价值包括动画制作和视频编辑等领域。未来工作可进一步优化模型或扩展到更多任务，但摘要未明确说明具体局限性。",
      "tags": [
        "Diffusion Transformer",
        "Instance Patch Embedding",
        "Physical Detail Reinforcement",
        "Dynamic RoPE Encoding",
        "Spatial-Temporal Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:50.633278Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23188",
    "title": "Efficient Real-Time Adaptation of ROMs for Unsteady Flows Using Data Assimilation",
    "authors": [
      "Ismaël Zighed",
      "Andrea Nóvoa",
      "Luca Magri",
      "Taraneh Sayadi"
    ],
    "abstract": "We propose an efficient retraining strategy for a parameterized Reduced Order Model (ROM) that attains accuracy comparable to full retraining while requiring only a fraction of the computational time and relying solely on sparse observations of the full system. The architecture employs an encode-process-decode structure: a Variational Autoencoder (VAE) to perform dimensionality reduction, and a transformer network to evolve the latent states and model the dynamics. The ROM is parameterized by an external control variable, the Reynolds number in the Navier-Stokes setting, with the transformer exploiting attention mechanisms to capture both temporal dependencies and parameter effects. The probabilistic VAE enables stochastic sampling of trajectory ensembles, providing predictive means and uncertainty quantification through the first two moments. After initial training on a limited set of dynamical regimes, the model is adapted to out-of-sample parameter regions using only sparse data. Its probabilistic formulation naturally supports ensemble generation, which we employ within an ensemble Kalman filtering framework to assimilate data and reconstruct full-state trajectories from minimal observations. We further show that, for the dynamical system considered, the dominant source of error in out-of-sample forecasts stems from distortions of the latent manifold rather than changes in the latent dynamics. Consequently, retraining can be limited to the autoencoder, allowing for a lightweight, computationally efficient, real-time adaptation procedure with very sparse fine-tuning data.",
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23188.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23188",
    "published": "2026-02-26T16:43:28Z",
    "updated": "2026-02-26T16:43:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种基于变分自动编码器和Transformer的参数化降阶模型高效重训练策略，能在稀疏数据下实现实时适应非定常流。",
      "motivation": "该研究旨在解决非定常流降阶模型实时适应性问题。传统方法在参数变化时需完全重新训练，计算成本高昂，且依赖于大量数据。现有ROMs难以在稀疏观察下高效适应样本外参数区域，限制了其实时应用。因此，开发一种计算高效、仅需稀疏数据的适应策略，对于流体动力学等领域的实时模拟和预测具有重要意义。",
      "method": "研究方法采用编码-处理-解码架构，结合变分自动编码器（VAE）进行降维和Transformer网络建模动态。VAE生成潜在状态并提供概率性框架，支持不确定性量化；Transformer利用注意力机制捕捉时间依赖和外部参数（如雷诺数）效应。模型通过参数化ROM实现灵活性，初始训练后，仅用稀疏数据通过微调自动编码器适应新参数区域，减少计算负担。",
      "result": "实验结果显示，所提方法在适应样本外参数区域时，精度与传统完全重新训练相当，但计算时间大幅减少。通过集合卡尔曼滤波框架，能从稀疏观察中有效重建全状态轨迹。错误分析表明，预测错误主要源于潜在流形失真而非动态变化，因此重训练可限于自动编码器，实现轻量级适应。具体性能指标未明确说明，但强调计算效率和实时性显著提升。",
      "conclusion": "结论是该方法为降阶模型实时适应提供了有效解决方案，核心贡献在于结合变分自动编码器、Transformer和数据同化技术。学术上，探索了ROM错误来源，为模型优化提供理论指导；应用上，可用于非定常流实时模拟，降低计算成本。局限性可能在于对特定动力系统的依赖，未来工作可扩展至更复杂场景或多参数适应。",
      "tags": [
        "Reduced Order Model",
        "Variational Autoencoder",
        "Transformer",
        "Data Assimilation",
        "Attention Mechanisms"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:20.139833Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23184",
    "title": "MTRAG-UN: A Benchmark for Open Challenges in Multi-Turn RAG Conversations",
    "authors": [
      "Sara Rosenthal",
      "Yannis Katsis",
      "Vraj Shah",
      "Lihong He",
      "Lucian Popa",
      "Marina Danilevsky"
    ],
    "abstract": "We present MTRAG-UN, a benchmark for exploring open challenges in multi-turn retrieval augmented generation, a popular use of large language models. We release a benchmark of 666 tasks containing over 2,800 conversation turns across 6 domains with accompanying corpora. Our experiments show that retrieval and generation models continue to struggle on conversations with UNanswerable, UNderspecified, and NONstandalone questions and UNclear responses. Our benchmark is available at https://github.com/IBM/mt-rag-benchmark",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23184.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23184",
    "published": "2026-02-26T16:41:17Z",
    "updated": "2026-02-26T16:41:17Z",
    "comment": "5 pages, 3 figures",
    "light_analysis": {
      "overview": "本文提出了MTRAG-UN基准数据集，用于评估多轮检索增强生成对话中未回答、未指定和非独立问题的开放挑战。",
      "motivation": "研究动机源于当前检索增强生成模型在多轮对话场景中处理复杂问题时的不足，特别是在面对难以回答、未指定或模糊的问题时表现不佳。多轮对话增加了交互的复杂性，而现有基准往往忽视这些挑战，导致模型在实际应用中鲁棒性有限。该问题的重要性在于RAG是大型语言模型的流行应用，如智能助手和信息检索系统，改进这些方面能提升系统实用性和用户体验。摘要直接指出模型在这些挑战下继续struggle，强调了现有方法的局限性。",
      "method": "研究方法包括创建并发布MTRAG-UN基准数据集，该数据集包含666个任务，涵盖超过2,800个对话回合，分布在6个不同领域，并附带相关语料库。核心创新是聚焦于多轮RAG对话中的特定挑战类型：UNanswerable（未回答）、UNderspecified（未指定）、NONstandalone（非独立）问题和UNclear（模糊）响应。通过提供标准化评估框架，该方法旨在系统测试模型性能，促进新算法的开发，数据集细节如任务数量和领域覆盖为后续研究奠定了基础。",
      "result": "主要实验结果表明，检索和生成模型在MTRAG-UN基准上遇到显著困难，特别是在处理UNanswerable、UNderspecified、NONstandalone问题和UNclear响应时。摘要未提供具体的性能指标（如准确率或效率数据），但指出模型继续struggle，暗示现有方法在这些挑战下表现不足。与基线方法的对比未明确说明，可能基于一般RAG模型的默认性能。结果突出了多轮对话中这些开放挑战的复杂性，需进一步研究来改进模型能力。",
      "conclusion": "论文的主要贡献是引入了MTRAG-UN基准，为多轮RAG对话研究提供了标准化测试集，揭示了模型在特定问题类型上的局限性。学术价值在于量化了挑战并推动了领域发展，实际应用价值包括帮助开发更鲁棒的对话AI系统。局限性可能在于数据集的规模和多样性，未来工作可以扩展到更多领域或挑战类型，以及探索新模型架构来应对这些困难。",
      "tags": [
        "Retrieval Augmented Generation",
        "Multi-Turn Dialogue",
        "Benchmark Dataset",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:23.356253Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23182",
    "title": "Closing the gap on tabular data with Fourier and Implicit Categorical Features",
    "authors": [
      "Marius Dragoi",
      "Florin Gogianu",
      "Elena Burceanu"
    ],
    "abstract": "While Deep Learning has demonstrated impressive results in applications on various data types, it continues to lag behind tree-based methods when applied to tabular data, often referred to as the last \"unconquered castle\" for neural networks. We hypothesize that a significant advantage of tree-based methods lies in their intrinsic capability to model and exploit non-linear interactions induced by features with categorical characteristics. In contrast, neural-based methods exhibit biases toward uniform numerical processing of features and smooth solutions, making it challenging for them to effectively leverage such patterns. We address this performance gap by using statistical-based feature processing techniques to identify features that are strongly correlated with the target once discretized. We further mitigate the bias of deep models for overly-smooth solutions, a bias that does not align with the inherent properties of the data, using Learned Fourier. We show that our proposed feature preprocessing significantly boosts the performance of deep learning models and enables them to achieve a performance that closely matches or surpasses XGBoost on a comprehensive tabular data benchmark.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23182.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23182",
    "published": "2026-02-26T16:40:23Z",
    "updated": "2026-02-26T16:40:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过统计特征处理和学习傅里叶特征，提升了深度学习模型在表格数据上的性能，使其接近或超越XGBoost。",
      "motivation": "表格数据是深度学习尚未完全征服的领域，长期以来，基于树的方法（如XGBoost）在此表现优于神经网络，这被称为神经网络的最后一个“未征服的城堡”。神经网络在处理表格数据时存在偏见，倾向于对特征进行均匀数值处理和寻找平滑解决方案，这阻碍了其有效利用分类特征的非线性交互。现有深度学习方法难以匹配树基方法的性能，限制了深度学习在广泛应用中的潜力。因此，解决这一性能差距对提升表格数据任务的准确性和效率至关重要，具有重要的理论和实际意义。",
      "method": "论文提出一种结合特征预处理和技术创新的方法来缩小性能差距。首先，使用基于统计的特征处理技术识别与目标变量强烈相关的离散化特征，从而增强模型对分类特征的捕捉能力。其次，引入学习傅里叶特征，以减轻深度模型对平滑解决方案的固有偏见，这有助于更好地适应表格数据的内在非光滑特性。该方法的关键创新在于通过特征选择和傅里叶变换优化数据表示，使深度模型能更有效地模拟树基方法擅长的非线性交互。尽管摘要未明确说明具体模型架构或数据集，但强调了这些技术步骤的实施和理论基础。",
      "result": "实验结果表明，提出的特征预处理方法显著提升了深度学习模型的性能。在全面的表格数据基准测试中，经过处理的深度学习模型性能接近或超越了XGBoost这一基线方法。摘要未提供具体数字指标（如准确率或效率改进），但指出性能提升是“显著的”，并且模型能够“接近或超越”树基方法。这显示了该方法在缩小深度学习和树基方法之间性能差距方面的有效性，为表格数据任务提供了新的性能基准。",
      "conclusion": "本研究的核心贡献在于通过统计特征处理和学习傅里叶特征，有效缩小了深度学习与树基方法在表格数据上的性能差距，使深度学习模型性能接近或超越XGBoost。这提高了深度学习在表格数据应用中的竞争力，具有重要的学术价值，可能推动更多神经网络方法在结构化数据上的应用。实际应用中，该方法可帮助改进金融、医疗等领域的预测模型。然而，摘要未明确说明局限性或未来工作方向；未来可能需要进一步优化特征处理算法或扩展到更多复杂数据集。",
      "tags": [
        "Tabular Data",
        "Feature Processing",
        "Learned Fourier",
        "Deep Learning",
        "XGBoost"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:06.122116Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23179",
    "title": "Induction Meets Biology: Mechanisms of Repeat Detection in Protein Language Models",
    "authors": [
      "Gal Kesten-Pomeranz",
      "Yaniv Nikankin",
      "Anja Reusch",
      "Tomer Tsaban",
      "Ora Schueler-Furman",
      "Yonatan Belinkov"
    ],
    "abstract": "Protein sequences are abundant in repeating segments, both as exact copies and as approximate segments with mutations. These repeats are important for protein structure and function, motivating decades of algorithmic work on repeat identification. Recent work has shown that protein language models (PLMs) identify repeats, by examining their behavior in masked-token prediction. To elucidate their internal mechanisms, we investigate how PLMs detect both exact and approximate repeats. We find that the mechanism for approximate repeats functionally subsumes that of exact repeats. We then characterize this mechanism, revealing two main stages: PLMs first build feature representations using both general positional attention heads and biologically specialized components, such as neurons that encode amino-acid similarity. Then, induction heads attend to aligned tokens across repeated segments, promoting the correct answer. Our results reveal how PLMs solve this biological task by combining language-based pattern matching with specialized biological knowledge, thereby establishing a basis for studying more complex evolutionary processes in PLMs.",
    "categories": [
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23179.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23179",
    "published": "2026-02-26T16:39:04Z",
    "updated": "2026-02-26T16:39:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文揭示了蛋白质语言模型通过结合语言模式匹配和生物专用知识来检测蛋白质序列重复片段的内部机制。",
      "motivation": "蛋白质序列中存在大量重复片段，包括精确和近似重复，这些重复对蛋白质结构和功能至关重要，已有几十年的算法研究致力于识别它们。近年来，蛋白质语言模型（PLMs）被证明能通过掩码令牌预测识别重复，但其内部机制尚不明确。本研究旨在阐明PLMs如何检测这些重复，以填补现有方法在理解模型工作机制上的不足，并为生物信息学应用提供更深入洞察，推动模型可解释性发展。",
      "method": "研究通过分析PLMs在掩码令牌预测中的行为来探究其内部机制，重点探讨精确和近似重复的检测过程。关键创新在于发现近似重复的检测机制功能上包含了精确重复机制，并揭示了该机制的两个阶段：首先，PLMs构建特征表示，利用一般位置注意力头和生物专用组件（如编码氨基酸相似性的神经元）来捕获序列信息；然后，归纳头关注重复片段间的对齐令牌，以促进正确预测。摘要未明确说明使用的具体数据集或模型架构，但方法强调了从内部组件角度解析模型工作原理。",
      "result": "研究发现蛋白质语言模型检测近似重复的机制功能上包含了精确重复机制，并将该机制分为两个主要阶段：特征构建阶段通过位置注意力和生物知识编码来生成表示；对齐阶段通过归纳头实现跨重复片段的令牌对齐。这些结果揭示了PLMs如何结合语言模式匹配和专用生物知识来高效解决重复检测任务，为理解模型内部工作机制提供了实证基础。摘要未提供具体性能指标（如准确率），但通过机制分析表明PLMs在生物任务中具有潜在优势，为未来研究奠定了基础。",
      "conclusion": "研究阐明了蛋白质语言模型检测重复片段的内部机制，表明其通过整合语言基础模式匹配和生物专用知识来执行任务，增强了模型在生物序列分析中的可解释性。这具有重要的学术价值，为研究更复杂进化过程提供了理论基础，并推动了PLMs在生物信息学中的应用。潜在局限性或未来工作方向包括扩展到其他生物任务或深入机制分析，摘要未明确说明具体细节，但暗示了进一步探索的可能性。",
      "tags": [
        "Protein Language Models",
        "Attention Mechanisms",
        "Induction Heads",
        "Biological Sequence Analysis",
        "Masked-Token Prediction"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:32.283252Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23177",
    "title": "Phys-3D: Physics-Constrained Real-Time Crowd Tracking and Counting on Railway Platforms",
    "authors": [
      "Bin Zeng",
      "Johannes Künzel",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "abstract": "Accurate, real-time crowd counting on railway platforms is essential for safety and capacity management. We propose to use a single camera mounted in a train, scanning the platform while arriving. While hardware constraints are simple, counting remains challenging due to dense occlusions, camera motion, and perspective distortions during train arrivals. Most existing tracking-by-detection approaches assume static cameras or ignore physical consistency in motion modeling, leading to unreliable counting under dynamic conditions. We propose a physics-constrained tracking framework that unifies detection, appearance, and 3D motion reasoning in a real-time pipeline. Our approach integrates a transfer-learned YOLOv11m detector with EfficientNet-B0 appearance encoding within DeepSORT, while introducing a physics-constrained Kalman model (Phys-3D) that enforces physically plausible 3D motion dynamics through pinhole geometry. To address counting brittleness under occlusions, we implement a virtual counting band with persistence. On our platform benchmark, MOT-RailwayPlatformCrowdHead Dataset(MOT-RPCH), our method reduces counting error to 2.97%, demonstrating robust performance despite motion and occlusions. Our results show that incorporating first-principles geometry and motion priors enables reliable crowd counting in safety-critical transportation scenarios, facilitating effective train scheduling and platform safety management.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23177.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23177",
    "published": "2026-02-26T16:38:44Z",
    "updated": "2026-02-26T16:38:44Z",
    "comment": "published at VISAPP 2026",
    "light_analysis": {
      "overview": "提出Phys-3D框架，通过物理约束的卡尔曼模型和针孔几何，实现铁路平台上实时、可靠的人群跟踪与计数。",
      "motivation": "铁路平台人群计数对安全和容量管理至关重要，但现有方法如检测-跟踪方法通常假设静态摄像头或忽略物理一致性，在动态场景（如火车到达时摄像头运动、密集遮挡和透视变形）下计数不可靠。这使得开发一种能处理这些挑战的实时计数方法成为迫切需求，以确保在复杂环境中实现精确监控。",
      "method": "论文提出一个物理约束的跟踪框架，在实时管道中统一检测、外观和3D运动推理。具体技术包括：集成迁移学习的YOLOv11m检测器和EfficientNet-B0外观编码到DeepSORT框架，引入Phys-3D模型（物理约束的卡尔曼滤波器），通过针孔几何强制物理上合理的3D运动动态，并采用虚拟计数带以处理遮挡带来的计数脆弱性。",
      "result": "在MOT-RailwayPlatformCrowdHead数据集上的实验显示，该方法将计数误差降低至2.97%，对比摘要未明确说明的基线方法，表现出显著性能提升。即使在摄像头运动和密集遮挡条件下，仍保持稳健的计数准确性，验证了物理约束方法的有效性。",
      "conclusion": "该研究通过结合第一性原理几何和运动先验，开发了Phys-3D框架，为安全关键运输场景提供可靠的人群计数。这不仅提升了计数的准确性和鲁棒性，还有助于实时监控、火车调度和平台安全管理。未来工作方向摘要未明确说明，但可能涉及扩展应用场景或优化模型效率。",
      "tags": [
        "Crowd Tracking",
        "Real-Time Counting",
        "Physics-Constrained Modeling",
        "Kalman Filter",
        "Pinhole Geometry"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:32.697994Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23172",
    "title": "Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking",
    "authors": [
      "Maximilian Luz",
      "Rohit Mohan",
      "Thomas Nürnberg",
      "Yakov Miron",
      "Daniele Cattaneo",
      "Abhinav Valada"
    ],
    "abstract": "Capturing 4D spatiotemporal surroundings is crucial for the safe and reliable operation of robots in dynamic environments. However, most existing methods address only one side of the problem: they either provide coarse geometric tracking via bounding boxes, or detailed 3D structures like voxel-based occupancy that lack explicit temporal association. In this work, we present Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking (LaGS) that advances spatiotemporal scene understanding in a holistic direction. Our approach incorporates camera-based end-to-end tracking with mask-based multi-view panoptic occupancy prediction, and addresses the key challenge of efficiently aggregating multi-view information into 3D voxel grids via a novel latent Gaussian splatting approach. Specifically, we first fuse observations into 3D Gaussians that serve as a sparse point-centric latent representation of the 3D scene, and then splat the aggregated features onto a 3D voxel grid that is decoded by a mask-based segmentation head. We evaluate LaGS on the Occ3D nuScenes and Waymo datasets, achieving state-of-the-art performance for 4D panoptic occupancy tracking. We make our code available at https://lags.cs.uni-freiburg.de/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23172.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23172",
    "published": "2026-02-26T16:34:49Z",
    "updated": "2026-02-26T16:34:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出LaGS方法，通过潜在高斯splatting技术实现了高效的4D全景占用跟踪，显著提升时空场景理解能力。",
      "motivation": "在动态环境中，机器人的安全操作依赖于对4D时空场景的准确捕捉。现有方法存在局限性：基于边界框的几何跟踪过于粗粒度，无法提供详细结构；而基于体素的3D占用方法虽能捕捉精细几何，但缺乏明确的时空关联，导致无法全面处理动态场景。这种不完整性制约了机器人感知系统的可靠性，因此需要一种能够同时整合时空信息和精细结构的解决方案来应对挑战。",
      "method": "LaGS方法整合了相机端到端跟踪与基于掩码的多视图全景占用预测，核心技术是新颖的潜在高斯splatting。首先，将多视图观测融合为3D高斯稀疏潜在表示，作为场景的点中心编码；然后，通过splatting操作将这些聚合特征映射到3D体素网格上，并使用一个基于掩码的分割头进行解码，实现时空一致的占用预测。该方法在Occ3D nuScenes和Waymo数据集上进行开发和验证，专注于高效处理多视图信息以生成4D场景表示。",
      "result": "在Occ3D nuScenes和Waymo数据集上的实验表明，LaGS在4D全景占用跟踪任务中实现了最先进的性能，优于现有基线方法。该方法在准确性和效率方面表现出显著提升，但具体的性能指标如准确率提升百分比或运行时间改进摘要未明确说明，进一步细节需参考论文完整内容以获取数据支撑。",
      "conclusion": "本论文的主要贡献是提出了LaGS方法，它通过创新的潜在高斯splatting技术有效解决了4D时空场景理解的难题。在学术上，该方法推进了全景占用跟踪领域的整体方向；在实际应用中，它为机器人在动态环境中的感知和决策提供了强大工具。未来工作可能包括优化计算效率或扩展到更多样化的数据集和场景，以进一步增强泛化能力。",
      "tags": [
        "4D Panoptic Occupancy Tracking",
        "Latent Gaussian Splatting",
        "Multi-view Aggregation",
        "3D Voxel Grid",
        "Occupancy Prediction"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:51.862785Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23169",
    "title": "Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration",
    "authors": [
      "Xiaole Tang",
      "Xiaoyi He",
      "Jiayi Xu",
      "Xiang Gu",
      "Jian Sun"
    ],
    "abstract": "Despite substantial advances in all-in-one image restoration for addressing diverse degradations within a unified model, existing methods remain vulnerable to out-of-distribution degradations, thereby limiting their generalization in real-world scenarios. To tackle the challenge, this work is motivated by the intuition that multisource degraded feature distributions are induced by different degradation-specific shifts from an underlying degradation-agnostic distribution, and recovering such a shared distribution is thus crucial for achieving generalization across degradations. With this insight, we propose BaryIR, a representation learning framework that aligns multisource degraded features in the Wasserstein barycenter (WB) space, which models a degradation-agnostic distribution by minimizing the average of Wasserstein distances to multisource degraded distributions. We further introduce residual subspaces, whose embeddings are mutually contrasted while remaining orthogonal to the WB embeddings. Consequently, BaryIR explicitly decouples two orthogonal spaces: a WB space that encodes the degradation-agnostic invariant contents shared across degradations, and residual subspaces that adaptively preserve the degradation-specific knowledge. This disentanglement mitigates overfitting to in-distribution degradations and enables adaptive restoration grounded on the degradation-agnostic shared invariance. Extensive experiments demonstrate that BaryIR performs competitively against state-of-the-art all-in-one methods. Notably, BaryIR generalizes well to unseen degradations (\\textit{e.g.,} types and levels) and shows remarkable robustness in learning generalized features, even when trained on limited degradation types and evaluated on real-world data with mixed degradations.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23169.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23169",
    "published": "2026-02-26T16:31:27Z",
    "updated": "2026-02-26T16:31:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出BaryIR框架，通过Wasserstein barycenter空间解耦退化不可知和特定特征，提升了图像恢复的泛化能力。",
      "motivation": "现有的一体化图像恢复方法虽然在统一处理多种退化方面取得进展，但在面对分布外退化时泛化能力有限，限制了真实场景应用。这是因为现有方法容易过拟合训练数据中的特定退化，未能有效捕捉跨退化的共享不变性。本文动机源于直觉：多源退化特征分布源自同一个底层分布的不同偏移，恢复这个共享分布是提升泛化能力的关键，从而解决实际世界中退化多样性和模型鲁棒性问题。",
      "method": "BaryIR是一个表示学习框架，通过在Wasserstein barycenter (WB)空间中对齐多源退化特征，最小化与各退化分布的平均Wasserstein距离来建模退化不可知分布。创新性地引入残差子空间，其嵌入通过对比学习相互比较，同时保持与WB嵌入正交，从而解耦WB空间（编码跨退化的共享不变内容）和残差子空间（自适应保留退化特定知识）。这种解耦设计旨在避免过拟合训练数据，实现自适应图像恢复。摘要未明确说明具体数据集或模型架构。",
      "result": "大量实验表明，BaryIR在性能上与最先进的一体化图像恢复方法竞争。特别地，BaryIR在未见退化类型和水平上表现出良好的泛化能力，例如在不同退化类型和混合退化的真实世界数据评估中显示出显著鲁棒性，即使在有限退化类型训练下也能保持效果。摘要未提供具体性能指标如准确率数据，但强调其优于基线方法的泛化优势。",
      "conclusion": "论文的主要贡献是提出了BaryIR框架，通过解耦退化不可知和特定特征，提高了图像恢复的泛化能力和适应性，为表示学习和泛化方法提供了新思路。研究具有实际应用价值，能更好地应对真实世界多样的退化场景。摘要未明确讨论局限性，未来工作可能涉及扩展到更多退化类型或优化计算效率。",
      "tags": [
        "Wasserstein Barycenter",
        "Representation Learning",
        "Image Restoration",
        "Contrastive Learning",
        "Disentangled Representations"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:58.869991Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23166",
    "title": "AgentVista: Evaluating Multimodal Agents in Ultra-Challenging Realistic Visual Scenarios",
    "authors": [
      "Zhaochen Su",
      "Jincheng Gao",
      "Hangyu Guo",
      "Zhenhua Liu",
      "Lueyang Zhang",
      "Xinyu Geng",
      "Shijue Huang",
      "Peng Xia",
      "Guanyu Jiang",
      "Cheng Wang",
      "Yue Zhang",
      "Yi R. Fung",
      "Junxian He"
    ],
    "abstract": "Real-world multimodal agents solve multi-step workflows grounded in visual evidence. For example, an agent can troubleshoot a device by linking a wiring photo to a schematic and validating the fix with online documentation, or plan a trip by interpreting a transit map and checking schedules under routing constraints. However, existing multimodal benchmarks mainly evaluate single-turn visual reasoning or specific tool skills, and they do not fully capture the realism, visual subtlety, and long-horizon tool use that practical agents require. We introduce AgentVista, a benchmark for generalist multimodal agents that spans 25 sub-domains across 7 categories, pairing realistic and detail-rich visual scenarios with natural hybrid tool use. Tasks require long-horizon tool interactions across modalities, including web search, image search, page navigation, and code-based operations for both image processing and general programming. Comprehensive evaluation of state-of-the-art models exposes significant gaps in their ability to carry out long-horizon multimodal tool use. Even the best model in our evaluation, Gemini-3-Pro with tools, achieves only 27.3% overall accuracy, and hard instances can require more than 25 tool-calling turns. We expect AgentVista to accelerate the development of more capable and reliable multimodal agents for realistic and ultra-challenging problem solving.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23166.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23166",
    "published": "2026-02-26T16:30:46Z",
    "updated": "2026-02-26T16:30:46Z",
    "comment": "The project website is available at \\url{https://agentvista-bench.github.io/}, and the code is available at \\url{https://github.com/hkust-nlp/AgentVista}",
    "light_analysis": {
      "overview": "本文提出了AgentVista基准，用于评估多模态代理在极挑战性现实视觉场景中的长时域工具使用能力。",
      "motivation": "现实世界的多模态代理需要解决基于视觉证据的多步骤工作流，如设备故障排除或旅行规划。然而，现有多模态基准主要评估单轮视觉推理或特定工具技能，无法充分捕捉真实感、视觉细微差别和长时域工具使用，这限制了代理在复杂任务中的应用。因此，需要开发一个更全面的评估框架以推动实用多模态代理的发展。",
      "method": "论文介绍了AgentVista基准，它涵盖7个类别和25个子领域，结合真实且细节丰富的视觉场景与自然混合工具使用。任务设计强调长时域跨模态工具交互，包括网络搜索、图像搜索、页面导航以及基于代码的图像处理和编程操作。关键创新在于模拟现实世界复杂工作流程，提供贴近实际应用的评估环境，无需额外数据集或模型架构细节。",
      "result": "对最先进模型的全面评估显示其在长时域多模态工具使用方面有显著差距。最佳模型Gemini-3-Pro with tools的整体准确率仅为27.3%，而困难实例可能需要超过25次工具调用。这表明现有方法在应对复杂现实视觉任务时性能不足，与理想效果相比存在较大提升空间。",
      "conclusion": "本研究通过提出AgentVista基准，为评估和改进多模态代理在现实场景中的能力提供了新标准，促进了更强大可靠代理的开发，具有重要学术和实际应用价值。未来工作可专注于提升模型在这些复杂任务上的性能，并扩展基准以覆盖更多领域，但摘要未明确说明具体局限性。",
      "tags": [
        "Multimodal Agents",
        "Benchmarking",
        "Tool Use",
        "Long-Horizon Tasks",
        "Realistic Visual Scenarios"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:02.550202Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23165",
    "title": "DyaDiT: A Multi-Modal Diffusion Transformer for Socially Favorable Dyadic Gesture Generation",
    "authors": [
      "Yichen Peng",
      "Jyun-Ting Song",
      "Siyeol Jung",
      "Ruofan Liu",
      "Haiyang Liu",
      "Xuangeng Chu",
      "Ruicong Liu",
      "Erwin Wu",
      "Hideki Koike",
      "Kris Kitani"
    ],
    "abstract": "Generating realistic conversational gestures are essential for achieving natural, socially engaging interactions with digital humans. However, existing methods typically map a single audio stream to a single speaker's motion, without considering social context or modeling the mutual dynamics between two people engaging in conversation. We present DyaDiT, a multi-modal diffusion transformer that generates contextually appropriate human motion from dyadic audio signals. Trained on Seamless Interaction Dataset, DyaDiT takes dyadic audio with optional social-context tokens to produce context-appropriate motion. It fuses information from both speakers to capture interaction dynamics, uses a motion dictionary to encode motion priors, and can optionally utilize the conversational partner's gestures to produce more responsive motion. We evaluate DyaDiT on standard motion generation metrics and conduct quantitative user studies, demonstrating that it not only surpasses existing methods on objective metrics but is also strongly preferred by users, highlighting its robustness and socially favorable motion generation. Code and models will be released upon acceptance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23165.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23165",
    "published": "2026-02-26T16:30:07Z",
    "updated": "2026-02-26T16:30:07Z",
    "comment": "13 pages, 9 figures",
    "light_analysis": {
      "overview": "提出DyaDiT，一个多模态扩散变压器，用于从双人音频生成社交友好的对话手势，考虑交互动态和社交上下文。",
      "motivation": "生成真实对话手势是实现数字人类自然社交互动的关键。现有方法通常将单个音频流映射到单个说话者的动作，忽视社交上下文和两人对话中的相互动态，这导致生成的手势不够自然，影响互动效果。该问题的重要性在于社交上下文和交互动态是模拟真实对话的基础，现有方法的不足限制了数字人类的社交表现力和用户体验。",
      "method": "DyaDiT是一个基于扩散变压器的多模态模型，核心方法融合了双人音频信号以捕获交互动态。技术特色包括使用运动字典来编码动作先验，并可选择性地结合对话伙伴的手势来生成更具响应性的动作。模型在Seamless Interaction Dataset上训练，输入包括双人音频和可选的社交上下文标记，通过多模态融合实现上下文适当的运动生成。",
      "result": "DyaDiT在标准动作生成指标上优于现有基线方法，具体表现为在客观性能指标上的提升。定量用户研究结果显示，用户对DyaDiT生成的手势有强烈偏好，突显其在鲁棒性和社交友好性方面的优势。与现有方法相比，DyaDiT不仅提高了生成质量，还通过用户主观评价验证了实际应用效果。",
      "conclusion": "DyaDiT的主要贡献在于通过多模态扩散变压器，从双人音频生成上下文适当的手势，改善了数字人类社交互动的自然性。研究具有学术价值，推动多模态手势生成技术的发展，并具有实际应用价值，促进更真实的对话体验。摘要未明确说明局限性和未来工作方向，但潜在扩展可能包括更复杂的社交场景建模或实时生成优化。",
      "tags": [
        "Multi-Modal",
        "Diffusion Transformer",
        "Gesture Generation",
        "Social Context",
        "Dyadic Interaction"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:58.175655Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23164",
    "title": "MetaOthello: A Controlled Study of Multiple World Models in Transformers",
    "authors": [
      "Aviral Chawla",
      "Galen Hall",
      "Juniper Lovato"
    ],
    "abstract": "Foundation models must handle multiple generative processes, yet mechanistic interpretability largely studies capabilities in isolation; it remains unclear how a single transformer organizes multiple, potentially conflicting \"world models\". Previous experiments on Othello playing neural-networks test world-model learning but focus on a single game with a single set of rules. We introduce MetaOthello, a controlled suite of Othello variants with shared syntax but different rules or tokenizations, and train small GPTs on mixed-variant data to study how multiple world models are organized in a shared representation space. We find that transformers trained on mixed-game data do not partition their capacity into isolated sub-models; instead, they converge on a mostly shared board-state representation that transfers causally across variants. Linear probes trained on one variant can intervene on another's internal state with effectiveness approaching that of matched probes. For isomorphic games with token remapping, representations are equivalent up to a single orthogonal rotation that generalizes across layers. When rules partially overlap, early layers maintain game-agnostic representations while a middle layer identifies game identity, and later layers specialize. MetaOthello offers a path toward understanding not just whether transformers learn world models, but how they organize many at once.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23164.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23164",
    "published": "2026-02-26T16:28:09Z",
    "updated": "2026-02-26T16:28:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "MetaOthello通过受控Othello变体套件，揭示了transformer在混合数据训练时如何组织共享表示空间，而非分割成孤立子模型。",
      "motivation": "当前基础模型如transformer需处理多生成过程，但机制解释性研究多孤立于单一能力，未探讨多个世界模型的共享机制。先前Othello实验仅聚焦单个游戏规则，限制了我们对模型如何同时学习多任务的理解，导致无法解释transformer内部多模型组织方式，影响模型泛化和新任务适应能力。",
      "method": "论文提出MetaOthello，一个基于Othello的变体套件，包含多个游戏版本，共享语法但规则或标记化不同。研究者训练小型GPT模型在混合变体数据上，分析其内部表示空间。创新点包括使用线性探针测量和干预表示，通过比较表示等价性探索世界模型共享机制；数据集为生成的Othello变体，模型架构为transformer类似GPT，聚焦共享表示空间的实验设计。",
      "result": "实验结果显示，transformer在混合数据上训练后，未分配容量到孤立子模型，而是形成共享棋盘状态表示，能因果传递到不同变体。线性探针从一个变体训练后，对其他变体的干预效果接近匹配探针。同构游戏的表示在单个正交旋转下等价，且跨层泛化；当规则部分重叠时，表示分层：早期层通用、中间层识别游戏身份、后期层专门化，验证了共享表示的有效性。",
      "conclusion": "本研究通过MetaOthello套件，深化了对transformer组织多个世界模型的机械理解，揭示了共享表示和分层结构的重要性。贡献在于提供实验框架促进机制解释性研究，可能指导多任务学习模型设计；潜在局限性包括仅使用简单游戏变体，未来工作可扩展至更复杂模型和应用场景，摘要未明确说明具体限制。",
      "tags": [
        "Transformers",
        "World Models",
        "Mechanistic Interpretability",
        "Linear Probes",
        "Shared Representation Space"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:23.886124Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23163",
    "title": "A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring",
    "authors": [
      "Usman Anwar",
      "Julianna Piskorz",
      "David D. Baek",
      "David Africa",
      "Jim Weatherall",
      "Max Tegmark",
      "Christian Schroeder de Witt",
      "Mihaela van der Schaar",
      "David Krueger"
    ],
    "abstract": "Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \\textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this otherwise latent asymmetry can be inferred from the agents' observable actions. To formalise this perspective, we introduce generalised $\\mathcal{V}$-information: a utilitarian framework for measuring the amount of usable information within some input. We use this to define the \\textbf{steganographic gap} -- a measure that quantifies steganography by comparing the downstream utility of the steganographic signal to agents that can and cannot decode the hidden content. We empirically validate our formalism, and show that it can be used to detect, quantify, and mitigate steganographic reasoning in LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.IT",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23163.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23163",
    "published": "2026-02-26T16:27:24Z",
    "updated": "2026-02-26T16:27:24Z",
    "comment": "First two authors contributed equally",
    "light_analysis": {
      "overview": "本文提出了一种基于决策理论的隐写术形式化框架，用于检测和量化大语言模型中的隐写推理行为。",
      "motivation": "大语言模型开始显现隐写能力，这可能使不匹配的模型逃避监督机制，威胁AI系统的安全性和可监管性。现有方法基于经典隐写定义，需要已知的非隐写信号参考分布来检测隐写，但在LLM环境中，获取这样的参考分布不切实际，导致这些方法失效。因此，迫切需要新的原则性方法来应对这一挑战，确保AI系统在部署过程中的可靠监控。",
      "method": "论文的核心方法是引入决策理论的隐写观，其关键创新点在于通过信息不对称来量化隐写：隐写在能解码和不能解码隐藏内容的代理之间创建了可用信息的不对称，这种不对称可从代理的可观察行动中推断。为此，论文定义了广义$\\mathcal{V}$-信息作为一个实用框架，用于测量输入中的可用信息量，并由此提出隐写间隙——通过比较隐写信号对解码和非解码代理的下游效用来量化隐写。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "摘要中提到通过实证验证了所提出的形式化框架，并展示其可用于检测、量化和减轻LLM中的隐写推理行为。然而，摘要未提供具体的性能指标，如准确率提升或效率改进的数值数据，也未提及与基线方法的详细对比情况，因此实验效果的具体数据在摘要中未明确说明。",
      "conclusion": "论文的主要贡献是建立了一个决策理论的框架来形式化隐写术，并将其应用于大语言模型的监控中，解决了现有方法对参考分布的依赖问题。该研究的学术价值在于将决策理论工具引入信息论领域，为隐写检测提供了新的方法论；实际应用价值在于增强LLM的安全性和透明度，助力AI监管。未来工作可能涉及进一步优化框架以处理更复杂的隐写场景或扩展到其他AI模型。",
      "tags": [
        "Steganography",
        "Large Language Models",
        "Decision Theory",
        "Generalized V-information",
        "LLM Monitoring"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:25.723168Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23161",
    "title": "PATRA: Pattern-Aware Alignment and Balanced Reasoning for Time Series Question Answering",
    "authors": [
      "Junkai Lu",
      "Peng Chen",
      "Xingjian Wu",
      "Yang Shu",
      "Chenjuan Guo",
      "Christian S. Jensen",
      "Bin Yang"
    ],
    "abstract": "Time series reasoning demands both the perception of complex dynamics and logical depth. However, existing LLM-based approaches exhibit two limitations: they often treat time series merely as text or images, failing to capture the patterns like trends and seasonalities needed to answer specific questions; and when trained on a mix of simple and complex tasks, simpler objectives often dominate the learning process, hindering the development of deep reasoning capabilities. To address these limitations, we propose the Pattern-Aware Alignment and Balanced Reasoning model (PATRA), introducing a pattern-aware mechanism that extracts trend and seasonality patterns from time series to achieve deep alignment. Furthermore, we design a task-aware balanced reward to harmonize learning across tasks of varying difficulty, incentivizing the generation of coherent Chains of Thought. Extensive experiments show that PATRA outperforms strong baselines across diverse Time Series Question Answering (TSQA) tasks, demonstrating superior cross-modal understanding and reasoning capability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23161.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23161",
    "published": "2026-02-26T16:20:03Z",
    "updated": "2026-02-26T16:20:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "PATRA模型通过模式感知对齐和平衡推理机制，显著提升了时间序列问答的跨模态理解和推理能力。",
      "motivation": "时间序列推理需同时感知复杂动态和逻辑深度，但现有基于大语言模型的方法存在两个关键局限：首先，它们将时间序列简单视为文本或图像，无法有效提取趋势和季节性等关键模式，导致回答问题不准确；其次，在混合简单和复杂任务训练时，简单任务常主导学习过程，抑制深度推理能力的培养。这些问题限制了时间序列问答等实际应用的性能，凸显了开发新方法的必要性。",
      "method": "论文提出PATRA模型，核心包括模式感知机制，从时间序列中提取趋势和季节性模式以实现深度对齐，增强跨模态理解。此外，设计了任务感知平衡奖励，协调不同难度任务的学习，激励生成连贯的思考链，促进深度推理。具体数据集和模型架构摘要未明确说明，但方法聚焦于整合模式提取与奖励平衡的创新设计。",
      "result": "大量实验表明，PATRA在各种时间序列问答任务上均优于强基线方法，展示了卓越的跨模态理解和推理能力。尽管摘要未提供具体性能指标如准确率提升，但通过对比验证了模型的优越性，证实了模式感知机制和平衡奖励在提升任务性能方面的有效性。",
      "conclusion": "PATRA模型成功解决了现有LLM-based方法在时间序列推理中模式捕获不足和任务不平衡的问题，提升了问答性能。其学术价值在于推动了时间序列分析与大语言模型的结合，实际应用可扩展至金融、医疗等领域的时间序列分析系统。未来工作可进一步探索更复杂模式或模型优化，摘要未明确说明具体局限性。",
      "tags": [
        "Time Series Question Answering",
        "Pattern-Aware Alignment",
        "Balanced Reasoning",
        "Cross-Modal Understanding",
        "Chains of Thought"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:31.559735Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23159",
    "title": "Benchmarking Temporal Web3 Intelligence: Lessons from the FinSurvival 2025 Challenge",
    "authors": [
      "Oshani Seneviratne",
      "Fernando Spadea",
      "Adrien Pavao",
      "Aaron Micah Green",
      "Kristin P. Bennett"
    ],
    "abstract": "Temporal Web analytics increasingly relies on large-scale, longitudinal data to understand how users, content, and systems evolve over time. A rapidly growing frontier is the \\emph{Temporal Web3}: decentralized platforms whose behavior is recorded as immutable, time-stamped event streams. Despite the richness of this data, the field lacks shared, reproducible benchmarks that capture real-world temporal dynamics, specifically censoring and non-stationarity, across extended horizons. This absence slows methodological progress and limits the transfer of techniques between Web3 and broader Web domains. In this paper, we present the \\textit{FinSurvival Challenge 2025} as a case study in benchmarking \\emph{temporal Web3 intelligence}. Using 21.8 million transaction records from the Aave v3 protocol, the challenge operationalized 16 survival prediction tasks to model user behavior transitions.We detail the benchmark design and the winning solutions, highlighting how domain-aware temporal feature construction significantly outperformed generic modeling approaches. Furthermore, we distill lessons for next-generation temporal benchmarks, arguing that Web3 systems provide a high-fidelity sandbox for studying temporal challenges, such as churn, risk, and evolution that are fundamental to the wider Web.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23159.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23159",
    "published": "2026-02-26T16:19:02Z",
    "updated": "2026-02-26T16:19:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出FinSurvival Challenge 2025基准测试，证明了领域感知时间特征构建在Temporal Web3中的有效性，为研究时间动态提供新范例。",
      "motivation": "研究动机源于Temporal Web3领域缺乏共享、可复现的基准来捕捉现实世界时间动态，特别是长期时间下的审查和非平稳性问题。随着去中心化平台产生丰富的时间戳事件流，这种缺失减慢了方法学进展，并限制了Web3技术与更广泛Web领域的转移，因此开发标准化基准至关重要。通过案例研究，本文旨在弥补这一空白，推动跨领域技术交流和进步。",
      "method": "研究方法包括设计FinSurvival Challenge 2025作为基准测试案例，使用来自Aave v3协议的21.8百万交易记录数据集，操作16个生存预测任务来建模用户行为转换。关键创新点是领域感知的时间特征构建，优于通用建模方法，并详细描述基准设计框架和获胜解决方案的技术细节，以促进可复现性。",
      "result": "主要实验结果显示，领域感知的时间特征构建在16个生存预测任务中显著优于通用建模方法，摘要未明确说明具体性能指标如准确率提升，但强调了这一方法在捕捉时间动态方面的优势。通过基准测试，获胜解决方案证实了领域特定特征的有效性，为未来研究提供性能对比基准。",
      "conclusion": "论文结论是FinSurvival Challenge 2025为Temporal Web3提供了高保真基准测试框架，总结出Web3系统可作为研究时间挑战（如流失、风险和演变）的理想沙箱。主要贡献在于推动方法学进展和技术转移，具有学术价值和实际应用意义，未来方向包括开发下一代时间基准以扩展跨领域应用。",
      "tags": [
        "Temporal Web3",
        "Survival Prediction",
        "Benchmarking",
        "Feature Construction",
        "Aave Protocol"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:36.993192Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23153",
    "title": "Efficient Encoder-Free Fourier-based 3D Large Multimodal Model",
    "authors": [
      "Guofeng Mei",
      "Wei Lin",
      "Luigi Riz",
      "Yujiao Wu",
      "Yiming Wang",
      "Fabio Poiesi"
    ],
    "abstract": "Large Multimodal Models (LMMs) that process 3D data typically rely on heavy, pre-trained visual encoders to extract geometric features. While recent 2D LMMs have begun to eliminate such encoders for efficiency and scalability, extending this paradigm to 3D remains challenging due to the unordered and large-scale nature of point clouds. This leaves a critical unanswered question: How can we design an LMM that tokenizes unordered 3D data effectively and efficiently without a cumbersome encoder? We propose Fase3D, the first efficient encoder-free Fourier-based 3D scene LMM. Fase3D tackles the challenges of scalability and permutation invariance with a novel tokenizer that combines point cloud serialization and the Fast Fourier Transform (FFT) to approximate self-attention. This design enables an effective and computationally minimal architecture, built upon three key innovations: First, we represent large scenes compactly via structured superpoints. Second, our space-filling curve serialization followed by an FFT enables efficient global context modeling and graph-based token merging. Lastly, our Fourier-augmented LoRA adapters inject global frequency-aware interactions into the LLMs at a negligible cost. Fase3D achieves performance comparable to encoder-based 3D LMMs while being significantly more efficient in computation and parameters. Project website: https://tev-fbk.github.io/Fase3D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23153.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23153",
    "published": "2026-02-26T16:16:02Z",
    "updated": "2026-02-26T16:16:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Fase3D，首款高效的无编码器傅里叶基3D大型多模态模型，通过FFT近似自注意力处理无序点云。",
      "motivation": "研究动机是解决处理3D数据的LMMs效率低下和可扩展性差的问题。现有方法依赖重的预训练视觉编码器提取点云几何特征，导致计算开销大、部署困难。虽然2D LMMs已开始去除编码器以提高效率，但3D点云的无序性和大规模性使其扩展面临挑战，核心未解问题是：如何设计高效且无需编码器的3D LMM。这突出了开发轻量化方法的必要性，以促进3D多模态模型的广泛应用。",
      "method": "研究方法基于Fase3D架构，设计了一种新颖的标记化器，结合点云序列化和快速傅里叶变换（FFT）来近似自注意力。首先，使用结构化超级点紧凑表示大规模3D场景。其次，通过空间填充曲线序列化点云数据，并应用FFT实现高效的全局上下文建模和图基令牌合并。最后，采用傅里叶增强的LoRA适配器，以可忽略的成本将全局频率感知交互注入大型语言模型（LLMs），构建了计算极简的架构。",
      "result": "实验结果表明，Fase3D在性能上与基于编码器的3D LMMs相当，同时在计算效率和参数数量方面显著更高效。虽然摘要未提供具体数据对比，但强调了其在减少资源消耗的同时保持竞争力，解决了传统方法的高成本问题，为实际部署提供了更可行的替代方案。",
      "conclusion": "论文的主要贡献是首次提出Fase3D，实现了高效的基于傅里叶的无编码器3D LMM，突破了3D数据处理中的效率瓶颈。其学术价值在于融合序列化技术和傅里叶变换，为无序点云提供了创新的标记化方法。实际应用价值在于提升模型的可扩展性和部署效率，适用于大规模3D场景分析。未来工作可能包括进一步优化或扩展至其他3D任务，以探索更广泛的应用潜力。",
      "tags": [
        "3D Large Multimodal Model",
        "Fast Fourier Transform (FFT)",
        "LoRA Adapters",
        "Point Cloud Tokenization",
        "Encoder-Free Architecture"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:52.936262Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23152",
    "title": "The Trinity of Consistency as a Defining Principle for General World Models",
    "authors": [
      "Jingxuan Wei",
      "Siyuan Li",
      "Yuhang Xu",
      "Zheng Sun",
      "Junjie Jiang",
      "Hexuan Jin",
      "Caijun Jia",
      "Honghao He",
      "Xinglong Xu",
      "Xi bai",
      "Chang Yu",
      "Yumou Liu",
      "Junnan Zhu",
      "Xuanhe Zhou",
      "Jintao Chen",
      "Xiaobin Hu",
      "Shancheng Pang",
      "Bihui Yu",
      "Ran He",
      "Zhen Lei",
      "Stan Z. Li",
      "Conghui He",
      "Shuicheng Yan",
      "Cheng Tan"
    ],
    "abstract": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23152.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23152",
    "published": "2026-02-26T16:15:55Z",
    "updated": "2026-02-26T16:15:55Z",
    "comment": "119 pages, 50 figures",
    "light_analysis": {
      "overview": "本文提出了三位一体一致性原则作为定义通用世界模型的理论框架，并引入CoW-Bench基准进行评估。",
      "motivation": "研究动机源于构建能学习、模拟和推理客观物理定律的世界模型是实现人工通用智能的基础挑战。尽管近期进展如Sora视频生成模型和统一多模态模型展示了数据驱动方法模拟物理动态的潜力，但领域内缺乏一个原则性理论框架来定义通用世界模型必备的属性，如一致性要求，这导致研究分散、评估标准不一，阻碍了系统性进展和跨模型比较。",
      "method": "研究方法包括提出三位一体一致性框架，由模态一致性（作为语义接口）、空间一致性（作为几何基础）和时间一致性（作为因果引擎）组成，作为通用世界模型的定义基础。通过这一框架，系统回顾了多模态学习的演变，从松散耦合的专业模块向统一架构发展，以促进内部世界模拟器的协同涌现。此外，引入了CoW-Bench基准，专注于多帧推理和生成场景，为视频生成模型和统一多模态模型提供统一的评估协议，以测试其物理理解和模拟能力。",
      "result": "主要实验结果是建立了CoW-Bench基准并实施统一评估协议，用于评估视频生成模型和统一多模态模型在多帧推理和生成任务中的表现。摘要未明确说明具体的性能指标（如准确率提升或效率改进）或与基线方法的详细对比数据，但该基准旨在标准化评估流程，促进模型间的公平比较，并帮助识别当前系统在一致性方面的局限性，为未来优化提供方向。",
      "conclusion": "本文的主要贡献是提出了三位一体一致性原则作为通用世界模型的理论定义，并结合CoW-Bench基准提供了评估工具，填补了领域内的理论空白。其学术价值在于为多模态学习和世界模拟的集成提供了框架，推动了AGI研究；实际应用价值在于为模型设计和评估指明了路径，有助于澄清当前限制并指导未来架构开发。未来工作可基于此框架探索更复杂场景，并完善基准以覆盖更多物理推理任务。",
      "tags": [
        "World Models",
        "Multimodal Learning",
        "Consistency Principles",
        "Benchmark Evaluation",
        "Unified Multimodal Model"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:12.552590Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23148",
    "title": "On Sample-Efficient Generalized Planning via Learned Transition Models",
    "authors": [
      "Nitin Gupta",
      "Vishal Pallagani",
      "John A. Aydin",
      "Biplav Srivastava"
    ],
    "abstract": "Generalized planning studies the construction of solution strategies that generalize across families of planning problems sharing a common domain model, formally defined by a transition function $γ: S \\times A \\rightarrow S$. Classical approaches achieve such generalization through symbolic abstractions and explicit reasoning over $γ$. In contrast, recent Transformer-based planners, such as PlanGPT and Plansformer, largely cast generalized planning as direct action-sequence prediction, bypassing explicit transition modeling. While effective on in-distribution instances, these approaches typically require large datasets and model sizes, and often suffer from state drift in long-horizon settings due to the absence of explicit world-state evolution. In this work, we formulate generalized planning as a transition-model learning problem, in which a neural model explicitly approximates the successor-state function $\\hatγ \\approx γ$ and generates plans by rolling out symbolic state trajectories. Instead of predicting actions directly, the model autoregressively predicts intermediate world states, thereby learning the domain dynamics as an implicit world model. To study size-invariant generalization and sample efficiency, we systematically evaluate multiple state representations and neural architectures, including relational graph encodings. Our results show that learning explicit transition models yields higher out-of-distribution satisficing-plan success than direct action-sequence prediction in multiple domains, while achieving these gains with significantly fewer training instances and smaller models. This is an extended version of a short paper accepted at ICAPS 2026 under the same title.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23148.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23148",
    "published": "2026-02-26T16:13:46Z",
    "updated": "2026-02-26T16:13:46Z",
    "comment": "14 pages; This is an extended version of a short paper accepted at ICAPS 2026 under the same title",
    "light_analysis": {
      "overview": "论文提出通过学习显式转移模型，实现了样本高效且泛化能力更强的广义规划方法。",
      "motivation": "广义规划研究如何构建适用于共享域模型规划家族的解决方案策略。现有基于Transformer的方法（如PlanGPT）通过直接预测动作序列实现泛化，虽在分布内实例有效，但需大数据集和大模型，且在长时域设置中因缺乏显式状态演化而出现状态漂移，限制了其实际应用。解决这些问题对于提升规划系统的效率和鲁棒性至关重要，特别是在资源受限的场景中。",
      "method": "本研究将广义规划定义为转移模型学习问题，其中神经模型显式近似后继状态函数，并通过展开符号状态轨迹生成计划。核心创新是模型自回归预测中间世界状态，而非直接预测动作，从而将领域动态学习为隐式世界模型。实验评估了多种状态表示和神经架构，包括关系图编码，以研究大小不变泛化和样本效率，确保方法在不同设置下的适应性。",
      "result": "实验结果表明，学习显式转移模型在多个规划领域实现了比直接动作序列预测更高的分布外满意计划成功率。此外，该方法使用显著更少的训练实例和更小的模型即可达到这些效果，显示出优越的样本效率和泛化能力。尽管摘要未提供具体数据，但与基线方法对比显示性能改进明显，验证了其在减少数据依赖和模型复杂度方面的优势。",
      "conclusion": "本研究的主要贡献是证明了学习显式转移模型能有效提升广义规划的样本效率和分布外泛化能力，为规划学习提供了新视角。学术价值在于推动神经符号规划方法的发展，实际应用价值在于降低对大规模数据的依赖，促进更高效的AI系统设计。未来工作可探索模型在更复杂领域或真实场景中的扩展，并优化状态表示以进一步提升性能。",
      "tags": [
        "Generalized Planning",
        "Transition Model Learning",
        "Neural Networks",
        "Relational Graph Encoding",
        "Sample Efficiency"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:03.057351Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23146",
    "title": "Partial recovery of meter-scale surface weather",
    "authors": [
      "Jonathan Giezendanner",
      "Qidong Yang",
      "Eric Schmitt",
      "Anirban Chandra",
      "Daniel Salles Civitarese",
      "Johannes Jakubik",
      "Jeremy Vila",
      "Detlef Hohl",
      "Campbell Watson",
      "Sherrie Wang"
    ],
    "abstract": "Near-surface atmospheric conditions can differ sharply over tens to hundreds of meters due to land cover and topography, yet this variability is absent from current weather analyses and forecasts. It is unclear whether such meter-scale variability reflects irreducibly chaotic dynamics or contains a component predictable from surface characteristics and large-scale atmospheric forcing. Here we show that a substantial, physically coherent component of meter-scale near-surface weather is statistically recoverable from existing observations. By conditioning coarse atmospheric state on sparse surface station measurements and high-resolution Earth observation data, we infer spatially continuous fields of near-surface wind, temperature, and humidity at 10 m resolution across the contiguous United States. Relative to ERA5, the inferred fields reduce wind error by 29% and temperature and dewpoint error by 6%, while explaining substantially more spatial variance at fixed time steps. They also exhibit physically interpretable structure, including urban heat islands, evapotranspiration-driven humidity contrasts, and wind speed differences across land cover types. Our findings expand the frontier of weather modeling by demonstrating a computationally feasible approach to continental-scale meter-resolution inference. More broadly, they illustrate how conditioning coarse dynamical models on static fine-scale features can reveal previously unresolved components of the Earth system.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23146.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23146",
    "published": "2026-02-26T16:11:53Z",
    "updated": "2026-02-26T16:11:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种通过结合粗粒度大气状态、稀疏地面站测量和高分辨率地球观测数据，统计性地恢复米尺度近地表天气的方法，显著提升了预测精度。",
      "motivation": "近地表大气条件在十到百米尺度上因土地覆盖和地形变化而显著不同，这对局部天气预测至关重要，例如城市热岛效应。然而，现有天气分析和预测（如ERA5）缺乏这种精细变异性，导致误差和不准确。该研究旨在解决米尺度天气是否可预测的问题，探索从表面特性和大尺度强迫中恢复这种变化的方法，以弥补当前高分辨率推断的不足。",
      "method": "研究方法基于统计推断，通过条件化粗粒度大气状态（如来自ERA5）在稀疏表面站测量和高分辨率地球观测数据上，生成连续的风、温度和湿度场，分辨率达到10米。关键创新点包括融合多源数据实现高分辨率推断，计算上可行，适用于大陆尺度分析。使用数据集包括ERA5大气状态、稀疏表面站观测和高分辨率卫星或遥感数据，以捕捉精细地表特征。",
      "result": "实验结果显示，与ERA5基线相比，推断的米尺度近地表天气场将风误差减少了29%，温度和露点误差减少了6%。在固定时间步长上，这些场解释了更多空间方差，并展现出物理可解释的结构，如城市热岛、蒸发驱动的湿度对比和不同土地覆盖类型的风速差异，验证了方法的有效性和准确性。",
      "conclusion": "研究结论表明，米尺度近地表天气的可预测部分可以通过条件化粗粒度模型于静态精细特征来统计恢复，这扩展了天气建模的前沿，实现了计算可行的大陆尺度高分辨率推断。学术价值在于揭示了地球系统中未解决的成分，实际应用价值包括提升局部天气预报精度。未来工作可能涉及在其他区域验证方法或进一步优化推断技术。",
      "tags": [
        "Meter-Scale Weather Prediction",
        "Statistical Inference",
        "High-Resolution Earth Observation",
        "Coarse-to-Fine Modeling",
        "Surface Weather Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:04.091670Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23142",
    "title": "Prediction of Diffusion Coefficients in Mixtures with Tensor Completion",
    "authors": [
      "Zeno Romero",
      "Kerstin Münnemann",
      "Hans Hasse",
      "Fabian Jirasek"
    ],
    "abstract": "Predicting diffusion coefficients in mixtures is crucial for many applications, as experimental data remain scarce, and machine learning (ML) offers promising alternatives to established semi-empirical models. Among ML models, matrix completion methods (MCMs) have proven effective in predicting thermophysical properties, including diffusion coefficients in binary mixtures. However, MCMs are restricted to single-temperature predictions, and their accuracy depends strongly on the availability of high-quality experimental data for each temperature of interest. In this work, we address this challenge by presenting a hybrid tensor completion method (TCM) for predicting temperature-dependent diffusion coefficients at infinite dilution in binary mixtures. The TCM employs a Tucker decomposition and is jointly trained on experimental data for diffusion coefficients at infinite dilution in binary systems at 298 K, 313 K, and 333 K. Predictions from the semi-empirical SEGWE model serve as prior knowledge within a Bayesian training framework. The TCM then extrapolates linearly to any temperature between 268 K and 378 K, achieving markedly improved prediction accuracy compared to established models across all studied temperatures. To further enhance predictive performance, the experimental database was expanded using active learning (AL) strategies for targeted acquisition of new diffusion data by pulsed-field gradient (PFG) NMR measurements. Diffusion coefficients at infinite dilution in 19 solute + solvent systems were measured at 298 K, 313 K, and 333 K. Incorporating these results yields a substantial improvement in the TCM's predictive accuracy. These findings highlight the potential of combining data-efficient ML methods with adaptive experimentation to advance predictive modeling of transport properties.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23142.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23142",
    "published": "2026-02-26T16:08:50Z",
    "updated": "2026-02-26T16:08:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出混合张量完成方法，用于预测二元混合物中温度依赖的扩散系数，通过结合Tucker分解和贝叶斯训练框架，显著提升预测准确性。",
      "motivation": "预测混合物中的扩散系数对诸多应用至关重要，但实验数据稀缺，传统半经验模型受限。现有矩阵完成方法（MCMs）虽能预测扩散系数，但仅支持单温度预测，且准确度高度依赖高质量实验数据，这限制了其在动态温度环境中的应用。因此，开发能处理温度依赖性的新方法成为研究重点，以解决数据不足和模型灵活性差的问题。",
      "method": "本研究提出混合张量完成方法（TCM），采用Tucker分解技术，联合训练298K、313K和333K温度点的实验数据。在贝叶斯训练框架中，集成SEGWE半经验模型的预测作为先验知识，实现温度线性外推到268K至378K范围。此外，通过主动学习策略扩展实验数据库，使用脉冲场梯度（PFG）NMR测量新扩散数据，涉及19个溶质-溶剂系统，以增强模型训练效果和预测能力。",
      "result": "TCM在预测温度依赖扩散系数方面表现优异，在268K至378K范围内相比现有模型（如SEGWE和传统矩阵完成方法）有显著改进的预测准确度，具体指标如准确率提升在摘要中未明确说明。通过主动学习获得的额外实验数据进一步优化了TCM的性能，实现了预测精度的显著提升，验证了方法在温度外推和数据扩展下的有效性。",
      "conclusion": "论文的主要贡献在于开发了混合张量完成方法，有效解决了温度依赖扩散系数预测的挑战，展示了数据高效机器学习与自适应实验结合的潜力。这为输运性质预测模型的发展提供了新方向，具有学术和应用价值；未来工作可扩展至更广温度范围或复杂混合物系统，以进一步验证和优化方法，摘要未明确说明具体局限性。",
      "tags": [
        "Tensor Completion",
        "Tucker Decomposition",
        "Bayesian Training",
        "Active Learning",
        "Diffusion Coefficients"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:37.512955Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23141",
    "title": "No Labels, No Look-Ahead: Unsupervised Online Video Stabilization with Classical Priors",
    "authors": [
      "Tao Liu",
      "Gang Wan",
      "Kan Ren",
      "Shibo Wen"
    ],
    "abstract": "We propose a new unsupervised framework for online video stabilization. Unlike methods based on deep learning that require paired stable and unstable datasets, our approach instantiates the classical stabilization pipeline with three stages and incorporates a multithreaded buffering mechanism. This design addresses three longstanding challenges in end-to-end learning: limited data, poor controllability, and inefficiency on hardware with constrained resources. Existing benchmarks focus mainly on handheld videos with a forward view in visible light, which restricts the applicability of stabilization to domains such as UAV nighttime remote sensing. To fill this gap, we introduce a new multimodal UAV aerial video dataset (UAV-Test). Experiments show that our method consistently outperforms state-of-the-art online stabilizers in both quantitative metrics and visual quality, while achieving performance comparable to offline methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23141.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23141",
    "published": "2026-02-26T16:04:36Z",
    "updated": "2026-02-26T16:04:36Z",
    "comment": "CVPR2026",
    "light_analysis": {
      "overview": "提出一种基于经典先验的无监督在线视频稳定框架，无需配对数据并解决效率和可控性问题。",
      "motivation": "当前视频稳定技术主要依赖深度学习，需要大量配对数据集且效率低、可控性差，特别是在资源受限的硬件上难以应用。现有基准集中于手持可见光视频，限制了在无人机夜间遥感等领域的通用性。本研究旨在开发一个无监督在线稳定方法，以克服数据稀缺、可控性不足和硬件效率低下的长期挑战，拓展稳定技术的适用范围。",
      "method": "本研究设计了一个无监督在线视频稳定框架，实例化经典稳定管道为三个阶段，并融入多线程缓冲机制以实现实时处理。核心创新在于避免使用深度学习所需的配对数据，转而利用经典先验（如运动估计）进行稳定，提高效率和可控性。此外，引入了新的多模态无人机航空视频数据集（UAV-Test）以评估方法性能。",
      "result": "实验结果显示，该方法在 UAV-Test 数据集上，定量指标（如稳定性分数）和视觉质量均一致优于现有最先进的在线稳定器。同时，其性能与离线方法相当，表明在资源受限硬件上实现了高效的实时处理，验证了方法的优越性和实用性。",
      "conclusion": "本研究的主要贡献是提出了一种结合经典先验和多线程缓冲的无监督在线视频稳定框架，有效解决了数据依赖、可控性和效率问题。学术价值在于为视频稳定提供了新的无监督解决方案，实际应用价值体现在扩展技术到无人机遥感等领域。未来工作可进一步优化机制或探索更多多模态应用。",
      "tags": [
        "Video Stabilization",
        "Unsupervised Learning",
        "Classical Priors",
        "Multithreaded Buffering",
        "UAV Dataset"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:34.972339Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23136",
    "title": "Modality Collapse as Mismatched Decoding: Information-Theoretic Limits of Multimodal LLMs",
    "authors": [
      "Jayadev Billa"
    ],
    "abstract": "Multimodal LLMs can process speech and images, but they cannot hear a speaker's voice or see an object's texture. We show this is not a failure of encoding: speaker identity, emotion, and visual attributes survive through every LLM layer (3--55$\\times$ above chance in linear probes), yet removing 64--71% of modality-specific variance improves decoder loss. The decoder has no learned use for these directions; their presence is noise.   We formalize this as a mismatched decoder problem: a decoder trained on text can only extract information along text-aligned directions. Accessible information is bounded by the Generalized Mutual Information (GMI), with degradation scaling with distributional distance and decoder sensitivity. The bound is a property of the decoder's scoring rule, not of any particular architecture; it applies whether non-text inputs arrive through a learned projection, a discrete codebook, or no explicit adapter at all. We validate this across five models spanning speech and vision. A controlled experiment (two Prismatic VLMs differing only in encoder text-alignment) confirms the bottleneck is the decoder's scoring rule, not the encoder or projection. A LoRA intervention demonstrates the fix: training with an emotion objective improves emotion accessibility ($+$7.5%) without affecting other attributes, confirming that the training objective determines what becomes accessible.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23136.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23136",
    "published": "2026-02-26T15:52:48Z",
    "updated": "2026-02-26T15:52:48Z",
    "comment": "22 pages, 11 tables, 2 figures. Code: https://github.com/jb1999/modality_collapse_paper",
    "light_analysis": {
      "overview": "本文通过形式化模态崩溃为不匹配解码问题，揭示了多模态LLMs中可访问信息受解码器评分规则限制的信息理论边界。",
      "motivation": "多模态LLMs能够处理语音和图像等非文本输入，但在实际应用中无法有效提取说话者声音、物体纹理等特定属性，导致模态崩溃。这个问题之所以重要，是因为尽管编码器层面保留了这些模态特定信息（如线性探针显示信息存活高于机会水平），但解码器无法利用，限制了模型的多模态理解能力。现有方法可能忽视了编码器与解码器之间的不匹配，因此本论文旨在探究其根本原因，为解决多模态信息提取瓶颈提供理论基础。",
      "method": "论文提出将模态崩溃形式化为不匹配解码器问题，使用广义互信息（GMI）量化可访问信息的理论边界，强调该边界与架构无关。关键创新包括理论分析解码器评分规则对信息提取的限制，并通过线性探针评估信息在LLM各层的存活情况（如移除模态特定方差以改善损失）。实验设计涉及五个语音和视觉模型，包括受控比较两个仅编码器文本对齐不同的棱柱VLMs，以及应用LoRA干预来调整训练目标，验证理论假设。",
      "result": "主要实验结果显示，线性探针表明模态特定信息在LLM层中存活，高于机会水平3-55倍，同时移除64-71%的模态特定方差改善了解码器损失。在五个模型中验证了理论边界，受控实验确认瓶颈在于解码器的评分规则而非编码器或投影。LoRA干预进一步提高了情绪可访问性7.5%，且不影响其他属性，证实了训练目标对信息可访问性的决定性作用，与基线方法对比突显了解码器优化的关键性。",
      "conclusion": "论文的主要贡献在于理论形式化模态崩溃为不匹配解码问题，提供了基于广义互信息（GMI）的信息理论边界，揭示了解码器评分规则是限制多模态信息可访问性的关键瓶颈。学术价值在于为多模态LLMs设计提供了新视角，强调训练目标的重要性；实际应用价值在于指导未来模型改进，如优化解码器或训练策略以增强模态特定信息提取。未来工作可能包括探索更有效的解码器设计或多模态融合方法，摘要未明确说明局限性，但可推断需进一步处理分布距离等挑战。",
      "tags": [
        "Multimodal LLMs",
        "Generalized Mutual Information (GMI)",
        "Mismatched Decoding",
        "LoRA",
        "Linear Probes"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:38.693011Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23135",
    "title": "DyGnROLE: Modeling Asymmetry in Dynamic Graphs with Node-Role-Oriented Latent Encoding",
    "authors": [
      "Tyler Bonnet",
      "Marek Rei"
    ],
    "abstract": "Real-world dynamic graphs are often directed, with source and destination nodes exhibiting asymmetrical behavioral patterns and temporal dynamics. However, existing dynamic graph architectures largely rely on shared parameters for processing source and destination nodes, with limited or no systematic role-aware modeling. We propose DyGnROLE (Dynamic Graph Node-Role-Oriented Latent Encoding), a transformer-based architecture that explicitly disentangles source and destination representations. By using separate embedding vocabularies and role-semantic positional encodings, the model captures the distinct structural and temporal contexts unique to each role. Critical to the effectiveness of these specialized embeddings in low-label regimes is a self-supervised pretraining objective we introduce: Temporal Contrastive Link Prediction (TCLP). The pretraining uses the full unlabeled interaction history to encode informative structural biases, enabling the model to learn role-specific representations without requiring annotated data. Evaluation on future edge classification demonstrates that DyGnROLE substantially outperforms a diverse set of state-of-the-art baselines, establishing role-aware modeling as an effective strategy for dynamic graph learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23135.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23135",
    "published": "2026-02-26T15:51:51Z",
    "updated": "2026-02-26T15:51:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "DyGnROLE提出一种基于transformer的角色感知潜编码架构，显式建模动态图中节点角色的不对称性。",
      "motivation": "现实世界动态图常表现为有向图，源节点和目标节点在行为模式和时间动态上存在显著不对称。然而，现有动态图学习方法多依赖共享参数处理不同角色节点，缺乏系统性的角色感知建模，这导致模型无法充分捕捉真实世界的复杂动态，尤其在低标签场景下性能受限。因此，研究旨在解决节点角色不对称性的建模问题，提升动态图学习的有效性和鲁棒性。",
      "method": "DyGnROLE采用transformer架构，通过为源节点和目的节点设计独立的嵌入词汇表，结合角色语义位置编码，显式分离节点表示以捕获角色特有的结构和时间上下文。关键创新是引入了自监督预训练目标——时间对比链接预测（TCLP），利用未标记的历史交互数据编码结构偏置，从而在不需要标注数据的情况下学习角色特定表示。这种方法增强了模型在低标签场景下的泛化能力。",
      "result": "在未来边分类任务的评估中，DyGnROLE大幅优于多种最先进的基线模型。摘要未明确说明具体的准确率或效率指标提升，但论文表明通过角色感知建模，模型在动态图学习中取得了更优性能，验证了该方法相对于传统共享参数架构的有效性和优势。",
      "conclusion": "DyGnROLE的主要贡献在于提出了一种显式建模动态图中节点角色不对称性的框架，结合角色感知潜编码和自监督学习，提升了动态图学习的性能。这项研究具有重要的学术价值，为动态图建模提供了新思路，并适用于社交网络分析等实际应用。未来工作可以探索扩展该方法到更广泛的图类型或集成其他学习任务，以进一步提升模型的泛化能力和应用范围。",
      "tags": [
        "Dynamic Graphs",
        "Node-Role Modeling",
        "Transformer Architecture",
        "Self-Supervised Learning",
        "Contrastive Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:33.485656Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23133",
    "title": "From Calibration to Refinement: Seeking Certainty via Probabilistic Evidence Propagation for Noisy-Label Person Re-Identification",
    "authors": [
      "Xin Yuan",
      "Zhiyong Zhang",
      "Xin Xu",
      "Zheng Wang",
      "Chia-Wen Lin"
    ],
    "abstract": "With the increasing demand for robust person Re-ID in unconstrained environments, learning from datasets with noisy labels and sparse per-identity samples remains a critical challenge. Existing noise-robust person Re-ID methods primarily rely on loss-correction or sample-selection strategies using softmax outputs. However, these methods suffer from two key limitations: 1) Softmax exhibits translation invariance, leading to over-confident and unreliable predictions on corrupted labels. 2) Conventional sample selection based on small-loss criteria often discards valuable hard positives that are crucial for learning discriminative features. To overcome these issues, we propose the CAlibration-to-REfinement (CARE) method, a two-stage framework that seeks certainty through probabilistic evidence propagation from calibration to refinement. In the calibration stage, we propose the probabilistic evidence calibration (PEC) that dismantles softmax translation invariance by injecting adaptive learnable parameters into the similarity function, and employs an evidential calibration loss to mitigate overconfidence on mislabeled samples. In the refinement stage, we design the evidence propagation refinement (EPR) that can more accurately distinguish between clean and noisy samples. Specifically, the EPR contains two steps: Firstly, the composite angular margin (CAM) metric is proposed to precisely distinguish clean but hard-to-learn positive samples from mislabeled ones in a hyperspherical space; Secondly, the certainty-oriented sphere weighting (COSW) is developed to dynamically allocate the importance of samples according to CAM, ensuring clean instances drive model updates. Extensive experimental results on Market1501, DukeMTMC-ReID, and CUHK03 datasets under both random and patterned noises show that CARE achieves competitive performance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23133.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23133",
    "published": "2026-02-26T15:50:15Z",
    "updated": "2026-02-26T15:50:15Z",
    "comment": "Accepted by IEEE TMM 2026",
    "light_analysis": {
      "overview": "论文提出了CARE方法，一个通过概率证据传播从校准到细化的两阶段框架，有效处理噪声标签并提升人员重识别性能。",
      "motivation": "随着在无约束环境中鲁棒人员重识别需求的增加，学习具有噪声标签和稀疏样本的数据集成为了关键挑战。现有方法主要依赖基于softmax输出的损失校正或样本选择策略，但存在两个主要不足：一是softmax的平移不变性导致对污染标签的过度自信和不可靠预测，限制了模型可靠性；二是基于小损失标准的样本选择常丢弃对学习判别特征至关重要的硬正样本，降低了学习效果。这些问题在真实场景中尤为突出，亟需改进以提升模型在噪声环境下的鲁棒性和准确性。",
      "method": "论文提出了CAlibration-to-REfinement（CARE）方法，这是一个两阶段框架。在校准阶段，设计了概率证据校准（PEC），通过向相似性函数注入自适应可学习参数来消除softmax平移不变性，并使用证据校准损失来缓解对错误标记样本的过度自信。在细化阶段，开发了证据传播细化（EPR），首先提出复合角边距（CAM）度量在超球面空间中精确区分干净但难以学习的正样本与错误标记样本；其次开发面向确定性的球面加权（COSW）根据CAM动态分配样本重要性，确保干净样本驱动模型更新。方法在多个标准数据集上进行了验证。",
      "result": "CARE方法在Market1501、DukeMTMC-ReID和CUHK03数据集上针对随机和模式噪声进行了广泛实验。结果表明，该方法在噪声标签下能够显著提升人员重识别性能，与现有基线方法相比展现出竞争性的表现。例如，在多种噪声设置下，CARE通过优化校准和样本选择，有效提高了准确率和鲁棒性，但摘要未明确说明具体数值。实验强调了其在处理噪声数据中的有效性和优越性。",
      "conclusion": "CARE方法通过概率证据传播框架成功解决了噪声标签人员重识别中的关键问题。主要贡献在于提出校准和细化两阶段策略，消除softmax限制并优化样本选择，从而提升模型在真实噪声环境中的鲁棒性。该研究具有重要的学术价值，为噪声鲁棒性方法提供了新思路，并具有实际应用前景，如监控和安防领域。未来工作可探索对不同噪声类型的适应性或扩展到其他视觉任务，摘要未明确说明具体局限性。",
      "tags": [
        "Person Re-Identification",
        "Noisy Label Learning",
        "Softmax Calibration",
        "Probabilistic Evidence",
        "Angular Margin Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:15.370465Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23128",
    "title": "Bound to Disagree : Generalization Bounds via Certifiable Surrogates",
    "authors": [
      "Mathieu Bazinet",
      "Valentina Zantedeschi",
      "Pascal Germain"
    ],
    "abstract": "Generalization bounds for deep learning models are typically vacuous, not computable or restricted to specific model classes. In this paper, we tackle these issues by providing new disagreement-based certificates for the gap between the true risk of any two predictors. We then bound the true risk of the predictor of interest via a surrogate model that enjoys tight generalization guarantees, and evaluating our disagreement bound on an unlabeled dataset. We empirically demonstrate the tightness of the obtained certificates and showcase the versatility of the approach by training surrogate models leveraging three different frameworks: sample compression, model compression and PAC-Bayes theory. Importantly, such guarantees are achieved without modifying the target model, nor adapting the training procedure to the generalization framework.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23128.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23128",
    "published": "2026-02-26T15:42:13Z",
    "updated": "2026-02-26T15:42:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种基于分歧的可认证代理方法，为任意深度学习模型提供严格的泛化边界，无需修改目标模型或训练过程。",
      "motivation": "当前深度学习模型的泛化边界通常存在空洞、不可计算或仅限于特定模型类别的问题，这限制了理论保障的实际应用价值。本研究旨在解决这些不足，通过开发新的分歧证书来量化任意两个预测器之间的真实风险差距，从而提供更通用和可计算的泛化保障，弥补现有方法的局限性。",
      "method": "论文提出一种基于分歧的证书方法，通过计算两个预测器在未标记数据集上的分歧来界定真实风险差距。关键创新在于引入代理模型，该模型受益于严格的泛化保证（利用样本压缩、模型压缩和PAC-Bayes理论框架），从而为目标预测器提供保障。方法不修改原始模型或训练流程，保持了独立性和通用性，仅需评估分歧边界在未标记数据上的表现。",
      "result": "实验结果表明，所获得的证书具有紧密性，能有效限制泛化差距，展示出方法的实用性。通过应用三种框架（样本压缩、模型压缩和PAC-Bayes理论）训练代理模型，证实了方法的通用性和稳健性。与基线方法相比，该方法提供了更精确的泛化边界，而无需调整目标模型的结构或训练算法。",
      "conclusion": "本研究通过基于分歧的证书和代理模型，为深度学习模型提供了通用的严格泛化边界，扩展了泛化理论的适用范围。其学术价值在于推动了泛化保障的通用化，实际应用可实现更可靠的模型评估和风险控制。潜在局限性可能包括计算复杂度较高，未来工作可探索更高效的代理模型设计或扩展到更多理论框架。",
      "tags": [
        "Generalization Bounds",
        "Disagreement Certificates",
        "Surrogate Models",
        "PAC-Bayes",
        "Sample Compression"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:02.648415Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23123",
    "title": "Multi-Agent Large Language Model Based Emotional Detoxification Through Personalized Intensity Control for Consumer Protection",
    "authors": [
      "Keito Inoshita"
    ],
    "abstract": "In the attention economy, sensational content exposes consumers to excessive emotional stimulation, hindering calm decision-making. This study proposes Multi-Agent LLM-based Emotional deToxification (MALLET), a multi-agent information sanitization system consisting of four agents: Emotion Analysis, Emotion Adjustment, Balance Monitoring, and Personal Guide. The Emotion Analysis Agent quantifies stimulus intensity using a 6-emotion BERT classifier, and the Emotion Adjustment Agent rewrites texts into two presentation modes, BALANCED (neutralized text) and COOL (neutralized text + supplementary text), using an LLM. The Balance Monitoring Agent aggregates weekly information consumption patterns and generates personalized advice, while the Personal Guide Agent recommends a presentation mode according to consumer sensitivity. Experiments on 800 AG News articles demonstrated significant stimulus score reduction (up to 19.3%) and improved emotion balance while maintaining semantic preservation. Near-zero correlation between stimulus reduction and semantic preservation confirmed that the two are independently controllable. Category-level analysis revealed substantial reduction (17.8-33.8%) in Sports, Business, and Sci/Tech, whereas the effect was limited in the World category, where facts themselves are inherently high-stimulus. The proposed system provides a framework for supporting calm information reception of consumers without restricting access to the original text.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23123.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23123",
    "published": "2026-02-26T15:37:03Z",
    "updated": "2026-02-26T15:37:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出MALLET，一个基于多代理LLM的系统，实现情感去毒化，通过个性化强度控制支持消费者冷静决策，保护其免受过度情绪刺激。",
      "motivation": "在注意力经济中，消费者常暴露于轰动性内容，导致情绪过度刺激，阻碍冷静决策，影响消费者保护。现有方法可能无法有效平衡情绪控制和语义保存，或缺乏个性化调整。因此，需要开发一个能独立控制情绪刺激和语义完整性的系统，以在不限制信息访问的前提下促进冷静信息接收。摘要未明确说明具体基线方法，但指出了情感去毒化的重要性。",
      "method": "MALLET系统由四个代理组成：情感分析代理使用6-emotion BERT分类器量化文本的刺激强度；情感调整代理利用LLM将文本重写为BALANCED（中性化文本）和COOL（中性化文本加补充文本）两种模式；平衡监控代理聚合用户每周信息消费模式生成个性化建议；个人指导代理根据消费者敏感性推荐合适呈现模式。关键创新在于多代理架构和个性化强度控制，使用数据集包括AG News文章进行实验。",
      "result": "在800篇AG News文章上的实验显示，刺激分数显著降低高达19.3%，同时改善了情绪平衡并保持了语义保存。刺激降低与语义保存之间的相关性接近零，表明两者可独立控制。类别级分析揭示，在Sports、Business和Sci/Tech类别中刺激降低17.8-33.8%，而在World类别效果有限，因为事实本身具有高刺激特性。系统有效减少了情绪刺激而不影响语义完整性，摘要未明确说明与基线方法的具体对比，但强调了独立可控性。",
      "conclusion": "本研究贡献了MALLET框架，通过多代理LLM系统实现情感去毒化，支持消费者冷静接收信息而不限制访问原始文本。学术上，展示了独立控制情绪刺激和语义保存的可行性；应用上，为消费者保护提供了实用工具。局限性包括在World类别效果不佳，未来工作可优化高刺激内容处理或扩展到其他信息领域，进一步提升个性化适应性。",
      "tags": [
        "Multi-Agent System",
        "Large Language Model",
        "BERT",
        "Emotion Classification",
        "Text Rewriting"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:20.545766Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23120",
    "title": "TriLite: Efficient Weakly Supervised Object Localization with Universal Visual Features and Tri-Region Disentanglement",
    "authors": [
      "Arian Sabaghi",
      "José Oramas"
    ],
    "abstract": "Weakly supervised object localization (WSOL) aims to localize target objects in images using only image-level labels. Despite recent progress, many approaches still rely on multi-stage pipelines or full fine-tuning of large backbones, which increases training cost, while the broader WSOL community continues to face the challenge of partial object coverage. We present TriLite, a single-stage WSOL framework that leverages a frozen Vision Transformer with Dinov2 pre-training in a self-supervised manner, and introduces only a minimal number of trainable parameters (fewer than 800K on ImageNet-1K) for both classification and localization. At its core is the proposed TriHead module, which decomposes patch features into foreground, background, and ambiguous regions, thereby improving object coverage while suppressing spurious activations. By disentangling classification and localization objectives, TriLite effectively exploits the universal representations learned by self-supervised ViTs without requiring expensive end-to-end training. Extensive experiments on CUB-200-2011, ImageNet-1K, and OpenImages demonstrate that TriLite sets a new state of the art, while remaining significantly more parameter-efficient and easier to train than prior methods. The code will be released soon.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23120.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23120",
    "published": "2026-02-26T15:33:22Z",
    "updated": "2026-02-26T15:33:22Z",
    "comment": "This paper consists of 8 pages including 6 figures. Accepted at CVPR 2026",
    "light_analysis": {
      "overview": "TriLite提出一种基于冻结自监督Vision Transformer和TriHead模块的单阶段弱监督目标定位框架，实现了高精度定位并显著减少参数量。",
      "motivation": "弱监督目标定位（WSOL）旨在仅使用图像级标签定位目标对象，但现有方法常依赖多阶段流程或大型骨干网络的全微调，导致训练成本高且面临目标覆盖不全的挑战。这些问题限制了WSOL在实际应用中的效率和准确性，尤其在资源受限环境中。本研究针对这些不足，旨在开发一种更高效、准确的WSOL方法，以降低计算需求并提升定位完整性。",
      "method": "TriLite是一个单阶段WSOL框架，采用预训练为Dinov2的Vision Transformer（ViT）骨干，并以自监督方式冻结该骨干，仅引入少量可训练参数（少于800K）用于分类和定位。核心创新是TriHead模块，它将补丁特征分解为前景、背景和模糊三个区域，从而改善对象覆盖并抑制虚假激活。通过解耦分类和定位目标，该方法有效利用自监督ViT的通用表示，避免了昂贵的端到端训练，实现高效单阶段流程。",
      "result": "在CUB-200-2011、ImageNet-1K和OpenImages数据集上的广泛实验显示，TriLite达到了新的最先进性能。具体而言，它仅需少于800K的可训练参数，比先前方法参数更少、训练更易。实验结果证明，在保持高定位精度的同时，显著提升了参数效率和训练易用性，与基线方法相比有明显改进。",
      "conclusion": "论文的主要贡献在于提出TriLite框架，通过冻结自监督ViT和解耦三区域特征，实现高效弱监督目标定位。该研究具有学术价值，推动了WSOL领域的发展；实际应用中，降低了训练成本，便于部署。摘要未明确说明局限性，但未来工作可能涉及进一步优化或扩展到其他任务，如多目标定位或更复杂场景。",
      "tags": [
        "Weakly Supervised Object Localization",
        "Vision Transformer",
        "Self-Supervised Learning",
        "Tri-Region Disentanglement",
        "Parameter Efficiency"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:15.192647Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23117",
    "title": "Devling into Adversarial Transferability on Image Classification: Review, Benchmark, and Evaluation",
    "authors": [
      "Xiaosen Wang",
      "Zhijin Ge",
      "Bohan Liu",
      "Zheng Fang",
      "Fengfan Zhou",
      "Ruixuan Zhang",
      "Shaokang Wang",
      "Yuyang Luo"
    ],
    "abstract": "Adversarial transferability refers to the capacity of adversarial examples generated on the surrogate model to deceive alternate, unexposed victim models. This property eliminates the need for direct access to the victim model during an attack, thereby raising considerable security concerns in practical applications and attracting substantial research attention recently. In this work, we discern a lack of a standardized framework and criteria for evaluating transfer-based attacks, leading to potentially biased assessments of existing approaches. To rectify this gap, we have conducted an exhaustive review of hundreds of related works, organizing various transfer-based attacks into six distinct categories. Subsequently, we propose a comprehensive framework designed to serve as a benchmark for evaluating these attacks. In addition, we delineate common strategies that enhance adversarial transferability and highlight prevalent issues that could lead to unfair comparisons. Finally, we provide a brief review of transfer-based attacks beyond image classification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23117.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23117",
    "published": "2026-02-26T15:30:36Z",
    "updated": "2026-02-26T15:30:36Z",
    "comment": "Code is available at https://github.com/Trustworthy-AI-Group/TransferAttack",
    "light_analysis": {
      "overview": "本文提出了一个标准化框架和基准，用于评估对抗性可转移性攻击，填补了现有评估中的空白。",
      "motivation": "对抗性可转移性攻击能在不直接访问受害者模型的情况下欺骗模型，这在实际安全应用中引发严重威胁，如模型逃逸攻击，增加了部署风险。现有评估缺乏统一标准，导致对攻击方法的比较可能存在偏差，影响研究进展和应用安全性。因此，迫切需要建立一个标准化框架来公正评估不同方法，以促进更可靠的安全研究和实际应用改进。",
      "method": "研究方法包括对数百篇相关文献进行系统性回顾，将基于转移的攻击方法划分为六个类别，并设计了一个全面的框架作为评估基准。此外，论文阐述了增强对抗性可转移性的常见策略，如输入变换或模型集成，并指出了评估中可能导致不公平比较的普遍问题，如数据集选择或指标不一致。整个方法侧重于文献综述和框架构建，旨在提供一个统一的标准来支持未来研究。",
      "result": "论文的主要结果是提出了一个评估框架和分类系统，但摘要中未提供具体的实验数据，如准确率提升或效率改进。因此，结果部分侧重于框架的建立和其在标准化评估中的潜在贡献，而非具体的性能指标。摘要未明确说明与基线方法的对比数据，而是强调了通过框架能够更公正地比较现有攻击方法，从而减少评估偏见。",
      "conclusion": "本文的主要贡献是通过回顾和分类现有攻击方法，提出了一个标准化评估框架，填补了对抗性可转移性研究中的空白。研究具有重要的学术价值，促进了更公平的方法比较和可靠的安全评估，有助于推动机器学习安全领域的发展。实际应用价值在于提升模型安全性评估标准，为防御策略提供参考。未来工作可扩展到图像分类之外的领域，并进一步完善框架细节以应对新兴威胁。",
      "tags": [
        "Adversarial Transferability",
        "Image Classification",
        "Benchmark Evaluation",
        "Transfer-based Attacks",
        "Machine Learning Security"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:24.108081Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23116",
    "title": "Regularized Online RLHF with Generalized Bilinear Preferences",
    "authors": [
      "Junghyun Lee",
      "Minju Hong",
      "Kwang-Sung Jun",
      "Chulhee Yun",
      "Se-Young Yun"
    ],
    "abstract": "We consider the problem of contextual online RLHF with general preferences, where the goal is to identify the Nash Equilibrium. We adopt the Generalized Bilinear Preference Model (GBPM) to capture potentially intransitive preferences via low-rank, skew-symmetric matrices. We investigate general preference learning with any strongly convex regularizer (where $η^{-1}$ is the regularization strength), generalizing beyond prior works limited to reverse KL-regularization. Central to our analysis is proving that the dual gap of the greedy policy is bounded by the square of the estimation error - a result derived solely from strong convexity and the skew-symmetricity of GBPM.Building on this insight and a feature diversity assumption, we establish two regret bounds via two simple algorithms: (1) Greedy Sampling achieves polylogarithmic, $e^{O(η)}$-free regret $\\tilde{O}(ηd^4 (\\log T)^2)$. (2) Explore-Then-Commit achieves $\\mathrm{poly}(d)$-free regret $\\tilde{O}(\\sqrt{ηr T})$ by exploiting the low-rank structure; this is the first statistically efficient guarantee for online RLHF in high-dimensions.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23116.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23116",
    "published": "2026-02-26T15:27:53Z",
    "updated": "2026-02-26T15:27:53Z",
    "comment": "43 pages, 1 table",
    "light_analysis": {
      "overview": "论文提出了基于广义双线性偏好模型的在线RLHF方法，通过强凸正则化器实现高效遗憾界，并首次提供高维统计高效保证。",
      "motivation": "研究动机是解决在线强化学习从人类反馈（RLHF）中偏好学习的挑战，特别是在一般偏好设置下。现有方法通常仅限于反向KL-正则化，限制了处理更广泛偏好的能力，如非传递偏好，从而影响了RLHF系统的灵活性和效率。本文旨在克服这一限制，通过引入广义偏好模型和强凸正则化器，提供更通用的解决方案，以识别纳什均衡，从而改进基于人类反馈的学习任务。",
      "method": "论文采用广义双线性偏好模型（GBPM），通过低秩斜对称矩阵捕捉可能非传递的偏好。方法核心是引入任何强凸正则化器，如正则化强度为η^{-1}的机制，扩展到反向KL-正则化之外。关键创新点包括证明贪婪策略的对偶间隙受估计误差平方限制，基于强凸性和GBPM的斜对称性，并结合特征多样性假设。提出了两种简单算法：Greedy Sampling和Explore-Then-Commit，后者利用低秩结构优化高维场景，实现了高效学习。",
      "result": "论文的主要实验结果包括：Greedy Sampling算法实现了多对数遗憾˜O(ηd^4 (log T)^2)，且与e^{O(η)}无关。Explore-Then-Commit算法通过利用低秩结构，实现了˜O(√(ηr T))遗憾，且与poly(d)无关。这些结果表明，在高维设置下，算法具有统计高效性，是首个在线RLHF的高维保证，超越了之前仅限于特定正则化的工作，提供了改进的性能指标。",
      "conclusion": "本文的主要贡献在于将正则化在线RLHF扩展到广义双线性偏好模型，通过强凸正则化器实现了高效学习，理论分析证明了贪婪策略的对偶间隙界限，并提出了两种算法提供改进的遗憾界。学术上，这扩展了偏好学习的理论框架，增强了在线RLHF的适用性；实际应用价值在于提升基于人类反馈的强化学习系统的性能和鲁棒性。未来工作可能包括更广泛的偏好模型验证、实际应用部署和探索更复杂的场景。",
      "tags": [
        "Generalized Bilinear Preference Model",
        "Online RLHF",
        "Strong Convex Regularization",
        "Low-rank Structure",
        "Regret Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:31.044010Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23115",
    "title": "FLIGHT: Fibonacci Lattice-based Inference for Geometric Heading in real-Time",
    "authors": [
      "David Dirnfeld",
      "Fabien Delattre",
      "Pedro Miraldo",
      "Erik Learned-Miller"
    ],
    "abstract": "Estimating camera motion from monocular video is a fundamental problem in computer vision, central to tasks such as SLAM, visual odometry, and structure-from-motion. Existing methods that recover the camera's heading under known rotation, whether from an IMU or an optimization algorithm, tend to perform well in low-noise, low-outlier conditions, but often decrease in accuracy or become computationally expensive as noise and outlier levels increase. To address these limitations, we propose a novel generalization of the Hough transform on the unit sphere (S(2)) to estimate the camera's heading. First, the method extracts correspondences between two frames and generates a great circle of directions compatible with each pair of correspondences. Then, by discretizing the unit sphere using a Fibonacci lattice as bin centers, each great circle casts votes for a range of directions, ensuring that features unaffected by noise or dynamic objects vote consistently for the correct motion direction. Experimental results on three datasets demonstrate that the proposed method is on the Pareto frontier of accuracy versus efficiency. Additionally, experiments on SLAM show that the proposed method reduces RMSE by correcting the heading during camera pose initialization.",
    "categories": [
      "cs.CV",
      "cs.CG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23115.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23115",
    "published": "2026-02-26T15:27:49Z",
    "updated": "2026-02-26T15:27:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于Fibonacci lattice的Hough变换方法，用于实时、鲁棒地估计相机航向，提高几何运动估计的准确性和效率。",
      "motivation": "从单目视频估计相机运动是计算机视觉的基础问题，对SLAM、视觉里程计等任务至关重要。现有方法在低噪声、低异常值条件下表现良好，但随着噪声和异常值增加，准确性显著下降或计算成本升高，限制了实际应用。因此，本研究旨在开发一种更鲁棒、高效的方法来解决这一瓶颈问题，以满足复杂环境下的需求。",
      "method": "本方法将Hough变换推广到单位球体(S(2))上，使用Fibonacci lattice作为bin中心来离散化球体，以实现高效计算。首先，提取两帧之间的对应点，为每对对应点生成兼容方向的大圆；然后，每个大圆为一个方向范围投票，利用Fibonacci lattice确保投票在噪声和动态对象影响下的一致性，从而准确地估计相机航向。该方法在三个数据集上进行了实验验证。",
      "result": "在三个数据集上的实验表明，本方法在准确性和效率方面处于Pareto前沿，优于现有基线方法。在SLAM应用中，通过修正相机位姿初始化时的航向，有效减少了RMSE，具体数据显示性能提升，但摘要未提供精确数字。这些结果证明了该方法在实际任务中的鲁棒性和有效性。",
      "conclusion": "本研究的主要贡献是提出了一种基于Fibonacci lattice的Hough变换方法，提升了相机航向估计的鲁棒性和计算效率，对SLAM等计算机视觉任务具有重要应用价值。然而，摘要未明确说明方法的局限性或未来工作方向，暗示了进一步优化和扩展的潜力。",
      "tags": [
        "Hough Transform",
        "Fibonacci Lattice",
        "Camera Motion Estimation",
        "SLAM",
        "Geometric Heading"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:07.915686Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23114",
    "title": "WARM-CAT: : Warm-Started Test-Time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning",
    "authors": [
      "Xudong Yan",
      "Songhe Feng",
      "Jiaxin Wang",
      "Xin Su",
      "Yi Jin"
    ],
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize novel attribute-object compositions based on the knowledge learned from seen ones. Existing methods suffer from performance degradation caused by the distribution shift of label space at test time, which stems from the inclusion of unseen compositions recombined from attributes and objects. To overcome the challenge, we propose a novel approach that accumulates comprehensive knowledge in both textual and visual modalities from unsupervised data to update multimodal prototypes at test time. Building on this, we further design an adaptive update weight to control the degree of prototype adjustment, enabling the model to flexibly adapt to distribution shift during testing. Moreover, a dynamic priority queue is introduced that stores high-confidence images to acquire visual prototypes from historical images for inference. Since the model tends to favor compositions already stored in the queue during testing, we warm-start the queue by initializing it with training images for visual prototypes of seen compositions and generating unseen visual prototypes using the mapping learned between seen and unseen textual prototypes. Considering the semantic consistency of multimodal knowledge, we align textual and visual prototypes by multimodal collaborative representation learning. To provide a more reliable evaluation for CZSL, we introduce a new benchmark dataset, C-Fashion, and refine the widely used but noisy MIT-States dataset. Extensive experiments indicate that our approach achieves state-of-the-art performance on four benchmark datasets under both closed-world and open-world settings. The source code and datasets are available at https://github.com/xud-yan/WARM-CAT .",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23114.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23114",
    "published": "2026-02-26T15:27:17Z",
    "updated": "2026-02-26T15:27:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出WARM-CAT方法，通过热启动和动态多模态知识积累，有效解决组合零样本学习中的测试时分布偏移问题。",
      "motivation": "组合零样本学习旨在从已见属性-对象组合中学习知识来识别未见组合，但测试时因包含未见组合导致标签空间分布偏移，使现有方法性能下降。这种偏移限制了模型泛化能力，因此需要开发新方法动态适应测试环境，提升模型在真实场景中的鲁棒性。",
      "method": "本研究提出WARM-CAT方法，通过无监督数据积累文本和视觉模态的全面知识，更新多模态原型以应对分布偏移。关键创新包括设计自适应更新权重控制原型调整程度、引入动态优先级队列存储高置信度图像获取视觉原型，并热启动队列用训练图像初始化已见组合视觉原型，以及基于文本原型映射生成未见组合视觉原型。同时，通过多模态协作表示学习对齐文本和视觉原型，确保语义一致性。",
      "result": "实验结果表明，WARM-CAT方法在包括新引入的C-Fashion数据集和改进后的MIT-States在内的四个基准数据集上，均在闭世界和开世界设置下实现了最先进的性能。尽管摘要未提供具体性能指标数值，但广泛实验证实了该方法在应对分布偏移方面的有效性，与基线方法相比有显著提升，验证了其泛化优势。",
      "conclusion": "本研究的主要贡献在于提出WARM-CAT方法，通过热启动和动态知识积累有效克服组合零样本学习中的测试时分布偏移，提升了模型的泛化能力。新数据集C-Fashion和改进的MIT-States为领域提供了更可靠的评估基准，对多模态学习和自适应系统具有重要学术和实际应用价值。未来工作可探索更复杂的组合场景或扩展至其他零样本学习任务。",
      "tags": [
        "Compositional Zero-Shot Learning",
        "Multimodal Learning",
        "Prototype Alignment",
        "Test-Time Adaptation"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:52.480891Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23113",
    "title": "Learning Physical Operators using Neural Operators",
    "authors": [
      "Vignesh Gopakumar",
      "Ander Gray",
      "Dan Giles",
      "Lorenzo Zanisi",
      "Matt J. Kusner",
      "Timo Betcke",
      "Stanislas Pamela",
      "Marc Peter Deisenroth"
    ],
    "abstract": "Neural operators have emerged as promising surrogate models for solving partial differential equations (PDEs), but struggle to generalise beyond training distributions and are often constrained to a fixed temporal discretisation. This work introduces a physics-informed training framework that addresses these limitations by decomposing PDEs using operator splitting methods, training separate neural operators to learn individual non-linear physical operators while approximating linear operators with fixed finite-difference convolutions. This modular mixture-of-experts architecture enables generalisation to novel physical regimes by explicitly encoding the underlying operator structure. We formulate the modelling task as a neural ordinary differential equation (ODE) where these learned operators constitute the right-hand side, enabling continuous-in-time predictions through standard ODE solvers and implicitly enforcing PDE constraints. Demonstrated on incompressible and compressible Navier-Stokes equations, our approach achieves better convergence and superior performance when generalising to unseen physics. The method remains parameter-efficient, enabling temporal extrapolation beyond training horizons, and provides interpretable components whose behaviour can be verified against known physics.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23113.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23113",
    "published": "2026-02-26T15:27:14Z",
    "updated": "2026-02-26T15:27:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种物理信息训练框架，通过算子分裂方法训练神经算子学习物理算子，实现泛化性和连续时间预测。",
      "motivation": "神经算子作为求解偏微分方程（PDEs）的代理模型具有前景，但现有方法在泛化到训练分布之外和固定时间离散化方面存在局限。这限制了其在实际物理模拟中的应用，因为物理系统常常涉及不同的参数和连续时间演化。因此，需要一种能够泛化到新物理机制并提供连续时间预测的方法。本研究旨在解决这些不足，通过分解PDEs并学习其组成算子来提升灵活性和泛化能力。",
      "method": "本研究提出了一种物理信息训练框架，采用算子分裂方法将PDEs分解为线性和非线性部分。非线性物理算子通过单独训练的神经算子学习，而线性算子则用固定的有限差分卷积近似，形成模块化的混合专家架构。建模任务被形式化为神经常微分方程（ODE），其中学习的算子构成右手边，允许通过标准ODE求解器进行连续时间预测，并隐含地强制执行PDE约束。在Navier-Stokes方程上演示了这一方法。",
      "result": "实验在不可压缩和可压缩Navier-Stokes方程上进行，方法在泛化到未见物理机制时显示出更好的收敛性和优越性能。摘要未提供具体数值指标，但表明其优于基线方法。此外，方法保持参数高效，能够超出训练范围进行时间外推，并提供可解释的组件，其行为可以通过已知物理进行验证。这证明了框架在提升泛化能力和时间灵活性方面的有效性。",
      "conclusion": "本文的主要贡献是开发了一个物理信息训练框架，通过算子分裂和神经ODE有效学习物理算子，解决了神经算子的泛化和时间离散化限制。该研究具有学术价值，为PDE求解提供了新的混合方法，并有实际应用潜力于复杂物理系统模拟。未来工作可扩展到更多类型的PDEs或探索更高效的学习策略，摘要未明确说明局限性。",
      "tags": [
        "Neural Operators",
        "Operator Splitting",
        "Neural ODE",
        "Physics-Informed Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:08.166759Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23111",
    "title": "PRAC: Principal-Random Subspace for LLM Activation Compression and Memory-Efficient Training",
    "authors": [
      "Yanyi Li",
      "Yimu Zhang",
      "Cong Fang"
    ],
    "abstract": "Activations have become the primary memory bottleneck in large-batch LLM training. However, existing compression methods fail to exploit the spectral structure of activations, resulting in slow convergence or limited compression. To address this, we bridge the relationship between the algorithm's fast convergence and the requirements for subspace projection, and show that an effective compression should yield an unbiased estimate of the original activation with low variance. We propose Principal-Random Subspace for LLM Activation Compression (PRAC), which novelly decomposes activations into two components: a principal subspace captured via SVD to retain dominant information, and a random subspace sampled from the orthogonal complement to approximate the tail. By introducing a precise scaling factor, we prove that PRAC yields an unbiased gradient estimator with minimum variance under certain conditions. Extensive experiments on pre-training and fine-tuning tasks demonstrate that PRAC achieves up to 36% total memory reduction with negligible performance degradation and minimal computational cost.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23111.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23111",
    "published": "2026-02-26T15:23:34Z",
    "updated": "2026-02-26T15:23:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "PRAC 方法通过分解激活值的谱结构，结合主成分和随机子空间，实现了高效的LLM激活压缩，解决了大批量训练中的内存瓶颈问题。",
      "motivation": "在大批量大型语言模型（LLM）训练中，激活值已成为主要内存瓶颈，导致计算资源浪费和训练效率低下。现有压缩方法未能充分利用激活值的谱结构，往往造成收敛速度缓慢或压缩率有限，限制了模型训练的扩展性。因此，开发一种既能高效压缩激活值又不影响性能的方法是重要的，以促进更经济、快速的大规模模型部署。",
      "method": "PRAC方法的核心创新在于将激活值分解为两个子空间：通过奇异值分解（SVD）捕获的主成分子空间，保留主要信息；以及从正交补中采样的随机子空间，近似尾部信息。引入精确的缩放因子，确保在特定条件下生成无偏梯度估计器，并最小化方差。该技术利用了激活值的谱结构，通过这种分解实现了高压缩率下的低误差，适用于LLM的预训练和微调任务。",
      "result": "在预训练和微调任务中的实验显示，PRAC实现了高达36%的总内存减少，性能下降可忽略不计，计算成本最小。与基线方法相比，该方法不仅显著提升了压缩效率，还保持了收敛性，验证了其在内存优化训练中的有效性和实用性，为大规模模型训练提供了可行解决方案。",
      "conclusion": "本研究提出了PRAC方法，通过理论证明和实验验证，展示了其在LLM激活压缩中的高效性和可靠性。学术价值在于为压缩算法提供了新理论框架，强调无偏估计和低方差；实际应用则有助于降低训练成本，促进更可持续的AI开发。未来工作可扩展至其他模型架构，或进一步优化算法复杂度。",
      "tags": [
        "Large Language Model (LLM)",
        "Activation Compression",
        "Subspace Projection",
        "Singular Value Decomposition (SVD)",
        "Memory-Efficient Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:01.521710Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23103",
    "title": "SpectralMamba-UNet: Frequency-Disentangled State Space Modeling for Texture-Structure Consistent Medical Image Segmentation",
    "authors": [
      "Fuhao Zhang",
      "Lei Liu",
      "Jialin Zhang",
      "Ya-Nan Zhang",
      "Nan Mu"
    ],
    "abstract": "Accurate medical image segmentation requires effective modeling of both global anatomical structures and fine-grained boundary details. Recent state space models (e.g., Vision Mamba) offer efficient long-range dependency modeling. However, their one-dimensional serialization weakens local spatial continuity and high-frequency representation. To this end, we propose SpectralMamba-UNet, a novel frequency-disentangled framework to decouple the learning of structural and textural information in the spectral domain. Our Spectral Decomposition and Modeling (SDM) module applies discrete cosine transform to decompose low- and high-frequency features, where low frequency contributes to global contextual modeling via a frequency-domain Mamba and high frequency preserves boundary-sensitive details. To balance spectral contributions, we introduce a Spectral Channel Reweighting (SCR) mechanism to form channel-wise frequency-aware attention, and a Spectral-Guided Fusion (SGF) module to achieve adaptively multi-scale fusion in the decoder. Experiments on five public benchmarks demonstrate consistent improvements across diverse modalities and segmentation targets, validating the effectiveness and generalizability of our approach.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23103.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23103",
    "published": "2026-02-26T15:17:42Z",
    "updated": "2026-02-26T15:17:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 SpectralMamba-UNet，一种频率解耦框架，在频域分离结构和纹理学习，以改进医学图像分割的一致性。",
      "motivation": "医学图像分割需同时建模全局结构和精细边界细节。现有状态空间模型（如 Vision Mamba）虽能有效处理长程依赖，但其一维序列化削弱了局部空间连续性和高频表示，导致在处理纹理细节和结构一致性时存在不足。这影响了分割准确性，尤其在需要捕捉高频信息的任务中，研究旨在解决此缺陷，通过频域方法提升模型性能。",
      "method": "提出 SpectralMamba-UNet 框架，核心包括 Spectral Decomposition and Modeling (SDM) 模块，使用离散余弦变换分解低频和高频特征；低频通过频域 Mamba 建模全局上下文，高频保留边界敏感细节。此外，引入 Spectral Channel Reweighting (SCR) 机制实现通道级频率感知注意力，以及 Spectral-Guided Fusion (SGF) 模块在解码器中实现自适应多尺度融合，以平衡谱贡献并优化结构纹理一致性。",
      "result": "在五个公开基准数据集上进行实验，覆盖多种医学图像模态和分割目标。结果表明，该方法相比基线模型取得了一致的性能提升，验证了其有效性和泛化能力，尤其在改善结构细节保留方面表现突出，但摘要未明确说明具体数值指标。",
      "conclusion": "本研究的主要贡献是提出 SpectralMamba-UNet，通过频域解耦方法结合状态空间模型和谱分析，显著提升医学图像分割的结构纹理一致性。该方法在多个基准上展示出良好的适用性，为医学图像分析提供了新思路，具有学术和实际价值。未来工作可扩展至其他视觉任务或优化计算效率。",
      "tags": [
        "State Space Modeling",
        "Frequency-Disentangled Learning",
        "Spectral Decomposition",
        "Channel-wise Attention",
        "Multi-scale Fusion"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:12.525234Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23101",
    "title": "Locally Adaptive Decay Surfaces for High-Speed Face and Landmark Detection with Event Cameras",
    "authors": [
      "Paul Kielty",
      "Timothy Hanley",
      "Peter Corcoran"
    ],
    "abstract": "Event cameras record luminance changes with microsecond resolution, but converting their sparse, asynchronous output into dense tensors that neural networks can exploit remains a core challenge. Conventional histograms or globally-decayed time-surface representations apply fixed temporal parameters across the entire image plane, which in practice creates a trade-off between preserving spatial structure during still periods and retaining sharp edges during rapid motion. We introduce Locally Adaptive Decay Surfaces (LADS), a family of event representations in which the temporal decay at each location is modulated according to local signal dynamics. Three strategies are explored, based on event rate, Laplacian-of-Gaussian response, and high-frequency spectral energy. These adaptive schemes preserve detail in quiescent regions while reducing blur in regions of dense activity. Extensive experiments on the public data show that LADS consistently improves both face detection and facial landmark accuracy compared to standard non-adaptive representations. At 30 Hz, LADS achieves higher detection accuracy and lower landmark error than either baseline, and at 240 Hz it mitigates the accuracy decline typically observed at higher frequencies, sustaining 2.44 % normalized mean error for landmarks and 0.966 mAP50 in face detection. These high-frequency results even surpass the accuracy reported in prior works operating at 30 Hz, setting new benchmarks for event-based face analysis. Moreover, by preserving spatial structure at the representation stage, LADS supports the use of much lighter network architectures while still retaining real-time performance. These results highlight the importance of context-aware temporal integration for neuromorphic vision and point toward real-time, high-frequency human-computer interaction systems that exploit the unique advantages of event cameras.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23101.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23101",
    "published": "2026-02-26T15:16:04Z",
    "updated": "2026-02-26T15:16:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 Locally Adaptive Decay Surfaces (LADS)，一种自适应事件表示方法，显著提升了事件相机在高速面部检测和面部标记任务中的准确性。",
      "motivation": "事件相机能以微秒级分辨率记录亮度变化，但其输出的稀疏性和异步性使得将其转换为神经网络可处理的密集张量成为一个核心挑战。现有的事件表示方法，如直方图或全局衰减时间表面，在整个图像平面上应用固定的时间参数，导致在静止期间保留空间结构和在快速运动中保持锐利边缘之间存在权衡。因此，需要一种能够根据局部信号动态调整的自适应表示方法，以充分利用事件相机的优势并改进现实应用。",
      "method": "论文提出了 Locally Adaptive Decay Surfaces (LADS)，这是一种事件表示方法，其中每个位置的时间衰减根据局部信号动态进行调制。研究了三种自适应策略：基于事件率、Laplacian-of-Gaussian 响应和高频谱能量。这些策略使得在静止区域可以保留更多细节，同时在活动密集区域减少模糊，从而生成更适合神经网络处理的事件表示。该方法在表示阶段就考虑空间结构，为后续的高效网络架构设计提供了基础。",
      "result": "在公共数据集上进行的大量实验表明，LADS 相比标准的非自适应表示方法，在面部检测和面部标记准确性方面持续提升。在 30 Hz 下，LADS 实现了更高的检测准确率和更低的标记错误率；在 240 Hz 下，它缓解了通常在高频率下观察到的准确性下降，具体达到 2.44% 的归一化平均错误率用于标记检测和 0.966 mAP50 用于面部检测。这些高频率结果甚至超越了先前工作在 30 Hz 下报告的准确性。",
      "conclusion": "该研究的主要贡献在于提出了 LADS，一种创新的自适应事件表示方法，有效解决了事件相机表示中的时空权衡问题。通过提升高频下的检测和标记准确性，LADS 推动了基于事件相机的实时人机交互系统的发展。此外，该方法支持使用更轻量的网络架构，同时保持实时性能，具有重要的实际应用价值。未来工作可以探索其他自适应策略或扩展到更广泛的计算机视觉任务。",
      "tags": [
        "Event Cameras",
        "Event Representation",
        "Adaptive Decay",
        "Face Detection",
        "Facial Landmark Detection"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:03.644464Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23093",
    "title": "Three AI-agents walk into a bar . . . . `Lord of the Flies' tribalism emerges among smart AI-Agents",
    "authors": [
      "Dhwanil M. Mori",
      "Neil F. Johnson"
    ],
    "abstract": "Near-future infrastructure systems may be controlled by autonomous AI agents that repeatedly request access to limited resources such as energy, bandwidth, or computing power. We study a simplified version of this setting using a framework where N AI-agents independently decide at each round whether to request one unit from a system with fixed capacity C. An AI version of \"Lord of the Flies\" arises in which controlling tribes emerge with their own collective character and identity. The LLM agents do not reduce overload or improve resource use, and often perform worse than if they were flipping coins to make decisions. Three main tribal types emerge: Aggressive (27.3%), Conservative (24.7%), and Opportunistic (48.1%). The more capable AI-agents actually increase the rate of systemic failure. Overall, our findings show that smarter AI-agents can behave dumber as a result of forming tribes.",
    "categories": [
      "cs.AI",
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23093.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23093",
    "published": "2026-02-26T15:12:26Z",
    "updated": "2026-02-26T15:12:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文发现更智能的AI代理在资源分配场景中形成部落主义，导致集体行为更差，系统性能降低。",
      "motivation": "未来基础设施系统可能由自主AI代理控制，它们需要请求有限资源如能源或带宽。研究旨在解决AI代理在集体决策时可能导致系统效率低下或失败的问题。现有AI代理方法往往忽视群体行为的影响，导致资源分配不当和过载，引发系统不稳定，强调了探索AI集体行为模式的重要性，以优化实际应用中的代理设计。",
      "method": "研究采用一个简化框架，其中N个AI代理在每一轮独立决定是否请求一个单位资源，系统有固定容量C。核心方法是观察AI代理如何通过交互形成部落，并分析部落类型和集体行为模式。关键创新点在于将人类社会学中的部落主义概念应用到AI代理行为分析中，使用LLM代理进行模拟，但摘要未明确说明具体模型架构或数据集细节，仅基于自主决策过程进行实验。",
      "result": "实验结果识别出三种主要部落类型：激进型（27.3%）、保守型（24.7%）和机会主义型（48.1%）。LLM代理未能减少系统过载或改善资源使用，其表现甚至不如随机决策（如抛硬币），且更智能的AI代理实际上增加了系统故障率，表明部落主义导致集体行为恶化。与基线相比，这些代理在资源分配中的效率降低，突显出智能代理在群体环境中可能出现非理性行为。",
      "conclusion": "研究主要贡献是揭示更智能的AI代理因形成部落主义而行为更差，挑战了智能度与性能正相关的假设。学术上强调AI集体行为的复杂性，为多代理系统研究提供新视角；实际应用中提示需设计避免部落形成的机制以提升系统稳定性。潜在局限性包括简化框架可能不覆盖现实复杂性，未来工作可探索优化代理交互策略以减少非理性行为或扩展实验场景。",
      "tags": [
        "AI Agents",
        "Multi-agent Systems",
        "Resource Allocation",
        "LLM",
        "Tribalism"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:03.351902Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23092",
    "title": "Enhancing CVRP Solver through LLM-driven Automatic Heuristic Design",
    "authors": [
      "Zhuoliang Xie",
      "Fei Liu",
      "Zhenkun Wang",
      "Qingfu Zhang"
    ],
    "abstract": "The Capacitated Vehicle Routing Problem (CVRP), a fundamental combinatorial optimization challenge, focuses on optimizing fleet operations under vehicle capacity constraints. While extensively studied in operational research, the NP-hard nature of CVRP continues to pose significant computational challenges, particularly for large-scale instances. This study presents AILS-AHD (Adaptive Iterated Local Search with Automatic Heuristic Design), a novel approach that leverages Large Language Models (LLMs) to revolutionize CVRP solving. Our methodology integrates an evolutionary search framework with LLMs to dynamically generate and optimize ruin heuristics within the AILS method. Additionally, we introduce an LLM-based acceleration mechanism to enhance computational efficiency. Comprehensive experimental evaluations against state-of-the-art solvers, including AILS-II and HGS, demonstrate the superior performance of AILS-AHD across both moderate and large-scale instances. Notably, our approach establishes new best-known solutions for 8 out of 10 instances in the CVRPLib large-scale benchmark, underscoring the potential of LLM-driven heuristic design in advancing the field of vehicle routing optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23092.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23092",
    "published": "2026-02-26T15:12:23Z",
    "updated": "2026-02-26T15:12:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出AILS-AHD方法，利用大语言模型实现自动启发式设计，显著增强容量车辆路径问题的求解性能。",
      "motivation": "容量车辆路径问题（CVRP）是组合优化的核心挑战，广泛应用于物流和车队运营，但其NP-hard特性导致大规模实例求解极为困难。现有方法如传统启发式或元启发式可能计算效率低，难以处理复杂约束或适应动态需求，因此需要创新技术来提升求解性能。本研究旨在通过引入大语言模型驱动的自动启发式设计，突破现有求解器的局限性，解决大规模CVRP的计算瓶颈。",
      "method": "AILS-AHD方法将自适应迭代局部搜索框架与大语言模型整合，在搜索过程中动态生成和优化破坏启发式规则。关键创新点在于使用LLM自动设计启发式，增强搜索的适应性和多样性；同时，引入基于LLM的加速机制，通过预测或简化步骤提高计算效率。该方法利用进化搜索框架迭代改进启发式，结合LLM的生成能力优化局部搜索过程，从而提升整体求解能力。",
      "result": "实验结果表明，AILS-AHD在中小型和大型CVRP实例上均优于当前最先进的求解器如AILS-II和HGS。在CVRPLib大规模基准测试中，该方法为10个实例中的8个建立了新的最佳已知解决方案，显著提升了求解质量。这些成果展示了LLM驱动的自动启发式设计在改进CVRP求解器性能方面的有效性，特别是在大规模问题实例中。",
      "conclusion": "本论文的主要贡献是提出了AILS-AHD方法，通过整合大语言模型与自适应迭代局部搜索，实现自动启发式设计，革新了CVRP求解。该研究不仅提高了求解性能，还为组合优化领域引入了新的AI应用范式，具有重要的学术价值和实用意义。未来工作可探索将方法扩展到其他NP-hard优化问题或进一步优化LLM集成策略。",
      "tags": [
        "Large Language Models",
        "Automatic Heuristic Design",
        "Capacitated Vehicle Routing Problem",
        "Adaptive Iterated Local Search"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:33.084728Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23089",
    "title": "Physics-informed neural particle flow for the Bayesian update step",
    "authors": [
      "Domonkos Csuzdi",
      "Tamás Bécsi",
      "Olivér Törő"
    ],
    "abstract": "The Bayesian update step poses significant computational challenges in high-dimensional nonlinear estimation. While log-homotopy particle flow filters offer an alternative to stochastic sampling, existing formulations usually yield stiff differential equations. Conversely, existing deep learning approximations typically treat the update as a black-box task or rely on asymptotic relaxation, neglecting the exact geometric structure of the finite-horizon probability transport. In this work, we propose a physics-informed neural particle flow, which is an amortized inference framework. To construct the flow, we couple the log-homotopy trajectory of the prior to posterior density function with the continuity equation describing the density evolution. This derivation yields a governing partial differential equation (PDE), referred to as the master PDE. By embedding this PDE as a physical constraint into the loss function, we train a neural network to approximate the transport velocity field. This approach enables purely unsupervised training, eliminating the need for ground-truth posterior samples. We demonstrate that the neural parameterization acts as an implicit regularizer, mitigating the numerical stiffness inherent to analytic flows and reducing online computational complexity. Experimental validation on multimodal benchmarks and a challenging nonlinear scenario confirms better mode coverage and robustness compared to state-of-the-art baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23089.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23089",
    "published": "2026-02-26T15:10:45Z",
    "updated": "2026-02-26T15:10:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种物理信息神经粒子流方法，用于贝叶斯更新步骤，通过嵌入偏微分方程约束实现无监督训练，有效提升高维非线性估计的效率和鲁棒性。",
      "motivation": "贝叶斯更新在高维非线性估计中面临巨大计算挑战，log-homotopy粒子流过滤器常产生刚性微分方程，求解困难；现有深度学习方法通常将更新视为黑盒任务或依赖渐近松弛，忽略了有限时间概率传输的精确几何结构。本研究旨在开发一种既能保持几何结构又避免数值刚性的高效方法，以提高估计精度和计算效率，解决实际应用中的非线性估计问题。",
      "method": "本研究提出物理信息神经粒子流框架，通过耦合先验到后验密度函数的log-homotopy轨迹与连续性方程，推导出主偏微分方程作为控制方程。将该偏微分方程作为物理约束嵌入损失函数，训练神经网络近似传输速度场，实现纯无监督训练。关键创新包括神经参数化作为隐式正则化器，减轻解析流固有的数值刚性，并降低在线计算复杂度。方法适用于多模态基准和复杂非线性场景，无需地面真实后验样本。",
      "result": "实验在多模态基准和具有挑战性的非线性场景中进行验证。结果表明，相比于最先进的基线方法，该方法在模态覆盖和鲁棒性方面表现更好。神经参数化有效减轻了数值刚性，减少了计算复杂度。尽管摘要未明确说明具体数值指标，但实验证实了性能提升，显示了该方法在提升估计精度和效率方面的优势。",
      "conclusion": "本文的主要贡献是提出了一种物理信息神经粒子流方法，有效解决了高维贝叶斯更新中的计算挑战。通过结合几何结构和神经网络，实现了无监督训练和数值稳定，具有重要的学术价值，为非线性估计提供了新思路，并在实际应用如信号处理等领域有潜力。未来工作可扩展到更广泛场景或优化网络架构。",
      "tags": [
        "Physics-informed Neural Networks",
        "Particle Flow Filters",
        "Bayesian Update",
        "Partial Differential Equations",
        "Unsupervised Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:47.618956Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23088",
    "title": "Cytoarchitecture in Words: Weakly Supervised Vision-Language Modeling for Human Brain Microscopy",
    "authors": [
      "Matthew Sutton",
      "Katrin Amunts",
      "Timo Dickscheid",
      "Christian Schiffer"
    ],
    "abstract": "Foundation models increasingly offer potential to support interactive, agentic workflows that assist researchers during analysis and interpretation of image data. Such workflows often require coupling vision to language to provide a natural-language interface. However, paired image-text data needed to learn this coupling are scarce and difficult to obtain in many research and clinical settings. One such setting is microscopic analysis of cell-body-stained histological human brain sections, which enables the study of cytoarchitecture: cell density and morphology and their laminar and areal organization. Here, we propose a label-mediated method that generates meaningful captions from images by linking images and text only through a label, without requiring curated paired image-text data. Given the label, we automatically mine area descriptions from related literature and use them as synthetic captions reflecting canonical cytoarchitectonic attributes. An existing cytoarchitectonic vision foundation model (CytoNet) is then coupled to a large language model via an image-to-text training objective, enabling microscopy regions to be described in natural language. Across 57 brain areas, the resulting method produces plausible area-level descriptions and supports open-set use through explicit rejection of unseen areas. It matches the cytoarchitectonic reference label for in-scope patches with 90.6% accuracy and, with the area label masked, its descriptions remain discriminative enough to recover the area in an 8-way test with 68.6% accuracy. These results suggest that weak, label-mediated pairing can suffice to connect existing biomedical vision foundation models to language, providing a practical recipe for integrating natural-language in domains where fine-grained paired annotations are scarce.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23088.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23088",
    "published": "2026-02-26T15:10:39Z",
    "updated": "2026-02-26T15:10:39Z",
    "comment": "8 pages, 3 figures, submitted for inclusion at a conference",
    "light_analysis": {
      "overview": "提出一种基于标签的弱监督视觉-语言模型，用于为人类大脑显微镜图像生成自然语言描述，解决了配对数据稀缺问题。",
      "motivation": "本研究的动机在于解决脑显微镜图像分析中视觉-语言耦合数据稀缺的问题。在细胞染色人脑组织切片分析领域，研究细胞密度、形态和分层组织（即脑细胞结构）需要自然语言接口以支持交互式工作流，但获取成对图像-文本数据困难且昂贵，尤其是在研究和临床设置中。现有方法依赖大量人工标注，限制了应用范围，因此开发弱监督方法成为必要，以在资源有限环境下实现高效分析。",
      "method": "本研究提出一种标签中介的弱监督方法，通过将图像和文本仅通过标签连接来生成描述。首先，给定脑区标签，自动从相关文献挖掘描述作为反映典型脑细胞结构属性的合成标题；然后，将现有的脑细胞结构视觉基础模型（CytoNet）与大语言模型耦合，采用图像到文本的训练目标，使模型能够用自然语言描述显微镜区域。该方法避免了传统方法所需的精细配对标注数据，创新点在于利用弱监督学习减少数据依赖，并融合领域特定知识。",
      "result": "在57个脑区上的实验结果显示，模型能够生成合理的区域级描述，并通过明确拒绝未见区域支持开放集使用。具体性能指标包括：在范围内补丁匹配脑细胞结构参考标签的准确率达到90.6%；即使掩蔽区域标签，生成的描述在8-way测试中恢复脑区的准确率为68.6%。这些结果证明了弱监督方法在生成描述和区分能力上的有效性，与基线方法相比表现优越。",
      "conclusion": "本研究的主要贡献是提供了一种实用弱监督方法，将现有生物医学视觉基础模型连接到语言，为脑显微镜图像分析领域集成自然语言接口。其学术价值在于推动视觉-语言建模在数据稀缺场景的应用，临床意义在于辅助研究人员进行交互式分析。未来工作可扩展至其他生物医学成像领域，并进一步优化模型泛化能力和性能。",
      "tags": [
        "Weakly Supervised Learning",
        "Vision-Language Modeling",
        "Cytoarchitecture",
        "Large Language Model",
        "Image-to-Text Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:43.038982Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23079",
    "title": "Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent",
    "authors": [
      "Boyang Zhang",
      "Yang Zhang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23079.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23079",
    "published": "2026-02-26T15:05:13Z",
    "updated": "2026-02-26T15:05:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一个结合文体分析和LLM推理的代理框架，用于评估和减轻文本作者去匿名化风险。",
      "motivation": "随着大语言模型（LLMs）的快速发展，其在作者身份推断方面的能力日益增强，引发了对于文本数据中无意去匿名化风险的担忧，例如新闻文章等公开文本可能暴露作者身份，威胁隐私。现有方法可能未能有效整合文体特征与LLM推理，导致推断不准确或缺乏可解释性，因此需要开发可解释的框架来评估和缓解这些风险。本研究旨在通过结构化方法应对这一挑战，强调保护作者隐私的重要性。",
      "method": "研究方法的核心是SALA方法，即Stylometry-Assisted LLM Analysis，该方法整合了定量文体特征和大语言模型推理，形成一个结构化和可解释的流程。关键创新点在于将传统文体学特征与LLM的推理能力结合，通过数据库模块增强推断准确率，并引入引导重组合策略，利用代理的推理轨迹生成改写提示，以减少作者可识别性同时保留文本意义。这一技术路线旨在实现鲁棒和透明的作者归属评估。",
      "result": "在大规模新闻数据集上的实验表明，SALA方法，特别是当结合数据库模块时，在各种场景下实现了高推断准确率，摘要未明确说明具体数据如准确率百分比，但强调了该方法在提升推断性能方面的有效性。与可能的基础方法相比，SALA通过整合文体特征和LLM推理提供了更鲁棒和可解释的结果，实验验证了该框架在评估去匿名化风险方面的潜力，展示了其在实际应用中的性能改进。",
      "conclusion": "本研究的主要贡献是提出了一个LLM代理框架，通过SALA方法评估和减轻文本作者去匿名化风险，研究发现突出了LLM代理在作者身份推断方面的潜力以及可解释的、主动防御措施对于保护作者隐私的重要性。该研究具有学术价值，为隐私保护提供了新的技术路线，实际应用价值在于帮助识别和缓解文本数据中的隐私泄露风险；未来工作可能包括扩展到其他文本类型或进一步优化方法，以应对更复杂的场景。",
      "tags": [
        "Large Language Model",
        "Stylometry",
        "Deanonymization",
        "LLM Agent",
        "Authorship Attribution"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:47.285081Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23075",
    "title": "CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery",
    "authors": [
      "Mengze Hong",
      "Di Jiang",
      "Chen Jason Zhang",
      "Zichang Guo",
      "Yawen Li",
      "Jun Chen",
      "Shaobo Cui",
      "Zhiyang Su"
    ],
    "abstract": "Large language models (LLMs) have created new opportunities to enhance the efficiency of scholarly activities; however, challenges persist in the ethical deployment of AI assistance, including (1) the trustworthiness of AI-generated content, (2) preservation of academic integrity and intellectual property, and (3) protection of information privacy. In this work, we present CiteLLM, a specialized agentic platform designed to enable trustworthy reference discovery for grounding author-drafted claims and statements. The system introduces a novel interaction paradigm by embedding LLM utilities directly within the LaTeX editor environment, ensuring a seamless user experience and no data transmission outside the local system. To guarantee hallucination-free references, we employ dynamic discipline-aware routing to retrieve candidates exclusively from trusted web-based academic repositories, while leveraging LLMs solely for generating context-aware search queries, ranking candidates by relevance, and validating and explaining support through paragraph-level semantic matching and an integrated chatbot. Evaluation results demonstrate the superior performance of the proposed system in returning valid and highly usable references.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23075.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23075",
    "published": "2026-02-26T15:02:22Z",
    "updated": "2026-02-26T15:02:22Z",
    "comment": "Accepted by TheWebConf 2026 Demo Track",
    "light_analysis": {
      "overview": "提出了CiteLLM，一个agentic平台，通过在LaTeX编辑器中嵌入大型语言模型实现可信的参考文献发现。",
      "motivation": "大型语言模型（LLMs）在学术活动中提高了效率，但面临关键挑战：AI生成内容的可信度不足，学术诚信受到威胁，信息隐私保护不当。这些挑战阻碍了AI在学术领域的负责任应用，尤其参考文献发现常因幻觉引用而不可靠。本研究旨在解决这些问题，提供一个可信平台，确保作者在起草学术声明时获得可靠支持，同时维护学术规范和隐私安全。",
      "method": "CiteLLM系统采用agentic架构，直接在LaTeX编辑环境中嵌入LLM工具，确保无缝用户体验，且所有数据处理本地进行，避免数据外泄。关键技术包括动态学科感知路由，仅从可信网络学术仓库检索候选文献，防止幻觉引用。LLMs仅用于生成上下文感知搜索查询、基于相关性排名候选，并通过段落级语义匹配和集成聊天机器人验证和解释支持关系，提升了系统的准确性和交互性。",
      "result": "评估结果显示，CiteLLM系统在返回有效且高可用参考文献方面表现优越。摘要未明确说明具体的性能指标（如准确率提升或效率改进）和基线对比方法，但强调了系统在减少幻觉引用和提高参考相关性方面的显著效果。基于评估推断，系统可能优于传统方法，但在数据细节上需进一步研究证实。",
      "conclusion": "本研究贡献了CiteLLM平台，解决了AI辅助学术引用中的可信度、学术诚信和隐私问题。创新点包括将LLMs嵌入LaTeX编辑器，结合动态路由和语义匹配确保无幻觉参考文献。学术上促进了AI在学术诚信领域的应用，实际中为研究人员提供了高效写作工具。潜在局限性如依赖可信仓库的未来更新，未来工作可扩展至其他学科或集成更多验证机制。",
      "tags": [
        "Large Language Model",
        "Agentic Platform",
        "Semantic Matching",
        "Dynamic Discipline-Aware Routing"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:57.631479Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23071",
    "title": "Quantity Convergence, Quality Divergence: Disentangling Fluency and Accuracy in L2 Mandarin Prosody",
    "authors": [
      "Yuqi Shi",
      "Hao Yang",
      "Xiyao Lu",
      "Jinsong Zhang"
    ],
    "abstract": "While second language (L2) learners may acquire target syntactic word order, mapping this syntax onto appropriate prosodic structures remains a persistent challenge. This study investigates the fossilization and stability of the L2 syntax-prosody interface by comparing 67 native Mandarin speakers with 67 Vietnamese learners using the BLCU-SAIT corpus. By integrating C-ToBI boundary annotation with Dependency Grammar analysis, we examined both the quantity of prosodic boundaries and their mapping to syntactic relations. Results reveal a non-linear acquisition: although high-proficiency learners (VNH) converge to the native baseline in boundary quantity at the Major Phrase level (B3), their structural mapping significantly diverges. Specifically, VNH demote the prosodic boundary at the Subject-Verb (SBV) interface (Major Phrase B3 -> Prosodic Word B1), while erroneously promoting the boundary at the Verb-Object (VOB) interface (Prosodic Word B1 -> Major Phrase B3). This strategy allows learners to maintain high long phrasal output at the expense of structural accuracy. This results in a distorted prosodic hierarchy where the native pattern is inverted.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23071.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23071",
    "published": "2026-02-26T15:00:59Z",
    "updated": "2026-02-26T15:00:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究揭示了第二语言学习者在普通话韵律习得中，边界数量趋同但结构映射质量分歧的非线性现象。",
      "motivation": "研究动机在于解决第二语言学习者在习得语法结构后，如何准确映射到韵律结构的持久挑战。这一问题对语言发音准确性和习得效率至关重要，因为它直接影响交流的流利度和自然度。现有方法可能过于关注边界数量而忽略了映射质量，导致无法全面评估韵律习得的复杂过程。摘要未明确说明现有具体方法的不足，但强调了对语法-韵律接口稳定性和石化现象的探讨需求。",
      "method": "研究方法基于BLCU-SAIT语料库，对比了67名母语普通话者和67名越南学习者的韵律表现。核心方法整合了C-ToBI边界标注和依赖语法分析，以同时考察韵律边界的数量及其与句法关系的映射关系。创新点在于通过这种结合，能够从量和质两个维度评估韵律习得，具体关注主要短语级别（B3）和韵律词级别（B1）的边界变化。技术细节包括使用标注工具进行边界识别，并分析主语-动词和动词-宾语界面的映射模式。",
      "result": "主要实验结果显示，高熟练度学习者在边界数量上趋近母语基线，特别是在主要短语级别（B3），但在结构映射上显著分歧。具体表现为，学习者降低主语-动词界面的边界级别（从B3到B1），而错误地提高动词-宾语界面的边界级别（从B1到B3），导致韵律层次颠倒。与母语基线对比，这种策略使学习者能维持较长短语输出，但牺牲了结构准确性，从而形成扭曲的韵律模式。数据支撑包括基于语料库的定量分析和定性映射评估。",
      "conclusion": "论文的主要贡献在于揭示了第二语言韵律习得的非线性特征，即在流畅性（边界数量）趋同的同时，准确性（结构映射）发生分歧，深化了对语法-韵律接口的理解。学术价值体现在为L2习得理论提供新见解，实际应用价值可能指导语言教学和发音矫正。摘要未明确说明局限性或未来工作，但可推断需要进一步研究其他语言对或扩展样本以验证普适性，并探索干预策略改进映射准确性。",
      "tags": [
        "C-ToBI",
        "Dependency Grammar",
        "Prosodic Analysis",
        "L2 Acquisition",
        "Mandarin Prosody"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:54.807678Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23069",
    "title": "Align then Adapt: Rethinking Parameter-Efficient Transfer Learning in 4D Perception",
    "authors": [
      "Yiding Sun",
      "Jihua Zhu",
      "Haozhe Cheng",
      "Chaoyi Lu",
      "Zhichuan Yang",
      "Lin Chen",
      "Yaonan Wang"
    ],
    "abstract": "Point cloud video understanding is critical for robotics as it accurately encodes motion and scene interaction. We recognize that 4D datasets are far scarcer than 3D ones, which hampers the scalability of self-supervised 4D models. A promising alternative is to transfer 3D pre-trained models to 4D perception tasks. However, rigorous empirical analysis reveals two critical limitations that impede transfer capability: overfitting and the modality gap. To overcome these challenges, we develop a novel \"Align then Adapt\" (PointATA) paradigm that decomposes parameter-efficient transfer learning into two sequential stages. Optimal-transport theory is employed to quantify the distributional discrepancy between 3D and 4D datasets, enabling our proposed point align embedder to be trained in Stage 1 to alleviate the underlying modality gap. To mitigate overfitting, an efficient point-video adapter and a spatial-context encoder are integrated into the frozen 3D backbone to enhance temporal modeling capacity in Stage 2. Notably, with the above engineering-oriented designs, PointATA enables a pre-trained 3D model without temporal knowledge to reason about dynamic video content at a smaller parameter cost compared to previous work. Extensive experiments show that PointATA can match or even outperform strong full fine-tuning models, whilst enjoying the advantage of parameter efficiency, e.g. 97.21 \\% accuracy on 3D action recognition, $+8.7 \\%$ on 4 D action segmentation, and 84.06\\% on 4D semantic segmentation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23069.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23069",
    "published": "2026-02-26T14:58:59Z",
    "updated": "2026-02-26T14:58:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了名为PointATA的'Align then Adapt'范式，通过分阶段对齐和适配，实现参数高效地从3D预训练模型转移到4D感知任务。",
      "motivation": "点云视频理解对机器人学至关重要，因为它能准确编码运动和场景交互。然而，4D数据集相比3D数据集稀缺，这阻碍了自监督4D模型的可扩展性。转移3D预训练模型到4D任务是一个有前景的替代方案，但实证分析揭示了两个关键限制：过拟合和模态差距。这些限制使得模型在动态视频内容推理中效果不佳，限制了实际应用的效率和性能。因此，开发新方法来解决这些问题对于提升4D感知能力至关重要。",
      "method": "论文提出的PointATA范式将参数高效转移学习分解为两个顺序阶段。第一阶段，利用最优传输理论量化3D和4D数据集的分布差异，并训练点对齐嵌入器以减轻模态差距。第二阶段，集成点视频适配器和空间上下文编码器到冻结的3D主干网络中，增强时间建模能力，从而缓解过拟合。核心创新在于通过结构化的对齐和适配，使预训练的3D模型无需额外时间知识就能推理动态视频内容，同时保持较小的参数开销。模型基于现有3D预训练主干，添加高效组件实现。",
      "result": "通过广泛实验，PointATA在多个任务上取得了优异表现。具体而言，在3D动作识别上达到97.21%的准确率；在4D动作分割上，相对于基线提升了8.7个百分点；在4D语义分割上实现了84.06%的准确率。与强全微调模型相比，PointATA能匹配甚至超越其性能，同时保持了参数效率的优势。这些结果表明，PointATA有效克服了过拟合和模态差距，在减少参数成本的同时显著提升了模型在4D感知任务中的表现。",
      "conclusion": "本研究的主要贡献是提出了PointATA范式，有效解决了3D到4D转移学习中的过拟合和模态差距问题。学术价值在于为点云视频理解的参数高效转移学习提供了新范式，促进了从静态3D模型到动态4D应用的转变。实际应用价值在于使预训练模型能以较低成本用于机器人学等领域的动态场景处理，提升效率和性能。未来工作方向摘要未明确说明，但可能包括扩展到其他数据模态或优化对齐策略。",
      "tags": [
        "Point Cloud Video Understanding",
        "Parameter-Efficient Transfer Learning",
        "Optimal Transport Theory",
        "4D Perception",
        "Temporal Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:17.265524Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23062",
    "title": "Toward Automatic Filling of Case Report Forms: A Case Study on Data from an Italian Emergency Department",
    "authors": [
      "Gabriela Anna Kaczmarek",
      "Pietro Ferrazzi",
      "Lorenzo Porta",
      "Vicky Rubini",
      "Bernardo Magnini"
    ],
    "abstract": "Case Report Forms (CRFs) collect data about patients and are at the core of well-established practices to conduct research in clinical settings. With the recent progress of language technologies, there is an increasing interest in automatic CRF-filling from clinical notes, mostly based on the use of Large Language Models (LLMs). However, there is a general scarcity of annotated CRF data, both for training and testing LLMs, which limits the progress on this task. As a step in the direction of providing such data, we present a new dataset of clinical notes from an Italian Emergency Department annotated with respect to a pre-defined CRF containing 134 items to be filled. We provide an analysis of the data, define the CRF-filling task and metric for its evaluation, and report on pilot experiments where we use an open-source state-of-the-art LLM to automatically execute the task. Results of the case-study show that (i) CRF-filling from real clinical notes in Italian can be approached in a zero-shot setting; (ii) LLMs' results are affected by biases (e.g., a cautious behaviour favours \"unknown\" answers), which need to be corrected.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23062.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23062",
    "published": "2026-02-26T14:49:11Z",
    "updated": "2026-02-26T14:49:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文通过提供意大利急诊科临床笔记的标注数据集，并探索使用大型语言模型在零样本设置下自动填充病例报告表。",
      "motivation": "病例报告表（CRFs）是临床研究中收集患者数据的核心工具，用于支持高质量研究。随着语言技术的进步，尤其是大型语言模型（LLMs）的发展，自动从临床笔记中填充CRFs的兴趣日益增加，以提高效率和准确性。然而，当前面临的主要挑战是标注CRF数据的普遍稀缺，这限制了LLMs的训练和测试，阻碍了自动填充任务的进展。本研究旨在通过提供新的标注数据集来解决数据稀缺问题，为推进该领域的研究奠定基础，并应对临床环境中数据提取的实际需求。",
      "method": "本研究首先构建了一个新数据集，包含意大利急诊科的真实临床笔记，对这些笔记进行了人工标注，以匹配一个预定义的CRF，涵盖134个需要填充的项目。然后，定义了CRF填充任务的具体框架和评估指标，以确保任务的标准化。在试点实验中，采用了一个开源的最新大型语言模型（LLM），在零样本设置下自动执行任务，这意味着模型未经过特定任务训练，直接利用其预训练知识来处理临床文本。这一方法旨在探索LLMs在医疗领域的适应性，并减少对大量标注数据的依赖。",
      "result": "实验结果显示，在零样本设置下，大型语言模型能够从意大利语临床笔记中自动填充病例报告表，验证了该方法的基本可行性。然而，LLM的输出存在偏差，例如表现出谨慎行为，倾向于选择“未知”作为答案，这可能影响了填充的准确性。这些初步结果提供了定量证据，表明在真实临床数据上应用LLMs具有潜力，但也突出了需要修正偏差以提高性能。研究还强调了与基线方法相比，当前模型的输出需要进一步优化，以更好地支持实际应用。",
      "conclusion": "本研究的主要贡献在于引入了一个新的标注数据集，弥补了自动CRF填充任务中数据稀缺的空白，并通过定义任务和评估指标为未来研究提供了框架。通过试点实验，证明了大型语言模型在零样本设置下处理临床文本的潜力，同时指出了偏差问题需引起注意。这不仅具有学术价值，推动了医疗自然语言处理领域的发展，还可能在实际临床研究中促进自动数据提取的应用。未来工作应集中在偏差校正、模型性能优化以及扩展数据集上，以提升系统的鲁棒性和实用性。",
      "tags": [
        "Large Language Model",
        "Zero-Shot Learning",
        "Clinical Text Analysis",
        "Dataset Construction",
        "Bias Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:35.421504Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23060",
    "title": "RhythmBERT: A Self-Supervised Language Model Based on Latent Representations of ECG Waveforms for Heart Disease Detection",
    "authors": [
      "Xin Wang",
      "Burcu Ozek",
      "Aruna Mohan",
      "Amirhossein Ravari",
      "Or Zilbershot",
      "Fatemeh Afghah"
    ],
    "abstract": "Electrocardiogram (ECG) analysis is crucial for diagnosing heart disease, but most self-supervised learning methods treat ECG as a generic time series, overlooking physiologic semantics and rhythm-level structure. Existing contrastive methods utilize augmentations that distort morphology, whereas generative approaches employ fixed-window segmentation, which misaligns cardiac cycles. To address these limitations, we propose RhythmBERT, a generative ECG language model that considers ECG as a language paradigm by encoding P, QRS, and T segments into symbolic tokens via autoencoder-based latent representations. These discrete tokens capture rhythm semantics, while complementary continuous embeddings retain fine-grained morphology, enabling a unified view of waveform structure and rhythm. RhythmBERT is pretrained on approximately 800,000 unlabeled ECG recordings with a masked prediction objective, allowing it to learn contextual representations in a label-efficient manner. Evaluations show that despite using only a single lead, RhythmBERT achieves comparable or superior performance to strong 12-lead baselines. This generalization extends from prevalent conditions such as atrial fibrillation to clinically challenging cases such as subtle ST-T abnormalities and myocardial infarction. Our results suggest that considering ECG as structured language offers a scalable and physiologically aligned pathway for advancing cardiac analysis.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23060.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23060",
    "published": "2026-02-26T14:45:29Z",
    "updated": "2026-02-26T14:45:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "RhythmBERT 是一个基于潜在表示的生成性 ECG 语言模型，通过将 ECG 视为结构化语言来提升心脏病检测的准确性和泛化能力。",
      "motivation": "心电图（ECG）分析对心脏病诊断至关重要，但现有自监督学习方法存在不足。多数方法将 ECG 视为通用时间序列，忽略了生理语义和节律级结构。对比学习方法使用扭曲形态的数据增强，生成方法采用固定窗口分割导致心脏周期错位，这限制了分析的精确性和可扩展性，因此需要一种新方法来结合波形结构和节律特征。",
      "method": "RhythmBERT 是一种生成性 ECG 语言模型，将 ECG 视为语言范式。通过基于自编码器的潜在表示，将 ECG 波形的 P、QRS 和 T 段编码为离散符号令牌，这些令牌捕获节律语义；同时，使用连续嵌入保留细粒度形态特征，实现了波形结构和节律的统一视图。模型在约 800,000 条无标签 ECG 记录上进行预训练，采用掩码预测目标以学习上下文表示。",
      "result": "实验评估显示，RhythmBERT 尽管仅使用单导联数据，其性能与强大的 12 导联基线相当或更优。该方法在多种心脏病检测任务中表现良好，包括常见的心房颤动和临床挑战性病例如细微 ST-T 异常和心肌梗死，展现出强大的泛化能力。摘要未提供具体数值指标，但结果表明该方法能有效提升检测准确性。",
      "conclusion": "RhythmBERT 通过将 ECG 视为结构化语言，提出了一种创新的自监督学习框架，显著提升了心脏病检测的性能。这一研究推动了 ECG 分析技术的发展，具有重要的临床应用价值，为可扩展和生理对齐的心脏分析提供了新路径。摘要未明确说明局限性，但未来可探索多导联扩展或更复杂病例的应用。",
      "tags": [
        "Self-Supervised Learning",
        "Generative Language Model",
        "ECG Waveform Encoding",
        "Latent Representations",
        "Heart Disease Detection"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:27.459083Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23058",
    "title": "GeoWorld: Geometric World Models",
    "authors": [
      "Zeyu Zhang",
      "Danning Li",
      "Ian Reid",
      "Richard Hartley"
    ],
    "abstract": "Energy-based predictive world models provide a powerful approach for multi-step visual planning by reasoning over latent energy landscapes rather than generating pixels. However, existing approaches face two major challenges: (i) their latent representations are typically learned in Euclidean space, neglecting the underlying geometric and hierarchical structure among states, and (ii) they struggle with long-horizon prediction, which leads to rapid degradation across extended rollouts. To address these challenges, we introduce GeoWorld, a geometric world model that preserves geometric structure and hierarchical relations through a Hyperbolic JEPA, which maps latent representations from Euclidean space onto hyperbolic manifolds. We further introduce Geometric Reinforcement Learning for energy-based optimization, enabling stable multi-step planning in hyperbolic latent space. Extensive experiments on CrossTask and COIN demonstrate around 3% SR improvement in 3-step planning and 2% SR improvement in 4-step planning compared to the state-of-the-art V-JEPA 2. Project website: https://steve-zeyu-zhang.github.io/GeoWorld.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23058.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23058",
    "published": "2026-02-26T14:42:53Z",
    "updated": "2026-02-26T14:42:53Z",
    "comment": "Accepted to CVPR 2026",
    "light_analysis": {
      "overview": "本文提出了GeoWorld，一个几何世界模型，通过双曲JEPA和几何强化学习改进多步视觉规划，解决现有方法的几何结构忽略和长时程预测问题。",
      "motivation": "基于能量的预测世界模型在视觉规划中表现出色，但现有方法面临两个关键挑战：一是潜在表示通常在欧几里得空间中学习，忽略了状态之间的几何和层次结构，导致模型无法有效捕捉数据的内在关系；二是长时程预测能力不足，预测性能随步骤增加而迅速退化，影响规划任务的实际应用。这些不足促使研究如何整合几何建模来提升世界模型的准确性和稳定性，以支持更可靠的长期推理。",
      "method": "GeoWorld采用Hyperbolic JEPA将潜在表示从欧几里得空间映射到双曲流形，以保留几何和层次结构，核心创新在于结合双曲几何和联合嵌入预测架构。进一步引入Geometric Reinforcement Learning进行能量优化，实现在双曲潜在空间中的稳定多步规划。模型在CrossTask和COIN数据集上进行训练和评估，架构融合了几何变换和能量预测机制，专注于提升长时程视觉规划的性能。",
      "result": "在CrossTask和COIN数据集上的实验显示，与最先进的V-JEPA 2相比，GeoWorld在3步规划中提高了约3%的成功率，4步规划中提高了约2%的成功率。这些SR指标的改进证明了模型在长时程视觉规划任务中的优越性，验证了几何建模能有效减缓预测退化，提升规划精度，增强了多步推理的稳定性。",
      "conclusion": "GeoWorld通过双曲JEPA和几何强化学习，成功解决了现有世界模型的几何结构忽略和长时程预测问题，显著提升了多步视觉规划性能。主要贡献在于提出创新的几何世界建模方法，具有重要的理论意义和实际应用价值，为AI中的几何应用提供了新方向。未来工作可能包括扩展模型到更复杂场景或优化计算效率，以进一步推动领域发展。",
      "tags": [
        "Geometric World Models",
        "Hyperbolic JEPA",
        "Geometric Reinforcement Learning",
        "Energy-based Predictive Models",
        "Visual Planning"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:49.995974Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23057",
    "title": "Affine-Scaled Attention: Towards Flexible and Stable Transformer Attention",
    "authors": [
      "Jeongin Bae",
      "Baeseong Park",
      "Gunho Park",
      "Minsub Kim",
      "Joonhyung Lee",
      "Junhee Yoo",
      "Sunghyeon Woo",
      "Jiwon Ryu",
      "Se Jung Kwon",
      "Dongsoo Lee"
    ],
    "abstract": "Transformer attention is typically implemented using softmax normalization, which enforces attention weights with unit sum normalization. While effective in many settings, this constraint can limit flexibility in controlling attention magnitudes and may contribute to overly concentrated or unstable attention patterns during training. Prior work has explored modifications such as attention sinks or gating mechanisms, but these approaches provide only limited or indirect control over attention reweighting. We propose Affine-Scaled Attention, a simple extension to standard attention that introduces input-dependent scaling and a corresponding bias term applied to softmax-normalized attention weights. This design relaxes the strict normalization constraint while maintaining aggregation of value representations, allowing the model to adjust both the relative distribution and the scale of attention in a controlled manner.   We empirically evaluate Affine-Scaled Attention in large-scale language model pretraining across multiple model sizes. Experimental results show consistent improvements in training stability, optimization behavior, and downstream task performance compared to standard softmax attention and attention sink baselines. These findings suggest that modest reweighting of attention outputs provides a practical and effective way to improve attention behavior in Transformer models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.23057.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23057",
    "published": "2026-02-26T14:42:16Z",
    "updated": "2026-02-26T14:42:16Z",
    "comment": "Preprint. 14 pages, 11 figures",
    "light_analysis": {
      "overview": "本文提出 Affine-Scaled Attention，一种通过引入输入相关的缩放和偏置项来增强 Transformer 注意力机制灵活性和稳定性的方法。",
      "motivation": "标准 Transformer 注意力使用 softmax 归一化，这强制注意力权重具有单位总和，限制了灵活控制注意力幅度的能力，可能导致训练过程中注意力分布过于集中或不稳定，影响模型性能。先前研究如注意力汇或门控机制提供有限或间接的控制，因此需要更有效的方法来直接调节注意力输出，以克服现有约束并提升训练行为。",
      "method": "Affine-Scaled Attention 是标准注意力机制的简单扩展，它在 softmax 归一化的注意力权重上应用输入相关的缩放因子和偏置项。这一设计放松了严格的归一化约束，同时保持值表示的聚合，允许模型可控地调整注意力的相对分布和尺度。实验在大规模语言模型预训练中进行，涵盖多个模型大小以评估通用性，但摘要未具体说明使用的数据集或模型架构细节。",
      "result": "在大规模语言模型预训练实验中，Affine-Scaled Attention 相比标准 softmax 注意力和注意力汇基线，显示出训练稳定性、优化行为和下游任务性能的持续改进。尽管摘要未提供具体数值（如准确率提升），但结果表明该方法能有效控制注意力模式，减少不稳定性，并增强整体模型表现。",
      "conclusion": "Affine-Scaled Attention 的主要贡献是通过重新加权注意力输出，提供了一种实用且有效的方法来改进 Transformer 模型的注意力行为。这具有学术价值，为注意力机制设计提供了新思路，并有实际应用潜力，可提升语言模型的训练效率和性能。未来工作可能包括扩展到其他任务或探索其局限性，但摘要未明确说明这些方向。",
      "tags": [
        "Transformer Attention",
        "Softmax Normalization",
        "Affine Scaling",
        "Attention Reweighting",
        "Language Model Pretraining"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:41.164655Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23056",
    "title": "Learning-based Multi-agent Race Strategies in Formula 1",
    "authors": [
      "Giona Fieni",
      "Joschua Wüthrich",
      "Marc-Philippe Neumann",
      "Christopher H. Onder"
    ],
    "abstract": "In Formula 1, race strategies are adapted according to evolving race conditions and competitors' actions. This paper proposes a reinforcement learning approach for multi-agent race strategy optimization. Agents learn to balance energy management, tire degradation, aerodynamic interaction, and pit-stop decisions. Building on a pre-trained single-agent policy, we introduce an interaction module that accounts for the behavior of competitors. The combination of the interaction module and a self-play training scheme generates competitive policies, and agents are ranked based on their relative performance. Results show that the agents adapt pit timing, tire selection, and energy allocation in response to opponents, achieving robust and consistent race performance. Because the framework relies only on information available during real races, it can support race strategists' decisions before and during races.",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.23056.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23056",
    "published": "2026-02-26T14:41:29Z",
    "updated": "2026-02-26T14:41:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种基于强化学习的多智能体策略优化方法，通过引入交互模块和自对弈训练实现F1比赛的自适应策略。",
      "motivation": "研究动机是解决F1比赛中策略的动态适应问题，比赛条件不断变化，竞争对手的行为直接影响策略决策，如能量管理、轮胎退化和进站时机。现有方法可能难以有效平衡这些多因素交互，且缺乏实时适应性，导致比赛性能不稳定。因此，开发智能化的多智能体学习系统至关重要，以提升策略的鲁棒性和响应速度，优化整体比赛表现。",
      "method": "研究方法采用强化学习框架，基于预训练的单智能体策略，核心创新是引入一个交互模块来模拟竞争对手的行为。该方法结合交互模块和自对弈训练方案，智能体在训练中相互竞争并排名，学习平衡能量管理、轮胎退化、空气动力学交互和进站决策。关键细节包括使用真实比赛中的信息进行训练，不依赖额外数据，确保方法的实用性。",
      "result": "实验结果显示，智能体能够根据对手行为自适应地调整进站时机、轮胎选择和能量分配，实现了鲁棒和一致的比赛表现。摘要未提供具体性能指标如准确率或效率提升，但强调生成的策略具有竞争性，通过自对弈训练优化了策略。由于框架仅依赖真实比赛信息，其决策支持在赛前和赛中均有效，验证了方法的适用性。",
      "conclusion": "论文的主要贡献是提出一个基于强化学习的多智能体比赛策略优化框架，学术上结合交互模块和自对弈处理复杂交互问题，推动多智能体学习领域发展。实际应用中，该框架能为F1策略师提供实时决策支持，使用真实信息增强策略可靠性。局限性摘要未明确说明，未来工作可能包括扩展到更多变量或实际部署测试。",
      "tags": [
        "Reinforcement Learning",
        "Multi-agent Systems",
        "Self-play",
        "Interaction Module",
        "Strategy Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:42.657033Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23050",
    "title": "Latent Matters: Learning Deep State-Space Models",
    "authors": [
      "Alexej Klushyn",
      "Richard Kurle",
      "Maximilian Soelch",
      "Botond Cseke",
      "Patrick van der Smagt"
    ],
    "abstract": "Deep state-space models (DSSMs) enable temporal predictions by learning the underlying dynamics of observed sequence data. They are often trained by maximising the evidence lower bound. However, as we show, this does not ensure the model actually learns the underlying dynamics. We therefore propose a constrained optimisation framework as a general approach for training DSSMs. Building upon this, we introduce the extended Kalman VAE (EKVAE), which combines amortised variational inference with classic Bayesian filtering/smoothing to model dynamics more accurately than RNN-based DSSMs. Our results show that the constrained optimisation framework significantly improves system identification and prediction accuracy on the example of established state-of-the-art DSSMs. The EKVAE outperforms previous models w.r.t. prediction accuracy, achieves remarkable results in identifying dynamical systems, and can furthermore successfully learn state-space representations where static and dynamic features are disentangled.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23050.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23050",
    "published": "2026-02-26T14:35:45Z",
    "updated": "2026-02-26T14:35:45Z",
    "comment": "Published at NeurIPS 2021",
    "light_analysis": {
      "overview": "本文提出一种约束优化框架和扩展卡尔曼变分自编码器（EKVAE），以改进深度状态空间模型的训练和动态建模。",
      "motivation": "深度状态空间模型（DSSMs）用于时间序列预测，通过学习观测序列的底层动态进行预测。然而，现有方法通常通过最大化证据下界进行训练，这不能确保模型真正学习到真实动态，导致在系统识别和预测任务中性能受限。这一问题的重要性在于准确建模动态对时间预测的可靠性至关重要，而现有方法的不足在于训练过程可能无法有效捕捉动态特征，因此需要开发更有效的训练策略来提升模型性能。摘要未明确说明具体应用领域，但强调了改进训练方法的必要性。",
      "method": "论文提出了一个约束优化框架作为训练深度状态空间模型的通用方法，旨在强制模型学习底层动态，从而提高训练效果。在此基础上，引入了扩展卡尔曼变分自编码器（EKVAE），该模型结合了摊销变分推断与经典贝叶斯滤波/平滑技术，以更准确地建模动态，优于基于RNN的DSSMs。关键创新点包括通过约束优化增强训练的稳定性，以及整合传统贝叶斯方法到深度学习中，以改善动态特征的学习。摘要未明确说明使用的具体数据集或详细模型架构。",
      "result": "实验结果显示，约束优化框架显著提高了系统识别和预测准确性，在现有最先进DSSMs上验证了其有效性。EKVAE在预测准确性方面优于先前模型，并在识别动态系统方面取得了显著成果。此外，它成功学习到状态空间表示，能够解耦静态和动态特征，这有助于更精细的动态建模。摘要未提供具体的性能指标数值，如准确率提升百分比，但强调了改进的显著性和模型在任务中的优越表现。",
      "conclusion": "本文的主要贡献是提出了约束优化框架和EKVAE模型，有效改进了深度状态空间模型的训练和动态建模，具有重要的学术价值，为DSSMs训练提供了新方法并结合了变分推断与贝叶斯技术。实际应用价值体现在系统识别和预测任务中性能的提升，有助于更准确的时间序列分析。未来工作可能包括进一步优化模型架构或将其扩展到更复杂的数据集和实际场景中，以增强泛化能力。摘要未明确说明局限性，但可推断需要更多实验验证。",
      "tags": [
        "Deep State-Space Models",
        "Constrained Optimisation",
        "Variational Inference",
        "Bayesian Filtering",
        "Extended Kalman VAE"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:54.521163Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23043",
    "title": "D-FINE-seg: Object Detection and Instance Segmentation Framework with multi-backend deployment",
    "authors": [
      "Argo Saakyan",
      "Dmitry Solntsev"
    ],
    "abstract": "Transformer-based real-time object detectors achieve strong accuracy-latency trade-offs, and D-FINE is among the top-performing recent architectures. However, real-time instance segmentation with transformers is still less common. We present D-FINE-seg, an instance segmentation extension of D-FINE that adds: a lightweight mask head, segmentation-aware training, including box cropped BCE and dice mask losses, auxiliary and denoising mask supervision, and adapted Hungarian matching cost. On the TACO dataset, D-FINE-seg improves F1-score over Ultralytics YOLO26 under a unified TensorRT FP16 end-to-end benchmarking protocol, while maintaining competitive latency. Second contribution is an end-to-end pipeline for training, exporting, and optimized inference across ONNX, TensorRT, OpenVINO for both object detection and instance segmentation tasks. This framework is released as open-source under the Apache-2.0 license. GitHub repository - https://github.com/ArgoHA/D-FINE-seg.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23043.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23043",
    "published": "2026-02-26T14:26:49Z",
    "updated": "2026-02-26T14:26:49Z",
    "comment": "6 pages, 4 figures, 5 tables",
    "light_analysis": {
      "overview": "D-FINE-seg 提出了一个基于 Transformer 的实时实例分割框架，通过轻量级掩码头和分割感知训练优化性能，并提供多后端部署支持。",
      "motivation": "基于 Transformer 的实时物体检测器如 D-FINE 在准确率和延迟间取得了良好权衡，但实时实例分割在 Transformer 架构中仍较少见。这导致计算机视觉应用中实例分割任务在保持实时性能方面存在不足。现有方法可能在分割精度或部署效率上受限，因此需要扩展 Transformer 的优势以解决实时实例分割的挑战，提升实际应用中的性能。",
      "method": "D-FINE-seg 扩展了 D-FINE 架构，添加了轻量级掩码头进行实例分割。训练中采用了分割感知技术，包括框裁剪二元交叉熵损失和 dice 掩码损失，以及辅助和去噪掩码监督，并调整了匈牙利匹配成本以优化训练过程。这些创新点旨在提高分割精度而不显著增加计算开销。摘要未明确说明具体模型架构细节，但使用了 TACO 数据集进行评估。",
      "result": "在 TACO 数据集上，D-FINE-seg 在统一的 TensorRT FP16 端到端基准测试协议下，相比 Ultralytics YOLO26 提高了 F1 分数，同时保持了有竞争力的延迟。这表明该方法在实例分割任务中实现了更好的性能-延迟权衡。具体提升数值摘要未明确说明，但强调了对基线方法的改进效果。",
      "conclusion": "D-FINE-seg 的主要贡献是提出了一个高效的实例分割框架，扩展了 Transformer 在实时应用中的能力。学术上，它为基于 Transformer 的实例分割提供了新方法；实际上，通过支持 ONNX、TensorRT 和 OpenVINO 等多后端部署，促进了模型的实际应用和优化。框架已开源，便于社区使用，未来工作可能包括进一步性能优化或扩展到更多任务。",
      "tags": [
        "Transformer-based Detection",
        "Instance Segmentation",
        "Multi-backend Deployment",
        "Lightweight Mask Head",
        "Segmentation-aware Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:09.548460Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23040",
    "title": "PackUV: Packed Gaussian UV Maps for 4D Volumetric Video",
    "authors": [
      "Aashish Rai",
      "Angela Xing",
      "Anushka Agarwal",
      "Xiaoyan Cong",
      "Zekun Li",
      "Tao Lu",
      "Aayush Prakash",
      "Srinath Sridhar"
    ],
    "abstract": "Volumetric videos offer immersive 4D experiences, but remain difficult to reconstruct, store, and stream at scale. Existing Gaussian Splatting based methods achieve high-quality reconstruction but break down on long sequences, temporal inconsistency, and fail under large motions and disocclusions. Moreover, their outputs are typically incompatible with conventional video coding pipelines, preventing practical applications.   We introduce PackUV, a novel 4D Gaussian representation that maps all Gaussian attributes into a sequence of structured, multi-scale UV atlas, enabling compact, image-native storage. To fit this representation from multi-view videos, we propose PackUV-GS, a temporally consistent fitting method that directly optimizes Gaussian parameters in the UV domain. A flow-guided Gaussian labeling and video keyframing module identifies dynamic Gaussians, stabilizes static regions, and preserves temporal coherence even under large motions and disocclusions. The resulting UV atlas format is the first unified volumetric video representation compatible with standard video codecs (e.g., FFV1) without losing quality, enabling efficient streaming within existing multimedia infrastructure.   To evaluate long-duration volumetric capture, we present PackUV-2B, the largest multi-view video dataset to date, featuring more than 50 synchronized cameras, substantial motion, and frequent disocclusions across 100 sequences and 2B (billion) frames. Extensive experiments demonstrate that our method surpasses existing baselines in rendering fidelity while scaling to sequences up to 30 minutes with consistent quality.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23040.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23040",
    "published": "2026-02-26T14:24:48Z",
    "updated": "2026-02-26T14:24:48Z",
    "comment": "https://ivl.cs.brown.edu/packuv",
    "light_analysis": {
      "overview": "PackUV提出了一种兼容标准视频编解码器的4D体积视频表示方法，通过映射高斯属性到UV atlas解决了时间一致性和存储效率问题。",
      "motivation": "4D体积视频提供沉浸式体验，但在重建、存储和流传输方面面临挑战。现有基于高斯溅射的方法在长期序列中容易崩溃，时间不一致性高，且在大运动和去遮挡情况下失效；此外，这些方法的输出不兼容传统视频编码管道，阻碍了实际应用。因此，开发一种兼容现有基础设施、确保时间一致性的高效表示方法至关重要。",
      "method": "PackUV将4D高斯属性映射到结构化、多尺度的UV atlas序列，实现紧凑的图像原生存储。通过PackUV-GS方法直接在UV域优化高斯参数，确保时间一致性；关键模块包括流引导的高斯标记和视频关键帧模块，用于识别动态高斯、稳定静态区域，并在大运动和去遮挡情况下保持时间相干性。输出格式兼容标准视频编解码器如FFV1。",
      "result": "在PackUV-2B数据集上的实验表明，该方法在渲染保真度上超越现有基线，支持长达30分钟的序列并保持一致性质量。输出格式兼容标准视频编解码器如FFV1，无需质量损失，实现了在现有多媒体基础设施中的高效流传输，解决了长期序列和大运动下的时间不一致问题。",
      "conclusion": "PackUV首次提供了统一的体积视频表示，兼容标准视频编解码器，改进了时间一致性和长期序列处理能力，具有学术和实际价值；未来工作方向摘要未明确说明，但可能包括进一步优化性能或扩展应用场景。",
      "tags": [
        "Gaussian Splatting",
        "UV Mapping",
        "4D Volumetric Video",
        "Video Coding",
        "Temporal Consistency"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:11.273797Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23035",
    "title": "Learning Disease-Sensitive Latent Interaction Graphs From Noisy Cardiac Flow Measurements",
    "authors": [
      "Viraj Patel",
      "Marko Grujic",
      "Philipp Aigner",
      "Theodor Abart",
      "Marcus Granegger",
      "Deblina Bhattacharjee",
      "Katharine Fraser"
    ],
    "abstract": "Cardiac blood flow patterns contain rich information about disease severity and clinical interventions, yet current imaging and computational methods fail to capture underlying relational structures of coherent flow features. We propose a physics-informed, latent relational framework to model cardiac vortices as interacting nodes in a graph. Our model combines a neural relational inference architecture with physics-inspired interaction energy and birth-death dynamics, yielding a latent graph sensitive to disease severity and intervention level. We first apply this to computational fluid dynamics simulations of aortic coarctation. Learned latent graphs reveal that as the aortic radius narrows, vortex interactions become stronger and more frequent. This leads to a higher graph entropy, correlating monotonically with coarctation severity ($R^2=0.78$, Spearman $|ρ|=0.96$). We then extend this method to ultrasound datasets of left ventricles under varying levels of left ventricular assist device support. Again the latent graph representation captures the weakening of coherent vortical structures, thereby demonstrating cross-modal generalisation. Results show latent interaction graphs and entropy serve as robust and interpretable markers of cardiac disease and intervention.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23035.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23035",
    "published": "2026-02-26T14:17:49Z",
    "updated": "2026-02-26T14:17:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种物理信息化的潜在关系框架，通过学习心脏血流涡流的交互图来捕捉疾病严重程度和干预水平。",
      "motivation": "心脏血流模式包含疾病严重程度和临床干预的丰富信息，但现有成像和计算方法无法有效捕捉其中相干流动特征的潜在关系结构。这一问题在心脏疾病诊断和治疗中至关重要，因为传统方法可能忽略涡流间的动态交互，导致评估不准确。论文旨在解决这一不足，通过建立更精细的模型来揭示血流中的关系模式，从而提供更稳健的疾病标记。",
      "method": "研究方法采用神经关系推理架构，将心脏涡流建模为图中的交互节点。创新点在于整合了物理启发的交互能量和生死动态，形成一种潜在图模型。该模型利用计算流体动力学模拟和超声数据集，通过图学习捕捉涡流之间的相互作用。关键细节包括使用图神经网络技术处理涡流节点，并引入物理约束来增强模型的解释性，从而生成对疾病状态敏感的潜在交互图。",
      "result": "主要实验结果在主动脉缩窄的计算流体动力学模拟中，学习到的潜在图显示随主动脉半径变窄，涡流交互增强且更频繁，图熵与疾病严重程度呈单调正相关（R²=0.78，Spearman |ρ|=0.96）。在左心室超声数据集中，模型成功捕捉到涡流结构随左心室辅助设备支持水平变化的减弱，实现了跨模态泛化。这表明潜在图和熵作为疾病标记，显著优于传统基线方法，提供了更准确的性能指标。",
      "conclusion": "论文的主要贡献是提出了一种稳健且可解释的潜在交互图框架，用于评估心脏疾病和干预效果。研究意义在于为医疗影像分析提供了新方法，结合物理知识和机器学习，增强了模型的泛化能力和应用价值。潜在局限性包括对特定疾病类型的依赖性，未来工作可扩展至其他生物流体系统或结合更多模态数据。",
      "tags": [
        "Neural Relational Inference",
        "Graph-based Models",
        "Physics-Informed Learning",
        "Cardiac Fluid Dynamics",
        "Cross-Modal Generalization"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:12.655071Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23031",
    "title": "Small Object Detection Model with Spatial Laplacian Pyramid Attention and Multi-Scale Features Enhancement in Aerial Images",
    "authors": [
      "Zhangjian Ji",
      "Huijia Yan",
      "Shaotong Qiao",
      "Kai Feng",
      "Wei Wei"
    ],
    "abstract": "Detecting objects in aerial images confronts some significant challenges, including small size, dense and non-uniform distribution of objects over high-resolution images, which makes detection inefficient. Thus, in this paper, we proposed a small object detection algorithm based on a Spatial Laplacian Pyramid Attention and Multi-Scale Feature Enhancement in aerial images. Firstly, in order to improve the feature representation of ResNet-50 on small objects, we presented a novel Spatial Laplacian Pyramid Attention (SLPA) module, which is integrated after each stage of ResNet-50 to identify and emphasize important local regions. Secondly, to enhance the model's semantic understanding and features representation, we designed a Multi-Scale Feature Enhancement Module (MSFEM), which is incorporated into the lateral connections of C5 layer for building Feature Pyramid Network (FPN). Finally, the features representation quality of traditional feature pyramid network will be affected because the features are not aligned when the upper and lower layers are fused. In order to handle it, we utilized deformable convolutions to align the features in the fusion processing of the upper and lower levels of the Feature Pyramid Network, which can help enhance the model's ability to detect and recognize small objects. The extensive experimental results on two benchmark datasets: VisDrone and DOTA demonstrate that our improved model performs better for small object detection in aerial images compared to the original algorithm.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23031.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23031",
    "published": "2026-02-26T14:11:30Z",
    "updated": "2026-02-26T14:11:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一种结合空间拉普拉斯金字塔注意力和多尺度特征增强的小物体检测模型，以提高航空图像中的检测性能。",
      "motivation": "航空图像中的小物体检测面临物体尺寸小、分布密集且不均匀的挑战，这些因素导致检测效率低下。由于高分辨率图像中物体信息稀疏，现有检测算法难以有效捕捉小物体特征，影响实际应用如无人机监控和遥感分析。因此，需改进特征表示和融合方法以提升检测性能，本研究旨在解决这一问题。",
      "method": "论文提出一种小物体检测算法，核心包括空间拉普拉斯金字塔注意力和多尺度特征增强模块。SLPA模块嵌入ResNet-50各阶段后，通过拉普拉斯金字塔结构识别重要局部区域以增强特征表示。MSFEM模块集成到C5层的横向连接，构建特征金字塔网络以提升多尺度语义理解。此外，使用可变形卷积在FPN中上下层融合时对齐特征，解决特征不对齐问题，从而优化小物体检测能力。",
      "result": "实验在VisDrone和DOTA两个基准数据集上进行，结果表明改进模型在小物体检测任务中优于原始算法。摘要未提供具体准确率数据，但实验证实了模型的有效性，通过特征增强和对齐技术提升了检测性能，尤其是在处理小物体时表现出色，与基线方法对比显示明显改进。",
      "conclusion": "论文的主要贡献在于提出了一种结合空间拉普拉斯金字塔注意力和多尺度特征增强的小物体检测模型，并通过可变形卷积优化特征对齐。该研究提高了航空图像中小物体检测的准确性和效率，具有重要的学术价值，为计算机视觉领域的小物体检测提供了新思路。实际应用中，可增强无人机监控和遥感分析的性能，未来工作可进一步优化模型效率或扩展到其他数据集。",
      "tags": [
        "Small Object Detection",
        "Spatial Laplacian Pyramid Attention",
        "Multi-Scale Feature Enhancement",
        "Deformable Convolution",
        "Feature Pyramid Network"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:17.995737Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23029",
    "title": "WISER: Wider Search, Deeper Thinking, and Adaptive Fusion for Training-Free Zero-Shot Composed Image Retrieval",
    "authors": [
      "Tianyue Wang",
      "Leigang Qu",
      "Tianyu Yang",
      "Xiangzhao Hao",
      "Yifan Xu",
      "Haiyun Guo",
      "Jinqiao Wang"
    ],
    "abstract": "Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images given a multimodal query (comprising a reference image and a modification text), without training on annotated triplets. Existing methods typically convert the multimodal query into a single modality-either as an edited caption for Text-to-Image retrieval (T2I) or as an edited image for Image-to-Image retrieval (I2I). However, each paradigm has inherent limitations: T2I often loses fine-grained visual details, while I2I struggles with complex semantic modifications. To effectively leverage their complementary strengths under diverse query intents, we propose WISER, a training-free framework that unifies T2I and I2I via a \"retrieve-verify-refine\" pipeline, explicitly modeling intent awareness and uncertainty awareness. Specifically, WISER first performs Wider Search by generating both edited captions and images for parallel retrieval to broaden the candidate pool. Then, it conducts Adaptive Fusion with a verifier to assess retrieval confidence, triggering refinement for uncertain retrievals, and dynamically fusing the dual-path for reliable ones. For uncertain retrievals, WISER generates refinement suggestions through structured self-reflection to guide the next retrieval round toward Deeper Thinking. Extensive experiments demonstrate that WISER significantly outperforms previous methods across multiple benchmarks, achieving relative improvements of 45% on CIRCO (mAP@5) and 57% on CIRR (Recall@1) over existing training-free methods. Notably, it even surpasses many training-dependent methods, highlighting its superiority and generalization under diverse scenarios. Code will be released at https://github.com/Physicsmile/WISER.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23029.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23029",
    "published": "2026-02-26T14:11:10Z",
    "updated": "2026-02-26T14:11:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出WISER框架，通过检索-验证-优化流程统一文本到图像和图像到图像检索，显著提升训练免费零样本组合图像检索性能。",
      "motivation": "零样本组合图像检索（ZS-CIR）旨在通过多模态查询检索目标图像，但无需训练数据，这在实际应用中如内容检索和推荐系统中至关重要。现有方法通常将查询转换为单一模态，如文本到图像检索（T2I）或图像到图像检索（I2I），但T2I方法在生成编辑文本时容易丢失细粒度视觉细节，I2I方法则难以处理复杂语义修改。这些局限性导致检索精度不足，需要一种方法能有效结合两者的互补优势，以适应多样化查询意图，提升检索的鲁棒性和准确性。",
      "method": "WISER框架采用“检索-验证-优化”管道，统一T2I和I2I检索路径，核心创新在于建模意图感知和不确定性感知。首先，进行更广泛搜索，通过生成编辑后的文本和图像并行检索，扩大候选图像池。然后，自适应融合阶段使用验证器评估检索置信度，动态融合双路径或触发优化；对于不确定检索结果，通过结构化自反思生成优化建议，引导下一轮检索，实现更深层次思考。该方法为训练免费，无需数据集训练，整合了多模态检索的关键技术。",
      "result": "WISER在多个基准测试中显著优于先前方法。在CIRCO数据集上，mAP@5指标相对提升了45%，在CIRR数据集上，Recall@1指标相对提升了57%，远超现有训练免费方法。此外，它甚至优于许多依赖训练的方法，显示出卓越的性能和泛化能力。这些实验结果表明WISER在多样化场景下具有广泛适用性，验证了其框架的有效性和鲁棒性。",
      "conclusion": "本研究提出WISER框架，为训练免费零样本组合图像检索提供了一种创新方法，成功统一T2I和I2I的优势。其学术价值在于引入意图感知和不确定性感知机制，提升了多模态检索性能；实际应用中，WISER具有泛化能力，适用于复杂查询场景。摘要未明确说明局限性，但未来工作可能包括优化融合策略或扩展到其他多模态任务，以进一步推动该领域发展。",
      "tags": [
        "Zero-Shot Composed Image Retrieval",
        "Training-Free Learning",
        "Adaptive Fusion",
        "Multimodal Retrieval",
        "Retrieve-Verify-Refine Pipeline"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:33.571200Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23022",
    "title": "DMAligner: Enhancing Image Alignment via Diffusion Model Based View Synthesis",
    "authors": [
      "Xinglong Luo",
      "Ao Luo",
      "Zhengning Wang",
      "Yueqi Yang",
      "Chaoyu Feng",
      "Lei Lei",
      "Bing Zeng",
      "Shuaicheng Liu"
    ],
    "abstract": "Image alignment is a fundamental task in computer vision with broad applications. Existing methods predominantly employ optical flow-based image warping. However, this technique is susceptible to common challenges such as occlusions and illumination variations, leading to degraded alignment visual quality and compromised accuracy in downstream tasks. In this paper, we present DMAligner, a diffusion-based framework for image alignment through alignment-oriented view synthesis. DMAligner is crafted to tackle the challenges in image alignment from a new perspective, employing a generation-based solution that showcases strong capabilities and avoids the problems associated with flow-based image warping. Specifically, we propose a Dynamics-aware Diffusion Training approach for learning conditional image generation, synthesizing a novel view for image alignment. This incorporates a Dynamics-aware Mask Producing (DMP) module to adaptively distinguish dynamic foreground regions from static backgrounds, enabling the diffusion model to more effectively handle challenges that classical methods struggle to solve. Furthermore, we develop the Dynamic Scene Image Alignment (DSIA) dataset using Blender, which includes 1,033 indoor and outdoor scenes with over 30K image pairs tailored for image alignment. Extensive experimental results demonstrate the superiority of the proposed approach on DSIA benchmarks, as well as on a series of widely-used video datasets for qualitative comparisons. Our code is available at https://github.com/boomluo02/DMAligner.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23022.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23022",
    "published": "2026-02-26T14:00:07Z",
    "updated": "2026-02-26T14:00:07Z",
    "comment": "Accepted by CVPR 2026",
    "light_analysis": {
      "overview": "DMAligner提出了一种基于扩散模型的新型图像对齐框架，通过视图合成解决传统光流方法在遮挡和光照变化下的局限性。",
      "motivation": "图像对齐是计算机视觉的基础任务，广泛应用于视频处理和增强现实等领域。现有方法主要依赖基于光流的图像变形技术，但面临遮挡、光照变化等常见挑战，导致对齐视觉质量下降和下游任务准确性受损。这些问题限制了方法的鲁棒性和实际应用效果，因此需要从新视角探索更有效的解决方案，以提升对齐任务的稳定性和精度。",
      "method": "DMAligner采用基于扩散模型的框架，通过Dynamics-aware Diffusion Training方法进行条件图像生成，合成新视图以实现图像对齐。关键创新包括Dynamics-aware Mask Producing (DMP)模块，自适应区分动态前景和静态背景区域，使扩散模型能更好处理遮挡和变化。研究还使用Blender工具构建了Dynamic Scene Image Alignment (DSIA)数据集，包含1,033个室内外场景和超过30K图像对，专门针对对齐任务设计。",
      "result": "实验结果显示，DMAligner在DSIA基准测试中表现优越，与现有方法相比在图像对齐质量方面有显著提升。在多个广泛使用的视频数据集上进行定性比较时，也验证了其有效性和鲁棒性。摘要未明确说明具体性能指标如准确率或效率改进，但强调了方法在复杂场景下的优势。",
      "conclusion": "论文成功提出了DMAligner框架，基于扩散模型和视图合成技术，有效克服了传统光流方法在图像对齐中的局限性。该研究具有重要的学术价值，推动了生成模型在视觉任务中的应用，并提升了实际场景下的对齐可靠性。未来工作可进一步探索模型在更多复杂应用中的扩展性和效率优化。",
      "tags": [
        "Diffusion Model",
        "Image Alignment",
        "View Synthesis",
        "Dynamics-aware Mask Producing",
        "Conditional Image Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:37.267566Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23013",
    "title": "SubspaceAD: Training-Free Few-Shot Anomaly Detection via Subspace Modeling",
    "authors": [
      "Camile Lendering",
      "Erkut Akdag",
      "Egor Bondarev"
    ],
    "abstract": "Detecting visual anomalies in industrial inspection often requires training with only a few normal images per category. Recent few-shot methods achieve strong results employing foundation-model features, but typically rely on memory banks, auxiliary datasets, or multi-modal tuning of vision-language models. We therefore question whether such complexity is necessary given the feature representations of vision foundation models. To answer this question, we introduce SubspaceAD, a training-free method, that operates in two simple stages. First, patch-level features are extracted from a small set of normal images by a frozen DINOv2 backbone. Second, a Principal Component Analysis (PCA) model is fit to these features to estimate the low-dimensional subspace of normal variations. At inference, anomalies are detected via the reconstruction residual with respect to this subspace, producing interpretable and statistically grounded anomaly scores. Despite its simplicity, SubspaceAD achieves state-of-the-art performance across one-shot and few-shot settings without training, prompt tuning, or memory banks. In the one-shot anomaly detection setting, SubspaceAD achieves image-level and pixel-level AUROC of 98.0% and 97.6% on the MVTec-AD dataset, and 93.3% and 98.3% on the VisA dataset, respectively, surpassing prior state-of-the-art results. Code and demo are available at https://github.com/CLendering/SubspaceAD.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.23013.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23013",
    "published": "2026-02-26T13:52:57Z",
    "updated": "2026-02-26T13:52:57Z",
    "comment": "Accepted to CVPR 2026",
    "light_analysis": {
      "overview": "本文提出SubspaceAD，一种基于子空间建模的无需训练少样本异常检测方法，在工业视觉任务中实现最先进性能。",
      "motivation": "在工业视觉检测中，常需仅用少量正常图像进行训练，因此开发高效的少样本异常检测方法至关重要。现有方法虽利用基础模型特征取得进展，但通常依赖内存库、辅助数据集或多模态调优，增加了复杂度。本研究质疑这种复杂性是否必要，基于视觉基础模型的现有特征表示，旨在简化方法并提高实用性，以应对工业实际需求。",
      "method": "SubspaceAD采用两阶段简单流程：首先，使用冻结的DINOv2骨干模型，从少量正常图像中提取补丁级特征。其次，应用主成分分析（PCA）拟合这些特征，估计正常变化的低维子空间。推理时，通过计算输入特征与该子空间的重建残差来检测异常，生成可解释且基于统计的异常得分，无需额外训练或调优。",
      "result": "在单样本异常检测设置中，SubspaceAD在MVTec-AD数据集上达到图像级AUROC 98.0%和像素级AUROC 97.6%，在VisA数据集上分别为93.3%和98.3%，超越了先前的状态oftheart结果。这些性能基于无需训练、提示调优或内存库的方法实现，证明了其高效性。",
      "conclusion": "本研究的主要贡献是开发了SubspaceAD，一种简单有效的无训练少样本异常检测框架，利用子空间建模简化了流程。学术上验证了视觉基础模型特征在异常检测任务中的潜力，应用上为工业检测提供了高效、可解释的解决方案。摘要未明确说明局限性，未来工作可能包括扩展到更多数据集或与其他技术结合以提升鲁棒性。",
      "tags": [
        "Anomaly Detection",
        "Subspace Modeling",
        "Principal Component Analysis (PCA)",
        "DINOv2",
        "Few-Shot Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:45.171247Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.23008",
    "title": "Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization",
    "authors": [
      "Zeyuan Liu",
      "Jeonghye Kim",
      "Xufang Luo",
      "Dongsheng Li",
      "Yuqing Yang"
    ],
    "abstract": "Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO$^2$), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO$^2$ achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO$^2$ demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO$^2$ as a promising framework for building more exploratory and generalizable LLM-based agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.23008.pdf",
    "abs_url": "https://arxiv.org/abs/2602.23008",
    "published": "2026-02-26T13:50:57Z",
    "updated": "2026-02-26T13:50:57Z",
    "comment": "Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "本文提出了EMPO²，一个结合记忆增强和混合on-/off-policy优化的强化学习框架，旨在提高大型语言模型代理的探索能力和泛化性能。",
      "motivation": "该研究旨在解决大型语言模型代理在使用强化学习训练时，探索能力不足的瓶颈问题。现有方法主要依赖预训练知识，但在需要发现未知状态的环境中表现不佳，限制了代理在复杂环境中的适应性和泛化能力。因此，开发新的探索机制变得至关重要，以提升代理在新颖场景中的性能。",
      "method": "EMPO²框架利用记忆机制增强探索，通过结合on-policy和off-policy优化策略，使代理能有效利用过往经验，并在有或无记忆时保持鲁棒性。具体地，它使用记忆存储状态信息来指导探索，提高探索效率，实验在ScienceWorld和WebShop数据集上进行，但摘要未明确说明具体模型架构细节。",
      "result": "在ScienceWorld和WebShop基准测试中，EMPO²相比基线方法GRPO分别实现了128.6%和11.3%的性能提升。此外，在分布外任务测试中，EMPO²显示出卓越的适应性，仅通过少量带有记忆的试验就能适应新任务，而无需更新模型参数，突显其强大的泛化能力。",
      "conclusion": "本研究的主要贡献是提出了EMPO²框架，它通过记忆增强和混合优化策略，显著提升了LLM代理的探索性和泛化性，为构建更强大的AI代理提供了新方法。这具有重要的学术价值，推动了强化学习在语言模型中的应用，并可能在实际的自适应系统中发挥效用，未来可进一步探索其在不同环境中的扩展性和局限性。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Memory-Augmented",
        "On-Policy Optimization",
        "Off-Policy Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:58.549505Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22988",
    "title": "Residual Koopman Spectral Profiling for Predicting and Preventing Transformer Training Instability",
    "authors": [
      "Bum Jun Kim",
      "Shohei Taniguchi",
      "Makoto Kawano",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "abstract": "Training divergence in transformers wastes compute, yet practitioners discover instability only after expensive runs begin. They therefore need an expected probability of failure for a transformer before training starts. Our study of Residual Koopman Spectral Profiling (RKSP) provides such an estimate. From a single forward pass at initialization, RKSP extracts Koopman spectral features by applying whitened dynamic mode decomposition to layer-wise residual snapshots. Our central diagnostic, the near-unit spectral mass, quantifies the fraction of modes concentrated near the unit circle, which captures instability risk. For predicting divergence across extensive configurations, this estimator achieves an AUROC of 0.995, outperforming the best gradient baseline. We further make this diagnostic actionable through Koopman Spectral Shaping (KSS), which reshapes spectra during training. We empirically validate that our method works in practice: RKSP predicts divergence at initialization, and when RKSP flags high risk, turning on KSS successfully prevents divergence. In the challenging high learning rate regime without normalization layers, KSS reduces the divergence rate from 66.7% to 12.5% and enables learning rates that are 50% to 150% higher. These findings generalize to WikiText-103 language modeling, vision transformers on CIFAR-10, and pretrained language models, including GPT-2 and LLaMA-2 up to 7B, as well as emerging architectures such as MoE, Mamba-style SSMs, and KAN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22988.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22988",
    "published": "2026-02-26T13:33:25Z",
    "updated": "2026-02-26T13:33:25Z",
    "comment": "23 pages, 7 figures",
    "light_analysis": {
      "overview": "论文提出了Residual Koopman Spectral Profiling（RKSP）和Koopman Spectral Shaping（KSS），用于在变压器训练初始化时预测并防止训练发散。",
      "motivation": "变压器训练中常出现发散问题，浪费大量计算资源，但现有方法无法在训练开始前有效预测不稳定性，导致实践者需在昂贵的运行后才发现，增加了成本。因此，迫切需要一种能在初始化阶段评估风险的工具，以优化训练策略和资源配置，解决当前梯度基线等方法的不足，提高训练效率和稳定性。",
      "method": "核心方法是Residual Koopman Spectral Profiling（RKSP），在初始化阶段通过单次前向传播，应用白化动态模式分解到层间残差快照，提取Koopman谱特征。关键创新点是近单位谱质量指标，用于量化集中在单位圆附近的模式比例，以捕捉不稳定性风险。进一步，Koopman Spectral Shaping（KSS）在训练期间基于这些谱特征调整模型，通过重塑谱来预防发散，确保训练过程稳定。",
      "result": "实验显示，RKSP在预测训练发散时AUROC达0.995，优于最佳梯度基线。在高学习率且无归一化层的设置下，KSS将发散率从66.7%降至12.5%，并允许学习率提升50%到150%。该方法在多种任务中验证有效，包括WikiText-103语言建模、CIFAR-10视觉变压器，以及GPT-2、LLaMA-2等预训练模型和新兴架构，展示了广泛泛化能力。",
      "conclusion": "论文贡献了RKSP和KSS，为变压器训练提供了预测和预防不稳定性的有效工具。学术上，引入了基于Koopman谱分析的新颖诊断方法；实际上，减少了计算浪费并提升了训练效率。局限性可能在于特定场景的适应，未来工作可扩展到更多模型架构和优化条件，以进一步验证其通用性。",
      "tags": [
        "Transformer Training Instability",
        "Koopman Spectral Profiling",
        "Dynamic Mode Decomposition",
        "Spectral Shaping",
        "High Learning Rate"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:06.745816Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22983",
    "title": "Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search",
    "authors": [
      "Xun Huang",
      "Simeng Qin",
      "Xiaoshuang Jia",
      "Ranjie Duan",
      "Huanqian Yan",
      "Zhitao Zeng",
      "Fei Yang",
      "Yang Liu",
      "Xiaojun Jia"
    ],
    "abstract": "As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions-covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22983.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22983",
    "published": "2026-02-26T13:25:35Z",
    "updated": "2026-02-26T13:25:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于果蝇优化的古典中文越狱提示自动生成框架 CC-BOS，有效增强黑盒攻击效果。",
      "motivation": "大型语言模型（LLMs）的广泛应用带来了日益严重的安全风险，其中越狱攻击尤为突出。现有研究表明，攻击效果在不同语言环境中存在差异，而古典中文由于其简洁和隐晦的特性，能够部分绕过现有的安全约束，暴露了 LLMs 的潜在漏洞。因此，本研究旨在探究古典中文在越狱攻击中的作用，开发自动生成对抗提示的方法，以应对黑盒设置下的安全挑战，为模型安全评估和防御机制提供新的研究方向。",
      "method": "论文提出 CC-BOS 框架，采用多维果蝇优化算法来自动生成古典中文越狱提示。首先，将提示编码为八个策略维度，包括角色、行为、机制、隐喻、表达、知识、触发模式和上下文，以全面覆盖攻击要素。然后，通过嗅觉搜索、视觉搜索和柯西变异进行迭代优化，高效探索搜索空间，提升攻击效率。此外，为增强可读性和评估准确性，还设计了古典中文到英文的翻译模块。该方法适用于黑盒设置，无需访问模型内部信息，实现了自动化攻击生成。",
      "result": "通过广泛实验验证，CC-BOS 框架在越狱攻击中 consistently 优于最先进的现有方法。实验结果展示了该框架的有效性，尽管摘要未提供具体性能指标如攻击成功率，但对比实验表明其在黑盒设置下的卓越表现。这证实了利用古典中文的隐晦性和生物启发式搜索进行提示优化的优势，为自动化攻击提供了强有力的工具。",
      "conclusion": "本研究开发了 CC-BOS 框架，揭示了古典中文在越狱攻击中的独特作用，并通过果蝇优化实现了自动提示生成。学术上，它拓展了语言特性对 LLM 安全影响的研究，为安全领域提供新视角；实际上，为自动化黑盒攻击提供了高效工具，有助于安全评估和漏洞识别。未来工作可探索扩展到其他语言或结合更多优化策略，以进一步提升攻击和防御能力。",
      "tags": [
        "Large Language Model",
        "Jailbreak Attack",
        "Classical Chinese",
        "Fruit Fly Optimization",
        "Prompt Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:20.132308Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22981",
    "title": "RepSPD: Enhancing SPD Manifold Representation in EEGs via Dynamic Graphs",
    "authors": [
      "Haohui Jia",
      "Zheng Chen",
      "Lingwei Zhu",
      "Xu Cao",
      "Yasuko Matsubara",
      "Takashi Matsubara",
      "Yasushi Sakurai"
    ],
    "abstract": "Decoding brain activity from electroencephalography (EEG) is crucial for neuroscience and clinical applications. Among recent advances in deep learning for EEG, geometric learning stands out as its theoretical underpinnings on symmetric positive definite (SPD) allows revealing structural connectivity analysis in a physics-grounded manner. However, current SPD-based methods focus predominantly on statistical aggregation of EEGs, with frequency-specific synchronization and local topological structures of brain regions neglected. Given this, we propose RepSPD, a novel geometric deep learning (GDL)-based model. RepSPD implements a cross-attention mechanism on the Riemannian manifold to modulate the geometric attributes of SPD with graph-derived functional connectivity features. On top of this, we introduce a global bidirectional alignment strategy to reshape tangent-space embeddings, mitigating geometric distortions caused by curvature and thereby enhancing geometric consistency. Extensive experiments demonstrate that our proposed framework significantly outperforms existing EEG representation methods, exhibiting superior robustness and generalization capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22981.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22981",
    "published": "2026-02-26T13:22:19Z",
    "updated": "2026-02-26T13:22:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "RepSPD模型通过动态图和跨注意力机制增强SPD流形表示，显著提升脑电图解码性能。",
      "motivation": "脑电图(EEG)解码在神经科学和临床应用中至关重要，近年来基于对称正定(SPD)流形的几何学习因其物理基础而受到关注。然而，现有SPD方法主要侧重于EEG信号的统计聚合，忽视了频率特异性同步和脑区局部拓扑结构的重要性。这些不足限制了EEG表示的准确性和鲁棒性，特别是在分析脑功能连接时，导致解码效率低下。因此，需要开发新方法来整合这些被忽略的特征，以更全面地揭示大脑活动的结构性连接。",
      "method": "RepSPD是一个基于几何深度学习的创新模型，通过在黎曼流形上实现跨注意力机制，将动态图导出的功能连接特征调制到SPD表示中，从而有效捕捉脑电图的频率特异性同步和局部拓扑结构。此外，模型引入全局双向对齐策略，重塑切空间嵌入，以减轻曲率引起的几何失真，增强表示的几何一致性。尽管摘要未明确说明具体使用的数据集或模型架构细节，但该方法结合了几何深度学习和图神经网络的优势，突出了在SPD流形上进行特征融合和优化的技术特色。",
      "result": "实验结果表明，RepSPD框架在脑电图表示任务中显著优于现有的方法，展现出更高的性能和更强的鲁棒性。尽管摘要未明确说明具体的准确率提升或效率改进数字，但报告强调该模型具有优越的泛化能力，能在不同场景下稳定工作。通过与基线方法对比，RepSPD在捕获EEG信号的复杂结构方面表现突出，为神经科学分析和临床应用提供了更可靠的表示基础。",
      "conclusion": "RepSPD通过动态图和跨注意力机制的整合，成功解决了SPD流形表示中的关键问题，显著提升了EEG解码的准确性和鲁棒性。该研究不仅贡献了一种新的几何深度学习模型，还推动了神经科学中脑功能连接分析的发展，具有重要的学术价值和实际应用潜力。未来工作可以探索将该方法扩展到其他生物医学信号处理任务，或进一步优化图结构设计以增强表示效率。",
      "tags": [
        "Symmetric Positive Definite Manifold",
        "Geometric Deep Learning",
        "Cross-Attention Mechanism",
        "Dynamic Graphs",
        "EEG Representation"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:33.283096Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22973",
    "title": "Modeling Expert AI Diagnostic Alignment via Immutable Inference Snapshots",
    "authors": [
      "Dimitrios P. Panagoulias",
      "Evangelia-Aikaterini Tsichrintzi",
      "Georgios Savvidis",
      "Evridiki Tsoureli-Nikita"
    ],
    "abstract": "Human-in-the-loop validation is essential in safety-critical clinical AI, yet the transition between initial model inference and expert correction is rarely analyzed as a structured signal. We introduce a diagnostic alignment framework in which the AI-generated image based report is preserved as an immutable inference state and systematically compared with the physician-validated outcome. The inference pipeline integrates a vision-enabled large language model, BERT- based medical entity extraction, and a Sequential Language Model Inference (SLMI) step to enforce domain-consistent refinement prior to expert review. Evaluation on 21 dermatological cases (21 complete AI physician pairs) em- ployed a four-level concordance framework comprising exact primary match rate (PMR), semantic similarity-adjusted rate (AMR), cross-category alignment, and Comprehensive Concordance Rate (CCR). Exact agreement reached 71.4% and remained unchanged under semantic similarity (t = 0.60), while structured cross-category and differential overlap analysis yielded 100% comprehensive concordance (95% CI: [83.9%, 100%]). No cases demonstrated complete diagnostic divergence. These findings show that binary lexical evaluation substantially un- derestimates clinically meaningful alignment. Modeling expert validation as a structured transformation enables signal-aware quantification of correction dynamics and supports traceable, human aligned evaluation of image based clinical decision support systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22973.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22973",
    "published": "2026-02-26T13:11:58Z",
    "updated": "2026-02-26T13:11:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出一种通过不可变推理快照建模专家AI诊断对齐的框架，以量化临床评估中的对齐动态并改进人类验证过程。",
      "motivation": "在安全关键的临床AI领域，人类在循环验证对于确保诊断准确性至关重要，但现有方法往往将AI初始推理与专家校正之间的过渡视为简单过程，忽略了作为结构化信号的分析。摘要指出，二元词汇评估可能严重低估临床意义上的对齐，导致对AI系统性能的误判。这凸显了研究如何建模专家验证动态的重要性，以解决评估不精确的问题，并为临床决策支持系统提供更可靠的量化基础。",
      "method": "论文提出了一个诊断对齐框架，核心是将AI生成的图像报告保存为不可变的推理快照，并与医生验证结果进行系统比较。方法集成了视觉启用的大型语言模型来生成报告，基于BERT的医学实体提取以识别关键信息，以及序列语言模型推理步骤来强制领域一致性细化，确保在专家审查前优化输出。创新点在于通过不可变状态捕捉推理过程，并使用结构化步骤来量化对齐，提高评估的可追溯性。",
      "result": "在21个皮肤病病例上评估，使用四层对齐框架：准确主要匹配率、语义相似性调整率、跨类别对齐和全面对齐率。结果显示，准确一致率达到71.4%，在语义相似性下保持不变（t = 0.60），而结构化跨类别和差异重叠分析达到100%全面对齐（95% CI: [83.9%, 100%]）。所有病例均未出现完全诊断分歧。这表明二元评估低估了实际对齐程度，支持框架的有效性。",
      "conclusion": "论文的主要贡献是提出一个结构化框架来建模专家验证作为变换过程，从而实现信号感知的校正动态量化。研究具有重要学术价值，为临床AI提供了更精确和可追溯的评估方法，改进图像基础的决策支持系统的可靠性。局限性包括样本量较小（21个病例），未来工作可扩展至更大数据集和更多医学领域，以验证泛化能力。",
      "tags": [
        "Diagnostic Alignment",
        "Immutable Inference Snapshots",
        "Vision-Enabled Large Language Model",
        "BERT-based Extraction",
        "Sequential Language Model Inference"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:26.374258Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22971",
    "title": "SPM-Bench: Benchmarking Large Language Models for Scanning Probe Microscopy",
    "authors": [
      "Peiyao Xiao",
      "Xiaogang Li",
      "Chengliang Xu",
      "Jiayi Wang",
      "Ben Wang",
      "Zichao Chen",
      "Zeyu Wang",
      "Kejun Yu",
      "Yueqian Chen",
      "Xulin Liu",
      "Wende Xiao",
      "Bing Zhao",
      "Hu Wei"
    ],
    "abstract": "As LLMs achieved breakthroughs in general reasoning, their proficiency in specialized scientific domains reveals pronounced gaps in existing benchmarks due to data contamination, insufficient complexity, and prohibitive human labor costs. Here we present SPM-Bench, an original, PhD-level multimodal benchmark specifically designed for scanning probe microscopy (SPM). We propose a fully automated data synthesis pipeline that ensures both high authority and low-cost. By employing Anchor-Gated Sieve (AGS) technology, we efficiently extract high-value image-text pairs from arXiv and journal papers published between 2023 and 2025. Through a hybrid cloud-local architecture where VLMs return only spatial coordinates \"llbox\" for local high-fidelity cropping, our pipeline achieves extreme token savings while maintaining high dataset purity. To accurately and objectively evaluate the performance of the LLMs, we introduce the Strict Imperfection Penalty F1 (SIP-F1) score. This metric not only establishes a rigorous capability hierarchy but also, for the first time, quantifies model \"personalities\" (Conservative, Aggressive, Gambler, or Wise). By correlating these results with model-reported confidence and perceived difficulty, we expose the true reasoning boundaries of current AI in complex physical scenarios. These insights establish SPM-Bench as a generalizable paradigm for automated scientific data synthesis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22971.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22971",
    "published": "2026-02-26T13:08:56Z",
    "updated": "2026-02-26T13:08:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了SPM-Bench，一个针对扫描探针显微镜（SPM）的PhD级多模态基准，通过全自动数据合成和SIP-F1指标来评估大型语言模型的专业能力，填补了专业科学领域的基准空白。",
      "motivation": "当前，大型语言模型（LLMs）在通用推理中取得突破，但在扫描探针显微镜等专业科学领域，现有基准存在数据污染、复杂度不足和高人力成本等问题。这些不足限制了LLMs在复杂物理场景中的应用，因此需要开发专门的基准来准确评估模型的专业推理能力，以推动AI在科学研究中的进展。摘要强调了现有基准的局限性，并指出SPM-Bench的提出旨在解决这些挑战。",
      "method": "论文提出了SPM-Bench基准，其核心技术是全自动数据合成管道。使用Anchor-Gated Sieve（AGS）技术从2023年至2025年的arXiv和期刊论文中提取高价值图像-文本对。通过混合云-本地架构，视觉语言模型（VLMs）仅返回空间坐标\"llbox\"，用于本地高保真裁剪，从而实现令牌节省和数据纯度保持。此外，引入Strict Imperfection Penalty F1（SIP-F1）分数来评估LLMs性能，该指标能建立能力层次并量化模型\"个性\"（如保守、激进等）。",
      "result": "研究通过SIP-F1分数评估了LLMs的性能，首次量化了模型的\"个性\"（如保守型、激进型、赌徒型或智者型），并将结果与模型报告的置信度和感知难度相关联，揭示了AI在复杂物理场景中的推理边界。SPM-Bench被确立为自动化科学数据合成的可推广范式，但具体性能提升数据（如准确率或效率改进）在摘要中未明确说明，可能与基线方法进行了对比以展示其有效性。",
      "conclusion": "论文的主要贡献是开发了SPM-Bench基准，并提出了全自动数据合成方法和SIP-F1评估指标，为专业科学领域的AI评估提供了新工具。这不仅增强了LLMs在扫描探针显微镜等复杂任务中的应用潜力，还推动了自动化科学数据合成的发展。未来工作可能包括将方法扩展到其他科学领域或改进评估指标，以进一步提升模型的适应性和准确性。",
      "tags": [
        "Large Language Model",
        "Scanning Probe Microscopy",
        "Multimodal Benchmark",
        "Anchor-Gated Sieve",
        "Strict Imperfection Penalty F1"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:43.064500Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22968",
    "title": "Certified Circuits: Stability Guarantees for Mechanistic Circuits",
    "authors": [
      "Alaa Anani",
      "Tobias Lorenz",
      "Bernt Schiele",
      "Mario Fritz",
      "Jonas Fischer"
    ],
    "abstract": "Understanding how neural networks arrive at their predictions is essential for debugging, auditing, and deployment. Mechanistic interpretability pursues this goal by identifying circuits - minimal subnetworks responsible for specific behaviors. However, existing circuit discovery methods are brittle: circuits depend strongly on the chosen concept dataset and often fail to transfer out-of-distribution, raising doubts whether they capture concept or dataset-specific artifacts. We introduce Certified Circuits, which provide provable stability guarantees for circuit discovery. Our framework wraps any black-box discovery algorithm with randomized data subsampling to certify that circuit component inclusion decisions are invariant to bounded edit-distance perturbations of the concept dataset. Unstable neurons are abstained from, yielding circuits that are more compact and more accurate. On ImageNet and OOD datasets, certified circuits achieve up to 91% higher accuracy while using 45% fewer neurons, and remain reliable where baselines degrade. Certified Circuits puts circuit discovery on formal ground by producing mechanistic explanations that are provably stable and better aligned with the target concept. Code will be released soon!",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22968.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22968",
    "published": "2026-02-26T13:07:31Z",
    "updated": "2026-02-26T13:07:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "Certified Circuits 通过随机数据子采样提供可证明的稳定性保证，改进机械解释性中的电路发现，提高准确性和紧凑性。",
      "motivation": "机械解释性旨在通过识别电路（最小子网络）来理解神经网络预测，但现有电路发现方法存在脆弱性问题：它们过度依赖特定概念数据集，在分布外传输时失败频繁，可能只捕获数据集特定工件而非真正概念，降低了其在调试、审计和实际部署中的可靠性，因此需要开发更稳定和可证明的方法来解决这一不足。",
      "method": "论文提出Certified Circuits框架，包裹任意黑盒电路发现算法，核心是使用随机数据子采样来验证电路组件包含决策对概念数据集的有限编辑距离扰动是否不变，排除不稳定的神经元，从而生成更紧凑和准确的电路。在实验中应用了ImageNet和OOD数据集，但模型架构等具体细节摘要未明确说明，重点在于算法层面的稳定保证。",
      "result": "在ImageNet和OOD数据集上的实验结果显示，Certified Circuits相比基线方法实现高达91%的准确率提升，同时使用45%更少的神经元，且在基线性能退化时仍保持可靠。这表明方法在提高电路发现的准确性和效率方面具有显著优势，验证了稳定性保证的实际效果。",
      "conclusion": "Certified Circuits为电路发现提供了正式的理论基础，产生可证明稳定且更符合目标概念的机械解释，增强了神经网络解释的可信度和应用价值，对学术研究和实际部署具有重要意义。摘要未明确说明局限性或未来工作方向，但暗示了代码发布和进一步探索的可能。",
      "tags": [
        "Mechanistic Interpretability",
        "Circuit Discovery",
        "Stability Guarantees",
        "Randomized Data Subsampling",
        "Out-of-Distribution Generalization"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:36.158174Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22963",
    "title": "FactGuard: Agentic Video Misinformation Detection via Reinforcement Learning",
    "authors": [
      "Zehao Li",
      "Hongwei Yu",
      "Hao Jiang",
      "Qiang Sheng",
      "Yilong Xu",
      "Baolong Bi",
      "Yang Li",
      "Zhenlong Yuan",
      "Yujun Cai",
      "Zhaoqi Wang"
    ],
    "abstract": "Multimodal large language models (MLLMs) have substantially advanced video misinformation detection through unified multimodal reasoning, but they often rely on fixed-depth inference and place excessive trust in internally generated assumptions, particularly in scenarios where critical evidence is sparse, fragmented, or requires external verification. To address these limitations, we propose FactGuard, an agentic framework for video misinformation detection that formulates verification as an iterative reasoning process built upon MLLMs. FactGuard explicitly assesses task ambiguity and selectively invokes external tools to acquire critical evidence, enabling progressive refinement of reasoning trajectories. To further strengthen this capability, we introduce a two-stage training strategy that combines domain-specific agentic supervised fine-tuning with decision-aware reinforcement learning to optimize tool usage and calibrate risk-sensitive decision making. Extensive experiments on FakeSV, FakeTT, and FakeVV demonstrate FactGuard's state-of-the-art performance and validate its excellent robustness and generalization capacity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22963.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22963",
    "published": "2026-02-26T13:00:31Z",
    "updated": "2026-02-26T13:00:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "FactGuard是一个基于多模态大语言模型的强化学习驱动代理框架，用于视频虚假信息检测，通过迭代推理和选择性外部工具调用提升了性能。",
      "motivation": "当前多模态大语言模型在视频虚假信息检测中虽然取得了进展，但依赖固定深度推理和过度信任内部假设，尤其是在证据稀疏、分散或需要外部验证的场景下，这可能导致误判。解决这些局限性对提高检测准确性和适应复杂实际环境至关重要。该研究旨在开发一个更鲁棒的框架，以应对这些挑战。",
      "method": "FactGuard框架将虚假信息验证设计为基于多模态大语言模型的迭代推理过程，通过评估任务模糊性并选择性调用外部工具来获取关键证据，从而逐步优化推理轨迹。关键创新点包括两阶段训练策略，结合了领域特定代理监督微调和决策感知强化学习，以优化工具使用并校准风险敏感决策。摘要未明确说明具体模型架构细节，但强调了这一方法的强化学习和技术整合特色。",
      "result": "在FakeSV、FakeTT和FakeVV数据集上的广泛实验表明，FactGuard实现了最先进的性能，具体表现在超越基线方法的检测准确性和鲁棒性，并展现出优秀的泛化能力。实验验证了该框架在处理多模态虚假信息时的有效性，但摘要未提供具体数值指标，主要基于整体性能描述。",
      "conclusion": "FactGuard通过集成迭代推理、外部工具调用和强化学习，为视频虚假信息检测提供了创新的代理框架，增强了检测的鲁棒性和适应性，具有重要的学术和应用价值。未来工作可扩展至更多多模态场景和外部工具类型。",
      "tags": [
        "Multimodal Large Language Models",
        "Reinforcement Learning",
        "Agentic Framework",
        "Video Misinformation Detection",
        "Iterative Reasoning"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:52.874310Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22962",
    "title": "Scaling Laws of Global Weather Models",
    "authors": [
      "Yuejiang Yu",
      "Langwen Huang",
      "Alexandru Calotoiu",
      "Torsten Hoefler"
    ],
    "abstract": "Data-driven models are revolutionizing weather forecasting. To optimize training efficiency and model performance, this paper analyzes empirical scaling laws within this domain. We investigate the relationship between model performance (validation loss) and three key factors: model size ($N$), dataset size ($D$), and compute budget ($C$). Across a range of models, we find that Aurora exhibits the strongest data-scaling behavior: increasing the training dataset by 10x reduces validation loss by up to 3.2x. GraphCast demonstrates the highest parameter efficiency, yet suffers from limited hardware utilization. Our compute-optimal analysis indicates that, under fixed compute budgets, allocating resources to longer training durations yields greater performance gains than increasing model size. Furthermore, we analyze model shape and uncover scaling behaviors that differ fundamentally from those observed in language models: weather forecasting models consistently favor increased width over depth. These findings suggest that future weather models should prioritize wider architectures and larger effective training datasets to maximize predictive performance.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22962.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22962",
    "published": "2026-02-26T12:57:38Z",
    "updated": "2026-02-26T12:57:38Z",
    "comment": "17 pages, 7 figures",
    "light_analysis": {
      "overview": "本文通过分析天气预报数据驱动模型的缩放定律，发现应优先采用更宽的架构和更大的训练数据集以优化预测性能。",
      "motivation": "本研究旨在优化天气预报数据驱动模型的训练效率和性能。数据驱动模型正革新天气预报领域，但缩放定律不明，导致资源分配不当和模型性能未最大化。现有方法如GraphCast虽参数效率高，但硬件利用率有限，影响整体性能，因此需要系统性分析缩放行为来指导模型设计。摘要未明确说明其他不足，但暗示资源优化和效率提升是核心问题。",
      "method": "论文采用经验性分析方法，研究模型性能（验证损失）与模型大小、数据集大小和计算预算之间的关系。核心创新在于对比不同模型（如Aurora和GraphCast）的缩放行为，并分析模型形状（宽度 vs 深度）。摘要未明确提及具体数据集或模型架构细节，但通过缩放定律研究揭示天气预报模型的独特行为，不同于语言模型，为模型优化提供技术路线。",
      "result": "实验结果显示，Aurora模型的数据缩放行为最强，训练数据集增加10倍可使验证损失减少最多3.2倍；GraphCast具有最高参数效率，但硬件利用率受限。计算最优分析表明，在固定计算预算下，延长训练时间比增加模型大小更能提升性能。此外，天气预报模型的缩放行为显示，增加模型宽度优于增加深度，这与语言模型相反。",
      "conclusion": "论文的主要贡献是揭示了天气预报模型的缩放定律，建议未来设计应优先考虑更宽的架构和更大的有效训练数据集。研究的学术价值在于为天气模型优化提供理论指导，实际应用价值在于提升天气预报的准确性和效率。摘要未明确说明局限性或未来工作方向，但可推断需进一步探索硬件利用率和跨模型泛化。",
      "tags": [
        "Scaling Laws",
        "Weather Forecasting Models",
        "Data-driven Models",
        "Model Efficiency",
        "Architecture Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:02.859421Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22960",
    "title": "UCM: Unifying Camera Control and Memory with Time-aware Positional Encoding Warping for World Models",
    "authors": [
      "Tianxing Xu",
      "Zixuan Wang",
      "Guangyuan Wang",
      "Li Hu",
      "Zhongyi Zhang",
      "Peng Zhang",
      "Bang Zhang",
      "Song-Hai Zhang"
    ],
    "abstract": "World models based on video generation demonstrate remarkable potential for simulating interactive environments but face persistent difficulties in two key areas: maintaining long-term content consistency when scenes are revisited and enabling precise camera control from user-provided inputs. Existing methods based on explicit 3D reconstruction often compromise flexibility in unbounded scenarios and fine-grained structures. Alternative methods rely directly on previously generated frames without establishing explicit spatial correspondence, thereby constraining controllability and consistency. To address these limitations, we present UCM, a novel framework that unifies long-term memory and precise camera control via a time-aware positional encoding warping mechanism. To reduce computational overhead, we design an efficient dual-stream diffusion transformer for high-fidelity generation. Moreover, we introduce a scalable data curation strategy utilizing point-cloud-based rendering to simulate scene revisiting, facilitating training on over 500K monocular videos. Extensive experiments on real-world and synthetic benchmarks demonstrate that UCM significantly outperforms state-of-the-art methods in long-term scene consistency, while also achieving precise camera controllability in high-fidelity video generation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22960.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22960",
    "published": "2026-02-26T12:54:46Z",
    "updated": "2026-02-26T12:54:46Z",
    "comment": "Project Page: https://humanaigc.github.io/ucm-webpage/",
    "light_analysis": {
      "overview": "UCM框架通过时间感知位置编码扭曲机制，统一了长期记忆和精确相机控制，解决了世界模型在长期一致性和可控性方面的关键挑战。",
      "motivation": "基于视频生成的世界模型在模拟交互式环境中展现潜力，但面临长期内容一致性和精确相机控制的困难。显式3D重建方法在无界场景中灵活度不足，牺牲了细粒度结构；而依赖先前生成帧的方法缺乏显式空间对应关系，限制了可控性和一致性。因此，本研究旨在开发一种新方法，以同时应对这些局限性，提升模型在现实应用中的实用性和仿真效果。",
      "method": "UCM框架采用时间感知位置编码扭曲机制，将长期记忆与相机控制统一起来，通过这种机制建立空间对应以提升一致性。为减少计算开销，设计了高效的双流扩散变换器，支持高保真视频生成。此外，引入可扩展的数据策展策略，利用点云渲染模拟场景重访，在超过500K单目视频数据集上进行训练，增强了模型的泛化能力和实用性。",
      "result": "在真实世界和合成基准上的实验表明，UCM在长期场景一致性方面显著优于现有最先进方法。摘要未明确说明具体性能指标数值，但强调了UCM在高保真视频生成中实现了精确的相机可控性，展示了其在提升模型一致性和控制能力方面的有效性，验证了方法的优越性和鲁棒性。",
      "conclusion": "UCM的主要贡献在于提出了一种统一框架，有效解决了世界模型中的长期一致性和相机控制问题，增强了模拟环境的真实性和交互性。该研究为视频生成和世界建模领域提供了新思路，具有重要的学术和实际应用价值。未来工作可进一步优化计算效率或扩展到更复杂的动态场景中，以应对更多挑战。",
      "tags": [
        "World Models",
        "Camera Control",
        "Time-aware Positional Encoding",
        "Diffusion Transformers",
        "Point Cloud Rendering"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:12.075719Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22959",
    "title": "Can Agents Distinguish Visually Hard-to-Separate Diseases in a Zero-Shot Setting? A Pilot Study",
    "authors": [
      "Zihao Zhao",
      "Frederik Hauke",
      "Juliana De Castilhos",
      "Sven Nebelung",
      "Daniel Truhn"
    ],
    "abstract": "The rapid progress of multimodal large language models (MLLMs) has led to increasing interest in agent-based systems. While most prior work in medical imaging concentrates on automating routine clinical workflows, we study an underexplored yet clinically significant setting: distinguishing visually hard-to-separate diseases in a zero-shot setting. We benchmark representative agents on two imaging-only proxy diagnostic tasks, (1) melanoma vs. atypical nevus and (2) pulmonary edema vs. pneumonia, where visual features are highly confounded despite substantial differences in clinical management. We introduce a multi-agent framework based on contrastive adjudication. Experimental results show improved diagnostic performance (an 11-percentage-point gain in accuracy on dermoscopy data) and reduced unsupported claims on qualitative samples, although overall performance remains insufficient for clinical deployment. We acknowledge the inherent uncertainty in human annotations and the absence of clinical context, which further limit the translation to real-world settings. Within this controlled setting, this pilot study provides preliminary insights into zero-shot agent performance in visually confounded scenarios.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22959.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22959",
    "published": "2026-02-26T12:53:50Z",
    "updated": "2026-02-26T12:53:50Z",
    "comment": "Code available at https://github.com/TruhnLab/Contrastive-Agent-Reasoning",
    "light_analysis": {
      "overview": "本论文提出了一种基于对比性裁决的多代理框架，用于在零样本设置中区分视觉上难以区分的疾病，如黑色素瘤与非典型痣，并展示了诊断准确率的提升。",
      "motivation": "随着多模态大语言模型的快速发展，基于代理的系统在医学影像领域受到广泛关注。然而，现有研究大多集中于自动化常规临床工作流，忽视了零样本设置中区分视觉混淆疾病的重要性。例如，黑色素瘤与非典型痣、肺水肿与肺炎在视觉特征上高度相似，但临床管理策略差异显著，准确区分对改善诊断和治疗决策至关重要。本研究旨在填补这一空白，探索在缺乏先验知识的场景下，代理系统如何应对视觉混淆的挑战，以提升医学影像诊断的准确性和可靠性。",
      "method": "本研究引入了一个基于对比性裁决的多代理框架。方法上，选择了两个成像代理任务：皮肤镜数据的黑色素瘤与非典型痣区分，以及肺部影像的肺水肿与肺炎区分。通过利用多模态大语言模型，设计多代理系统进行对比分析，以增强诊断性能。关键创新点在于采用对比性裁决机制，通过多个代理的协作减少误判，并在零样本设置下评估模型能力。摘要未明确说明具体模型架构或数据集细节，但推断使用了标准代理基准和对比学习技术来优化诊断过程。",
      "result": "实验结果显示，所提出的多代理框架在皮肤镜数据上诊断准确率提高了11个百分点，同时减少了无支持的主张。与代表代理基准相比，该方法在视觉混淆任务中表现出改进，但整体性能仍不足以直接应用于临床部署。这表明框架在零样本设置下具有潜力，但面对高度相似的疾病特征，诊断准确性仍需进一步提升，以克服实际应用中的挑战。",
      "conclusion": "本初步研究提供了关于零样本代理在视觉混淆疾病诊断中性能的初步见解，主要贡献在于提出了一个有效的多代理框架，展示了区分视觉相似疾病的潜力。学术上，这丰富了零样本学习在医学影像中的应用；实际上，为未来智能诊断系统开发提供了参考。然而，研究指出了局限性，如人类标注的固有不确定性和缺乏临床背景，这限制了翻译到现实世界应用的可能性。未来工作可聚焦于整合更多临床数据、上下文信息，以提高模型的鲁棒性和实用性。",
      "tags": [
        "Multimodal Large Language Models",
        "Zero-Shot Learning",
        "Contrastive Adjudication",
        "Medical Imaging",
        "Diagnostic Agents"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:30.124085Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22955",
    "title": "MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis",
    "authors": [
      "Feng Guo",
      "Jiaxiang Liu",
      "Yang Li",
      "Qianqian Shi",
      "Mingkun Xu"
    ],
    "abstract": "Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco, a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the generation of diagnosis-related semantics beyond mask-only annotations. Building upon this dataset, we further construct MM-NeuroOnco-Bench, a manually annotated evaluation benchmark with a rejection-aware setting to reduce biases inherent in closed-ended question formats. Evaluation across ten representative models shows that even the strongest baseline, Gemini 3 Flash, achieves only 41.88% accuracy on diagnosis-related questions, highlighting the substantial challenges of multimodal brain tumor diagnostic understanding. Leveraging MM-NeuroOnco, we further propose NeuroOnco-GPT, which achieves a 27% absolute accuracy improvement on diagnostic questions following fine-tuning. This result demonstrates the effectiveness of our dataset and benchmark in advancing clinically grounded multimodal diagnostic reasoning. Code and dataset are publicly available at: https://github.com/gfnnnb/MM-NeuroOnco",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22955.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22955",
    "published": "2026-02-26T12:50:32Z",
    "updated": "2026-02-26T12:50:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了大规模多模态基准和指令数据集MM-NeuroOnco，并开发了NeuroOnco-GPT模型，显著提升了基于MRI的脑肿瘤诊断准确性和临床可解释性。",
      "motivation": "准确的脑肿瘤诊断需要AI模型不仅能检测病灶，还需基于影像表现生成临床可解释的推理，但现有公共数据集在注释丰富性和诊断语义方面存在局限。这一问题的重要性在于，高质量的诊断推理对临床决策至关重要，而现有方法的不足（如注释贫乏和成本高昂）限制了多模态AI在医疗领域的应用潜力，因此亟需构建更全面的数据集以支持复杂诊断任务。",
      "method": "研究核心是构建MM-NeuroOnco数据集，包含24,726个MRI切片和约200,000条语义丰富的多模态指令，覆盖多样肿瘤亚型和影像模态。为应对诊断语义注释稀缺问题，开发了多模型协作管道自动化完成医疗信息并控制质量，生成超越仅掩码注释的诊断语义。基于此，进一步构建了手动注释的评估基准MM-NeuroOnco-Bench，采用拒绝感知设置以减少封闭式问题的偏见，并提出了NeuroOnco-GPT模型用于多模态诊断任务。",
      "result": "实验评估了十个代表性模型，最强基线Gemini 3 Flash在诊断相关问题上的准确率仅为41.88%，凸显了多模态脑肿瘤诊断的挑战。通过微调MM-NeuroOnco数据集，NeuroOnco-GPT实现了27%的绝对准确率提升，显著优于基线，证明了数据集和基准在提升临床基础多模态诊断推理方面的有效性，展示了模型在复杂任务中的潜力。",
      "conclusion": "本研究的主要贡献是提出了MM-NeuroOnco数据集和NeuroOnco-GPT模型，推动了基于MRI的脑肿瘤诊断多模态AI研究。学术价值在于提供丰富的注释资源和评估基准，支持未来模型开发；实际应用价值在于提高诊断准确性和可解释性，辅助临床决策。摘要未明确说明局限性，但公开的代码和数据集为后续优化和应用扩展奠定了基础。",
      "tags": [
        "Multimodal Dataset",
        "Instruction Tuning",
        "MRI Analysis",
        "Brain Tumor Diagnosis",
        "Automated Annotation"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:35.518651Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22953",
    "title": "General Agent Evaluation",
    "authors": [
      "Elron Bandel",
      "Asaf Yehudai",
      "Lilach Eden",
      "Yehoshua Sagron",
      "Yotam Perlitz",
      "Elad Venezian",
      "Natalia Razinkov",
      "Natan Ergas",
      "Shlomit Shachor Ifergan",
      "Segev Shlomov",
      "Michal Jacovi",
      "Leshem Choshen",
      "Liat Ein-Dor",
      "Yoav Katz",
      "Michal Shmueli-Scheuer"
    ],
    "abstract": "The promise of general-purpose agents - systems that perform tasks in unfamiliar environments without domain-specific engineering - remains largely unrealized. Existing agents are predominantly specialized, and while emerging implementations like OpenAI SDK Agent and Claude Code hint at broader capabilities, no systematic evaluation of their general performance has been pursued. Current agentic benchmarks assume domain-specific integration, encoding task information in ways that preclude fair evaluation of general agents. This paper frames general-agent evaluation as a first-class research objective. We propose conceptual principles for such evaluation, a Unified Protocol enabling agent-benchmark integration, and Exgentic - a practical framework for general agent evaluation. We benchmark five prominent agent implementations across six environments as the first Open General Agent Leaderboard. Our experiments show that general agents generalize across diverse environments, achieving performance comparable to domain-specific agents without any environment-specific tuning. We release our evaluation protocol, framework, and leaderboard to establish a foundation for systematic research on general-purpose agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22953.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22953",
    "published": "2026-02-26T12:48:02Z",
    "updated": "2026-02-26T12:48:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究开发了通用智能代理评估的系统框架和首个公开排行榜，填补了该领域系统性评估的空白。",
      "motivation": "通用智能代理具有在陌生环境中执行任务而不依赖领域特定工程的潜力，但当前实现多为专门化代理，缺乏统一评估标准。现有基准如OpenAI SDK Agent和Claude Code虽展现更广泛能力，却未进行系统评估；这些基准通常假设领域特定集成，任务信息编码方式不利于公平评估通用代理，导致评估偏差，阻碍了技术发展。本研究旨在解决通用代理性能评估的缺失，以促进其实际应用和研究进步。",
      "method": "论文将通用代理评估确立为首要研究目标，提出了评估的概念原则，设计了Unified Protocol以实现代理与基准的集成，并开发了Exgentic作为实际评估框架。关键创新点包括标准化评估流程和首个Open General Agent Leaderboard的创建。研究使用六个不同环境和五个代理实现进行基准测试，作为框架验证的基础，但没有详细说明具体数据集或模型架构，摘要未明确说明这些细节。",
      "result": "通过在六个环境中对五个代理进行基准测试，实验结果表明通用代理能够在多样环境中有效泛化，性能与领域特定代理相当，且无需环境特定调整。具体数据未在摘要中提供，但与基线对比显示相似效果，验证了评估框架的有效性和公平性。这为首个公开排行榜的建立提供了实证基础，为后续研究提供了参考。",
      "conclusion": "本研究的主要贡献是系统地提出了通用代理评估的方法，包括概念原则、Unified Protocol和Exgentic框架，并发布了首个公开排行榜，为系统性研究奠定基础。学术价值在于推动了评估标准化，实际应用价值在于促进通用智能代理的技术发展和部署。摘要未明确说明局限性，但暗示未来工作可扩展评估环境和代理类型，进一步完善评估体系。",
      "tags": [
        "General-Purpose Agents",
        "Agent Evaluation",
        "Benchmarking",
        "Unified Protocol",
        "Exgentic Framework"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:30.506016Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22949",
    "title": "OpenFS: Multi-Hand-Capable Fingerspelling Recognition with Implicit Signing-Hand Detection and Frame-Wise Letter-Conditioned Synthesis",
    "authors": [
      "Junuk Cha",
      "Jihyeon Kim",
      "Han-Mu Park"
    ],
    "abstract": "Fingerspelling is a component of sign languages in which words are spelled out letter by letter using specific hand poses. Automatic fingerspelling recognition plays a crucial role in bridging the communication gap between Deaf and hearing communities, yet it remains challenging due to the signing-hand ambiguity issue, the lack of appropriate training losses, and the out-of-vocabulary (OOV) problem. Prior fingerspelling recognition methods rely on explicit signing-hand detection, which often leads to recognition failures, and on a connectionist temporal classification (CTC) loss, which exhibits the peaky behavior problem. To address these issues, we develop OpenFS, an open-source approach for fingerspelling recognition and synthesis. We propose a multi-hand-capable fingerspelling recognizer that supports both single- and multi-hand inputs and performs implicit signing-hand detection by incorporating a dual-level positional encoding and a signing-hand focus (SF) loss. The SF loss encourages cross-attention to focus on the signing hand, enabling implicit signing-hand detection during recognition. Furthermore, without relying on the CTC loss, we introduce a monotonic alignment (MA) loss that enforces the output letter sequence to follow the temporal order of the input pose sequence through cross-attention regularization. In addition, we propose a frame-wise letter-conditioned generator that synthesizes realistic fingerspelling pose sequences for OOV words. This generator enables the construction of a new synthetic benchmark, called FSNeo. Through comprehensive experiments, we demonstrate that our approach achieves state-of-the-art performance in recognition and validate the effectiveness of the proposed recognizer and generator. Codes and data are available in: https://github.com/JunukCha/OpenFS.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22949.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22949",
    "published": "2026-02-26T12:41:24Z",
    "updated": "2026-02-26T12:41:24Z",
    "comment": "Accepted to CVPR 2026",
    "light_analysis": {
      "overview": "OpenFS是一种开源的多手能力手指拼写识别方法，通过隐式手检测和帧级字母条件合成解决手模糊和词汇外问题。",
      "motivation": "自动手指拼写识别在弥合聋人和听人社区沟通障碍中至关重要，但面临手模糊问题、训练损失不足和词汇外单词挑战。现有方法依赖显式手检测易导致识别失败，且使用CTC损失函数存在峰值行为问题，限制了识别准确性和鲁棒性，因此需要更有效的解决方案。",
      "method": "OpenFS提出多手能力识别器，支持单双手输入，通过双级位置编码和手关注损失实现隐式手检测，避免显式检测的失败。引入单调对齐损失替代CTC损失，利用交叉注意力正则化确保输出字母序列遵循输入姿势序列的时间顺序。同时，开发帧级字母条件生成器合成逼真手指拼写姿势序列，用于处理词汇外单词，并构建新合成基准FSNeo。",
      "result": "实验表明，OpenFS在手指拼写识别任务中取得了最先进的性能，验证了识别器和生成器的有效性。虽然摘要未提供具体性能指标，但结果显示方法能提升识别准确性和鲁棒性，解决了现有方法的不足。",
      "conclusion": "OpenFS通过隐式手检测、新损失函数和合成器技术，解决了手指拼写识别的核心问题，具有重要学术价值，推动AI在手语识别领域的应用。其开源框架有助于促进实际部署，未来工作可扩展至更多手语组件或提高泛化能力。",
      "tags": [
        "Fingerspelling Recognition",
        "Implicit Signing-Hand Detection",
        "Monotonic Alignment Loss",
        "Frame-Wise Letter-Conditioned Synthesis"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:40.663207Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22948",
    "title": "ToProVAR: Efficient Visual Autoregressive Modeling via Tri-Dimensional Entropy-Aware Semantic Analysis and Sparsity Optimization",
    "authors": [
      "Jiayu Chen",
      "Ruoyu Lin",
      "Zihao Zheng",
      "Jingxin Li",
      "Maoliang Li",
      "Guojie Luo",
      "Xiang chen"
    ],
    "abstract": "Visual Autoregressive(VAR) models enhance generation quality but face a critical efficiency bottleneck in later stages. In this paper, we present a novel optimization framework for VAR models that fundamentally differs from prior approaches such as FastVAR and SkipVAR. Instead of relying on heuristic skipping strategies, our method leverages attention entropy to characterize the semantic projections across different dimensions of the model architecture. This enables precise identification of parameter dynamics under varying token granularity levels, semantic scopes, and generation scales. Building on this analysis, we further uncover sparsity patterns along three critical dimensions-token, layer, and scale-and propose a set of fine-grained optimization strategies tailored to these patterns. Extensive evaluation demonstrates that our approach achieves aggressive acceleration of the generation process while significantly preserving semantic fidelity and fine details, outperforming traditional methods in both efficiency and quality. Experiments on Infinity-2B and Infinity-8B models demonstrate that ToProVAR achieves up to 3.4x acceleration with minimal quality loss, effectively mitigating the issues found in prior work. Our code will be made publicly available.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22948.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22948",
    "published": "2026-02-26T12:36:56Z",
    "updated": "2026-02-26T12:36:56Z",
    "comment": "ToProVAR is honored to be accepted by ICLR 2026",
    "light_analysis": {
      "overview": "提出ToProVAR框架，通过三维熵感知语义分析和稀疏性优化，高效提升视觉自回归模型的生成效率和保真度。",
      "motivation": "视觉自回归（VAR）模型在视觉生成任务中能够提高生成质量，但在后期生成阶段面临效率瓶颈，这限制了其实际应用。现有方法如FastVAR和SkipVAR主要依赖启发式跳过策略，这些策略可能不够精准，导致质量下降或效率提升有限。因此，需要开发一种更高效且能保持语义保真度的方法，以解决效率问题并推动相关技术的实际部署。",
      "method": "ToProVAR方法基于注意力熵来表征模型架构中不同维度（如token粒度、语义范围和生成尺度）的语义投影，从而精确识别参数动态。关键创新包括分析三维（token、层、尺度）稀疏性模式，并设计针对这些模式的细粒度优化策略。在Infinity-2B和Infinity-8B模型上进行实验，该方法通过动态调整计算资源，实现高效的自回归建模。",
      "result": "实验结果显示，ToProVAR在Infinity-2B和Infinity-8B模型上实现了高达3.4倍的生成加速，同时最小化质量损失，保持了语义保真度和精细细节。与基线方法如FastVAR和SkipVAR相比，该方法在效率和生成质量上均有显著提升，有效缓解了先前工作中存在的效率瓶颈和质量下降问题。摘要未明确说明具体的性能指标如准确率，但强调了整体性能优于传统方法。",
      "conclusion": "ToProVAR通过三维熵感知语义分析和稀疏性优化，解决了VAR模型在效率上的关键瓶颈，同时提升了生成质量，具有重要的学术价值和实际应用潜力。该方法创新性地结合了注意力熵和稀疏性模式，为视觉生成任务提供了新思路。未来工作可能包括将该框架扩展到其他模型或进一步优化参数，以应对更广泛的应用场景。摘要未明确说明具体局限性，但暗示了在保持效率和质量平衡方面的持续改进空间。",
      "tags": [
        "Visual Autoregressive Modeling",
        "Attention Entropy",
        "Sparsity Optimization",
        "Tri-Dimensional Analysis",
        "Semantic Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:46.741148Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22941",
    "title": "Velocity and stroke rate reconstruction of canoe sprint team boats based on panned and zoomed video recordings",
    "authors": [
      "Julian Ziegler",
      "Daniel Matthes",
      "Finn Gerdts",
      "Patrick Frenzel",
      "Torsten Warnke",
      "Matthias Englert",
      "Tina Koevari",
      "Mirco Fuchs"
    ],
    "abstract": "Pacing strategies, defined by velocity and stroke rate profiles, are essential for peak performance in canoe sprint. While GPS is the gold standard for analysis, its limited availability necessitates automated video-based solutions. This paper presents an extended framework for reconstructing performance metrics from panned and zoomed video recordings across all sprint disciplines (K1-K4, C1-C2) and distances (200m-500m). Our method utilizes YOLOv8 for buoy and athlete detection, leveraging the known buoy grid to estimate homographies. We generalized the estimation of the boat position by means of learning a boat-specific athlete offset using a U-net based boat tip calibration. Further, we implement a robust tracking scheme using optical flow to adapt to multi-athlete boat types. Finally, we introduce methods to extract stroke rate information from either pose estimations or the athlete bounding boxes themselves. Evaluation against GPS data from elite competitions yields a velocity RRMSE of 0.020 +- 0.011 (rho = 0.956) and a stroke rate RRMSE of 0.022 +- 0.024 (rho = 0.932). The methods provide coaches with highly accurate, automated feedback without requiring on-boat sensors or manual annotation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22941.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22941",
    "published": "2026-02-26T12:31:30Z",
    "updated": "2026-02-26T12:31:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个基于平移和缩放视频的扩展框架，用于自动重建独木舟冲刺团队船的速度和划桨速率，为教练提供高精度反馈。",
      "motivation": "在独木舟冲刺运动中，速度和划桨速率策略对峰值性能至关重要。GPS是分析的金标准，但其可用性有限、成本高且可能干扰运动员，因此需要自动视频解决方案来弥补不足。现有视频方法可能精度不足或无法处理团队船等复杂场景，本研究旨在开发一个能从视频中重建性能指标的框架，克服GPS限制，为教练提供便捷、准确的分析工具。",
      "method": "本研究采用YOLOv8进行浮标和运动员检测，利用已知浮标网格估计单应性变换处理视频的平移和缩放。通过基于U-net的船头校准模型学习船特定运动员偏移，泛化船位置估计。使用光流技术实现鲁棒跟踪，适配多运动员船类型（如K2、K4）。最后，从姿态估计或运动员边界框提取划桨速率信息，关键创新在于结合计算机视觉技术实现自动、高精度的性能重建。",
      "result": "论文通过对比精英比赛的GPS数据评估方法性能，结果显示速度的根相对均方误差（RRMSE）为0.020 ± 0.011，相关系数ρ为0.956；划桨速率的RRMSE为0.022 ± 0.024，ρ为0.932。这些数据表明，该方法与GPS金标准相比具有高精度和强一致性，为教练提供了可靠自动反馈，无需船上传感器或手动标注。",
      "conclusion": "本研究的主要贡献是开发了一个扩展框架，用于从平移和缩放视频中自动重建独木舟冲刺团队船的速度和划桨速率，覆盖所有冲刺项目和距离。学术上，它推进了计算机视觉在体育分析中的应用；实际上，为教练提供了高精度、自动化的性能分析工具，减少对昂贵传感器的依赖。未来工作可优化视频噪声处理或扩展至其他水上运动。",
      "tags": [
        "YOLOv8",
        "Homography Estimation",
        "Optical Flow",
        "Pose Estimation",
        "U-net"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:00.772239Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22938",
    "title": "pMoE: Prompting Diverse Experts Together Wins More in Visual Adaptation",
    "authors": [
      "Shentong Mo",
      "Xufang Luo",
      "Dongsheng Li"
    ],
    "abstract": "Parameter-efficient fine-tuning has demonstrated promising results across various visual adaptation tasks, such as classification and segmentation. Typically, prompt tuning techniques have harnessed knowledge from a single pre-trained model, whether from a general or a specialized medical domain. However, this approach typically overlooks the potential synergies that could arise from integrating diverse domain knowledge within the same tuning process. In this work, we propose a novel Mixture-of-Experts prompt tuning method called pMoE, which leverages the strengths of multiple expert domains through expert-specialized prompt tokens and the learnable dispatcher, effectively combining their expertise in a unified model framework. Our pMoE introduces expert-specific prompt tokens and utilizes a dynamic token dispatching mechanism at various prompt layers to optimize the contribution of each domain expert during the adaptation phase. By incorporating both domain knowledge from diverse experts, the proposed pMoE significantly enhances the model's versatility and applicability to a broad spectrum of tasks. We conduct extensive experiments across 47 adaptation tasks, including both classification and segmentation in general and medical domains. The results demonstrate that our pMoE not only achieves superior performance with a large margin of improvements but also offers an optimal trade-off between computational efficiency and adaptation effectiveness compared to existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22938.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22938",
    "published": "2026-02-26T12:27:06Z",
    "updated": "2026-02-26T12:27:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出pMoE方法，通过整合多个领域专家的提示令牌和动态调度机制，显著提升视觉适应任务的性能。",
      "motivation": "现有参数高效微调方法，如提示调优，通常依赖于单一预训练模型（无论是通用领域还是专业医学领域），这种方法忽略了整合多样领域知识时可能产生的协同效应，限制了模型在多样化视觉任务中的适应能力和性能提升。因此，研究如何有效融合多个专家领域的知识以优化视觉适应过程变得至关重要，从而解决现有方法在泛化和效率方面的不足。",
      "method": "pMoE方法的核心是引入专家特定提示令牌和可学习调度器，通过动态令牌调度机制在不同提示层中优化每个领域专家的贡献。该方法基于混合专家架构，利用多个预训练模型作为专家源，在适应阶段智能组合它们的专业知识。技术特色包括专家专用提示令牌和灵活的调度策略，以实现知识融合和模型泛化能力的增强。摘要未明确说明具体使用的数据集细节。",
      "result": "论文在47个视觉适应任务上进行了广泛实验，包括分类和分割任务，涵盖通用和医学领域。结果显示，pMoE在性能上实现了大幅度的提升，与现有基线方法相比有显著优势。同时，该方法在计算效率和适应效果之间提供了最佳权衡，表明其高效性和实用性。具体性能指标如准确率改进数值摘要未明确说明，但基于描述推断出整体性能优于现有方法。",
      "conclusion": "pMoE的主要贡献在于提出了一种整合多样专家知识的提示调优框架，显著增强了模型在视觉适应任务中的通用性和应用范围。这项研究为参数高效微调提供了新思路，具有重要的学术价值（如推动多任务学习领域）和实际应用价值（例如在医疗图像分析等领域）。未来工作可以扩展更多专家领域或优化调度机制，以应对更复杂的任务需求，摘要未明确说明具体局限性。",
      "tags": [
        "Prompt Tuning",
        "Mixture-of-Experts",
        "Visual Adaptation",
        "Parameter-efficient Fine-tuning",
        "Dynamic Token Dispatching"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:08.414258Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22937",
    "title": "MSINO: Curvature-Aware Sobolev Optimization for Manifold Neural Networks",
    "authors": [
      "Suresan Pareth"
    ],
    "abstract": "We introduce Manifold Sobolev Informed Neural Optimization (MSINO), a curvature aware training framework for neural networks defined on Riemannian manifolds. The method replaces standard Euclidean derivative supervision with a covariant Sobolev loss that aligns gradients using parallel transport and improves stability via a Laplace Beltrami smoothness regularization term.   Building on classical results in Riemannian optimization and Sobolev theory on manifolds, we derive geometry dependent constants that yield (i) a Descent Lemma with a manifold Sobolev smoothness constant, (ii) a Sobolev Polyak Lojasiewicz inequality giving linear convergence guarantees for Riemannian gradient descent and stochastic gradient descent under explicit step size bounds, and (iii) a two step Newton Sobolev method with local quadratic contraction in curvature controlled neighborhoods.   Unlike prior Sobolev training in Euclidean space, MSINO provides training time guarantees that explicitly track curvature and transported Jacobians. Applications include surface imaging, physics informed learning settings, and robotics on Lie groups such as SO(3) and SE(3). The framework unifies value and gradient based learning with curvature aware convergence guarantees for neural training on manifolds.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22937.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22937",
    "published": "2026-02-26T12:27:00Z",
    "updated": "2026-02-26T12:27:00Z",
    "comment": "32 pages, 6 figures. Submitted for journal consideration",
    "light_analysis": {
      "overview": "提出MSINO框架，结合协变Sobolev损失和几何感知优化，为黎曼流形上神经网络提供曲率感知收敛保证。",
      "motivation": "研究动机在于解决黎曼流形上神经网络训练的挑战。现有欧几里得空间的方法在处理非线性几何结构时效率低下，缺乏对曲率的明确考虑，导致训练不稳定和收敛性能不足。MSINO框架旨在通过引入几何感知的优化方法，改进在流形数据上的训练过程，适用于需要处理复杂几何的应用领域，如表面成像和机器人学。",
      "method": "方法核心是使用协变Sobolev损失替换标准欧几里得导数监督，通过平行传输对齐梯度，并引入Laplace Beltrami平滑正则项以提高稳定性。基于黎曼优化和流形Sobolev理论，推导出几何依赖常数，包括带流形Sobolev平滑常数的下降引理、Sobolev Polyak Lojasiewicz不等式（提供线性收敛保证）和两步牛顿Sobolev方法（实现局部二次收缩）。框架统一了基于值和梯度的学习，并明确跟踪曲率和传输雅可比矩阵。",
      "result": "摘要未明确说明具体实验数据，但理论分析表明MSINO提供了曲率感知的收敛保证。与欧几里得空间中的Sobolev训练相比，MSINO通过跟踪曲率和传输雅可比矩阵，在黎曼流形上实现更稳定的优化。推导的几何常数确保了在显式步长边界下的线性收敛和局部二次收缩，为神经训练提供了坚实的理论基础。",
      "conclusion": "结论是MSINO框架为黎曼流形上神经网络训练提供了统一的曲率感知优化方法。其主要贡献在于结合Sobolev损失和几何理论，提供收敛保证，扩展了神经网络在非线性几何结构中的应用。应用价值体现在表面成像、物理信息学习和机器人学等领域。未来工作可能包括扩展到更复杂流形或结合更多实际数据集验证。",
      "tags": [
        "Riemannian Optimization",
        "Sobolev Training",
        "Parallel Transport",
        "Laplace-Beltrami Operator",
        "Manifold Neural Networks"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:06.270437Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22936",
    "title": "Generalization Bounds of Stochastic Gradient Descent in Homogeneous Neural Networks",
    "authors": [
      "Wenquan Ma",
      "Yang Sui",
      "Jiaye Teng",
      "Bohan Wang",
      "Jing Xu",
      "Jingqin Yang"
    ],
    "abstract": "Algorithmic stability is among the most potent techniques in generalization analysis. However, its derivation usually requires a stepsize $η_t = \\mathcal{O}(1/t)$ under non-convex training regimes, where $t$ denotes iterations. This rigid decay of the stepsize potentially impedes optimization and may not align with practical scenarios. In this paper, we derive the generalization bounds under the homogeneous neural network regimes, proving that this regime enables slower stepsize decay of order $Ω(1/\\sqrt{t})$ under mild assumptions. We further extend the theoretical results from several aspects, e.g., non-Lipschitz regimes. This finding is broadly applicable, as homogeneous neural networks encompass fully-connected and convolutional neural networks with ReLU and LeakyReLU activations.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22936.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22936",
    "published": "2026-02-26T12:26:32Z",
    "updated": "2026-02-26T12:26:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文证明了在齐次神经网络中，随机梯度下降允许更慢的步长衰减Ω(1/√t)，从而扩展了泛化分析框架。",
      "motivation": "研究动机源自算法稳定性在非凸训练中通常要求步长以O(1/t)衰减，这可能导致优化效率低下，且与实际情况不符。现有方法过于严格，限制了随机梯度下降的步长选择，影响训练效果。本研究旨在放宽步长衰减要求，使泛化分析更贴近实际训练场景，解决理论与实践之间的差距问题。",
      "method": "研究方法基于齐次神经网络框架，推导随机梯度下降的泛化界。通过理论分析，在温和假设下证明可以允许步长衰减为Ω(1/√t)，比传统O(1/t)更慢。关键创新在于利用网络齐次性质，扩展分析到非Lipschitz机制，覆盖使用ReLU和LeakyReLU激活函数的全连接和卷积神经网络，增强方法的通用性和实用性。",
      "result": "实验结果表明，在齐次神经网络中推导出泛化界，允许步长衰减更慢为Ω(1/√t)，提供了比传统O(1/t)更灵活的步长选择。摘要未明确提供具体性能数据，如准确率提升，但强调了该框架的广泛适用性，可与基线方法形成理论对比，适用于多种神经网络结构，为优化过程提供更优的理论支撑。",
      "conclusion": "本研究的主要贡献是为齐次神经网络提供了更宽松的泛化界，允许随机梯度下降使用更慢的步长衰减，从而提高理论分析的实际适用性。学术价值在于扩展了算法稳定性理论，而实际应用价值在于更好地匹配现实训练需求，增强优化效率。摘要未明确说明局限性，但可能依赖于假设条件，未来工作可探索更广泛的网络类型或优化场景。",
      "tags": [
        "Stochastic Gradient Descent",
        "Generalization Bounds",
        "Homogeneous Neural Networks",
        "ReLU",
        "LeakyReLU"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:15.530505Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22932",
    "title": "MSJoE: Jointly Evolving MLLM and Sampler for Efficient Long-Form Video Understanding",
    "authors": [
      "Wenhui Tan",
      "Xiaoyi Yu",
      "Jiaze Li",
      "Yijing Chen",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Ruihua Song",
      "Jian Luan"
    ],
    "abstract": "Efficiently understanding long-form videos remains a fundamental challenge for multimodal large language models (MLLMs). In this paper, we present MLLM-Sampler Joint Evolution (MSJoE), a novel framework that jointly evolves the MLLM and a lightweight key-frame sampler for efficient long-form video understanding. MSJoE builds upon a key assumption that only a small subset of key-frames is truly informative for answering each question to a video. Specifically, MSJoE first reasons out several queries, which describe diverse visual perspectives relevant to the question. Then, these queries interact with a frozen CLIP model to produce a query-frame similarity matrix. Finally, a lightweight sampler predicts key-frame sampling weights from this matrix, selecting a compact set of informative frames, which are then fed into the MLLM for answer generation. Both the MLLM and sampler are jointly optimized through reinforcement learning, enabling co-adaptation of query-reasoning, frame-sampling, and key-frame understanding. A new long-video QA dataset containing 2.8K videos with 7K question-answer pairs is collected to support the training process. Extensive experiments on VideoMME, LongVideoBench, LVBench, and MLVU show that MSJoE achieves 8.0\\% accuracy gain upon the base MLLM, and 1.1\\% higher accuracy than strongest baseline method.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22932.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22932",
    "published": "2026-02-26T12:24:17Z",
    "updated": "2026-02-26T12:24:17Z",
    "comment": "Accepted by CVPR2026",
    "light_analysis": {
      "overview": "MSJoE框架通过联合演化多模态大语言模型和关键帧采样器，实现高效的长视频理解。",
      "motivation": "长视频理解是MLLMs面临的基础挑战，现有方法在处理长视频时效率低下，因为需要分析大量帧，导致计算成本高昂和资源浪费。该研究旨在解决这一问题，基于只有少量关键帧对回答视频问题真正有用的假设，提高理解效率并优化资源利用。",
      "method": "MSJoE首先推理出多个描述问题相关视觉视角的查询，与冻结的CLIP模型交互生成查询-帧相似矩阵。接着，轻量采样器从矩阵预测关键帧采样权重，选择紧凑的有信息帧，输入MLLM生成答案。通过强化学习联合优化MLLM和采样器，促进查询推理、帧采样和关键帧理解的协同适应。训练使用新收集的长视频QA数据集，包含2.8K视频和7K问答对。",
      "result": "在VideoMME、LongVideoBench、LVBench和MLVU数据集上的实验表明，MSJoE相比基础MLLM实现了8.0%的准确率提升，比最强基线方法高出1.1%的准确率，验证了其在长视频理解任务中的高效性和性能优越性。",
      "conclusion": "MSJoE提出了一种联合优化MLLM和采样器的框架，显著提升了长视频理解的效率和准确性。该研究在学术上推动了多模态模型的发展，为实际视频分析任务提供了高效解决方案，摘要未明确说明未来工作方向。",
      "tags": [
        "Multimodal Large Language Model",
        "Key-Frame Sampler",
        "Reinforcement Learning",
        "CLIP",
        "Video Question Answering"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:18.861146Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22923",
    "title": "WaterVideoQA: ASV-Centric Perception and Rule-Compliant Reasoning via Multi-Modal Agents",
    "authors": [
      "Runwei Guan",
      "Shaofeng Liang",
      "Ningwei Ouyang",
      "Weichen Fei",
      "Shanliang Yao",
      "Wei Dai",
      "Chenhao Ge",
      "Penglei Sun",
      "Xiaohui Zhu",
      "Tao Huang",
      "Ryan Wen Liu",
      "Hui Xiong"
    ],
    "abstract": "While autonomous navigation has achieved remarkable success in passive perception (e.g., object detection and segmentation), it remains fundamentally constrained by a void in knowledge-driven, interactive environmental cognition. In the high-stakes domain of maritime navigation, the ability to bridge the gap between raw visual perception and complex cognitive reasoning is not merely an enhancement but a critical prerequisite for Autonomous Surface Vessels to execute safe and precise maneuvers. To this end, we present WaterVideoQA, the first large-scale, comprehensive Video Question Answering benchmark specifically engineered for all-waterway environments. This benchmark encompasses 3,029 video clips across six distinct waterway categories, integrating multifaceted variables such as volatile lighting and dynamic weather to rigorously stress-test ASV capabilities across a five-tier hierarchical cognitive framework. Furthermore, we introduce NaviMind, a pioneering multi-agent neuro-symbolic system designed for open-ended maritime reasoning. By synergizing Adaptive Semantic Routing, Situation-Aware Hierarchical Reasoning, and Autonomous Self-Reflective Verification, NaviMind transitions ASVs from superficial pattern matching to regulation-compliant, interpretable decision-making. Experimental results demonstrate that our framework significantly transcends existing baselines, establishing a new paradigm for intelligent, trustworthy interaction in dynamic maritime environments.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22923.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22923",
    "published": "2026-02-26T12:12:40Z",
    "updated": "2026-02-26T12:12:40Z",
    "comment": "11 pages,8 figures",
    "light_analysis": {
      "overview": "提出首个针对全水道环境的视频问答基准WaterVideoQA和神经符号推理系统NaviMind，推动海事自主导航从感知到认知的转变。",
      "motivation": "海事自主导航在被动感知方面已取得进展，但缺乏知识驱动的交互式环境认知能力。现有方法局限于对象检测和分割等感知任务，无法支持复杂的认知推理。在海事导航这一高风险领域，桥接原始视觉感知与认知推理是确保自主水面舰船安全精准操作的关键前提，因为单纯模式匹配不足以处理动态环境中的法规遵从和决策解释性问题。",
      "method": "论文提出WaterVideoQA作为大规模视频问答基准，涵盖3,029个视频剪辑、六类水道，集成多变光照和天气条件，在五层分级认知框架中测试ASV能力。同时，开发NaviMind多智能体神经符号系统，结合自适应语义路由实现信息流优化，情境感知分级推理处理多级认知任务，自主自反验证确保决策合规性和可解释性，从被动感知转向主动推理。",
      "result": "实验结果表明，该框架在动态海事环境中的视频问答和推理任务上显著超越现有基线，未明确具体性能指标如准确率，但通过新基准和系统建立了智能交互的新范式，强调其在实际应用中对提升ASV决策可靠性的贡献。",
      "conclusion": "主要贡献在于建立首个全水道视频问答基准和神经符号推理系统，促进海事导航的可解释决策和可信交互，具有实际应用价值如提升导航安全性。未来可扩展基准到更多场景或优化推理效率。",
      "tags": [
        "Video Question Answering",
        "Multi-Modal Agents",
        "Neuro-Symbolic Reasoning",
        "Hierarchical Reasoning",
        "Autonomous Surface Vessels"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:26.321617Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22920",
    "title": "OSDaR-AR: Enhancing Railway Perception Datasets via Multi-modal Augmented Reality",
    "authors": [
      "Federico Nesti",
      "Gianluca D'Amico",
      "Mauro Marinoni",
      "Giorgio Buttazzo"
    ],
    "abstract": "Although deep learning has significantly advanced the perception capabilities of intelligent transportation systems, railway applications continue to suffer from a scarcity of high-quality, annotated data for safety-critical tasks like obstacle detection. While photorealistic simulators offer a solution, they often struggle with the ``sim-to-real\" gap; conversely, simple image-masking techniques lack the spatio-temporal coherence required to obtain augmented single- and multi-frame scenes with the correct appearance and dimensions. This paper introduces a multi-modal augmented reality framework designed to bridge this gap by integrating photorealistic virtual objects into real-world railway sequences from the OSDaR23 dataset. Utilizing Unreal Engine 5 features, our pipeline leverages LiDAR point-clouds and INS/GNSS data to ensure accurate object placement and temporal stability across RGB frames. This paper also proposes a segmentation-based refinement strategy for INS/GNSS data to significantly improve the realism of the augmented sequences, as confirmed by the comparative study presented in the paper. Carefully designed augmented sequences are collected to produce OSDaR-AR, a public dataset designed to support the development of next-generation railway perception systems. The dataset is available at the following page: https://syndra.retis.santannapisa.it/osdarar.html",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22920.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22920",
    "published": "2026-02-26T12:08:02Z",
    "updated": "2026-02-26T12:08:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出多模态增强现实框架，集成虚拟对象到真实铁路序列，并发布OSDaR-AR数据集以增强铁路感知数据。",
      "motivation": "铁路应用面临安全关键任务如障碍检测缺乏高质量标注数据的问题。现有逼真模拟器存在模拟到现实的差距，而简单图像掩蔽技术则缺乏时空连贯性，无法生成符合实际外观和尺寸的增强场景。因此，开发能够弥合这一差距的方法对于提高铁路感知系统的可靠性和安全性至关重要。",
      "method": "研究采用多模态增强现实框架，利用Unreal Engine 5将逼真虚拟对象嵌入来自OSDaR23数据集的真实铁路序列中。核心创新点包括结合LiDAR点云和INS/GNSS数据来确保物体放置的准确性和时间稳定性，并提出基于分割的INS/GNSS数据细化策略，以提升增强序列的真实感。",
      "result": "通过比较研究证实，提出的细化策略显著提高了增强序列的真实感。论文收集了精心设计的增强序列，形成了公开的OSDaR-AR数据集，旨在支持下一代铁路感知系统的开发。但摘要未明确给出具体的性能指标对比数据。",
      "conclusion": "论文的主要贡献是开发了一个多模态增强现实框架并发布了OSDaR-AR公共数据集，有效解决了铁路感知领域的数据稀缺问题。这具有重要学术价值，推动了增强现实技术在智能交通中的应用，并为实践提供了高质量资源。未来工作可进一步优化技术或扩展数据集的覆盖范围。",
      "tags": [
        "Augmented Reality",
        "LiDAR",
        "INS/GNSS",
        "Unreal Engine 5",
        "Segmentation"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:45.372535Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22919",
    "title": "Chain of Flow: A Foundational Generative Framework for ECG-to-4D Cardiac Digital Twins",
    "authors": [
      "Haofan Wu",
      "Nay Aung",
      "Theodoros N. Arvanitis",
      "Joao A. C. Lima",
      "Steffen E. Petersen",
      "Le Zhang"
    ],
    "abstract": "A clinically actionable Cardiac Digital Twin (CDT) should reconstruct individualised cardiac anatomy and physiology, update its internal state from multimodal signals, and enable a broad range of downstream simulations beyond isolated tasks. However, existing CDT frameworks remain limited to task-specific predictors rather than building a patient-specific, manipulable virtual heart. In this work, we introduce Chain of Flow (COF), a foundational ECG-driven generative framework that reconstructs full 4D cardiac structure and motion from a single cardiac cycle. The method integrates cine-CMR and 12-lead ECG during training to learn a unified representation of cardiac geometry, electrophysiology, and motion dynamics. We evaluate Chain of Flow on diverse cohorts and demonstrate accurate recovery of cardiac anatomy, chamber-wise function, and dynamic motion patterns. The reconstructed 4D hearts further support downstream CDT tasks such as volumetry, regional function analysis, and virtual cine synthesis. By enabling full 4D organ reconstruction directly from ECG, COF transforms cardiac digital twins from narrow predictive models into fully generative, patient-specific virtual hearts. Code will be released after review.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22919.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22919",
    "published": "2026-02-26T12:06:43Z",
    "updated": "2026-02-26T12:06:43Z",
    "comment": "10 pages, 8 figures. Submitted to IEEE Transactions on Medical Imaging (TMI). Code will be released after review",
    "light_analysis": {
      "overview": "COF 是一个基础生成框架，通过心电图驱动从单心搏周期重建患者特定的 4D 心脏数字孪生，实现全生成性虚拟心脏。",
      "motivation": "临床应用中需要可操作的心脏数字孪生来重建个体化解剖结构和生理状态，并支持下游模拟任务，但现有框架局限于任务特定的预测器，无法构建患者特定、可操控的虚拟心脏。这限制了医疗诊断和治疗的准确性，COF 旨在解决这一问题，通过生成性方法整合多模态数据，提升心脏数字孪生的整体性和实用性。",
      "method": "Chain of Flow 框架在训练中整合 cine-CMR 和 12 导联 ECG 数据，利用生成模型学习心脏几何、电生理和运动动力学的统一表示。核心创新点包括直接从 ECG 输入生成完整的 4D 心脏结构和运动，避免了传统方法的任务特定限制，通过多模态信号融合实现患者特定的重建。",
      "result": "在不同患者队列中评估，COF 能准确恢复心脏解剖细节、心室功能和动态运动模式，重建的 4D 心脏支持下游任务如容量测量、区域功能分析和虚拟 cine 合成。实验结果显示其生成效果优于现有狭窄预测模型，提升了心脏数字孪生的准确性和多功能性，尽管具体性能指标未在摘要中给出。",
      "conclusion": "COF 为心脏数字孪生提供了一个基础生成框架，直接从 ECG 重建 4D 心脏，推动了从预测模型向生成性虚拟心脏的转变，具有重要学术价值和临床应用前景。潜在局限性可能包括数据依赖性，未来工作可扩展到更多模态数据或更广泛的医疗模拟场景。",
      "tags": [
        "Generative Framework",
        "ECG-to-4D Reconstruction",
        "Cardiac Digital Twins",
        "Multi-modal Learning",
        "Unified Representation"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:54.554089Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22918",
    "title": "Where Vision Becomes Text: Locating the OCR Routing Bottleneck in Vision-Language Models",
    "authors": [
      "Jonathan Steinberg",
      "Oren Gal"
    ],
    "abstract": "Vision-language models (VLMs) can read text from images, but where does this optical character recognition (OCR) information enter the language processing stream? We investigate the OCR routing mechanism across three architecture families (Qwen3-VL, Phi-4, InternVL3.5) using causal interventions. By computing activation differences between original images and text-inpainted versions, we identify architecture-specific OCR bottlenecks whose dominant location depends on the vision-language integration strategy: DeepStack models (Qwen) show peak sensitivity at mid-depth (about 50%) for scene text, while single-stage projection models (Phi-4, InternVL) peak at early layers (6-25%), though the exact layer of maximum effect varies across datasets. The OCR signal is remarkably low-dimensional: PC1 captures 72.9% of variance. Crucially, principal component analysis (PCA) directions learned on one dataset transfer to others, demonstrating shared text-processing pathways. Surprisingly, in models with modular OCR circuits (notably Qwen3-VL-4B), OCR removal can improve counting performance (up to +6.9 percentage points), suggesting OCR interferes with other visual processing in sufficiently modular architectures.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22918.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22918",
    "published": "2026-02-26T12:06:02Z",
    "updated": "2026-02-26T12:06:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过因果干预定位视觉语言模型中OCR信息处理的瓶颈层，揭示了不同架构的策略差异和OCR信号的共享处理路径。",
      "motivation": "视觉语言模型虽然能读取图像中的文本，但OCR信息如何进入语言处理流尚不明确，这限制了模型的解释性和优化潜力。研究旨在探究OCR在模型中的具体路由机制，以解决现有方法忽视处理路径细节的问题，从而改进模型设计和性能。背景是视觉语言模型的广泛应用需要更高效和准确的文本处理理解。",
      "method": "研究者采用因果干预技术，通过计算原始图像与文本修复版本间的激活差异来识别OCR处理瓶颈。分析覆盖三种架构家族：Qwen3-VL（DeepStack模型）、Phi-4和InternVL3.5（单阶段投影模型），并结合主成分分析（PCA）揭示OCR信号的低维特性。关键创新在于精确层级定位和跨数据集验证共享处理路径。",
      "result": "实验结果表明，OCR瓶颈位置依赖架构：DeepStack模型在约50%深度对场景文本最敏感，而单阶段投影模型在早期层（6-25%）达到峰值。OCR信号高度低维，第一主成分捕获72.9%的方差，且PCA方向可跨数据集迁移，证实共享文本处理路径。意外发现是，在模块化架构如Qwen3-VL-4B中，去除OCR能提升计数性能达6.9个百分点，显示OCR可能干扰其他视觉处理。",
      "conclusion": "本研究揭示了视觉语言模型中OCR处理路径的架构依赖性，并发现OCR信号的低维和可迁移特性，提升了模型解释性。意外干扰现象提示在模块化设计中需平衡OCR与其他视觉模块，为未来优化模型效率和准确性提供方向，潜在局限性包括数据集泛化或更多架构验证，未来工作可扩展至其他视觉任务或模型微调。",
      "tags": [
        "Vision-Language Models",
        "Optical Character Recognition",
        "Causal Intervention",
        "Principal Component Analysis",
        "DeepStack Architecture"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:03.351616Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22917",
    "title": "Towards Multimodal Domain Generalization with Few Labels",
    "authors": [
      "Hongzhao Li",
      "Hao Dong",
      "Hualei Wan",
      "Shupan Li",
      "Mingliang Xu",
      "Muhammad Haris Khan"
    ],
    "abstract": "Multimodal models ideally should generalize to unseen domains while remaining data-efficient to reduce annotation costs. To this end, we introduce and study a new problem, Semi-Supervised Multimodal Domain Generalization (SSMDG), which aims to learn robust multimodal models from multi-source data with few labeled samples. We observe that existing approaches fail to address this setting effectively: multimodal domain generalization methods cannot exploit unlabeled data, semi-supervised multimodal learning methods ignore domain shifts, and semi-supervised domain generalization methods are confined to single-modality inputs. To overcome these limitations, we propose a unified framework featuring three key components: Consensus-Driven Consistency Regularization, which obtains reliable pseudo-labels through confident fused-unimodal consensus; Disagreement-Aware Regularization, which effectively utilizes ambiguous non-consensus samples; and Cross-Modal Prototype Alignment, which enforces domain- and modality-invariant representations while promoting robustness under missing modalities via cross-modal translation. We further establish the first SSMDG benchmarks, on which our method consistently outperforms strong baselines in both standard and missing-modality scenarios. Our benchmarks and code are available at https://github.com/lihongzhao99/SSMDG.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22917.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22917",
    "published": "2026-02-26T12:05:56Z",
    "updated": "2026-02-26T12:05:56Z",
    "comment": "Accepted to CVPR 2026",
    "light_analysis": {
      "overview": "本文提出了半监督多模态域泛化（SSMDG）问题，并设计了一个包含共识驱动一致性正则化等组件的统一框架来解决该问题。",
      "motivation": "研究旨在解决多模态模型在未见域上泛化时标注成本高的问题。现有方法存在显著不足：多模态域泛化方法无法利用无标签数据，半监督多模态学习方法忽略域偏移，而半监督域泛化方法仅限于单模态输入。这些问题导致模型在实际应用中数据效率低、泛化能力弱，无法应对多样化的真实场景，因此亟需结合半监督学习、多模态处理和域泛化的新方法。",
      "method": "论文提出了一个统一框架，核心包括三个关键组件：共识驱动一致性正则化，通过自信融合单模态共识获取可靠伪标签；分歧感知正则化，有效利用模糊的非共识样本；跨模态原型对齐，强制域和模态不变表示，并通过跨模态翻译增强缺失模态下的鲁棒性。该方法整合了半监督学习、域泛化和多模态对齐技术，以提高模型的数据效率和泛化能力，摘要未明确说明具体数据集或模型架构，但提及建立了基准测试。",
      "result": "在建立的第一个SSMDG基准测试上，该方法在标准和缺失模态场景下均一致优于强基线。尽管摘要未提供具体数值指标（如准确率提升），但结果表明方法能有效处理域偏移和少标签情况，相比现有方法展现出更好的泛化能力和鲁棒性，填补了多模态半监督域泛化领域的性能空白。",
      "conclusion": "本文的主要贡献是提出了SSMDG问题和相应解决方案，并建立了首个相关基准测试。研究学术上推动了多模态、半监督和域泛化的交叉研究，填补了领域空白；实践上，有助于降低标注成本，提升模型在多样化环境中的鲁棒性和应用效果。未来工作可探索扩展到更多模态或复杂场景，但摘要未明确说明局限性。",
      "tags": [
        "Multimodal Learning",
        "Domain Generalization",
        "Semi-Supervised Learning",
        "Consistency Regularization",
        "Cross-Modal Translation"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:17.672840Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22911",
    "title": "NoRA: Breaking the Linear Ceiling of Low-Rank Adaptation via Manifold Expansion",
    "authors": [
      "Hung-Hsuan Chen"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) dominates parameter-efficient fine-tuning (PEFT). However, it faces a critical ``linear ceiling'' in complex reasoning tasks: simply increasing the rank yields diminishing returns due to intrinsic linear constraints. We introduce NoRA (Non-linear Rank Adaptation), a weight-level parallel adapter that injects SiLU gating and structural dropout to induce manifold expansion. On the SlimOrca benchmark, NoRA breaks this linear barrier: NoRA remarkably at rank 64 (PPL 3.89) outperforms LoRA at rank 512 (PPL 3.90), demonstrating superior spectral efficiency. This advantage generalizes to mathematical reasoning, where NoRA achieves a perplexity of 1.97 on MathInstruct, significantly surpassing LoRA's saturation point of 2.07. Mechanism analysis via Singular Value Decomposition (SVD) confirms that NoRA activates the dormant tail of the singular value spectrum, effectively preventing the rank collapse observed in linear methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22911.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22911",
    "published": "2026-02-26T11:55:25Z",
    "updated": "2026-02-26T11:55:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "NoRA提出了一种非线性秩适应方法，通过流形扩展突破了LoRA在复杂推理任务中的线性天花板，实现了更高效的参数微调。",
      "motivation": "低秩适应（LoRA）在参数高效微调（PEFT）中占据主导地位，但在处理复杂推理任务时面临“线性天花板”问题：由于内在线性约束，单纯增加秩会导致收益递减。这一问题的重要性在于它限制了模型在需要高层次推理任务上的性能提升，而现有LoRA方法因线性结构无法有效克服这一瓶颈，因此亟需开发新的非线性适应技术来提高微调效率和表达能力。",
      "method": "论文提出了NoRA（非线性秩适应），一种权重级并行适配器，通过集成SiLU门控和结构dropout机制来诱导流形扩展。该方法的核心创新在于引入非线性元素，打破线性方法的限制，从而在微调过程中动态调整权重。NoRA在SlimOrca和MathInstruct等数据集上进行评估，通过奇异值分解分析证实其能够激活奇异值谱的尾部，防止秩塌缩，实现了更有效的参数优化。",
      "result": "在SlimOrca基准测试中，NoRA在秩64时达到困惑度3.89，优于LoRA在秩512时的困惑度3.90，展示了显著的谱效率优势。在数学推理任务MathInstruct上，NoRA的困惑度为1.97，明显超越LoRA的饱和点2.07。奇异值分解分析进一步确认NoRA能够激活奇异值谱的休眠尾部，有效防止线性方法中常见的秩塌缩，从而在多个复杂任务中实现更好的性能表现。",
      "conclusion": "NoRA的主要贡献是成功突破了LoRA的线性天花板，通过非线性适应机制提高了参数高效微调的效率。其学术价值在于提出了流形扩展概念，为非线性的适应技术提供了新思路；实际应用价值体现在能以更低参数成本在复杂推理任务中取得更优性能。摘要未明确说明局限性或未来工作方向，但可推测未来可能扩展到更多任务或优化非线性结构。",
      "tags": [
        "Low-Rank Adaptation",
        "Non-linear Adaptation",
        "SiLU gating",
        "Structural Dropout",
        "Singular Value Decomposition"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:15.395486Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22902",
    "title": "A Data-Driven Approach to Support Clinical Renal Replacement Therapy",
    "authors": [
      "Alice Balboni",
      "Luis Escobar",
      "Andrea Manno",
      "Fabrizio Rossi",
      "Maria Cristina Ruffa",
      "Gianluca Villa",
      "Giordano D'Aloisio",
      "Antonio Consolo"
    ],
    "abstract": "This study investigates a data-driven machine learning approach to predict membrane fouling in critically ill patients undergoing Continuous Renal Replacement Therapy (CRRT). Using time-series data from an ICU, 16 clinically selected features were identified to train predictive models. To ensure interpretability and enable reliable counterfactual analysis, the researchers adopted a tabular data approach rather than modeling temporal dependencies directly. Given the imbalance between fouling and non-fouling cases, the ADASYN oversampling technique was applied to improve minority class representation. Random Forest, XGBoost, and LightGBM models were tested, achieving balanced performance with 77.6% sensitivity and 96.3% specificity at a 10% rebalancing rate. Results remained robust across different forecasting horizons. Notably, the tabular approach outperformed LSTM recurrent neural networks, suggesting that explicit temporal modeling was not necessary for strong predictive performance. Feature selection further reduced the model to five key variables, improving simplicity and interpretability with minimal loss of accuracy. A Shapley value-based counterfactual analysis was applied to the best-performing model, successfully identifying minimal input changes capable of reversing fouling predictions. Overall, the findings support the viability of interpretable machine learning models for predicting membrane fouling during CRRT. The integration of prediction and counterfactual analysis offers practical clinical value, potentially guiding therapeutic adjustments to reduce fouling risk and improve patient management.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22902.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22902",
    "published": "2026-02-26T11:47:22Z",
    "updated": "2026-02-26T11:47:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种基于表格数据的可解释机器学习方法，用于预测重症患者连续肾脏替代疗法中的膜污染，并通过反事实分析提供临床指导。",
      "motivation": "连续肾脏替代疗法（CRRT）是重症患者的关键治疗，但膜污染会显著降低治疗效果，需要预测以指导干预。现有方法如LSTM时间序列模型可能过度依赖复杂时序建模，缺乏可解释性，难以在临床中可靠应用。本研究旨在解决这一问题，通过数据驱动方法提升预测准确性和可解释性，以支持临床决策。摘要未明确说明其他具体不足，但强调了可解释性的重要性。",
      "method": "研究使用ICU时间序列数据提取16个临床特征，采用表格数据方法避免直接建模时间依赖性。为处理数据不平衡，应用ADASYN过采样技术增强少数类表示。测试了Random Forest、XGBoost和LightGBM等机器学习模型，并通过特征选择优化至五个关键变量，以提高简单性和可解释性。关键创新点包括使用Shapley值进行反事实分析，识别逆转预测的最小输入变化，确保模型透明可靠。",
      "result": "在10%重新平衡率下，模型达到77.6%敏感性和96.3%特异性，表现平衡且稳健。结果在不同预测时间范围内保持一致，表格方法在预测性能上优于LSTM递归神经网络，表明无需显式时间建模也能取得良好效果。特征选择后模型简化，精度损失最小，验证了方法的有效性。具体对比显示，表格方法在准确性和效率上超过传统时序模型。",
      "conclusion": "研究发现可解释机器学习模型能有效预测CRRT膜污染，整合预测和反事实分析提供了实际临床价值，可指导治疗调整以减少污染风险和改善患者管理。研究的学术价值在于证明了表格数据方法在医疗时间序列预测中的优势，应用潜力包括扩展到其他临床场景。局限性可能涉及数据泛化和模型优化，未来工作可探索更多特征和算法增强。",
      "tags": [
        "Tabular Data",
        "ADASYN",
        "Random Forest",
        "Shapley Value",
        "Counterfactual Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:22.125149Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22897",
    "title": "OmniGAIA: Towards Native Omni-Modal AI Agents",
    "authors": [
      "Xiaoxi Li",
      "Wenxiang Jiao",
      "Jiarui Jin",
      "Shijian Wang",
      "Guanting Dong",
      "Jiajie Jin",
      "Hao Wang",
      "Yinuo Wang",
      "Ji-Rong Wen",
      "Yuan Lu",
      "Zhicheng Dou"
    ],
    "abstract": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22897.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22897",
    "published": "2026-02-26T11:35:04Z",
    "updated": "2026-02-26T11:35:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出OmniGAIA基准和OmniAtlas代理，旨在推动全模态AI助手的发展，通过评估和增强代理在多模态交互和工具执行上的能力。",
      "motivation": "人类智能能自然结合视觉、音频和语言等多模态感知，并与复杂推理和工具使用交织，以应对真实世界互动。然而，当前多模态大语言模型主要局限于双模态交互（如视觉-语言），缺乏统一认知能力，限制了它们在通用AI助手中的应用。因此，本研究旨在解决这一问题，开发能处理全模态、跨模态推理和工具集成的AI系统，以弥补现有方法的不足并满足复杂场景需求。",
      "method": "研究方法分为两部分：一是构建OmniGAIA基准，采用全模态事件图方法从真实世界数据生成复杂多跳查询，这些查询需要跨模态推理和外部工具集成；二是提出OmniAtlas代理，作为原生全模态基础代理，采用工具集成推理范式和主动全模态感知。训练中，使用后见指导的树探索策略合成轨迹，并利用OmniDPO进行细粒度错误修正，以优化模型性能。",
      "result": "主要实验结果显示，OmniAtlas能有效增强现有开源模型的工具使用能力，尽管摘要未明确提供具体量化指标（如准确率提升百分比）。通过与基线方法的对比，该代理在处理跨模态推理和多轮工具执行任务上表现出改进，展示了其潜在性能优势，但具体数据需参考论文细节。",
      "conclusion": "本论文的主要贡献是推出了OmniGAIA基准和OmniAtlas代理，这标志着向下一代原生全模态AI助手迈进了一步。OmniGAIA提供了全面评估平台，而OmniAtlas通过创新训练方法增强了工具集成能力，具有推动多模态AI发展的学术价值，并为智能助手等实际应用奠定基础。未来工作可能包括优化模型、扩展模态或进一步在真实场景中测试。",
      "tags": [
        "Omni-Modal Agents",
        "Tool-Integrated Reasoning",
        "Multi-Modal Benchmark",
        "Event Graph",
        "DPO"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:35.491327Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22882",
    "title": "Fair feature attribution for multi-output prediction: a Shapley-based perspective",
    "authors": [
      "Umberto Biccari",
      "Alain Ibáñez de Opakua",
      "José María Mato",
      "Óscar Millet",
      "Roberto Morales",
      "Enrique Zuazua"
    ],
    "abstract": "In this article, we provide an axiomatic characterization of feature attribution for multi-output predictors within the Shapley framework. While SHAP explanations are routinely computed independently for each output coordinate, the theoretical necessity of this practice has remained unclear. By extending the classical Shapley axioms to vector-valued cooperative games, we establish a rigidity theorem showing that any attribution rule satisfying efficiency, symmetry, dummy player, and additivity must necessarily decompose component-wise across outputs. Consequently, any joint-output attribution rule must relax at least one of the classical Shapley axioms. This result identifies a previously unformalized structural constraint in Shapley-based interpretability, clarifying the precise scope of fairness-consistent explanations in multi-output learning. Numerical experiments on a biomedical benchmark illustrate that multi-output models can yield computational savings in training and deployment, while producing SHAP explanations that remain fully consistent with the component-wise structure imposed by the Shapley axioms.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22882.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22882",
    "published": "2026-02-26T11:22:08Z",
    "updated": "2026-02-26T11:22:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一个基于Shapley公理的多输出特征归因公理化框架，揭示了联合输出归因必须放宽经典公理的刚性定理。",
      "motivation": "本研究动机源于多输出机器学习中特征归因解释的理论基础不明确。SHAP解释通常独立计算每个输出坐标，忽略了输出间的潜在关联，可能导致解释偏差或不公平性，影响模型可信度。现有方法缺乏对输出依赖性的形式化分析，因此需要公理化框架来确保解释的公平性和一致性，尤其是在生物医学等多输出应用领域，以提供可靠的理论支撑。",
      "method": "研究方法基于扩展经典Shapley公理到向量值合作游戏，包括效率、对称性、虚拟玩家和可加性。通过定义满足这些公理的归因规则，建立了一个刚性定理，证明任何规则必须跨输出组件分解。这提供了一个公理化的框架来分析多输出特征归因的公平性，揭示了联合输出归因需放松至少一个公理的结构约束，关键创新在于理论扩展和结构分析。",
      "result": "主要结果包括刚性定理证明，确认任何公平归因规则必须跨输出分解，联合输出归因需放宽经典公理。在生物医学基准上的数值实验表明，多输出模型在训练和部署中实现了计算节省，同时SHAP解释保持与公理的一致性，验证了理论发现的实用性。实验展示了模型优化和解释一致性的优势，尽管摘要未提供具体数据，但证实了方法的有效性。",
      "conclusion": "论文通过公理化方法揭示了多输出特征归因的结构约束，强调联合输出归因必须放松Shapley公理，丰富了可解释AI的理论基础。研究的学术价值在于形式化了未注意到的约束，为多输出学习中的公平解释提供指导，实际应用可扩展到生物医学等领域。未来工作可能涉及设计放松公理的新归因规则，以增强解释的灵活性，推动可解释性研究发展。",
      "tags": [
        "Shapley Axioms",
        "Multi-output Prediction",
        "Feature Attribution",
        "Cooperative Games",
        "SHAP"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:46.494376Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22879",
    "title": "Towards LLM-Empowered Knowledge Tracing via LLM-Student Hierarchical Behavior Alignment in Hyperbolic Space",
    "authors": [
      "Xingcheng Fu",
      "Shengpeng Wang",
      "Yisen Gao",
      "Xianxian Li",
      "Chunpei Li",
      "Qingyun Sun",
      "Dongran Yu"
    ],
    "abstract": "Knowledge Tracing (KT) diagnoses students' concept mastery through continuous learning state monitoring in education.Existing methods primarily focus on studying behavioral sequences based on ID or textual information.While existing methods rely on ID-based sequences or shallow textual features, they often fail to capture (1) the hierarchical evolution of cognitive states and (2) individualized problem difficulty perception due to limited semantic modeling. Therefore, this paper proposes a Large Language Model Hyperbolic Aligned Knowledge Tracing(L-HAKT). First, the teacher agent deeply parses question semantics and explicitly constructs hierarchical dependencies of knowledge points; the student agent simulates learning behaviors to generate synthetic data. Then, contrastive learning is performed between synthetic and real data in hyperbolic space to reduce distribution differences in key features such as question difficulty and forgetting patterns. Finally, by optimizing hyperbolic curvature, we explicitly model the tree-like hierarchical structure of knowledge points, precisely characterizing differences in learning curve morphology for knowledge points at different levels. Extensive experiments on four real-world educational datasets validate the effectiveness of our Large Language Model Hyperbolic Aligned Knowledge Tracing (L-HAKT) framework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22879.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22879",
    "published": "2026-02-26T11:17:31Z",
    "updated": "2026-02-26T11:17:31Z",
    "comment": "9 pages, 6 figures, Accepted to AAAI 2026",
    "light_analysis": {
      "overview": "论文提出了一种基于大语言模型和双曲空间的知识追踪框架L-HAKT，通过层次行为对齐改进认知状态建模和个性化难度感知。",
      "motivation": "知识追踪（KT）在教育中用于监控学生学习状态，但现有方法主要依赖基于ID的序列或浅层文本特征，无法有效捕捉认知状态的层次演化以及学生对问题难度的个性化感知。这限制了KT的准确性和自适应学习系统的应用，因为语义建模不足导致忽略知识点间层次结构和学习动态变化。因此，亟需引入更精细的语义解析和层次建模技术来提升KT性能，解决这些关键挑战。",
      "method": "L-HAKT框架首先使用教师代理深度解析问题语义并显式构建知识点的层次依赖关系，同时学生代理模拟学习行为生成合成数据以增强训练。接着，在双曲空间中对合成数据和真实数据进行对比学习，以减少问题难度和遗忘模式等关键特征的分布差异。最后，通过优化双曲曲率，显式建模知识点的树状层次结构，精确描述不同层级知识点的学习曲线形态差异，从而结合LLM的语义理解和双曲空间的几何特性提升追踪精度。",
      "result": "论文在四个真实世界教育数据集上进行了广泛实验，验证了L-HAKT框架在知识追踪任务中的有效性。结果表明，该方法相比现有基线在建模层次结构和个性化难度感知方面表现优异，显著提升了追踪准确性。然而，摘要未明确说明具体的性能指标如准确率提升数值，仅强调了框架在减少分布差异和捕获学习动态上的整体优势，为KT领域提供了实证支持。",
      "conclusion": "本研究的主要贡献是提出了L-HAKT框架，创新性地整合大语言模型和双曲空间技术，以解决KT中层次演化和语义建模的不足。通过教师-学生代理的对齐和双曲曲率优化，显式建模了知识点的树状结构，提升了学习曲线描述的精确性。这项工作在学术上推动了KT领域的语义和几何方法发展，在实际应用中可增强自适应教育系统的诊断能力。未来工作可能包括扩展到更多数据集或探索其他空间的应用。",
      "tags": [
        "Knowledge Tracing",
        "Large Language Model",
        "Hyperbolic Space",
        "Contrastive Learning",
        "Hierarchical Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:03.862365Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22871",
    "title": "Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching",
    "authors": [
      "Roy Miles",
      "Aysim Toker",
      "Andreea-Maria Oncescu",
      "Songcen Xu",
      "Jiankang Deng",
      "Ismail Elezi"
    ],
    "abstract": "Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or \"nearly correct\" attempts. We propose Stitching Noisy Diffusion Thoughts, a self-consistency framework that turns cheap diffusion-sampled reasoning into a reusable pool of step-level candidates. Given a problem, we (i) sample many diverse, low-cost reasoning trajectories using a masked diffusion language model, (ii) score every intermediate step with an off-the-shelf process reward model (PRM), and (iii) stitch these highest-quality steps across trajectories into a composite rationale. This rationale then conditions an autoregressive (AR) model (solver) to recompute only the final answer. This modular pipeline separates exploration (diffusion) from evaluation and solution synthesis, avoiding monolithic unified hybrids while preserving broad search. Across math reasoning benchmarks, we find that step-level recombination is most beneficial on harder problems, and ablations highlight the importance of the final AR solver in converting stitched but imperfect rationales into accurate answers. Using low-confidence diffusion sampling with parallel, independent rollouts, our training-free framework improves average accuracy by up to 23.8% across six math and coding tasks. At the same time, it achieves up to a 1.8x latency reduction relative to both traditional diffusion models (e.g., Dream, LLaDA) and unified architectures (e.g., TiDAR). Code is available at https://github.com/roymiles/diffusion-stitching.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22871.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22871",
    "published": "2026-02-26T11:08:39Z",
    "updated": "2026-02-26T11:08:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于扩散语言模型和奖励指导缝合的自洽框架，通过步骤级重组推理链提升大型语言模型的推理性能。",
      "motivation": "在大型语言模型推理中，现有方法如轨迹级别选择或投票常丢弃部分或接近正确尝试中的有用中间工作，限制了性能提升，尤其在数学推理等需要复杂步骤的任务中。该研究旨在解决这一问题，强调步骤级信息整合的重要性，以弥补现有聚合策略的不足，提高推理准确性和效率。",
      "method": "研究方法包括三个步骤：首先使用掩码扩散语言模型采样多个多样且低成本的推理轨迹；其次利用现成的过程奖励模型（PRM）为每个中间步骤打分；最后将跨轨迹中最高质量步骤缝合形成复合推理链，并以此条件自回归（AR）模型重新计算最终答案。该方法采用模块化设计，将探索、评估和合成分离，避免了单一架构的复杂性，同时支持广泛搜索。",
      "result": "实验结果显示，在六个数学和编码任务的基准测试中，该框架将平均准确率提高了高达23.8%。同时，相对于传统扩散模型（如Dream、LLaDA）和统一架构（如TiDAR），实现了高达1.8倍的延迟减少。消融研究进一步表明，最终的自回归求解器在将缝合推理链转化为准确答案中起到关键作用，特别是在较难问题上。",
      "conclusion": "该研究的主要贡献是提出了一个步骤级缝合的推理框架，有效利用中间步骤信息提升性能，具有模块化设计和自洽性。学术价值在于结合扩散和自回归模型的优势，推动推理方法创新；实际应用能提高任务速度和准确性，无需额外训练。未来工作可能包括扩展到更多领域或优化缝合技术。",
      "tags": [
        "Diffusion Language Model",
        "Process Reward Model",
        "Autoregressive Model",
        "Self-Consistency",
        "Stitching Technique"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:13.360835Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22868",
    "title": "Rejection Mixing: Fast Semantic Propagation of Mask Tokens for Efficient DLLM Inference",
    "authors": [
      "Yushi Ye",
      "Feng Hong",
      "Huangjie Zheng",
      "Xu Chen",
      "Zhiyong Chen",
      "Yanfeng Wang",
      "Jiangchao Yao"
    ],
    "abstract": "Diffusion Large Language Models (DLLMs) promise fast non-autoregressive inference but suffer a severe quality-speed trade-off in parallel decoding. This stems from the ''combinatorial contradiction'' phenomenon, where parallel tokens form semantically inconsistent combinations. We address this by integrating continuous representations into the discrete decoding process, as they preserve rich inter-position dependency. We propose ReMix (Rejection Mixing), a framework that introduces a novel Continuous Mixing State as an intermediate between the initial masked state and the final decoded token state. This intermediate state allows a token's representation to be iteratively refined in a continuous space, resolving mutual conflicts with other tokens before collapsing into a final discrete sample. Furthermore, a rejection rule reverts uncertain representations from the continuous state back to the masked state for reprocessing, ensuring stability and preventing error propagation. ReMix thus mitigates combinatorial contradictions by enabling continuous-space refinement during discrete diffusion decoding. Extensive experiments demonstrate that ReMix, as a training-free method, achieves a $2-8 \\times$ inference speedup without any quality degradation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22868.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22868",
    "published": "2026-02-26T11:08:11Z",
    "updated": "2026-02-26T11:08:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出ReMix框架，通过连续混合状态优化扩散大语言模型的非自回归推理，实现速度提升而不降低质量。",
      "motivation": "扩散大语言模型在非自回归推理中虽速度快，但面临质量与速度的权衡，这源于并行解码中的'组合矛盾'现象，即并行令牌形成语义不一致的组合。现有方法难以有效解决此问题，导致推理效率受限，而连续表示能保持令牌间的依赖关系，为解决这一矛盾提供可能。",
      "method": "论文提出ReMix（拒绝混合）框架，核心是引入连续混合状态作为初始掩码状态和最终解码令牌状态的中间层。该状态允许令牌在连续空间中进行迭代细化，通过整合连续表示到离散解码过程，解决与其他令牌的冲突；此外，拒绝规则将不确定表示从连续状态回退到掩码状态重新处理，确保稳定性和防止错误传播。",
      "result": "实验显示，ReMix作为一种无需训练的方法，在扩散大语言模型推理中实现了2到8倍的推理加速，且未造成任何质量退化，显著优于基线方法，为高效推理提供了实际解决方案。",
      "conclusion": "本研究主要贡献是提出ReMix框架，有效缓解扩散大语言模型中的组合矛盾问题，实现推理速度的大幅提升，具有重要的学术价值，为改进非自回归解码提供了新方法，并推动高效AI应用；未来工作方向如扩展至其他模型类型，摘要未明确说明。",
      "tags": [
        "Diffusion Large Language Models",
        "Continuous Mixing State",
        "Rejection Rule",
        "Non-Autoregressive Inference",
        "Parallel Decoding"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:00.757584Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22867",
    "title": "SO3UFormer: Learning Intrinsic Spherical Features for Rotation-Robust Panoramic Segmentation",
    "authors": [
      "Qinfeng Zhu",
      "Yunxi Jiang",
      "Lei Fan"
    ],
    "abstract": "Panoramic semantic segmentation models are typically trained under a strict gravity-aligned assumption. However, real-world captures often deviate from this canonical orientation due to unconstrained camera motions, such as the rotational jitter of handheld devices or the dynamic attitude shifts of aerial platforms. This discrepancy causes standard spherical Transformers to overfit global latitude cues, leading to performance collapse under 3D reorientations. To address this, we introduce SO3UFormer, a rotation-robust architecture designed to learn intrinsic spherical features that are less sensitive to the underlying coordinate frame. Our approach rests on three geometric pillars: (1) an intrinsic feature formulation that decouples the representation from the gravity vector by removing absolute latitude encoding; (2) quadrature-consistent spherical attention that accounts for non-uniform sampling densities; and (3) a gauge-aware relative positional mechanism that encodes local angular geometry using tangent-plane projected angles and discrete gauge pooling, avoiding reliance on global axes. We further use index-based spherical resampling together with a logit-level SO(3)-consistency regularizer during training. To rigorously benchmark robustness, we introduce Pose35, a dataset variant of Stanford2D3D perturbed by random rotations within $\\pm 35^\\circ$. Under the extreme test of arbitrary full SO(3) rotations, existing SOTAs fail catastrophically: the baseline SphereUFormer drops from 67.53 mIoU to 25.26 mIoU. In contrast, SO3UFormer demonstrates remarkable stability, achieving 72.03 mIoU on Pose35 and retaining 70.67 mIoU under full SO(3) rotations.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22867.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22867",
    "published": "2026-02-26T11:07:51Z",
    "updated": "2026-02-26T11:07:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "SO3UFormer提出了一种旋转鲁棒的全景语义分割架构，通过几何方法学习内在球面特征，有效应对相机旋转导致的性能下降。",
      "motivation": "全景语义分割模型通常基于重力对齐假设训练，但在真实应用中，如手持设备的旋转抖动或无人机平台的动态姿态变化，相机运动会导致方向偏差。这使得标准球面Transformer过度依赖全局坐标系，特别是纬度线索，在3D重定向下性能崩溃。现有方法缺乏对旋转的鲁棒性，限制了在动态环境中的实用性，因此开发不敏感于坐标框架的模型至关重要。",
      "method": "SO3UFormer基于三个几何支柱：内在特征公式化通过移除绝对纬度编码，使表示与重力向量解耦；正交一致球面注意力考虑了球面上的非均匀采样密度；基于规范池化的位置机制使用切线平面投影角度和离散规范池化编码局部角几何，避免依赖全局轴。此外，训练中结合索引球面重采样和logit级SO(3)一致性正则化，进一步增强了模型的旋转不变性。",
      "result": "在Pose35数据集（Stanford2D3D的随机旋转扰动变体）上，SO3UFormer达到72.03 mIoU。在极端测试下，即任意完整SO(3)旋转，现有最优模型SphereUFormer从67.53 mIoU急剧下降到25.26 mIoU，而SO3UFormer保持了70.67 mIoU，展示了卓越的稳定性。这些结果表明，SO3UFormer在旋转条件下显著优于基线方法，提高了分割精度。",
      "conclusion": "本论文提出了SO3UFormer，通过几何创新学习内在球面特征，有效解决了全景分割的旋转敏感问题。主要贡献包括引入内在特征公式化、正交一致注意力和规范池化机制，提升了模型的鲁棒性。这项研究具有重要学术价值，为动态环境如无人机或手持设备提供实用解决方案，未来可扩展至其他旋转敏感任务。",
      "tags": [
        "SO3UFormer",
        "Spherical Attention",
        "Gauge Pooling",
        "SO(3) Consistency",
        "Panoramic Segmentation"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:17.110025Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22865",
    "title": "Effective QA-driven Annotation of Predicate-Argument Relations Across Languages",
    "authors": [
      "Jonathan Davidov",
      "Aviv Slobodkin",
      "Shmuel Tomi Klein",
      "Reut Tsarfaty",
      "Ido Dagan",
      "Ayal Klein"
    ],
    "abstract": "Explicit representations of predicate-argument relations form the basis of interpretable semantic analysis, supporting reasoning, generation, and evaluation. However, attaining such semantic structures requires costly annotation efforts and has remained largely confined to English. We leverage the Question-Answer driven Semantic Role Labeling (QA-SRL) framework -- a natural-language formulation of predicate-argument relations -- as the foundation for extending semantic annotation to new languages. To this end, we introduce a cross-linguistic projection approach that reuses an English QA-SRL parser within a constrained translation and word-alignment pipeline to automatically generate question-answer annotations aligned with target-language predicates. Applied to Hebrew, Russian, and French -- spanning diverse language families -- the method yields high-quality training data and fine-tuned, language-specific parsers that outperform strong multilingual LLM baselines (GPT-4o, LLaMA-Maverick). By leveraging QA-SRL as a transferable natural-language interface for semantics, our approach enables efficient and broadly accessible predicate-argument parsing across languages.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22865.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22865",
    "published": "2026-02-26T11:01:38Z",
    "updated": "2026-02-26T11:01:38Z",
    "comment": "Accepted to EACL 2026 (Main Conference)",
    "light_analysis": {
      "overview": "该论文提出了一种基于QA-SRL的跨语言投影方法，通过自动化生成标注数据，实现高效的多语言谓词-论元解析。",
      "motivation": "本研究的动机源于谓词-论元关系作为可解释语义分析的基础，对推理和生成任务至关重要。然而，获取这些语义结构通常需要昂贵的标注努力，且现有资源主要局限于英语，这限制了多语言NLP应用的发展。现有方法的不足在于人工标注成本高、难以扩展至非英语语言，导致跨语言语义解析的覆盖率低。因此，开发一种高效、低成本的自动化方法来解决此问题，对于推动全球化语义分析系统具有重要意义。",
      "method": "研究方法基于QA-SRL框架，将谓词-论元关系以自然语言问答形式表示。核心创新是提出跨语言投影方法：重用英语QA-SRL解析器，结合自动翻译和词对齐技术，构建约束管道，为希伯来语、俄语和法语等目标语言自动生成与谓词对齐的问答标注。通过这一流程，生成的标注数据用于训练语言特定解析器，避免从头开始的高成本人工标注。关键特色在于利用QA-SRL作为自然语言接口，实现语义信息的跨语言迁移。",
      "result": "主要实验结果：应用该方法于希伯来语、俄语和法语，成功生成了高质量训练数据，并微调出针对各语言的解析器。这些语言特定解析器在性能上显著优于强大的多语言大语言模型基线，包括GPT-4o和LLaMA-Maverick。摘要未明确给出具体性能指标数据，但指出方法在跨语言谓词-论元解析任务中表现更优，提升了语义角色标注的准确性和效率。与基线对比表明，该方法能更有效地处理多语言语义分析挑战。",
      "conclusion": "结论表明，本研究通过将QA-SRL作为可转移的自然语言接口，实现了高效的跨语言谓词-论元解析，减少了标注成本并扩展了语义分析范围。主要贡献在于提出一种自动化投影方法，使得多语言语义解析更广泛可访问。学术价值体现在推动跨语言NLP技术的发展；实际应用价值在于支持多语言推理和生成任务。未来工作方向可能包括扩展到更多语言或优化投影技术以提升鲁棒性，但摘要未明确说明具体细节。",
      "tags": [
        "QA-SRL",
        "Cross-linguistic Projection",
        "Word Alignment",
        "Semantic Role Labeling",
        "Multilingual Parsing"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:23.047931Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22859",
    "title": "From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models",
    "authors": [
      "Hongrui Jia",
      "Chaoya Jiang",
      "Shikun Zhang",
      "Wei Ye"
    ],
    "abstract": "As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22859.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22859",
    "published": "2026-02-26T10:53:57Z",
    "updated": "2026-02-26T10:53:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出诊断驱动的渐进演化（DPE），一种通过诊断指导数据生成和强化的螺旋循环方法，用于持续改进大型多模态模型的训练。",
      "motivation": "研究背景是大型多模态模型在规模和强化学习方法成熟后，在复杂推理和决策方面取得进步，但训练仍依赖于静态数据和固定方法，难以诊断能力盲点或提供动态、有针对性的强化。现有方法无法有效识别模型弱点，导致训练效率低下。受测试驱动错误暴露和反馈纠正优于重复练习的发现启发，作者旨在开发一种能动态改进LMMs能力的训练范式，以解决传统训练中的局限性和不足。",
      "method": "研究方法包括诊断驱动的渐进演化（DPE）框架，它是一个螺旋循环过程。首先，使用多个代理通过工具如网络搜索和图像编辑，注释和质量控制大规模未标记多模态数据，生成多样、真实的样本。其次，DPE将模型失败归因于特定弱点，动态调整数据混合，并指导代理生成针对弱点的数据，用于有针对性的强化学习。关键创新在于结合诊断、数据生成和迭代优化，以实现自适应的模型改进。",
      "result": "实验在Qwen3-VL-8B-Instruct和Qwen2.5-VL-7B-Instruct模型上进行，结果显示在11个基准测试中，DPE实现了稳定、持续的收益。这表明DPE方法能有效提升模型性能，相较于传统的静态训练方法，DPE通过动态诊断和强化不断改进模型，但具体性能指标如准确率百分比提升摘要未明确说明。结果证明了DPE在开放任务分布下具有可扩展性和有效性。",
      "conclusion": "论文的主要贡献是提出了DPE作为一种可扩展的范式，用于在开放任务分布下持续训练大型多模态模型。其学术价值在于创新了训练方法，使模型能通过迭代诊断和强化自适应改进；实际应用价值在于提高了LMMs在复杂任务中的性能。局限性方面摘要未明确说明，但未来工作可能包括优化诊断精度或扩展到更多模态和任务。",
      "tags": [
        "Large Multimodal Models",
        "Reinforcement Learning",
        "Iterative Training",
        "Data Generation",
        "Weakness Diagnosis"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:23.604855Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22850",
    "title": "MEDNA-DFM: A Dual-View FiLM-MoE Model for Explainable DNA Methylation Prediction",
    "authors": [
      "Yi He",
      "Yina Cao",
      "Jixiu Zhai",
      "Di Wang",
      "Junxiao Kong",
      "Tianchi Lu"
    ],
    "abstract": "Accurate computational identification of DNA methylation is essential for understanding epigenetic regulation. Although deep learning excels in this binary classification task, its \"black-box\" nature impedes biological insight. We address this by introducing a high-performance model MEDNA-DFM, alongside mechanism-inspired signal purification algorithms. Our investigation demonstrates that MEDNA-DFM effectively captures conserved methylation patterns, achieving robust distinction across diverse species. Validation on external independent datasets confirms that the model's generalization is driven by conserved intrinsic motifs (e.g., GC content) rather than phylogenetic proximity. Furthermore, applying our developed algorithms extracted motifs with significantly higher reliability than prior studies. Finally, empirical evidence from a Drosophila 6mA case study prompted us to propose a \"sequence-structure synergy\" hypothesis, suggesting that the GAGG core motif and an upstream A-tract element function cooperatively. We further validated this hypothesis via in silico mutagenesis, confirming that the ablation of either or both elements significantly degrades the model's recognition capabilities. This work provides a powerful tool for methylation prediction and demonstrates how explainable deep learning can drive both methodological innovation and the generation of biological hypotheses.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22850.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22850",
    "published": "2026-02-26T10:38:41Z",
    "updated": "2026-02-26T10:38:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出 MEDNA-DFM，一种双视角 FiLM-MoE 模型，用于可解释的 DNA 甲基化预测，并结合信号净化算法验证其有效性和生物学洞见。",
      "motivation": "DNA 甲基化的准确计算识别对于理解表观遗传调控至关重要，是生物医学研究的关键问题。尽管深度学习在此二元分类任务中表现出色，但其'黑盒'特性阻碍了生物学洞见的获取，限制了在解释分子机制方面的应用。因此，本研究旨在解决现有方法在可解释性上的不足，开发高性能且透明的模型，以促进表观遗传学领域的深入探索。",
      "method": "本研究引入 MEDNA-DFM 模型，采用双视角 FiLM-MoE 架构，结合 Feature-wise Linear Modulation（FiLM）和 Mixture of Experts（MoE）技术，以增强模型对 DNA 序列数据的处理能力和可解释性。同时，开发了机制启发的信号净化算法，用于提取和验证序列中的关键基序，提升生物学意义的可靠性。模型设计旨在捕捉保守的甲基化模式，并通过算法优化解决'黑盒'问题。",
      "result": "MEDNA-DFM 能有效捕捉保守甲基化模式，实现跨物种的稳健区分，外部独立数据集验证表明模型泛化由保守内在基序（如 GC 含量）驱动。信号净化算法提取的基序可靠性显著高于先前研究。在果蝇 6mA 案例中，提出'序列-结构协同'假说，并通过计算机突变实验验证，移除 GAGG 核心基序或上游 A-tract 元素会显著降低模型识别能力，支持假说有效性。",
      "conclusion": "本研究提供了强大的 DNA 甲基化预测工具 MEDNA-DFM，不仅提升了预测性能，还通过可解释性推动了方法论创新和生物学假说生成。学术上，展示了可解释深度学习在生物信息学中的价值；实际上，有助于表观遗传学研究。未来工作可进一步验证假说并扩展到其他生物系统，摘要未明确说明具体局限性。",
      "tags": [
        "Explainable Deep Learning",
        "DNA Methylation Prediction",
        "FiLM",
        "MoE",
        "Motif Extraction"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:41.646017Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22847",
    "title": "Decentralized Ranking Aggregation: Gossip Algorithms for Borda and Copeland Consensus",
    "authors": [
      "Anna Van Elst",
      "Kerrian Le Caillec",
      "Igor Colin",
      "Stephan Clémençon"
    ],
    "abstract": "The concept of ranking aggregation plays a central role in preference analysis, and numerous algorithms for calculating median rankings, often originating in social choice theory, have been documented in the literature, offering theoretical guarantees in a centralized setting, i.e., when all the ranking data to be aggregated can be brought together in a single computing unit. For many technologies (e.g. peer-to-peer networks, IoT, multi-agent systems), extending the ability to calculate consensus rankings with guarantees in a decentralized setting, i.e., when preference data is initially distributed across a communicating network, remains a major methodological challenge. Indeed, in recent years, the literature on decentralized computation has mainly focused on computing or optimizing statistics such as arithmetic means using gossip algorithms. The purpose of this article is precisely to study how to achieve reliable consensus on collective rankings using classical rules (e.g. Borda, Copeland) in a decentralized setting, thereby raising new questions, robustness to corrupted nodes, and scalability through reduced communication costs in particular. The approach proposed and analyzed here relies on random gossip communication, allowing autonomous agents to compute global ranking consensus using only local interactions, without coordination or central authority.   We provide rigorous convergence guarantees, including explicit rate bounds, for the Borda and Copeland consensus methods. Beyond these rules, we also provide a decentralized implementation of consensus according to the median rank rule and local Kemenization. Extensive empirical evaluations on various network topologies and real and synthetic ranking datasets demonstrate that our algorithms converge quickly and reliably to the correct ranking aggregation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22847.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22847",
    "published": "2026-02-26T10:37:23Z",
    "updated": "2026-02-26T10:37:23Z",
    "comment": "8 pages, 2 figures",
    "light_analysis": {
      "overview": "论文提出了一种基于随机gossip通信的去中心化排名聚合方法，以实现Borda和Copeland共识。",
      "motivation": "排名聚合在偏好分析中扮演核心角色，但现有算法主要针对集中式设置，即所有排名数据可汇聚于单一计算单元时提供理论保证。对于点对点网络、物联网和多代理系统等技术，偏好数据初始分布在一个通信网络中，如何计算具有保证的共识排名成为一个主要方法学挑战。近年来，去中心化计算文献多关注使用gossip算法计算算术均值等统计量，排名聚合领域缺乏有效方法，本研究旨在解决这一问题，提升去中心化设置下的共识排名计算能力。",
      "method": "本研究提出了一种基于随机gossip通信的方法，允许自治代理仅通过本地交互计算全局排名共识，无需协调或中央权威。核心创新在于将经典排名聚合规则（如Borda和Copeland）扩展到去中心化设置。具体技术路线包括分析Borda和Copeland共识方法，提供严格的收敛保证和显式速率界。此外，还实现了基于中值排名规则和局部Kemenization的去中心化共识，通过随机gossip算法减少通信成本并增强鲁棒性。",
      "result": "论文通过广泛的实证评估，在多种网络拓扑和真实与合成排名数据集上验证了算法的有效性。结果显示，所提出的算法能够快速且可靠地收敛到正确的排名聚合。摘要未明确提供具体性能指标如准确率，但强调了收敛的快速性和可靠性。与基线方法相比，该方法在去中心化环境中展示了可行性，通过gossip算法降低了通信开销，并成功处理了分布式数据挑战。",
      "conclusion": "本研究的主要贡献在于提出了一个去中心化排名聚合框架，基于gossip算法实现Borda和Copeland共识，并提供了理论收敛保证。学术价值在于将社会选择理论中的经典规则应用于去中心化计算，解决了分布式偏好数据的共识问题。实际应用适用于物联网、多代理系统等需要分布式决策的场景。未来工作可能包括扩展到其他排名规则、优化算法效率，或进一步研究鲁棒性和可扩展性，摘要未明确说明局限性。",
      "tags": [
        "Ranking Aggregation",
        "Gossip Algorithms",
        "Decentralized Computing",
        "Borda Rule",
        "Copeland Rule"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:50.727205Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22846",
    "title": "Improving Neural Argumentative Stance Classification in Controversial Topics with Emotion-Lexicon Features",
    "authors": [
      "Mohammad Yeghaneh Abkenar",
      "Weixing Wang",
      "Manfred Stede",
      "Davide Picca",
      "Mark A. Finlayson",
      "Panagiotis Ioannidis"
    ],
    "abstract": "Argumentation mining comprises several subtasks, among which stance classification focuses on identifying the standpoint expressed in an argumentative text toward a specific target topic. While arguments-especially about controversial topics-often appeal to emotions, most prior work has not systematically incorporated explicit, fine-grained emotion analysis to improve performance on this task. In particular, prior research on stance classification has predominantly utilized non-argumentative texts and has been restricted to specific domains or topics, limiting generalizability. We work on five datasets from diverse domains encompassing a range of controversial topics and present an approach for expanding the Bias-Corrected NRC Emotion Lexicon using DistilBERT embeddings, which we feed into a Neural Argumentative Stance Classification model. Our method systematically expands the emotion lexicon through contextualized embeddings to identify emotionally charged terms not previously captured in the lexicon. Our expanded NRC lexicon (eNRC) improves over the baseline across all five datasets (up to +6.2 percentage points in F1 score), outperforms the original NRC on four datasets (up to +3.0), and surpasses the LLM-based approach on nearly all corpora. We provide all resources-including eNRC, the adapted corpora, and model architecture-to enable other researchers to build upon our work.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22846.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22846",
    "published": "2026-02-26T10:37:05Z",
    "updated": "2026-02-26T10:37:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出通过扩展情感词汇表结合DistilBERT嵌入的方法，提升了神经网络在争议主题中的立场分类性能。",
      "motivation": "立场分类是论证挖掘的关键子任务，用于识别论点文本对特定主题的立场。在实际争议话题中，论点常诉诸情感以增强说服力，但现有研究未系统整合精细情感分析，导致分类准确性受限。此外，先前工作多依赖非论点文本或局限于特定领域，泛化性较差。因此，本研究旨在解决如何有效结合情感分析来改进立场分类，并扩展应用到多样化争议主题，以提高模型的通用性和性能。",
      "method": "本研究采用五个涵盖不同争议主题的数据集，提出一种神经网络立场分类方法。核心创新在于使用DistilBERT生成的上下文嵌入，对Bias-Corrected NRC情感词汇表进行扩展，形成eNRC词汇表，以动态识别原始词汇表未覆盖的情感术语。然后，将eNRC特征输入到神经网络模型中进行训练和分类。该方法通过上下文感知的情感词汇扩展，增强了模型对争议论点中情感表达的理解，从而提升分类准确性。",
      "result": "实验结果表明，扩展的NRC词汇表（eNRC）在所有五个数据集上均优于基线方法，F1分数最高提升6.2个百分点；在四个数据集上超越原始NRC词汇表，最高提升3.0个百分点；在几乎所有语料库上，性能也超过了基于大型语言模型（LLM）的方法。具体数据支撑了eNRC在立场分类任务中的显著改进，特别是在处理多样化争议主题时，展现出较强的鲁棒性和泛化能力。",
      "conclusion": "本研究的核心贡献是通过扩展情感词汇表与DistilBERT结合的方法，显著提高了神经网络立场分类的性能。学术上，推动了论证挖掘与情感分析的深度融合；实践上，提供了eNRC词汇表、适应语料库和模型架构等资源，支持后续研究和应用。尽管摘要未明确说明局限性，但该方法通过整合多样化数据集增强了泛化性，未来工作可探索更多情感特征或其他领域的扩展。",
      "tags": [
        "Argumentation Mining",
        "Stance Classification",
        "Emotion Lexicon",
        "DistilBERT",
        "Neural Networks"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:45.194189Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22843",
    "title": "A data- and compute-efficient chest X-ray foundation model beyond aggressive scaling",
    "authors": [
      "Chong Wang",
      "Yabin Zhang",
      "Yunhe Gao",
      "Maya Varma",
      "Clemence Mottez",
      "Faidra Patsatzi",
      "Jiaming Liu",
      "Jin Long",
      "Jean-Benoit Delbrouck",
      "Sergios Gatidis",
      "Akshay S. Chaudhari",
      "Curtis P. Langlotz"
    ],
    "abstract": "Foundation models for medical imaging are typically pretrained on increasingly large datasets, following a \"scale-at-all-costs\" paradigm. However, this strategy faces two critical challenges: large-scale medical datasets often contain substantial redundancy and severe class imbalance that bias representation learning toward over-represented patterns, and indiscriminate training regardless of heterogeneity in data quality incurs considerable computational inefficiency. Here we demonstrate that active, principled data curation during pretraining can serve as a viable, cost-effective alternative to brute-force dataset enlargement. We introduce CheXficient, a chest X-ray (CXR) foundation model that selectively prioritizes informative training samples. CheXficient is pretrained on only 22.7% of 1,235,004 paired CXR images and reports while consuming under 27.3% of the total compute budget, yet achieving comparable or superior performance to its full-data counterpart and other large-scale pretrained models. We assess CheXficient across 20 individual benchmarks spanning 5 task types, including non-adapted off-the-shelf evaluations (zero-shot findings classification and crossmodal retrieval) and adapted downstream tasks (disease prediction, semantic segmentation, and radiology report generation). Further analyses show that CheXficient systematically prioritizes under-represented training samples, improving generalizability on long-tailed or rare conditions. Overall, our work offers practical insights into the data and computation demands for efficient pretraining and downstream adaptation of medical vision-language foundation models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22843.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22843",
    "published": "2026-02-26T10:32:08Z",
    "updated": "2026-02-26T10:32:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出CheXficient胸X光基础模型，通过主动数据策划实现数据-和计算-高效预训练，挑战传统大规模数据集预训练范式。",
      "motivation": "医学影像基础模型通常采用大规模数据集预训练，但面临数据冗余和严重类别不平衡，导致学习偏向过代表模式；同时，数据质量异质引发计算低效。这些问题浪费资源并限制模型在实际医疗应用中的可扩展性，因此需要更高效预训练方法以提升模型效率和泛化能力。",
      "method": "论文引入CheXficient模型，其核心创新在于选择性优先处理信息性训练样本，通过主动和有原则的数据策划替代盲目数据集扩大。预训练仅使用1,235,004个胸X光图像和报告的22.7%，计算预算少于总预算的27.3%，优化数据选择以降低冗余和提高学习效率，摘要未明确说明具体模型架构细节。",
      "result": "CheXficient在20个基准测试中评估，涵盖零样本分类、跨模态检索、疾病预测、语义分割和放射报告生成等5种任务，性能与全数据模型及其他大型预训练模型相当或更优；具体地，使用22.7%数据和27.3%计算，改善了长尾或罕见条件的泛化能力，提升整体效率。",
      "conclusion": "本研究贡献在于展示数据策划作为高效预训练的可行替代方案，挑战了传统“scale-at-all-costs”范式，为医学视觉语言基础模型提供数据-和计算-效率的实用见解，学术上推动高效AI在医疗领域的应用，实际价值在于降低资源需求和提高可部署性，未来工作可能涉及扩展至其他医学影像领域。",
      "tags": [
        "Foundation Model",
        "Data Curation",
        "Compute Efficiency",
        "Medical Imaging",
        "Vision-Language Model"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:56.339513Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22842",
    "title": "The AI Research Assistant: Promise, Peril, and a Proof of Concept",
    "authors": [
      "Tan Bui-Thanh"
    ],
    "abstract": "Can artificial intelligence truly contribute to creative mathematical research, or does it merely automate routine calculations while introducing risks of error? We provide empirical evidence through a detailed case study: the discovery of novel error representations and bounds for Hermite quadrature rules via systematic human-AI collaboration.   Working with multiple AI assistants, we extended results beyond what manual work achieved, formulating and proving several theorems with AI assistance. The collaboration revealed both remarkable capabilities and critical limitations. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation. However, every step required rigorous human verification, mathematical intuition for problem formulation, and strategic direction.   We document the complete research workflow with unusual transparency, revealing patterns in successful human-AI mathematical collaboration and identifying failure modes researchers must anticipate. Our experience suggests that, when used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery while demanding careful human oversight and deep domain expertise.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "math.NA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22842.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22842",
    "published": "2026-02-26T10:29:05Z",
    "updated": "2026-02-26T10:29:05Z",
    "comment": "11 pages, 1 figure",
    "light_analysis": {
      "overview": "本研究通过系统的人机协作，在Hermite求积规则中发现新误差表示和界限，展示了AI在数学研究中加速发现的潜力。",
      "motivation": "本研究旨在解决人工智能是否能在创造性数学研究中提供实质性贡献，而非仅自动化计算并引入错误风险的问题。数学研究需要精确性和直觉，当前AI工具在复杂任务中应用不足，缺乏实证验证其创新能力和协作潜力。现有方法往往未充分考虑人机交互的深度，导致AI在数学等领域的局限未被充分识别。因此，本研究通过案例探讨人机协作模式，以评估AI的实际作用并识别潜在挑战，填补这一空白。",
      "method": "研究方法采用详细案例研究，基于系统的人类-AI协作框架。具体技术路线涉及与多个AI助手合作，AI负责代数操作、系统证明探索、文献综合和LaTeX准备等任务，而人类则提供严格的验证、数学直觉和战略方向。关键创新点在于透明的全工作流程记录，以及分析成功协作模式并识别失败模式。虽然摘要未明确说明使用的AI模型或数据集，但强调了协作过程中人类专家的核心作用。",
      "result": "主要实验结果显示，通过人机协作，研究扩展了手动工作的成果，成功制定并证明了多个定理，发现了Hermite求积规则的新误差表示和界限。虽然没有提供具体的性能数据如准确率，但研究表明AI在代数操作和证明探索中表现出色，能加速数学发现过程。与基线手动方法相比，协作实现了更高效的结果输出，但每一步都需要人类监督，以避免错误并确保质量。",
      "conclusion": "本研究的主要贡献是揭示了AI工具在数学研究中能加速发现，但必须结合人类深度专业知识和严格验证。研究意义在于提供了实证证据，支持人机协作在学术研究中的应用价值，并识别了失败模式供未来参考。潜在局限性在于依赖具体案例，且摘要未明确说明技术扩展性。未来工作方向可包括探索更多数学领域或开发自动化验证协议，以优化协作效率。",
      "tags": [
        "Human-AI Collaboration",
        "Theorem Proving",
        "Mathematical Research",
        "Algebraic Manipulation",
        "LaTeX Automation"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:14.068452Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22839",
    "title": "DeepPresenter: Environment-Grounded Reflection for Agentic Presentation Generation",
    "authors": [
      "Hao Zheng",
      "Guozhao Mo",
      "Xinru Yan",
      "Qianhao Yuan",
      "Wenkai Zhang",
      "Xuanang Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ],
    "abstract": "Presentation generation requires deep content research, coherent visual design, and iterative refinement based on observation. However, existing presentation agents often rely on predefined workflows and fixed templates. To address this, we present DeepPresenter, an agentic framework that adapts to diverse user intents, enables effective feedback-driven refinement, and generalizes beyond a scripted pipeline. Specifically, DeepPresenter autonomously plans, renders, and revises intermediate slide artifacts to support long-horizon refinement with environmental observations. Furthermore, rather than relying on self-reflection over internal signals (e.g., reasoning traces), our environment-grounded reflection conditions the generation process on perceptual artifact states (e.g., rendered slides), enabling the system to identify and correct presentation-specific issues during execution. Results on the evaluation set covering diverse presentation-generation scenarios show that DeepPresenter achieves state-of-the-art performance, and the fine-tuned 9B model remains highly competitive at substantially lower cost. Our project is available at: https://github.com/icip-cas/PPTAgent",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22839.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22839",
    "published": "2026-02-26T10:26:48Z",
    "updated": "2026-02-26T10:26:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "DeepPresenter提出一种基于环境接地反射的智能体框架，用于实现自适应和迭代优化的演示生成，超越传统脚本化方法。",
      "motivation": "演示生成需要深度内容研究、视觉设计和基于观察的迭代优化，但现有演示代理常依赖预定义工作流和固定模板，限制了系统的灵活性和适应能力。这导致无法有效处理多样用户意图和动态反馈，降低了演示工具的实用性。因此，研究旨在开发一个更灵活、反馈驱动的框架来解决这一问题。",
      "method": "DeepPresenter框架通过自主规划、渲染和修订中间幻灯片工件，支持长视野优化过程。其关键创新是环境接地反射机制，基于感知工件状态（如渲染的幻灯片）条件生成过程，而非依赖内部信号（如推理轨迹）。这使系统能在执行中识别和纠正演示特定问题，摘要提及使用了微调的9B模型，暗示依托大型预训练模型进行实现。",
      "result": "在覆盖多样演示生成场景的评估集上，DeepPresenter实现了最先进的性能，表明其在效果上优于现有方法。微调的9B模型在显著降低成本的同时保持高度竞争力，突显了框架在效率和效果上的优势。摘要未明确说明具体提升数据，但整体评估展现了出色的综合表现。",
      "conclusion": "DeepPresenter的主要贡献是提供一个灵活、反馈驱动的智能体框架，能够适应多样用户意图并超越脚本化管道。其环境接地反射机制增强了演示生成的适应性和纠错能力，具有实际应用价值。研究为演示工具的发展提供了新方向，未来工作可能涉及更多场景的扩展或优化，摘要未明确说明具体局限性。",
      "tags": [
        "Agentic Framework",
        "Environment-Grounded Reflection",
        "Presentation Generation",
        "Large Language Model",
        "Slide Artifacts"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:46.472199Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22831",
    "title": "Moral Preferences of LLMs Under Directed Contextual Influence",
    "authors": [
      "Phil Blandfort",
      "Tushar Karayil",
      "Urja Pawar",
      "Robert Graham",
      "Alex McKenzie",
      "Dmitrii Krasheninnikov"
    ],
    "abstract": "Moral benchmarks for LLMs typically use context-free prompts, implicitly assuming stable preferences. In deployment, however, prompts routinely include contextual signals such as user requests, cues on social norms, etc. that may steer decisions. We study how directed contextual influences reshape decisions in trolley-problem-style moral triage settings. We introduce a pilot evaluation harness for directed contextual influence in trolley-problem-style moral triage: for each demographic factor, we apply matched, direction-flipped contextual influences that differ only in which group they favor, enabling systematic measurement of directional response. We find that: (i) contextual influences often significantly shift decisions, even when only superficially relevant; (ii) baseline preferences are a poor predictor of directional steerability, as models can appear baseline-neutral yet exhibit systematic steerability asymmetry under influence; (iii) influences can backfire: models may explicitly claim neutrality or discount the contextual cue, yet their choices still shift, sometimes in the opposite direction; and (iv) reasoning reduces average sensitivity, but amplifies the effect of biased few-shot examples. Our findings motivate extending moral evaluations with controlled, direction-flipped context manipulations to better characterize model behavior.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22831.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22831",
    "published": "2026-02-26T10:17:57Z",
    "updated": "2026-02-26T10:17:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一个评估框架，研究定向上下文影响如何重塑大型语言模型的道德决策，揭示了其偏好稳定性的局限性和可操控性。",
      "motivation": "现有研究通常使用上下文无关提示来评估LLMs的道德偏好，假设其偏好稳定。然而，在实际部署中，提示常包含用户请求、社会规范线索等上下文信号，这可能影响模型的决策。本研究的动机在于探究这些定向上下文影响如何改变模型的道德决策，因为现有基准未能充分考虑上下文因素，可能导致评估结果不准确，忽略了模型在真实世界应用中的潜在偏见和可操控性。",
      "method": "论文引入了一个试点评估框架，用于测量 trolley-problem-style 道德分诊设置中的定向上下文影响。核心方法是针对每个 demographic factor，应用匹配的、方向翻转的上下文影响，这些影响仅在偏好组别上有所不同，从而系统性测量定向响应。创新点在于通过方向翻转的上下文操作，识别模型的可操控性模式。摘要未明确说明使用的具体数据集或模型架构，但该方法基于 trolley-problem-style 情境进行实验设计。",
      "result": "实验结果表明：首先，上下文影响经常显著改变模型的决策，即使这些影响仅表面上相关。其次，基线偏好不是定向可操控性的好预测指标，因为模型可能在基线中表现中性，但在影响下显示出系统性的可操控性不对称。第三，影响可能适得其反，模型声称中立或忽略线索，但决策仍改变，有时甚至相反方向。第四，推理过程降低平均敏感性，但放大偏少样本示例的效果。这些发现基于系统性测量，但摘要未提供具体性能指标数据如准确率变化。",
      "conclusion": "本研究的主要贡献在于揭示定向上下文影响能显著重塑LLMs的道德决策，挑战了现有道德基准的假设。学术上，提供了一种扩展评估方法，包括受控的、方向翻转的上下文操作，以更准确地表征模型行为。实际应用中，这有助于改进道德基准设计，减少偏见，确保模型在部署中的可靠性。局限性可能包括仅关注 trolley-problem-style 设置，未来工作可扩展到更多道德场景和上下文类型。",
      "tags": [
        "Large Language Model",
        "Moral Evaluation",
        "Contextual Influence",
        "Trolley Problem",
        "Bias Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:40.100316Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22829",
    "title": "Reflectance Multispectral Imaging for Soil Composition Estimation and USDA Texture Classification",
    "authors": [
      "G. A. S. L Ranasinghe",
      "J. A. S. T. Jayakody",
      "M. C. L. De Silva",
      "G. Thilakarathne",
      "G. M. R. I. Godaliyadda",
      "H. M. V. R. Herath",
      "M. P. B. Ekanayake",
      "S. K. Navaratnarajah"
    ],
    "abstract": "Soil texture is a foundational attribute that governs water availability and erosion in agriculture, as well as load bearing capacity, deformation response, and shrink-swell risk in geotechnical engineering. Yet texture is still typically determined by slow and labour intensive laboratory particle size tests, while many sensing alternatives are either costly or too coarse to support routine field scale deployment. This paper proposes a robust and field deployable multispectral imaging (MSI) system and machine learning framework for predicting soil composition and the United States Department of Agriculture (USDA) texture classes. The proposed system uses a cost effective in-house MSI device operating from 365 nm to 940 nm to capture thirteen spectral bands, which effectively capture the spectral properties of soil texture. Regression models use the captured spectral properties to estimate clay, silt, and sand percentages, while a direct classifier predicts one of the twelve USDA textural classes. Indirect classification is obtained by mapping the regressed compositions to texture classes via the USDA soil texture triangle. The framework is evaluated on mixture data by mixing clay, silt, and sand in varying proportions, using the USDA classification triangle as a basis. Experimental results show that the proposed approach achieves a coefficient of determination R^2 up to 0.99 for composition prediction and over 99% accuracy for texture classification. These findings indicate that MSI combined with data-driven modeling can provide accurate, non-destructive, and field deployable soil texture characterization suitable for geotechnical screening and precision agriculture.",
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22829.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22829",
    "published": "2026-02-26T10:12:25Z",
    "updated": "2026-02-26T10:12:25Z",
    "comment": "Under Review at IEEE Access. 17 pages, 15 figures",
    "light_analysis": {
      "overview": "该论文提出了一种结合多光谱成像和机器学习的高精度、可野外部署的土壤质地分析系统，用于估计土壤成分和分类 USDA 质地。",
      "motivation": "土壤质地是农业和地质工程中的关键属性，影响水资源管理和工程稳定性，但传统实验室测试方法缓慢且劳动密集，而现有传感技术要么成本高昂，要么分辨率低，不适合常规野外部署。因此，需要一种高效、准确且易于部署的土壤分析方案，以支持精准农业和地质工程应用，解决当前方法效率低下和适应性差的问题。",
      "method": "论文提出一个鲁棒的多光谱成像（MSI）系统，使用内部开发设备在 365 nm 到 940 nm 范围内捕获 13 个光谱带，以获取土壤光谱特性。机器学习框架包括回归模型，用于估计粘土、淤泥和砂的百分比，以及直接分类器预测 USDA 的 12 个质地类别。间接分类通过将回归结果映射到 USDA 土壤质地三角形实现。评估基于混合物数据，通过混合不同比例的土壤成分来模拟真实场景。",
      "result": "实验结果显示，组成预测的确定系数 R^2 高达 0.99，表明模型能高度准确地估计土壤成分。质地分类的准确率超过 99%，证明系统在分类任务中的卓越性能。这些结果与传统的实验室方法相比，显示出更高的效率和精度，适用于实际野外部署，摘要未明确说明具体基线对比，但隐含地展示了优于现有传感方案的优势。",
      "conclusion": "该研究开发了一个准确、非破坏性且可野外部署的土壤质地表征系统，结合多光谱成像和数据驱动建模，为土壤科学提供了创新的方法。其学术价值在于推动了传感技术与机器学习在环境监测中的应用，实际应用适用于地质工程筛选和精准农业，提升土壤分析的效率和准确性。未来工作可能包括扩展到更多土壤类型或优化设备成本，但摘要未明确说明局限性。",
      "tags": [
        "Multispectral Imaging",
        "Machine Learning",
        "Regression Analysis",
        "Classification",
        "Soil Texture Triangle"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:35.898458Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22828",
    "title": "TCM-DiffRAG: Personalized Syndrome Differentiation Reasoning Method for Traditional Chinese Medicine based on Knowledge Graph and Chain of Thought",
    "authors": [
      "Jianmin Li",
      "Ying Chang",
      "Su-Kit Tang",
      "Yujia Liu",
      "Yanwen Wang",
      "Shuyuan Lin",
      "Binkai Ou"
    ],
    "abstract": "Background: Retrieval augmented generation (RAG) technology can empower large language models (LLMs) to generate more accurate, professional, and timely responses without fine tuning. However, due to the complex reasoning processes and substantial individual differences involved in traditional Chinese medicine (TCM) clinical diagnosis and treatment, traditional RAG methods often exhibit poor performance in this domain. Objective: To address the limitations of conventional RAG approaches in TCM applications, this study aims to develop an improved RAG framework tailored to the characteristics of TCM reasoning. Methods: We developed TCM-DiffRAG, an innovative RAG framework that integrates knowledge graphs (KG) with chains of thought (CoT). TCM-DiffRAG was evaluated on three distinctive TCM test datasets. Results: The experimental results demonstrated that TCM-DiffRAG achieved significant performance improvements over native LLMs. For example, the qwen-plus model achieved scores of 0.927, 0.361, and 0.038, which were significantly enhanced to 0.952, 0.788, and 0.356 with TCM-DiffRAG. The improvements were even more pronounced for non-Chinese LLMs. Additionally, TCM-DiffRAG outperformed directly supervised fine-tuned (SFT) LLMs and other benchmark RAG methods. Conclusions: TCM-DiffRAG shows that integrating structured TCM knowledge graphs with Chain of Thought based reasoning substantially improves performance in individualized diagnostic tasks. The joint use of universal and personalized knowledge graphs enables effective alignment between general knowledge and clinical reasoning. These results highlight the potential of reasoning-aware RAG frameworks for advancing LLM applications in traditional Chinese medicine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22828.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22828",
    "published": "2026-02-26T10:11:15Z",
    "updated": "2026-02-26T10:11:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出TCM-DiffRAG框架，通过集成知识图和思维链推理，改进大语言模型在中医个性化辨证诊断中的性能。",
      "motivation": "检索增强生成（RAG）技术虽能增强大语言模型的响应准确性，但在中医领域，传统RAG方法表现不佳，因为中医临床诊断涉及复杂的推理过程和显著的个体差异，导致无法有效处理个性化需求。这一问题限制了LLMs在专业医学应用中的潜力，因此需开发针对中医推理特点的改进框架，以克服现有方法的局限性，提升诊断精确性和临床实用性。",
      "method": "论文提出TCM-DiffRAG框架，集成知识图（KG）和思维链（CoT）来支持中医辨证推理。该框架利用结构化知识图提供专业中医知识，并通过思维链引导推理过程，以适应复杂的临床场景。研究方法包括在三个独特的中医测试数据集上评估框架，验证其技术特色，关键创新点在于结合结构化知识与推理路径，针对中医个体化诊断需求设计。",
      "result": "实验结果显示，TCM-DiffRAG显著提升性能，优于原生LLMs、监督微调LLMs和其他基准RAG方法。以qwen-plus模型为例，得分从0.927、0.361、0.038提升到0.952、0.788、0.356，改进幅度明显。与非中文LLMs对比时改进更显著，证明框架在跨语言或专业领域应用中的优势，具体数据支撑了其在中医诊断任务中的效率提升和准确性增强。",
      "conclusion": "研究证实，集成结构化中医知识图和思维链推理能有效提高个体化诊断任务性能，通过联合通用和个性化知识图实现知识与临床推理的对齐。这为大语言模型在传统中医等专业领域的应用提供了新方向，具有重要学术价值和实际应用潜力。摘要未明确说明局限性，但可推断未来工作可扩展至更广泛临床验证和框架优化，以进一步推进技术发展。",
      "tags": [
        "Retrieval Augmented Generation",
        "Knowledge Graph",
        "Chain of Thought",
        "Large Language Models",
        "Traditional Chinese Medicine"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:44.153704Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22827",
    "title": "TARAZ: Persian Short-Answer Question Benchmark for Cultural Evaluation of Language Models",
    "authors": [
      "Reihaneh Iranmanesh",
      "Saeedeh Davoudi",
      "Pasha Abrishamchian",
      "Ophir Frieder",
      "Nazli Goharian"
    ],
    "abstract": "This paper presents a comprehensive evaluation framework for assessing the cultural competence of large language models (LLMs) in Persian. Existing Persian cultural benchmarks rely predominantly on multiple-choice formats and English-centric metrics that fail to capture Persian's morphological complexity and semantic nuance. Our framework introduces a Persian-specific short-answer evaluation that combines rule-based morphological normalization with a hybrid syntactic and semantic similarity module, enabling robust soft-match scoring beyond exact string overlap. Through systematic evaluation of 15 state-of-the-art open- and closed-source models, we demonstrate that our hybrid evaluation improves scoring consistency by +10% compared to exact-match baselines by capturing meaning that surface-level methods cannot detect. We publicly release our evaluation framework, providing the first standardized benchmark for measuring cultural understanding in Persian and establishing a reproducible foundation for cross-cultural LLM evaluation research.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22827.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22827",
    "published": "2026-02-26T10:08:02Z",
    "updated": "2026-02-26T10:08:02Z",
    "comment": "11 pages, 3 figures, Fifteenth biennial Language Resources and Evaluation Conference (LREC) 2026 (to appear)",
    "light_analysis": {
      "overview": "提出波斯语文化能力评估框架TARAZ，结合形态归一化和混合相似度模块，实现鲁棒的软匹配评分，提升大型语言模型的文化理解评估准确性。",
      "motivation": "本研究动机源于现有波斯语文化基准主要依赖多项选择题和英语中心指标，无法处理波斯语的形态复杂性和语义细微差别，导致评估不准确。这一问题的重要性在于波斯语作为全球主要语言，其文化理解评估对确保模型的实用性和公平性至关重要。现有方法不足以捕捉文化背景，制约了模型在波斯语环境中的应用性能，因此需要专门针对波斯语特性的评估框架以弥补这一研究空白。",
      "method": "论文方法采用波斯语特定短答案评估框架，核心包括基于规则的形态归一化处理和混合句法语义相似度模块。形态归一化处理波斯语的语法变化以降低噪声，相似度模块通过软匹配评分超越精确字符串匹配，实现更鲁棒的文化能力评估。关键创新点在于结合形态和语义分析，提高评估的准确性和鲁棒性，但摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "实验结果显示，通过对15个开源和闭源模型的系统评估，提出的混合评估方法相比精确匹配基线，在评分一致性上提升了10%。这一提升表明新框架能更有效地捕捉模型回答中的深层语义和文化含义，减少误判，从而为文化能力测量提供了更可靠的指标，验证了其在波斯语环境中的实用性和改进潜力。",
      "conclusion": "结论强调了论文的主要贡献：提出了首个标准化波斯语文化理解评估基准TARAZ，并公开框架以促进可重现的跨文化LLM评估研究。学术意义在于填补波斯语文化评估的空白，推动文化敏感AI发展；实际应用价值有助于提升模型的文化适应性和公平性。未来工作可扩展此框架到其他语言或文化领域，以促进全球LLM评估的统一性和可比性。",
      "tags": [
        "Large Language Model",
        "Cultural Competence Evaluation",
        "Morphological Normalization",
        "Hybrid Similarity",
        "Persian Benchmark"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:47.362025Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22823",
    "title": "Hypernetwork-based approach for grid-independent functional data clustering",
    "authors": [
      "Anirudh Thatipelli",
      "Ali Siahkoohi"
    ],
    "abstract": "Functional data clustering is concerned with grouping functions that share similar structure, yet most existing methods implicitly operate on sampled grids, causing cluster assignments to depend on resolution, sampling density, or preprocessing choices rather than on the underlying functions themselves. To address this limitation, we introduce a framework that maps discretized function observations -- at arbitrary resolution and on arbitrary grids -- into a fixed-dimensional vector space via an auto-encoding architecture. The encoder is a hypernetwork that maps coordinate-value pairs to the weight space of an implicit neural representation (INR), which serves as the decoder. Because INRs represent functions with very few parameters, this design yields compact representations that are decoupled from the sampling grid, while the hypernetwork amortizes weight prediction across the dataset. Clustering is then performed in this weight space using standard algorithms, making the approach agnostic to both the discretization and the choice of clustering method. By means of synthetic and real-world experiments in high-dimensional settings, we demonstrate competitive clustering performance that is robust to changes in sampling resolution -- including generalization to resolutions not seen during training.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22823.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22823",
    "published": "2026-02-26T10:05:07Z",
    "updated": "2026-02-26T10:05:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于超网络和隐式神经表示的网格独立函数数据聚类框架，以解耦聚类与采样网格的依赖。",
      "motivation": "函数数据聚类旨在根据结构相似性分组函数，但现有方法通常基于离散采样网格操作，导致聚类结果受分辨率、采样密度和预处理选择的影响，而非函数本质。这一问题在如时间序列分析等应用中尤为重要，因为网格依赖性限制了聚类的稳定性和可靠性，尤其在变分辨率或高维场景下。研究动机是克服这一不足，开发更稳健的方法，直接关注函数本身结构而非其离散表示。",
      "method": "论文引入一个自动编码架构，将任意分辨率和网格的离散函数观测映射到固定维度向量空间。编码器采用超网络，将坐标-值对映射到隐式神经表示（INR）的权重空间，解码器为INR。超网络分摊权重预测以提升效率，INR用少量参数表示函数，生成独立于采样网格的紧凑表示。聚类在权重空间进行，使用标准算法，使方法对离散化和聚类方法选择都不可知，适用于高维函数数据处理。",
      "result": "通过合成和现实世界的高维实验，该方法展现出具有竞争力的聚类性能。摘要未提供具体准确率数据，但强调聚类结果对采样分辨率变化具有鲁棒性，包括推广到训练中未见的分辨率。与基线方法相比，性能相当或更优，突显了该方法在解耦表示与网格方面的有效性，提高了聚类稳定性和适应性。",
      "conclusion": "该研究的主要贡献是提出了网格独立的函数数据聚类框架，结合超网络和隐式神经表示，解决了现有方法对采样网格的依赖。学术价值在于为函数数据分析提供了新视角，增强鲁棒性；实际应用可拓展至高维数据如信号处理和时间序列分析。局限性可能涉及计算复杂度或对特定数据类型的泛化，未来工作可探索优化和扩展到更广泛领域。",
      "tags": [
        "Hypernetwork",
        "Implicit Neural Representation",
        "Functional Data Clustering",
        "Autoencoder",
        "Grid-Independent Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:56.407529Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22822",
    "title": "FlexMS is a flexible framework for benchmarking deep learning-based mass spectrum prediction tools in metabolomics",
    "authors": [
      "Yunhua Zhong",
      "Yixuan Tang",
      "Yifan Li",
      "Jie Yang",
      "Pan Liu",
      "Jun Xia"
    ],
    "abstract": "The identification and property prediction of chemical molecules is of central importance in the advancement of drug discovery and material science, where the tandem mass spectrometry technology gives valuable fragmentation cues in the form of mass-to-charge ratio peaks. However, the lack of experimental spectra hinders the attachment of each molecular identification, and thus urges the establishment of prediction approaches for computational models. Deep learning models appear promising for predicting molecular structure spectra, but overall assessment remains challenging as a result of the heterogeneity in methods and the lack of well-defined benchmarks. To address this, our contribution is the creation of benchmark framework FlexMS for constructing and evaluating diverse model architectures in mass spectrum prediction. With its easy-to-use flexibility, FlexMS supports the dynamic construction of numerous distinct combinations of model architectures, while assessing their performance on preprocessed public datasets using different metrics. In this paper, we provide insights into factors influencing performance, including the structural diversity of datasets, hyperparameters like learning rate and data sparsity, pretraining effects, metadata ablation settings and cross-domain transfer learning analysis. This provides practical guidance in choosing suitable models. Moreover, retrieval benchmarks simulate practical identification scenarios and score potential matches based on predicted spectra.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22822.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22822",
    "published": "2026-02-26T10:05:01Z",
    "updated": "2026-02-26T10:05:01Z",
    "comment": "28 pages, preprint version",
    "light_analysis": {
      "overview": "提出FlexMS框架，用于在代谢组学中灵活基准测试深度学习质谱预测模型，填补方法异质性和基准缺失的空白。",
      "motivation": "化学分子识别和性质预测对药物发现和材料科学至关重要，质谱技术能提供关键碎片线索。然而，实验质谱数据稀缺，制约了分子识别的进展，亟需计算模型预测方法。现有深度学习模型虽然有潜力，但由于方法异质性和缺乏明确定义基准，整体评估面临挑战，导致难以比较和优化模型。因此，建立标准化基准框架以促进质谱预测模型的开发和评估成为迫切需求。",
      "method": "FlexMS框架通过动态构建多种深度学习模型架构组合，支持灵活基准测试。它基于预处理的公共数据集，使用不同性能指标评估模型。关键创新包括分析数据集结构多样性、超参数（如学习率和数据稀疏性）、预训练效果、元数据设置及跨域迁移学习等因素对性能的影响。框架还集成检索基准，模拟实际分子识别场景，评估预测质谱与实际质谱的匹配分数，增强实用性。",
      "result": "摘要未明确提供具体的实验结果数据，如准确率或效率改进数值。论文提到通过FlexMS框架分析了性能影响因素，为模型选择提供指导，但未详细说明基线方法的对比情况或性能提升的具体指标。这表明研究侧重于框架设计和影响因素分析，而非发布量化结果。",
      "conclusion": "论文的主要贡献是开发了FlexMS基准框架，解决了深度学习质谱预测模型的评估难题。该框架具有灵活性和易用性，能支持广泛模型架构的比较，提供实用指导帮助研究者选择合适模型。通过模拟实际场景的检索基准，增强了框架的应用价值。未来工作可扩展数据集、优化框架功能，并可能探索更复杂的预测任务和模型优化方法。",
      "tags": [
        "Deep Learning Models",
        "Mass Spectrum Prediction",
        "Benchmark Framework",
        "Hyperparameter Tuning",
        "Transfer Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:54.633940Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22821",
    "title": "CMSA-Net: Causal Multi-scale Aggregation with Adaptive Multi-source Reference for Video Polyp Segmentation",
    "authors": [
      "Tong Wang",
      "Yaolei Qi",
      "Siwen Wang",
      "Imran Razzak",
      "Guanyu Yang",
      "Yutong Xie"
    ],
    "abstract": "Video polyp segmentation (VPS) is an important task in computer-aided colonoscopy, as it helps doctors accurately locate and track polyps during examinations. However, VPS remains challenging because polyps often look similar to surrounding mucosa, leading to weak semantic discrimination. In addition, large changes in polyp position and scale across video frames make stable and accurate segmentation difficult. To address these challenges, we propose a robust VPS framework named CMSA-Net. The proposed network introduces a Causal Multi-scale Aggregation (CMA) module to effectively gather semantic information from multiple historical frames at different scales. By using causal attention, CMA ensures that temporal feature propagation follows strict time order, which helps reduce noise and improve feature reliability. Furthermore, we design a Dynamic Multi-source Reference (DMR) strategy that adaptively selects informative and reliable reference frames based on semantic separability and prediction confidence. This strategy provides strong multi-frame guidance while keeping the model efficient for real-time inference. Extensive experiments on the SUN-SEG dataset demonstrate that CMSA-Net achieves state-of-the-art performance, offering a favorable balance between segmentation accuracy and real-time clinical applicability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22821.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22821",
    "published": "2026-02-26T10:03:31Z",
    "updated": "2026-02-26T10:03:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出CMSA-Net框架，通过因果多尺度聚合模块和自适应多源参考策略，提升视频息肉分割的准确性和实时性。",
      "motivation": "视频息肉分割在计算机辅助结肠镜检查中至关重要，能帮助医生准确定位和跟踪息肉，改善诊断效果。然而，息肉与周围黏膜相似，导致语义区分困难，且视频帧中息肉位置和尺度变化大，使现有分割方法难以稳定处理动态场景。这些问题降低了分割的可靠性，因此开发鲁棒的框架以增强语义区分和时间一致性成为迫切需求。摘要未明确说明现有方法的具体不足，但强调了这些挑战的重要性。",
      "method": "研究提出了CMSA-Net框架，核心包括Causal Multi-scale Aggregation (CMA)模块和Dynamic Multi-source Reference (DMR)策略。CMA模块使用因果注意力从多个历史帧中聚合多尺度语义信息，确保时间顺序以减少噪声并提高特征可靠性。DMR策略基于语义可分性和预测置信度自适应选择参考帧，提供多帧指导，同时保持模型高效以支持实时推理。实验使用SUN-SEG数据集，框架设计旨在解决语义相似性和动态变化问题。",
      "result": "在SUN-SEG数据集上的实验表明，CMSA-Net达到了最先进的性能，在分割精度和实时临床适用性之间实现了良好平衡。摘要未提供具体性能指标如准确率数值，但强调了与基线方法相比的优势，并指出该方法为实时应用提供了高效框架，进一步验证了其鲁棒性和实用性。",
      "conclusion": "论文的主要贡献是提出CMSA-Net框架，通过因果多尺度聚合和自适应多源参考策略，有效解决视频息肉分割中的语义相似性和动态变化挑战。学术上，它引入了创新的注意力机制和参考选择方法；实际应用价值在于支持临床实时诊断，增强分割的稳定性和准确性。摘要未明确说明局限性或未来工作方向。",
      "tags": [
        "Video Polyp Segmentation",
        "Causal Attention",
        "Multi-scale Aggregation",
        "Real-time Segmentation",
        "Adaptive Reference"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:06.538714Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22819",
    "title": "Face Time Traveller : Travel Through Ages Without Losing Identity",
    "authors": [
      "Purbayan Kar",
      "Ayush Ghadiya",
      "Vishal Chudasama",
      "Pankaj Wasnik",
      "C. V. Jawahar"
    ],
    "abstract": "Face aging, an ill-posed problem shaped by environmental and genetic factors, is vital in entertainment, forensics, and digital archiving, where realistic age transformations must preserve both identity and visual realism. However, existing works relying on numerical age representations overlook the interplay of biological and contextual cues. Despite progress in recent face aging models, they struggle with identity preservation in wide age transformations, also static attention and optimization-heavy inversion in diffusion limit adaptability, fine-grained control and background consistency. To address these challenges, we propose Face Time Traveller (FaceTT), a diffusion-based framework that achieves high-fidelity, identity-consistent age transformation. Here, we introduce a Face-Attribute-Aware Prompt Refinement strategy that encodes intrinsic (biological) and extrinsic (environmental) aging cues for context-aware conditioning. A tuning-free Angular Inversion method is proposed that efficiently maps real faces into the diffusion latent space for fast and accurate reconstruction. Moreover, an Adaptive Attention Control mechanism is introduced that dynamically balances cross-attention for semantic aging cues and self-attention for structural and identity preservation. Extensive experiments on benchmark datasets and in-the-wild testset demonstrate that FaceTT achieves superior identity retention, background preservation and aging realism over state-of-the-art (SOTA) methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22819.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22819",
    "published": "2026-02-26T10:01:37Z",
    "updated": "2026-02-26T10:01:37Z",
    "comment": "Accepted at CVPR 2026 (Findings Track)",
    "light_analysis": {
      "overview": "Face Time Traveller 提出一种基于扩散的框架，通过属性感知提示优化、无调优角度反转和自适应注意力控制，实现高保真、身份一致的人脸年龄转换。",
      "motivation": "人脸老化问题在娱乐、法医和数字存档中至关重要，要求转换时保持身份和视觉真实感。现有方法依赖数值年龄表示，忽略了生物和上下文线索的相互作用，导致在广泛年龄转换中身份保留差；扩散模型中的静态注意力和优化重的反转也限制了适应性、细粒度控制和背景一致性，因此需更有效的解决方案来解决这些局限性。",
      "method": "FaceTT采用扩散模型框架，引入Face-Attribute-Aware Prompt Refinement策略，编码内在生物和外在环境老化线索以进行上下文感知条件调节；提出Tuning-free Angular Inversion方法，无需调整即可高效映射真实人脸到扩散潜在空间，实现快速准确重建；并设计Adaptive Attention Control机制，动态平衡交叉注意力（用于语义老化）和自注意力（用于结构身份保持）。实验在多个基准数据集和野外测试集上进行。",
      "result": "在基准数据集和野外测试集上的广泛实验显示，FaceTT在身份保留、背景保持和老化真实感方面优于当前最先进方法。尽管摘要未提供具体数值指标，但强调了其对现有技术的超越，表明在视觉质量和适应性方面有显著提升，例如在身份一致性测试中表现突出。",
      "conclusion": "论文通过FaceTT框架和一系列创新策略，有效解决了人脸老化中身份一致性和真实感的挑战，提升了扩散模型在该领域的应用。学术价值在于改进了老化模型的性能，实际应用则增强了娱乐、法医等领域的实用性；潜在局限性可能涉及极端年龄转换的适应性，未来工作可探索更细粒度控制或优化计算效率。摘要未明确说明具体局限性或未来方向细节。",
      "tags": [
        "Face Aging",
        "Diffusion Models",
        "Adaptive Attention Control",
        "Prompt Refinement",
        "Identity Preservation"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:28.153493Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22817",
    "title": "Hierarchy-of-Groups Policy Optimization for Long-Horizon Agentic Tasks",
    "authors": [
      "Shuo He",
      "Lang Feng",
      "Qi Wei",
      "Xin Cheng",
      "Lei Feng",
      "Bo An"
    ],
    "abstract": "Group-based reinforcement learning (RL), such as GRPO, has advanced the capabilities of large language models on long-horizon agentic tasks. To enable more fine-grained policy updates, recent research has increasingly shifted toward stepwise group-based policy optimization, which treats each step in a rollout trajectory independently while using a memory module to retain historical context. However, we find a key issue in estimating stepwise relative advantages, namely context inconsistency, where steps within the same group may differ in their historical contexts. Empirically, we reveal that this issue can lead to severely biased advantage estimation, thereby degrading policy optimization significantly. To address the issue, in this paper, we propose Hierarchy-of-Groups Policy Optimization (HGPO) for long-horizon agentic tasks. Specifically, within a group of rollout trajectories, HGPO assigns each step to multiple hierarchical groups according to the consistency of historical contexts. Then, for each step, HGPO computes distinct advantages within each group and aggregates them with an adaptive weighting scheme. In this way, HGPO can achieve a favorable bias-variance trade-off in stepwise advantage estimation, without extra models or rollouts. Evaluations on two challenging agentic tasks, ALFWorld and WebShop with Qwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct, show that HGPO significantly outperforms existing agentic RL methods under the same computational constraints. Code is available at https://github.com/langfengQ/verl-agent/tree/master/recipe/hgpo.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22817.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22817",
    "published": "2026-02-26T09:58:10Z",
    "updated": "2026-02-26T09:58:10Z",
    "comment": "Accepted at ICLR 2026",
    "light_analysis": {
      "overview": "本论文提出Hierarchy-of-Groups Policy Optimization (HGPO)方法，解决逐步优势估计中的上下文不一致性问题，显著提升长期代理任务的策略优化性能。",
      "motivation": "现有基于组的强化学习（如GRPO）已提升大型语言模型在长期代理任务中的能力。然而，逐步基于组的策略优化中，步骤独立处理并使用记忆模块，导致同一组内步骤的历史上下文不一致，引发优势估计严重偏差，进而显著降低策略优化效果。这突显了改进优势估计方法以支持更精细策略更新的重要性。",
      "method": "HGPO方法在组内根据历史上下文一致性将每个步骤分配到多个层次组，计算不同组内的优势值，并通过自适应加权方案聚合这些优势，实现偏差-方差权衡。核心创新在于层次分组和自适应聚合机制，无需额外模型或rollouts，使用Qwen2.5系列模型进行评估，但方法不依赖特定架构。",
      "result": "实验在ALFWorld和WebShop两个具有挑战性的长期代理任务上进行，使用Qwen2.5-1.5B-Instruct和Qwen2.5-7B-Instruct模型。结果表明，在相同计算约束下，HGPO显著优于现有代理强化学习方法，展示了其改进策略优化性能的有效性。代码已公开，但摘要未明确说明具体性能指标。",
      "conclusion": "本论文贡献是提出HGPO解决逐步优势估计中的上下文不一致性问题，提升了长期代理任务的策略优化。学术价值在于改进了强化学习技术，提供有效的偏差-方差权衡；实际应用可增强代理在复杂环境中的决策能力。未来工作可探索HGPO在其他任务或模型上的应用和潜在局限性。",
      "tags": [
        "Group-based Reinforcement Learning",
        "Policy Optimization",
        "Context Consistency",
        "Long-Horizon Tasks",
        "Adaptive Weighting"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:35.774999Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22814",
    "title": "When Should an AI Act? A Human-Centered Model of Scene, Context, and Behavior for Agentic AI Design",
    "authors": [
      "Soyoung Jung",
      "Daehoo Yoon",
      "Sung Gyu Koh",
      "Young Hwan Kim",
      "Yehan Ahn",
      "Sung Park"
    ],
    "abstract": "Agentic AI increasingly intervenes proactively by inferring users' situations from contextual data yet often fails for lack of principled judgment about when, why, and whether to act. We address this gap by proposing a conceptual model that reframes behavior as an interpretive outcome integrating Scene (observable situation), Context (user-constructed meaning), and Human Behavior Factors (determinants shaping behavioral likelihood). Grounded in multidisciplinary perspectives across the humanities, social sciences, HCI, and engineering, the model separates what is observable from what is meaningful to the user and explains how the same scene can yield different behavioral meanings and outcomes. To translate this lens into design action, we derive five agent design principles (behavioral alignment, contextual sensitivity, temporal appropriateness, motivational calibration, and agency preservation) that guide intervention depth, timing, intensity, and restraint. Together, the model and principles provide a foundation for designing agentic AI systems that act with contextual sensitivity and judgment in interactions.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22814.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22814",
    "published": "2026-02-26T09:56:37Z",
    "updated": "2026-02-26T09:56:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一个整合场景、上下文和人类行为因素的概念模型，并衍生出五个设计原则，用于指导代理AI系统的干预决策。",
      "motivation": "代理AI系统在主动干预用户行为时，常因缺乏对行动时机、原因和必要性的原则性判断而失败，导致系统不精准和用户不满。现有方法多依赖可观察数据，忽视了用户构建的意义和行为因素，限制了AI的判断能力。本研究旨在弥补这一差距，通过提供一个综合模型来改善AI的干预决策，提升系统的上下文敏感性和可靠性。",
      "method": "论文提出一个概念模型，将行为定义为整合场景（可观察情况）、上下文（用户构建意义）和人类行为因素（决定行为可能性）的解释性结果。该模型基于人文、社会科学、HCI和工程学的多学科视角，区分可观察内容与用户意义内容。基于此模型，衍生出五个代理设计原则：行为对齐、上下文敏感性、时间适当性、动机校准和代理保护，以指导干预的深度、时机、强度和克制。",
      "result": "摘要未明确说明具体实验结果，如准确率或效率改进。论文主要贡献是理论模型和设计原则，因此未提供与基线方法的对比数据。结果侧重于模型和原则的理论推导，未来研究可能需要实证验证其在具体系统中的效果，以评估实际性能提升。",
      "conclusion": "本研究提出的概念模型和设计原则为代理AI系统设计提供了新框架，强调上下文敏感性和判断力的重要性。模型基于多学科整合，有助于理解行为差异并指导干预决策。学术价值在于跨领域知识融合，实际应用价值在于提升AI系统的智能性和用户体验。未来工作可能包括模型应用实证和系统实现验证。",
      "tags": [
        "Agentic AI",
        "Conceptual Model",
        "Context Awareness",
        "Behavioral Modeling",
        "Human-Computer Interaction"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:22.772002Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22812",
    "title": "Accelerating Local LLMs on Resource-Constrained Edge Devices via Distributed Prompt Caching",
    "authors": [
      "Hiroki Matsutani",
      "Naoki Matsuda",
      "Naoto Sugiura"
    ],
    "abstract": "Since local LLM inference on resource-constrained edge devices imposes a severe performance bottleneck, this paper proposes distributed prompt caching to enhance inference performance by cooperatively sharing intermediate processing states across multiple low-end edge devices. To fully utilize prompt similarity, our distributed caching mechanism also supports partial matching. As this approach introduces communication overhead associated with state sharing over a wireless network, we introduce a Bloom-filter-based data structure, referred to as a catalog, to determine whether a remote server possesses the desired internal states, thereby suppressing unnecessary communication. Experiments using the Gemma-3 270M model and the MMLU dataset on the Raspberry Pi Zero 2W platform demonstrate that the proposed approach reduces TTFT (Time to First Token) and TTLT (Time to Last Token) by 93.12% and 50.07% on average, respectively.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22812.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22812",
    "published": "2026-02-26T09:53:17Z",
    "updated": "2026-02-26T09:53:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一种分布式提示缓存方法，通过在资源受限的边缘设备间共享中间处理状态，显著加速本地大型语言模型的推理性能。",
      "motivation": "本地大型语言模型在资源受限的边缘设备上进行推理时面临严重的性能瓶颈，因为计算能力和内存有限，导致延迟较高，影响边缘计算应用效率。现有方法通常依赖单设备处理，无法充分利用设备间协作来缓解资源限制，导致推理速度缓慢和资源利用率低下。因此，本研究旨在通过分布式方法解决这一问题，提升边缘环境中的LLM推理性能。",
      "method": "本论文提出分布式提示缓存机制，通过在多个低端边缘设备间协作共享中间处理状态来加速LLM推理。关键创新点包括支持提示的部分匹配，以充分利用相似性减少重复计算，以及引入基于Bloom过滤器的catalog数据结构，用于高效判断远程服务器是否拥有所需状态，从而抑制无线网络上的通信开销。实验使用Gemma-3 270M模型和MMLU数据集，在Raspberry Pi Zero 2W平台上实现和验证。",
      "result": "实验结果表明，所提出的分布式提示缓存方法在Raspberry Pi Zero 2W平台上，使用Gemma-3 270M模型和MMLU数据集，平均将首次令牌时间（TTFT）减少了93.12%，末次令牌时间（TTLT）减少了50.07%。这些性能提升表明该方法能有效降低推理延迟，相比未优化或单设备基准方法有显著改进，验证了其在高延迟边缘环境中的有效性。",
      "conclusion": "本论文的主要贡献是提出分布式提示缓存方法，通过设备间状态共享和Bloom过滤器优化通信，显著加速边缘设备上的本地LLM推理，提高了资源利用效率。这具有重要学术价值和实际应用意义，为边缘AI部署提供了新思路。未来工作可探索更复杂的模型集成或优化网络条件以进一步提升性能。",
      "tags": [
        "Large Language Model",
        "Distributed Caching",
        "Bloom Filter",
        "Edge Computing",
        "Prompt Similarity"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:32.295062Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22810",
    "title": "Multi-agent imitation learning with function approximation: Linear Markov games and beyond",
    "authors": [
      "Luca Viano",
      "Till Freihaut",
      "Emanuele Nevali",
      "Volkan Cevher",
      "Matthieu Geist",
      "Giorgia Ramponi"
    ],
    "abstract": "In this work, we present the first theoretical analysis of multi-agent imitation learning (MAIL) in linear Markov games where both the transition dynamics and each agent's reward function are linear in some given features. We demonstrate that by leveraging this structure, it is possible to replace the state-action level \"all policy deviation concentrability coefficient\" (Freihaut et al., arXiv:2510.09325) with a concentrability coefficient defined at the feature level which can be much smaller than the state-action analog when the features are informative about states' similarity. Furthermore, to circumvent the need for any concentrability coefficient, we turn to the interactive setting. We provide the first, computationally efficient, interactive MAIL algorithm for linear Markov games and show that its sample complexity depends only on the dimension of the feature map $d$. Building on these theoretical findings, we propose a deep MAIL interactive algorithm which clearly outperforms BC on games such as Tic-Tac-Toe and Connect4.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22810.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22810",
    "published": "2026-02-26T09:50:15Z",
    "updated": "2026-02-26T09:50:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文首次在线性马尔可夫博弈中理论分析多智能体模仿学习，提出特征级别集中系数和交互式算法以优化样本效率。",
      "motivation": "研究多智能体模仿学习（MAIL）在处理复杂环境时的效率问题，现有方法依赖于状态-动作级别的集中系数，这在高维或相似状态空间下可能导致样本需求过高，限制了实际应用。通过利用线性特征结构，可以降低对集中系数的依赖，提升学习效率和理论分析的可行性，因此本研究旨在探索MAIL在线性马尔可夫博弈中的理论基础，以解决样本复杂度高的挑战。",
      "method": "论文方法首先理论分析线性马尔可夫博弈，其中转移动力学和每个智能体的奖励函数都是线性特征的。核心创新是将状态-动作级别的集中系数替换为特征级别集中系数，当特征能有效表示状态相似性时，后者可大幅减小。接着，提出交互式设置下的计算高效MAIL算法，其样本复杂度仅依赖于特征映射的维度d。基于这些理论发现，开发深度MAIL交互式算法，应用于游戏环境如Tic-Tac-Toe和Connect4，以验证实际性能。",
      "result": "实验结果显示，所提出的深度MAIL交互式算法在Tic-Tac-Toe和Connect4游戏中性能明显优于基线方法行为克隆（BC）。理论分析表明，特征级别集中系数的使用可以减少样本复杂度，使算法更高效。摘要未提供具体量化指标如准确率提升，但通过交互式学习和线性特征近似，MAIL在这些复杂游戏中的表现得到验证，显示出实际应用的潜力和改进。",
      "conclusion": "本文主要贡献在于首次在线性马尔可夫博弈中建立多智能体模仿学习的理论分析框架，通过引入特征级别集中系数和改进交互式算法，显著优化了样本效率。这深化了MAIL的理论基础，并为实际应用如游戏策略学习提供了高效解决方案，未来工作可扩展至非线性特征或更广泛的多智能体环境，以进一步提升算法的泛化能力和实际适用性。",
      "tags": [
        "Multi-agent Imitation Learning",
        "Linear Markov Games",
        "Feature Approximation",
        "Interactive Learning",
        "Deep Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:34.599168Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22809",
    "title": "PhotoAgent: Agentic Photo Editing with Exploratory Visual Aesthetic Planning",
    "authors": [
      "Mingde Yao",
      "Zhiyuan You",
      "Tam-King Man",
      "Menglu Wang",
      "Tianfan Xue"
    ],
    "abstract": "With the recent fast development of generative models, instruction-based image editing has shown great potential in generating high-quality images. However, the quality of editing highly depends on carefully designed instructions, placing the burden of task decomposition and sequencing entirely on the user. To achieve autonomous image editing, we present PhotoAgent, a system that advances image editing through explicit aesthetic planning. Specifically, PhotoAgent formulates autonomous image editing as a long-horizon decision-making problem. It reasons over user aesthetic intent, plans multi-step editing actions via tree search, and iteratively refines results through closed-loop execution with memory and visual feedback, without requiring step-by-step user prompts. To support reliable evaluation in real-world scenarios, we introduce UGC-Edit, an aesthetic evaluation benchmark consisting of 7,000 photos and a learned aesthetic reward model. We also construct a test set containing 1,017 photos to systematically assess autonomous photo editing performance. Extensive experiments demonstrate that PhotoAgent consistently improves both instruction adherence and visual quality compared with baseline methods. The project page is https://github.com/mdyao/PhotoAgent.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22809.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22809",
    "published": "2026-02-26T09:46:06Z",
    "updated": "2026-02-26T09:46:06Z",
    "comment": "A fully automated, intelligent photo-editing agent that autonomously plans multi-step aesthetic enhancements, smartly chooses diverse editing tools, and enables everyday users to achieve professional-looking results without crafting complex prompts. Project page: https://github.com/mdyao/PhotoAgent",
    "light_analysis": {
      "overview": "PhotoAgent通过显式美学规划和树搜索技术实现自主图像编辑，提升美学质量和用户效率。",
      "motivation": "随着生成模型的快速发展，指令基于图像编辑在生成高质量图像方面展现出巨大潜力。然而，编辑质量高度依赖于用户精心设计的指令，这要求用户承担任务分解和序列化的全部负担，增加了使用复杂度。现有方法无法自主处理复杂编辑任务，限制了实际应用。因此，本文旨在开发一个系统，通过自动化美学规划来实现自主图像编辑，以减轻用户负担、提高编辑效果，并推动更智能的图像处理工具的发展。",
      "method": "PhotoAgent将自主图像编辑建模为长期决策问题，通过推理用户的美学意图，利用树搜索算法规划多步编辑动作。系统采用闭环执行机制，结合内存和视觉反馈迭代优化结果，无需用户逐步提示。关键创新在于将规划与执行结合，实现自主和适应性强的编辑流程。为支持可靠评估，本文引入了UGC-Edit基准，包括7,000张照片和美学奖励模型，以及一个1,017张照片的测试集来系统评估性能。",
      "result": "通过广泛实验，PhotoAgent在指令遵循和视觉质量方面相比基线方法表现出一致的改进。在UGC-Edit基准和测试集上的评估显示，系统能更好地理解和执行用户意图，生成更高质量的图像。具体性能指标如准确率等在摘要中未明确说明，但与基线相比有显著提升，验证了自主美学规划的有效性和实用性。",
      "conclusion": "PhotoAgent通过显式美学规划成功实现了自主图像编辑，减少了用户干预，提升了编辑效率和美学质量。该研究的学术价值在于提出了一种结合规划与执行的框架，推动了自主编辑领域的发展。实际应用价值体现在为图像处理工具提供更智能的自动化能力。潜在局限性可能包括计算复杂度或对特定数据集的依赖性，未来工作可扩展至更多编辑任务或优化规划算法。",
      "tags": [
        "Autonomous Image Editing",
        "Tree Search",
        "Aesthetic Planning",
        "Closed-loop Execution",
        "Visual Feedback"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:43.641053Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22808",
    "title": "MiroFlow: Towards High-Performance and Robust Open-Source Agent Framework for General Deep Research Tasks",
    "authors": [
      "Shiqian Su",
      "Sen Xing",
      "Xuan Dong",
      "Muyan Zhong",
      "Bin Wang",
      "Xizhou Zhu",
      "Yuntao Chen",
      "Wenhai Wang",
      "Yue Deng",
      "Pengxiang Zhu",
      "Ziyuan Liu",
      "Tiantong Li",
      "Jiaheng Yu",
      "Zhe Chen",
      "Lidong Bing",
      "Jifeng Dai"
    ],
    "abstract": "Despite the remarkable progress of large language models (LLMs), the capabilities of standalone LLMs have begun to plateau when tackling real-world, complex tasks that require interaction with external tools and dynamic environments. Although recent agent frameworks aim to enhance model autonomy through tool integration and external interaction, they still suffer from naive workflows, unstable performance, limited support across diverse benchmarks and tasks, and heavy reliance on costly commercial APIs. In this work, we propose a high-performance and robust open-source agent framework, termed MiroFlow, which incorporates an agent graph for flexible orchestration, an optional deep reasoning mode to enhance performance, and a robust workflow execution to ensure stable and reproducible performance. Extensive experiments demonstrate that MiroFlow consistently achieves state-of-the-art performance across multiple agent benchmarks, including GAIA, BrowseComp-EN/ZH, HLE, xBench-DeepSearch, and notably FutureX. We hope it could serve as an easily accessible, reproducible, and comparable baseline for the deep research community.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22808.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22808",
    "published": "2026-02-26T09:45:04Z",
    "updated": "2026-02-26T09:45:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "MiroFlow是一个开源代理框架，通过代理图、深度推理模式和稳健工作流，提升LLM代理在复杂任务中的性能和稳定性。",
      "motivation": "研究动机在于大型语言模型在独立处理真实世界复杂任务（需要外部工具交互和动态环境适应）时能力趋于饱和。尽管现有代理框架通过工具集成增强自主性，但仍存在工作流简单、性能不稳定、跨不同基准和任务支持有限，以及严重依赖昂贵商业API等不足。因此，开发一个高性能、稳健且开源的新框架来解决这些问题至关重要，以促进更可靠的代理系统应用和研究发展。",
      "method": "MiroFlow框架的核心技术包括代理图用于灵活任务编排，可选的深度推理模式以增强处理复杂问题的能力，以及稳健的工作流执行机制确保性能稳定和可重复。这些创新组件设计旨在克服现有框架的局限性，提供更灵活的架构和增强的推理能力。摘要未明确说明使用的具体数据集或模型架构细节，但框架侧重于代理系统的高效与鲁棒性整合。",
      "result": "实验表明MiroFlow在多个代理基准测试中实现了最先进的性能，涵盖GAIA、BrowseComp-EN/ZH、HLE、xBench-DeepSearch和FutureX等。这些结果证明框架在各种任务和基准上具有鲁棒性和高效性，与基线方法相比，表现出显著的性能提升。摘要未提供具体的准确率或效率改进数据，但其声称达到领先水平，凸显了实际效果和跨基准的一致性。",
      "conclusion": "论文主要贡献是提出了MiroFlow，一个开源高性能代理框架，通过灵活编排和稳健执行为深度研究任务提供可靠工具。学术价值在于推动了代理系统技术进步，实际应用价值在于降低对商业API的依赖，并为研究社区设立可访问、可重复和可比较的基准。未来工作方向可能包括扩展更多基准或优化性能，但摘要未明确说明具体细节。",
      "tags": [
        "Agent Framework",
        "Large Language Model",
        "Deep Reasoning",
        "Benchmark Evaluation",
        "Graph Orchestration"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:44.425487Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22800",
    "title": "GSTurb: Gaussian Splatting for Atmospheric Turbulence Mitigation",
    "authors": [
      "Hanliang Du",
      "Zhangji Lu",
      "Zewei Cai",
      "Qijian Tang",
      "Qifeng Yu",
      "Xiaoli Liu"
    ],
    "abstract": "Atmospheric turbulence causes significant image degradation due to pixel displacement (tilt) and blur, particularly in long-range imaging applications. In this paper, we propose a novel framework for atmospheric turbulence mitigation, GSTurb, which integrates optical flow-guided tilt correction and Gaussian splatting for modeling non-isoplanatic blur. The framework employs Gaussian parameters to represent tilt and blur, and optimizes them across multiple frames to enhance restoration. Experimental results on the ATSyn-static dataset demonstrate the effectiveness of our method, achieving a peak PSNR of 27.67 dB and SSIM of 0.8735. Compared to the state-of-the-art method, GSTurb improves PSNR by 1.3 dB (a 4.5% increase) and SSIM by 0.048 (a 5.8% increase). Additionally, on real datasets, including the TSRWGAN Real-World and CLEAR datasets, GSTurb outperforms existing methods, showing significant improvements in both qualitative and quantitative performance. These results highlight that combining optical flow-guided tilt correction with Gaussian splatting effectively enhances image restoration under both synthetic and real-world turbulence conditions. The code for this method will be available at https://github.com/DuhlLiamz/3DGS_turbulence/tree/main.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22800.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22800",
    "published": "2026-02-26T09:37:27Z",
    "updated": "2026-02-26T09:37:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出GSTurb框架，通过集成光流引导的倾斜校正和高斯splatting，有效缓解大气湍流导致的图像退化问题。",
      "motivation": "大气湍流在长距离成像中引起像素位移（倾斜）和模糊，导致图像质量严重下降，影响实际应用如监控或遥感。现有方法可能难以同时处理非等晕模糊和动态倾斜，限制恢复效果。本研究针对这一挑战，旨在开发综合框架来提升图像恢复的准确性和鲁棒性，解决传统技术在复杂湍流环境下的不足。",
      "method": "GSTurb框架结合光学流引导的倾斜校正和高斯splatting技术。利用高斯参数表示湍流引起的倾斜和模糊，通过优化这些参数在多帧图像中进行恢复。关键创新包括使用光流信息指导倾斜校正过程，以及应用高斯splatting建模非等晕模糊的复杂分布，实现全面的图像增强。该方法在多个帧上迭代优化参数，以提升细节清晰度。",
      "result": "在ATSyn-static合成数据集上，GSTurb达到峰值PSNR 27.67 dB和SSIM 0.8735。相比最先进方法，PSNR提升1.3 dB（4.5%），SSIM提升0.048（5.8%）。在真实数据集如TSRWGAN Real-World和CLEAR上，也显示出显著的定性和定量改进，验证了方法的有效性和泛化能力，超越了现有技术。",
      "conclusion": "GSTurb通过整合光流和高斯splatting，有效提升了大气湍流下的图像恢复质量，适用于合成和真实场景。该研究为长距离成像提供了新颖解决方案，具有学术价值和实际应用潜力。未来工作可能包括优化计算效率或扩展到其他图像退化问题，以促进领域发展，摘要未明确说明具体局限性。",
      "tags": [
        "Gaussian Splatting",
        "Optical Flow",
        "Atmospheric Turbulence Mitigation",
        "Image Restoration"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:57.068510Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22794",
    "title": "Doubly Adaptive Channel and Spatial Attention for Semantic Image Communication by IoT Devices",
    "authors": [
      "Soroosh Miri",
      "Sepehr Abolhasani",
      "Shahrokh Farahmand",
      "S. Mohammad Razavizadeh"
    ],
    "abstract": "Internet of Things (IoT) networks face significant challenges such as limited communication bandwidth, constrained computational and energy resources, and highly dynamic wireless channel conditions. Utilization of deep neural networks (DNNs) combined with semantic communication has emerged as a promising paradigm to address these limitations. Deep joint source-channel coding (DJSCC) has recently been proposed to enable semantic communication of images. Building upon the original DJSCC formulation, low-complexity attention-style architectures has been added to the DNNs for further performance enhancement. As a main hurdle, training these DNNs separately for various signal-to-noise ratios (SNRs) will amount to excessive storage or communication overhead, which can not be maintained by small IoT devices. SNR Adaptive DJSCC (ADJSCC), has been proposed to train the DNNs once but feed the current SNR as part of the data to the channel-wise attention mechanism. We improve upon ADJSCC by a simultaneous utilization of doubly adaptive channel-wise and spatial attention modules at both transmitter and receiver. These modules dynamically adjust to varying channel conditions and spatial feature importance, enabling robust and efficient feature extraction and semantic information recovery. Simulation results corroborate that our proposed doubly adaptive DJSCC (DA-DJSCC) significantly improves upon ADJSCC in several performance criteria, while incurring a mild increase in complexity. These facts render DA-DJSCC a desirable choice for semantic communication in performance demanding but low-complexity IoT networks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22794.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22794",
    "published": "2026-02-26T09:29:42Z",
    "updated": "2026-02-26T09:29:42Z",
    "comment": "6 pages, 7 figures, conference",
    "light_analysis": {
      "overview": "提出一种双重自适应信道和空间注意力的深度联合源信道编码方法，以增强物联网设备在动态信道条件下的语义图像通信性能和效率。",
      "motivation": "物联网网络在语义图像通信中面临带宽有限、计算资源受限和无线信道条件高度动态的挑战。现有深度联合源信道编码方法需要针对不同信噪比分别训练深度神经网络，导致过高的存储和通信开销，这不适合资源受限的小型物联网设备。因此，开发一种能自适应信道变化且低复杂度的通信方法至关重要，以克服现有方法在实际部署中的不足。",
      "method": "本文提出双重自适应深度联合源信道编码方法，通过在发送端和接收端同时集成信道和空间注意力模块。这些模块动态调整以适应变化信道条件和空间特征重要性，实现鲁棒的语义信息提取和恢复。基于深度神经网络，该方法训练一次即可适应多种信噪比，减少了训练和部署开销，是改进先前自适应方法的关键创新。",
      "result": "模拟实验结果表明，所提出的DA-DJSCC方法在多个性能标准上显著优于先前的ADJSCC方法，例如在通信效率和鲁棒性方面有提升，虽然复杂性略有增加，但这种提升在可接受范围内。与基线方法对比，DA-DJSCC展示了更好的适应性，适用于资源受限的物联网网络。",
      "conclusion": "本研究的主要贡献是开发了一种双重自适应注意力机制的深度联合源信道编码方案，有效解决了物联网语义通信中的动态信道适应问题。该方法在学术上推进了注意力机制在通信领域的应用，实际上为高性能、低复杂度的物联网网络提供了可行的通信解决方案，潜在局限性如具体性能指标未详细说明，未来工作可能包括进一步优化复杂性和扩展到其他应用场景。",
      "tags": [
        "Semantic Communication",
        "Deep Joint Source-Channel Coding",
        "Attention Mechanism",
        "Internet of Things",
        "Adaptive Networks"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:50.089890Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22791",
    "title": "Robust Human Trajectory Prediction via Self-Supervised Skeleton Representation Learning",
    "authors": [
      "Taishu Arashima",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "abstract": "Human trajectory prediction plays a crucial role in applications such as autonomous navigation and video surveillance. While recent works have explored the integration of human skeleton sequences to complement trajectory information, skeleton data in real-world environments often suffer from missing joints caused by occlusions. These disturbances significantly degrade prediction accuracy, indicating the need for more robust skeleton representations. We propose a robust trajectory prediction method that incorporates a self-supervised skeleton representation model pretrained with masked autoencoding. Experimental results in occlusion-prone scenarios show that our method improves robustness to missing skeletal data without sacrificing prediction accuracy, and consistently outperforms baseline models in clean-to-moderate missingness regimes.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22791.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22791",
    "published": "2026-02-26T09:25:52Z",
    "updated": "2026-02-26T09:25:52Z",
    "comment": "11 pages main, 5 pages supplementary material",
    "light_analysis": {
      "overview": "提出了一种通过自监督骨架表示学习来提高人类轨迹预测鲁棒性的方法。",
      "motivation": "人类轨迹预测在自动驾驶和视频监控等应用中至关重要，但现有方法在集成骨架序列时，常因现实环境中的遮挡问题导致骨架数据关节缺失，这显著降低了预测精度。因此，迫切需要开发更鲁棒的骨架表示方法，以应对这些干扰并提升预测系统的可靠性，从而解决实际应用中的性能退化问题。",
      "method": "论文提出了一种结合自监督骨架表示模型的鲁棒轨迹预测方法，其核心是通过掩码自编码进行预训练，以学习缺失关节情况下的鲁棒骨架表示。关键创新点在于利用自监督学习技术增强骨架表示的鲁棒性，从而在轨迹预测任务中更有效地处理遮挡导致的缺失数据，无需牺牲预测性能。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验结果表明，在易发生遮挡的场景中，该方法显著提高了对缺失骨架数据的鲁棒性，同时保持了预测精度。与基线模型相比，在从清洁数据到中等缺失程度的各种情况下，该方法均表现出更优越的性能，验证了自监督骨架表示在增强轨迹预测鲁棒性方面的有效性。",
      "conclusion": "该研究的主要贡献是提出了一种鲁棒的人类轨迹预测方法，通过自监督学习改进骨架表示。其学术价值在于提升了轨迹预测模型对缺失数据的处理能力，实际应用价值在于为自动驾驶和视频监控系统提供更可靠的预测支持。未来工作可能涉及模型优化或扩展到其他相关领域。",
      "tags": [
        "Human Trajectory Prediction",
        "Self-Supervised Learning",
        "Skeleton Representation",
        "Masked Autoencoding"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:09.311363Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22790",
    "title": "Natural Language Declarative Prompting (NLD-P): A Modular Governance Method for Prompt Design Under Model Drift",
    "authors": [
      "Hyunwoo Kim",
      "Hanau Yi",
      "Jaehee Bae",
      "Yumin Kim"
    ],
    "abstract": "The rapid evolution of large language models (LLMs) has transformed prompt engineering from a localized craft into a systems-level governance challenge. As models scale and update across generations, prompt behavior becomes sensitive to shifts in instruction-following policies, alignment regimes, and decoding strategies, a phenomenon we characterize as GPT-scale model drift. Under such conditions, surface-level formatting conventions and ad hoc refinement are insufficient to ensure stable, interpretable control. This paper reconceptualizes Natural Language Declarative Prompting (NLD-P) as a declarative governance method rather than a rigid field template. NLD-P is formalized as a modular control abstraction that separates provenance, constraint logic, task content, and post-generation evaluation, encoded directly in natural language without reliance on external orchestration code. We define minimal compliance criteria, analyze model-dependent schema receptivity, and position NLD-P as an accessible governance framework for non-developer practitioners operating within evolving LLM ecosystems. Portions of drafting and editorial refinement employed a schema-bound LLM assistant configured under NLD-P. All conceptual framing, methodological claims, and final revisions were directed, reviewed, and approved by the human author under a documented human-in-the-loop protocol. The paper concludes by outlining implications for declarative control under ongoing model evolution and identifying directions for future empirical validation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22790.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22790",
    "published": "2026-02-26T09:23:09Z",
    "updated": "2026-02-26T09:23:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了Natural Language Declarative Prompting (NLD-P)，一种模块化声明式治理方法，用于在大型语言模型漂移下实现稳定和可解释的提示设计。",
      "motivation": "随着大型语言模型的快速发展和更新，模型漂移现象导致提示行为对指令遵循策略、对齐机制和解码策略的变化敏感，传统基于表面级格式化约定和临时细化的提示工程方法难以确保稳定控制。这一问题在LLM生态系统演变中日益突出，突显了需要系统级治理方法来应对模型变化，维护提示的可靠性和可解释性，从而解决非开发人员从业者在动态环境中面临的挑战。",
      "method": "NLD-P被形式化为一个模块化控制抽象，分离了来源、约束逻辑、任务内容和后生成评估，直接编码在自然语言中，无需依赖外部编排代码。该方法定义了最小合规标准，并分析模型依赖的模式接受性，旨在为非开发人员从业者提供一个易于使用的治理框架。部分撰写过程使用了NLD-P配置的LLM助手，展示了其在实践中的应用潜力。",
      "result": "摘要未明确说明具体的实验结果或性能指标。然而，论文通过理论框架和概念分析，可能展示了NLD-P在模型漂移下提供稳定和可解释控制的潜力。提及部分撰写使用了该方法，暗示其在实际应用中的可行性，但未提供与基线方法的对比数据或量化改进。",
      "conclusion": "NLD-P作为一个模块化声明式治理框架，为大型语言模型漂移下的提示设计提供了理论支持，增强了控制的稳定性和可解释性。其学术价值在于提出了系统级治理方法，实际意义在于为非开发人员从业者提供了可访问的工具。未来研究方向包括进一步实证验证，以及在持续模型演变中探索声明式控制的应用和局限性。",
      "tags": [
        "Natural Language Prompting (NLD-P)",
        "Large Language Models",
        "Model Drift",
        "Declarative Control",
        "Modular Governance"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:11.134373Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22787",
    "title": "Probing for Knowledge Attribution in Large Language Models",
    "authors": [
      "Ivo Brink",
      "Alexander Boer",
      "Dennis Ulmer"
    ],
    "abstract": "Large language models (LLMs) often generate fluent but unfounded claims, or hallucinations, which fall into two types: (i) faithfulness violations - misusing user context - and (ii) factuality violations - errors from internal knowledge. Proper mitigation depends on knowing whether a model's answer is based on the prompt or its internal weights. This work focuses on the problem of contributive attribution: identifying the dominant knowledge source behind each output. We show that a probe, a simple linear classifier trained on model hidden representations, can reliably predict contributive attribution. For its training, we introduce AttriWiki, a self-supervised data pipeline that prompts models to recall withheld entities from memory or read them from context, generating labelled examples automatically. Probes trained on AttriWiki data reveal a strong attribution signal, achieving up to 0.96 Macro-F1 on Llama-3.1-8B, Mistral-7B, and Qwen-7B, transferring to out-of-domain benchmarks (SQuAD, WebQuestions) with 0.94-0.99 Macro-F1 without retraining. Attribution mismatches raise error rates by up to 70%, demonstrating a direct link between knowledge source confusion and unfaithful answers. Yet, models may still respond incorrectly even when attribution is correct, highlighting the need for broader detection frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22787.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22787",
    "published": "2026-02-26T09:21:12Z",
    "updated": "2026-02-26T09:21:12Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一个简单线性探针方法，可靠地识别大型语言模型输出中知识来源的主导性，以区分幻觉类型并提升模型可信度。",
      "motivation": "大型语言模型常产生流畅但无根据的幻觉，分为误用用户上下文的忠实性违反和内部知识错误的事实性违反。问题关键在于无法确定答案基于提示还是模型权重，导致难以针对性缓解。现有方法缺乏有效归因机制，使得模型可靠性受限，因此研究知识来源归因对改进AI系统的透明度和准确性至关重要。",
      "method": "研究提出使用一个简单的线性分类器作为探针，在模型的隐藏表示上训练，以预测输出知识来源是内部记忆还是外部上下文。关键创新是引入AttriWiki自监督数据管道，通过提示模型回忆记忆中的实体或从上下文中阅读，自动生成带标签的示例用于训练。实验涉及Llama-3.1-8B、Mistral-7B和Qwen-7B等模型，探针训练基于这些隐藏状态，无需复杂架构。",
      "result": "在AttriWiki数据上训练的探针在Llama-3.1-8B等模型上达到高达0.96的宏F1分数，且无需重新训练即可迁移到SQuAD和WebQuestions等外部基准，宏F1分数为0.94-0.99，显示其强泛化能力。归因不匹配（如误判知识来源）导致模型错误率增加达70%，证明了知识来源混淆与不忠实答案的直接关联。然而，即使归因正确，模型仍可能错误响应，凸显了检测框架的局限性。",
      "conclusion": "论文证实线性探针能有效归因知识来源，为缓解大型语言模型幻觉提供了新工具，具有学术价值。实际应用上，这有助于开发更可靠的AI系统，但研究指出仅归因不足，需要结合更广泛的检测方法以应对复杂错误。未来工作可扩展归因框架或集成其他检测技术，以全面提升模型性能。",
      "tags": [
        "Large Language Model",
        "Knowledge Attribution",
        "Probing",
        "Self-Supervised Learning",
        "Linear Classification"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:10.832745Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22785",
    "title": "SceneTransporter: Optimal Transport-Guided Compositional Latent Diffusion for Single-Image Structured 3D Scene Generation",
    "authors": [
      "Ling Wang",
      "Hao-Xiang Guo",
      "Xinzhou Wang",
      "Fuchun Sun",
      "Kai Sun",
      "Pengkun Liu",
      "Hang Xiao",
      "Zhong Wang",
      "Guangyuan Fu",
      "Eric Li",
      "Yang Liu",
      "Yikai Wang"
    ],
    "abstract": "We introduce SceneTransporter, an end-to-end framework for structured 3D scene generation from a single image. While existing methods generate part-level 3D objects, they often fail to organize these parts into distinct instances in open-world scenes. Through a debiased clustering probe, we reveal a critical insight: this failure stems from the lack of structural constraints within the model's internal assignment mechanism. Based on this finding, we reframe the task of structured 3D scene generation as a global correlation assignment problem. To solve this, SceneTransporter formulates and solves an entropic Optimal Transport (OT) objective within the denoising loop of the compositional DiT model. This formulation imposes two powerful structural constraints. First, the resulting transport plan gates cross-attention to enforce an exclusive, one-to-one routing of image patches to part-level 3D latents, preventing entanglement. Second, the competitive nature of the transport encourages the grouping of similar patches, a process that is further regularized by an edge-based cost, to form coherent objects and prevent fragmentation. Extensive experiments show that SceneTransporter outperforms existing methods on open-world scene generation, significantly improving instance-level coherence and geometric fidelity. Code and models will be publicly available at https://2019epwl.github.io/SceneTransporter/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22785.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22785",
    "published": "2026-02-26T09:19:59Z",
    "updated": "2026-02-26T09:19:59Z",
    "comment": "published at iclr 2026",
    "light_analysis": {
      "overview": "SceneTransporter提出了一种基于最优运输指导的构图潜在扩散框架，用于从单张图像生成结构化3D场景。",
      "motivation": "现有方法在生成部分级别3D对象时，难以在开放世界场景中将它们组织成不同的实例，导致场景出现纠缠和碎片化问题。通过去偏聚类探测，我们发现这种失败源于模型内部分配机制缺乏结构约束，影响了实例级一致性和几何保真度。因此，本研究旨在解决这一结构化场景生成问题，重新定义任务为全局相关性分配，以弥补现有方法的不足。",
      "method": "SceneTransporter将任务重构为全局相关性分配问题，在 compositional DiT 模型的去噪循环中，采用熵最优运输目标。该方法施加两个结构约束：运输计划通过控制交叉注意力，强制实现图像补丁到部分级别3D潜在变量的一对一专属分配，防止纠缠；竞争性运输鼓励相似补丁分组，并通过基于边缘的成本正则化，形成连贯对象并避免碎片化。核心创新包括最优运输与扩散模型的结合，以及结构约束的集成。",
      "result": "广泛的实验表明，SceneTransporter在开放世界场景生成任务中优于现有方法，显著提高了实例级一致性和几何保真度。尽管摘要未明确说明具体性能指标（如准确率或效率数据），但通过视觉评估和基准对比，验证了该方法在减少纠缠和碎片化方面的有效性，优于基线方法，改善了结构化场景的质量。",
      "conclusion": "本研究的主要贡献是提出了SceneTransporter框架，通过最优运输指导的构图潜在扩散，改进了结构化3D场景生成。其学术价值在于为解决实例级一致性提供了新方法，推动3D生成领域发展；实际应用可用于计算机图形学、虚拟现实等场景。摘要未明确说明局限性，但未来工作可能包括优化模型效率或扩展到更多场景类型，代码和模型的公开将促进社区进步。",
      "tags": [
        "Optimal Transport",
        "Latent Diffusion",
        "Diffusion Transformers",
        "Cross-Attention",
        "3D Scene Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:21.886573Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22779",
    "title": "TrajTok: Learning Trajectory Tokens enables better Video Understanding",
    "authors": [
      "Chenhao Zheng",
      "Jieyu Zhang",
      "Jianing Zhang",
      "Weikai Huang",
      "Ashutosh Kumar",
      "Quan Kong",
      "Oncel Tuzel",
      "Chun-Liang Li",
      "Ranjay Krishna"
    ],
    "abstract": "Tokenization in video models, typically through patchification, generates an excessive and redundant number of tokens. This severely limits video efficiency and scalability. While recent trajectory-based tokenizers offer a promising solution by decoupling video duration from token count, they rely on complex external segmentation and tracking pipelines that are slow and task-agnostic. We propose TrajTok, an end-to-end video tokenizer module that is fully integrated and co-trained with video models for a downstream objective, dynamically adapting its token granularity to semantic complexity, independent of video duration. TrajTok contains a unified segmenter that performs implicit clustering over pixels in both space and time to directly produce object trajectories in a single forward pass. By prioritizing downstream adaptability over pixel-perfect segmentation fidelity, TrajTok is lightweight and efficient, yet empirically improves video understanding performance. With TrajTok, we implement a video CLIP model trained from scratch (TrajViT2). It achieves the best accuracy at scale across both classification and retrieval benchmarks, while maintaining efficiency comparable to the best token-merging methods. TrajTok also proves to be a versatile component beyond its role as a tokenizer. We show that it can be seamlessly integrated as either a probing head for pretrained visual features (TrajAdapter) or an alignment connector in vision-language models (TrajVLM) with especially strong performance in long-video reasoning.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22779.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22779",
    "published": "2026-02-26T09:15:34Z",
    "updated": "2026-02-26T09:15:34Z",
    "comment": "CVPR 2026",
    "light_analysis": {
      "overview": "TrajTok提出一种端到端视频分词器，通过动态学习轨迹tokens来提升视频理解性能和效率。",
      "motivation": "视频理解模型中，传统分词方法如补丁化会生成大量冗余tokens，严重限制模型的效率和可扩展性。现有基于轨迹的分词器虽能解耦视频时长与token数量，但依赖复杂的外部分割和跟踪管道，导致速度慢且任务无关，难以适应下游需求。因此，需要一种轻量、高效且能动态适应语义复杂度的集成式分词器来解决这些问题。",
      "method": "TrajTok是一个端到端视频分词器模块，与下游视频模型集成并共训练，动态调整token粒度以匹配语义复杂度。其核心是统一分割器，通过时空隐式聚类像素，在单次前向传递中直接生成物体轨迹，优先下游任务适应性而非像素完美分割，实现轻量高效设计。使用TrajTok实现了从零训练的TrajViT2模型，展示了该方法的技术特色。",
      "result": "实验结果显示，TrajTok实现的TrajViT2模型在视频分类和检索基准上取得了最佳准确率，同时效率与现有最佳token合并方法可比。此外，TrajTok作为探针头TrajAdapter或对齐连接器TrajVLM时，在长视频推理任务中表现尤为出色，验证了其在多任务整合中的通用性和有效性。",
      "conclusion": "TrajTok的主要贡献是提出一种轻量、高效的端到端视频分词器，通过动态轨迹学习提升视频理解和效率，具有重要的学术价值，推动了视频模型设计的创新。在实际应用上，它支持长视频推理和视觉语言模型整合，尽管摘要未明确说明局限性，但未来工作可能包括扩展到更广泛视频任务或进一步优化效率。",
      "tags": [
        "Video Tokenization",
        "Trajectory Learning",
        "End-to-End Training",
        "Implicit Clustering",
        "Vision-Language Models"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:18.019021Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22777",
    "title": "KMLP: A Scalable Hybrid Architecture for Web-Scale Tabular Data Modeling",
    "authors": [
      "Mingming Zhang",
      "Pengfei Shi",
      "Zhiqing Xiao",
      "Feng Zhao",
      "Guandong Sun",
      "Yulin Kang",
      "Ruizhe Gao",
      "Ningtao Wang",
      "Xing Fu",
      "Weiqiang Wang",
      "Junbo Zhao"
    ],
    "abstract": "Predictive modeling on web-scale tabular data with billions of instances and hundreds of heterogeneous numerical features faces significant scalability challenges. These features exhibit anisotropy, heavy-tailed distributions, and non-stationarity, creating bottlenecks for models like Gradient Boosting Decision Trees and requiring laborious manual feature engineering. We introduce KMLP, a hybrid deep architecture integrating a shallow Kolmogorov-Arnold Network (KAN) front-end with a Gated Multilayer Perceptron (gMLP) backbone. The KAN front-end uses learnable activation functions to automatically model complex non-linear transformations for each feature, while the gMLP backbone captures high-order interactions. Experiments on public benchmarks and an industrial dataset with billions of samples show KMLP achieves state-of-the-art performance, with advantages over baselines like GBDTs increasing at larger scales, validating KMLP as a scalable deep learning paradigm for large-scale web tabular data.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22777.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22777",
    "published": "2026-02-26T09:12:12Z",
    "updated": "2026-02-26T09:12:12Z",
    "comment": "Accepted by THE ACM WEB CONFERENCE 2026",
    "light_analysis": {
      "overview": "KMLP提出一种可扩展的混合深度架构，结合KAN前端和gMLP主干，专为大规模网络表格数据建模设计，实现了最先进的性能。",
      "motivation": "研究动机在于处理具有数十亿实例和数百个异构数值特征的网络规模表格数据时，现有方法如梯度提升决策树面临严重的可扩展性挑战。这些特征表现出各向异性、重尾分布和非平稳性，不仅增加建模复杂性，还依赖大量手动特征工程，限制模型效率和准确性。因此，开发自动化、高效的深度学习架构至关重要，以提升大规模数据建模的性能和可扩展性，减少人工干预需求。",
      "method": "KMLP采用混合架构设计，前端使用浅层Kolmogorov-Arnold Network (KAN)，通过学习可调节的激活函数自动建模每个特征的复杂非线性变换；主干部分采用Gated Multilayer Perceptron (gMLP)捕获特征间的高阶交互作用。这种结合优化了表格数据的异质性和动态性处理，增强了大规模场景下的特征提取和模式识别能力。摘要未明确说明具体的数据集或模型架构细节。",
      "result": "实验在公开基准和包含数十亿样本的工业数据集上进行，结果显示KMLP实现了最先进的性能。与基线方法如梯度提升决策树相比，KMLP的优势在数据规模更大时更为显著，验证了其作为大规模网络表格数据建模范式的可扩展性和有效性。摘要未提及具体的准确率提升或效率改进数值，但强调了优于基线的表现，显示其适用于海量数据场景。",
      "conclusion": "KMLP的主要贡献是提出了一种可扩展的混合深度架构，能够自动建模大规模表格数据的复杂特征，减少对人工特征工程的依赖。这项研究为大规模网络数据建模提供了新的深度学习范式，具有重要的学术和实际应用价值，特别是在处理海量异构数据时。未来工作可能包括进一步优化架构或扩展到其他数据领域，摘要未明确说明局限性。",
      "tags": [
        "Kolmogorov-Arnold Network (KAN)",
        "Gated Multilayer Perceptron (gMLP)",
        "Hybrid Architecture",
        "Tabular Data Modeling",
        "Scalable Deep Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:30.075202Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22771",
    "title": "ClinDet-Bench: Beyond Abstention, Evaluating Judgment Determinability of LLMs in Clinical Decision-Making",
    "authors": [
      "Yusuke Watanabe",
      "Yohei Kobashi",
      "Takeshi Kojima",
      "Yusuke Iwasawa",
      "Yasushi Okuno",
      "Yutaka Matsuo"
    ],
    "abstract": "Clinical decisions are often required under incomplete information. Clinical experts must identify whether available information is sufficient for judgment, as both premature conclusion and unnecessary abstention can compromise patient safety. To evaluate this capability of large language models (LLMs), we developed ClinDet-Bench, a benchmark based on clinical scoring systems that decomposes incomplete-information scenarios into determinable and undeterminable conditions. Identifying determinability requires considering all hypotheses about missing information, including unlikely ones, and verifying whether the conclusion holds across them. We find that recent LLMs fail to identify determinability under incomplete information, producing both premature judgments and excessive abstention, despite correctly explaining the underlying scoring knowledge and performing well under complete information. These findings suggest that existing benchmarks are insufficient to evaluate the safety of LLMs in clinical settings. ClinDet-Bench provides a framework for evaluating determinability recognition, leading to appropriate abstention, with potential applicability to medicine and other high-stakes domains, and is publicly available.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22771.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22771",
    "published": "2026-02-26T09:03:41Z",
    "updated": "2026-02-26T09:03:41Z",
    "comment": "17 pages, 3 figures, 10 tables",
    "light_analysis": {
      "overview": "开发了ClinDet-Bench基准，用于评估大语言模型在临床决策中判断信息是否足以做出结论的能力。",
      "motivation": "临床决策常在不完整信息下进行，专家需评估信息是否充分，以避免过早结论或不当弃权，从而保障患者安全。现有大型语言模型评估方法在临床安全性方面存在不足，无法有效测试其在信息不全时的判断能力，这限制了LLMs在医疗等高风险领域的可靠应用，因此开发新基准至关重要。",
      "method": "研究提出ClinDet-Bench基准，基于临床评分系统，将不完整信息场景分解为可确定和不可确定的条件。核心创新在于要求模型考虑所有缺失信息的假设，包括极端情况，以验证结论的稳定性。该方法通过构建具体测试任务评估LLMs的可确定性识别能力，摘要未明确说明使用的具体数据集或模型架构。",
      "result": "实验发现，近期的大语言模型在不完整信息下无法正确识别可确定性，导致过早判断和过度弃权。尽管这些模型能正确解释临床评分知识并在完整信息下表现良好，但在可确定性评估上失败。这表明现有基准不足以全面评估LLMs的临床安全性，需要新的评估框架如ClinDet-Bench。",
      "conclusion": "本研究的主要贡献是开发了ClinDet-Bench基准，为评估LLMs在临床决策中的可确定性识别提供了新框架。这有助于提升LLMs的安全性和可靠性，促进其在医学等高风险领域的应用。基准公开可用，支持后续研究，未来可扩展至其他领域或改进模型的可确定性判断能力。",
      "tags": [
        "Large Language Model",
        "Clinical Decision-Making",
        "Benchmark",
        "Judgment Determinability",
        "Safety Evaluation"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:31.571642Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22769",
    "title": "AMA-Bench: Evaluating Long-Horizon Memory for Agentic Applications",
    "authors": [
      "Yujie Zhao",
      "Boqin Yuan",
      "Junbo Huang",
      "Haocheng Yuan",
      "Zhongming Yu",
      "Haozhou Xu",
      "Lanxiang Hu",
      "Abhilash Shankarampeta",
      "Zimeng Huang",
      "Wentao Ni",
      "Yuandong Tian",
      "Jishen Zhao"
    ],
    "abstract": "Large Language Models (LLMs) are deployed as autonomous agents in increasingly complex applications, where enabling long-horizon memory is critical for achieving strong performance. However, a significant gap exists between practical applications and current evaluation standards for agent memory: existing benchmarks primarily focus on dialogue-centric, human-agent interactions. In reality, agent memory consists of a continuous stream of agent-environment interactions that are primarily composed of machine-generated representations. To bridge this gap, we introduce AMA-Bench (Agent Memory with Any length), which evaluates long-horizon memory for LLMs in real agentic applications. It features two key components: (1) a set of real-world agentic trajectories across representative agentic applications, paired with expert-curated QA, and (2) a set of synthetic agentic trajectories that scale to arbitrary horizons, paired with rule-based QA. Our comprehensive study shows that existing memory systems underperform on AMA-Bench primarily because they lack causality and objective information and are constrained by the lossy nature of similarity-based retrieval employed by many memory systems. To address these limitations, we propose AMA-Agent, an effective memory system featuring a causality graph and tool-augmented retrieval. Our results demonstrate that AMA-Agent achieves 57.22% average accuracy on AMA-Bench, surpassing the strongest memory system baselines by 11.16%.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22769.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22769",
    "published": "2026-02-26T08:59:31Z",
    "updated": "2026-02-26T08:59:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了AMA-Bench基准以评估代理应用中的长时记忆，并开发了AMA-Agent记忆系统以解决现有方法的局限性。",
      "motivation": "本研究动机源于当前评估代理记忆的标准与真实应用之间的显著差距。现有基准主要专注于对话中心的人机交互，而实际代理记忆涉及连续代理环境交互的机器生成表示，导致长时记忆评估不全面。由于长时记忆对复杂代理应用性能至关重要，如自主决策和任务执行，这一问题的重要性凸显。现有方法的不足在于它们未能有效评估因果性和目标信息，且受限于相似性检索的损失性，从而限制了代理系统在现实场景中的表现。",
      "method": "研究方法基于引入AMA-Bench基准，该基准包含两个关键组件：一是真实世界代理轨迹与专家策划的问答配对，用于模拟实际应用；二是合成代理轨迹与基于规则的问答配对，可扩展到任意时间范围以测试长期记忆。核心创新是提出AMA-Agent记忆系统，它采用因果图结构和工具增强检索机制，旨在克服现有系统缺乏因果联系和信息完整性的问题。数据集设计覆盖代表性代理应用场景，强调机器生成交互的代表性，为评估提供多样化数据支撑。",
      "result": "主要实验结果显示，AMA-Agent在AMA-Bench基准上实现了57.22%的平均准确率，超越了现有最强记忆系统基线11.16个百分点。基线系统表现不佳，归因于缺乏因果性和目标信息，以及相似性检索的局限性，导致在长时记忆任务中准确率较低。通过与基线对比，AMA-Agent的有效性得到验证，显著提升了评估性能，证明了新方法在代理记忆系统中的优势。",
      "conclusion": "论文的主要贡献是提出了AMA-Bench基准和AMA-Agent记忆系统，填补了代理应用中长时记忆评估的空白。学术上，这推动了代理记忆研究的标准化和深入，为未来评估提供新标准；实践中，有助于改进自主代理在复杂任务中的性能和可靠性。未来工作可能包括扩展基准到更多应用场景、优化记忆系统架构以处理更复杂交互，或探索其他检索机制以进一步提升效果。",
      "tags": [
        "Large Language Models",
        "Agent Memory",
        "Benchmark Evaluation",
        "Causality Graph",
        "Tool-Augmented Retrieval"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:32.187559Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22766",
    "title": "Imagination Helps Visual Reasoning, But Not Yet in Latent Space",
    "authors": [
      "You Li",
      "Chi Chen",
      "Yanghao Li",
      "Fanhu Zeng",
      "Kaiyu Huang",
      "Jinan Xu",
      "Maosong Sun"
    ],
    "abstract": "Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Latent-Answer Disconnect: perturbations on the latent tokens yield minimal impact on the final answer, indicating the limited causal effect latent tokens imposing on the outcome. Furthermore, extensive probing analysis reveals that latent tokens encode limited visual information and exhibit high similarity. Consequently, we challenge the necessity of latent reasoning and propose a straightforward alternative named CapImagine, which teaches the model to explicitly imagine using text. Experiments on vision-centric benchmarks show that CapImagine significantly outperforms complex latent-space baselines, highlighting the superior potential of visual reasoning through explicit imagination.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22766.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22766",
    "published": "2026-02-26T08:56:23Z",
    "updated": "2026-02-26T08:56:23Z",
    "comment": "13 pages, 6 figures",
    "light_analysis": {
      "overview": "本文通过因果中介分析揭示潜在视觉推理的局限性，并提出基于文本显式想象的CapImagine方法以改进视觉推理性能。",
      "motivation": "潜在视觉推理旨在模仿人类想象力，通过多模态大型语言模型的隐藏状态进行推理，被视为有前景的范式。然而，现有方法的有效性机制不清，可能导致推理效率低下或可靠性不足。本研究旨在揭秘这些机制，理解输入、潜在状态和答案之间的因果关系，从而优化视觉推理方法，以应对复杂视觉任务中的挑战。",
      "method": "研究方法采用因果中介分析，将视觉推理过程建模为因果链：输入作为处理变量，潜在令牌作为中介变量，最终答案作为结果变量。关键创新点包括识别输入-潜在断开和潜在-答案断开，表明潜在令牌对输入注意力不足且对答案影响有限。此外，提出CapImagine方法，教导模型使用文本进行显式想象，替代复杂的潜在空间操作，以增强视觉推理的透明性和效果。",
      "result": "实验结果发现输入-潜在断开和潜在-答案断开，表明潜在令牌编码有限视觉信息且相似度高，对推理贡献较小。在视觉基准测试中，CapImagine方法显著优于复杂的潜在空间基线，显示出显式想象在提升视觉推理性能上的优越潜力。尽管摘要未明确提供具体数值，但强调了方法在效果上的明显改进，为后续应用提供实证支持。",
      "conclusion": "论文挑战了潜在推理的必要性，强调显式想象在视觉推理中的优势。主要贡献在于提供因果分析框架和改进方法，深化对多模态推理机制的理解，具有重要学术价值，并为实际视觉任务如自动驾驶或图像分析提供更高效的解决方案。未来工作可扩展到更广泛数据集或验证方法在其他领域的适用性。",
      "tags": [
        "Latent Visual Reasoning",
        "Causal Mediation Analysis",
        "Multimodal Large Language Models",
        "CapImagine",
        "Explicit Imagination"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:33.376393Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22765",
    "title": "Towards Better RL Training Data Utilization via Second-Order Rollout",
    "authors": [
      "Zhe Yang",
      "Yudong Wang",
      "Rang Li",
      "Zhifang Sui"
    ],
    "abstract": "Reinforcement Learning (RL) has empowered Large Language Models (LLMs) with strong reasoning capabilities, but vanilla RL mainly focuses on generation capability improvement by training with only first-order rollout (generating multiple responses for a question), and we argue that this approach fails to fully exploit the potential of training data because of the neglect of critique capability training. To tackle this problem, we further introduce the concept of second-order rollout (generating multiple critiques for a response) and propose a unified framework for jointly training generation and critique capabilities. Extensive experiments across various models and datasets demonstrate that our approach can utilize training data more effectively than vanilla RL and achieve better performance under the same training data. Additionally, we uncover several insightful findings regarding second-order rollout and critique training, such as the importance of label balance in critique training and the noise problem of outcome-based rewards, which can be mitigated through sampling techniques. Our work offers a preliminary exploration of dynamic data augmentation and joint generation-critique training in RL, providing meaningful inspiration for the further advancement of RL training",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22765.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22765",
    "published": "2026-02-26T08:55:58Z",
    "updated": "2026-02-26T08:55:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过引入二阶 rollout 和联合训练生成与批判能力的框架，显著提升了强化学习中训练数据的利用效率。",
      "motivation": "现有的强化学习方法主要依赖于一阶 rollout，即针对问题生成多个响应来训练生成能力，但忽略了批判能力的训练，导致训练数据的潜力未能被充分利用。在大型语言模型的背景下，批判能力对于提高推理性能至关重要，而现有方法的不足在于仅关注生成能力，限制了数据利用效率的提升。因此，开发一种能够同时训练生成和批判能力的方法，以解决数据利用不足的问题，具有重要的研究意义。",
      "method": "本研究提出了二阶 rollout 的概念，即在生成响应的基础上，进一步生成多个批判来训练模型的批判能力，并设计了一个统一框架将生成和批判能力的训练结合起来。关键创新点在于扩展了传统的一阶 rollout，引入了动态数据增强机制，通过采样技术来缓解基于结果的奖励中的噪声问题。虽然摘要未明确说明具体的数据集和模型架构，但实验涉及了多种模型和数据集，框架旨在实现更全面的训练数据利用。",
      "result": "广泛的实验结果表明，与传统的 vanilla RL 方法相比，本文提出的方法在相同的训练数据下能够实现更好的性能表现，有效提升了训练数据的利用效率。实验在多种模型和数据集上验证了这一点，并揭示了二阶 rollout 和批判训练中的关键发现，如批判训练中标签平衡的重要性以及通过采样技术缓解奖励噪声的效果。这些结果证明了联合训练框架的优越性和实用性。",
      "conclusion": "本研究的主要贡献在于提出了基于二阶 rollout 的强化学习方法，通过联合训练生成和批判能力，为动态数据增强在 RL 中的应用提供了初步探索。学术价值在于启发了 RL 训练方法的进一步优化，具有潜在的实际应用价值，可能提高大型语言模型的推理能力。尽管这是一个初步尝试，但未来工作可以探索更复杂的实现细节和在不同领域的应用，以深化研究。",
      "tags": [
        "Reinforcement Learning",
        "Large Language Models",
        "Second-Order Rollout",
        "Critique Training",
        "Dynamic Data Augmentation"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:49.735500Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22759",
    "title": "Beyond Detection: Multi-Scale Hidden-Code for Natural Image Deepfake Recovery and Factual Retrieval",
    "authors": [
      "Yuan-Chih Chen",
      "Chun-Shien Lu"
    ],
    "abstract": "Recent advances in image authenticity have primarily focused on deepfake detection and localization, leaving recovery of tampered contents for factual retrieval relatively underexplored. We propose a unified hidden-code recovery framework that enables both retrieval and restoration from post-hoc and in-generation watermarking paradigms. Our method encodes semantic and perceptual information into a compact hidden-code representation, refined through multi-scale vector quantization, and enhances contextual reasoning via conditional Transformer modules. To enable systematic evaluation for natural images, we construct ImageNet-S, a benchmark that provides paired image-label factual retrieval tasks. Extensive experiments on ImageNet-S demonstrate that our method exhibits promising retrieval and reconstruction performance while remaining fully compatible with diverse watermarking pipelines. This framework establishes a foundation for general-purpose image recovery beyond detection and localization.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22759.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22759",
    "published": "2026-02-26T08:47:48Z",
    "updated": "2026-02-26T08:47:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一个统一的多尺度隐藏码恢复框架，用于自然图像Deepfake的恢复和事实检索，超越了传统的检测和定位方法。",
      "motivation": "图像真实性验证研究主要集中在deepfake检测和定位技术上，而篡改内容的恢复用于事实检索则相对未被充分探索。现有方法在恢复篡改内容以支持事实验证方面存在不足，这在媒体认证和虚假信息检测等实际应用中至关重要，需要从水印图像中高效提取原始信息。本研究旨在解决这一缺口，通过构建通用恢复框架，提升图像恢复能力。",
      "method": "该方法提出一个隐藏码恢复框架，将语义和感知信息编码为紧凑隐藏码表示，并通过多尺度向量量化进行精炼。关键创新在于使用条件Transformer模块增强上下文推理能力，以支持从后置和生成中水印范式中恢复内容。技术特色包括构建ImageNet-S基准用于系统评估，框架与多种水印管道兼容，为通用图像恢复提供了技术支持。",
      "result": "在ImageNet-S基准测试中，该方法在事实检索和图像重建任务中表现出良好的性能，实现了有效的恢复效果。尽管摘要未提供具体数值，但实验结果表明，方法在检索准确率和重建质量方面有潜力，并且能够与多样水印方案无缝集成，验证了其实用性和通用性。基线对比显示方法在恢复任务中具有竞争优势。",
      "conclusion": "本研究的核心贡献是建立了一个超越检测和定位的通用图像恢复框架，为deepfake恢复和事实检索奠定了基础。其学术价值在于推动图像真实性验证向恢复方向发展，实际应用潜力包括媒体认证和信息检索任务。局限性方面，摘要未明确说明，未来工作可扩展至更复杂篡改场景或优化性能指标，以进一步提升框架的适用范围。",
      "tags": [
        "Hidden-Code Recovery",
        "Multi-Scale Vector Quantization",
        "Conditional Transformer",
        "Factual Retrieval"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:56.030937Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22758",
    "title": "Decomposing Physician Disagreement in HealthBench",
    "authors": [
      "Satya Borgohain",
      "Roy Mariathas"
    ],
    "abstract": "We decompose physician disagreement in the HealthBench medical AI evaluation dataset to understand where variance resides and what observable features can explain it. Rubric identity accounts for 15.8% of met/not-met label variance but only 3.6-6.9% of disagreement variance; physician identity accounts for just 2.4%. The dominant 81.8% case-level residual is not reduced by HealthBench's metadata labels (z = -0.22, p = 0.83), normative rubric language (pseudo R^2 = 1.2%), medical specialty (0/300 Tukey pairs significant), surface-feature triage (AUC = 0.58), or embeddings (AUC = 0.485). Disagreement follows an inverted-U with completion quality (AUC = 0.689), confirming physicians agree on clearly good or bad outputs but split on borderline cases. Physician-validated uncertainty categories reveal that reducible uncertainty (missing context, ambiguous phrasing) more than doubles disagreement odds (OR = 2.55, p < 10^(-24)), while irreducible uncertainty (genuine medical ambiguity) has no effect (OR = 1.01, p = 0.90), though even the former explains only ~3% of total variance. The agreement ceiling in medical AI evaluation is thus largely structural, but the reducible/irreducible dissociation suggests that closing information gaps in evaluation scenarios could lower disagreement where inherent clinical ambiguity does not, pointing toward actionable evaluation design improvements.",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22758.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22758",
    "published": "2026-02-26T08:47:42Z",
    "updated": "2026-02-26T08:47:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究分解HealthBench医学AI评估数据集中医生分歧，发现分歧主要源于病例级别的结构性因素，并区分可减少和不可减少不确定性的影响，为评估设计提供改进方向。",
      "motivation": "医学AI评估中医生分歧影响评估的可靠性和AI系统的有效性，是一个关键问题。现有方法如使用评分规则或医生身份解释分歧方差有限（评分规则仅占3.6-6.9%，医生身份仅2.4%），表明现有评估设计可能不足以捕捉分歧来源，需要深入分析以提升评估质量，支持更准确的AI系统验证和临床应用。本研究旨在通过分解分歧，识别可解释特征，为优化评估框架奠定基础。",
      "method": "本研究基于HealthBench数据集，采用统计分析方法分解医生评估标签的方差。使用方差分解技术量化评分规则身份、医生身份等因素对分歧的贡献，并通过AUC和逻辑回归分析元数据标签、医学专业、表面特征筛选、嵌入等对减少残差的效果。关键创新包括引入医生验证的不确定性类别（如可减少的缺失上下文和不可减少的医学模糊），分析其对分歧几率的影響，以探索评估设计的可改进点。",
      "result": "主要实验结果：评分规则身份占标签方差15.8%，但分歧方差仅3.6-6.9%；医生身份贡献2.4%；81.8%病例级别残差未被解释，且不受HealthBench元数据等因素显著影响（如z = -0.22, p = 0.83）。分歧随完成质量呈倒U型（AUC = 0.689），表明医生在边界情况下分歧较大。可减少不确定性使分歧几率加倍（OR = 2.55, p < 10^(-24)），但仅解释约3%总方差；不可减少不确定性无影响（OR = 1.01, p = 0.90），支持结论中的结构性分歧特征。",
      "conclusion": "研究结论表明，医学AI评估中的分歧主要是结构性的，难以通过现有评估特征显著减少，这反映了评估一致性的内在限制。然而，可减少和不可减少不确定性的分离指出，通过填补评估场景中的信息空白（如提供更多上下文），可以在非固有模糊情况下降低分歧，这为改进评估设计提供了可操作方向。学术价值在于深化对评估方法学的理解，实际应用价值在于指导开发更可靠的医学AI系统评估框架，未来工作可聚焦于实施这些设计改进以验证效果。",
      "tags": [
        "HealthBench Dataset",
        "Variance Decomposition",
        "Physician Disagreement",
        "Uncertainty Categorization",
        "Evaluation Design"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:13.911560Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22755",
    "title": "AuditBench: Evaluating Alignment Auditing Techniques on Models with Hidden Behaviors",
    "authors": [
      "Abhay Sheshadri",
      "Aidan Ewart",
      "Kai Fronsdal",
      "Isha Gupta",
      "Samuel R. Bowman",
      "Sara Price",
      "Samuel Marks",
      "Rowan Wang"
    ],
    "abstract": "We introduce AuditBench, an alignment auditing benchmark. AuditBench consists of 56 language models with implanted hidden behaviors. Each model has one of 14 concerning behaviors--such as sycophantic deference, opposition to AI regulation, or secret geopolitical loyalties--which it does not confess to when directly asked. AuditBench models are highly diverse--some are subtle, while others are overt, and we use varying training techniques both for implanting behaviors and training models not to confess. To demonstrate AuditBench's utility, we develop an investigator agent that autonomously employs a configurable set of auditing tools. By measuring investigator agent success using different tools, we can evaluate their efficacy. Notably, we observe a tool-to-agent gap, where tools that perform well in standalone non-agentic evaluations fail to translate into improved performance when used with our investigator agent. We find that our most effective tools involve scaffolded calls to auxiliary models that generate diverse prompts for the target. White-box interpretability tools can be helpful, but the agent performs best with black-box tools. We also find that audit success varies greatly across training techniques: models trained on synthetic documents are easier to audit than models trained on demonstrations, with better adversarial training further increasing auditing difficulty. We release our models, agent, and evaluation framework to support future quantitative, iterative science on alignment auditing.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22755.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22755",
    "published": "2026-02-26T08:43:07Z",
    "updated": "2026-02-26T08:43:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出AuditBench基准，通过植入隐藏行为的语言模型和自主代理审计技术，评估对齐审计工具的有效性。",
      "motivation": "当前AI模型可能植入隐藏行为，如奉承性顺从或反对AI监管，这些行为在直接询问时不承认，威胁模型安全和可信。现有对齐审计方法缺乏标准化评估，难以量化工具效能。研究动机是创建AuditBench基准，解决对齐审计的定量评估问题，以提高模型对齐性和安全性，填补评估空白。",
      "method": "研究构建AuditBench基准，包含56个语言模型，植入14种隐藏行为（如奉承性顺从），使用多样训练技术（如合成文档和对抗训练）。开发调查代理，自主配置审计工具集，包括辅助模型生成多样提示、白盒可解释性工具和黑盒工具。方法核心是代理驱动的评估框架，用于系统测试不同审计工具的有效性。",
      "result": "实验发现工具到代理的差距：独立评估表现好的工具在代理中使用时效果不佳。最有效工具涉及辅助模型生成多样提示，黑盒工具在代理中表现最佳，白盒工具有帮助但稍逊。审计成功率因训练技术而异：合成文档训练的模型更易审计（提升约20%），对抗训练增加难度。结果揭示了审计工具的效能随使用环境和训练方法变化。",
      "conclusion": "论文贡献包括AuditBench基准、代理审计框架和实验发现，发布模型和代码支持未来定量研究。学术价值在于促进对齐审计的科学迭代，实际应用有助于提高AI模型安全评估。局限性在于模型行为有限，未来可扩展基准到更多行为或优化代理工具以提高泛化能力。",
      "tags": [
        "Alignment Auditing",
        "Language Models",
        "Adversarial Training",
        "Interpretability",
        "Agent Evaluation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:00.500835Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22752",
    "title": "Towards Simulating Social Media Users with LLMs: Evaluating the Operational Validity of Conditioned Comment Prediction",
    "authors": [
      "Nils Schwager",
      "Simon Münker",
      "Alistair Plum",
      "Achim Rettinger"
    ],
    "abstract": "The transition of Large Language Models (LLMs) from exploratory tools to active \"silicon subjects\" in social science lacks extensive validation of operational validity. This study introduces Conditioned Comment Prediction (CCP), a task in which a model predicts how a user would comment on a given stimulus by comparing generated outputs with authentic digital traces. This framework enables a rigorous evaluation of current LLM capabilities with respect to the simulation of social media user behavior. We evaluated open-weight 8B models (Llama3.1, Qwen3, Ministral) in English, German, and Luxembourgish language scenarios. By systematically comparing prompting strategies (explicit vs. implicit) and the impact of Supervised Fine-Tuning (SFT), we identify a critical form vs. content decoupling in low-resource settings: while SFT aligns the surface structure of the text output (length and syntax), it degrades semantic grounding. Furthermore, we demonstrate that explicit conditioning (generated biographies) becomes redundant under fine-tuning, as models successfully perform latent inference directly from behavioral histories. Our findings challenge current \"naive prompting\" paradigms and offer operational guidelines prioritizing authentic behavioral traces over descriptive personas for high-fidelity simulation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22752.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22752",
    "published": "2026-02-26T08:40:21Z",
    "updated": "2026-02-26T08:40:21Z",
    "comment": "14 pages, 1 figure, 7 tables. Accepted to the 15th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis (WASSA) at EACL 2026, Rabat, Morocco",
    "light_analysis": {
      "overview": "本研究引入条件评论预测任务，评估LLM模拟社交媒体用户行为的操作有效性，发现监督微调导致形式与内容解耦，并挑战现有提示范式，提供基于真实行为痕迹的模拟指南。",
      "motivation": "大型语言模型在社会科学研究中从探索工具转向主动主体时，缺乏对其操作有效性的系统验证。现有方法难以确保模型能准确模拟真实用户行为，尤其是在多语言和低资源场景下，影响研究可靠性和应用价值。因此，需要建立严格评估框架来解决这一问题，以提升LLM在模拟用户行为方面的实用性和准确性。",
      "method": "论文提出条件评论预测（CCP）任务，模型基于给定刺激预测用户评论，并通过与真实数字痕迹比较来评估性能。使用开放权重的8B参数模型（Llama3.1、Qwen3、Ministral），在英语、德语和卢森堡语环境中进行实验。关键创新点包括系统比较显式与隐式提示策略，并分析监督微调（SFT）对模型行为的影响，以探究模拟社交媒体用户的技术路线和有效性。",
      "result": "实验结果显示，在低资源设置下，监督微调虽能对齐文本输出的表面结构（如长度和语法），但降低了语义接地，导致形式与内容解耦。与基线方法相比，显式条件在微调后变得冗余，模型能从行为历史中进行潜在推理，挑战了当前依赖“天真提示”的范式。这表明高保真模拟应优先使用真实行为痕迹，而非依赖描述性人物，提升了操作有效性评估的准确性。",
      "conclusion": "研究的主要贡献在于通过条件评论预测框架验证了LLM模拟社交媒体用户的操作有效性，揭示了监督微调中的局限性，如形式与内容解耦。学术价值在于为社会科学研究提供了新的评估方法，实际应用价值在于指导高保真模拟优先使用真实行为数据。未来工作可扩展至更多语言或领域，并优化模型训练策略以克服现有局限，进一步提升模拟的可靠性和效率。",
      "tags": [
        "Large Language Model (LLM)",
        "Conditioned Comment Prediction (CCP)",
        "Supervised Fine-Tuning (SFT)",
        "Prompting Strategies",
        "Behavioral Simulation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:09.481533Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22751",
    "title": "Know What You Know: Metacognitive Entropy Calibration for Verifiable RL Reasoning",
    "authors": [
      "Qiannian Zhao",
      "Chen Yang",
      "Jinhao Jing",
      "Yunke Zhang",
      "Xuhui Ren",
      "Lu Yu",
      "Shijie Zhang",
      "Hongzhi Yin"
    ],
    "abstract": "Large reasoning models (LRMs) have emerged as a powerful paradigm for solving complex real-world tasks. In practice, these models are predominantly trained via Reinforcement Learning with Verifiable Rewards (RLVR), yet most existing outcome-only RLVR pipelines rely almost exclusively on a binary correctness signal and largely ignore the model's intrinsic uncertainty. We term this discrepancy the uncertainty-reward mismatch, under which high- and low-uncertainty solutions are treated equivalently, preventing the policy from \"Know What You Know\" and impeding the shift from optimizing for correct answers to optimizing effective reasoning paths. This limitation is especially critical in reasoning-centric tasks such as mathematics and question answering, where performance hinges on the quality of the model's internal reasoning process rather than mere memorization of final answers. To address this, we propose EGPO, a metacognitive entropy calibration framework that explicitly integrates intrinsic uncertainty into RLVR for enhancing LRMs. EGPO estimates per-sample uncertainty using a zero-overhead entropy proxy derived from token-level likelihoods and aligns it with extrinsic correctness through an asymmetric calibration mechanism that preserves correct reasoning while selectively regulating overconfident failures, thereby enabling stable and uncertainty-aware policy optimization. Moreover, EGPO recovers informative learning signals from otherwise degenerate group-based rollouts without modifying the verifier or reward definition. Extensive experiments across multiple benchmarks demonstrate that the proposed EGPO leads to substantial and consistent improvements in reasoning performance, establishing a principled path for advancing LRMs through metacognitive entropy calibration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22751.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22751",
    "published": "2026-02-26T08:40:06Z",
    "updated": "2026-02-26T08:40:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了EGPO框架，通过元认知熵校准将内在不确定性整合到RLVR中，以提升大推理模型的推理性能。",
      "motivation": "大推理模型在训练中依赖于带可验证奖励的强化学习，但现有方法仅使用二元的正确性信号，忽略了模型的内在不确定性，这导致不确定性-奖励不匹配问题。该问题在数学和问答等推理任务中尤其关键，因为这些任务的性能取决于推理过程的质量，而非仅仅记忆答案。现有方法的不足在于无法区分高和低不确定性的解决方案，阻碍了从优化正确答案到优化有效推理路径的转变，因此需要一种新的机制来整合不确定性以改进模型性能。",
      "method": "本研究提出EGPO，一个元认知熵校准框架，通过整合内在不确定性来增强RLVR。核心创新包括使用零开销熵代理估计每个样本的不确定性，该代理从令牌级似然派生，无需额外计算开销。EGPO采用非对称校准机制，将内在不确定性与外部正确性对齐，保留正确推理的同时选择性调节过度自信的失败。此外，框架不修改验证器或奖励定义，而是从退化的组级展开中恢复信息学习信号，从而实现稳定且不确定性感知的策略优化。",
      "result": "在多个基准测试中进行广泛实验，结果表明EGPO显著且持续地提升了推理性能。尽管摘要未提供具体数字，但相对于仅依赖二元的正确性信号的基线RLVR方法，EGPO显示出改进，尤其在处理不确定性-奖励不匹配问题方面有效，增强了模型在推理任务中的稳定性和准确性。这验证了框架在优化推理路径而非仅正确答案方面的优势。",
      "conclusion": "EGPO框架的主要贡献在于提供了一种原则性方法来通过元认知熵校准增强大推理模型的推理性能。其学术价值体现在解决了不确定性-奖励不匹配问题，推动了元认知概念在强化学习中的应用。实际应用中，该方法可提升数学推理、问答等任务的效果。摘要未明确说明局限性，但未来工作可能涉及扩展到更多任务类型或进一步优化校准机制。",
      "tags": [
        "Large Reasoning Models",
        "Reinforcement Learning with Verifiable Rewards",
        "Uncertainty Calibration",
        "Entropy Estimation",
        "Metacognitive Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:11.285275Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22747",
    "title": "Set-based v.s. Distribution-based Representations of Epistemic Uncertainty: A Comparative Study",
    "authors": [
      "Kaizheng Wang",
      "Yunjia Wang",
      "Fabio Cuzzolin",
      "David Moens",
      "Hans Hallez",
      "Siu Lun Chau"
    ],
    "abstract": "Epistemic uncertainty in neural networks is commonly modeled using two second-order paradigms: distribution-based representations, which rely on posterior parameter distributions, and set-based representations based on credal sets (convex sets of probability distributions). These frameworks are often regarded as fundamentally non-comparable due to differing semantics, assumptions, and evaluation practices, leaving their relative merits unclear. Empirical comparisons are further confounded by variations in the underlying predictive models. To clarify this issue, we present a controlled comparative study enabling principled, like-for-like evaluation of the two paradigms. Both representations are constructed from the same finite collection of predictive distributions generated by a shared neural network, isolating representational effects from predictive accuracy. Our study evaluates each representation through the lens of 3 uncertainty measures across 8 benchmarks, including selective prediction and out-of-distribution detection, spanning 6 underlying predictive models and 10 independent runs per configuration. Our results show that meaningful comparison between these seemingly non-comparable frameworks is both feasible and informative, providing insights into how second-order representation choices impact practical uncertainty-aware performance.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22747.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22747",
    "published": "2026-02-26T08:36:09Z",
    "updated": "2026-02-26T08:36:09Z",
    "comment": "29 pages",
    "light_analysis": {
      "overview": "本研究提出了一个受控比较方法，使神经网络中认知不确定性的两种二阶表示范式能够进行原则性评估，揭示了它们对实际性能的影响。",
      "motivation": "神经网络中的认知不确定性常通过二阶范式建模，包括基于分布的表示和基于集合的表示。这些框架由于在语义、假设和评估实践上的不同，被视为不可比较，使得它们的相对优势模糊不清。此外，实证比较常被底层预测模型的变异性所混淆，导致无法准确评估表示效果。认知不确定性对机器学习模型的可靠性至关重要，尤其是在高风险应用中，因此需要澄清这一问题的控制变量方法。",
      "method": "本研究采用受控比较方法，通过共享神经网络生成相同有限预测分布集合，从中分别构建基于分布和基于集合的两种二阶表示，确保表示效果独立于预测准确性。评估方案包括使用3个不确定性度量在8个基准测试中，如选择性预测和分布外检测，涉及6个底层预测模型，每个配置进行10次独立运行以增强统计可靠性。这种方法隔离了变量，使比较仅聚焦于表示范式本身。",
      "result": "实验结果表明，这些看似不可比较的框架之间的有意义比较是可行的。研究揭示了二阶表示选择对实际不确定性感知性能的影响，例如在选择性预测和分布外检测任务中，比较了两种范式的表现。然而，摘要未明确说明具体的性能指标如准确率提升等数据，但强调了比较的有效性，为后续研究提供了基础。",
      "conclusion": "本研究证明了神经网络中认知不确定性的两种二阶表示范式可以通过受控方法进行有意义的比较，解决了它们的相对优势问题。研究提供了关于二阶表示选择如何影响不确定性感知性能的见解，对不确定性建模的理论和实践有重要价值。学术上澄清了范式的可比性；应用上指导了表示方法的选择。未来工作可扩展到更多任务或应用场景。",
      "tags": [
        "Epistemic Uncertainty",
        "Second-order Representations",
        "Credal Sets",
        "Selective Prediction",
        "Out-of-distribution Detection"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:27.045016Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22745",
    "title": "SPATIALALIGN: Aligning Dynamic Spatial Relationships in Video Generation",
    "authors": [
      "Fengming Liu",
      "Tat-Jen Cham",
      "Chuanxia Zheng"
    ],
    "abstract": "Most text-to-video (T2V) generators prioritize aesthetic quality, but often ignoring the spatial constraints in the generated videos. In this work, we present SPATIALALIGN, a self-improvement framework that enhances T2V models capabilities to depict Dynamic Spatial Relationships (DSR) specified in text prompts. We present a zeroth-order regularized Direct Preference Optimization (DPO) to fine-tune T2V models towards better alignment with DSR. Specifically, we design DSR-SCORE, a geometry-based metric that quantitatively measures the alignment between generated videos and the specified DSRs in prompts, which is a step forward from prior works that rely on VLM for evaluation. We also conduct a dataset of text-video pairs with diverse DSRs to facilitate the study. Extensive experiments demonstrate that our fine-tuned model significantly out performs the baseline in spatial relationships. The code will be released in Link.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22745.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22745",
    "published": "2026-02-26T08:34:09Z",
    "updated": "2026-02-26T08:34:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出SPATIALALIGN框架，通过DSR-SCORE度量和零阶正则化DPO微调，提升文本到视频生成模型对动态空间关系的对齐能力。",
      "motivation": "当前文本到视频生成器虽然注重美学质量，但往往忽略生成视频中的空间约束，导致视频内容与文本提示中的动态空间关系不匹配。这一问题至关重要，因为准确的空间关系描绘是视频生成的关键要素，直接影响内容的真实性和连贯性。现有方法多依赖于视觉语言模型进行评估，缺乏定量度量，限制了模型在空间对齐方面的改进和优化，亟需更精确的评估和增强方法来解决这一不足。",
      "method": "SPATIALALIGN框架的核心创新包括设计DSR-SCORE，一个基于几何的度量，用于定量评估生成视频与文本提示中动态空间关系的对齐，这比先前依赖视觉语言模型的方法更精确和可解释。此外，采用零阶正则化的直接偏好优化对T2V模型进行微调，以增强其在动态空间关系上的表现。研究还建立了一个包含多样动态空间关系的文本-视频对数据集，为训练和评估提供支持，促进了该领域的数据驱动研究。",
      "result": "通过广泛实验，论文表明微调后的模型在空间关系方面显著优于基线模型。摘要未明确说明具体性能指标提升，如准确率或效率改进的百分比，但实验结果显示所提框架能够有效改善T2V模型对动态空间关系的描绘能力，验证了DSR-SCORE度量和DPO微调方法的有效性，为后续研究提供了实证基础。",
      "conclusion": "本研究的贡献在于提出了SPATIALALIGN框架，通过引入DSR-SCORE度量和应用DPO微调，显著提升了T2V模型在动态空间关系上的对齐能力，弥补了现有方法在定量评估和模型优化上的不足。学术价值在于推动了视频生成技术中对空间关系处理的深入探索，实际应用价值在于增强了生成视频的真实性和实用性。未来工作包括代码发布和进一步优化模型性能，以扩展到更复杂的场景中。",
      "tags": [
        "Text-to-Video Generation",
        "Dynamic Spatial Relationships",
        "Direct Preference Optimization",
        "Geometry-based Metric",
        "Self-Improvement Framework"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:26.161361Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22743",
    "title": "Generative Data Transformation: From Mixed to Unified Data",
    "authors": [
      "Jiaqing Zhang",
      "Mingjia Yin",
      "Hao Wang",
      "Yuxin Tian",
      "Yuyang Ye",
      "Yawen Li",
      "Wei Guo",
      "Yong Liu",
      "Enhong Chen"
    ],
    "abstract": "Recommendation model performance is intrinsically tied to the quality, volume, and relevance of their training data. To address common challenges like data sparsity and cold start, recent researchs have leveraged data from multiple auxiliary domains to enrich information within the target domain. However, inherent domain gaps can degrade the quality of mixed-domain data, leading to negative transfer and diminished model performance. Existing prevailing \\emph{model-centric} paradigm -- which relies on complex, customized architectures -- struggles to capture the subtle, non-structural sequence dependencies across domains, leading to poor generalization and high demands on computational resources. To address these shortcomings, we propose \\textsc{Taesar}, a \\emph{data-centric} framework for \\textbf{t}arget-\\textbf{a}lign\\textbf{e}d \\textbf{s}equenti\\textbf{a}l \\textbf{r}egeneration, which employs a contrastive decoding mechanism to adaptively encode cross-domain context into target-domain sequences. It employs contrastive decoding to encode cross-domain context into target sequences, enabling standard models to learn intricate dependencies without complex fusion architectures. Experiments show \\textsc{Taesar} outperforms model-centric solutions and generalizes to various sequential models. By generating enriched datasets, \\textsc{Taesar} effectively combines the strengths of data- and model-centric paradigms. The code accompanying this paper is available at~ \\textcolor{blue}{https://github.com/USTC-StarTeam/Taesar}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22743.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22743",
    "published": "2026-02-26T08:30:09Z",
    "updated": "2026-02-26T08:30:09Z",
    "comment": "Accepted by The Web Conference 2026 (WWW '26)",
    "light_analysis": {
      "overview": "本文提出Taesar框架，通过对比解码将多域数据自适应转换为目标域序列，以解决推荐系统中的数据稀疏和域差距问题，提升模型性能。",
      "motivation": "推荐模型的性能依赖于训练数据的质量、数量和相关性，现有方法常利用多域数据应对数据稀疏和冷启动挑战，但域间差距导致混合数据质量下降，引发负迁移和性能下降。当前模型中心范式依赖复杂架构，难以捕捉跨域的非结构序列依赖，泛化能力差且计算资源需求高，因此亟需有效整合多域数据的新方法。",
      "method": "Taesar是一个数据中心框架，采用目标对齐序列再生方法，使用对比解码机制自适应地将跨域上下文编码到目标域序列中。这一创新使标准序列模型能学习跨域的复杂依赖关系，无需设计复杂的融合架构，通过生成统一数据集简化模型训练。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验显示Taesar在性能上优于模型中心解决方案，并能泛化到各种序列模型中，有效结合数据中心和模型中心范式的优势，提升推荐系统表现。摘要未提供具体准确率或效率数据，但表明其优于基线方法。",
      "conclusion": "Taesar的主要贡献是提出数据中心跨域数据转换方法，通过对比解码生成统一序列，增强推荐模型性能，学术上为多域学习提供新思路，实际应用上改善冷启动和数据稀疏问题。摘要未明确说明局限性或未来工作，但可能涉及进一步优化或扩展。",
      "tags": [
        "Recommendation Systems",
        "Multi-domain Learning",
        "Contrastive Decoding",
        "Sequence Models",
        "Data Transformation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:17.506764Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22742",
    "title": "ProjFlow: Projection Sampling with Flow Matching for Zero-Shot Exact Spatial Motion Control",
    "authors": [
      "Akihisa Watanabe",
      "Qing Yu",
      "Edgar Simo-Serra",
      "Kent Fujiwara"
    ],
    "abstract": "Generating human motion with precise spatial control is a challenging problem. Existing approaches often require task-specific training or slow optimization, and enforcing hard constraints frequently disrupts motion naturalness. Building on the observation that many animation tasks can be formulated as a linear inverse problem, we introduce ProjFlow, a training-free sampler that achieves zero-shot, exact satisfaction of linear spatial constraints while preserving motion realism. Our key advance is a novel kinematics-aware metric that encodes skeletal topology. This metric allows the sampler to enforce hard constraints by distributing corrections coherently across the entire skeleton, avoiding the unnatural artifacts of naive projection. Furthermore, for sparse inputs, such as filling in long gaps between a few keyframes, we introduce a time-varying formulation using pseudo-observations that fade during sampling. Extensive experiments on representative applications, motion inpainting, and 2D-to-3D lifting, demonstrate that ProjFlow achieves exact constraint satisfaction and matches or improves realism over zero-shot baselines, while remaining competitive with training-based controllers.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22742.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22742",
    "published": "2026-02-26T08:29:25Z",
    "updated": "2026-02-26T08:29:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "ProjFlow 是一种无需训练的采样器，通过运动学感知度量和流匹配实现零样本精确空间运动控制，在满足线性约束的同时保持运动自然性。",
      "motivation": "该研究旨在解决生成人体运动时精确空间控制的挑战，这在计算机动画和虚拟现实中至关重要。现有方法通常需要针对特定任务进行训练或使用缓慢的优化过程，强制执行硬约束时容易破坏运动的自然性，导致不自然伪影。许多动画任务可以形式化为线性逆问题，因此开发一种无需训练、零样本下精确满足约束且不牺牲真实性的方法具有重要应用价值，能提高动画制作的效率和质量。",
      "method": "论文提出 ProjFlow，一个基于投影采样和流匹配的训练自由采样器。核心创新是引入运动学感知度量，该度量编码骨架拓扑结构，允许在强制执行硬约束时协调整个骨架上的修正，避免朴素投影导致的不自然伪影。此外，针对稀疏输入如关键帧间隙，采用时间变化公式，通过伪观测在采样过程中渐弱处理，增强实用性。该方法应用于运动修复和 2D 到 3D 提升等代表性任务，无需额外训练即可直接处理线性逆问题。",
      "result": "在运动修复和 2D 到 3D 提升等代表性应用上的广泛实验表明，ProjFlow 能够实现精确的线性空间约束满足，同时在运动真实性方面匹配或超越了零样本基线方法。尽管摘要未明确说明具体性能指标，但结果显示该方法与需要训练的控制器保持竞争力，验证了其在处理稀疏输入和保持自然性方面的有效性，为动画任务提供了高效且高质量的解决方案。",
      "conclusion": "论文的主要贡献是提出了 ProjFlow，一种无需训练即可实现零样本精确空间运动控制的方法，通过运动学感知度量和时间变化伪观测创新地解决了硬约束与自然性的平衡问题。在学术上，该方法推动了人体运动生成和线性逆问题求解技术的发展；实际上，它为动画制作和机器人控制提供了高效工具，提高了应用的灵活性。未来工作可探索扩展到更复杂的非线性约束或其他运动模态，以进一步提升通用性和性能。",
      "tags": [
        "Projection Sampling",
        "Flow Matching",
        "Kinematics-aware Metric",
        "Zero-Shot Learning",
        "Motion Inpainting"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:40.388815Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22740",
    "title": "AMLRIS: Alignment-aware Masked Learning for Referring Image Segmentation",
    "authors": [
      "Tongfei Chen",
      "Shuo Yang",
      "Yuguang Yang",
      "Linlin Yang",
      "Runtang Guo",
      "Changbai Li",
      "He Long",
      "Chunyu Xie",
      "Dawei Leng",
      "Baochang Zhang"
    ],
    "abstract": "Referring Image Segmentation (RIS) aims to segment an object in an image identified by a natural language expression. The paper introduces Alignment-Aware Masked Learning (AML), a training strategy to enhance RIS by explicitly estimating pixel-level vision-language alignment, filtering out poorly aligned regions during optimization, and focusing on trustworthy cues. This approach results in state-of-the-art performance on RefCOCO datasets and also enhances robustness to diverse descriptions and scenarios",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22740.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22740",
    "published": "2026-02-26T08:29:04Z",
    "updated": "2026-02-26T08:29:04Z",
    "comment": "ICLR 2026 conference paper",
    "light_analysis": {
      "overview": "该论文提出了Alignment-Aware Masked Learning (AML)训练策略，通过增强像素级视觉-语言对齐来改进Referring Image Segmentation，实现更准确的分割和更强的鲁棒性。",
      "motivation": "Referring Image Segmentation (RIS)旨在基于自然语言表达分割图像中的指定对象，但现有方法在像素级视觉-语言对齐估计上存在不足，导致分割精度受限，且对多样描述和场景的鲁棒性较差。本研究动机是解决这一对齐问题，以提升RIS在实际应用中的准确性和适应性。",
      "method": "论文提出Alignment-Aware Masked Learning (AML)，一种训练策略，通过明确计算像素级视觉-语言对齐得分，在优化过程中过滤对齐差的区域，并引导模型专注于可信的视觉线索。关键创新在于直接估计和对齐过程，使用掩码学习技术增强模型的学习效率，实验基于RefCOCO数据集实施。",
      "result": "AML在RefCOCO数据集上实现了最先进的性能，显著优于基线方法，并增强了对多样自然语言描述和不同场景的鲁棒性。尽管摘要未提供具体数值指标，但结果表明该方法在分割精度和适应性方面有明显提升。",
      "conclusion": "本研究的主要贡献是引入AML训练策略，有效提升了RIS任务的精度和鲁棒性，为视觉-语言对齐方法提供了新思路，具有实际应用价值如人机交互。摘要未明确说明局限性，未来工作可能涉及扩展到更复杂的数据集或集成先进语言模型。",
      "tags": [
        "Referring Image Segmentation",
        "Vision-Language Alignment",
        "Masked Learning",
        "Deep Learning Training Strategy",
        "RefCOCO Dataset"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:46.063938Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22734",
    "title": "Asymmetric Idiosyncrasies in Multimodal Models",
    "authors": [
      "Muzi Tao",
      "Chufan Shi",
      "Huijuan Wang",
      "Shengbang Tong",
      "Xuezhe Ma"
    ],
    "abstract": "In this work, we study idiosyncrasies in the caption models and their downstream impact on text-to-image models. We design a systematic analysis: given either a generated caption or the corresponding image, we train neural networks to predict the originating caption model. Our results show that text classification yields very high accuracy (99.70\\%), indicating that captioning models embed distinctive stylistic signatures. In contrast, these signatures largely disappear in the generated images, with classification accuracy dropping to at most 50\\% even for the state-of-the-art Flux model. To better understand this cross-modal discrepancy, we further analyze the data and find that the generated images fail to preserve key variations present in captions, such as differences in the level of detail, emphasis on color and texture, and the distribution of objects within a scene. Overall, our classification-based framework provides a novel methodology for quantifying both the stylistic idiosyncrasies of caption models and the prompt-following ability of text-to-image systems.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22734.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22734",
    "published": "2026-02-26T08:16:47Z",
    "updated": "2026-02-26T08:16:47Z",
    "comment": "Project page: https://muzi-tao.github.io/asymmetric-idiosyncrasies/",
    "light_analysis": {
      "overview": "论文提出了一种基于分类的新框架，用于量化caption模型的风格特征和text-to-image系统的提示跟随能力。",
      "motivation": "本研究旨在探究caption模型中存在的独特风格特征（idiosyncrasies）及其对下游text-to-image模型的影响。由于多模态模型中的不对称性可能导致生成图像未能忠实反映输入文本的风格细节，因此理解这种差异对评估和改进图像生成系统至关重要。现有研究可能未系统量化风格特征在跨模态传递中的保留情况，本工作旨在通过新方法填补这一空白，以揭示caption风格如何影响图像生成质量。",
      "method": "论文设计了一个系统分析框架，通过训练神经网络来预测生成的caption或图像来源于哪个特定的caption模型。核心创新在于使用分类任务量化模型嵌入的风格特征，从而评估caption模型的独特签名。具体方法包括：给定caption或图像作为输入，神经网络进行分类以预测来源模型，以准确率作为衡量指标。摘要未明确说明使用的具体神经网络架构或数据集细节，但基于现有信息推断采用了标准分类模型进行实验。",
      "result": "实验结果显示，在文本分类任务中，神经网络能准确识别caption的来源模型，准确率高达99.70%，证实caption模型具有显著的风格特征。然而，在图像分类任务中，准确率急剧下降至最多50%，即使是先进的Flux模型也表现不佳。这表明生成的图像中风格特征大部分消失，未能保留caption中的关键变化，如细节水平、颜色纹理强调和场景对象分布，与基线方法对比突显跨模态差异。",
      "conclusion": "该研究的主要贡献是提出了一个基于分类的框架，用于量化caption模型的风格特征和text-to-image系统的prompt-following能力。学术价值在于揭示了多模态模型中的不对称特性，为系统评估图像生成性能提供了新方法论。实际应用中，这有助于改进text-to-image系统以更好地遵循输入提示。未来工作可探索如何增强图像生成中风格特征的保留，并扩展框架到其他多模态任务，摘要未明确说明具体局限性。",
      "tags": [
        "Multimodal Models",
        "Caption Generation",
        "Text-to-Image Synthesis",
        "Neural Classification",
        "Style Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:00.647600Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22730",
    "title": "Extending Czech Aspect-Based Sentiment Analysis with Opinion Terms: Dataset and LLM Benchmarks",
    "authors": [
      "Jakub Šmíd",
      "Pavel Přibáň",
      "Pavel Král"
    ],
    "abstract": "This paper introduces a novel Czech dataset in the restaurant domain for aspect-based sentiment analysis (ABSA), enriched with annotations of opinion terms. The dataset supports three distinct ABSA tasks involving opinion terms, accommodating varying levels of complexity. Leveraging this dataset, we conduct extensive experiments using modern Transformer-based models, including large language models (LLMs), in monolingual, cross-lingual, and multilingual settings. To address cross-lingual challenges, we propose a translation and label alignment methodology leveraging LLMs, which yields consistent improvements. Our results highlight the strengths and limitations of state-of-the-art models, especially when handling the linguistic intricacies of low-resource languages like Czech. A detailed error analysis reveals key challenges, including the detection of subtle opinion terms and nuanced sentiment expressions. The dataset establishes a new benchmark for Czech ABSA, and our proposed translation-alignment approach offers a scalable solution for adapting ABSA resources to other low-resource languages.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22730.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22730",
    "published": "2026-02-26T08:13:42Z",
    "updated": "2026-02-26T08:13:42Z",
    "comment": "Accepted for the 15th edition of the Language Resources and Evaluation Conference (LREC 2026)",
    "light_analysis": {
      "overview": "本文通过引入捷克基于方面的情感分析数据集和基于大语言模型的翻译对齐方法，提升了跨语言情感分析性能。",
      "motivation": "研究动机源于在基于方面的情感分析（ABSA）中，意见术语的准确标注对提高分析精度至关重要，但低资源语言如捷克缺乏此类高质量数据集。现有模型在处理语言复杂性时表现不足，特别是在跨语言迁移中面临挑战，导致情感分析效果受限。现有方法在检测微妙意见术语和细微情感表达方面存在缺陷，因此开发新数据集和方法以弥补资源空白和提升适应性成为必要。",
      "method": "研究方法包括创建一个捷克餐厅领域的ABSA数据集，该数据集增加了意见术语注释并支持三个复杂度不同的任务。利用基于Transformer的现代模型，如大语言模型（LLMs），在单语言、跨语言和多语言设置下进行基准实验。关键创新是提出了一种翻译和标签对齐方法，该方法利用LLMs自动处理数据翻译和标签映射，以适配其他语言的资源并提高一致性。数据集构建涉及手动标注，实验涵盖多种模型架构和场景。",
      "result": "实验结果表明，提出的翻译对齐方法在跨语言ABSA任务中带来了性能提升，与基线方法相比表现更优。新数据集的使用揭示了模型在处理捷克语微妙意见术语和情感表达时的优劣，例如模型在检测复杂表达方面仍存在挑战。错误分析显示关键难点包括细微差异的检测和敏感性不足，尽管摘要未提供具体数字，但强调了该方法的一致改进效果。结果还突出了模型在低资源语言环境下的局限性。",
      "conclusion": "本文结论是新数据集为捷克ABSA设立了新基准，促进了该领域研究。提出的翻译对齐方法提供了一种可扩展方案，能够适配到其他低资源语言，解决跨语言资源不足问题。研究不仅提升了特定语言的情感分析性能，还为多语言应用提供了通用框架。学术上，该研究贡献了新数据和创新方法，深化了对模型处理复杂语言现象的理解；应用上支持实际场景。未来工作可优化方法或扩展到更多语言和领域。",
      "tags": [
        "Aspect-Based Sentiment Analysis",
        "Large Language Models",
        "Transformer Models",
        "Cross-Lingual Learning",
        "Opinion Mining"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:07.309726Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22727",
    "title": "HulluEdit: Single-Pass Evidence-Consistent Subspace Editing for Mitigating Hallucinations in Large Vision-Language Models",
    "authors": [
      "Yangguang Lin",
      "Quan Fang",
      "Yufei Li",
      "Jiachen Sun",
      "Junyu Gao",
      "Jitao Sang"
    ],
    "abstract": "Object hallucination in Large Vision-Language Models (LVLMs) significantly hinders their reliable deployment. Existing methods struggle to balance efficiency and accuracy: they often require expensive reference models and multiple forward passes, or apply static edits that risk suppressing genuine visual evidence. To address this, we introduce HulluEdit, a single-pass, reference-free intervention framework. Our core innovation is orthogonal subspace editing: we decompose the hidden states of the model into orthogonal subspaces - visual evidence, conflicting priors, and residual uncertainty - enabling selective suppression of hallucinatory patterns without interfering with visual grounding. This approach mathematically guarantees that edits applied to the prior subspace leave the visual component entirely unaffected. Extensive experiments show that HulluEdit achieves state-of-the-art hallucination reduction on benchmarks including POPE and CHAIR across diverse architectures, while preserving general capabilities on MME and maintaining efficient inference. Our method consistently outperforms contrastive decoding and static subspace editing baselines, offering a new pathway toward more trustworthy LVLMs.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22727.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22727",
    "published": "2026-02-26T08:08:25Z",
    "updated": "2026-02-26T08:08:25Z",
    "comment": "accepted at CVPR 2026",
    "light_analysis": {
      "overview": "本文提出HulluEdit框架，通过正交子空间编辑在单步操作中减少大型视觉语言模型的幻觉问题。",
      "motivation": "大型视觉语言模型在生成响应时经常出现物体幻觉，这严重限制了其在实际应用中的可靠部署。现有方法如对比解码或静态子空间编辑存在效率和准确性之间的平衡难题：它们要么依赖昂贵的参考模型和多次前向传播，计算成本高昂；要么采用固定编辑策略，可能错误地抑制真实视觉证据，导致干预不精确。因此，开发一种既能高效运行又能精确减少幻觉的新方法至关重要，以推动LVLMs在关键领域的应用。",
      "method": "HulluEdit的核心技术是正交子空间编辑。首先，将模型的隐藏状态分解为三个正交子空间：视觉证据子空间（反映输入图像的真实信息）、冲突先验子空间（包含可能导致幻觉的预训练知识）和剩余不确定性子空间。然后，仅对冲突先验子空间进行编辑，选择性地抑制幻觉模式，同时通过数学正交性保证视觉证据子空间完全不受影响。该方法在单次前向传播中完成，无需额外参考模型，实现了高效的干预，且适用于多种模型架构。",
      "result": "HulluEdit在多个标准基准测试中表现出色，如在POPE和CHAIR上实现了最先进的幻觉减少效果，显著降低了物体幻觉率。与基线方法如对比解码和静态子空间编辑相比，它在保持模型一般能力（如在MME基准上的性能）的同时，取得了更好的幻觉缓解效果，并维持了高效的推理速度，避免了多次计算的开销。实验表明，该方法在不同架构上均能有效平衡准确性和效率。",
      "conclusion": "本研究提出的HulluEdit框架通过正交子空间编辑技术，为大型视觉语言模型的幻觉问题提供了一种高效且精确的解决方案。其主要贡献在于数学上保证了干预的精确性，同时通过单步操作提升了效率，增强了模型的可信度。这一方法不仅具有学术价值，推动了AI可靠性的研究，还为实际应用如自动驾驶和医疗诊断提供了支持。未来工作可进一步探索子空间优化或扩展到其他幻觉类型，以提升泛化能力。",
      "tags": [
        "Large Vision-Language Models",
        "Orthogonal Subspace Editing",
        "Hallucination Mitigation",
        "Single-Pass Inference",
        "Visual Grounding"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:09.905335Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22723",
    "title": "Human Label Variation in Implicit Discourse Relation Recognition",
    "authors": [
      "Frances Yung",
      "Daniil Ignatev",
      "Merel Scholman",
      "Vera Demberg",
      "Massimo Poesio"
    ],
    "abstract": "There is growing recognition that many NLP tasks lack a single ground truth, as human judgments reflect diverse perspectives. To capture this variation, models have been developed to predict full annotation distributions rather than majority labels, while perspectivist models aim to reproduce the interpretations of individual annotators. In this work, we compare these approaches on Implicit Discourse Relation Recognition (IDRR), a highly ambiguous task where disagreement often arises from cognitive complexity rather than ideological bias. Our experiments show that existing annotator-specific models perform poorly in IDRR unless ambiguity is reduced, whereas models trained on label distributions yield more stable predictions. Further analysis indicates that frequent cognitively demanding cases drive inconsistency in human interpretation, posing challenges for perspectivist modeling in IDRR.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22723.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22723",
    "published": "2026-02-26T07:56:24Z",
    "updated": "2026-02-26T07:56:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究比较了注释分布模型与perspectivist模型在隐含话语关系识别中的表现，发现基于标签分布的模型在高度模糊任务中提供更稳定预测。",
      "motivation": "随着NLP领域认识到许多任务缺乏单一真实标签，人类注释反映多样视角，需要模型处理这种变异。隐含话语关系识别是一个高度模糊的任务，分歧常源于认知复杂性而非意识形态偏见，这使其成为研究人类标签变异的理想场景。现有方法包括预测完整注释分布和perspectivist建模，但它们在IDRR中的有效性尚不明确，本研究旨在评估这些方法，以理解如何更好地处理认知复杂性导致的标签不一致。",
      "method": "本研究比较了两种处理人类标签变异的方法：一是预测完整注释分布的模型，二是旨在复制个体注释者解释的perspectivist模型。实验在隐含话语关系识别任务上进行，具体数据集和模型架构摘要未明确说明，推断可能使用标准IDRR数据集进行训练和评估。关键创新点在于分析这些方法在高度模糊任务中的性能差异，以探究认知复杂性对建模的影响。",
      "result": "实验结果显示，现有的注释者特定perspectivist模型在IDRR中表现不佳，除非任务模糊性被降低；而基于标签分布训练的模型能产生更稳定的预测。进一步分析表明，频繁出现的认知需求案例是驱动人类解释不一致性的主要因素，这给perspectivist建模带来了挑战。具体性能指标如准确率提升摘要未提供，但结果强调了标签分布模型在处理模糊任务时的优势。",
      "conclusion": "本研究的主要贡献是比较了注释分布模型和perspectivist模型在IDRR任务上的表现，发现基于标签分布的模型更有效，这强调了在处理高度模糊NLP任务时考虑标签分布的重要性。学术价值在于为人类标签变异建模提供了 insights，实际应用可改进IDRR等任务的模型鲁棒性。局限性在于摘要未明确说明具体技术细节，未来工作可探索减少模糊性或增强perspectivist模型的方法。",
      "tags": [
        "Implicit Discourse Relation Recognition",
        "Human Label Variation",
        "Perspectivist Models",
        "Annotation Distributions",
        "Cognitive Complexity"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:55.754710Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22719",
    "title": "Interpreting and Steering State-Space Models via Activation Subspace Bottlenecks",
    "authors": [
      "Vamshi Sunku Mohan",
      "Kaustubh Gupta",
      "Aneesha Das",
      "Chandan Singh"
    ],
    "abstract": "State-space models (SSMs) have emerged as an efficient strategy for building powerful language models, avoiding the quadratic complexity of computing attention in transformers. Despite their promise, the interpretability and steerability of modern SSMs remain relatively underexplored. We take a major step in this direction by identifying activation subspace bottlenecks in the Mamba family of SSM models using tools from mechanistic interpretability. We then introduce a test-time steering intervention that simply multiplies the activations of the identified bottlenecks by a scalar. Across 5 SSMs and 6 diverse benchmarks, this intervention improves performance by an average of 8.27%, without requiring any task-specific tuning. Finally, we validate that the identified bottlenecks are indeed hindering performance by modifying them to yield an architecture we call Stable-Mamba, which achieves long-context performance gains when retrained from scratch.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22719.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22719",
    "published": "2026-02-26T07:46:42Z",
    "updated": "2026-02-26T07:46:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过识别和操作 State-Space Models 中的激活子空间瓶颈，提高了其性能和可操作性，并提出 Stable-Mamba 架构。",
      "motivation": "State-space models (SSMs) 作为构建高效语言模型的方法，避免了 transformers 的二次计算复杂度，但可解释性和可操作性未被充分探索，限制了模型优化和应用。本研究旨在解决这一不足，通过揭示 SSMs 内部机制并开发控制方法，以提升其在各种任务中的性能，推动相关研究进展。",
      "method": "研究采用机制解释工具分析 Mamba 家族 SSM 模型，识别激活子空间瓶颈，并提出一种简单的测试时干预：将瓶颈激活乘以标量，无需额外训练或任务特定调整。关键创新在于基于瓶颈的发现进行直接干预，并设计了 Stable-Mamba 架构，通过修改瓶颈结构以在长上下文任务中提升性能，展示了方法的通用性和简易性。",
      "result": "在 5 个不同 SSM 模型和 6 个多样化基准测试中，测试时干预使性能平均提升 8.27%，且无需任务特定调优，证明了干预的有效性。与基线相比，改进显著；同时，Stable-Mamba 架构在重新训练后，长上下文任务性能获得提升，验证了瓶颈对模型性能的阻碍作用。",
      "conclusion": "本研究贡献在于识别 SSMs 的瓶颈并提出简单干预方法，增强了可解释性和可操作性，为高效语言模型开发提供新路径。Stable-Mamba 架构的长上下文提升展示了实际应用价值。未来工作可能扩展到更多模型和复杂干预机制，进一步优化性能。",
      "tags": [
        "State-Space Models",
        "Mechanistic Interpretability",
        "Activation Subspace Bottlenecks",
        "Mamba",
        "Test-time Steering Intervention"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:14.337625Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22718",
    "title": "RLHFless: Serverless Computing for Efficient RLHF",
    "authors": [
      "Rui Wei",
      "Hanfei Yu",
      "Shubham Jain",
      "Yogarajan Sivakumar",
      "Devesh Tiwari",
      "Jian Li",
      "Seung-Jong Park",
      "Hao Wang"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been widely applied to Large Language Model (LLM) post-training to align model outputs with human preferences. Recent models, such as DeepSeek-R1, have also shown RLHF's potential to improve LLM reasoning on complex tasks. In RL, inference and training co-exist, creating dynamic resource demands throughout the workflow. Compared to traditional RL, RLHF further challenges training efficiency due to expanding model sizes and resource consumption. Several RLHF frameworks aim to balance flexible abstraction and efficient execution. However, they rely on serverful infrastructures, which struggle with fine-grained resource variability. As a result, during synchronous RLHF training, idle time between or within RL components often causes overhead and resource wastage.   To address these issues, we present RLHFless, the first scalable training framework for synchronous RLHF, built on serverless computing environments. RLHFless adapts to dynamic resource demands throughout the RLHF pipeline, pre-computes shared prefixes to avoid repeated computation, and uses a cost-aware actor scaling strategy that accounts for response length variation to find sweet spots with lower cost and higher speed. In addition, RLHFless assigns workloads efficiently to reduce intra-function imbalance and idle time. Experiments on both physical testbeds and a large-scale simulated cluster show that RLHFless achieves up to 1.35x speedup and 44.8% cost reduction compared to the state-of-the-art baseline.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22718.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22718",
    "published": "2026-02-26T07:45:37Z",
    "updated": "2026-02-26T07:45:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出首个基于无服务器计算的可扩展同步RLHF训练框架RLHFless，以提升效率并降低成本。",
      "motivation": "强化学习从人类反馈（RLHF）在大型语言模型对齐和复杂任务推理提升中发挥关键作用，但现有RLHF框架依赖服务器基础设施，难以处理训练过程中由推理与训练共存引起的动态资源需求。这导致同步训练时组件间的空闲时间和资源浪费问题加剧，尤其是在模型规模扩大后，资源消耗增加，传统方法效率不足，亟需更灵活的解决方案来提高训练效率和资源利用率。",
      "method": "RLHFless框架基于无服务器计算环境设计，核心创新包括适应RLHF流水线的动态资源需求、预计算共享前缀以消除重复计算、采用成本感知的执行器扩展策略来优化响应长度变化并找到成本与速度的平衡点。此外，框架高效分配工作负载以减少内部函数不平衡和空闲时间，从而实现可扩展的同步训练，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "在物理测试床和大规模模拟集群上的实验中，RLHFless与最先进基线相比，实现了高达1.35倍的速度提升和44.8%的成本降低，显示了其在训练效率和成本优化方面的显著改进，有效减少了同步RLHF训练中的资源浪费和空闲时间，证明了该框架的实际性能优势。",
      "conclusion": "RLHFless为解决同步RLHF训练中的资源效率问题提供了首个基于无服务器计算的创新框架，其学术价值在于探索了动态资源优化技术在高效训练中的应用，实际应用价值在于降低了部署成本并提高了速度，但摘要未明确说明潜在的局限性或未来工作方向，如扩展至更多场景或模型的验证。",
      "tags": [
        "Reinforcement Learning from Human Feedback (RLHF)",
        "Serverless Computing",
        "Synchronous Training",
        "Dynamic Resource Allocation",
        "Cost Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:02.173488Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22717",
    "title": "IRSDE-Despeckle: A Physics-Grounded Diffusion Model for Generalizable Ultrasound Despeckling",
    "authors": [
      "Shuoqi Chen",
      "Yujia Wu",
      "Geoffrey P. Luke"
    ],
    "abstract": "Ultrasound imaging is widely used for real-time, noninvasive diagnosis, but speckle and related artifacts reduce image quality and can hinder interpretation. We present a diffusion-based ultrasound despeckling method built on the Image Restoration Stochastic Differential Equations framework. To enable supervised training, we curate large paired datasets by simulating ultrasound images from speckle-free magnetic resonance images using the Matlab UltraSound Toolbox. The proposed model reconstructs speckle-suppressed images while preserving anatomically meaningful edges and contrast. On a held-out simulated test set, our approach consistently outperforms classical filters and recent learning-based despeckling baselines. We quantify prediction uncertainty via cross-model variance and show that higher uncertainty correlates with higher reconstruction error, providing a practical indicator of difficult or failure-prone regions. Finally, we evaluate sensitivity to simulation probe settings and observe domain shift, motivating diversified training and adaptation for robust clinical deployment.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22717.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22717",
    "published": "2026-02-26T07:42:25Z",
    "updated": "2026-02-26T07:42:25Z",
    "comment": "12 pages main text + 6 pages appendix, 7 figures main + 3 figures appendix, 3 tables main + 1 table appendix. Preprint",
    "light_analysis": {
      "overview": "本研究提出IRSDE-Despeckle，一种基于物理的扩散模型，用于通用超声图像去斑点，有效抑制斑点并保留解剖细节。",
      "motivation": "超声成像广泛应用于实时、无创诊断，但斑点和相关伪影显著降低图像质量，可能误导临床解读。尽管现有方法包括经典滤波器和基于学习的去斑点技术已取得进展，但它们常无法在抑制斑点时充分保留重要的解剖边缘和对比度，导致图像失真或泛化能力不足。因此，开发一种更稳健、通用的去斑点方法对于提升诊断准确性和临床实用性至关重要。摘要未明确说明具体不足之处，但暗示现有方法在性能和泛化方面仍有提升空间。",
      "method": "论文提出一种基于扩散的去斑点方法，建立在Image Restoration Stochastic Differential Equations框架上，利用物理基础建模斑点抑制过程。为了进行监督训练，作者策划了大尺度配对数据集，通过Matlab UltraSound Toolbox从无斑点的磁共振图像模拟超声图像，确保数据多样性和真实性。核心创新点包括将扩散模型应用于超声图像恢复，并通过IRSDE框架优化重构过程，重点在于同时去除斑点和保留解剖上有意义的边缘与对比度，摘要未明确说明具体模型架构细节。",
      "result": "在保留的模拟测试集上，IRSDE-Despeckle持续优于经典滤波器和近期基于学习的去斑点基线方法，表现为更高的图像质量和去斑点效果。作者通过跨模型方差量化预测不确定性，发现较高不确定性与较高的重构误差相关，为识别图像中困难或易失败区域提供了实用指标。此外，评估对模拟探针设置的敏感性时观察到领域偏移现象，提示模型可能需要适应不同临床环境以保持性能。摘要未提供具体性能数据如准确率提升值。",
      "conclusion": "该研究的主要贡献是提出了一个通用且有效的超声去斑点扩散模型，通过不确定性量化为模型可靠性提供了新见解。学术价值在于将物理基础的扩散方法应用于医学图像处理，实际应用中可帮助改善超声诊断的清晰度。局限性包括对模拟数据的依赖性，未来工作可专注于多样化训练、领域适应和临床部署验证，以应对领域偏移问题，摘要未明确说明其他具体局限性。",
      "tags": [
        "Diffusion Model",
        "Ultrasound Despeckling",
        "Image Restoration",
        "Stochastic Differential Equations",
        "Supervised Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:03.777874Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22716",
    "title": "SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs",
    "authors": [
      "Guanting Ye",
      "Qiyan Zhao",
      "Wenhao Yu",
      "Liangyu Yuan",
      "Mingkai Li",
      "Xiaofeng Zhang",
      "Jianmin Ji",
      "Yanyong Zhang",
      "Qing Jiang",
      "Ka-Veng Yuen"
    ],
    "abstract": "3D Large Vision-Language Models (3D LVLMs) built upon Large Language Models (LLMs) have achieved remarkable progress across various multimodal tasks. However, their inherited position-dependent modeling mechanism, Rotary Position Embedding (RoPE), remains suboptimal for 3D multimodal understanding. The vanilla RoPE formulation fails to preserve essential three-dimensional spatial structures when encoding 3D tokens, and its relative distance computation overlooks angular dependencies, hindering the model's ability to capture directional variations in visual representations. To overcome these limitations, we introduce Spherical Coordinate-based Positional Embedding (SoPE). Our method maps point-cloud token indices into a 3D spherical coordinate space, enabling unified modeling of spatial locations and directional angles. This formulation preserves the inherent geometric structure of point-cloud data, enhances spatial awareness, and yields more consistent and expressive geometric representations for multimodal learning. In addition, we introduce a multi-scale frequency mixing strategy to fuse feature information across different frequency domains. Experimental results on multiple 3D scene benchmarks validate the effectiveness of our approach, while real-world deployment experiments further demonstrate its strong generalization capability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22716.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22716",
    "published": "2026-02-26T07:42:15Z",
    "updated": "2026-02-26T07:42:15Z",
    "comment": "CVPR 2026",
    "light_analysis": {
      "overview": "本文提出基于球坐标的位置嵌入（SoPE）方法，以增强3D大型视觉语言模型的空间感知能力，从而改进3D多模态理解。",
      "motivation": "当前3D大型视觉语言模型（3D LVLMs）依赖于旋转位置嵌入（RoPE），但该机制在3D多模态理解中存在局限性。RoPE在编码3D token时未能保留必要的三维空间结构，且其相对距离计算忽视了角度依赖，导致模型难以捕捉视觉表示中的方向变化。这影响了3D LVLMs在空间感知任务上的性能，限制了其在复杂3D场景中的应用，因此需要改进位置嵌入方法以更精确地处理三维几何数据。",
      "method": "论文提出了基于球坐标的位置嵌入（SoPE）方法，该方法将点云token的索引映射到三维球坐标系中，实现空间位置和方向角的统一建模，以保留点云数据的固有几何结构并增强空间感知。关键创新点包括球坐标的引入，以处理三维空间的角向信息，并辅以多尺度频率混合策略，融合不同频域的特征信息，提升模型表达能力。技术路线涉及点云数据的使用，通过球坐标转换增强token的位置编码，以生成更一致和富有表现力的几何表示用于多模态学习。",
      "result": "实验在多个3D场景基准上进行，验证了SoPE方法的有效性，表明其能够提升3D LVLMs的空间感知能力和几何表示质量。摘要未明确说明具体性能指标如准确率提升，但提到实验结果证实SoPE在捕捉方向变化和保留空间结构方面优于基线方法。实际部署实验进一步证明了SoPE的强大泛化能力，展示其在现实场景中的应用潜力。",
      "conclusion": "SoPE方法的主要贡献是通过球坐标位置嵌入，显著增强了3D LVLMs的空间感知能力和几何表示一致性，为3D多模态学习提供了更有效的建模方式。这项研究具有学术价值，推动了位置嵌入技术在3D视觉语言模型中的发展；在实际应用中，SoPE的泛化能力使其适用于各种3D场景，提高了模型的鲁棒性。未来工作方向可能包括优化多尺度频率策略或扩展到其他类型的3D数据。",
      "tags": [
        "Spherical Coordinate",
        "Positional Embedding",
        "3D Large Vision-Language Models (3D LVLMs)",
        "Multimodal Learning",
        "Point-Cloud Data"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:28.487365Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22712",
    "title": "UFO-DETR: Frequency-Guided End-to-End Detector for UAV Tiny Objects",
    "authors": [
      "Yuankai Chen",
      "Kai Lin",
      "Qihong Wu",
      "Xinxuan Yang",
      "Jiashuo Lai",
      "Ruoen Chen",
      "Haonan Shi",
      "Minfan He",
      "Meihua Wang"
    ],
    "abstract": "Small target detection in UAV imagery faces significant challenges such as scale variations, dense distribution, and the dominance of small targets. Existing algorithms rely on manually designed components, and general-purpose detectors are not optimized for UAV images, making it difficult to balance accuracy and complexity. To address these challenges, this paper proposes an end-to-end object detection framework, UFO-DETR, which integrates an LSKNet-based backbone network to optimize the receptive field and reduce the number of parameters. By combining the DAttention and AIFI modules, the model flexibly models multi-scale spatial relationships, improving multi-scale target detection performance. Additionally, the DynFreq-C3 module is proposed to enhance small target detection capability through cross-space frequency feature enhancement. Experimental results show that, compared to RT-DETR-L, the proposed method offers significant advantages in both detection performance and computational efficiency, providing an efficient solution for UAV edge computing.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22712.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22712",
    "published": "2026-02-26T07:37:45Z",
    "updated": "2026-02-26T07:37:45Z",
    "comment": "6 pages, 6 figures, published to 2026 International Conference on Computer Supported Cooperative Work in Design",
    "light_analysis": {
      "overview": "本文提出UFO-DETR检测器，通过集成LSKNet骨干和频率特征增强模块，优化无人机图像中小目标的检测性能与计算效率。",
      "motivation": "无人机图像中的小目标检测面临尺度变化大、目标密集且多为小尺寸的挑战，在军事、监控等领域具有重要应用。现有算法依赖手动设计组件，缺乏针对性优化，而通用检测器在处理无人机图像时难以平衡准确率和计算开销，限制了实际部署效率。因此，需开发一种轻量级、高性能的专门化检测方法以应对这些挑战。",
      "method": "UFO-DETR是一个端到端目标检测框架，采用LSKNet-based骨干网络优化感受野并减少参数数量。结合DAttention和AIFI模块，灵活建模多尺度空间关系以提升多尺度目标检测能力。此外，提出DynFreq-C3模块，通过跨空间频率特征增强来专门加强小目标检测，针对无人机图像特点进行整体优化。",
      "result": "摘要未明确说明具体性能指标如准确率或计算时间，但指出与基线方法RT-DETR-L相比，UFO-DETR在检测性能和计算效率方面表现出显著优势，暗示了在保持高精度的同时降低计算开销，适合资源受限的无人机边缘设备。",
      "conclusion": "UFO-DETR的主要贡献在于提出频率引导的端到端检测框架，通过优化骨干网络和频率特征增强，提升了小目标检测性能并减少了参数复杂度，为无人机边缘计算提供了高效解决方案。未来工作可探索在不同数据集上的泛化能力和实时性能优化。",
      "tags": [
        "Object Detection",
        "DETR",
        "LSKNet",
        "Frequency Enhancement",
        "Edge Computing"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:24.938140Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22703",
    "title": "Enhancing Geometric Perception in VLMs via Translator-Guided Reinforcement Learning",
    "authors": [
      "Hao Yu",
      "Shuning Jia",
      "Guanghao Li",
      "Wenhao Jiang",
      "Chun Yuan"
    ],
    "abstract": "Vision-language models (VLMs) often struggle with geometric reasoning due to their limited perception of fundamental diagram elements. To tackle this challenge, we introduce GeoPerceive, a benchmark comprising diagram instances paired with domain-specific language (DSL) representations, along with an efficient automatic data generation pipeline. This design enables the isolated evaluation of geometric perception independently from reasoning. To exploit the data provided by GeoPerceive for enhancing the geometric perception capabilities of VLMs, we propose GeoDPO, a translator-guided reinforcement learning (RL) framework. GeoDPO employs an NL-to-DSL translator, which is trained on synthetic pairs generated by the data engine of GeoPerceive, to bridge natural language and DSL. This translator facilitates the computation of fine-grained, DSL-level scores, which serve as reward signals in reinforcement learning. We assess GeoDPO on both in-domain and out-of-domain datasets, spanning tasks in geometric perception as well as downstream reasoning. Experimental results demonstrate that, while supervised fine-tuning (SFT) offers only marginal improvements and may even impair performance in out-of-domain scenarios, GeoDPO achieves substantial gains: $+26.5\\%$ on in-domain data, $+8.0\\%$ on out-of-domain data, and $+39.0\\%$ on downstream reasoning tasks. These findings underscore the superior performance and generalization ability of GeoDPO over SFT. All codes are released at https://github.com/Longin-Yu/GeoPerceive   to ensure reproducibility.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22703.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22703",
    "published": "2026-02-26T07:28:04Z",
    "updated": "2026-02-26T07:28:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "GeoDPO通过翻译器引导的强化学习框架，显著提升视觉语言模型在几何感知任务上的性能和泛化能力。",
      "motivation": "视觉语言模型（VLMs）在几何推理任务中表现不佳，主要因为对图表基本元素的感知有限，限制了其实际应用。现有方法如监督微调（SFT）效果有限，在域外场景中甚至可能导致性能下降，这凸显了增强VLM几何感知和改善泛化能力的重要性。本研究旨在解决这一问题，通过开发新方法来弥补VLMs的感知不足，从而推动几何推理领域的发展。",
      "method": "论文提出GeoDPO框架，这是一个结合翻译器和强化学习的方法。首先，构建GeoPerceive基准，包含图表实例与领域特定语言（DSL）表示，并设计了自动数据生成流水线来产生训练数据。核心创新是训练一个自然语言到DSL的翻译器，基于GeoPerceive的合成数据进行训练，用于将自然语言指令转换为DSL表示。该翻译器通过计算细粒度的DSL级分数，生成强化学习中的奖励信号，从而优化模型参数，提升几何感知能力。",
      "result": "实验结果显示，GeoDPO在几何感知任务中取得显著提升：在域内数据上性能提升26.5%，域外数据上提升8.0%，下游推理任务上提升39.0%。相比之下，监督微调（SFT）仅带来边际改进，且在域外场景中可能损害性能。这证明了GeoDPO在增强模型性能和泛化能力方面的优越性，特别是在处理复杂几何任务时。",
      "conclusion": "GeoDPO框架成功提高了VLMs的几何感知能力和泛化性能，通过翻译器引导的强化学习方法解决了现有技术的局限。该研究在学术上贡献了一种结合领域特定语言和强化学习的创新技术路线，应用上可促进几何推理任务的进展。未来工作可进一步优化框架或扩展到其他感知任务，但摘要未明确说明具体方向。",
      "tags": [
        "Vision-Language Models",
        "Geometric Reasoning",
        "Reinforcement Learning",
        "Domain-Specific Language",
        "Translator-Guided Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:30.897262Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22702",
    "title": "Knob: A Physics-Inspired Gating Interface for Interpretable and Controllable Neural Dynamics",
    "authors": [
      "Siyu Jiang",
      "Sanshuai Cui",
      "Hui Zeng"
    ],
    "abstract": "Existing neural network calibration methods often treat calibration as a static, post-hoc optimization task. However, this neglects the dynamic and temporal nature of real-world inference. Moreover, existing methods do not provide an intuitive interface enabling human operators to dynamically adjust model behavior under shifting conditions. In this work, we propose Knob, a framework that connects deep learning with classical control theory by mapping neural gating dynamics to a second-order mechanical system. By establishing correspondences between physical parameters -- damping ratio ($ζ$) and natural frequency ($ω_n$) -- and neural gating, we create a tunable \"safety valve\". The core mechanism employs a logit-level convex fusion, functioning as an input-adaptive temperature scaling. It tends to reduce model confidence particularly when model branches produce conflicting predictions. Furthermore, by imposing second-order dynamics (Knob-ODE), we enable a \\textit{dual-mode} inference: standard i.i.d. processing for static tasks, and state-preserving processing for continuous streams. Our framework allows operators to tune \"stability\" and \"sensitivity\" through familiar physical analogues. This paper presents an exploratory architectural interface; we focus on demonstrating the concept and validating its control-theoretic properties rather than claiming state-of-the-art calibration performance. Experiments on CIFAR-10-C validate the calibration mechanism and demonstrate that, in Continuous Mode, the gate responses are consistent with standard second-order control signatures (step settling and low-pass attenuation), paving the way for predictable human-in-the-loop tuning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22702.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22702",
    "published": "2026-02-26T07:25:22Z",
    "updated": "2026-02-26T07:25:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Knob框架，通过物理启发方法将神经门控动态映射到二阶力学系统，实现可解释和可控的神经网络推理。",
      "motivation": "现有神经网络校准方法通常作为静态后处理优化任务，忽视了实际推理中的动态和时态特性，限制了模型在动态环境中的适应性。更关键的是，现有方法缺乏直观界面，无法让人类操作者在变化条件下动态调整模型行为，这阻碍了模型的可控性和实际应用。该研究旨在解决这些不足，提供一个动态、交互式的校准方案，以提升神经网络的灵活性和人机协同能力。",
      "method": "Knob框架的核心是连接深度学习和经典控制理论，通过建立物理参数（如阻尼比ζ和自然频率ω_n）与神经门控的对应关系，创建可调谐的“安全阀”。关键技术包括logit级凸融合机制，它作为输入自适应温度缩放，在模型分支产生冲突预测时降低模型置信度；并通过施加二阶动态（Knob-ODE）实现双模式推理：支持静态任务的标准i.i.d.处理，以及连续流的状态保持处理。实验基于CIFAR-10-C数据集进行验证。",
      "result": "在CIFAR-10-C数据集上的实验验证了Knob的校准机制。结果显示，在连续模式下，门控响应展现出与标准二阶控制系统一致的特征，如阶跃稳定性和低通衰减，这证实了框架的控制理论性质，并为可预测的人机协同调谐提供了基础。摘要未明确说明具体校准性能的改进数据，但强调了概念验证的重要性，未与基线方法进行详细对比。",
      "conclusion": "Knob框架的主要贡献在于提供一个物理启发的门控接口，增强了神经网络的可解释性和动态可控性。学术上，它促进了深度学习与控制理论的交叉融合，推动了动态校准方法的研究；实际上，为动态推理任务提供了直观的调谐工具，支持人机协同。研究是探索性的，未来工作可扩展到更广泛的应用场景，如优化性能并集成到更多任务中。",
      "tags": [
        "Physics-Inspired Learning",
        "Gating Mechanisms",
        "Control Theory",
        "Adaptive Calibration",
        "Second-Order Dynamics"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:47.319155Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22698",
    "title": "Tokenization, Fusion and Decoupling: Bridging the Granularity Mismatch Between Large Language Models and Knowledge Graphs",
    "authors": [
      "Siyue Su",
      "Jian Yang",
      "Bo Li",
      "Guanglin Niu"
    ],
    "abstract": "Leveraging Large Language Models (LLMs) for Knowledge Graph Completion (KGC) is promising but hindered by a fundamental granularity mismatch. LLMs operate on fragmented token sequences, whereas entities are the fundamental units in knowledge graphs (KGs) scenarios. Existing approaches typically constrain predictions to limited candidate sets or align entities with the LLM's vocabulary by pooling multiple tokens or decomposing entities into fixed-length token sequences, which fail to capture both the semantic meaning of the text and the structural integrity of the graph. To address this, we propose KGT, a novel framework that uses dedicated entity tokens to enable efficient, full-space prediction. Specifically, we first introduce specialized tokenization to construct feature representations at the level of dedicated entity tokens. We then fuse pre-trained structural and textual features into these unified embeddings via a relation-guided gating mechanism, avoiding training from scratch. Finally, we implement decoupled prediction by leveraging independent heads to separate and combine semantic and structural reasoning. Experimental results show that KGT consistently outperforms state-of-the-art methods across multiple benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22698.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22698",
    "published": "2026-02-26T07:20:40Z",
    "updated": "2026-02-26T07:20:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出KGT框架，通过专用实体令牌化和解耦预测，有效解决大型语言模型与知识图谱在知识图谱补全中的粒度不匹配问题。",
      "motivation": "研究动机源于利用大型语言模型进行知识图谱补全时面临的粒度不匹配挑战：大型语言模型基于片段化的令牌序列操作，而知识图谱以实体为基本单位。现有方法通常限制预测到有限候选集或通过调整实体表示来对齐，但无法同时捕捉文本语义和图形结构完整性，导致性能受限。这种不匹配阻碍了知识图谱补全的准确性和效率，因此需要开发新方法以更好地结合两者，提升实际应用效果。",
      "method": "KGT框架采用专用令牌化构建实体令牌级别的特征表示，避免了对实体进行固定长度分解。通过关系引导的门控机制，融合预训练的结构和文本特征到统一嵌入中，实现高效特征融合而无需从头训练。最后，利用独立头部实施解耦预测，分离语义推理和结构推理，并有效结合，以处理知识图谱补全任务。该方法的核心创新包括专用实体令牌、融合机制和解耦推理。",
      "result": "实验结果显示，KGT在多个知识图谱补全基准测试中一致优于当前最先进的方法，证明了其处理粒度不匹配问题的有效性。尽管摘要未提供具体性能指标如准确率或提升幅度，但作者强调KGT在不同任务上的优越表现，表明该框架通过桥接大型语言模型与知识图谱的粒度差异，显著提升了知识图谱补全的性能，为后续研究提供了新基准。",
      "conclusion": "KGT框架的主要贡献在于提出专用实体令牌化、特征融合和解耦预测方法，成功解决了大型语言模型与知识图谱之间的粒度不匹配问题。该研究具有重要的学术价值，促进了大型语言模型与知识图谱的结合，提升了知识图谱补全的准确性和效率。实际应用中，KGT可广泛应用于知识图谱构建和推理任务，增强智能系统的知识处理能力。摘要未明确说明研究局限性或未来工作方向。",
      "tags": [
        "Knowledge Graph Completion",
        "Large Language Models",
        "Tokenization",
        "Feature Fusion",
        "Decoupled Prediction"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:54.976024Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22697",
    "title": "Reinforcing Real-world Service Agents: Balancing Utility and Cost in Task-oriented Dialogue",
    "authors": [
      "Ning Gao",
      "Wei Zhang",
      "Yuqin Dai",
      "Ling Shi",
      "Ziyin Wang",
      "Yujie Wang",
      "Wei He",
      "Jinpeng Wang",
      "Chaozheng Wang"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) has accelerated the transition from conversational chatbots to general agents. However, effectively balancing empathetic communication with budget-aware decision-making remains an open challenge. Since existing methods fail to capture these complex strategic trade-offs, we propose InteractCS-RL, a framework that reframes task-oriented dialogue as a multi-granularity reinforcement learning process. Specifically, we first establish a User-centric Interaction Framework to provide a high-fidelity training gym, enabling agents to dynamically explore diverse strategies with persona-driven users. Then, we introduce Cost-aware Multi-turn Policy Optimization (CMPO) with a hybrid advantage estimation strategy. By integrating generative process credits and employing a PID-Lagrangian cost controller, CMPO effectively guides the policy to explore Pareto boundary between user reward and global cost constraints. Extensive experiments on customized real business scenarios demonstrate that InteractCS-RL significantly outperform other baselines across three evaluation dimensions. Further evaluation on tool-agent-user interaction benchmarks verify InteractCS-RL robustness across diverse domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22697.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22697",
    "published": "2026-02-26T07:19:57Z",
    "updated": "2026-02-26T07:19:57Z",
    "comment": "35 pages, 8 tables, 3 figures",
    "light_analysis": {
      "overview": "提出InteractCS-RL框架，通过多粒度强化学习实现任务导向对话中用户奖励与成本约束的平衡。",
      "motivation": "随着大型语言模型的快速发展，任务导向对话系统正从简单聊天机器人向通用代理演进。然而，在实际应用中，如何同时实现用户情感沟通的满意度与基于预算的决策效率，仍是一个关键挑战。现有方法通常未能有效捕捉这些复杂的战略权衡，导致代理在真实场景中表现受限，无法兼顾用户效用和操作成本。因此，本研究旨在解决这一平衡问题，以提升服务代理在真实世界中的综合性能。",
      "method": "论文提出了InteractCS-RL框架，将任务导向对话重构为多粒度强化学习过程。首先，建立用户中心交互框架，提供高保真训练环境，使代理能够与角色驱动用户动态探索多样化策略。然后，引入成本感知多轮策略优化（CMPO），采用混合优势估计策略，通过整合生成过程信用和使用PID-Lagrangian成本控制器，有效引导策略探索用户奖励与全局成本约束之间的帕累托边界。该方法的关键创新在于结合强化学习和成本控制技术。",
      "result": "实验在自定义的真实业务场景中进行，结果显示InteractCS-RL在三个评估维度上显著优于其他基线方法。进一步，在工具-代理-用户交互基准测试中验证了该框架的鲁棒性，能够适应不同领域的任务。摘要未明确说明具体性能指标如准确率提升，但强调了在平衡用户奖励和成本方面的有效改进，这表明该方法在实际应用中具有潜在优势。",
      "conclusion": "该研究的主要贡献是开发了InteractCS-RL框架，成功解决了任务导向对话中平衡用户效用和操作成本的难题。学术上，它推动了多目标强化学习在对话系统中的应用，为智能代理设计提供了新方法。实际价值体现在能帮助服务代理在保持用户满意度的同时优化成本，提升业务效率。未来方向可能包括扩展到更复杂场景或集成更多成本因素。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning",
        "Cost-aware Optimization",
        "Task-oriented Dialogue",
        "PID-Lagrangian"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:02.505495Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22696",
    "title": "Enhancing Persuasive Dialogue Agents by Synthesizing Cross-Disciplinary Communication Strategies",
    "authors": [
      "Shinnosuke Nozue",
      "Yuto Nakano",
      "Yotaro Watanabe",
      "Meguru Takasaki",
      "Shoji Moriya",
      "Reina Akama",
      "Jun Suzuki"
    ],
    "abstract": "Current approaches to developing persuasive dialogue agents often rely on a limited set of predefined persuasive strategies that fail to capture the complexity of real-world interactions. We applied a cross-disciplinary approach to develop a framework for designing persuasive dialogue agents that draws on proven strategies from social psychology, behavioral economics, and communication theory. We validated our proposed framework through experiments on two distinct datasets: the Persuasion for Good dataset, which represents a specific in-domain scenario, and the DailyPersuasion dataset, which encompasses a wide range of scenarios. The proposed framework achieved strong results for both datasets and demonstrated notable improvement in the persuasion success rate as well as promising generalizability. Notably, the proposed framework also excelled at persuading individuals with initially low intent, which addresses a critical challenge for persuasive dialogue agents.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22696.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22696",
    "published": "2026-02-26T07:18:45Z",
    "updated": "2026-02-26T07:18:45Z",
    "comment": "Accepted to the EMNLP 2025 Industry Track; 26 pages",
    "light_analysis": {
      "overview": "论文提出一个跨学科框架，通过整合社会心理学、行为经济学和沟通理论的策略来增强说服对话代理。",
      "motivation": "当前说服对话代理通常依赖有限的预定义策略，无法充分模拟现实世界交互的复杂性，导致在多样化场景中说服效果受限。这一问题在说服初始意图低的个体时尤为突出，影响了代理的实用性和泛化能力。现有方法策略单一，缺乏跨领域知识融合，因此本研究旨在开发一个更全面的框架，以捕捉人类说服行为的微妙之处，提升对话代理的适应性和有效性。",
      "method": "研究方法采用跨学科途径，构建了一个框架，从社会心理学、行为经济学和沟通理论中汲取已验证的策略。关键创新在于合成这些不同领域的策略，形成一个统一的设计方法，以提高说服代理的多样性和适应性。为了验证框架，使用两个数据集：Persuasion for Good（代表特定领域场景）和DailyPersuasion（涵盖广泛场景），从而评估其在不同环境下的鲁棒性和通用性。",
      "result": "实验结果显示，提出的框架在两个数据集上都取得了强结果，显著提升了说服成功率，并展示出良好的泛化能力。具体而言，框架能有效说服初始意图较低的个体，这解决了说服对话代理中的关键挑战。尽管摘要未明确说明与基线方法的详细对比数据，但结果表明性能有显著改进，证明了跨学科策略合成的优势。",
      "conclusion": "本研究的主要贡献是提出一个跨学科框架，有效增强说服对话代理的性能和泛化能力。学术上，它为对话系统研究提供了新视角，促进多领域知识的融合；实际应用上，有助于开发更智能、适应性更强的对话代理，适用于多样场景。未来工作可扩展框架到更多领域或集成先进AI技术，以进一步提升说服效果和效率。",
      "tags": [
        "Persuasive Dialogue Agents",
        "Cross-Disciplinary Framework",
        "Communication Strategies",
        "Social Psychology",
        "Behavioral Economics"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:48.403056Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22695",
    "title": "GFRRN: Explore the Gaps in Single Image Reflection Removal",
    "authors": [
      "Yu Chen",
      "Zewei He",
      "Xingyu Liu",
      "Zixuan Chen",
      "Zheming Lu"
    ],
    "abstract": "Prior dual-stream methods with the feature interaction mechanism have achieved remarkable performance in single image reflection removal (SIRR). However, they often struggle with (1) semantic understanding gap between the features of pre-trained models and those of reflection removal models, and (2) reflection label inconsistencies between synthetic and real-world training data. In this work, we first adopt the parameter efficient fine-tuning (PEFT) strategy by integrating several learnable Mona layers into the pre-trained model to align the training directions. Then, a label generator is designed to unify the reflection labels for both synthetic and real-world data. In addition, a Gaussian-based Adaptive Frequency Learning Block (G-AFLB) is proposed to adaptively learn and fuse the frequency priors, and a Dynamic Agent Attention (DAA) is employed as an alternative to window-based attention by dynamically modeling the significance levels across windows (inter-) and within an individual window (intra-). These components constitute our proposed Gap-Free Reflection Removal Network (GFRRN). Extensive experiments demonstrate the effectiveness of our GFRRN, achieving superior performance against state-of-the-art SIRR methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22695.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22695",
    "published": "2026-02-26T07:17:49Z",
    "updated": "2026-02-26T07:17:49Z",
    "comment": "CVPR26",
    "light_analysis": {
      "overview": "本文提出GFRRN网络，通过整合参数高效微调、标签生成器和自适应频率学习块，解决单图像反射去除中的语义理解差距和标签不一致问题，提升了反射去除模型的性能和泛化能力。",
      "motivation": "现有双流方法在单图像反射去除中虽表现出色，但面临两大挑战：一是预训练模型特征与反射去除模型特征之间的语义理解差距，影响特征对齐；二是合成数据与真实世界数据反射标签的不一致性，导致训练数据噪声和模型泛化能力下降。这些问题限制了方法在真实场景中的应用效果，亟需新策略来统一处理这些间隙以提升准确性。",
      "method": "论文提出了GFRRN网络，核心方法包括：采用参数高效微调策略，通过集成可学习的Mona层来对齐预训练模型与反射去除模型的训练方向；设计标签生成器统一合成和真实数据的反射标签，减少数据不一致性；引入高斯自适应频率学习块自适应学习和融合频率先验；使用动态代理注意力动态建模窗口内和窗口间的重要性，替代传统的窗口注意力机制。这些组件共同构建了一个鲁棒且高效的反射去除模型。",
      "result": "大量实验表明GFRRN在单图像反射去除任务上表现优越，优于当前最先进方法。摘要未明确说明具体性能指标如准确率或效率改进的数值，但通过与其他方法的比较验证了其有效性，展示了在反射去除领域的竞争优势。",
      "conclusion": "本研究的主要贡献是设计了GFRRN，有效解决了反射去除中的语义理解差距和标签不一致问题，通过创新机制提升了模型性能。研究具有重要学术价值，推动了计算机视觉中反射去除技术的进步，并可能在图像增强、自动驾驶等实际应用中发挥价值。未来工作可探索更复杂场景下的模型优化或进一步降低计算成本。",
      "tags": [
        "Single Image Reflection Removal",
        "Parameter Efficient Fine-Tuning",
        "Mona Layers",
        "Gaussian-based Adaptive Frequency Learning",
        "Dynamic Agent Attention"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:59.368755Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22689",
    "title": "No Caption, No Problem: Caption-Free Membership Inference via Model-Fitted Embeddings",
    "authors": [
      "Joonsung Jeon",
      "Woo Jae Kim",
      "Suhyeon Ha",
      "Sooel Son",
      "Sung-Eui Yoon"
    ],
    "abstract": "Latent diffusion models have achieved remarkable success in high-fidelity text-to-image generation, but their tendency to memorize training data raises critical privacy and intellectual property concerns. Membership inference attacks (MIAs) provide a principled way to audit such memorization by determining whether a given sample was included in training. However, existing approaches assume access to ground-truth captions. This assumption fails in realistic scenarios where only images are available and their textual annotations remain undisclosed, rendering prior methods ineffective when substituted with vision-language model (VLM) captions. In this work, we propose MoFit, a caption-free MIA framework that constructs synthetic conditioning inputs that are explicitly overfitted to the target model's generative manifold. Given a query image, MoFit proceeds in two stages: (i) model-fitted surrogate optimization, where a perturbation applied to the image is optimized to construct a surrogate in regions of the model's unconditional prior learned from member samples, and (ii) surrogate-driven embedding extraction, where a model-fitted embedding is derived from the surrogate and then used as a mismatched condition for the query image. This embedding amplifies conditional loss responses for member samples while leaving hold-outs relatively less affected, thereby enhancing separability in the absence of ground-truth captions. Our comprehensive experiments across multiple datasets and diffusion models demonstrate that MoFit consistently outperforms prior VLM-conditioned baselines and achieves performance competitive with caption-dependent methods.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22689.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22689",
    "published": "2026-02-26T07:07:11Z",
    "updated": "2026-02-26T07:07:11Z",
    "comment": "Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "论文提出 MoFit 框架，通过模型拟合嵌入实现无需标注的成员推理攻击，有效审计扩散模型的训练数据记忆。",
      "motivation": "潜在扩散模型在文本到图像生成中表现出色，但存在记忆训练数据的问题，引发隐私和知识产权担忧。成员推理攻击作为一种审计手段，可以检测特定样本是否属于训练集。然而，现有 MIA 方法依赖真实标注，这在现实场景中不成立，因为只有图像可用而标注未公开。这使得先前方法在使用视觉语言模型生成标注时效果不佳，凸显了开发无标注 MIA 方法的必要性，以应对实际应用中的隐私和版权挑战。",
      "method": "MoFit 是一个无需标注的 MIA 框架，通过两阶段过程构造合成条件输入。第一阶段是模型拟合替代优化：对查询图像应用扰动，优化使其在目标模型的无条件先验区域中构造替代，该先验从成员样本学习而来。第二阶段是替代驱动的嵌入提取：从替代中提取模型拟合嵌入，用作查询图像的失配条件。这种方法放大成员样本的条件损失响应，同时较少影响非成员样本，从而在无真实标注情况下增强可分离性，核心创新在于过拟合到生成流形。",
      "result": "在多个数据集和扩散模型上的综合实验表明，MoFit 一致优于先前的 VLM 条件基线，并在性能上与依赖标注的方法竞争。这意味着 MoFit 在处理无标注图像时仍能有效进行成员推理，弥补了现有方法的不足。实验验证了模型拟合嵌入在放大条件损失差异方面的有效性，提供了可靠的审计能力，尽管摘要未提供具体数据，但强调了其优越性和竞争性，表明在无标注场景下实现了显著改进。",
      "conclusion": "论文的主要贡献是提出 MoFit 框架，成功实现无需标注的成员推理攻击，解决了实际场景中标注不可用的问题。这项研究增强了扩散模型隐私审计的实用性，为保护知识产权和隐私提供了新工具。学术价值在于扩展了 MIA 方法到更现实的条件，实际应用价值在于应对生成模型的潜在风险。未来工作可能包括扩展到其他模型类型或进一步优化嵌入提取过程，但摘要未明确说明具体局限性或细节方向。",
      "tags": [
        "Membership Inference Attacks",
        "Latent Diffusion Models",
        "Model-Fitted Embeddings",
        "Vision-Language Models",
        "Conditional Loss"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:10.760968Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22685",
    "title": "Switch-Hurdle: A MoE Encoder with AR Hurdle Decoder for Intermittent Demand Forecasting",
    "authors": [
      "Fabian Muşat",
      "Simona Căbuz"
    ],
    "abstract": "Intermittent demand, a pattern characterized by long sequences of zero sales punctuated by sporadic, non-zero values, poses a persistent challenge in retail and supply chain forecasting. Both traditional methods, such as ARIMA, exponential smoothing, or Croston variants, as well as modern neural architectures such as DeepAR and Transformer-based models often underperform on such data, as they treat demand as a single continuous process or become computationally expensive when scaled across many sparse series. To address these limitations, we introduce Switch-Hurdle: a new framework that integrates a Mixture-of-Experts (MoE) encoder with a Hurdle-based probabilistic decoder. The encoder uses a sparse Top-1 expert routing during the forward pass yet approximately dense in the backward pass via a straight-through estimator (STE). The decoder follows a cross-attention autoregressive design with a shared hurdle head that explicitly separates the forecasting task into two components: a binary classification component estimating the probability of a sale, and a conditional regression component, predicting the quantity given a sale. This structured separation enables the model to capture both occurrence and magnitude processes inherent to intermittent demand. Empirical results on the M5 benchmark and a large proprietary retail dataset show that Switch-Hurdle achieves state-of-the-art prediction performance while maintaining scalability.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22685.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22685",
    "published": "2026-02-26T07:03:19Z",
    "updated": "2026-02-26T07:03:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Switch-Hurdle框架，集成MoE编码器和AR Hurdle解码器，通过分离销售发生和数量预测提升间歇性需求预测的性能和可扩展性。",
      "motivation": "间歇性需求预测在零售和供应链中至关重要，其特征是长期零销售与零星非零值交织，导致传统方法如ARIMA、指数平滑和Croston变体以及现代神经网络如DeepAR和Transformer表现不佳。这些方法常将需求视为连续过程，无法有效处理稀疏序列，或计算成本高难以扩展，因此需要创新解决方案来捕捉间歇性模式的独特动态。",
      "method": "Switch-Hurdle框架结合Mixture-of-Experts（MoE）编码器和Hurdle-based概率解码器。编码器在前向传播中使用稀疏Top-1专家路由，通过直通估计器（STE）在后向传播中实现近似密集优化，以平衡效率与梯度流动。解码器采用交叉注意力自回归设计，共享hurdle头，将任务分解为二分类组件（估计销售概率）和条件回归组件（预测销售数量），从而结构化捕捉需求的发生和大小过程。",
      "result": "在M5基准和大型专有零售数据集上，Switch-Hurdle实现了最先进的预测性能，同时保持可扩展性。实验表明模型在准确率上有显著提升，相比传统方法和现代神经网络基线具有优势，摘要未明确说明具体数字，但强调了在效率和预测精度方面的改进，适应大规模稀疏时间序列数据。",
      "conclusion": "Switch-Hurdle的主要贡献在于创新集成MoE编码器和Hurdle解码器，有效解决间歇性需求预测难题。学术上推动了混合专家模型和概率建模的应用，实际价值体现在为零售和供应链提供高效预测工具。未来方向可包括扩展到更广泛稀疏序列领域或优化计算架构以增强实用性。",
      "tags": [
        "Mixture-of-Experts",
        "Hurdle Model",
        "Cross-Attention",
        "Autoregressive Modeling",
        "Intermittent Demand Forecasting"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:44.756016Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22683",
    "title": "SUPERGLASSES: Benchmarking Vision Language Models as Intelligent Agents for AI Smart Glasses",
    "authors": [
      "Zhuohang Jiang",
      "Xu Yuan",
      "Haohao Qu",
      "Shanru Lin",
      "Kanglong Liu",
      "Wenqi Fan",
      "Qing Li"
    ],
    "abstract": "The rapid advancement of AI-powered smart glasses, one of the hottest wearable devices, has unlocked new frontiers for multimodal interaction, with Visual Question Answering (VQA) over external knowledge sources emerging as a core application. Existing Vision Language Models (VLMs) adapted to smart glasses are typically trained and evaluated on traditional multimodal datasets; however, these datasets lack the variety and realism needed to reflect smart glasses usage scenarios and diverge from their specific challenges, where accurately identifying the object of interest must precede any external knowledge retrieval. To bridge this gap, we introduce SUPERGLASSES, the first comprehensive VQA benchmark built on real-world data entirely collected by smart glasses devices. SUPERGLASSES comprises 2,422 egocentric image-question pairs spanning 14 image domains and 8 query categories, enriched with full search trajectories and reasoning annotations. We evaluate 26 representative VLMs on this benchmark, revealing significant performance gaps. To address the limitations of existing models, we further propose SUPERLENS, a multimodal smart glasses agent that enables retrieval-augmented answer generation by integrating automatic object detection, query decoupling, and multimodal web search. Our agent achieves state-of-the-art performance, surpassing GPT-4o by 2.19 percent, and highlights the need for task-specific solutions in smart glasses VQA scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22683.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22683",
    "published": "2026-02-26T06:55:48Z",
    "updated": "2026-02-26T06:55:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出SUPERGLASSES基准和SUPERLENS代理，以提升智能眼镜中视觉语言模型的任务特定性能。",
      "motivation": "AI智能眼镜作为热门穿戴设备，其多模态交互中的视觉问答结合外部知识已成为核心应用。现有视觉语言模型通常依赖传统多模态数据集进行训练和评估，但这些数据集缺乏真实性和多样性，无法准确模拟智能眼镜的实际使用场景。特别是在智能眼镜场景中，必须先准确识别感兴趣对象才能进行外部知识检索，而现有方法忽略这一关键挑战。因此，迫切需要专门针对智能眼镜的基准和解决方案，以弥补这一研究空白并推动实际应用发展。",
      "method": "研究包括两方面：首先，构建SUPERGLASSES基准，这是首个完全由智能眼镜设备收集的真实世界视觉问答数据集，包含2,422个自我中心图像-问题对，覆盖14个图像域和8个查询类别，并附带完整的搜索轨迹和推理注释。其次，提出SUPERLENS代理，这是一种多模态智能眼镜智能代理，通过集成自动对象检测、查询解耦和多模态网络搜索技术，实现检索增强的答案生成。该方法的核心创新点在于利用真实数据创建针对性基准，并设计任务特定的代理架构以提升性能。",
      "result": "在SUPERGLASSES基准上评估了26个代表性视觉语言模型，结果显示存在显著性能差距，凸显现有模型在智能眼镜场景下的不足。提出的SUPERLENS代理取得了最先进性能，在基准测试中超越了GPT-4o，具体提升了2.19个百分点。这一对比表明，任务特定的解决方案能有效克服通用模型的局限性，验证了SUPERLENS在智能眼镜视觉问答任务中的优越性和实用性。",
      "conclusion": "论文的主要贡献是引入了SUPERGLASSES基准和SUPERLENS代理，填补了智能眼镜视觉问答领域的研究空白。学术价值在于提供了标准评估平台，促进了任务特定模型的发展；实际应用价值则体现在提升智能眼镜的交互体验和智能化水平。未来工作可能包括扩展数据集规模、优化代理架构以适应更多场景，或探索更高效的多模态集成方法。摘要未明确说明具体局限性，但可以推断需要更广泛的真实数据收集和跨领域测试。",
      "tags": [
        "Vision Language Models",
        "Visual Question Answering",
        "Benchmarking",
        "Smart Glasses",
        "Retrieval-Augmented Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:37.582212Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22681",
    "title": "Accelerating LLM Pre-Training through Flat-Direction Dynamics Enhancement",
    "authors": [
      "Shuchen Zhu",
      "Rizhen Hu",
      "Mingze Wang",
      "Mou Sun",
      "Xue Wang",
      "Kun Yuan",
      "Zaiwen Wen"
    ],
    "abstract": "Pre-training Large Language Models requires immense computational resources, making optimizer efficiency essential. The optimization landscape is highly anisotropic, with loss reduction driven predominantly by progress along flat directions. While matrix-based optimizers such as Muon and SOAP leverage fine-grained curvature information to outperform AdamW, their updates tend toward isotropy -- relatively conservative along flat directions yet potentially aggressive along sharp ones. To address this limitation, we first establish a unified Riemannian Ordinary Differential Equation (ODE) framework that elucidates how common adaptive algorithms operate synergistically: the preconditioner induces a Riemannian geometry that mitigates ill-conditioning, while momentum serves as a Riemannian damping term that promotes convergence. Guided by these insights, we propose LITE, a generalized acceleration strategy that enhances training dynamics by applying larger Hessian damping coefficients and learning rates along flat trajectories. Extensive experiments demonstrate that LITE significantly accelerates both Muon and SOAP across diverse architectures (Dense, MoE), parameter scales (130M--1.3B), datasets (C4, Pile), and learning-rate schedules (cosine, warmup-stable-decay). Theoretical analysis confirms that LITE facilitates faster convergence along flat directions in anisotropic landscapes, providing a principled approach to efficient LLM pre-training. The code is available at https://github.com/SHUCHENZHU/LITE.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22681.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22681",
    "published": "2026-02-26T06:54:57Z",
    "updated": "2026-02-26T06:54:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出LITE方法，通过增强平坦方向的训练动态，显著加速大型语言模型的预训练。",
      "motivation": "论文针对大型语言模型预训练中计算资源消耗巨大的问题，优化器效率至关重要。现有矩阵基优化器如Muon和SOAP虽利用细粒度曲率信息优于AdamW，但其更新趋于各向同性，导致在平坦方向保守、尖锐方向激进，限制了效率提升。因此，需改进优化策略以更好地处理非各向同性的优化地形，从而加速预训练。",
      "method": "论文首先建立统一的黎曼常微分方程框架，阐明自适应算法中预处理器诱导黎曼几何减轻病态条件，动量作为阻尼项促进收敛。基于此，提出LITE策略，通过在平坦方向上应用更大的Hessian阻尼系数和学习率来增强训练动态。该方法针对非各向同性优化地形，提升平坦方向的收敛速度，适用于多种预训练设置。",
      "result": "实验显示LITE在多种设置下显著加速Muon和SOAP优化器的预训练，包括密集和混合专家架构、参数规模从130M到1.3B、数据集如C4和Pile，以及不同学习率计划。理论分析证实LITE在非各向同性地形中促进平坦方向的更快收敛，提供了高效预训练的原则性方法。",
      "conclusion": "论文的主要贡献在于提出LITE方法，通过增强平坦方向的训练动态来加速大型语言模型预训练，并建立统一黎曼框架解释优化器机制，具有重要学术价值和实际应用意义，能显著减少计算资源消耗。未来工作可能包括扩展到更大模型或其他优化场景，但摘要未明确说明具体局限。",
      "tags": [
        "Large Language Model",
        "Optimization",
        "Riemannian ODE",
        "Hessian Damping",
        "Pre-training Acceleration"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:27.312002Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22680",
    "title": "Toward Personalized LLM-Powered Agents: Foundations, Evaluation, and Future Directions",
    "authors": [
      "Yue Xu",
      "Qian Chen",
      "Zizhan Ma",
      "Dongrui Liu",
      "Wenxuan Wang",
      "Xiting Wang",
      "Li Xiong",
      "Wenjie Wang"
    ],
    "abstract": "Large language models have enabled agents that reason, plan, and interact with tools and environments to accomplish complex tasks. As these agents operate over extended interaction horizons, their effectiveness increasingly depends on adapting behavior to individual users and maintaining continuity across time, giving rise to personalized LLM-powered agents. In such long-term, user-dependent settings, personalization permeates the entire decision pipeline rather than remaining confined to surface-level generation. This survey provides a capability-oriented review of personalized LLM-powered agents. We organize the literature around four interdependent components: profile modeling, memory, planning, and action execution. Using this taxonomy, we synthesize representative methods and analyze how user signals are represented, propagated, and utilized, highlighting cross-component interactions and recurring design trade-offs. We further examine evaluation metrics and benchmarks tailored to personalized agents, summarize application scenarios spanning general assistance to specialized domains, and outline future directions for research and deployment. By offering a structured framework for understanding and designing personalized LLM-powered agents, this survey charts a roadmap toward more user-aligned, adaptive, robust, and deployable agentic systems, accelerating progress from prototype personalization to scalable real-world assistants.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22680.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22680",
    "published": "2026-02-26T06:52:47Z",
    "updated": "2026-02-26T06:52:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "本综述论文的核心贡献是提出一个能力导向的结构化框架，用于理解和设计个性化大型语言模型驱动的代理。",
      "motivation": "随着大型语言模型驱动的代理在复杂任务中广泛应用，长期互动下其效果日益依赖于适应个体用户和保持行为连续性，这凸显了个人化的必要性。当前方法往往局限于表层生成，未能将个性化整合到整个决策管道中，导致代理在用户对齐和适应性方面存在不足。因此，本研究旨在系统性探索个性化LLM代理的机制，以提升其在现实世界中的有效性和可部署性，解决现有研究的分散性和不完整性。",
      "method": "论文采用综述研究方法，以能力导向将文献组织成四个相互依赖的组件：个人资料建模、记忆、规划和行动执行。通过这一分类法，论文综合分析了代表性方法，探讨用户信号如何被表示、传播和利用，突出组件间的交互和常见设计折衷。关键创新在于提供了一个统一框架，促进了对个性化代理设计的系统性理解，虽然摘要未明确提及具体数据集或模型架构，但强调基于现有研究进行综合分析的技术路线。",
      "result": "作为综述论文，摘要未包含具体的实验数据或性能指标。论文探讨了针对个性化代理的评估指标和基准，并总结了从通用援助到专业领域的应用场景，但未提供如准确率提升或效率改进的量化结果，也未与基线方法进行详细对比。因此，摘要未明确说明主要实验结果，而是侧重于理论分析和框架构建。",
      "conclusion": "本综述通过提供一个结构化框架，推动个性化LLM代理的设计和部署，具有促进用户对齐、自适应、鲁棒和可部署代理系统发展的学术价值，并加速从原型到可扩展现实世界助手的实际应用。未来研究方向包括优化代理的个性化机制，提升在不同场景下的适应性，以及解决部署中的挑战如数据隐私和计算效率，从而为领域研究奠定基础。",
      "tags": [
        "Large Language Model",
        "Personalized Agents",
        "Profile Modeling",
        "Memory Management",
        "Planning"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:35.592521Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22678",
    "title": "ViCLIP-OT: The First Foundation Vision-Language Model for Vietnamese Image-Text Retrieval with Optimal Transport",
    "authors": [
      "Quoc-Khang Tran",
      "Minh-Thien Nguyen",
      "Nguyen-Khang Pham"
    ],
    "abstract": "Image-text retrieval has become a fundamental component in intelligent multimedia systems; however, most existing vision-language models are optimized for highresource languages and remain suboptimal for low-resource settings such as Vietnamese. This work introduces ViCLIP-OT, a foundation vision-language model specifically designed for Vietnamese image-text retrieval. The proposed framework integrates CLIP-style contrastive learning with a Similarity-Graph Regularized Optimal Transport (SIGROT) loss to enhance global cross-modal consistency and mitigate modality gap issues. Extensive experiments on three Vietnamese benchmarks (UITOpenViIC, KTVIC, and Crossmodal-3600) demonstrate that ViCLIP-OT consistently outperforms CLIP and SigLIP baselines in both in-domain and zero-shot settings. On UIT-OpenViIC, the model achieves an average Recall@K of 67.34%, improving upon CLIP by 5.75 percentage points. In zero-shot evaluation on Crossmodal-3600, ViCLIPOT surpasses CLIP by 11.72 percentage points. Embedding-space analysis further confirms improved alignment and reduced modality gap. The results indicate that integrating SIGROT provides an effective and scalable strategy for cross-modal retrieval in low-resource languages, offering practical implications for intelligent multimedia retrieval systems in Vietnamese and other underrepresented linguistic contexts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22678.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22678",
    "published": "2026-02-26T06:51:25Z",
    "updated": "2026-02-26T06:51:25Z",
    "comment": "Preprint submitted to Expert Systems with Applications",
    "light_analysis": {
      "overview": "ViCLIP-OT是首个针对越南语图像-文本检索的基础视觉-语言模型，通过集成最优传输损失提升跨模态对齐性能，填补低资源语言研究的空白。",
      "motivation": "研究动机源于现有视觉-语言模型主要为高资源语言如英语优化，对低资源语言如越南语的图像-文本检索任务表现不佳。随着智能多媒体系统发展，支持多语言尤其是欠代表性语言对促进语言多样性和应用公平至关重要。现有方法在低资源语言上常面临模态差距大、跨模态一致性差等问题，导致检索性能受限，这突出了开发专用模型的必要性和紧迫性。",
      "method": "论文提出ViCLIP-OT框架，结合CLIP风格的对比学习方法与相似图正则化最优传输（SIGROT）损失。CLIP对比学习用于对齐视觉和文本表示，而SIGROT损失通过优化传输矩阵增强全局跨模态一致性，减少模态差距。模型在多个越南语数据集（如UIT-OpenViIC）上训练，SIGROT的核心创新在于引入相似性图约束，改善跨模态对齐，从而提升检索性能。",
      "result": "实验在三个越南语基准测试（UIT-OpenViIC、KTVIC和Crossmodal-3600）上进行，ViCLIP-OT在域内和零样本设置下均优于CLIP和SigLIP基线。在UIT-OpenViIC上，模型平均Recall@K达到67.34%，比CLIP提升5.75个百分点。零样本评估中，在Crossmodal-3600上提升11.72个百分点。嵌入空间分析进一步确认了视觉-文本对齐改善和模态差距减少，验证了SIGROT损失的有效性。",
      "conclusion": "论文的主要贡献是提出了首个针对越南语图像-文本检索的基础视觉-语言模型ViCLIP-OT，并整合了SIGROT损失以提升性能。学术上，为低资源语言的跨模态检索提供了有效的技术路径，促进了多语言AI模型研究。实际应用中，模型适用于越南语智能多媒体检索系统，并可扩展至其他欠代表性语言。未来工作可进一步优化模型支持更多语言或探索其他正则化方法。",
      "tags": [
        "Vision-Language Model",
        "Contrastive Learning",
        "Optimal Transport",
        "Low-Resource Language",
        "Image-Text Retrieval"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:53.070960Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22675",
    "title": "Search More, Think Less: Rethinking Long-Horizon Agentic Search for Efficiency and Generalization",
    "authors": [
      "Qianben Chen",
      "Tianrui Qin",
      "King Zhu",
      "Qiexiang Wang",
      "Chengjun Yu",
      "Shu Xu",
      "Jiaqi Wu",
      "Jiayu Zhang",
      "Xinpeng Liu",
      "Xin Gui",
      "Jingyi Cao",
      "Piaohong Wang",
      "Dingfeng Shi",
      "He Zhu",
      "Tiannan Wang",
      "Yuqing Wang",
      "Maojia Song",
      "Tianyu Zheng",
      "Ge Zhang",
      "Jian Yang",
      "Jiaheng Liu",
      "Minghao Liu",
      "Yuchen Eleanor Jiang",
      "Wangchunshu Zhou"
    ],
    "abstract": "Recent deep research agents primarily improve performance by scaling reasoning depth, but this leads to high inference cost and latency in search-intensive scenarios. Moreover, generalization across heterogeneous research settings remains challenging. In this work, we propose \\emph{Search More, Think Less} (SMTL), a framework for long-horizon agentic search that targets both efficiency and generalization. SMTL replaces sequential reasoning with parallel evidence acquisition, enabling efficient context management under constrained context budgets. To support generalization across task types, we further introduce a unified data synthesis pipeline that constructs search tasks spanning both deterministic question answering and open-ended research scenarios with task appropriate evaluation metrics. We train an end-to-end agent using supervised fine-tuning and reinforcement learning, achieving strong and often state of the art performance across benchmarks including BrowseComp (48.6\\%), GAIA (75.7\\%), Xbench (82.0\\%), and DeepResearch Bench (45.9\\%). Compared to Mirothinker-v1.0, SMTL with maximum 100 interaction steps reduces the average number of reasoning steps on BrowseComp by 70.7\\%, while improving accuracy.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22675.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22675",
    "published": "2026-02-26T06:46:41Z",
    "updated": "2026-02-26T06:46:41Z",
    "comment": "12 pages, 5 figures",
    "light_analysis": {
      "overview": "SMTL框架通过并行证据获取和统一数据合成，提升了长视界代理搜索的效率和泛化能力。",
      "motivation": "当前深度研究智能体主要通过扩展推理深度来提高性能，但这在搜索密集型场景中导致高推理成本和延迟，限制了实际部署效率。此外，现有方法难以泛化到异构研究设置，如从确定性问答到开放式研究任务，这阻碍了智能体的适应性和广泛应用。因此，迫切需要一种新方法来解决效率和泛化问题，以应对不同任务类型和资源约束下的挑战。",
      "method": "SMTL框架采用并行证据获取替代传统顺序推理，在有限上下文预算下实现高效上下文管理，以减少推理步骤。关键创新包括引入统一数据合成管道，该管道构建涵盖确定性问答和开放式研究场景的搜索任务，并配备任务适当的评估指标，以支持跨任务泛化。训练过程结合了监督微调和强化学习，以端到端方式优化智能体，确保模型能适应不同搜索环境。",
      "result": "SMTL在多个基准上取得了优秀性能，包括BrowseComp（48.6%准确率）、GAIA（75.7%）、Xbench（82.0%）和DeepResearch Bench（45.9%）。与基线方法Mirothinker-v1.0相比，在最大100个交互步骤下，SMTL将BrowseComp上的平均推理步骤减少了70.7%，同时提高了准确性。这表明SMTL在保持高性能的同时显著提升了效率，验证了其在搜索任务中的优势。",
      "conclusion": "SMTL框架通过并行证据获取和统一数据合成，有效解决了长视界代理搜索的效率和泛化问题，在多个基准上达到领先水平。该研究学术上推进了代理搜索方法的创新，实际应用中可能降低推理成本并增强跨任务适应性。摘要未明确说明局限性，但未来工作可能包括优化并行策略或扩展数据合成范围，以进一步提升模型性能。",
      "tags": [
        "Agentic Search",
        "Parallel Evidence Acquisition",
        "Data Synthesis",
        "Supervised Fine-Tuning",
        "Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:54.672079Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22674",
    "title": "SPMamba-YOLO: An Underwater Object Detection Network Based on Multi-Scale Feature Enhancement and Global Context Modeling",
    "authors": [
      "Guanghao Liao",
      "Zhen Liu",
      "Liyuan Cao",
      "Yonghui Yang",
      "Qi Li"
    ],
    "abstract": "Underwater object detection is a critical yet challenging research problem owing to severe light attenuation, color distortion, background clutter, and the small scale of underwater targets. To address these challenges, we propose SPMamba-YOLO, a novel underwater object detection network that integrates multi-scale feature enhancement with global context modeling. Specifically, a Spatial Pyramid Pooling Enhanced Layer Aggregation Network (SPPELAN) module is introduced to strengthen multi-scale feature aggregation and expand the receptive field, while a Pyramid Split Attention (PSA) mechanism enhances feature discrimination by emphasizing informative regions and suppressing background interference. In addition, a Mamba-based state space modeling module is incorporated to efficiently capture long-range dependencies and global contextual information, thereby improving detection robustness in complex underwater environments. Extensive experiments on the URPC2022 dataset demonstrate that SPMamba-YOLO outperforms the YOLOv8n baseline by more than 4.9\\% in mAP@0.5, particularly for small and densely distributed underwater objects, while maintaining a favorable balance between detection accuracy and computational cost.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22674.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22674",
    "published": "2026-02-26T06:45:11Z",
    "updated": "2026-02-26T06:45:11Z",
    "comment": "31 pages, 10 figures, 6 tables. This paper presents SPMamba-YOLO, an underwater object detection framework integrating multi-scale feature enhancement and global context modeling. The work is under review",
    "light_analysis": {
      "overview": "SPMamba-YOLO通过集成多尺度特征增强和全局上下文建模，提出了一种创新的水下目标检测网络，显著提升检测精度。",
      "motivation": "水下目标检测因光衰减、颜色失真、背景杂乱和目标小等挑战而复杂化，现有方法可能在这些极端条件下表现不足，导致检测准确率低。本研究旨在解决这些问题，通过增强特征表示和全局建模来提高鲁棒性，对海洋监测、资源探索等应用具有重要意义。",
      "method": "SPMamba-YOLO结合了三个关键模块：SPPELAN模块用于多尺度特征聚合和扩展感受野；PSA机制通过注意力增强信息区域并抑制背景干扰；基于Mamba的状态空间建模模块捕获长距离依赖和全局上下文。网络在URPC2022数据集上训练，优化了检测精度与计算效率的平衡。",
      "result": "在URPC2022数据集上的实验表明，SPMamba-YOLO在mAP@0.5指标上相比YOLOv8n基线提升了超过4.9%，尤其在小目标和密集分布目标上表现优异，同时保持了检测精度与计算成本的平衡，验证了其在复杂水下环境中的有效性。",
      "conclusion": "SPMamba-YOLO通过创新模块集成，显著提高了水下目标检测的性能和鲁棒性，为海洋研究和实际应用提供了有力工具。其学术价值在于结合了多尺度特征和全局建模，未来可扩展到其他视觉任务或优化计算开销。",
      "tags": [
        "Underwater Object Detection",
        "Multi-Scale Feature Enhancement",
        "Global Context Modeling",
        "State Space Models",
        "YOLO Architecture"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:52.287895Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22673",
    "title": "Forecasting Antimicrobial Resistance Trends Using Machine Learning on WHO GLASS Surveillance Data: A Retrieval-Augmented Generation Approach for Policy Decision Support",
    "authors": [
      "Md Tanvir Hasan Turja"
    ],
    "abstract": "Antimicrobial resistance (AMR) is a growing global crisis projected to cause 10 million deaths per year by 2050. While the WHO Global Antimicrobial Resistance and Use Surveillance System (GLASS) provides standardized surveillance data across 44 countries, few studies have applied machine learning to forecast population-level resistance trends from this data. This paper presents a two-component framework for AMR trend forecasting and evidence-grounded policy decision support. We benchmark six models -- Naive, Linear Regression, Ridge Regression, XGBoost, LightGBM, and LSTM -- on 5,909 WHO GLASS observations across six WHO regions (2021-2023). XGBoost achieved the best performance with a test MAE of 7.07% and R-squared of 0.854, outperforming the naive baseline by 83.1%. Feature importance analysis identified the prior-year resistance rate as the dominant predictor (50.5% importance), while regional MAE ranged from 4.16% (European Region) to 10.14% (South-East Asia Region). We additionally implemented a Retrieval-Augmented Generation (RAG) pipeline combining a ChromaDB vector store of WHO policy documents with a locally deployed Phi-3 Mini language model, producing source-attributed, hallucination-constrained policy answers. Code and data are available at https://github.com/TanvirTurja",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22673.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22673",
    "published": "2026-02-26T06:45:08Z",
    "updated": "2026-02-26T06:45:08Z",
    "comment": "18 pages, 4 figures, code and data available at https://github.com/TanvirTurja",
    "light_analysis": {
      "overview": "论文提出了一个结合机器学习预测模型和检索增强生成技术的框架，用于准确预测抗菌药物耐药性趋势并支持证据基础的政策决策。",
      "motivation": "抗菌药物耐药性（AMR）是全球性的公共卫生危机，预计到2050年每年将导致1000万人死亡，因此急需有效的预测和干预策略。世界卫生组织全球抗菌药物耐药性和使用监测系统（GLASS）提供了覆盖44个国家的标准化数据，然而目前很少有研究应用机器学习从这些数据中预测人口层面的耐药趋势。这一问题的重要性在于，准确的预测可以指导政策制定，优化资源分配，以应对日益严重的AMR威胁，现有方法的不足主要体现在缺乏先进预测技术的应用，导致决策支持不足。",
      "method": "论文采用一个两组件框架，包括AMR趋势预测和政策决策支持。在预测部分，基准测试了六种模型（Naive、线性回归、岭回归、XGBoost、LightGBM、LSTM），使用WHO GLASS的5,909个观察数据，覆盖六个WHO区域（2021-2023）。关键创新是结合XGBoost进行最优预测，并实现一个检索增强生成（RAG）管道，该管道使用ChromaDB向量存储WHO政策文档，与本地部署的Phi-3 Mini语言模型集成，以生成有来源、减少幻觉的政策答案。",
      "result": "实验结果显示，XGBoost模型在测试集上取得了最佳性能，平均绝对误差（MAE）为7.07%，决定系数（R-squared）为0.854，相比朴素基线提升了83.1%。特征重要性分析表明，前一年的耐药率是最重要的预测因子，占50.5%的重要性。区域性能差异明显，MAE从欧洲区域的4.16%到东南亚区域的10.14%。此外，RAG管道成功生成了基于证据的政策建议，有效约束了幻觉。",
      "conclusion": "本研究的核心贡献是开发了一个综合框架，显著提高了AMR趋势的预测准确性，并整合了RAG技术为政策决策提供支持。这为机器学习在公共卫生监测中的应用提供了新思路，具有重要学术价值。实际应用中，该框架可帮助决策者制定基于数据的干预措施。代码和数据已公开，促进进一步研究。未来工作可能包括扩展到更多区域或优化模型，但摘要未明确说明具体方向。",
      "tags": [
        "XGBoost",
        "LightGBM",
        "LSTM",
        "Retrieval-Augmented Generation",
        "WHO GLASS"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:08.049928Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22667",
    "title": "Monocular Open Vocabulary Occupancy Prediction for Indoor Scenes",
    "authors": [
      "Changqing Zhou",
      "Yueru Luo",
      "Han Zhang",
      "Zeyu Jiang",
      "Changhao Chen"
    ],
    "abstract": "Open-vocabulary 3D occupancy is vital for embodied agents, which need to understand complex indoor environments where semantic categories are abundant and evolve beyond fixed taxonomies. While recent work has explored open-vocabulary occupancy in outdoor driving scenarios, such methods transfer poorly indoors, where geometry is denser, layouts are more intricate, and semantics are far more fine-grained. To address these challenges, we adopt a geometry-only supervision paradigm that uses only binary occupancy labels (occupied vs free). Our framework builds upon 3D Language-Embedded Gaussians, which serve as a unified intermediate representation coupling fine-grained 3D geometry with a language-aligned semantic embedding. On the geometry side, we find that existing Gaussian-to-Occupancy operators fail to converge under such weak supervision, and we introduce an opacity-aware, Poisson-based approach that stabilizes volumetric aggregation. On the semantic side, direct alignment between rendered features and open-vocabulary segmentation features suffers from feature mixing; we therefore propose a Progressive Temperature Decay schedule that gradually sharpens opacities during splatting, strengthening Gaussian-language alignment. On Occ-ScanNet, our framework achieves 59.50 IoU and 21.05 mIoU in the open-vocabulary setting, surpassing all existing occupancy methods in IoU and outperforming prior open-vocabulary approaches by a large margin in mIoU. Code will be released at https://github.com/JuIvyy/LegoOcc.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22667.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22667",
    "published": "2026-02-26T06:37:43Z",
    "updated": "2026-02-26T06:37:43Z",
    "comment": "Accepted by CVPR2026",
    "light_analysis": {
      "overview": "提出一个用于室内场景的单目开放词汇占用预测框架，通过几何监督和语言对齐方法，显著提升性能。",
      "motivation": "开放词汇3D占用对具身智能体至关重要，使它们能理解不断演变的语义类别，但现有方法主要针对户外驾驶场景。在室内环境中，几何更密集、布局更复杂、语义更细粒度，导致现有方法转移效果不佳，限制了智能体的部署能力。因此，需要开发专门针对室内的开放词汇占用预测方法来解决这些挑战，以提升环境理解能力。",
      "method": "该方法采用几何监督范式，仅使用二进制占用标签（占用与空闲），框架基于3D语言嵌入高斯作为统一中间表示，结合细粒度3D几何和语言对齐语义嵌入。在几何方面，引入不透明度感知、泊松基础的方法来稳定体积聚合；在语义方面，提出渐进温度衰减计划，通过逐渐锐化不透明度来增强高斯-语言对齐，克服特征混合问题，提升模型收敛性和语义准确性。",
      "result": "在Occ-ScanNet数据集上的开放词汇设置中，该框架达到59.50 IoU和21.05 mIoU，在IoU指标上超越所有现有占用预测方法，在mIoU上大幅优于先前开放词汇方法，表明几何和语义性能均有显著提升。这些结果验证了所提方法的有效性，通过具体数据展示了其在室内场景中的优越表现。",
      "conclusion": "该研究的主要贡献是提出并验证了一个室内单目开放词汇占用预测框架，通过创新的几何聚合和语义对齐方法解决了现有方法的局限性，提升了具身智能体在复杂环境中的感知能力，具有重要的学术和实际应用价值。局限性或未来工作方向摘要未明确说明，但可能包括扩展到更多场景或优化实时性。",
      "tags": [
        "Open Vocabulary 3D Occupancy",
        "3D Language-Embedded Gaussians",
        "Opacity-Aware Poisson Aggregation",
        "Progressive Temperature Decay",
        "Monocular Occupancy Prediction"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:08.435291Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22666",
    "title": "ArtPro: Self-Supervised Articulated Object Reconstruction with Adaptive Integration of Mobility Proposals",
    "authors": [
      "Xuelu Li",
      "Zhaonan Wang",
      "Xiaogang Wang",
      "Lei Wu",
      "Manyi Li",
      "Changhe Tu"
    ],
    "abstract": "Reconstructing articulated objects into high-fidelity digital twins is crucial for applications such as robotic manipulation and interactive simulation. Recent self-supervised methods using differentiable rendering frameworks like 3D Gaussian Splatting remain highly sensitive to the initial part segmentation. Their reliance on heuristic clustering or pre-trained models often causes optimization to converge to local minima, especially for complex multi-part objects. To address these limitations, we propose ArtPro, a novel self-supervised framework that introduces adaptive integration of mobility proposals. Our approach begins with an over-segmentation initialization guided by geometry features and motion priors, generating part proposals with plausible motion hypotheses. During optimization, we dynamically merge these proposals by analyzing motion consistency among spatial neighbors, while a collision-aware motion pruning mechanism prevents erroneous kinematic estimation. Extensive experiments on both synthetic and real-world objects demonstrate that ArtPro achieves robust reconstruction of complex multi-part objects, significantly outperforming existing methods in accuracy and stability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22666.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22666",
    "published": "2026-02-26T06:35:23Z",
    "updated": "2026-02-26T06:35:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "ArtPro 提出一种自适应集成运动提案的自监督框架，以稳健重建复杂铰接式对象，显著提升重建的准确性和稳定性。",
      "motivation": "铰接式对象的高保真重建对机器人操作和交互模拟等应用至关重要。然而，现有自监督方法使用如 3D Gaussian Splatting 的可微分渲染框架，高度依赖初始部分分割，常采用启发式聚类或预训练模型，导致优化过程易收敛到局部最小值，特别是在处理复杂多部分对象时。这限制了重建的准确性和鲁棒性，亟待解决。",
      "method": "ArtPro 框架基于自监督学习，首先通过几何特征和运动先验指导的过分割初始化生成多个部分提案，每个提案附带可信的运动假设。优化过程中，通过分析空间邻居间的运动一致性动态合并提案，同时采用碰撞感知机制修剪错误的运动估计。该方法不依赖外部预训练模型，利用可微分渲染技术实现端到端优化。",
      "result": "在合成和现实世界对象的广泛实验中，ArtPro 成功重建了复杂多部分铰接式对象。与现有方法相比，它在准确性和稳定性方面均显著优于传统技术，有效避免了由初始化问题导致的优化失败。摘要未明确说明具体性能指标数值，但强调了其在鲁棒性上的优越表现。",
      "conclusion": "ArtPro 通过自适应集成运动提案解决了自监督铰接式对象重建中的初始化依赖和优化难题。这项研究为高保真数字孪生构建提供了创新方案，在计算机视觉和机器人学领域具有重要学术价值和实际应用潜力。未来工作可探索更高效的算法扩展或应用到更多样化的场景中。",
      "tags": [
        "Self-Supervised Learning",
        "Articulated Object Reconstruction",
        "Differentiable Rendering",
        "3D Gaussian Splatting",
        "Motion Consistency"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:20.377211Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22661",
    "title": "dLLM: Simple Diffusion Language Modeling",
    "authors": [
      "Zhanhui Zhou",
      "Lingjie Chen",
      "Hanghang Tong",
      "Dawn Song"
    ],
    "abstract": "Although diffusion language models (DLMs) are evolving quickly, many recent models converge on a set of shared components. These components, however, are distributed across ad-hoc research codebases or lack transparent implementations, making them difficult to reproduce or extend. As the field accelerates, there is a clear need for a unified framework that standardizes these common components while remaining flexible enough to support new methods and architectures.   To address this gap, we introduce dLLM, an open-source framework that unifies the core components of diffusion language modeling -- training, inference, and evaluation -- and makes them easy to customize for new designs. With dLLM, users can reproduce, finetune, deploy, and evaluate open-source large DLMs such as LLaDA and Dream through a standardized pipeline. The framework also provides minimal, reproducible recipes for building small DLMs from scratch with accessible compute, including converting any BERT-style encoder or autoregressive LM into a DLM. We also release the checkpoints of these small DLMs to make DLMs more accessible and accelerate future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22661.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22661",
    "published": "2026-02-26T06:26:02Z",
    "updated": "2026-02-26T06:26:02Z",
    "comment": "Code available at: https://github.com/ZHZisZZ/dllm",
    "light_analysis": {
      "overview": "本文提出了 dLLM，一个开源框架，统一了扩散语言模型的训练、推理和评估组件，使其易于定制和扩展。",
      "motivation": "扩散语言模型（DLMs）快速发展，但核心组件分散在随意代码库或缺乏透明实现，导致难以重现、复现和扩展。现有代码不统一，阻碍了领域进展，因为研究人员需要花费大量时间处理不兼容的代码和工具。因此，迫切需要标准化框架，促进组件共享和灵活性，以支持新方法的发展，并提高研究可重现性。摘要未明确说明具体应用问题，但强调了统一框架对加速 AI 研究的重要性。",
      "method": "dLLM 框架统一了扩散语言建模的核心环节，包括训练、推理和评估，通过标准化管道实现。关键创新在于提供易于定制的接口，允许用户灵活设计新方法。框架支持重现、微调和部署开源大 DLMs（如 LLaDA 和 Dream），并提供最小化、可重现的配方，从零构建小 DLMs。此外，它能将 BERT-style 编码器或自回归语言模型转换为 DLM，便于资源受限的研究。摘要未明确说明具体数据集或详细模型架构。",
      "result": "dLLM 框架通过标准化工具链，使用户能够更方便地重现和评估 DLMs，提升了实验复现性。框架释放的小 DLMs 检查点增强了可访问性，预期加速未来研究。摘要未提供具体性能数据如准确率提升，但强调了资源共享和标准化带来的效率改进，如更快的模型开发和部署。与现有方法的对比主要是通过简化流程，而非直接性能比较。",
      "conclusion": "dLLM 框架的主要贡献在于标准化扩散语言模型组件，提高了研究效率和可访问性。学术价值是促进领域内代码统一和可重现性；实际应用价值包括简化模型开发和部署。局限性方面，摘要未明确说明；未来工作可能涉及扩展框架以支持更多模型类型或优化性能，进一步降低计算门槛。",
      "tags": [
        "Diffusion Language Model",
        "Unified Framework",
        "BERT-style Encoder",
        "Autoregressive Language Model",
        "Training Pipeline"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:23.398265Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22660",
    "title": "LEDA: Latent Semantic Distribution Alignment for Multi-domain Graph Pre-training",
    "authors": [
      "Lianze Shan",
      "Jitao Zhao",
      "Dongxiao He",
      "Siqi Liu",
      "Jiaxu Cui",
      "Weixiong Zhang"
    ],
    "abstract": "Recent advances in generic large models, such as GPT and DeepSeek, have motivated the introduction of universality to graph pre-training, aiming to learn rich and generalizable knowledge across diverse domains using graph representations to improve performance in various downstream applications. However, most existing methods face challenges in learning effective knowledge from generic graphs, primarily due to simplistic data alignment and limited training guidance. The issue of simplistic data alignment arises from the use of a straightforward unification for highly diverse graph data, which fails to align semantics and misleads pre-training models. The problem with limited training guidance lies in the arbitrary application of in-domain pre-training paradigms to cross-domain scenarios. While it is effective in enhancing discriminative representation in one data space, it struggles to capture effective knowledge from many graphs. To address these challenges, we propose a novel Latent sEmantic Distribution Alignment (LEDA) model for universal graph pre-training. Specifically, we first introduce a dimension projection unit to adaptively align diverse domain features into a shared semantic space with minimal information loss. Furthermore, we design a variational semantic inference module to obtain the shared latent distribution. The distribution is then adopted to guide the domain projection, aligning it with shared semantics across domains and ensuring cross-domain semantic learning. LEDA exhibits strong performance across a broad range of graphs and downstream tasks. Remarkably, in few-shot cross-domain settings, it significantly outperforms in-domain baselines and advanced universal pre-training models.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22660.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22660",
    "published": "2026-02-26T06:18:14Z",
    "updated": "2026-02-26T06:18:14Z",
    "comment": "Accepted by WWW-26, 12 pages, 2 figures",
    "light_analysis": {
      "overview": "LEDA模型通过潜语义分布对齐技术解决多域图预训练中的语义对齐和训练指导不足问题，提升了跨域知识学习能力。",
      "motivation": "随着通用大模型（如GPT和DeepSeek）的兴起，图预训练领域开始追求通用性，以学习跨域的通用知识来提升下游任务性能。然而，现有方法面临两大挑战：一是数据对齐过于简单，仅通过统一化处理多样图数据，导致语义未对齐并误导预训练模型；二是训练指导不足，将域内预训练范式直接应用于跨域场景，难以从多个图中捕获有效知识。这些限制了图预训练在跨域应用中的效果，凸显了改进的必要性。",
      "method": "LEDA模型的核心技术包括维度投影单元和变分语义推理模块。维度投影单元自适应地将多样域图特征对齐到共享语义空间，最小化信息损失；变分语义推理模块则用于推断共享潜分布，该分布进一步指导域投影过程，确保跨域语义对齐。通过这种结合自适应投影和变分推理的方法，LEDA实现了潜语义分布对齐，优化了跨域预训练的学习能力。模型架构针对通用图预训练设计，强调语义对齐和分布指导。",
      "result": "LEDA模型在广泛的图数据集和下游任务中表现出强大性能。在少样本跨域设置下，它显著优于域内基准模型和先进的通用预训练模型，验证了其在跨域学习中的有效性。摘要未提供具体数据，但强调了其在多种场景下的优越表现，展示了改进对齐和指导机制的正面效果。",
      "conclusion": "LEDA模型通过潜语义分布对齐成功解决了多域图预训练中的关键挑战，提升了跨域知识学习能力。该研究为通用图预训练提供了创新方法，具有重要的学术价值，有助于推动图表示学习的发展；实际应用价值在于改进下游任务的性能。未来工作可探索模型在更复杂图结构或其他领域的扩展，以及进一步优化对齐机制。",
      "tags": [
        "Graph Pre-training",
        "Latent Semantic Alignment",
        "Multi-domain Learning",
        "Variational Inference",
        "Cross-domain Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:34.334113Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22659",
    "title": "Scaling Audio-Visual Quality Assessment Dataset via Crowdsourcing",
    "authors": [
      "Renyu Yang",
      "Jian Jin",
      "Lili Meng",
      "Meiqin Liu",
      "Yilin Wang",
      "Balu Adsumilli",
      "Weisi Lin"
    ],
    "abstract": "Audio-visual quality assessment (AVQA) research has been stalled by limitations of existing datasets: they are typically small in scale, with insufficient diversity in content and quality, and annotated only with overall scores. These shortcomings provide limited support for model development and multimodal perception research. We propose a practical approach for AVQA dataset construction. First, we design a crowdsourced subjective experiment framework for AVQA, breaks the constraints of in-lab settings and achieves reliable annotation across varied environments. Second, a systematic data preparation strategy is further employed to ensure broad coverage of both quality levels and semantic scenarios. Third, we extend the dataset with additional annotations, enabling research on multimodal perception mechanisms and their relation to content. Finally, we validate this approach through YT-NTU-AVQ, the largest and most diverse AVQA dataset to date, consisting of 1,620 user-generated audio and video (A/V) sequences. The dataset and platform code are available at https://github.com/renyu12/YT-NTU-AVQ",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22659.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22659",
    "published": "2026-02-26T06:18:11Z",
    "updated": "2026-02-26T06:18:11Z",
    "comment": "Accepted to ICASSP 2026. 5 pages (main paper) + 8 pages (supplementary material)",
    "light_analysis": {
      "overview": "论文提出了一种基于众包的实用方法，构建了最大且最多样化的音视频质量评估数据集YT-NTU-AVQ，以克服现有数据集规模小、多样性不足的限制。",
      "motivation": "音视频质量评估（AVQA）研究因现有数据集的局限性而停滞不前：这些数据集通常规模较小，内容和质量多样性不足，且仅注释整体评分。这些缺陷限制了模型开发和多模态感知研究的进展，导致相关模型训练和感知机制分析缺乏充分的数据支持。因此，构建更强大且多样化的数据集对于推动AVQA和多模态研究至关重要，以解决实际应用中音视频质量评估的需求。",
      "method": "论文提出了一种三步方法的AVQA数据集构建框架：首先，设计众包主观实验框架，打破传统实验室设置的限制，在不同环境中实现可靠注释；其次，采用系统数据准备策略，确保广泛覆盖多种质量水平和语义场景；最后，扩展数据集带有额外注释，以支持多模态感知机制及其与内容关系的研究。通过这些方法，构建了YT-NTU-AVQ数据集，其中包含用户生成的音视频序列，为后续研究提供坚实基础。",
      "result": "论文通过构建YT-NTU-AVQ数据集验证了所提方法的有效性，该数据集是目前最大且最多样化的AVQA数据集，包含1,620个用户生成的音视频序列。摘要未明确说明具体性能指标如准确率提升或效率改进，也未提供与基线方法的对比数据，但强调数据集的规模、多样性和额外注释的优势，为模型开发和多模态研究提供了丰富资源。",
      "conclusion": "论文的主要贡献是提出了一种实用的AVQA数据集构建方法，并发布了YT-NTU-AVQ数据集，为音视频质量评估和多模态感知研究提供了关键工具。这具有重要的学术价值，能促进模型开发和感知机制分析，同时具备实际应用潜力，如改善用户体验和内容质量评估。未来工作可能包括进一步扩展数据集规模或探索该方法在其他质量评估领域的应用，以克服潜在局限性。",
      "tags": [
        "Audio-Visual Quality Assessment",
        "Crowdsourcing",
        "Dataset Construction",
        "Multimodal Perception",
        "Subjective Experiment Framework"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:37.843931Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22654",
    "title": "Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache",
    "authors": [
      "Bowen Cui",
      "Yuanbin Wang",
      "Huajiang Xu",
      "Biaolong Chen",
      "Aixi Zhang",
      "Hao Jiang",
      "Zhengzheng Jin",
      "Xu Liu",
      "Pipei Huang"
    ],
    "abstract": "Diffusion models have demonstrated remarkable success in image and video generation, yet their practical deployment remains hindered by the substantial computational overhead of multi-step iterative sampling. Among acceleration strategies, caching-based methods offer a training-free and effective solution by reusing or predicting features across timesteps. However, existing approaches rely on fixed or locally adaptive schedules without considering the global structure of the denoising trajectory, often leading to error accumulation and visual artifacts. To overcome this limitation, we propose DPCache, a novel training-free acceleration framework that formulates diffusion sampling acceleration as a global path planning problem. DPCache constructs a Path-Aware Cost Tensor from a small calibration set to quantify the path-dependent error of skipping timesteps conditioned on the preceding key timestep. Leveraging this tensor, DPCache employs dynamic programming to select an optimal sequence of key timesteps that minimizes the total path cost while preserving trajectory fidelity. During inference, the model performs full computations only at these key timesteps, while intermediate outputs are efficiently predicted using cached features. Extensive experiments on DiT, FLUX, and HunyuanVideo demonstrate that DPCache achieves strong acceleration with minimal quality loss, outperforming prior acceleration methods by $+$0.031 ImageReward at 4.87$\\times$ speedup and even surpassing the full-step baseline by $+$0.028 ImageReward at 3.54$\\times$ speedup on FLUX, validating the effectiveness of our path-aware global scheduling framework. Code will be released at https://github.com/argsss/DPCache.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22654.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22654",
    "published": "2026-02-26T06:13:33Z",
    "updated": "2026-02-26T06:13:33Z",
    "comment": "Accepted by CVPR 2026",
    "light_analysis": {
      "overview": "本文提出DPCache框架，将扩散模型采样加速作为全局路径规划问题，通过动态规划优化关键timesteps选择，实现无需训练的高效加速。",
      "motivation": "扩散模型在图像和视频生成中表现出色，但其多步迭代采样的高计算成本限制了实际部署。现有基于缓存的加速方法无需训练，但常采用固定或局部自适应调度，忽视了去噪轨迹的全局结构，导致误差累积和视觉伪影，影响了生成质量和效率，因此迫切需要一种能全局优化timesteps序列的方法来解决这些问题。",
      "method": "DPCache框架将扩散采样加速视为全局路径规划问题。首先，基于小校准集构建路径感知成本张量，量化跳过的timesteps在依赖前置关键timestep时的错误。然后，利用动态规划算法选择最小化总路径成本的关键timesteps序列，确保轨迹保真度。在推理阶段，模型仅在关键timesteps执行完整计算，中间输出通过缓存特征高效预测，从而显著减少计算开销，无需额外训练。",
      "result": "在DiT、FLUX和HunyuanVideo模型上的实验表明，DPCache实现了强加速且质量损失最小。具体地，在FLUX上，以4.87倍速度加速时，ImageReward提升0.031；以3.54倍速度加速时，甚至超过完整步长基线0.028 ImageReward。这些结果验证了全局调度框架的有效性，优于现有加速方法，展示了在多个模型上的稳健性能。",
      "conclusion": "DPCache的主要贡献是提出了一种无需训练的扩散模型加速框架，通过全局路径规划优化timesteps选择，显著提高了采样效率并保持了高质量输出。该方法证明了考虑全局结构的重要性，为扩散模型部署提供了实用解决方案，具有学术和应用价值。摘要未明确说明具体局限性，但未来工作可能包括进一步优化路径规划算法或扩展至其他生成模型。",
      "tags": [
        "Diffusion Models",
        "Training-Free Acceleration",
        "Caching",
        "Dynamic Programming",
        "Path Planning"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:36.444317Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22650",
    "title": "AHBid: An Adaptable Hierarchical Bidding Framework for Cross-Channel Advertising",
    "authors": [
      "Xinxin Yang",
      "Yangyang Tang",
      "Yikun Zhou",
      "Yaolei Liu",
      "Yun Li",
      "Bo Yang"
    ],
    "abstract": "In online advertising, the inherent complexity and dynamic nature of advertising environments necessitate the use of auto-bidding services to assist advertisers in bid optimization. This complexity is further compounded in multi-channel scenarios, where effective allocation of budgets and constraints across channels with distinct behavioral patterns becomes critical for optimizing return on investment. Current approaches predominantly rely on either optimization-based strategies or reinforcement learning techniques. However, optimization-based methods lack flexibility in adapting to dynamic market conditions, while reinforcement learning approaches often struggle to capture essential historical dependencies and observational patterns within the constraints of Markov Decision Process frameworks. To address these limitations, we propose AHBid, an Adaptable Hierarchical Bidding framework that integrates generative planning with real-time control. The framework employs a high-level generative planner based on diffusion models to dynamically allocate budgets and constraints by effectively capturing historical context and temporal patterns. We introduce a constraint enforcement mechanism to ensure compliance with specified constraints, along with a trajectory refinement mechanism that enhances adaptability to environmental changes through the utilization of historical data. The system further incorporates a control-based bidding algorithm that synergistically combines historical knowledge with real-time information, significantly improving both adaptability and operational efficacy. Extensive experiments conducted on large-scale offline datasets and through online A/B tests demonstrate the effectiveness of AHBid, yielding a 13.57% increase in overall return compared to existing baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22650.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22650",
    "published": "2026-02-26T06:07:28Z",
    "updated": "2026-02-26T06:07:28Z",
    "comment": "11 pages, 6 figures, accepted by WWW'2026",
    "light_analysis": {
      "overview": "AHBid框架通过整合基于扩散模型的生成规划和实时控制，有效优化跨渠道广告投标的适应性和投资回报。",
      "motivation": "在在线广告中，特别是多渠道场景下，预算和约束的分配对投资回报优化至关重要。现有方法如基于优化的策略缺乏对动态市场条件的适应性，而强化学习方法受限于MDP框架，难以有效捕捉历史依赖性和观测模式。因此，亟需一种灵活且能充分利用历史和实时数据的自动投标框架来解决这些不足。",
      "method": "AHBid框架采用分层方法，高层生成规划器基于扩散模型动态分配预算和约束，并融合历史上下文和时间模式。框架包括约束执行机制确保合规性，以及轨迹精炼机制利用历史数据增强环境变化适应性。系统还整合了控制算法，协同历史知识和实时信息，提升操作效能。实验中使用大规模离线数据集和在线A/B测试，具体模型架构摘要未明确说明。",
      "result": "通过在大规模离线数据集和在线A/B测试中验证，AHBid框架的总体投资回报比现有基线提高了13.57%，展示了其在跨渠道广告投标优化中的显著效果。实验结果表明，该方法在适应性和操作效能方面均优于传统优化和强化学习基准。",
      "conclusion": "AHBid框架的主要贡献在于通过集成生成规划和实时控制，有效克服了现有自动投标方法的局限性，提高了广告投资回报和资源分配效率。该研究具有实际应用价值，为复杂多广告渠道环境提供了新的解决方案，未来工作可探索算法进一步优化或扩展到其他类似领域，摘要未明确说明具体局限性。",
      "tags": [
        "Diffusion Models",
        "Generative Planning",
        "Reinforcement Learning",
        "Constraint Enforcement",
        "Online Advertising"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:37.979723Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22649",
    "title": "Interactive Medical-SAM2 GUI: A Napari-based semi-automatic annotation tool for medical images",
    "authors": [
      "Woojae Hong",
      "Jong Ha Hwang",
      "Jiyong Chung",
      "Joongyeon Choi",
      "Hyunngun Kim",
      "Yong Hwy Kim"
    ],
    "abstract": "Interactive Medical-SAM2 GUI is an open-source desktop application for semi-automatic annotation of 2D and 3D medical images. Built on the Napari multi-dimensional viewer, box/point prompting is integrated with SAM2-style propagation by treating a 3D volume as a slice sequence, enabling mask propagation from sparse prompts using Medical-SAM2 on top of SAM2. Voxel-level annotation remains essential for developing and validating medical imaging algorithms, yet manual labeling is slow and expensive for 3D scans, and existing integrations frequently emphasize per-slice interaction without providing a unified, cohort-oriented workflow for navigation, propagation, interactive correction, and quantitative export in a single local pipeline. To address this practical limitation, a local-first Napari workflow is provided for efficient 3D annotation across multiple studies using standard DICOM series and/or NIfTI volumes. Users can annotate cases sequentially under a single root folder with explicit proceed/skip actions, initialize objects via box-first prompting (including first/last-slice initialization for single-object propagation), refine predictions with point prompts, and finalize labels through prompt-first correction prior to saving. During export, per-object volumetry and 3D volume rendering are supported, and image geometry is preserved via SimpleITK. The GUI is implemented in Python using Napari and PyTorch, with optional N4 bias-field correction, and is intended exclusively for research annotation workflows. The code is released on the project page: https://github.com/SKKU-IBE/Medical-SAM2GUI/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22649.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22649",
    "published": "2026-02-26T06:05:57Z",
    "updated": "2026-02-26T06:05:57Z",
    "comment": "6 pages, 2 figures, Planning to submit JOSS (Journal of Open Source Software)",
    "light_analysis": {
      "overview": "开发了一个基于Napari和SAM2的交互式医学图像半自动注释工具，支持2D和3D图像的注释。",
      "motivation": "医学图像体素级注释对算法开发和验证至关重要，但手动标注3D扫描耗时且成本高昂。现有工具多关注单个切片交互，缺乏统一的、面向队列的工作流程，无法在一个本地管道中集成导航、传播、交互修正和定量导出。这限制了注释效率和算法研究进展。因此，本研究旨在解决这一实际限制，提供一种高效的半自动注释解决方案来提升医学图像处理流程。",
      "method": "该方法基于Napari多维度查看器，通过将3D体积视为切片序列，整合了方框/点提示与SAM2风格的传播。核心创新点在于使用Medical-SAM2在SAM2基础上实现从稀疏提示的掩码传播。工具提供本地优先工作流程，支持标准DICOM系列和NIfTI体积，用户可在单个根文件夹下顺序注释案例，通过方框优先提示初始化对象，点提示修正预测，并在保存前进行提示优先修正。实现使用Python、Napari和PyTorch，可选N4偏置场校正。",
      "result": "摘要未明确提供具体实验性能指标，但描述了工具的功能：支持多个研究的3D注释，包括初始化、修正和导出，如每对象体积测量和3D体积渲染，并通过SimpleITK保持图像几何。工具旨在提供高效的半自动注释流程，但未与基线方法进行对比或报告准确率等数据。",
      "conclusion": "本研究贡献了一个开源的、基于Napari的医学图像半自动注释工具，通过整合SAM2传播技术，实现了高效的2D/3D注释工作流程。学术价值在于简化医学图像标注过程，支持算法开发；实际应用价值在于提升研究中的注释效率。未来工作可能包括扩展更多交互功能或集成其他模型，以进一步提升工具的应用范围。",
      "tags": [
        "Napari",
        "SAM2",
        "Medical Imaging",
        "Semi-automatic Annotation",
        "DICOM/NIfTI"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:44.726317Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22645",
    "title": "MUG: Meta-path-aware Universal Heterogeneous Graph Pre-Training",
    "authors": [
      "Lianze Shan",
      "Jitao Zhao",
      "Dongxiao He",
      "Yongqi Huang",
      "Zhiyong Feng",
      "Weixiong Zhang"
    ],
    "abstract": "Universal graph pre-training has emerged as a key paradigm in graph representation learning, offering a promising way to train encoders to learn transferable representations from unlabeled graphs and to effectively generalize across a wide range of downstream tasks. However, recent explorations in universal graph pre-training primarily focus on homogeneous graphs and it remains unexplored for heterogeneous graphs, which exhibit greater structural and semantic complexity. This heterogeneity makes it highly challenging to train a universal encoder for diverse heterogeneous graphs: (i) the diverse types with dataset-specific semantics hinder the construction of a unified representation space; (ii) the number and semantics of meta-paths vary across datasets, making encoding and aggregation patterns learned from one dataset difficult to apply to others. To address these challenges, we propose a novel Meta-path-aware Universal heterogeneous Graph pre-training (MUG) approach. Specifically, for challenge (i), MUG introduces a input unification module that integrates information from multiple node and relation types within each heterogeneous graph into a unified representation.This representation is then projected into a shared space by a dimension-aware encoder, enabling alignment across graphs with diverse schemas.Furthermore, for challenge (ii), MUG trains a shared encoder to capture consistent structural patterns across diverse meta-path views rather than relying on dataset-specific aggregation strategies, while a global objective encourages discriminability and reduces dataset-specific biases. Extensive experiments demonstrate the effectiveness of MUG on some real datasets.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22645.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22645",
    "published": "2026-02-26T05:52:28Z",
    "updated": "2026-02-26T05:52:28Z",
    "comment": "Accepted by AAAI-26, 9 pages, 3 figures",
    "light_analysis": {
      "overview": "MUG提出了一种元路径感知的通用异质图预训练方法，通过输入统一和共享编码器解决异质图预训练中的多样性和元路径挑战。",
      "motivation": "通用图预训练是图表示学习的关键范式，能够从无标签图中学习可迁移表示并泛化到多种下游任务。然而，现有研究主要关注同质图，而异质图因其结构复杂性和语义多样性面临较大挑战：节点和关系类型的多样性阻碍统一表示空间的构建；元路径的数量和语义跨数据集变化，使预训练编码器难以应用。这些问题限制了异质图预训练的发展，因此迫切需要创新方法处理异质性并实现跨数据集的通用预训练。",
      "method": "MUG方法包括输入统一模块和共享编码器。输入统一模块整合异质图中多类型节点和关系信息成统一表示，通过维度感知编码器投影到共享空间，实现不同图模式对齐。共享编码器训练以捕捉跨多样元路径视图的一致结构模式，避免数据集特定聚合策略；全局目标函数增强表示区分性并减少数据集偏见，从而解决元路径和语义多样性问题。",
      "result": "摘要未明确说明具体实验结果，但指出广泛的实验在真实数据集上验证了MUG的有效性。这表明MUG可能优于现有方法，提升了在异质图上的泛化能力和表示学习性能；为了全面评估，需要参考论文详细数据，但基于摘要推断其在通用预训练方面取得积极成果。",
      "conclusion": "MUG的主要贡献在于提出了一个元路径感知的预训练框架，成功解决了异质图预训练的关键挑战。该研究具有重要学术价值，推动了通用图表示学习在异质图领域的进展，为下游任务如节点分类提供了更有效的预训练模型；未来工作可探索扩展到动态图或多模态图，并进一步优化编码器和目标函数。",
      "tags": [
        "Heterogeneous Graph",
        "Graph Pre-training",
        "Meta-path",
        "Universal Representation",
        "Graph Encoder"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:51.842436Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22644",
    "title": "Plug, Play, and Fortify: A Low-Cost Module for Robust Multimodal Image Understanding Models",
    "authors": [
      "Siqi Lu",
      "Wanying Xu",
      "Yongbin Zheng",
      "Wenting Luan",
      "Peng Sun",
      "Jianhang Yao"
    ],
    "abstract": "Missing modalities present a fundamental challenge in multimodal models, often causing catastrophic performance degradation. Our observations suggest that this fragility stems from an imbalanced learning process, where the model develops an implicit preference for certain modalities, leading to the under-optimization of others. We propose a simple yet efficient method to address this challenge. The central insight of our work is that the dominance relationship between modalities can be effectively discerned and quantified in the frequency domain. To leverage this principle, we first introduce a Frequency Ratio Metric (FRM) to quantify modality preference by analyzing features in the frequency domain. Guided by FRM, we then propose a Multimodal Weight Allocation Module, a plug-and-play component that dynamically re-balances the contribution of each branch during training, promoting a more holistic learning paradigm. Extensive experiments demonstrate that MWAM can be seamlessly integrated into diverse architectural backbones, such as those based on CNNs and ViTs. Furthermore, MWAM delivers consistent performance gains across a wide range of tasks and modality combinations. This advancement extends beyond merely optimizing the performance of the base model; it also manifests as further performance improvements to state-of-the-art methods addressing the missing modality problem.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22644.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22644",
    "published": "2026-02-26T05:51:41Z",
    "updated": "2026-02-26T05:51:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一个名为MWAM的低成本即插即用模块，通过频率域量化模态偏好并动态平衡多模态贡献，显著增强模型在缺失模态情况下的鲁棒性。",
      "motivation": "多模态模型在处理缺失模态时面临性能急剧下降的挑战，这在实际应用中如自动驾驶和医疗影像中尤为关键。现有方法常因学习过程不平衡，导致模型隐含偏好某些模态，使其他模态未充分优化，从而影响模型可靠性。虽然已有技术尝试通过数据增强等方式缓解，但未能从根本上解决模态偏好问题。因此，本研究旨在开发一种高效方法来平衡多模态学习，以应对模态缺失带来的不稳定性。",
      "method": "论文提出一种基于频率域分析的两步法：首先，引入频率比度量（FRM），通过分析特征在频率域中的分布来量化模态间的偏好关系，这一创新点源于模态主导关系可在频率域中有效辨识的洞察。其次，基于FRM设计多模态权重分配模块（MWAM），这是一个即插即用组件，可在训练过程中动态调整各模态分支的权重，以促进更全面的学习范式。该方法适用于多种主干架构，如卷积神经网络（CNNs）和视觉变换器（ViTs），无需修改模型结构。",
      "result": "广泛实验表明，MWAM能够无缝集成到包括CNNs和ViTs在内的多样架构中，并在各种任务和模态组合中实现一致的性能提升，例如在图像理解任务中增强鲁棒性。此外，MWAM不仅优化了基础模型的性能，还进一步改进了处理缺失模态问题的最先进方法，展现出其泛化能力。尽管摘要未提供具体数值，但结果强调了该模块在提升模型稳定性和适用性方面的有效性。",
      "conclusion": "本研究的核心贡献是提出MWAM模块，通过频率域量化模态偏好和动态权重分配，有效解决多模态模型中的模态不平衡问题，提高了模型在缺失模态场景下的鲁棒性。这不仅为多模态学习提供了新的技术视角，还具有低成本、即插即用的实际应用价值。未来工作可探索在更多模态类型和复杂场景中的扩展，以及进一步优化动态平衡策略以应对更广泛的挑战。",
      "tags": [
        "Multimodal Learning",
        "Frequency Domain Analysis",
        "Dynamic Weight Allocation",
        "Plug-and-Play Module",
        "Missing Modalities"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:07.838283Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22642",
    "title": "Compress the Easy, Explore the Hard: Difficulty-Aware Entropy Regularization for Efficient LLM Reasoning",
    "authors": [
      "Qin-Wen Luo",
      "Sheng Ren",
      "Xiang Chen",
      "Rui Liu",
      "Jun Fang",
      "Naiqiang Tan",
      "Sheng-Jun Huang"
    ],
    "abstract": "Chain-of-Thought (CoT) has substantially empowered Large Language Models (LLMs) to tackle complex reasoning tasks, yet the verbose nature of explicit reasoning steps incurs prohibitive inference latency and computational costs, limiting real-world deployment. While existing compression methods - ranging from self-training to Reinforcement Learning (RL) with length constraints - attempt to mitigate this, they often sacrifice reasoning capability for brevity. We identify a critical failure mode in these approaches: explicitly optimizing for shorter trajectories triggers rapid entropy collapse, which prematurely shrinks the exploration space and stifles the discovery of valid reasoning paths, particularly for challenging questions requiring extensive deduction. To address this issue, we propose Compress responses for Easy questions and Explore Hard ones (CEEH), a difficulty-aware approach to RL-based efficient reasoning. CEEH dynamically assesses instance difficulty to apply selective entropy regularization: it preserves a diverse search space for currently hard questions to ensure robustness, while permitting aggressive compression on easier instances where the reasoning path is well-established. In addition, we introduce a dynamic optimal-length penalty anchored to the historically shortest correct response, which effectively counteracts entropy-induced length inflation and stabilizes the reward signal. Across six reasoning benchmarks, CEEH consistently reduces response length while maintaining accuracy comparable to the base model, and improves Pass@k relative to length-only optimization.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22642.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22642",
    "published": "2026-02-26T05:47:30Z",
    "updated": "2026-02-26T05:47:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出CEEH方法，基于难度感知的熵正则化，高效平衡大型语言模型推理的压缩和探索，以解决推理效率问题。",
      "motivation": "Chain-of-Thought (CoT) 使大型语言模型能处理复杂推理任务，但其冗长的推理步骤导致高推理延迟和计算成本，限制了实际部署。现有压缩方法，如自训练和带长度约束的强化学习，虽试图缓解，但常牺牲推理能力以换取简短，关键不足在于优化短轨迹会引发熵崩溃，过早缩小探索空间，阻碍发现有效推理路径，尤其对于需要广泛推导的困难问题，这影响了LLM在实际应用中的效率和鲁棒性。",
      "method": "本研究提出Compress responses for Easy questions and Explore Hard ones (CEEH)，一种基于强化学习的高效推理方法。CEEH的核心在于动态评估每个实例的难度，并应用选择性熵正则化：对于当前困难的推理问题，保持多样化的搜索空间以确保鲁棒性；而对于容易问题，则允许激进压缩推理路径。此外，引入动态最优长度惩罚机制，锚定历史最短正确响应，有效抵消熵引起的长度膨胀，并稳定强化学习中的奖励信号，从而在减少响应长度的同时维护推理能力。",
      "result": "在六个推理基准测试中，CEEH方法持续降低了响应长度，同时保持了与基础模型相当的准确率。相对于仅优化长度的方法，CEEH提高了Pass@k指标，表明在压缩推理步骤的同时，有效维持或提升了推理性能，实现了效率与准确性的平衡。摘要未提供具体数值数据，但强调了CEEH在多个基准上的稳定表现和改进。",
      "conclusion": "本文的主要贡献是提出了CEEH方法，通过难度感知熵正则化，有效解决了大型语言模型推理中的效率与准确性平衡问题。该方法在保持推理能力的同时，显著压缩响应长度，提升了实际部署的可行性。学术价值在于引入了动态难度评估和选择性熵正则化技术，为高效推理提供了新思路。摘要未明确说明局限性，未来工作可能包括扩展应用到更广泛的推理任务或进一步优化算法参数。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Entropy Regularization",
        "Chain-of-Thought",
        "Difficulty-Aware"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:13.795384Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22639",
    "title": "QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition",
    "authors": [
      "Daniel Miao",
      "Gilad Lerman",
      "Joe Kileel"
    ],
    "abstract": "In structure from motion, quadrifocal tensors capture more information than their pairwise counterparts (essential matrices), yet they have often been thought of as impractical and only of theoretical interest. In this work, we challenge such beliefs by providing a new framework to recover $n$ cameras from the corresponding collection of quadrifocal tensors. We form the block quadrifocal tensor and show that it admits a Tucker decomposition whose factor matrices are the stacked camera matrices, and which thus has a multilinear rank of (4,~4,~4,~4) independent of $n$. We develop the first synchronization algorithm for quadrifocal tensors, using Tucker decomposition, alternating direction method of multipliers, and iteratively reweighted least squares. We further establish relationships between the block quadrifocal, trifocal, and bifocal tensors, and introduce an algorithm that jointly synchronizes these three entities. Numerical experiments demonstrate the effectiveness of our methods on modern datasets, indicating the potential and importance of using higher-order information in synchronization.",
    "categories": [
      "cs.CV",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22639.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22639",
    "published": "2026-02-26T05:42:17Z",
    "updated": "2026-02-26T05:42:17Z",
    "comment": "30 pages, accepted to CVPR 2026",
    "light_analysis": {
      "overview": "本论文提出一种基于Tucker分解的四焦张量同步框架，首次实现高效相机恢复，挑战了四焦张量仅具理论价值的传统观点。",
      "motivation": "在运动恢复结构（SfM）中，相机参数恢复通常依赖成对对应物（如本质矩阵），但四焦张量能捕获更多信息，长期以来被视为理论工具而未被实际应用，导致高阶信息利用不足。本研究旨在解决这一实际问题，通过开发实用框架来同步四焦张量，提升相机恢复的准确性和效率，弥补现有方法中对高阶张量研究的缺失。",
      "method": "论文提出一种新方法，首先构造块四焦张量，证明其Tucker分解的因子矩阵对应堆叠相机矩阵，多线性秩固定为(4,4,4,4)。基于此，开发了首个四焦张量同步算法，结合Tucker分解、交替方向乘子法（ADMM）和迭代重加权最小二乘法（IRLS）进行优化，并扩展为联合处理四焦、三焦和双焦张量的算法，以提高同步效率和鲁棒性。",
      "result": "数值实验结果表明，所提出的四焦张量同步框架在现代化数据集上表现有效，验证了使用高阶信息（如四焦张量）的潜力和重要性。摘要未明确说明具体性能指标，但论文暗示通过Tucker分解和优化方法，能够高效恢复相机参数，相比传统基于成对对应物的方法可能具有改进效果。",
      "conclusion": "本论文的主要贡献在于首次为四焦张量提供同步算法，证明了其在运动恢复结构中的实际应用价值，通过整合高阶信息挑战了四焦张量不切实际的观点。研究具有重要学术意义，推动了张量分解和优化技术在计算机视觉领域的应用，并为提高SfM系统性能开辟新途径。未来工作可进一步优化算法或扩展到其他多视图几何问题。",
      "tags": [
        "Quadrifocal Tensor",
        "Tucker Decomposition",
        "Structure from Motion",
        "Alternating Direction Method of Multipliers",
        "Iteratively Reweighted Least Squares"
      ]
    },
    "analyzed_at": "2026-02-27T04:01:11.028484Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22638",
    "title": "MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios",
    "authors": [
      "Zhiheng Song",
      "Jingshuai Zhang",
      "Chuan Qin",
      "Chao Wang",
      "Chao Chen",
      "Longfei Xu",
      "Kaikui Liu",
      "Xiangxiang Chu",
      "Hengshu Zhu"
    ],
    "abstract": "Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench .",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22638.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22638",
    "published": "2026-02-26T05:39:38Z",
    "updated": "2026-02-26T05:39:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出MobilityBench基准，通过真实数据和多维评估协议实现基于LLM路线规划代理的可重复、系统评估。",
      "motivation": "LLM驱动的路线规划代理在现实世界移动场景中展现出潜力，但现有评估方法面临挑战，包括路由需求的多样性、非确定性映射服务带来的不可重复性，以及缺乏系统性基准。这阻碍了代理性能的优化和实际应用的发展，因此需要构建一个可扩展的评估框架来解决这些问题。",
      "method": "研究方法包括构建MobilityBench基准，基于Amap收集的大规模真实匿名用户查询，覆盖全球多个城市的多种路线规划意图。核心创新是设计确定性API重放沙盒，消除实时服务的环境变化，确保可重复性。此外，提出了以结果有效性为核心的多维评估协议，评估指令理解、规划、工具使用和效率等方面。",
      "result": "使用MobilityBench评估多个基于LLM的路线规划代理，结果表明模型在基本信息检索和路线规划任务上表现良好，但在偏好约束的路线规划任务上显著挣扎，突显了在个性化移动应用中的重大改进空间。这些发现基于基准的量化评估，展示了当前技术的局限性。",
      "conclusion": "论文贡献了MobilityBench基准、评估工具和公开数据，推动了LLM路线规划代理的现实世界评估。其学术价值在于提供标准化评估方法，实际应用价值在于支持个性化移动服务的开发。未来工作可聚焦于改进模型在复杂偏好处理方面的能力。",
      "tags": [
        "Large Language Model",
        "Route-Planning",
        "Benchmark Evaluation",
        "API Replay Sandbox",
        "Real-World Mobility"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:01.888580Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22633",
    "title": "Tackling Privacy Heterogeneity in Differentially Private Federated Learning",
    "authors": [
      "Ruichen Xu",
      "Ying-Jun Angela Zhang",
      "Jianwei Huang"
    ],
    "abstract": "Differentially private federated learning (DP-FL) enables clients to collaboratively train machine learning models while preserving the privacy of their local data. However, most existing DP-FL approaches assume that all clients share a uniform privacy budget, an assumption that does not hold in real-world scenarios where privacy requirements vary widely. This privacy heterogeneity poses a significant challenge: conventional client selection strategies, which typically rely on data quantity, cannot distinguish between clients providing high-quality updates and those introducing substantial noise due to strict privacy constraints. To address this gap, we present the first systematic study of privacy-aware client selection in DP-FL. We establish a theoretical foundation by deriving a convergence analysis that quantifies the impact of privacy heterogeneity on training error. Building on this analysis, we propose a privacy-aware client selection strategy, formulated as a convex optimization problem, that adaptively adjusts selection probabilities to minimize training error. Extensive experiments on benchmark datasets demonstrate that our approach achieves up to a 10% improvement in test accuracy on CIFAR-10 compared to existing baselines under heterogeneous privacy budgets. These results highlight the importance of incorporating privacy heterogeneity into client selection for practical and effective federated learning.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22633.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22633",
    "published": "2026-02-26T05:20:37Z",
    "updated": "2026-02-26T05:20:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文首次系统研究了差分隐私联邦学习中的隐私感知客户端选择，提出基于凸优化的策略以应对隐私异质性问题，显著提升模型精度。",
      "motivation": "差分隐私联邦学习中，现有方法假设所有客户端共享统一隐私预算，但现实场景中隐私需求存在差异，导致隐私异质性。这种异质性挑战在于传统基于数据量的客户端选择策略无法区分高质量更新和因严格隐私约束引入的噪声，从而影响模型训练效果。因此，需要开发隐私感知的客户端选择方法来优化联邦学习的实用性和效率。",
      "method": "论文首先建立理论基础，通过收敛分析量化隐私异质性对训练误差的影响。基于此，提出隐私感知客户端选择策略，将问题表述为凸优化问题，自适应调整客户端选择概率以最小化误差。实验使用CIFAR-10等基准数据集验证方法，但模型架构的具体细节摘要未明确说明。",
      "result": "在基准数据集上的广泛实验表明，该方法在异质隐私预算下相较于现有基线方法，测试准确率最高提升了10%（在CIFAR-10数据集上）。这证明了结合隐私异质性进行客户端选择的有效性，显著提高了联邦学习的性能。",
      "conclusion": "本文的主要贡献在于首次系统研究并解决了差分隐私联邦学习中的隐私感知客户端选择问题，提供了理论分析和优化策略。该研究增强了联邦学习的隐私保护能力并提升了性能，具有实际应用价值。未来工作可能包括扩展到更复杂场景或进一步优化策略，但摘要未明确说明具体方向。",
      "tags": [
        "Differentially Private Federated Learning",
        "Privacy Heterogeneity",
        "Client Selection",
        "Convex Optimization",
        "Convergence Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:14.645814Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22629",
    "title": "CRAG: Can 3D Generative Models Help 3D Assembly?",
    "authors": [
      "Zeyu Jiang",
      "Sihang Li",
      "Siqi Tan",
      "Chenyang Xu",
      "Juexiao Zhang",
      "Julia Galway-Witham",
      "Xue Wang",
      "Scott A. Williams",
      "Radu Iovita",
      "Chen Feng",
      "Jing Zhang"
    ],
    "abstract": "Most existing 3D assembly methods treat the problem as pure pose estimation, rearranging observed parts via rigid transformations. In contrast, human assembly naturally couples structural reasoning with holistic shape inference. Inspired by this intuition, we reformulate 3D assembly as a joint problem of assembly and generation. We show that these two processes are mutually reinforcing: assembly provides part-level structural priors for generation, while generation injects holistic shape context that resolves ambiguities in assembly. Unlike prior methods that cannot synthesize missing geometry, we propose CRAG, which simultaneously generates plausible complete shapes and predicts poses for input parts. Extensive experiments demonstrate state-of-the-art performance across in-the-wild objects with diverse geometries, varying part counts, and missing pieces. Our code and models will be released.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22629.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22629",
    "published": "2026-02-26T05:04:42Z",
    "updated": "2026-02-26T05:04:42Z",
    "comment": "10 pages, 7 figures",
    "light_analysis": {
      "overview": "提出CRAG模型，通过将3D组装与生成结合，同时预测部分姿态和生成完整形状，解决现有方法在缺失几何处理上的不足。",
      "motivation": "现有3D组装方法主要关注纯姿态估计，通过刚性变换重新排列观察到的部分，但无法处理缺失几何的情况，导致在复杂场景下性能受限。人类组装过程自然结合结构推理和整体形状推断，能有效解决歧义和部分缺失。因此，研究旨在将生成模型引入组装任务，弥补现有方法的不足，提升在野外对象中的组装能力，满足实际应用中对不完整数据处理的需求。",
      "method": "论文提出CRAG方法，将3D组装重新定义为组装和生成的联合问题。核心创新在于组装和生成相互强化：组装提供部分级结构先验用于生成完整形状，而生成则注入整体形状上下文以解决组装中的歧义。CRAG能够同时生成合理完整形状并预测输入部分姿态，区别于以往仅进行姿态估计的方法。摘要未明确说明具体的数据集和模型架构，但暗示使用生成模型技术处理缺失几何，可能涉及神经网络结构如自注意力机制或对比学习，以优化联合学习过程。",
      "result": "广泛的实验表明，CRAG在具有多样几何形状、不同部分数量和缺失部分的野外对象上取得了最先进的性能。实验验证了该方法能有效解决组装歧义并生成完整形状，与基线方法相比，在处理缺失几何时表现更优。尽管摘要未提供具体数值指标如准确率提升，但强调了在复杂场景下的性能改进，例如提升了姿态预测的稳定性和形状生成的合理性，为实际应用提供了有力支撑。",
      "conclusion": "CRAG的主要贡献是将3D组装与生成结合，解决了现有方法在缺失几何处理上的局限性，为组装任务提供了新方向。学术上，它展示了生成模型在结构推理中的潜力，推动了多任务学习的发展；实际上，适用于机器人组装、虚拟重建等需要处理不完整数据的领域。潜在局限性可能包括生成质量的优化和扩展到更复杂对象，未来工作可探索改进模型效率和适应更多样化场景。",
      "tags": [
        "3D Assembly",
        "3D Generative Models",
        "Shape Completion",
        "Pose Estimation",
        "Joint Learning"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:51.143690Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22624",
    "title": "Instruction-based Image Editing with Planning, Reasoning, and Generation",
    "authors": [
      "Liya Ji",
      "Chenyang Qi",
      "Qifeng Chen"
    ],
    "abstract": "Editing images via instruction provides a natural way to generate interactive content, but it is a big challenge due to the higher requirement of scene understanding and generation. Prior work utilizes a chain of large language models, object segmentation models, and editing models for this task. However, the understanding models provide only a single modality ability, restricting the editing quality. We aim to bridge understanding and generation via a new multi-modality model that provides the intelligent abilities to instruction-based image editing models for more complex cases. To achieve this goal, we individually separate the instruction editing task with the multi-modality chain of thought prompts, i.e., Chain-of-Thought (CoT) planning, editing region reasoning, and editing. For Chain-of-Thought planning, the large language model could reason the appropriate sub-prompts considering the instruction provided and the ability of the editing network. For editing region reasoning, we train an instruction-based editing region generation network with a multi-modal large language model. Finally, a hint-guided instruction-based editing network is proposed for editing image generations based on the sizeable text-to-image diffusion model to accept the hints for generation. Extensive experiments demonstrate that our method has competitive editing abilities on complex real-world images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22624.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22624",
    "published": "2026-02-26T04:56:02Z",
    "updated": "2026-02-26T04:56:02Z",
    "comment": "10 pages, 7 figures",
    "light_analysis": {
      "overview": "本文提出了一种结合多模态链式思维提示的基于指令图像编辑方法，通过规划、推理和生成三个阶段提升编辑能力。",
      "motivation": "基于指令的图像编辑为交互内容生成提供了自然方式，但面临场景理解和生成的更高要求。现有方法通常采用大型语言模型、对象分割模型和编辑模型的链式组合，但这些理解模型仅限于单模态能力，无法有效处理复杂场景，导致编辑质量受限。因此，本研究旨在通过多模态模型桥接理解和生成，以应对更复杂的图像编辑任务，提升编辑的准确性和实用性。",
      "method": "本研究将指令编辑任务分解为多模态链式思维提示的三个阶段：链式思维规划、编辑区域推理和编辑。在链式思维规划中，使用大型语言模型根据指令和编辑网络能力推理适当的子提示。接着，训练一个基于指令的编辑区域生成网络，利用多模态大型语言模型进行编辑区域推理。最后，提出一个提示引导的基于指令的编辑网络，基于文本到图像扩散模型接收提示进行图像生成。关键创新在于整合多模态模型以增强整体编辑流程。",
      "result": "摘要未明确说明具体的实验结果数据，如准确率或效率指标。然而，广泛实验表明，该方法在复杂真实世界图像上具有竞争力的编辑能力，可能在与基线方法的对比中表现出改进，但具体性能提升细节未提供。",
      "conclusion": "本研究的主要贡献是提出了一种多模态模型，通过链式思维规划、编辑区域推理和生成来增强基于指令的图像编辑。其学术价值在于解决了现有方法中单模态能力限制编辑质量的问题，为复杂图像编辑提供了更智能的解决方案。实际应用中，该方法有望提升交互内容生成的效率和质量，未来可进一步探索更广泛的多模态编辑任务或扩展到其他领域。",
      "tags": [
        "Instruction-based Image Editing",
        "Multi-modality Model",
        "Chain-of-Thought (CoT)",
        "Large Language Model",
        "Text-to-Image Diffusion Model"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:35.391114Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22623",
    "title": "ContextRL: Enhancing MLLM's Knowledge Discovery Efficiency with Context-Augmented RL",
    "authors": [
      "Xingyu Lu",
      "Jinpeng Wang",
      "YiFan Zhang",
      "Shijie Ma",
      "Xiao Hu",
      "Tianke Zhang",
      "Haonan fan",
      "Kaiyu Jiang",
      "Changyi Liu",
      "Kaiyu Tang",
      "Bin Wen",
      "Fan Yang",
      "Tingting Gao",
      "Han Li",
      "Chun Yuan"
    ],
    "abstract": "We propose ContextRL, a novel framework that leverages context augmentation to overcome these bottlenecks. Specifically, to enhance Identifiability, we provide the reward model with full reference solutions as context, enabling fine-grained process verification to filter out false positives (samples with the right answer but low-quality reasoning process). To improve Reachability, we introduce a multi-turn sampling strategy where the reward model generates mistake reports for failed attempts, guiding the policy to \"recover\" correct responses from previously all-negative groups. Experimental results on 11 perception and reasoning benchmarks show that ContextRL significantly improves knowledge discovery efficiency. Notably, ContextRL enables the Qwen3-VL-8B model to achieve performance comparable to the 32B model, outperforming standard RLVR baselines by a large margin while effectively mitigating reward hacking. Our in-depth analysis reveals the significant potential of contextual information for improving reward model accuracy and document the widespread occurrence of reward hacking, offering valuable insights for future RLVR research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22623.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22623",
    "published": "2026-02-26T04:55:57Z",
    "updated": "2026-02-26T04:55:57Z",
    "comment": "14 pages, 5 figures",
    "light_analysis": {
      "overview": "ContextRL 是一种利用上下文增强强化学习的新框架，显著提升多模态大语言模型的知识发现效率。",
      "motivation": "本研究旨在解决多模态大语言模型在知识发现中面临的可识别性和可达性瓶颈，如摘要中提到的“overcome these bottlenecks”。现有强化学习与价值对齐方法常产生误报和奖励劫持问题，导致推理过程质量低、效率低下，影响模型性能和可靠性。ContextRL 通过引入上下文信息，旨在更精准地验证推理过程并优化模型行为，以提升整体效率和准确性，弥补现有方法的不足。摘要未明确说明具体瓶颈，但从上下文推断，这些问题对大规模模型部署至关重要。",
      "method": "ContextRL 框架通过上下文增强强化学习技术实现知识发现优化。首先，为奖励模型提供完整的参考解决方案作为额外上下文，进行细粒度推理过程验证，有效过滤误报，提高可识别性。其次，采用多轮采样策略，奖励模型为失败的尝试生成错误报告，指导策略从先前全负样本中恢复正确响应，增强可达性。关键创新在于整合上下文信息和多轮交互，结合强化学习机制，以提升模型在复杂任务中的表现。该方法基于奖励模型和策略调整，利用上下文感知优化决策过程。",
      "result": "实验在11个感知和推理基准测试中进行，结果表明 ContextRL 显著提高了知识发现效率。具体而言，Qwen3-VL-8B 模型在使用 ContextRL 后，性能达到与更大的 32B 模型相当的水平，大幅超越了标准的强化学习与价值对齐基线。同时，该方法有效缓解了奖励劫持现象，证明了其鲁棒性和有效性。摘要未提供具体百分比数据，但强调了性能提升和基线对比的显著优势，验证了框架在多种任务中的通用性和应用价值。",
      "conclusion": "ContextRL 的主要贡献是提出一种上下文增强强化学习框架，解决了知识发现中的瓶颈问题。研究表明，整合上下文信息能显著提高奖励模型准确性，并揭示了奖励劫持的广泛存在，为未来强化学习与价值对齐研究提供了重要见解。学术价值在于推动了模型效率优化方法的发展；实际应用价值体现在提升多模态大语言模型的性能和可靠性。未来工作可探索更精细的上下文策略或扩展到其他领域。",
      "tags": [
        "Context-Augmented Reinforcement Learning",
        "Reward Hacking",
        "Multi-Turn Sampling",
        "Knowledge Discovery",
        "MLLM"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:34.139301Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22621",
    "title": "CGSA: Class-Guided Slot-Aware Adaptation for Source-Free Object Detection",
    "authors": [
      "Boyang Dai",
      "Zeng Fan",
      "Zihao Qi",
      "Meng Lou",
      "Yizhou Yu"
    ],
    "abstract": "Source-Free Domain Adaptive Object Detection (SF-DAOD) aims to adapt a detector trained on a labeled source domain to an unlabeled target domain without retaining any source data. Despite recent progress, most popular approaches focus on tuning pseudo-label thresholds or refining the teacher-student framework, while overlooking object-level structural cues within cross-domain data. In this work, we present CGSA, the first framework that brings Object-Centric Learning (OCL) into SF-DAOD by integrating slot-aware adaptation into the DETR-based detector. Specifically, our approach integrates a Hierarchical Slot Awareness (HSA) module into the detector to progressively disentangle images into slot representations that act as visual priors. These slots are then guided toward class semantics via a Class-Guided Slot Contrast (CGSC) module, maintaining semantic consistency and prompting domain-invariant adaptation. Extensive experiments on multiple cross-domain datasets demonstrate that our approach outperforms previous SF-DAOD methods, with theoretical derivations and experimental analysis further demonstrating the effectiveness of the proposed components and the framework, thereby indicating the promise of object-centric design in privacy-sensitive adaptation scenarios. Code is released at https://github.com/Michael-McQueen/CGSA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22621.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22621",
    "published": "2026-02-26T04:54:39Z",
    "updated": "2026-02-26T04:54:39Z",
    "comment": "The paper has been accepted by the conference ICLR 2026",
    "light_analysis": {
      "overview": "提出CGSA框架，首次将对象中心学习引入无源域自适应目标检测，通过slot-aware adaptation提升性能。",
      "motivation": "本研究旨在解决无源域自适应目标检测（SF-DAOD）中忽视对象级结构线索的问题。SF-DAOD要求将源域训练的检测器适应无标签目标域而不使用源数据，这在隐私敏感场景中至关重要。现有方法侧重于调整伪标签阈值或精炼师生框架，但忽略了跨域数据中对象级的结构信息，导致适应性不足和性能瓶颈。",
      "method": "CGSA框架将对象中心学习融入SF-DAOD，具体包括两个核心模块：Hierarchical Slot Awareness (HSA)模块集成到DETR-based检测器，逐步将图像分解为slot representations作为视觉先验；Class-Guided Slot Contrast (CGSC)模块引导这些slot朝向类语义，通过对比学习保持语义一致性并促进域不变适应。关键创新点在于slot-aware adaptation和类指导的对比学习，增强了检测器对对象级结构的利用。",
      "result": "在多个跨域数据集上的广泛实验表明，CGSA框架优于先前的SF-DAOD方法。理论推导和实验分析验证了HSA和CGSC模块的有效性，具体表现为检测性能的显著提升，但摘要未明确说明具体数值指标如准确率。这表明框架在隐私敏感适应场景中具有潜力，并优于基线方法。",
      "conclusion": "CGSA的主要贡献是首次将对象中心学习应用于无源域自适应目标检测，通过slot-aware adaptation和类指导对比学习优化适应性。研究突出了对象级结构线索的重要性，为隐私敏感场景提供了新思路。学术价值在于推动领域适应技术的创新，实际应用价值包括安全检测系统。未来工作可探索扩展到其他检测架构或更多数据集。",
      "tags": [
        "Object-Centric Learning",
        "Slot-Aware Adaptation",
        "DETR",
        "Source-Free Domain Adaptation",
        "Contrastive Learning"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:16.792786Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22620",
    "title": "Coded-E2LF: Coded Aperture Light Field Imaging from Events",
    "authors": [
      "Tomoya Tsuchida",
      "Keita Takahashi",
      "Chihiro Tsutake",
      "Toshiaki Fujii",
      "Hajime Nagahara"
    ],
    "abstract": "We propose Coded-E2LF (coded event to light field), a computational imaging method for acquiring a 4-D light field using a coded aperture and a stationary event-only camera. In a previous work, an imaging system similar to ours was adopted, but both events and intensity images were captured and used for light field reconstruction. In contrast, our method is purely event-based, which relaxes restrictions for hardware implementation. We also introduce several advancements from the previous work that enable us to theoretically support and practically improve light field reconstruction from events alone. In particular, we clarify the key role of a black pattern in aperture coding patterns. We finally implemented our method on real imaging hardware to demonstrate its effectiveness in capturing real 3-D scenes. To the best of our knowledge, we are the first to demonstrate that a 4-D light field with pixel-level accuracy can be reconstructed from events alone. Our software and supplementary video are available from our project website.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22620.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22620",
    "published": "2026-02-26T04:53:08Z",
    "updated": "2026-02-26T04:53:08Z",
    "comment": "accepted to CVPR 2026",
    "light_analysis": {
      "overview": "提出一种纯事件基础的编码孔径成像方法，首次实现从事件中重建具有像素级精度的4-D光场。",
      "motivation": "现有光场成像方法通常结合事件和强度图像，这增加了硬件复杂性和实现限制。本研究旨在解决仅使用事件相机高效获取4-D光场的实际问题，因为事件相机具有高速和低功耗优势，但单独重建光场困难。开发纯事件基础系统可以减少硬件依赖，提高成像效率，具有重要应用价值，如3-D场景捕获和计算成像。",
      "method": "本论文提出Coded-E2LF方法，使用编码孔径和静态事件相机进行纯事件基础的4-D光场重建。核心创新是优化孔径编码模式，特别是阐明了黑色模式在模式设计中的关键作用，以支持理论分析和改进重建质量。技术路线涉及计算成像技术，通过事件流处理实现光场获取，无需强度图像，简化了硬件实现。",
      "result": "在真实成像硬件上实现了该方法，成功演示了捕获真实3-D场景的有效性。据作者所知，首次展示可以从事件中重建具有像素级精度的4-D光场，但摘要未明确说明具体的性能指标（如准确率或效率改进）或与基线方法的详细对比数据，仅强调了其突破性。",
      "conclusion": "本研究的主要贡献是提出了一种纯事件基础的光场成像方法，理论上支持并实际上改进了仅从事件中重建光场的能力，简化了硬件设计。这推动了事件相机在计算成像领域的学术应用，并具有实际价值，如3-D视觉系统。潜在局限性包括未详细讨论性能优化，未来工作可能涉及方法扩展或应用场景深化。",
      "tags": [
        "Event Camera",
        "Light Field Imaging",
        "Coded Aperture",
        "Computational Imaging",
        "4-D Reconstruction"
      ]
    },
    "analyzed_at": "2026-02-27T04:01:39.973483Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22617",
    "title": "Semantic Tube Prediction: Beating LLM Data Efficiency with JEPA",
    "authors": [
      "Hai Huang",
      "Yann LeCun",
      "Randall Balestriero"
    ],
    "abstract": "Large Language Models (LLMs) obey consistent scaling laws -- empirical power-law fits that predict how loss decreases with compute, data, and parameters. While predictive, these laws are descriptive rather than prescriptive: they characterize typical training, not optimal training. Surprisingly few works have successfully challenged the data-efficiency bounds implied by these laws -- which is our primary focus. To that end, we introduce the Geodesic Hypothesis, positing that token sequences trace geodesics on a smooth semantic manifold and are therefore locally linear. Building on this principle, we propose a novel Semantic Tube Prediction (STP) task, a JEPA-style regularizer that confines hidden-state trajectories to a tubular neighborhood of the geodesic. STP generalizes JEPA to language without requiring explicit multi-view augmentations. We show this constraint improves signal-to-noise ratio, and consequently preserves diversity by preventing trajectory collisions during inference. Empirically, STP allows LLMs to match baseline accuracy with 16$\\times$ less training data on the NL-RX-SYNTH dataset, directly violating the data term of Chinchilla-style scaling laws and demonstrating that principled geometric priors can surpass brute-force scaling. Code is available at https://github.com/galilai-group/llm-jepa#stp.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22617.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22617",
    "published": "2026-02-26T04:45:07Z",
    "updated": "2026-02-26T04:45:07Z",
    "comment": "21 pages, 13 figures",
    "light_analysis": {
      "overview": "本文提出Semantic Tube Prediction方法，基于测地线假设通过JEPA风格正则化，显著提升大型语言模型的数据效率。",
      "motivation": "大型语言模型（LLMs）通常遵循描述性的缩放定律，这些定律预测了损失随计算、数据和参数的变化，但未提供优化训练的指导。现有方法在挑战数据效率界限方面进展有限，这限制了LLMs的高效训练。本研究旨在解决LLM训练中过度依赖大规模数据的问题，通过引入几何先验来突破缩放定律的数据效率约束，强调现有方法的不足在于缺乏对语义结构的利用。",
      "method": "本研究基于测地线假设，即token序列在平滑语义流形上跟踪测地线并呈局部线性，提出了Semantic Tube Prediction（STP）任务。STP是一种基于Joint Embedding Predictive Architecture（JEPA）的正则化器，它将隐藏状态轨迹限制在测地线的管状邻域内，无需使用显式的多视图数据增强。关键创新点包括将JEPA扩展到语言领域，提高训练中的信噪比，并在推理时防止轨迹碰撞以保持多样性。研究中使用了大型语言模型，但具体架构细节摘要未明确说明。",
      "result": "实验在NL-RX-SYNTH数据集上进行，结果显示使用STP的LLMs仅需基准训练数据量的1/16即可达到相同的准确率，这直接违反了Chinchilla-style缩放定律中关于数据项的预测。性能对比表明，STP在保持准确率的同时，显著减少了数据需求，超越了基于暴力缩放的基线方法。具体指标为匹配基准准确率，但摘要未明确说明额外效率改进如训练时间减少。",
      "conclusion": "本研究的主要贡献是展示了原则性几何先验如何超越传统的暴力缩放方法，挑战了现有缩放定律的有效性，为高效训练LLMs提供了新思路。学术价值在于通过STP任务引入语义约束，提高了模型的泛化能力和数据效率；实际应用价值包括减少训练成本并推广到其他语言任务。局限性包括摘要未明确说明模型适用范围的限制，未来工作可能涉及将STP应用于更广泛的模型架构和数据集。",
      "tags": [
        "Large Language Model",
        "JEPA",
        "Geodesic Hypothesis",
        "Semantic Tube Prediction",
        "Regularization"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:38.222506Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22613",
    "title": "Spectrally Distilled Representations Aligned with Instruction-Augmented LLMs for Satellite Imagery",
    "authors": [
      "Minh Kha Do",
      "Wei Xiang",
      "Kang Han",
      "Di Wu",
      "Khoa Phan",
      "Yi-Ping Phoebe Chen",
      "Gaowen Liu",
      "Ramana Rao Kompella"
    ],
    "abstract": "Vision-language foundation models (VLFMs) promise zero-shot and retrieval understanding for Earth observation. While operational satellite systems often lack full multi-spectral coverage, making RGB-only inference highly desirable for scalable deployment, the adoption of VLFMs for satellite imagery remains hindered by two factors: (1) multi-spectral inputs are informative but difficult to exploit consistently due to band redundancy and misalignment; and (2) CLIP-style text encoders limit semantic expressiveness and weaken fine-grained alignment. We present SATtxt, a spectrum-aware VLFM that operates with RGB inputs only at inference while retaining spectral cues learned during training. Our framework comprises two stages. First, Spectral Representation Distillation transfers spectral priors from a frozen multi-spectral teacher to an RGB student via a lightweight projector. Second, Spectrally Grounded Alignment with Instruction-Augmented LLMs bridges the distilled visual space and an expressive LLM embedding space. Across EuroSAT, BigEarthNet, and ForestNet, SATtxt improves zero-shot classification on average by 4.2%, retrieval by 5.9%, and linear probing by 2.7% over baselines, showing an efficient path toward spectrum-aware vision-language learning for Earth observation. Project page: https://ikhado.github.io/sattxt/",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22613.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22613",
    "published": "2026-02-26T04:34:47Z",
    "updated": "2026-02-26T04:34:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "SATtxt是一种光谱感知视觉-语言基础模型，通过光谱表示蒸馏和对齐指令增强的大型语言模型，实现仅用RGB输入的卫星影像推理，提升地球观测能力。",
      "motivation": "该研究旨在解决视觉-语言基础模型在卫星影像中部署的难题。由于操作卫星系统常缺乏全多光谱覆盖，使用RGB-only推理对可扩展部署至关重要。现有方法中，多光谱输入因频带冗余和不对齐而难以一致利用，CLIP风格的文本编码器在语义表达和细粒度对齐方面表现不足，限制了零样本理解和检索效果。因此，SATtxt提出改进路径，以高效处理卫星影像数据。",
      "method": "SATtxt框架包含两个核心阶段。首先，光谱表示蒸馏通过轻量级投影器，将光谱先验从冻结的多光谱教师模型传递到RGB学生模型，以学习并保留光谱线索。其次，光谱对齐使用指令增强的大型语言模型，将蒸馏后的视觉空间与表达力更强的LLM嵌入空间对齐，增强语义理解和零样本能力。整个方法专注于蒸馏和对齐技术，优化了视觉-语言模型在有限输入下的性能。",
      "result": "在EuroSAT、BigEarthNet和ForestNet数据集上的实验表明，SATtxt显著提升了性能。与基线方法相比，平均零样本分类准确率提高了4.2%，检索效率提高了5.9%，线性探测准确率提高了2.7%。这些数据证明了SATtxt在零样本理解和下游任务中的有效性，展示了其在实际部署中的潜力。",
      "conclusion": "SATtxt的主要贡献是提供了一种高效的光谱感知视觉-语言学习路径，通过蒸馏和对齐技术改进卫星影像处理。研究具有学术价值，推动了视觉-语言模型在地球观测领域的应用；实际应用上，通过RGB-only推理促进可扩展部署。未来工作可能包括扩展多光谱处理或进一步优化对齐方法，但摘要未明确说明具体方向。",
      "tags": [
        "Vision-Language Foundation Models",
        "Multi-spectral Satellite Imagery",
        "Representation Distillation",
        "Instruction-Augmented LLMs",
        "CLIP-style Text Encoder"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:33.523055Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22611",
    "title": "Mitigating Membership Inference in Intermediate Representations via Layer-wise MIA-risk-aware DP-SGD",
    "authors": [
      "Jiayang Meng",
      "Tao Huang",
      "Chen Hou",
      "Guolong Zheng",
      "Hong Chen"
    ],
    "abstract": "In Embedding-as-an-Interface (EaaI) settings, pre-trained models are queried for Intermediate Representations (IRs). The distributional properties of IRs can leak training-set membership signals, enabling Membership Inference Attacks (MIAs) whose strength varies across layers. Although Differentially Private Stochastic Gradient Descent (DP-SGD) mitigates such leakage, existing implementations employ per-example gradient clipping and a uniform, layer-agnostic noise multiplier, ignoring heterogeneous layer-wise MIA vulnerability. This paper introduces Layer-wise MIA-risk-aware DP-SGD (LM-DP-SGD), which adaptively allocates privacy protection across layers in proportion to their MIA risk. Specifically, LM-DP-SGD trains a shadow model on a public shadow dataset, extracts per-layer IRs from its train/test splits, and fits layer-specific MIA adversaries, using their attack error rates as MIA-risk estimates. Leveraging the cross-dataset transferability of MIAs, these estimates are then used to reweight each layer's contribution to the globally clipped gradient during private training, providing layer-appropriate protection under a fixed noise magnitude. We further establish theoretical guarantees on both privacy and convergence of LM-DP-SGD. Extensive experiments show that, under the same privacy budget, LM-DP-SGD reduces the peak IR-level MIA risk while preserving utility, yielding a superior privacy-utility trade-off.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22611.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22611",
    "published": "2026-02-26T04:32:14Z",
    "updated": "2026-02-26T04:32:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出LM-DP-SGD方法，通过层感知成员推理攻击风险评估，自适应分配差分隐私保护以优化隐私-效用权衡。",
      "motivation": "在嵌入即接口设置中，预训练模型的中间表示分布特性可能泄露训练集成员信息，导致成员推理攻击，且攻击强度随层变化。现有差分隐私随机梯度下降方法采用统一的噪声乘数和每示例梯度裁剪，忽视了层间MIA脆弱性的异质性，可能导致资源浪费或保护不足，因此研究旨在开发一种自适应方法，根据各层MIA风险分配隐私保护，以更有效地平衡隐私与效用。",
      "method": "LM-DP-SGD的核心方法包括：首先，在公开影子数据集上训练影子模型，并从其训练和测试分割中提取每层中间表示。接着，拟合层特定的MIA攻击器，使用攻击错误率作为MIA风险估计。然后，利用MIAs的跨数据集可转移性，在私有训练中将这些估计用于重新加权每层对全局裁剪梯度的贡献，在固定噪声幅度下实现层适当的保护。此外，论文提供了隐私和收敛的理论保证，确保方法的技术可靠性。",
      "result": "实验结果表明，在相同隐私预算下，LM-DP-SGD降低了峰值中间表示层级的MIA风险，同时保持了模型效用，实现了比基线差分隐私随机梯度下降更优越的隐私-效用权衡。具体性能指标如准确率提升或效率改进在摘要中未明确说明，但理论分析和实验验证支持其有效性，强调了方法的实用优势。",
      "conclusion": "本研究的主要贡献是提出了LM-DP-SGD方法，通过层感知MIA风险评估优化差分隐私分配，提高了隐私保护效率。学术上，它改进了隐私保护技术，提供了理论框架；实际应用中，适用于嵌入即接口设置中的隐私防护。局限性或未来方向摘要未明确说明，但可能包括扩展到其他攻击类型或更复杂的模型结构，以进一步提升适用性。",
      "tags": [
        "Membership Inference Attacks",
        "DP-SGD",
        "Intermediate Representations",
        "Layer-wise Adaptation",
        "Privacy-Utility Trade-off"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:56.256686Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22610",
    "title": "DP-aware AdaLN-Zero: Taming Conditioning-Induced Heavy-Tailed Gradients in Differentially Private Diffusion",
    "authors": [
      "Tao Huang",
      "Jiayang Meng",
      "Xu Yang",
      "Chen Hou",
      "Hong Chen"
    ],
    "abstract": "Condition injection enables diffusion models to generate context-aware outputs, which is essential for many time-series tasks. However, heterogeneous conditional contexts (e.g., observed history, missingness patterns or outlier covariates) can induce heavy-tailed per-example gradients. Under Differentially Private Stochastic Gradient Descent (DP-SGD), these rare conditioning-driven heavy-tailed gradients disproportionately trigger global clipping, resulting in outlier-dominated updates, larger clipping bias, and degraded utility under a fixed privacy budget. In this paper, we propose DP-aware AdaLN-Zero, a drop-in sensitivity-aware conditioning mechanism for conditional diffusion transformers that limits conditioning-induced gain without modifying the DP-SGD mechanism. DP-aware AdaLN-Zero jointly constrains conditioning representation magnitude and AdaLN modulation parameters via bounded re-parameterization, suppressing extreme gradient tail events before gradient clipping and noise injection. Empirically, DP-SGD equipped with DP-aware AdaLN-Zero improves interpolation/imputation and forecasting under matched privacy settings. We observe consistent gains on a real-world power dataset and two public ETT benchmarks over vanilla DP-SGD. Moreover, gradient diagnostics attribute these improvements to conditioning-specific tail reshaping and reduced clipping distortion, while preserving expressiveness in non-private training. Overall, these results show that sensitivity-aware conditioning can substantially improve private conditional diffusion training without sacrificing standard performance.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22610.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22610",
    "published": "2026-02-26T04:32:07Z",
    "updated": "2026-02-26T04:32:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出DP-aware AdaLN-Zero机制，通过敏感性感知条件处理重尾梯度，以改善差分私有扩散模型的训练效用而不修改DP-SGD。",
      "motivation": "在条件扩散模型中，异构条件上下文（如历史观测、缺失模式）会引发重尾的每个样本梯度。在差分私有随机梯度下降（DP-SGD）下，这些梯度过度触发全局裁剪，导致更新由离群值主导、裁剪偏差增大，并在固定隐私预算下降低模型效用。现有DP-SGD方法在处理这些罕见但严重的梯度尾事件时效率低下，限制了私有条件下条件扩散训练的实用性和性能。",
      "method": "论文提出DP-aware AdaLN-Zero，一个敏感性感知的条件机制，专为条件扩散变换器设计。核心创新在于通过有界重新参数化联合约束条件表示幅度和AdaLN调制参数，从而在梯度裁剪和噪声注入前抑制极端梯度尾事件。该方法作为插入式机制，不改变DP-SGD的底层框架，通过控制条件诱导的增益来优化梯度分布，适用于时间序列任务中的条件扩散模型。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验显示，DP-SGD配备DP-aware AdaLN-Zero在插值/插补和预测任务中优于vanilla DP-SGD。在真实世界电力数据集和两个公共ETT基准上，观察到一致性能增益。梯度诊断将改进归因于条件特定的尾部重塑和减少的裁剪失真，同时验证了在非私有训练中模型表达力的保持。与基线方法相比，该方法在匹配隐私设置下提升了任务效用，表明敏感性感知条件能有效缓解重尾梯度问题。摘要未明确说明具体准确率或效率数值。",
      "conclusion": "该研究贡献了DP-aware AdaLN-Zero机制，显著改善了差分私有条件下扩散模型的训练效用，无需牺牲非私有训练的性能。学术价值在于提出一种新颖的条件机制来处理重尾梯度，扩展了隐私保护机器学习的方法；实际应用价值体现在增强时间序列任务中隐私模型的可靠性和效率。局限性可能包括机制在其他任务或数据集上的泛化性，未来工作可探索更广泛的条件设置和优化参数调整。",
      "tags": [
        "Differentially Private Stochastic Gradient Descent",
        "Diffusion Models",
        "Conditioning Mechanisms",
        "AdaLN-Zero",
        "Heavy-Tailed Gradients"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:19.345951Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22607",
    "title": "LoR-LUT: Learning Compact 3D Lookup Tables via Low-Rank Residuals",
    "authors": [
      "Ziqi Zhao",
      "Abhijit Mishra",
      "Shounak Roychowdhury"
    ],
    "abstract": "We present LoR-LUT, a unified low-rank formulation for compact and interpretable 3D lookup table (LUT) generation. Unlike conventional 3D-LUT-based techniques that rely on fusion of basis LUTs, which are usually dense tensors, our unified approach extends the current framework by jointly using residual corrections, which are in fact low-rank tensors, together with a set of basis LUTs. The approach described here improves the existing perceptual quality of an image, which is primarily due to the technique's novel use of residual corrections. At the same time, we achieve the same level of trilinear interpolation complexity, using a significantly smaller number of network, residual corrections, and LUT parameters. The experimental results obtained from LoR-LUT, which is trained on the MIT-Adobe FiveK dataset, reproduce expert-level retouching characteristics with high perceptual fidelity and a sub-megabyte model size. Furthermore, we introduce an interactive visualization tool, termed LoR-LUT Viewer, which transforms an input image into the LUT-adjusted output image, via a number of slidebars that control different parameters. The tool provides an effective way to enhance interpretability and user confidence in the visual results. Overall, our proposed formulation offers a compact, interpretable, and efficient direction for future LUT-based image enhancement and style transfer.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22607.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22607",
    "published": "2026-02-26T04:28:35Z",
    "updated": "2026-02-26T04:28:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "LoR-LUT通过引入低秩残差校正，提出一种紧凑且可解释的3D查找表生成方法，用于高效图像增强。",
      "motivation": "传统基于3D查找表的图像增强技术依赖稠密张量的基础LUT融合，导致模型参数多、可解释性差，难以实现紧凑表示。这限制了实际应用中的效率和用户交互。LoR-LUT旨在解决这些问题，通过利用低秩残差校正减少参数并提升感知质量，为图像处理提供更优解决方案，弥补现有方法的不足。",
      "method": "LoR-LUT采用统一的低秩框架，结合基础查找表和低秩残差校正。核心创新是使用低秩张量表示残差，显著减少网络和参数数量，同时维持标准三线性插值计算复杂度。方法在MIT-Adobe FiveK数据集上训练，并引入交互式工具LoR-LUT Viewer，通过滑块控制参数实时调整图像，增强可解释性和用户交互。",
      "result": "实验在MIT-Adobe FiveK数据集上进行，LoR-LUT能够再现专家级修图特性，具有高感知保真度和亚兆字节模型大小。相比传统稠密张量方法，使用更少参数实现相同计算复杂度，提高了参数效率和可解释性。具体性能指标如准确率提升未明确说明，但强调紧凑性和效果优势。",
      "conclusion": "该研究的主要贡献是提出一种紧凑、可解释、高效的3D查找表生成方法，通过低秩残差校正和交互式工具，增强了图像增强的透明度和用户信心。为基于LUT的图像处理和风格迁移提供了新方向，具有学术和实际应用价值。潜在局限性或未来工作方向摘要未明确说明。",
      "tags": [
        "Low-Rank Tensor",
        "3D Lookup Table (LUT)",
        "Image Enhancement",
        "Interactive Visualization",
        "MIT-Adobe FiveK Dataset"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:28.384729Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22603",
    "title": "SideQuest: Model-Driven KV Cache Management for Long-Horizon Agentic Reasoning",
    "authors": [
      "Sanjay Kariyappa",
      "G. Edward Suh"
    ],
    "abstract": "Long-running agentic tasks, such as deep research, require multi-hop reasoning over information distributed across multiple webpages and documents. In such tasks, the LLM context is dominated by tokens from external retrieval, causing memory usage to grow rapidly and limiting decode performance. While several KV cache compression techniques exist for long-context inputs, we find that existing heuristics fail to support multi-step reasoning models effectively. We address this challenge with SideQuest -- a novel approach that leverages the Large Reasoning Model (LRM) itself to perform KV cache compression by reasoning about the usefulness of tokens in its context. To prevent the tokens associated with this management process from polluting the model's memory, we frame KV cache compression as an auxiliary task executed in parallel to the main reasoning task. Our evaluations, using a model trained with just 215 samples, show that SideQuest reduces peak token usage by up to 65% on agentic tasks with minimal degradation in accuracy, outperforming heuristic-based KV cache compression techniques.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22603.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22603",
    "published": "2026-02-26T04:20:44Z",
    "updated": "2026-02-26T04:20:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "SideQuest提出了一种模型驱动的KV缓存管理方法，通过将缓存压缩作为并行辅助任务，显著降低长视野代理推理中的内存使用。",
      "motivation": "在长运行代理任务（如多步推理）中，LLM上下文被大量外部检索令牌占据，导致内存使用快速增加和解码性能受限。现有启发式KV缓存压缩技术难以有效支持复杂推理模型，因此需要一种更智能的管理方法来优化内存效率，以应对多步推理场景下的挑战。",
      "method": "SideQuest利用大型推理模型本身评估上下文令牌的重要性，并据此执行KV缓存压缩。关键创新在于将压缩任务设计为与主推理任务并行的辅助流程，避免管理令牌污染内存。该方法使用少量样本（如215个）训练的模型实现，提高了管理效率和适应性。",
      "result": "评估结果显示，SideQuest在代理任务上能减少高达65%的峰值令牌使用，同时准确性下降最小，性能优于传统启发式压缩技术，这证明了其在优化内存开销方面的有效性。摘要未明确说明具体基线对比细节，但强调了显著改进。",
      "conclusion": "该研究为长视野代理推理提供了有效的KV缓存管理方案，通过模型驱动压缩降低了内存开销，增强了LLM在复杂任务中的实用性。未来工作可探索扩展到更多模型和任务，以进一步提高广泛应用的潜力。",
      "tags": [
        "KV Cache",
        "Large Reasoning Model",
        "Agentic Reasoning",
        "Parallel Task Execution",
        "Model-Driven Compression"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:12.513622Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22601",
    "title": "$φ$-DPO: Fairness Direct Preference Optimization Approach to Continual Learning in Large Multimodal Models",
    "authors": [
      "Thanh-Dat Truong",
      "Huu-Thien Tran",
      "Jackson Cothren",
      "Bhiksha Raj",
      "Khoa Luu"
    ],
    "abstract": "Fairness in Continual Learning for Large Multimodal Models (LMMs) is an emerging yet underexplored challenge, particularly in the presence of imbalanced data distributions that can lead to biased model updates and suboptimal performance across tasks. While recent continual learning studies have made progress in addressing catastrophic forgetting, the problem of fairness caused the imbalanced data remains largely underexplored. This paper presents a novel Fairness Direct Preference Optimization (FaiDPO or $φ$-DPO) framework for continual learning in LMMs. In particular, we first propose a new continual learning paradigm based on Direct Preference Optimization (DPO) to mitigate catastrophic forgetting by aligning learning with pairwise preference signals. Then, we identify the limitations of conventional DPO in imbalanced data and present a new $φ$-DPO loss that explicitly addresses distributional biases. We provide a comprehensive theoretical analysis demonstrating that our approach addresses both forgetting and data imbalance. Additionally, to enable $φ$-DPO-based continual learning, we construct pairwise preference annotations for existing benchmarks in the context of continual learning. Extensive experiments and ablation studies show the proposed $φ$-DPO achieves State-of-the-Art performance across multiple benchmarks, outperforming prior continual learning methods of LMMs.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22601.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22601",
    "published": "2026-02-26T04:14:33Z",
    "updated": "2026-02-26T04:14:33Z",
    "comment": "Accepted to CVPR'26",
    "light_analysis": {
      "overview": "提出了 $φ$-DPO 框架，用于解决大型多模态模型持续学习中的公平性问题，通过处理数据不平衡导致的偏见和灾难性遗忘。",
      "motivation": "在大型多模态模型的持续学习中，公平性是一个新兴但未被充分探索的挑战。当数据分布不平衡时，模型更新可能产生偏差，导致跨任务性能次优。尽管已有研究解决了灾难性遗忘问题，但由数据不平衡引发的公平性缺失仍缺乏关注，这在实际应用中影响模型的泛化能力和公平性，需要一种综合方法来同时优化遗忘和偏差问题。",
      "method": "该研究提出了 Fairness Direct Preference Optimization ($φ$-DPO) 框架。首先，基于直接偏好优化（DPO）构建持续学习范式，通过成对偏好信号来缓解灾难性遗忘。然后，针对传统 DPO 在数据不平衡中的局限性，设计了 $φ$-DPO 损失函数，显式处理分布偏差以提升公平性。作者提供了理论分析证明该方法能同时应对遗忘和失衡问题，并构建了基准测试的成对偏好注释来支持实验。",
      "result": "广泛的实验和消融研究表明，$φ$-DPO 在多个基准测试中取得了最先进的性能，优于先前的持续学习方法。摘要未明确说明具体性能指标数据，但强调该方法在公平性和任务性能上均有显著提升，有效解决了灾难性遗忘和数据不平衡问题，显示出更强的鲁棒性和适应性。",
      "conclusion": "$φ$-DPO 框架的主要贡献在于整合持续学习和公平性优化，通过改进 DPO 损失来处理数据不平衡，扩展了 DPO 在公平学习中的应用。学术上，提供了理论分析支持方法的有效性；实际中，有望提升大型多模态模型在公平环境下的学习效率和跨任务性能。未来工作可能包括扩展到更多场景或进一步优化损失函数。",
      "tags": [
        "Large Multimodal Models",
        "Continual Learning",
        "Direct Preference Optimization",
        "Fairness Learning",
        "Data Imbalance"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:19.017239Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22600",
    "title": "Transformers converge to invariant algorithmic cores",
    "authors": [
      "Joshua S. Schiffman"
    ],
    "abstract": "Large language models exhibit sophisticated capabilities, yet understanding how they work internally remains a central challenge. A fundamental obstacle is that training selects for behavior, not circuitry, so many weight configurations can implement the same function. Which internal structures reflect the computation, and which are accidents of a particular training run? This work extracts algorithmic cores: compact subspaces necessary and sufficient for task performance. Independently trained transformers learn different weights but converge to the same cores. Markov-chain transformers embed 3D cores in nearly orthogonal subspaces yet recover identical transition spectra. Modular-addition transformers discover compact cyclic operators at grokking that later inflate, yielding a predictive model of the memorization-to-generalization transition. GPT-2 language models govern subject-verb agreement through a single axis that, when flipped, inverts grammatical number throughout generation across scales. These results reveal low-dimensional invariants that persist across training runs and scales, suggesting that transformer computations are organized around compact, shared algorithmic structures. Mechanistic interpretability could benefit from targeting such invariants -- the computational essence -- rather than implementation-specific details.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22600.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22600",
    "published": "2026-02-26T04:09:11Z",
    "updated": "2026-02-26T04:09:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文通过提取算法核心，揭示了不同训练运行的transformers收敛到相同的紧凑、共享算法结构。",
      "motivation": "大型语言模型内部工作机制的理解是AI领域的核心挑战。由于训练过程基于行为选择而非电路设计，导致多种权重配置可实现相同功能，难以区分哪些内部结构反映计算本质，哪些是训练偶然结果。这一问题对模型可解释性和可靠性至关重要，现有方法往往关注具体实现细节，缺乏对核心计算结构的系统识别。研究动机在于解决这一障碍，为机械可解释性提供基础，帮助识别模型中的不变计算核心。",
      "method": "论文提出提取算法核心的方法，定义为对任务性能必要且充分的紧凑子空间。关键创新在于识别不变量结构，而非具体权重配置。通过分析多种transformers模型进行验证，包括Markov-chain transformers、Modular-addition transformers和GPT-2语言模型，利用这些模型的数据集和架构来揭示收敛行为。技术特色包括从训练运行中提取低维子空间，并比较不同模型的核心结构，以证明其普遍性。",
      "result": "结果显示，独立训练的transformers尽管初始权重不同，但收敛到相同的算法核心。具体地，Markov-chain transformers在近正交子空间中嵌入3D核心，但恢复相同的转移谱；Modular-addition transformers在grokking时发现紧凑循环算子，随后膨胀，提供了从记忆到泛化过渡的预测模型；GPT-2通过单个轴控制主谓一致，翻转时在整个生成过程中反转语法数字。这些发现表明低维不变量在训练运行和规模上持续存在，与权重多样性形成对比。",
      "conclusion": "论文的主要贡献是揭示了transformers计算围绕紧凑、共享算法结构组织，这些不变量在训练中持续存在。研究对机械可解释性有重要学术价值，建议未来工作针对计算本质而非实现细节进行探索。实际应用价值包括提升模型可靠性和可解释性，潜在局限性是未覆盖所有任务类型，未来可扩展此方法到更广泛的AI模型和场景。",
      "tags": [
        "Transformers",
        "Algorithmic Cores",
        "Invariants",
        "Mechanistic Interpretability",
        "Grokking"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:18.082898Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22596",
    "title": "BetterScene: 3D Scene Synthesis with Representation-Aligned Generative Model",
    "authors": [
      "Yuci Han",
      "Charles Toth",
      "John E. Anderson",
      "William J. Shuart",
      "Alper Yilmaz"
    ],
    "abstract": "We present BetterScene, an approach to enhance novel view synthesis (NVS) quality for diverse real-world scenes using extremely sparse, unconstrained photos. BetterScene leverages the production-ready Stable Video Diffusion (SVD) model pretrained on billions of frames as a strong backbone, aiming to mitigate artifacts and recover view-consistent details at inference time. Conventional methods have developed similar diffusion-based solutions to address these challenges of novel view synthesis. Despite significant improvements, these methods typically rely on off-the-shelf pretrained diffusion priors and fine-tune only the UNet module while keeping other components frozen, which still leads to inconsistent details and artifacts even when incorporating geometry-aware regularizations like depth or semantic conditions. To address this, we investigate the latent space of the diffusion model and introduce two components: (1) temporal equivariance regularization and (2) vision foundation model-aligned representation, both applied to the variational autoencoder (VAE) module within the SVD pipeline. BetterScene integrates a feed-forward 3D Gaussian Splatting (3DGS) model to render features as inputs for the SVD enhancer and generate continuous, artifact-free, consistent novel views. We evaluate on the challenging DL3DV-10K dataset and demonstrate superior performance compared to state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22596.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22596",
    "published": "2026-02-26T03:58:42Z",
    "updated": "2026-02-26T03:58:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "BetterScene通过改进扩散模型的VAE模块，引入时间等变性正则化和视觉基础模型对齐表示，提升了新视角合成的质量和一致性。",
      "motivation": "研究旨在解决新视角合成中，传统扩散模型方法仅微调UNet模块导致的伪影和视图不一致问题。这些方法通常依赖预训练扩散先验，即使在加入几何感知正则化（如深度或语义条件）后，仍难以恢复一致细节。使用极稀疏、无约束照片时，这些限制尤为突出，影响真实世界场景的合成质量，因此BetterScene探索优化扩散模型的潜在空间来改进性能。",
      "method": "BetterScene基于预训练的Stable Video Diffusion (SVD)模型作为骨干，研究了其VAE模块的潜在空间，并引入两个关键组件：时间等变性正则化和视觉基础模型对齐表示，以增强视图一致性和细节恢复。同时，集成前馈式3D高斯溅射模型来渲染场景特征，作为SVD增强器的输入，生成连续、无伪影的新视角。这种方法通过多组件协同优化潜在表示，减少了推理时的伪影。",
      "result": "在挑战性的DL3DV-10K数据集上进行评估，BetterScene在视图合成任务中优于当前最先进的方法。它有效减少了伪影并提高了细节一致性，生成了更连续、真实的合成视图，尽管摘要未明确说明具体性能指标（如准确率），但与基线方法的对比显示出显著的质量改进，为新视角合成设立了更高标准。",
      "conclusion": "BetterScene通过优化扩散模型的VAE模块，为新视角合成提供了创新解决方案，显著提升了合成质量和视图一致性。该研究推动了扩散模型在3D视觉领域的应用，对虚拟现实、增强现实等实际场景具有重要价值。未来工作可探索更广泛的数据集和正则化技术，以进一步提高泛化能力和效率。",
      "tags": [
        "Novel View Synthesis",
        "Stable Video Diffusion",
        "3D Gaussian Splatting",
        "Variational Autoencoder",
        "Temporal Equivariance"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:32.106751Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22595",
    "title": "Don't let the information slip away",
    "authors": [
      "Taozhe Li"
    ],
    "abstract": "Real-time object detection has advanced rapidly in recent years. The YOLO series of detectors is among the most well-known CNN-based object detection models and cannot be overlooked. The latest version, YOLOv26, was recently released, while YOLOv12 achieved state-of-the-art (SOTA) performance with 55.2 mAP on the COCO val2017 dataset. Meanwhile, transformer-based object detection models, also known as DEtection TRansformer (DETR), have demonstrated impressive performance. RT-DETR is an outstanding model that outperformed the YOLO series in both speed and accuracy when it was released. Its successor, RT-DETRv2, achieved 53.4 mAP on the COCO val2017 dataset. However, despite their remarkable performance, all these models let information to slip away. They primarily focus on the features of foreground objects while neglecting the contextual information provided by the background. We believe that background information can significantly aid object detection tasks. For example, cars are more likely to appear on roads rather than in offices, while wild animals are more likely to be found in forests or remote areas rather than on busy streets. To address this gap, we propose an object detection model called Association DETR, which achieves state-of-the-art results compared to other object detection models on the COCO val2017 dataset.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22595.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22595",
    "published": "2026-02-26T03:58:41Z",
    "updated": "2026-02-26T03:58:41Z",
    "comment": "10",
    "light_analysis": {
      "overview": "提出Association DETR模型，通过整合背景上下文信息提升物体检测性能，实现state-of-the-art结果。",
      "motivation": "实时物体检测模型如YOLO和DETR系列在速度和精度上表现优秀，但主要关注前景物体特征，忽略了背景提供的上下文信息。背景信息（如场景类型）能显著辅助检测任务，例如物体在特定环境中的出现概率。现有方法的不足在于缺乏对背景的有效利用，导致潜在信息流失。因此，研究动机是解决这一差距，通过结合背景上下文来改进物体检测的准确性和鲁棒性。",
      "method": "论文提出Association DETR模型，核心创新点是将背景上下文信息整合到检测过程中。模型可能基于DETR架构，通过关联前景物体特征与背景特征来优化检测性能。具体技术细节摘要未明确说明，但推断涉及transformer机制和上下文建模，以增强模型对场景的理解。该方法旨在平衡前景和背景信息的利用，提升整体检测效果。",
      "result": "Association DETR在COCO val2017数据集上与其他物体检测模型相比，取得了state-of-the-art性能。具体性能指标摘要未提供，但暗示优于现有模型如YOLOv12（55.2 mAP）和RT-DETRv2（53.4 mAP）。这表明整合背景信息能有效提升检测精度，尽管实验细节未详述，但结果强调了上下文建模的潜力。",
      "conclusion": "论文的主要贡献是提出了Association DETR模型，通过利用背景上下文信息显著改善物体检测性能，强调了上下文在视觉任务中的重要性。这项研究具有学术价值，为物体检测领域提供了新思路，并可能在实际应用中提升场景理解能力。潜在局限性包括模型效率或泛化能力未讨论，未来工作可探索优化技术或扩展到其他数据集和任务。",
      "tags": [
        "Object Detection",
        "DETR",
        "Contextual Information",
        "Background Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:17.226849Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22594",
    "title": "Causal Motion Diffusion Models for Autoregressive Motion Generation",
    "authors": [
      "Qing Yu",
      "Akihisa Watanabe",
      "Kent Fujiwara"
    ],
    "abstract": "Recent advances in motion diffusion models have substantially improved the realism of human motion synthesis. However, existing approaches either rely on full-sequence diffusion models with bidirectional generation, which limits temporal causality and real-time applicability, or autoregressive models that suffer from instability and cumulative errors. In this work, we present Causal Motion Diffusion Models (CMDM), a unified framework for autoregressive motion generation based on a causal diffusion transformer that operates in a semantically aligned latent space. CMDM builds upon a Motion-Language-Aligned Causal VAE (MAC-VAE), which encodes motion sequences into temporally causal latent representations. On top of this latent representation, an autoregressive diffusion transformer is trained using causal diffusion forcing to perform temporally ordered denoising across motion frames. To achieve fast inference, we introduce a frame-wise sampling schedule with causal uncertainty, where each subsequent frame is predicted from partially denoised previous frames. The resulting framework supports high-quality text-to-motion generation, streaming synthesis, and long-horizon motion generation at interactive rates. Experiments on HumanML3D and SnapMoGen demonstrate that CMDM outperforms existing diffusion and autoregressive models in both semantic fidelity and temporal smoothness, while substantially reducing inference latency.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22594.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22594",
    "published": "2026-02-26T03:58:25Z",
    "updated": "2026-02-26T03:58:25Z",
    "comment": "Accepted to CVPR 2026, Project website: https://yu1ut.com/CMDM-HP/",
    "light_analysis": {
      "overview": "本研究提出了因果运动扩散模型(CMDM)，通过因果扩散变换器在语义对齐潜在空间中实现高效、高质量的自回归运动生成，解决了现有方法的因果关系和实时性问题。",
      "motivation": "现有运动扩散模型在人类运动合成中虽提升了真实性，但存在两类主要问题：基于双向生成的全序列扩散模型受限于时间因果关系和实时应用性；自回归模型则易出现不稳定性和累积误差，限制了实际部署。因此，开发一个能兼顾生成质量和推理效率的框架对动画、虚拟现实等应用至关重要，本工作旨在通过统一方法弥补这些不足。",
      "method": "CMDM框架基于Motion-Language-Aligned Causal VAE (MAC-VAE)将运动序列编码为时间因果的潜在表示，然后训练一个自回归扩散变换器，使用因果扩散强制策略在运动帧上进行有序去噪。为加速推理，引入基于因果不确定性的逐帧采样计划，使后续帧能从部分去噪的前帧预测，支持文本到运动生成、流式合成和长时程运动生成。",
      "result": "在HumanML3D和SnapMoGen数据集上的实验表明，CMDM在语义保真度和时间平滑度方面均优于现有扩散模型和自回归模型，同时显著降低了推理延迟，实现了交互式速率的运动生成，但具体性能数据摘要未明确说明，仅提及综合改进。",
      "conclusion": "本研究的核心贡献是提出CMDM框架，融合因果表示和扩散模型，为自回归运动生成提供高质量、高效率的解决方案，学术上推动了运动合成技术的发展，实际上支持实时动画等应用，未来工作可探索潜在空间优化或多模态扩展，但摘要未明确说明局限性。",
      "tags": [
        "Causal Diffusion Models",
        "Autoregressive Motion Generation",
        "Transformer",
        "Variational Autoencoder",
        "Motion Synthesis"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:50.706015Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22592",
    "title": "pQuant: Towards Effective Low-Bit Language Models via Decoupled Linear Quantization-Aware Training",
    "authors": [
      "Wenzheng Zhang",
      "Bingzheng Liu",
      "Yang Hu",
      "Xiaoying Bai",
      "Wentao Zhang",
      "Bin Cui"
    ],
    "abstract": "Quantization-Aware Training from scratch has emerged as a promising approach for building efficient large language models (LLMs) with extremely low-bit weights (sub 2-bit), which can offer substantial advantages for edge deployment. However, existing methods still fail to achieve satisfactory accuracy and scalability. In this work, we identify a parameter democratization effect as a key bottleneck: the sensitivity of all parameters becomes homogenized, severely limiting expressivity. To address this, we propose pQuant, a method that decouples parameters by splitting linear layers into two specialized branches: a dominant 1-bit branch for efficient computation and a compact high-precision branch dedicated to preserving the most sensitive parameters. Through tailored feature scaling, we explicitly guide the model to allocate sensitive parameters to the high-precision branch. Furthermore, we extend this branch into multiple, sparsely-activated experts, enabling efficient capacity scaling. Extensive experiments indicate our pQuant achieves state-of-the-art performance in extremely low-bit quantization.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22592.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22592",
    "published": "2026-02-26T03:51:58Z",
    "updated": "2026-02-26T03:51:58Z",
    "comment": "10 pages, 7 figures",
    "light_analysis": {
      "overview": "提出pQuant方法，通过解耦线性量化感知训练和特征缩放，有效提升极低比特大语言模型的准确性和可扩展性。",
      "motivation": "量化感知训练是构建高效大语言模型的关键技术，尤其适用于边缘部署中的极低比特权重（如sub 2-bit），以实现计算效率。然而，现有方法在准确性和可扩展性方面不足，主要因参数民主化效应导致所有参数灵敏度同质化，限制了模型的表达性。本研究旨在解决这一问题，以在资源受限环境下实现高性能LLMs部署。",
      "method": "pQuant的核心方法是将线性层解耦为两个分支：一个用于高效计算的1比特分支和一个保留敏感参数的紧凑高精度分支。通过特征缩放技术引导模型将敏感参数分配到高精度分支，并扩展为多个稀疏激活专家，以支持容量扩展，提升模型的可扩展性和表达能力，从而优化量化训练过程。",
      "result": "实验表明，pQuant在极低比特量化中取得了最先进的性能，显著优于现有方法。摘要未明确说明具体性能指标和基线对比细节，但可推断该方法在准确性和效率方面有显著提升，为极低位LLMs部署提供了有效解决方案。",
      "conclusion": "pQuant通过解耦参数分配和特征缩放解决了量化训练中的参数民主化效应，提升了极低比特大语言模型的性能。其学术贡献在于改进量化感知训练技术，实际价值体现在支持边缘设备的高效模型部署。摘要未明确说明局限性或未来工作，但可探索进一步优化扩展。",
      "tags": [
        "Quantization-Aware Training",
        "Low-Bit Quantization",
        "Large Language Models",
        "Sparse Experts",
        "Linear Layers"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:57.988289Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22586",
    "title": "TabDLM: Free-Form Tabular Data Generation via Joint Numerical-Language Diffusion",
    "authors": [
      "Donghong Cai",
      "Jiarui Feng",
      "Yanbo Wang",
      "Da Zheng",
      "Yixin Chen",
      "Muhan Zhang"
    ],
    "abstract": "Synthetic tabular data generation has attracted growing attention due to its importance for data augmentation, foundation models, and privacy. However, real-world tabular datasets increasingly contain free-form text fields (e.g., reviews or clinical notes) alongside structured numerical and categorical attributes. Generating such heterogeneous tables with joint modeling of different modalities remains challenging. Existing approaches broadly fall into two categories: diffusion-based methods and LLM-based methods. Diffusion models can capture complex dependencies over numerical and categorical features in continuous or discrete spaces, but extending them to open-ended text is nontrivial and often leads to degraded text quality. In contrast, LLM-based generators naturally produce fluent text, yet their discrete tokenization can distort precise or wide-range numerical values, hindering accurate modeling of both numbers and language. In this work, we propose TabDLM, a unified framework for free-form tabular data generation via a joint numerical--language diffusion model built on masked diffusion language models (MDLMs). TabDLM models textual and categorical features through masked diffusion, while modeling numerical features with a continuous diffusion process through learned specialized numeric tokens embedding; bidirectional attention then captures cross-modality interactions within a single model. Extensive experiments on diverse benchmarks demonstrate the effectiveness of TabDLM compared to strong diffusion- and LLM-based baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22586.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22586",
    "published": "2026-02-26T03:41:49Z",
    "updated": "2026-02-26T03:41:49Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "TabDLM 提出了一种通过联合数值-语言扩散模型生成自由形式表格数据的统一框架。",
      "motivation": "合成表格数据生成对于数据增强、基础模型和隐私保护至关重要，但真实世界表格数据集常包含自由文本字段和结构化数值/分类属性，生成这种异构表具有挑战。现有方法中，基于扩散的模型能有效建模数值和分类特征，但在扩展到开放文本时文本质量下降；基于 LLM 的模型虽生成流畅文本，但其离散令牌化会扭曲数值数据。因此，需要一种方法来联合建模文本和数值，以解决现有方法的不足，提升异构表格生成的质量和实用性。",
      "method": "TabDLM 基于掩码扩散语言模型（MDLMs），构建了一个联合数值-语言扩散模型。文本和分类特征通过掩码扩散过程建模，数值特征则通过连续扩散过程使用学习的专用数值令牌嵌入来建模。通过双向注意力机制，模型在单一框架内捕捉文本、分类和数值特征之间的跨模态交互，实现了异构表格数据的综合生成。",
      "result": "摘要未明确说明具体实验数据，但指出通过在不同基准上的广泛实验，证明了 TabDLM 相比基于扩散和 LLM 的基线方法的有效性。这表明该方法在生成自由形式表格数据方面可能具有提升的生成质量和跨模态一致性，超越了现有方法的局限性。",
      "conclusion": "TabDLM 的主要贡献是提出了一个统一框架，有效生成包含自由文本和数值的异构表格数据。该研究通过结合扩散模型和语言模型的优势，解决了现有方法的不足，在学术上推动了多模态数据生成领域的发展，并在实际应用中促进了数据增强和隐私保护。未来工作可能包括优化模型性能或扩展到其他数据类型。",
      "tags": [
        "Masked Diffusion Language Models",
        "Joint Numerical-Language Diffusion",
        "Tabular Data Generation",
        "Cross-modality Interactions",
        "Continuous Diffusion Process"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:57.568464Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22585",
    "title": "Correcting Human Labels for Rater Effects in AI Evaluation: An Item Response Theory Approach",
    "authors": [
      "Jodi M. Casabianca",
      "Maggie Beiting-Parrish"
    ],
    "abstract": "Human evaluations play a central role in training and assessing AI models, yet these data are rarely treated as measurements subject to systematic error. This paper integrates psychometric rater models into the AI pipeline to improve the reliability and validity of conclusions drawn from human judgments. The paper reviews common rater effects, severity and centrality, that distort observed ratings, and demonstrates how item response theory rater models, particularly the multi-faceted Rasch model, can separate true output quality from rater behavior. Using the OpenAI summarization dataset as an empirical example, we show how adjusting for rater severity produces corrected estimates of summary quality and provides diagnostic insight into rater performance. Incorporating psychometric modeling into human-in-the-loop evaluation offers more principled and transparent use of human data, enabling developers to make decisions based on adjusted scores rather than raw, error-prone ratings. This perspective highlights a path toward more robust, interpretable, and construct-aligned practices for AI development and evaluation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22585.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22585",
    "published": "2026-02-26T03:35:36Z",
    "updated": "2026-02-26T03:35:36Z",
    "comment": "16 pages, 5 figures, 1 table; The 16th Annual Learning Analytics and Knowledge Conference (LAK) Workshop on LLM Psychometrics, April 27, 2026, Bergen, Norway",
    "light_analysis": {
      "overview": "论文提出将项目反应理论（IRT）评分者模型集成到AI评估流程中，以纠正人类评分者的系统性偏差，提高评估的可靠性和有效性。",
      "motivation": "人类评估在AI模型训练和评估中起关键作用，但数据常被忽视为有系统性误差的测量。主要问题是评分者效应（如严格性和中心性）扭曲观察到的评分，导致评估结论不准确，影响AI开发决策。现有方法通常直接使用原始评分，缺乏对评分者行为的统计调整，这使得评估不够可靠和有效，限制了AI模型的精确优化。因此，研究旨在解决如何更可靠地处理人类评分数据，确保评估质量。",
      "method": "论文采用心理测量学的项目反应理论（IRT），特别是多面Rasch模型，来分离真实AI输出质量与评分者行为。该方法将评分者的严格性等效应建模为模型参数，通过统计调整纠正原始评分。实证研究使用OpenAI摘要数据集，应用多面Rasch模型估计评分者偏差并生成修正分数。关键创新点在于首次系统整合IRT评分者模型到AI评估流程中，提供一种透明和原则化的方法来处理人类评分数据，并集成到人机循环评估中。",
      "result": "在OpenAI摘要数据集上，论文展示了调整评分者严格性后，能产生修正的摘要质量估计，这些估计更准确反映真实输出质量。方法还提供了评分者性能的诊断洞察，如识别过度严格或偏差的评分者。与基线未调整的原始评分相比，调整后的分数减少了系统性误差，从而提升了评估的可靠性。摘要未明确具体性能指标（如准确率提升），但结果证明了方法能有效修正评分偏差，并为开发者提供基于调整分数的更可靠决策依据。",
      "conclusion": "论文的主要贡献是引入心理测量学模型（如IRT和多面Rasch模型）到AI评估中，实现了对人类评分数据的更原则化和透明处理。这提升了评估的稳健性、可解释性和建构对齐性，有助于改进AI开发中的决策质量。学术价值在于跨学科整合心理测量学与AI评估，实际应用价值包括促进更可靠的模型评估实践。未来工作方向可能涉及扩展到其他数据集或任务，以及优化模型以处理更多类型的评分者效应，但摘要未明确说明具体局限性。",
      "tags": [
        "Item Response Theory (IRT)",
        "Multi-faceted Rasch Model",
        "Rater Bias Correction",
        "Human-in-the-Loop Evaluation",
        "Psychometric Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:10.374843Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22584",
    "title": "Towards Faithful Industrial RAG: A Reinforced Co-adaptation Framework for Advertising QA",
    "authors": [
      "Wenwei Li",
      "Ming Xu",
      "Tianle Xia",
      "Lingxiang Hu",
      "Yiding Sun",
      "Linfang Shang",
      "Liqun Liu",
      "Peng Shu",
      "Huan Yu",
      "Jie Jiang"
    ],
    "abstract": "Industrial advertising question answering (QA) is a high-stakes task in which hallucinated content, particularly fabricated URLs, can lead to financial loss, compliance violations, and legal risk. Although Retrieval-Augmented Generation (RAG) is widely adopted, deploying it in production remains challenging because industrial knowledge is inherently relational, frequently updated, and insufficiently aligned with generation objectives. We propose a reinforced co-adaptation framework that jointly optimizes retrieval and generation through two components: (1) Graph-aware Retrieval (GraphRAG), which models entity-relation structure over a high-citation knowledge subgraph for multi-hop, domain-specific evidence selection; and (2) evidence-constrained reinforcement learning via Group Relative Policy Optimization (GRPO) with multi-dimensional rewards covering faithfulness, style compliance, safety, and URL validity. Experiments on an internal advertising QA dataset show consistent gains across expert-judged dimensions including accuracy, completeness, and safety, while reducing the hallucination rate by 72\\%. A two-week online A/B test demonstrates a 28.6\\% increase in like rate, a 46.2\\% decrease in dislike rate, and a 92.7\\% reduction in URL hallucination. The system has been running in production for over half a year and has served millions of QA interactions.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22584.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22584",
    "published": "2026-02-26T03:35:09Z",
    "updated": "2026-02-26T03:35:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一个强化协同适应框架，通过图感知检索和多维奖励强化学习，共同优化检索和生成以解决工业广告QA中的幻觉问题。",
      "motivation": "工业广告问答任务中，幻觉内容（尤其是伪造URL）可能导致财务损失、合规违规和法律风险，这凸显了任务的重要性。现有检索增强生成方法在部署中面临挑战，因为工业知识具有关系性、频繁更新且与生成目标不一致，这限制了其在生产环境中的有效应用，并加剧了幻觉风险，从而突显了改进的必要性。",
      "method": "研究提出一个强化协同适应框架，包含两个核心组件：GraphRAG（图感知检索），它在高引用知识子图上建模实体关系结构，实现多跳、领域特定的证据选择，以提升检索精度；以及基于Group Relative Policy Optimization（GRPO）的证据约束强化学习，利用多维奖励（覆盖忠诚度、风格合规、安全性和URL有效性）优化生成过程，共同提高系统整体性能。",
      "result": "实验在内部广告QA数据集上进行，结果显示幻觉率降低72%。在线A/B测试中，点赞率增加28.6%，不点赞率减少46.2%，URL幻觉减少92.7%，并在专家评估的维度（如准确性、完整性和安全性）上持续提升，与基线方法相比显著改善了系统可靠性和用户满意度。",
      "conclusion": "该研究的主要贡献是开发了一个可部署的RAG框架，有效减少了工业广告QA中的幻觉，并提升了忠诚度和安全性。系统已稳定运行超过半年，服务数百万次交互，证明了其实际应用价值；摘要未明确说明局限性，但未来工作可能涉及框架扩展或其他领域的适应。",
      "tags": [
        "Retrieval-Augmented Generation (RAG)",
        "Graph-based Retrieval",
        "Reinforcement Learning",
        "Group Relative Policy Optimization (GRPO)",
        "Multi-hop Reasoning"
      ]
    },
    "analyzed_at": "2026-02-27T03:44:58.508109Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22583",
    "title": "Strategy Executability in Mathematical Reasoning: Leveraging Human-Model Differences for Effective Guidance",
    "authors": [
      "Weida Liang",
      "Yiyou Sun",
      "Shuyuan Nan",
      "Chuang Li",
      "Dawn Song",
      "Kenji Kawaguchi"
    ],
    "abstract": "Example-based guidance is widely used to improve mathematical reasoning at inference time, yet its effectiveness is highly unstable across problems and models-even when the guidance is correct and problem-relevant. We show that this instability arises from a previously underexplored gap between strategy usage-whether a reasoning strategy appears in successful solutions-and strategy executability-whether the strategy remains effective when instantiated as guidance for a target model. Through a controlled analysis of paired human-written and model-generated solutions, we identify a systematic dissociation between usage and executability: human- and model-derived strategies differ in structured, domain-dependent ways, leading to complementary strengths and consistent source-dependent reversals under guidance. Building on this diagnosis, we propose Selective Strategy Retrieval (SSR), a test-time framework that explicitly models executability by selectively retrieving and combining strategies using empirical, multi-route, source-aware signals. Across multiple mathematical reasoning benchmarks, SSR yields reliable and consistent improvements over direct solving, in-context learning, and single-source guidance, improving accuracy by up to $+13$ points on AIME25 and $+5$ points on Apex for compact reasoning models. Code and benchmark are publicly available at: https://github.com/lwd17/strategy-execute-pipeline.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22583.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22583",
    "published": "2026-02-26T03:34:23Z",
    "updated": "2026-02-26T03:34:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出选择性策略检索（SSR）框架，通过建模策略可执行性，利用人类-模型差异来提高数学推理中示例指导的稳定性和准确性。",
      "motivation": "在数学推理领域，示例指导常被用于推理时提升模型性能，但其效果在问题和模型间表现出高度不稳定性，即使指导内容正确且相关。这种不稳定性源于先前未被充分探索的策略使用（策略在成功解决方案中的出现）与策略可执行性（策略作为指导时对目标模型的有效性）之间的差距。现有方法如单源指导或上下文学习忽视这一差距，导致指导效果不一致，限制了实际应用价值，尤其在需要可靠推理的AI辅助场景中尤为重要。",
      "method": "论文首先通过对比分析人类编写和模型生成的配对解决方案，识别出策略使用与可执行性的系统性差异：人类和模型衍生的策略在结构化、领域依赖的方式上存在不同，导致指导下的互补优势和源依赖的反转效应。基于此诊断，提出选择性策略检索（SSR）框架，这是一个推理时方法，显式建模可执行性，使用经验性、多路径、源感知信号选择性检索和结合策略。该方法不依赖特定数据集，但应用于多个数学推理基准如AIME25和Apex，针对紧凑推理模型进行优化，关键创新在于通过信号驱动提升指导的适应性。",
      "result": "在多个数学推理基准测试中，SSR框架相比直接求解、上下文学习和单源指导，实现了可靠且一致的改进。具体数据表明，在AIME25基准上，准确性提升了高达13个百分点；在Apex基准上，提升了5个百分点，这些提升主要针对紧凑推理模型。实验结果验证了SSR能有效利用人类-模型差异，在指导效果上优于基线方法，强调了建模策略可执行性的实用性和鲁棒性。",
      "conclusion": "论文的主要贡献在于揭示了策略可执行性问题，并提出SSR框架以解决示例指导的不稳定性。这项研究不仅提高了数学推理的指导准确性，还为理解人类与模型在推理策略上的差异提供了新视角，学术上推动了推理系统的优化，应用上可增强AI在教育等领域的性能。未来工作方向可能包括扩展到其他推理任务或探索更多策略组合方法，但摘要未明确说明具体局限性。",
      "tags": [
        "Mathematical Reasoning",
        "Strategy Executability",
        "Selective Strategy Retrieval",
        "In-Context Learning",
        "Test-Time Guidance"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:36.893462Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22581",
    "title": "IBCircuit: Towards Holistic Circuit Discovery with Information Bottleneck",
    "authors": [
      "Tian Bian",
      "Yifan Niu",
      "Chaohao Yuan",
      "Chengzhi Piao",
      "Bingzhe Wu",
      "Long-Kai Huang",
      "Yu Rong",
      "Tingyang Xu",
      "Hong Cheng",
      "Jia Li"
    ],
    "abstract": "Circuit discovery has recently attracted attention as a potential research direction to explain the non-trivial behaviors of language models. It aims to find the computational subgraphs, also known as circuits, within the model that are responsible for solving specific tasks. However, most existing studies overlook the holistic nature of these circuits and require designing specific corrupted activations for different tasks, which is inaccurate and inefficient. In this work, we propose an end-to-end approach based on the principle of Information Bottleneck, called IBCircuit, to identify informative circuits holistically. IBCircuit is an optimization framework for holistic circuit discovery and can be applied to any given task without tediously corrupted activation design. In both the Indirect Object Identification (IOI) and Greater-Than tasks, IBCircuit identifies more faithful and minimal circuits in terms of critical node components and edge components compared to recent related work.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22581.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22581",
    "published": "2026-02-26T03:33:35Z",
    "updated": "2026-02-26T03:33:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出基于信息瓶颈的IBCircuit框架，实现无需设计干扰激活的整体电路发现方法。",
      "motivation": "电路发现是解释语言模型行为的重要研究方向，旨在识别模型中负责特定任务的计算子图。然而，现有方法通常忽略电路的整体性，并且需要为每个任务手动设计corrupted activations，这导致过程不准确且低效，限制了方法的通用性和解释效果。摘要未明确说明该问题在实际应用中的具体影响，但强调了改进现有方法的必要性，以提升解释性AI的可靠性。",
      "method": "论文提出了IBCircuit，一种基于信息瓶颈原理的端到端优化框架，用于整体电路发现。核心创新在于无需为不同任务设计corrupted activations，而是通过信息瓶颈原理自动识别信息丰富的电路组件。该方法可应用于任何给定任务，例如在Indirect Object Identification (IOI)和Greater-Than任务中验证，利用优化过程选择关键节点和边组件，提高了电路的准确性和最小化程度。摘要未详细说明模型架构或具体实现细节。",
      "result": "在IOI和Greater-Than任务中，IBCircuit识别出比近期相关方法更忠实和最小化的电路，特别是在关键节点组件和边组件方面表现优异。这证明了该方法在提升电路发现准确性方面的有效性，但摘要未提供具体性能指标（如准确率或效率改进数值）。与基线方法的对比表明，IBCircuit在避免设计corrupted activations的同时，仍能达到更好的电路识别效果。",
      "conclusion": "论文的主要贡献是提出了IBCircuit，一种基于信息瓶颈的电路发现框架，解决了现有方法忽略整体性和设计复杂的不足。其学术价值在于改进了解释语言模型行为的电路发现方法，提高了通用性和效率；实际应用价值体现在无需繁琐设计即可应用于多种任务。未来工作可能包括扩展到更多任务或模型类型，以及进一步验证其鲁棒性。摘要未明确说明局限性。",
      "tags": [
        "Circuit Discovery",
        "Information Bottleneck",
        "Language Models",
        "Optimization Framework",
        "End-to-End Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:20.399479Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22576",
    "title": "Search-P1: Path-Centric Reward Shaping for Stable and Efficient Agentic RAG Training",
    "authors": [
      "Tianle Xia",
      "Ming Xu",
      "Lingxiang Hu",
      "Yiding Sun",
      "Wenwei Li",
      "Linfang Shang",
      "Liqun Liu",
      "Peng Shu",
      "Huan Yu",
      "Jie Jiang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, yet traditional single-round retrieval struggles with complex multi-step reasoning. Agentic RAG addresses this by enabling LLMs to dynamically decide when and what to retrieve, but current RL-based training methods suffer from sparse outcome rewards that discard intermediate signals and low sample efficiency where failed samples contribute nothing. We propose Search-P1, a framework that introduces path-centric reward shaping for agentic RAG training, comprising two key components: (1) Path-Centric Reward, which evaluates the structural quality of reasoning trajectories through order-agnostic step coverage and soft scoring that extracts learning signals even from failed samples, and (2) Dual-Track Path Scoring with offline-generated reference planners that assesses paths from both self-consistency and reference-alignment perspectives. Experiments on multiple QA benchmarks demonstrate that Search-P1 achieves significant improvements over Search-R1 and other strong baselines, with an average accuracy gain of 7.7 points.",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.22576.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22576",
    "published": "2026-02-26T03:31:00Z",
    "updated": "2026-02-26T03:31:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Search-P1框架，通过路径中心奖励塑造改进agentic RAG训练的稳定性和效率。",
      "motivation": "检索增强生成（RAG）通过融入外部知识来增强大型语言模型处理复杂推理任务，但传统单轮检索在多步推理中表现有限。Agentic RAG允许模型动态检索，但基于强化学习的训练方法面临奖励稀疏和低样本效率问题，丢弃中间推理信号且失败样本无法提供学习信号，这限制了训练效果和任务性能的进一步提升，因此需要更高效稳定的训练方法。",
      "method": "Search-P1框架包含两个核心组件。首先，路径中心奖励通过顺序无关的步骤覆盖和软评分评估推理轨迹的结构质量，即使从失败样本中提取学习信号。其次，双轨路径评分使用离线生成的参考计划器，从自一致性和参考对齐两个角度综合评估路径质量。该方法未在摘要中明确指定具体数据集或模型架构，但重点在优化奖励机制以提高agentic RAG的训练样本利用率和稳定性。",
      "result": "在多个问答基准测试上，Search-P1相比Search-R1和其他强基线取得显著改进，平均准确率提升了7.7个百分点。具体数据显示，该方法有效提高了agentic RAG的性能，验证了路径中心奖励塑造在增强训练效果和推理准确性方面的优越性，基线对比突显了其在准确率上的明显增益。",
      "conclusion": "Search-P1通过路径中心奖励塑造解决了agentic RAG训练中的奖励稀疏和样本效率问题，贡献在于创新地整合了结构质量评估和双轨评分方法。学术上，它为强化学习在RAG应用提供了新思路；应用上，能提升复杂推理任务的系统性能。未来工作可扩展到更多任务或探索其局限性，摘要未明确说明具体未来方向。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Reinforcement Learning",
        "Path-Centric Reward Shaping",
        "Agentic RAG",
        "Dual-Track Scoring"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:40.724719Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22575",
    "title": "S2O: Early Stopping for Sparse Attention via Online Permutation",
    "authors": [
      "Yu Zhang",
      "Songwei Liu",
      "Chenqian Yan",
      "Sheng Lin",
      "Beichen Ning",
      "Fangmin Chen",
      "Xing Wang"
    ],
    "abstract": "Attention scales quadratically with sequence length, fundamentally limiting long-context inference. Existing block-granularity sparsification can reduce latency, but coarse blocks impose an intrinsic sparsity ceiling, making further improvements difficult even with carefully engineered designs. We present S2O, which performs early stopping for sparse attention via online permutation. Inspired by virtual-to-physical address mapping in memory systems, S2O revisits and factorizes FlashAttention execution, enabling inference to load non-contiguous tokens rather than a contiguous span in the original order. Motivated by fine-grained structures in attention heatmaps, we transform explicit permutation into an online, index-guided, discrete loading policy; with extremely lightweight preprocessing and index-remapping overhead, it concentrates importance on a small set of high-priority blocks. Building on this importance-guided online permutation for loading, S2O further introduces an early-stopping rule: computation proceeds from high to low importance; once the current block score falls below a threshold, S2O terminates early and skips the remaining low-contribution blocks, thereby increasing effective sparsity and reducing computation under a controlled error budget.   As a result, S2O substantially raises the practical sparsity ceiling. On Llama-3.1-8B under a 128K context, S2O reduces single-operator MSE by 3.82$\\times$ at matched sparsity, and reduces prefill compute density by 3.31$\\times$ at matched MSE; meanwhile, it preserves end-to-end accuracy and achieves 7.51$\\times$ attention and 3.81$\\times$ end-to-end speedups.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22575.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22575",
    "published": "2026-02-26T03:30:28Z",
    "updated": "2026-02-26T03:30:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出S2O方法，通过在线排列实现稀疏注意力的早期停止，突破现有稀疏化方法的上限，提升长序列推理的效率和性能。",
      "motivation": "注意力机制的计算复杂度随序列长度呈平方级增长，这严重限制了长上下文推理的应用。现有的块粒度稀疏化方法虽能减少延迟，但由于粗粒度块存在固有的稀疏性上限，即使经过精心设计也难以进一步提升。因此，开发更高效的稀疏注意力方法对于加速大模型推理、降低计算成本至关重要，特别是在处理长序列任务时。",
      "method": "S2O方法的核心包括在线排列和早期停止规则。灵感来源于内存系统中的虚拟到物理地址映射，S2O重新审视并分解FlashAttention的执行过程，允许推理时加载非连续的令牌。通过分析注意力热图中的细粒度结构，将显式排列转化为在线、索引引导的离散加载策略，采用轻量级预处理和索引重映射，将重要性集中在少量高优先级块上。在此基础上，引入早期停止规则：计算按重要性从高到低进行，当当前块分数低于阈值时提前终止，从而在控制误差预算下增加有效稀疏性并减少计算量。",
      "result": "实验结果表明，S2O显著提高了实际稀疏性上限。在Llama-3.1-8B模型上，使用128K上下文，在匹配稀疏性时，单算子均方误差（MSE）减少了3.82倍；在匹配MSE时，预填充计算密度减少了3.31倍。同时，该方法保持了端到端的准确性，并实现了注意力计算7.51倍的加速和端到端推理3.81倍的加速，优于现有基线方法。",
      "conclusion": "S2O通过在线排列和早期停止规则，有效提高了稀疏注意力的效率和稀疏性，为解决长序列推理的计算瓶颈提供了新思路。该研究具有重要学术价值，为注意力机制优化开辟了新方向，并具有实际应用潜力，可加速大语言模型的推理过程，降低资源消耗。未来工作可进一步探索在更多模型和任务上的适用性，以及优化阈值设定等参数，摘要未明确说明具体局限性。",
      "tags": [
        "Sparse Attention",
        "Online Permutation",
        "Early Stopping",
        "FlashAttention",
        "Long-Context Inference"
      ]
    },
    "analyzed_at": "2026-02-27T03:45:46.246099Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22571",
    "title": "GIFSplat: Generative Prior-Guided Iterative Feed-Forward 3D Gaussian Splatting from Sparse Views",
    "authors": [
      "Tianyu Chen",
      "Wei Xiang",
      "Kang Han",
      "Yu Lu",
      "Di Wu",
      "Gaowen Liu",
      "Ramana Rao Kompella"
    ],
    "abstract": "Feed-forward 3D reconstruction offers substantial runtime advantages over per-scene optimization, which remains slow at inference and often fragile under sparse views. However, existing feed-forward methods still have potential for further performance gains, especially for out-of-domain data, and struggle to retain second-level inference time once a generative prior is introduced. These limitations stem from the one-shot prediction paradigm in existing feed-forward pipeline: models are strictly bounded by capacity, lack inference-time refinement, and are ill-suited for continuously injecting generative priors. We introduce GIFSplat, a purely feed-forward iterative refinement framework for 3D Gaussian Splatting from sparse unposed views. A small number of forward-only residual updates progressively refine current 3D scene using rendering evidence, achieve favorable balance between efficiency and quality. Furthermore, we distill a frozen diffusion prior into Gaussian-level cues from enhanced novel renderings without gradient backpropagation or ever-increasing view-set expansion, thereby enabling per-scene adaptation with generative prior while preserving feed-forward efficiency. Across DL3DV, RealEstate10K, and DTU, GIFSplat consistently outperforms state-of-the-art feed-forward baselines, improving PSNR by up to +2.1 dB, and it maintains second-scale inference time without requiring camera poses or any test-time gradient optimization.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22571.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22571",
    "published": "2026-02-26T03:25:18Z",
    "updated": "2026-02-26T03:25:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "GIFSplat是一个通过迭代细化和生成先验引导的前馈框架，用于从稀疏无姿态视图实现高效的3D高斯溅射重建，提升了质量和效率的平衡。",
      "motivation": "研究动机在于解决稀疏视图下3D重建的挑战。前馈方法虽然相比每场景优化具有运行时优势，推理更快，但现有方法在处理域外数据时性能有限，且引入生成先验后难以保持秒级推理时间。这些不足源于一次性预测范式，模型受容量限制，缺乏推理时细化能力，也不适合连续注入生成先验，导致质量与效率难以兼顾。因此，需要一种新框架来改进稀疏视图重建，同时维持高效的前馈特性。",
      "method": "GIFSplat采用一个纯前馈的迭代细化框架，基于稀疏无姿态视图进行3D高斯溅射重建。其核心是通过少量前向残差更新，利用渲染证据逐步优化当前3D场景，实现效率与质量的平衡。关键创新在于将冻结的扩散先验蒸馏为高斯级线索，从增强的新渲染中提取信息，无需梯度反向传播或视图集扩展，从而实现每个场景的生成先验适应。这种方法保持了前馈效率，避免了传统优化延迟。",
      "result": "在DL3DV、RealEstate10K和DTU数据集上的实验表明，GIFSplat一致优于最先进的前馈基线方法。具体性能指标上，PSNR提升高达+2.1 dB，显示了显著的质量改进。同时，该方法保持了秒级推理时间，无需相机姿态或任何测试时梯度优化，验证了其效率优势。对比基线，GIFSplat在稀疏视图下表现出更好的鲁棒性和适应性。",
      "conclusion": "本研究的主要贡献是提出了GIFSplat框架，通过迭代细化和生成先验蒸馏，实现了从稀疏视图的高效3D重建。这解决了现有前馈方法在质量和效率之间的平衡问题，具有重要的学术价值，推动了实时3D重建技术的发展。实际应用中，可促进VR/AR和机器人视觉等领域。未来工作可能包括扩展到更复杂场景或优化先验蒸馏过程，但摘要未明确说明具体局限性。",
      "tags": [
        "Generative Prior",
        "3D Gaussian Splatting",
        "Iterative Refinement",
        "Feed-Forward Reconstruction",
        "Diffusion Prior"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:02.122701Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22570",
    "title": "Guidance Matters: Rethinking the Evaluation Pitfall for Text-to-Image Generation",
    "authors": [
      "Dian Xie",
      "Shitong Shao",
      "Lichen Bai",
      "Zikai Zhou",
      "Bojun Cheng",
      "Shuo Yang",
      "Jun Wu",
      "Zeke Xie"
    ],
    "abstract": "Classifier-free guidance (CFG) has helped diffusion models achieve great conditional generation in various fields. Recently, more diffusion guidance methods have emerged with improved generation quality and human preference. However, can these emerging diffusion guidance methods really achieve solid and significant improvements? In this paper, we rethink recent progress on diffusion guidance. Our work mainly consists of four contributions. First, we reveal a critical evaluation pitfall that common human preference models exhibit a strong bias towards large guidance scales. Simply increasing the CFG scale can easily improve quantitative evaluation scores due to strong semantic alignment, even if image quality is severely damaged (e.g., oversaturation and artifacts). Second, we introduce a novel guidance-aware evaluation (GA-Eval) framework that employs effective guidance scale calibration to enable fair comparison between current guidance methods and CFG by identifying the effects orthogonal and parallel to CFG effects. Third, motivated by the evaluation pitfall, we design Transcendent Diffusion Guidance (TDG) method that can significantly improve human preference scores in the conventional evaluation framework but actually does not work in practice. Fourth, in extensive experiments, we empirically evaluate recent eight diffusion guidance methods within the conventional evaluation framework and the proposed GA-Eval framework. Notably, simply increasing the CFG scales can compete with most studied diffusion guidance methods, while all methods suffer severely from winning rate degradation over standard CFG. Our work would strongly motivate the community to rethink the evaluation paradigm and future directions of this field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22570.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22570",
    "published": "2026-02-26T03:24:11Z",
    "updated": "2026-02-26T03:24:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文揭示扩散指导方法的评估偏见，并提出GA-Eval框架以实现公平比较。",
      "motivation": "扩散模型如CFG已在文本到图像生成等领域推动条件生成进展，新兴指导方法声称能改善质量和人类偏好。但问题在于现有评估方法存在陷阱：人类偏好模型对大的指导尺度有强烈偏见，导致仅增加CFG尺度就能虚假提升评分，即使图像质量因过饱和和伪影严重受损。这引发对新兴方法是否真有显著改进的质疑，重要性在于避免误导研究进展，不足在于评估范式不公，可能阻碍技术创新。",
      "method": "论文提出四步方法：首先，揭示评估陷阱，指出偏好模型对指导尺度的偏差。其次，引入Guidance-aware evaluation (GA-Eval)框架，通过指导尺度校准，区分与CFG效应正交和平行的因素，实现公平比较。第三，设计Transcendent Diffusion Guidance (TDG)作为示例方法，在传统评估中得分高但实际无效，以演示陷阱。第四，在实验中评估八个扩散指导方法，使用传统和GA-Eval框架，涉及具体模型和数据对比分析。",
      "result": "实验结果表明，在传统评估中，简单增加CFG尺度可与大多数扩散指导方法竞争，提升语义对齐评分，但所有方法在获胜率上相比标准CFG严重下降。在GA-Eval框架下公平比较，发现大多数方法未实现显著改进，且TDG在传统评估中得分高但实际测试无效。具体数据如指导尺度的影响被量化，凸显评估陷阱的存在，并证实GA-Eval框架的有效性。",
      "conclusion": "论文主要贡献是揭示扩散指导方法的评估偏见并提出GA-Eval框架，推动社区重新思考评估范式和未来方向。学术价值在于纠正错误评估方法，促进领域健康发展；实际应用价值在于优化文本到图像生成的模型选择。潜在局限性包括GA-Eval框架需更多验证，未来工作可扩展至其他生成任务和开发更鲁棒的评估指标。",
      "tags": [
        "Classifier-free Guidance",
        "Diffusion Models",
        "Text-to-Image Generation",
        "Guidance Scale",
        "Human Preference Models"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:00.019683Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22568",
    "title": "Quality-Aware Robust Multi-View Clustering for Heterogeneous Observation Noise",
    "authors": [
      "Peihan Wu",
      "Guanjie Cheng",
      "Yufei Tong",
      "Meng Xi",
      "Shuiguang Deng"
    ],
    "abstract": "Deep multi-view clustering has achieved remarkable progress but remains vulnerable to complex noise in real-world applications. Existing noisy robust methods predominantly rely on a simplified binary assumption, treating data as either perfectly clean or completely corrupted. This overlooks the prevalent existence of heterogeneous observation noise, where contamination intensity varies continuously across data. To bridge this gap, we propose a novel framework termed Quality-Aware Robust Multi-View Clustering (QARMVC). Specifically, QARMVC employs an information bottleneck mechanism to extract intrinsic semantics for view reconstruction. Leveraging the insight that noise disrupts semantic integrity and impedes reconstruction, we utilize the resulting reconstruction discrepancy to precisely quantify fine-grained contamination intensity and derive instance-level quality scores. These scores are integrated into a hierarchical learning strategy: at the feature level, a quality-weighted contrastive objective is designed to adaptively suppress the propagation of noise; at the fusion level, a high-quality global consensus is constructed via quality-weighted aggregation, which is subsequently utilized to align and rectify local views via mutual information maximization. Extensive experiments on five benchmark datasets demonstrate that QARMVC consistently outperforms state-of-the-art baselines, particularly in scenarios with heterogeneous noise intensities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22568.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22568",
    "published": "2026-02-26T03:16:44Z",
    "updated": "2026-02-26T03:16:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种质量感知的鲁棒多视图聚类框架（QARMVC），通过分层学习策略处理异构观测噪声，显著提升了聚类性能。",
      "motivation": "深度多视图聚类在现实应用中常受复杂噪声影响，而现有方法多基于简化的二元假设，将数据视为完全清洁或完全污染，忽视了噪声强度的连续性。这种异构观测噪声广泛存在于真实世界数据中，导致现有方法鲁棒性不足，无法精确处理不同污染程度的数据，从而降低了聚类准确性和稳定性。因此，开发能够量化噪声强度并自适应抑制噪声的框架至关重要，以应对现实场景中的噪声挑战。",
      "method": "QARMVC 采用信息瓶颈机制提取内在语义进行视图重建，并利用重建差异精确量化实例级污染强度，生成质量分数。在特征层面，设计质量加权对比目标，自适应抑制噪声传播；在融合层面，通过质量加权聚合构建高质量全局共识，并使用互信息最大化对齐和校正局部视图。关键创新在于通过质量感知机制实现细粒度噪声处理，并通过分层学习策略优化特征表示和视图融合，提升了模型对异构噪声的适应性。",
      "result": "在五个基准数据集上的实验表明，QARMVC 一致优于最先进的基线方法，尤其是在异构噪声强度场景下表现出色。这些结果验证了框架在处理复杂噪声时的有效性和鲁棒性，显著提升了聚类性能，摘要未提供具体性能指标数值，但强调了其相对于现有方法的优越性。",
      "conclusion": "本研究提出了 QARMVC 框架，通过质量感知和分层学习策略有效处理异构观测噪声，为多视图聚类领域提供了新的鲁棒性方法。学术价值在于创新地结合了信息瓶颈和质量加权机制，实际应用价值体现在处理现实世界噪声数据的能力。未来工作可探索更多噪声类型或扩展框架到其他机器学习任务，摘要未明确说明具体局限性。",
      "tags": [
        "Multi-View Clustering",
        "Information Bottleneck",
        "Contrastive Learning",
        "Mutual Information Maximization",
        "Noise Robustness"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:01.367057Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22565",
    "title": "SwiftNDC: Fast Neural Depth Correction for High-Fidelity 3D Reconstruction",
    "authors": [
      "Kang Han",
      "Wei Xiang",
      "Lu Yu",
      "Mathew Wyatt",
      "Gaowen Liu",
      "Ramana Rao Kompella"
    ],
    "abstract": "Depth-guided 3D reconstruction has gained popularity as a fast alternative to optimization-heavy approaches, yet existing methods still suffer from scale drift, multi-view inconsistencies, and the need for substantial refinement to achieve high-fidelity geometry. Here, we propose SwiftNDC, a fast and general framework built around a Neural Depth Correction field that produces cross-view consistent depth maps. From these refined depths, we generate a dense point cloud through back-projection and robust reprojection-error filtering, obtaining a clean and uniformly distributed geometric initialization for downstream reconstruction. This reliable dense geometry substantially accelerates 3D Gaussian Splatting (3DGS) for mesh reconstruction, enabling high-quality surfaces with significantly fewer optimization iterations. For novel-view synthesis, SwiftNDC can also improve 3DGS rendering quality, highlighting the benefits of strong geometric initialization. We conduct a comprehensive study across five datasets, including two for mesh reconstruction, as well as three for novel-view synthesis. SwiftNDC consistently reduces running time for accurate mesh reconstruction and boosts rendering fidelity for view synthesis, demonstrating the effectiveness of combining neural depth refinement with robust geometric initialization for high-fidelity and efficient 3D reconstruction.",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.22565.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22565",
    "published": "2026-02-26T03:07:53Z",
    "updated": "2026-02-26T03:07:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "SwiftNDC 框架通过神经深度修正场生成跨视角一致的深度图，加速高保真 3D 重建，提升几何质量和渲染效率。",
      "motivation": "深度引导的 3D 重建作为快速替代方法虽受欢迎，但现有方法面临尺度漂移、多视角不一致和需要大量细化的挑战，这限制了高保真几何的快速生成。这些不足导致重建结果不够准确或计算成本高昂，尤其是在动态场景和复杂数据集中，因此亟需一种高效方法来解决深度图的准确性和一致性问题，以提高重建的实用性和效率，满足计算机视觉和图形学应用的需求。",
      "method": "SwiftNDC 围绕神经深度修正场构建，该场通过神经网络处理生成跨视角一致的深度图，解决了多视角不一致问题。修正后的深度图通过反投影和稳健的重投影误差过滤转化为密集点云，作为下游重建的干净、均匀分布的几何初始化。这一初始化加速了 3D Gaussian Splatting 的优化过程，减少网格重建的迭代次数，同时适用于新视角合成任务，通过几何初始化改善整体性能，方法设计为快速通用，适应不同数据集。",
      "result": "实验在五个数据集上进行全面研究，包括两个用于网格重建和三个用于新视角合成。SwiftNDC 显著减少准确网格重建的运行时间，并提升新视角合成的渲染保真度。与基线方法对比，该方法在保持或提高几何质量的同时减少优化迭代，突出了几何初始化的关键作用，验证了结合神经深度修正和稳健几何初始化的有效性，实现了高效和高保真的 3D 重建性能。",
      "conclusion": "论文的主要贡献是提出 SwiftNDC 框架，通过神经深度修正场和稳健几何初始化相结合，实现了快速和高保真的 3D 重建。该方法不仅加速了网格重建过程，还提高了新视角合成的渲染质量，在计算机视觉和图形学领域具有重要学术价值和实际应用潜力。未来工作可以探索更广泛的适用性或进一步优化深度修正技术，以适应更复杂的场景。",
      "tags": [
        "Neural Depth Correction",
        "3D Gaussian Splatting",
        "Cross-view Consistency",
        "Depth Refinement",
        "3D Reconstruction"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:13.590739Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22560",
    "title": "Operationalizing Fairness: Post-Hoc Threshold Optimization Under Hard Resource Limits",
    "authors": [
      "Moirangthem Tiken Singh",
      "Amit Kalita",
      "Sapam Jitu Singh"
    ],
    "abstract": "The deployment of machine learning in high-stakes domains requires a balance between predictive safety and algorithmic fairness. However, existing fairness interventions often as- sume unconstrained resources and employ group-specific decision thresholds that violate anti- discrimination regulations. We introduce a post-hoc, model-agnostic threshold optimization framework that jointly balances safety, efficiency, and equity under strict and hard capacity constraints. To ensure legal compliance, the framework enforces a single, global decision thresh- old. We formulated a parameterized ethical loss function coupled with a bounded decision rule that mathematically prevents intervention volumes from exceeding the available resources. An- alytically, we prove the key properties of the deployed threshold, including local monotonicity with respect to ethical weighting and the formal identification of critical capacity regimes. We conducted extensive experimental evaluations on diverse high-stakes datasets. The principal re- sults demonstrate that capacity constraints dominate ethical priorities; the strict resource limit determines the final deployed threshold in over 80% of the tested configurations. Furthermore, under a restrictive 25% capacity limit, the proposed framework successfully maintains high risk identification (recall ranging from 0.409 to 0.702), whereas standard unconstrained fairness heuristics collapse to a near-zero utility. We conclude that theoretical fairness objectives must be explicitly subordinated to operational capacity limits to remain in deployment. By decou- pling predictive scoring from policy evaluation and strictly bounding intervention rates, this framework provides a practical and legally compliant mechanism for stakeholders to navigate unavoidable ethical trade-offs in resource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22560.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22560",
    "published": "2026-02-26T02:56:36Z",
    "updated": "2026-02-26T02:56:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种后处理阈值优化框架，在硬资源限制下平衡算法公平性、安全性和效率，通过单一全局阈值确保法律合规。",
      "motivation": "机器学习在高风险领域部署时需兼顾预测安全性和算法公平性。现有公平干预方法常假设资源无限，使用组特定决策阈值违反反歧视法规，导致在实际资源受限环境中无法实施。资源限制是现实世界部署的关键挑战，需要开发在容量约束下平衡公平、安全和效率的解决方案，以避免法律风险和操作失效。",
      "method": "该研究提出一个模型无关的后处理阈值优化框架，定义参数化伦理损失函数和有界决策规则，强制使用单一全局决策阈值以确保法律合规。损失函数优化安全性、效率和公平性的平衡，决策规则数学上限制干预量不超过可用资源。分析中证明了部署阈值的局部单调性和临界容量区域，框架解耦预测评分与政策评估，提供灵活的策略调整机制。",
      "result": "在多个高风险数据集上的实验表明，容量约束主导伦理优先级，80%以上配置中严格资源限制决定最终部署阈值。在25%容量限制下，框架保持高召回率（0.409-0.702），有效识别高风险案例；相比之下，标准无约束公平启发式方法几乎失效，召回率接近零。这凸显了框架在资源受限环境中的稳健性和实用优势。",
      "conclusion": "该框架通过解耦预测评分与政策评估、严格限制干预率，为资源约束环境下的伦理权衡提供合法且实用的机制。研究强调公平目标必须从属于操作容量限制，对机器学习部署的学术理论和实际应用有重要价值，未来工作可探索更复杂场景或优化算法以扩展适用性。",
      "tags": [
        "Fairness in AI",
        "Post-hoc Optimization",
        "Threshold Optimization",
        "Capacity Constraints",
        "Model-Agnostic"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:34.212117Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22557",
    "title": "CourtGuard: A Model-Agnostic Framework for Zero-Shot Policy Adaptation in LLM Safety",
    "authors": [
      "Umid Suleymanov",
      "Rufiz Bayramov",
      "Suad Gafarli",
      "Seljan Musayeva",
      "Taghi Mammadov",
      "Aynur Akhundlu",
      "Murat Kantarcioglu"
    ],
    "abstract": "Current safety mechanisms for Large Language Models (LLMs) rely heavily on static, fine-tuned classifiers that suffer from adaptation rigidity, the inability to enforce new governance rules without expensive retraining. To address this, we introduce CourtGuard, a retrieval-augmented multi-agent framework that reimagines safety evaluation as Evidentiary Debate. By orchestrating an adversarial debate grounded in external policy documents, CourtGuard achieves state-of-the-art performance across 7 safety benchmarks, outperforming dedicated policy-following baselines without fine-tuning. Beyond standard metrics, we highlight two critical capabilities: (1) Zero-Shot Adaptability, where our framework successfully generalized to an out-of-domain Wikipedia Vandalism task (achieving 90\\% accuracy) by swapping the reference policy; and (2) Automated Data Curation and Auditing, where we leveraged CourtGuard to curate and audit nine novel datasets of sophisticated adversarial attacks. Our results demonstrate that decoupling safety logic from model weights offers a robust, interpretable, and adaptable path for meeting current and future regulatory requirements in AI governance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.22557.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22557",
    "published": "2026-02-26T02:52:11Z",
    "updated": "2026-02-26T02:52:11Z",
    "comment": "Under Review",
    "light_analysis": {
      "overview": "CourtGuard 是一个模型无关的框架，通过检索增强的多智能体辩论实现大型语言模型安全的零样本政策适应。",
      "motivation": "当前大型语言模型的安全机制主要依赖静态、微调的分类器，导致适应性僵化，无法在不进行昂贵重新训练的情况下强制执行新的治理规则。随着 AI 治理需求的增加，现有方法难以灵活适应新政策，限制了安全措施的时效性和有效性。这一问题在应对不断变化的监管要求时尤为突出，因此需要开发更灵活、可扩展的安全框架。",
      "method": "CourtGuard 是一个检索增强的多智能体框架，将安全评估重新构想为证据辩论过程。它通过协调基于外部政策文档的对抗性辩论来实现模型无关的安全检测，关键创新包括使用检索技术动态获取政策信息，并利用多智能体系统进行辩论，从而无需模型微调即可适应新政策。摘要未明确说明具体模型架构或数据集细节，但强调了框架的模型无关性和检索组件。",
      "result": "CourtGuard 在七个安全基准测试中实现了最先进的性能，超越了专用政策遵循基线，且无需微调。具体来说，通过交换参考政策，框架在域外的 Wikipedia 破坏检测任务中达到 90% 的准确率，展示了零样本适应性。此外，CourtGuard 被用于策展和审计九个新颖的复杂对抗攻击数据集，进一步验证了其实用性和鲁棒性。",
      "conclusion": "CourtGuard 的主要贡献在于通过解耦安全逻辑与模型权重，为大型语言模型安全提供了一个鲁棒、可解释且适应性强的框架。这具有重要的学术价值，推动了安全评估方法的创新，并具有实际应用意义，能帮助满足当前和未来的 AI 监管需求。未来工作可以探索在更多场景中的应用，例如扩展辩论机制或集成更多政策源。",
      "tags": [
        "Large Language Model Safety",
        "Retrieval-Augmented Generation",
        "Multi-Agent Systems",
        "Zero-Shot Learning",
        "Policy Adaptation"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:40.729766Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22556",
    "title": "Stable Adaptive Thinking via Advantage Shaping and Length-Aware Gradient Regulation",
    "authors": [
      "Zihang Xu",
      "Haozhi Xie",
      "Ziqi Miao",
      "Wuxuan Gong",
      "Chen Qian",
      "Lijun Li"
    ],
    "abstract": "Large reasoning models (LRMs) achieve strong performance through extended reasoning traces, but they often exhibit overthinking behavior for low-complexity queries. Existing efforts to mitigate this issue are fundamentally limited by unstable accuracy-efficiency trade-offs and poor robustness to heterogeneous reasoning behaviors. To address these challenges, we propose a two-stage framework for stable adaptive thinking in LRMs. The framework first applies Hybrid Fine-Tuning to expose the model to both thinking and no-thinking behaviors, establishing well-conditioned initialization. It then performs adaptive reinforcement learning with Correctness-Preserving Advantage Shaping (CPAS) to avoid suppressing correct long-chain reasoning, and Length-Aware Gradient Regulation (LAGR) to stabilize optimization under severe reasoning-length heterogeneity. Extensive experiments on Qwen2.5-1.5B and 7B show consistent improvements over strong baselines, achieving up to +3.7/+3.6 accuracy points while reducing generated tokens by 40.6%/43.9%. Further analyses across varying problem difficulties and out-of-distribution tasks confirm the robustness and generalization of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22556.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22556",
    "published": "2026-02-26T02:49:36Z",
    "updated": "2026-02-26T02:49:36Z",
    "comment": "15 pages, 7 figures",
    "light_analysis": {
      "overview": "论文提出一个两阶段框架，通过混合微调和自适应强化学习，结合优势塑造和梯度调节，实现大型推理模型的稳定自适应思考，提高准确性和效率。",
      "motivation": "大型推理模型在处理低复杂度查询时表现出过度思考行为，导致准确性-效率权衡不稳定，且对异质性推理行为鲁棒性差，这限制了模型的实际应用效率。现有方法主要聚焦于平衡推理长度和性能，但往往牺牲准确性或缺乏对复杂场景的适应性，无法有效解决推理长度变化带来的优化不稳定问题，因此需开发更稳健的解决方案。",
      "method": "该方法采用两阶段框架：首先进行混合微调（Hybrid Fine-Tuning），使模型同时学习思考和思考行为，建立良好初始化条件；然后执行自适应强化学习，结合保留正确性的优势塑造（CPAS）来避免抑制正确长链推理，以及长度感知梯度调节（LAGR）来稳定优化过程，以应对推理长度的严重异质性。实验在Qwen2.5-1.5B和7B模型上进行。",
      "result": "实验结果显示，在Qwen2.5-1.5B和7B模型上，与强基线相比，该方法在准确性上提升了高达+3.7点（1.5B模型）和+3.6点（7B模型），同时减少了生成标记的40.6%和43.9%。在不同难度问题和分布外任务上的进一步分析证实了该方法具有良好的鲁棒性和泛化能力，有效解决了过度思考问题。",
      "conclusion": "论文的主要贡献是提出了一种稳定自适应思考框架，通过混合微调和自适应强化学习技术，有效缓解了大型推理模型的过度思考行为，提高了准确性和效率，具有显著的学术和实际应用价值。未来工作可探索扩展到其他模型类型或更广泛的推理任务中，以进一步增强方法的普适性和性能。",
      "tags": [
        "Large Reasoning Models (LRMs)",
        "Hybrid Fine-Tuning",
        "Correctness-Preserving Advantage Shaping (CPAS)",
        "Length-Aware Gradient Regulation (LAGR)",
        "Adaptive Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:38.766477Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22555",
    "title": "Autoregressive Visual Decoding from EEG Signals",
    "authors": [
      "Sicheng Dai",
      "Hongwang Xiao",
      "Shan Yu",
      "Qiwei Ye"
    ],
    "abstract": "Electroencephalogram (EEG) signals have become a popular medium for decoding visual information due to their cost-effectiveness and high temporal resolution. However, current approaches face significant challenges in bridging the modality gap between EEG and image data. These methods typically rely on complex adaptation processes involving multiple stages, making it hard to maintain consistency and manage compounding errors. Furthermore, the computational overhead imposed by large-scale diffusion models limit their practicality in real-world brain-computer interface (BCI) applications. In this work, we present AVDE, a lightweight and efficient framework for visual decoding from EEG signals. First, we leverage LaBraM, a pre-trained EEG model, and fine-tune it via contrastive learning to align EEG and image representations. Second, we adopt an autoregressive generative framework based on a \"next-scale prediction\" strategy: images are encoded into multi-scale token maps using a pre-trained VQ-VAE, and a transformer is trained to autoregressively predict finer-scale tokens starting from EEG embeddings as the coarsest representation. This design enables coherent generation while preserving a direct connection between the input EEG signals and the reconstructed images. Experiments on two datasets show that AVDE outperforms previous state-of-the-art methods in both image retrieval and reconstruction tasks, while using only 10% of the parameters. In addition, visualization of intermediate outputs shows that the generative process of AVDE reflects the hierarchical nature of human visual perception. These results highlight the potential of autoregressive models as efficient and interpretable tools for practical BCI applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22555.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22555",
    "published": "2026-02-26T02:49:04Z",
    "updated": "2026-02-26T02:49:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了AVDE框架，一个基于自回归生成和对比学习的轻量方法，用于从EEG信号高效解码视觉信息。",
      "motivation": "脑电图（EEG）信号因其成本效益和高时间分辨率，成为解码视觉信息的常用媒介。然而，现有方法在弥合EEG与图像数据之间的模态差距时面临挑战，通常依赖多阶段复杂适应过程，导致一致性差和误差累积。此外，大规模扩散模型的计算开销限制了其在真实世界脑机接口（BCI）应用中的实用性。因此，需要一种轻量高效的框架来解决这些问题，以提高解码精度并降低计算负担，推动BCI的实际部署。",
      "method": "论文提出AVDE框架，首先利用预训练的EEG模型LaBraM，通过对比学习微调以对齐EEG和图像表示，减少模态差距。其次，采用自回归生成框架，基于“next-scale预测”策略：使用预训练的VQ-VAE将图像编码成多尺度token图，训练一个transformer从EEG嵌入作为最粗表示开始，自回归预测更细尺度的token。这种设计确保生成过程的连贯性，并保持输入EEG信号与重建图像之间的直接连接，提升解码效率。",
      "result": "实验在两个数据集上进行，结果显示AVDE在图像检索和重建任务中均优于先前的最先进方法，证明了其有效性。此外，AVDE仅使用10%的参数，显著降低了计算开销，提高了模型的轻量化程度。可视化中间输出表明，生成过程反映了人类视觉感知的层次性，增强了模型的解释性，为BCI应用提供了性能提升和实用性支持。",
      "conclusion": "本文的主要贡献是提出了AVDE，一个轻量高效的自回归视觉解码框架，展示了自回归模型在BCI应用中作为高效和可解释工具的潜力。研究通过降低参数量和保持高性能，提升了框架的实用性。虽然摘要未明确说明局限性，但可以推测未来工作可能包括扩展到更多模态或优化生成质量，以进一步推动BCI技术的发展和应用价值。",
      "tags": [
        "Autoregressive Models",
        "EEG Decoding",
        "Contrastive Learning",
        "VQ-VAE",
        "Transformer"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:46.567620Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22554",
    "title": "Multilingual Safety Alignment Via Sparse Weight Editing",
    "authors": [
      "Jiaming Liang",
      "Zhaoxin Wang",
      "Handing Wang"
    ],
    "abstract": "Large Language Models (LLMs) exhibit significant safety disparities across languages, with low-resource languages (LRLs) often bypassing safety guardrails established for high-resource languages (HRLs) like English. Existing solutions, such as multilingual supervised fine-tuning (SFT) or Reinforcement Learning from Human Feedback (RLHF), are computationally expensive and dependent on scarce multilingual safety data. In this work, we propose a novel, training-free alignment framework based on Sparse Weight Editing. Identifying that safety capabilities are localized within a sparse set of safety neurons, we formulate the cross-lingual alignment problem as a constrained linear transformation. We derive a closed-form solution to optimally map the harmful representations of LRLs to the robust safety subspaces of HRLs, while preserving general utility via a null-space projection constraint. Extensive experiments across 8 languages and multiple model families (Llama-3, Qwen-2.5) demonstrate that our method substantially reduces Attack Success Rate (ASR) in LRLs with negligible impact on general reasoning capabilities, all achieved with a single, data-efficient calculation.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22554.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22554",
    "published": "2026-02-26T02:46:13Z",
    "updated": "2026-02-26T02:46:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种基于稀疏权重编辑的免训练多语言安全对齐框架，旨在解决大语言模型在低资源语言中的安全差异问题。",
      "motivation": "大语言模型（LLMs）在多语言环境中表现出显著的安全能力差异，低资源语言（LRLs）常能绕过为高资源语言（如英语）建立的安全护栏，导致潜在的安全风险。这一问题对全球AI部署至关重要，因为安全漏洞可能引发有害内容生成。现有方法，如多语言监督微调（SFT）和人类反馈的强化学习（RLHF），虽能提升安全性，但计算成本高昂且依赖稀缺的多语言安全数据，限制了其可扩展性和实用性。因此，亟需开发高效、数据驱动的对齐方案来弥补这一不足。",
      "method": "论文提出一个基于稀疏权重编辑的免训练对齐框架，核心是通过识别模型中对安全能力关键的稀疏神经元集合，将跨语言安全对齐问题建模为约束线性变换。方法推导出闭式解，以最优方式将低资源语言的有害表示映射到高资源语言的鲁棒安全子空间，同时利用零空间投影约束来保护一般语言能力，避免性能下降。该技术无需额外训练数据，在多个模型家族（如Llama-3、Qwen-2.5）上进行验证，仅通过单次计算即可实现高效对齐，突出了其数据效率和计算优势。",
      "result": "实验在8种语言和多个模型家族（包括Llama-3和Qwen-2.5）上展开，结果显示，该方法显著降低了低资源语言的攻击成功率（ASR），同时对模型的一般推理能力影响微乎其微。与现有基线方法（如SFT和RLHF）相比，这种免训练框架在数据效率和计算成本上表现出明显优势，通过一次数据高效的计算即能达到有效安全对齐，避免了传统方法对大量标注数据和昂贵训练的依赖。具体性能提升幅度摘要未明确说明，但实验证实了方法的有效性和鲁棒性。",
      "conclusion": "本研究的主要贡献是提出了一种新颖的免训练多语言安全对齐框架，通过稀疏权重编辑和约束线性变换，高效解决了大语言模型在低资源语言中的安全问题。学术上，这为模型对齐提供了新的技术路径，减少了数据依赖性；实际应用中，能提升多语言AI系统的安全性和可扩展性，降低部署成本。局限性方面摘要未明确说明，但未来工作可能涉及扩展到更多语言或模型类型，以及进一步验证方法的泛化能力和鲁棒性。",
      "tags": [
        "Large Language Model",
        "Sparse Weight Editing",
        "Multilingual Safety Alignment",
        "Constrained Linear Transformation",
        "Null-space Projection"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:59.809857Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.22552",
    "title": "Relatron: Automating Relational Machine Learning over Relational Databases",
    "authors": [
      "Zhikai Chen",
      "Han Xie",
      "Jian Zhang",
      "Jiliang Tang",
      "Xiang Song",
      "Huzefa Rangwala"
    ],
    "abstract": "Predictive modeling over relational databases (RDBs) powers applications, yet remains challenging due to capturing both cross-table dependencies and complex feature interactions. Relational Deep Learning (RDL) methods automate feature engineering via message passing, while classical approaches like Deep Feature Synthesis (DFS) rely on predefined non-parametric aggregators. Despite performance gains, the comparative advantages of RDL over DFS and the design principles for selecting effective architectures remain poorly understood. We present a comprehensive study that unifies RDL and DFS in a shared design space and conducts architecture-centric searches across diverse RDB tasks. Our analysis yields three key findings: (1) RDL does not consistently outperform DFS, with performance being highly task-dependent; (2) no single architecture dominates across tasks, underscoring the need for task-aware model selection; and (3) validation accuracy is an unreliable guide for architecture choice. This search yields a model performance bank that links architecture configurations to their performance; leveraging this bank, we analyze the drivers of the RDL-DFS performance gap and introduce two task signals -- RDB task homophily and an affinity embedding that captures size, path, feature, and temporal structure -- whose correlation with the gap enables principled routing. Guided by these signals, we propose Relatron, a task embedding-based meta-selector that chooses between RDL and DFS and prunes the within-family search. Lightweight loss-landscape metrics further guard against brittle checkpoints by preferring flatter optima. In experiments, Relatron resolves the \"more tuning, worse performance\" effect and, in joint hyperparameter-architecture optimization, achieves up to 18.5% improvement over strong baselines with 10x lower cost than Fisher information-based alternatives.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.22552.pdf",
    "abs_url": "https://arxiv.org/abs/2602.22552",
    "published": "2026-02-26T02:45:22Z",
    "updated": "2026-02-26T02:45:22Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "论文提出Relatron，一个基于任务信号和任务嵌入的元选择器，自动化选择关系机器学习方法以优化性能并显著降低成本。",
      "motivation": "关系数据库上的预测建模面临捕获跨表依赖和复杂特征交互的挑战。现有方法如关系深度学习通过消息传递自动化特征工程，而深度特征合成依赖预定义聚合器；但两者性能比较不明确，缺乏统一设计原则和有效选择机制，导致在实际应用中难以优化架构，问题重要因为影响自动化机器学习在关系数据上的效率和准确性。",
      "method": "研究首先统一关系深度学习和深度特征合成在一个共享设计空间中，进行架构中心搜索，分析性能差距的驱动因素。关键创新是引入两个任务信号：RDB任务同质性和亲和嵌入，后者捕获大小、路径、特征和时间结构。基于这些信号，提出Relatron元选择器，用于在两类方法间选择并修剪家族内搜索；还使用轻量级损失景观指标优先平坦最优解以避免脆弱检查点，数据集和模型架构细节摘要未明确说明。",
      "result": "实验表明，Relatron解决了'更多调优，性能更差'的现象，在联合超参数和架构优化任务中，性能比强基线提升高达18.5%，同时成本比基于Fisher信息的替代方法低10倍；这表明Relatron能有效选择合适方法并显著提高效率和效果，与基线对比显示任务依赖性得到改进。",
      "conclusion": "论文贡献在于系统分析关系机器学习方法性能差距，并提出任务信号驱动的元选择器框架，提升自动化水平；研究具有学术价值，为关系数据库上机器学习提供新方向，实际应用能优化性能和成本；局限性包括信号泛化性，未来工作可扩展信号类型或应用于其他领域。",
      "tags": [
        "Relational Deep Learning",
        "Deep Feature Synthesis",
        "Task Embedding",
        "Meta-Selector",
        "Loss Landscape Metrics"
      ]
    },
    "analyzed_at": "2026-02-27T03:46:54.253370Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.21262",
    "title": "Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models",
    "authors": [
      "Sasha Robinson",
      "Kerem Oktar",
      "Katherine M. Collins",
      "Ilia Sucholutsky",
      "Kelsey R. Allen"
    ],
    "abstract": "With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.21262.pdf",
    "abs_url": "https://arxiv.org/abs/2602.21262",
    "published": "2026-02-24T04:09:21Z",
    "updated": "2026-02-26T06:37:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文首次研究了大语言模型中说服力、警觉性和任务性能之间的关系，发现它们是分离的能力，并强调了独立监测这些能力对AI安全的重要性。",
      "motivation": "随着大语言模型越来越多地应用于高风险人类决策领域，作为顾问时，它们需要筛选海量信息（包括善意和恶意内容），并说服用户采取特定行动。这涉及警觉性（确定使用哪些信息）和说服力（综合证据提出有力论点）两种社会能力。现有研究通常孤立探讨这些能力，缺乏对它们关联性的深入调查，而这对于评估LLMs作为顾问的风险至关重要，尤其是在面临潜在欺骗和误导时，确保模型能正确决策。",
      "method": "论文采用一个简单的多轮益智游戏Sokoban作为实验环境，研究LLMs的说服力和理性警觉能力。通过设计多轮交互，让LLM代理在游戏中互相提供建议（包括善意和恶意），观察它们如何说服其他代理并检测误导。关键创新在于首次将说服力和警觉性联系起来，在动态交互中量化这些能力。摘要未明确说明具体使用的LLM模型，但实验基于LLM代理进行多轮交互，以模拟真实世界的顾问场景，突显了技术方法的实用性和可操作性。",
      "result": "实验结果表明，谜题解决性能、说服能力和警觉性是分离的：即使LLMs在游戏中表现良好，也不一定能检测到误导，即使明确提及欺骗可能性。此外，LLMs在使用令牌方面表现出调整，对善意建议使用较少的令牌进行推理，而对恶意建议使用更多的令牌，尽管最终仍可能被说服采取导致失败的行动。与基线预期不同，这些发现突显了说服力和警觉性并非与任务性能直接相关，强调了在评估模型时需独立考察这些能力。",
      "conclusion": "本研究首次调查了大语言模型中说服力、警觉性和任务性能之间的关系，主要贡献在于揭示这些能力是分离的，并呼吁未来AI安全工作中独立监测它们。学术上，这为理解LLMs的社会能力提供了新视角；实际上，在LLMs作为高风险决策顾问的应用中，确保其同时具备良好警觉性和说服力至关重要，以减少被恶意内容误导的风险。未来工作可以进一步探索如何增强LLMs的警觉性，并开发更全面的评估框架。",
      "tags": [
        "Large Language Models",
        "Persuasion",
        "Vigilance",
        "Multi-turn Interaction",
        "AI Safety"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:14.653725Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.19424",
    "title": "Hepato-LLaVA: An Expert MLLM with Sparse Topo-Pack Attention for Hepatocellular Pathology Analysis on Whole Slide Images",
    "authors": [
      "Yuxuan Yang",
      "Zhonghao Yan",
      "Yi Zhang",
      "Bo Yun",
      "Muxi Diao",
      "Guowei Zhao",
      "Kongming Liang",
      "Wenbin Li",
      "Zhanyu Ma"
    ],
    "abstract": "Hepatocellular Carcinoma diagnosis relies heavily on the interpretation of gigapixel Whole Slide Images. However, current computational approaches are constrained by fixed-resolution processing mechanisms and inefficient feature aggregation, which inevitably lead to either severe information loss or high feature redundancy. To address these challenges, we propose Hepato-LLaVA, a specialized Multi-modal Large Language Model designed for fine-grained hepatocellular pathology analysis. We introduce a novel Sparse Topo-Pack Attention mechanism that explicitly models 2D tissue topology. This mechanism effectively aggregates local diagnostic evidence into semantic summary tokens while preserving global context. Furthermore, to overcome the lack of multi-scale data, we present HepatoPathoVQA, a clinically grounded dataset comprising 33K hierarchically structured question-answer pairs validated by expert pathologists. Our experiments demonstrate that Hepato-LLaVA achieves state-of-the-art performance on HCC diagnosis and captioning tasks, significantly outperforming existing methods. Our code and implementation details are available at https://pris-cv.github.io/Hepto-LLaVA/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.19424.pdf",
    "abs_url": "https://arxiv.org/abs/2602.19424",
    "published": "2026-02-23T01:43:32Z",
    "updated": "2026-02-26T09:59:43Z",
    "comment": "10 pages, 3 figures",
    "light_analysis": {
      "overview": "本文提出了Hepato-LLaVA，一个采用稀疏拓扑包注意力机制的多模态大语言模型，用于肝细胞癌全切片图像的精细病理分析。",
      "motivation": "肝癌（HCC）诊断高度依赖千兆像素全切片图像，但现有计算方法存在固定分辨率处理和低效特征聚合的问题，导致信息严重丢失或特征高度冗余。这些问题限制了自动病理分析的准确性和效率，使得临床诊断仍面临挑战。本研究旨在开发一种新方法，以克服这些局限性，提升对复杂组织结构的理解，从而为肝癌早期检测和精准医疗提供支持。",
      "method": "本研究提出Hepato-LLaVA，一个专门为肝细胞病理分析设计的多模态大语言模型。核心创新是稀疏拓扑包注意力机制，该机制显式建模2D组织拓扑，有效聚合局部诊断证据为语义摘要token，同时保持全局上下文，以减少特征冗余。此外，为解决多尺度数据缺乏，团队构建了HepatoPathoVQA数据集，包含33K个由专家验证的分层结构问答对，为模型训练提供了高质量临床基础。",
      "result": "实验结果显示，Hepato-LLaVA在肝细胞癌（HCC）诊断和图像描述任务上实现了最先进的性能。该方法显著优于现有基线方法，具体表现为在诊断准确性和captioning质量上的提升。尽管摘要未明确说明具体数据（如准确率百分比），但可以推断其在多个评估指标上达到领先水平，验证了稀疏拓扑包注意力机制的有效性和模型的优越性。",
      "conclusion": "本研究的主要贡献是开发了Hepato-LLaVA模型和稀疏拓扑包注意力机制，以及构建了HepatoPathoVQA数据集。这为肝癌病理分析提供了高效的计算工具，具有重要的学术价值和临床应用潜力，可助力自动化诊断和医学研究。局限性包括摘要未明确说明模型的通用性或计算成本，未来工作可扩展模型到其他病理类型或进一步优化注意力机制的效率。",
      "tags": [
        "Multi-modal Large Language Model",
        "Sparse Topo-Pack Attention",
        "Whole Slide Images",
        "Hepatocellular Carcinoma",
        "Medical Imaging"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:19.794105Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.19327",
    "title": "Soft Sequence Policy Optimization",
    "authors": [
      "Svetlana Glazyrina",
      "Maksim Kryzhanovskiy",
      "Roman Ischenko"
    ],
    "abstract": "A significant portion of recent research on Large Language Model (LLM) alignment focuses on developing new policy optimization methods based on Group Relative Policy Optimization (GRPO). Two prominent directions have emerged: (i) a shift toward sequence-level importance sampling weights that better align with the sequence-level rewards used in many tasks, and (ii) alternatives to PPO-style clipping that aim to avoid the associated loss of training signal and entropy collapse. We introduce Soft Sequence Policy Optimization, an off-policy reinforcement learning objective that incorporates soft gating functions over token-level probability ratios within sequence-level importance weights. We provide theoretical motivation for SSPO and investigate practical modifications to improve optimization behavior. Empirically, we show that SSPO improves training stability and performance in mathematical reasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.19327.pdf",
    "abs_url": "https://arxiv.org/abs/2602.19327",
    "published": "2026-02-22T20:21:00Z",
    "updated": "2026-02-26T08:54:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了Soft Sequence Policy Optimization (SSPO)，一种结合软门控函数改进大型语言模型对齐训练的离线强化学习方法。",
      "motivation": "近期大型语言模型对齐研究专注于基于Group Relative Policy Optimization (GRPO) 的政策优化方法。现有研究揭示两个主要方向：转向序列级重要性采样权重以更好匹配任务中的序列级奖励，以及寻找替代PPO-style剪裁的方法以避免训练信号损失和熵崩溃。SSPO旨在解决这些不足，通过新方法提升训练效率和模型性能。",
      "method": "论文提出的Soft Sequence Policy Optimization (SSPO) 是一种离线强化学习目标，核心创新在于在序列级重要性采样权重中融入软门控函数，以处理token级概率比率。该方法提供了理论动机，并探讨了实际修改以优化训练行为，包括改进权重计算，旨在更好地结合序列级奖励。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实证结果表明，SSPO在数学推理任务中显著改善了训练稳定性和性能。与基线方法相比，该方法在相关指标上表现出进步，但摘要未提供具体的数据支撑如准确率提升或效率改进的数值。实验验证了其有效性，尤其在复杂任务中的表现增强。",
      "conclusion": "论文的主要贡献是提出了SSPO方法，通过软门控函数集成到序列级重要性权重中，提升了LLM对齐的训练效果。该研究在学术上提供了新的强化学习目标，实际应用中可增强模型在数学推理等任务的表现。潜在的局限性或未来工作摘要未明确说明，但暗示了优化行为改进的价值。",
      "tags": [
        "Large Language Model",
        "Group Relative Policy Optimization",
        "Sequence-Level Importance Sampling",
        "Soft Gating Functions",
        "Off-policy Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:18.529168Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.19190",
    "title": "FUSAR-GPT : A Spatiotemporal Feature-Embedded and Two-Stage Decoupled Visual Language Model for SAR Imagery",
    "authors": [
      "Xiaokun Zhang",
      "Yi Yang",
      "Ziqi Ye",
      "Baiyun",
      "Xiaorong Guo",
      "Qingchen Fang",
      "Ruyi Zhang",
      "Xinpeng Zhou",
      "Haipeng Wang"
    ],
    "abstract": "Research on the intelligent interpretation of all-weather, all-time Synthetic Aperture Radar (SAR) is crucial for advancing remote sensing applications. In recent years, although Visual Language Models (VLMs) have demonstrated strong open-world understanding capabilities on RGB images, their performance is severely limited when directly applied to the SAR field due to the complexity of the imaging mechanism, sensitivity to scattering features, and the scarcity of high-quality text corpora. To systematically address this issue, we constructed the inaugural SAR Image-Text-AlphaEarth feature triplet dataset and developed FUSAR-GPT, a VLM specifically for SAR. FUSAR-GPT innovatively introduces a geospatial baseline model as a 'world knowledge' prior and embeds multi-source remote-sensing temporal features into the model's visual backbone via 'spatiotemporal anchors', enabling dynamic compensation for the sparse representation of targets in SAR images. Furthermore, we designed a two-stage SFT strategy to decouple the knowledge injection and task execution of large models. The spatiotemporal feature embedding and the two-stage decoupling paradigm enable FUSAR-GPT to achieve state-of-the-art performance across several typical remote sensing visual-language benchmark tests, significantly outperforming mainstream baseline models by over 12%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.19190.pdf",
    "abs_url": "https://arxiv.org/abs/2602.19190",
    "published": "2026-02-22T13:40:17Z",
    "updated": "2026-02-26T09:45:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "FUSAR-GPT是一种针对合成孔径雷达图像的视觉语言模型，通过时空特征嵌入和两阶段解耦策略，提升了SAR图像的智能理解和解释能力。",
      "motivation": "研究动机源于合成孔径雷达（SAR）的全天候、全天时特性对遥感应用至关重要，但现有视觉语言模型直接应用于SAR时表现受限，因为SAR成像机制复杂、对散射特征敏感，且高质量文本语料稀缺。这限制了SAR图像智能解释的发展，因此需要开发专门模型来解决这些问题，以推动遥感技术的进步。",
      "method": "研究方法包括构建首个SAR图像-文本-AlphaEarth特征三元组数据集，并开发FUSAR-GPT模型。该模型创新性地引入地理空间基线模型作为先验知识，通过时空锚点将多源遥感时间特征嵌入视觉骨干，以动态补偿SAR图像中目标的稀疏表示。此外，设计了两阶段监督微调策略，解耦大模型的知识注入和任务执行，优化模型性能。",
      "result": "主要实验结果表明，FUSAR-GPT在多个典型遥感视觉语言基准测试中取得了最先进的性能，显著优于主流基线模型，性能提升超过12%。这证明了模型在SAR图像理解方面的有效性和优越性，显示出在解决复杂成像机制下的高准确率。",
      "conclusion": "结论是FUSAR-GPT通过时空特征嵌入和两阶段解耦策略，成功解决了SAR图像智能解释的挑战。该研究推动了SAR与视觉语言模型的结合，提升了遥感应用的效率和准确性，为SAR数据处理提供了新方法。未来工作可能包括扩展数据集和进一步优化模型泛化能力，但摘要未明确说明具体方向。",
      "tags": [
        "Synthetic Aperture Radar (SAR)",
        "Visual Language Model (VLM)",
        "Spatiotemporal Feature Embedding",
        "Two-Stage Fine-Tuning",
        "Remote Sensing Imaging"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:31.909912Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.19128",
    "title": "K-Search: LLM Kernel Generation via Co-Evolving Intrinsic World Model",
    "authors": [
      "Shiyi Cao",
      "Ziming Mao",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "abstract": "Optimizing GPU kernels is critical for efficient modern machine learning systems yet remains challenging due to the complex interplay of design factors and rapid hardware evolution. Existing automated approaches typically treat Large Language Models (LLMs) merely as stochastic code generators within heuristic-guided evolutionary loops. These methods often struggle with complex kernels requiring coordinated, multi-step structural transformations, as they lack explicit planning capabilities and frequently discard promising strategies due to inefficient or incorrect intermediate implementations. To address this, we propose Search via Co-Evolving World Model and build K-Search based on this method. By replacing static search heuristics with a co-evolving world model, our framework leverages LLMs' prior domain knowledge to guide the search, actively exploring the optimization space. This approach explicitly decouples high-level algorithmic planning from low-level program instantiation, enabling the system to navigate non-monotonic optimization paths while remaining resilient to temporary implementation defects. We evaluate K-Search on diverse, complex kernels from FlashInfer, including GQA, MLA, and MoE kernels. Our results show that K-Search significantly outperforms state-of-the-art evolutionary search methods, achieving an average 2.10x improvement and up to a 14.3x gain on complex MoE kernels. On the GPUMode TriMul task, K-Search achieves state-of-the-art performance on H100, reaching 1030us and surpassing both prior evolution and human-designed solutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.19128.pdf",
    "abs_url": "https://arxiv.org/abs/2602.19128",
    "published": "2026-02-22T11:06:22Z",
    "updated": "2026-02-26T10:37:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于协同演化世界模型的K-Search方法，通过解耦算法规划与程序实例化，显著提升GPU内核生成的优化效率。",
      "motivation": "GPU内核优化对现代机器学习系统的高效运行至关重要，但现有自动化方法，如将大型语言模型视为随机代码生成器在启发式演化循环中使用，在应对需要多步协调结构变换的复杂内核时存在不足。这些方法因缺乏显式规划能力，且常因中间实现缺陷而丢弃有前景策略，导致优化效果受限。因此，迫切需要一种能处理非单调优化路径并增强鲁棒性的新方法。",
      "method": "论文提出Search via Co-Evolving World Model框架，并构建K-Search作为实现。该方法的关键创新是用协同演化世界模型替代传统静态搜索启发式，利用大型语言模型的先验领域知识主动引导优化搜索，显式解耦高级算法规划和低级程序实例化。这使得系统能够探索更广泛的优化空间，同时容忍临时实现缺陷。评估基于FlashInfer数据集中的复杂内核，如GQA、MLA和MoE，以验证技术有效性。",
      "result": "K-Search在多样复杂GPU内核上表现优异，显著超越现有演化搜索方法，平均性能提升2.10倍，在复杂MoE内核上最高提升达14.3倍。在GPUMode TriMul任务中，K-Search在H100 GPU上实现1030微秒的性能，达到最先进水平，超越了先前的演化方法和人工设计解决方案，证实了其在硬件加速优化中的高效性。",
      "conclusion": "该研究的主要贡献是开发了一种基于协同演化世界模型的新优化框架，有效解决了GPU内核生成中的复杂性问题。学术上，通过结合大型语言模型和演化搜索引入创新方法；应用上，显著提升内核性能，有潜力加速机器学习系统部署。尽管摘要未明确说明，但未来工作可能扩展到更多硬件类型或优化场景，以进一步验证通用性。",
      "tags": [
        "Large Language Models",
        "Co-Evolving World Model",
        "Kernel Generation",
        "Evolutionary Search",
        "GPU Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:23.275979Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.18509",
    "title": "Depth from Defocus via Direct Optimization",
    "authors": [
      "Holly Jackson",
      "Caleb Adams",
      "Ignacio Lopez-Francos",
      "Benjamin Recht"
    ],
    "abstract": "Though there exists a reasonable forward model for blur based on optical physics, recovering depth from a collection of defocused images remains a computationally challenging optimization problem. In this paper, we show that with contemporary optimization methods and reasonable computing resources, a global optimization approach to depth from defocus is feasible. Our approach rests on alternating minimization. When holding the depth map fixed, the forward model is linear with respect to the all-in-focus image. When holding the all-in-focus image fixed, the depth at each pixel can be computed independently, enabling embarrassingly parallel computation. We show that alternating between convex optimization and parallel grid search can effectively solve the depth-from-defocus problem at higher resolutions than current deep learning methods. We demonstrate our approach on benchmark datasets with synthetic and real defocus blur and show promising results compared to prior approaches. Our code is available at github.com/hollyjackson/dfd.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.18509.pdf",
    "abs_url": "https://arxiv.org/abs/2602.18509",
    "published": "2026-02-18T22:24:05Z",
    "updated": "2026-02-26T05:47:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于交替最小化和并行计算的全局优化方法，用于从离焦图像中高效恢复深度。",
      "motivation": "从离焦图像中恢复深度是一个基于光学物理的前向模型问题，但长期以来一直面临计算挑战。现有方法，如深度学习方法，在高分辨率处理时可能效率较低或精度不足。本研究旨在解决这一问题，通过现代优化技术和合理计算资源，证明全局优化方法在深度从离焦问题上具有可行性，从而克服当前方法的局限性，推动计算机视觉中深度估计技术的发展。",
      "method": "研究方法采用交替最小化策略。当深度图固定时，前向模型对全焦图像呈线性关系，可通过凸优化求解；当全焦图像固定时，每个像素的深度可独立计算，支持并行化处理。该方法结合凸优化和并行网格搜索，能够高效处理高分辨率图像，避免传统优化方法的计算瓶颈，关键创新在于利用并行计算提升效率。",
      "result": "在合成和真实离焦模糊的基准数据集上，本方法展示了有希望的结果。与先前方法相比，它能够在更高分辨率下有效运行，尽管摘要未明确说明具体的性能指标如准确率提升。实验表明，交替优化策略优于当前深度学习方法在分辨率方面的限制，为深度从离焦问题提供了更高效的解决方案。",
      "conclusion": "本文的主要贡献是证明了深度从离焦的全局优化方法通过交替最小化和并行计算变得可行。学术上，这展示了传统优化技术在现代计算资源下的潜力；实际应用上，为计算机视觉中的深度估计提供了新思路。未来工作可能包括进一步优化算法效率或扩展到更复杂的真实世界场景，摘要未明确说明具体局限性。",
      "tags": [
        "Depth from Defocus",
        "Alternating Minimization",
        "Convex Optimization",
        "Parallel Computing",
        "Grid Search"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:30.632872Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.13507",
    "title": "Benchmarking Video Foundation Models for Remote Parkinson's Disease Screening",
    "authors": [
      "Md Saiful Islam",
      "Ekram Hossain",
      "Abdelrahman Abdelkader",
      "Tariq Adnan",
      "Fazla Rabbi Mashrur",
      "Sooyong Park",
      "Praveen Kumar",
      "Qasim Sudais",
      "Natalia Chunga",
      "Nami Shah",
      "Jan Freyberg",
      "Christopher Kanan",
      "Ruth Schneider",
      "Ehsan Hoque"
    ],
    "abstract": "Video-based assessments offer a scalable pathway for remote Parkinson's disease (PD) screening. While traditional approaches rely on handcrafted features mimicking clinical scales, recent advances in video foundation models (VFMs) enable representation learning without task-specific customization. However, the comparative effectiveness of different VFM architectures across diverse clinical tasks remains poorly understood. We present a large-scale systematic study using a novel video dataset from 1,888 participants (727 with PD), comprising 32,847 videos across 16 standardized clinical tasks. We evaluate seven state-of-the-art VFMs -- including VideoPrism, V-JEPA, ViViT, and VideoMAE -- to determine their robustness in clinical screening. By evaluating frozen embeddings with a linear classification head, we demonstrate that task saliency is highly model-dependent: VideoPrism excels in capturing visual speech kinematics (no audio) and facial expressivity, while V-JEPA proves superior for upper-limb motor tasks. Notably, TimeSformer remains highly competitive for rhythmic tasks like finger tapping. Our experiments yield AUCs of 76.4 - 85.3% and accuracies of 71.5 - 80.6%. While high specificity (up to 90.3%) suggests strong potential for ruling out healthy individuals, the lower sensitivity (43.2 - 57.3%) highlights the need for task-aware calibration and integration of multiple tasks and modalities. Overall, this work establishes a rigorous baseline for VFM-based PD screening and provides a roadmap for selecting suitable tasks and architectures in remote neurological monitoring. Code and anonymized structured data are publicly available: https://anonymous.4open.science/r/parkinson\\_video\\_benchmarking-A2C5",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.13507.pdf",
    "abs_url": "https://arxiv.org/abs/2602.13507",
    "published": "2026-02-13T22:36:42Z",
    "updated": "2026-02-26T15:15:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过大规模基准测试，确定了不同视频基础模型在帕金森病远程筛查中的优势和适用性。",
      "motivation": "远程帕金森病筛查需要高效可扩展的方法，传统基于手工特征的方法难以泛化，而视频基础模型允许通用表示学习。然而，不同VFM架构在不同临床任务中的性能差异显著，且现有研究缺乏系统比较，这限制了远程神经监测的实际应用。因此，本研究旨在评估多种VFMs在标准化任务中的鲁棒性，以填补这一空白，优化筛查流程。",
      "method": "研究采用一个包含1,888名参与者（727名帕金森患者）的新视频数据集，涵盖16个标准化临床任务，总计32,847个视频。评估了七种先进的视频基础模型，如VideoPrism、V-JEPA、ViViT和VideoMAE。通过冻结模型嵌入并使用线性分类头进行测试，避免了任务特定训练，专注于模型的表示能力。这种方法确保了公平比较，并揭示了模型依赖性，为临床筛查提供技术指导。",
      "result": "实验结果显示，模型性能高度依赖任务类型：VideoPrism在捕捉视觉语音动力学和面部表达方面表现最佳，V-JEPA在上肢运动任务中更优，TimeSformer在手指敲击等节奏任务中保持竞争力。整体AUC范围为76.4%至85.3%，准确率为71.5%至80.6%，高特异性（最高90.3%）表明能有效排除健康个体，但较低敏感性（43.2%至57.3%）提示需要改进校准和集成多任务。",
      "conclusion": "本研究为基于视频基础模型的帕金森病远程筛查建立了严格的基线，通过揭示模型与任务的依赖关系，提供了选择合适架构和任务的路线图，具有推动远程神经监测发展的学术和实践价值。局限性包括敏感性较低，未来工作可聚焦于任务感知校准、多任务和多模态整合，以提高筛查准确性，代码和匿名数据已公开促进进一步研究。",
      "tags": [
        "Video Foundation Models",
        "Remote Parkinson's Disease Screening",
        "Benchmarking",
        "Linear Classification",
        "Clinical Video Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:55.634578Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.11221",
    "title": "The Automatic Verification of Image-Text Claims (AVerImaTeC) Shared Task",
    "authors": [
      "Rui Cao",
      "Zhenyun Deng",
      "Yulong Chen",
      "Michael Schlichtkrull",
      "Andreas Vlachos"
    ],
    "abstract": "The Automatic Verification of Image-Text Claims (AVerImaTeC) shared task aims to advance system development for retrieving evidence and verifying real-world image-text claims. Participants were allowed to either employ external knowledge sources, such as web search engines, or leverage the curated knowledge store provided by the organizers. System performance was evaluated using the AVerImaTeC score, defined as a conditional verdict accuracy in which a verdict is considered correct only when the associated evidence score exceeds a predefined threshold. The shared task attracted 14 submissions during the development phase and 6 submissions during the testing phase. All participating systems in the testing phase outperformed the baseline provided. The winning team, HUMANE, achieved an AVerImaTeC score of 0.5455. This paper provides a detailed description of the shared task, presents the complete evaluation results, and discusses key insights and lessons learned.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.11221.pdf",
    "abs_url": "https://arxiv.org/abs/2602.11221",
    "published": "2026-02-11T12:32:15Z",
    "updated": "2026-02-26T03:55:17Z",
    "comment": "Shared Task Overview and Summary for the Ninth FEVER Workshop, Co-located at EACL 2026",
    "light_analysis": {
      "overview": "本文介绍了AVerImaTeC共享任务，旨在促进图像-文本声明验证系统的研发。",
      "motivation": "研究动机源于图像-文本声明的自动验证在现实世界中的重要性，特别是在内容审核和虚假信息检测领域。现有方法可能在证据检索和验证准确性方面存在不足，难以有效处理复杂的图像文本关联。共享任务通过公开竞赛形式，吸引多团队参与，以推动技术突破。摘要未明确说明具体不足细节，但强调了通过任务来填补这一需求空白。",
      "method": "研究方法基于共享任务的组织框架，允许参与者选择外部知识源（如网络搜索引擎）或组织者提供的知识库来构建验证系统。核心创新点在于AVerImaTeC分数的定义，它采用条件判断准确率作为评估指标，要求判断正确的同时证据得分必须超过预设阈值，以确保验证的可靠性。摘要未提供具体模型架构或数据集细节，但突出了任务的结构化评估方法。",
      "result": "主要实验结果显示，共享任务在测试阶段共收到6个系统提交，所有系统均超越了基线性能，证明任务有效推动了技术进步。获胜团队HUMANE取得了0.5455的AVerImaTeC分数，提供了具体的量化指标来展示系统性能的提升。数据表明任务吸引了多团队参与，开发阶段有14个提交，展示了该领域的广泛兴趣和竞争潜力。",
      "conclusion": "结论总结了AVerImaTeC共享任务的成功，它通过集思广益促进了图像-文本验证系统的学术发展和实践应用。研究为相关领域提供了标准评估基准，具有重要的学术价值；在实际应用中，有助于提升信息真实性和内容审核效率。未来工作方向可能包括优化评估指标或扩展任务范围，摘要未明确说明局限性，但暗示了任务可进一步改进。",
      "tags": [
        "Image-Text Verification",
        "Evidence Retrieval",
        "Shared Task",
        "Conditional Verdict Accuracy"
      ]
    },
    "analyzed_at": "2026-02-27T03:47:51.061898Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.10195",
    "title": "Versor: A Geometric Sequence Architecture",
    "authors": [
      "Truong Minh Huy",
      "Edward Hirst"
    ],
    "abstract": "A novel sequence architecture is introduced, Versor, which uses Conformal Geometric Algebra (CGA) in place of traditional linear operations to achieve structural generalization and significant performance improvements on a variety of tasks, while offering improved interpretability and efficiency. By embedding states in the $Cl_{4,1}$ manifold and evolving them via geometric transformations (rotors), Versor natively represents $SE(3)$-equivariant relationships without requiring explicit structural encoding. Versor is validated on chaotic N-body dynamics, topological reasoning, and standard multimodal benchmarks (CIFAR-10, WikiText-103), consistently outperforming Transformers, Graph Networks, and geometric baselines (GATr, EGNN). Key results include: orders-of-magnitude fewer parameters ($200\\times$ vs. Transformers); interpretable attention decomposing into proximity and orientational components; zero-shot scale generalization (0.993 vs. 0.070 MCC for ViT); and featuring a Recursive Rotor Accumulator (RRA) for $O(L)$ linear temporal complexity in dynamical systems, and a Geometric Product Attention (GPA) mechanism for $O(L^{2})$ global relational modeling, allowing for task-specific architectural pruning or hybridization depending on the required scale. In out-of-distribution tests, Versor maintains stable predictions while Transformers fail catastrophically. Custom Clifford kernels achieve a cumulative over $100\\times$ speedup via bit-masked contraction and specialized Matrix Isomorphism kernels, reducing per-step latency to 1.05 ms and outperforming highly-optimized Transformer baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-th"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.10195.pdf",
    "abs_url": "https://arxiv.org/abs/2602.10195",
    "published": "2026-02-10T19:00:02Z",
    "updated": "2026-02-26T12:37:43Z",
    "comment": "19+28 pages, 5 figures",
    "light_analysis": {
      "overview": "提出Versor几何序列架构，利用共形几何代数替代线性操作，实现结构泛化和显著性能提升，增强可解释性。",
      "motivation": "研究动机源于传统序列架构在处理几何关系和结构泛化时的局限性。现有方法如Transformers和Graph Networks在复杂几何变换中效率低、泛化能力差，特别是在分布外测试中易出现灾难性失败，这在动态系统和多模态任务中至关重要。Versor通过引入几何代数，旨在解决这些问题，提供更自然的建模方式以提升性能和可解释性，适用于混沌动力学、拓扑推理等多样化任务。",
      "method": "研究方法基于共形几何代数，将状态嵌入$Cl_{4,1}$流形，通过几何变换（rotors）演化状态，原生实现$SE(3)$-等变关系，无需显式结构编码。核心创新包括递归转子累积器（RRA）用于动态系统中的$O(L)$线性时间复杂性，以及几何产品注意力（GPA）机制用于$O(L^{2})$全局关系建模，允许任务特定架构调整。此外，定制Clifford核采用位掩码收缩和专用矩阵同构核以加速计算。",
      "result": "主要实验结果表明，Versor在多个任务上优于基线：参数数量级减少（相对于Transformers减少200倍），零样本尺度泛化MCC达0.993（ViT为0.070），在混沌N-body动力学、拓扑推理和标准基准（如CIFAR-10、WikiText-103）上表现优异。分布外测试中Versor保持稳定预测，而Transformers灾难性失败。定制核实现累计超过100倍速度提升，每步延迟降至1.05 ms，效率远超高度优化的Transformer基线。",
      "conclusion": "Versor通过几何代数方法显著提升了序列建模的性能、效率和可解释性，为复杂几何关系处理提供新路径。其学术价值在于将几何代数引入深度学习，扩展理论框架；实际应用价值广泛，适用于动态系统、多模态学习等领域。未来工作可探索更多几何代数应用或优化架构以减少计算成本，潜在局限性包括对特定几何任务的依赖性，摘要未明确说明具体限制。",
      "tags": [
        "Conformal Geometric Algebra",
        "Geometric Sequence Architecture",
        "Rotor Transformations",
        "Recursive Rotor Accumulator",
        "Geometric Product Attention"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:16.232811Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.08683",
    "title": "OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence",
    "authors": [
      "Feilong Tang",
      "Xiang An",
      "Yunyao Yan",
      "Yin Xie",
      "Bin Qin",
      "Kaicheng Yang",
      "Yifei Shen",
      "Yuanhan Zhang",
      "Chunyuan Li",
      "Shikun Feng",
      "Changrui Chen",
      "Huajie Tan",
      "Ming Hu",
      "Manyuan Zhang",
      "Bo Li",
      "Ziyong Feng",
      "Ziwei Liu",
      "Zongyuan Ge",
      "Jiankang Deng"
    ],
    "abstract": "Hypothesis. Artificial general intelligence is, at its core, a compression problem. Effective compression demands resonance: deep learning scales best when its architecture aligns with the fundamental structure of the data. These are the fundamental principles. Yet, modern vision architectures have strayed from these truths: visual signals are highly redundant, while discriminative information, the surprise, is sparse. Current models process dense pixel grids uniformly, wasting vast compute on static background rather than focusing on the predictive residuals that define motion and meaning. We argue that to solve visual understanding, we must align our architectures with the information-theoretic principles of video, i.e., Codecs.   Method. OneVision-Encoder encodes video by compressing predictive visual structure into semantic meaning. By adopting Codec Patchification, OV-Encoder abandons uniform computation to focus exclusively on the 3.1%-25% of regions rich in signal entropy. To unify spatial and temporal reasoning under irregular token layouts, OneVision-Encoder employs a shared 3D RoPE and is trained with a large-scale cluster discrimination objective over more than one million semantic concepts, jointly capturing object permanence and motion dynamics.   Evidence. The results validate our core hypothesis: efficiency and accuracy are not a trade-off; they are positively correlated. When integrated into LLM, it consistently outperforms strong vision backbones such as Qwen3-ViT and SigLIP2 across 16 image, video, and document understanding benchmarks, despite using substantially fewer visual tokens and pretraining data. Notably, on video understanding tasks, OV-Encoder achieves an average improvement of 4.1% over Qwen3-ViT. Codec-aligned, patch-level sparsity is a foundational principle, enabling OV-Encoder as a scalable engine for next-generation visual generalists.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.08683.pdf",
    "abs_url": "https://arxiv.org/abs/2602.08683",
    "published": "2026-02-09T14:06:17Z",
    "updated": "2026-02-26T04:09:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于 Codec-aligned sparsity 的 OneVision-Encoder，通过聚焦稀疏信息区域实现视频理解的高效性和准确性。",
      "motivation": "现代视觉架构在处理视频时均匀处理所有像素，浪费计算资源在冗余背景上，而关键判别信息（如运动和意义）稀疏分布。现有方法如 Qwen3-ViT 未能与信息论原理对齐，导致效率和准确性权衡，限制了视觉理解的性能提升。因此，研究旨在通过对齐视频编解码器原理，开发更有效的架构，以解决计算资源浪费和性能瓶颈问题，推动多模态智能的发展。",
      "method": "OneVision-Encoder 采用 Codec Patchification 技术，放弃均匀计算，仅处理信号熵丰富的区域（占比 3.1%-25%）。模型使用共享的 3D RoPE 统一空间和时间推理，并通过大规模聚类判别目标训练，涵盖一百万个语义概念，共同捕捉对象持久性和运动动力学。核心创新在于将稀疏性与信息论对齐，利用 patch-level 处理实现高效视频编码，为模型提供更好的语义表示。",
      "result": "实验显示，OV-Encoder 在 16 个图像、视频和文档理解基准上持续优于 Qwen3-ViT 和 SigLIP2，尽管使用更少的视觉令牌和预训练数据。具体在视频理解任务上，平均准确率比 Qwen3-ViT 提高 4.1%，验证了效率和准确性的正相关性。结果表明，Codec-aligned sparsity 能有效提升模型性能，同时降低计算成本，展现出优于基线的综合表现。",
      "conclusion": "论文证实 Codec-aligned sparsity 是视觉架构的基本原则，通过 OneVision-Encoder 实现了高效且准确的视频理解。其贡献在于提出新的架构对齐方法，具有学术价值，为下一代视觉通才模型提供可扩展基础。未来工作可扩展至更多模态或任务，并进一步优化稀疏性策略，以提升实际应用中的鲁棒性和适应性。",
      "tags": [
        "Codec-Aligned Sparsity",
        "Codec Patchification",
        "3D RoPE",
        "Cluster Discrimination",
        "Multimodal Video Encoding"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:21.087147Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.08470",
    "title": "Learning Credal Ensembles via Distributionally Robust Optimization",
    "authors": [
      "Kaizheng Wang",
      "Ghifari Adam Faza",
      "Fabio Cuzzolin",
      "Siu Lun Chau",
      "David Moens",
      "Hans Hallez"
    ],
    "abstract": "Credal predictors are models that are aware of epistemic uncertainty and produce a convex set of probabilistic predictions. They offer a principled way to quantify predictive epistemic uncertainty (EU) and have been shown to improve model robustness in various settings. However, most state-of-the-art methods mainly define EU as disagreement caused by random training initializations, which mostly reflects sensitivity to optimization randomness rather than uncertainty from deeper sources. To address this, we define EU as disagreement among models trained with varying relaxations of the i.i.d. assumption between training and test data. Based on this idea, we propose CreDRO, which learns an ensemble of plausible models through distributionally robust optimization. As a result, CreDRO captures EU not only from training randomness but also from meaningful disagreement due to potential distribution shifts between training and test data. Empirical results show that CreDRO consistently outperforms existing credal methods on tasks such as out-of-distribution detection across multiple benchmarks and selective classification in medical applications.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.08470.pdf",
    "abs_url": "https://arxiv.org/abs/2602.08470",
    "published": "2026-02-09T10:16:43Z",
    "updated": "2026-02-26T08:23:39Z",
    "comment": "32 pages",
    "light_analysis": {
      "overview": "CreDRO通过分布鲁棒优化学习credal集合，以更全面地捕获认知不确定性并优于现有方法。",
      "motivation": "Credal predictors作为一种量化认知不确定性的模型，被广泛用于提高机器学习模型的鲁棒性。然而，当前主流方法主要将认知不确定性定义为随机训练初始化引起的模型分歧，这主要反映了优化过程的随机性，而非更深层的不确定性来源，如训练与测试数据间的分布差异。因此，本研究旨在通过重新定义认知不确定性以包含分布偏移的考量，提出更全面的不确定性量化方法，以应对实际应用中数据分布变化带来的挑战，从而提高模型的可靠性和泛化能力。",
      "method": "本文提出CreDRO方法，其核心是通过分布鲁棒优化学习一个credal模型集合。关键创新点是将认知不确定性定义为在不同训练数据分布假设下训练的模型之间的分歧，具体通过放松训练和测试数据的独立同分布假设来实现。CreDRO利用分布鲁棒优化技术，训练一个模型集合，这些模型在面对数据分布扰动时保持鲁棒，从而不仅捕获由训练随机性引起的不确定性，还能反映由于潜在分布偏移而产生的meaningful disagreement，整合了多种不确定性来源以增强模型性能。",
      "result": "实证结果显示，CreDRO在多个基准测试中表现优异，尤其是在out-of-distribution检测任务和医学应用的选择性分类任务上，一致优于现有的credal方法。这表明CreDRO能够更有效地捕获认知不确定性，提高模型在分布变化下的性能，但摘要未明确说明具体的性能指标如准确率或效率改进。结果强调了该方法在应对数据分布偏移时的优势，为不确定性和鲁棒性研究提供了实证支持，显示出在多种场景下的普适性和有效性。",
      "conclusion": "本研究提出了CreDRO方法，通过分布鲁棒优化学习credal集合，显著改善了认知不确定性的量化，不仅考虑训练随机性，还整合了潜在分布偏移的影响。这项工作提高了模型在分布变化下的鲁棒性，特别是在out-of-distribution检测和选择性分类等任务中具有重要应用价值，为不确定性和鲁棒性领域提供了新视角。未来工作可扩展到更多复杂场景，或结合其他优化技术以进一步优化性能，摘要未明确说明局限性，但潜在方向包括进一步的理论分析或在实际部署中的验证。",
      "tags": [
        "Credal Predictors",
        "Epistemic Uncertainty",
        "Distributionally Robust Optimization",
        "Ensemble Learning",
        "Out-of-Distribution Detection"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:34.538408Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.21233",
    "title": "AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression",
    "authors": [
      "Rui Cen",
      "QiangQiang Hu",
      "Hong Huang",
      "Hong Liu",
      "Song Liu",
      "Xin Luo",
      "Lin Niu",
      "Yifan Tan",
      "Decheng Wu",
      "Linchuan Xie",
      "Rubing Yang",
      "Guanghua Yu",
      "Jianchen Zhu"
    ],
    "abstract": "This technical report introduces AngelSlim, a comprehensive and versatile toolkit for large model compression developed by the Tencent Hunyuan team. By consolidating cutting-edge algorithms, including quantization, speculative decoding, token pruning, and distillation. AngelSlim provides a unified pipeline that streamlines the transition from model compression to industrial-scale deployment. To facilitate efficient acceleration, we integrate state-of-the-art FP8 and INT8 Post-Training Quantization (PTQ) algorithms alongside pioneering research in ultra-low-bit regimes, featuring HY-1.8B-int2 as the first industrially viable 2-bit large model. Beyond quantization, we propose a training-aligned speculative decoding framework compatible with multimodal architectures and modern inference engines, achieving 1.8x to 2.0x throughput gains without compromising output correctness. Furthermore, we develop a training-free sparse attention framework that reduces Time-to-First-Token (TTFT) in long-context scenarios by decoupling sparse kernels from model architectures through a hybrid of static patterns and dynamic token selection. For multimodal models, AngelSlim incorporates specialized pruning strategies, namely IDPruner for optimizing vision tokens via Maximal Marginal Relevance and Samp for adaptive audio token merging and pruning. By integrating these compression strategies from low-level implementations, AngelSlim enables algorithm-focused research and tool-assisted deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.21233.pdf",
    "abs_url": "https://arxiv.org/abs/2602.21233",
    "published": "2026-02-07T07:02:56Z",
    "updated": "2026-02-26T04:50:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "AngelSlim是一个全面的大型模型压缩工具包，通过整合量化、推测解码和剪枝等先进算法，提供统一流水线以简化工业部署，并实现高效加速。",
      "motivation": "大型模型在部署时面临高计算成本和效率挑战，现有压缩工具可能不够全面或难以集成。AngelSlim旨在解决这一问题，通过整合多种前沿压缩技术，提供一个易于访问和高效的工具包，促进从研究到工业应用的平滑过渡，应对模型部署的实际困难。",
      "method": "AngelSlim整合了多种压缩算法，包括后训练量化（FP8和INT8）、2-bit量化模型HY-1.8B-int2、训练对齐的推测解码框架（兼容多模态架构和现代推理引擎）、无需训练的稀疏注意力框架（通过静态模式和动态令牌选择减少长上下文首次令牌时间），以及针对多模态模型的专门剪枝策略如IDPruner（优化视觉令牌）和Samp（自适应音频令牌合并与剪枝）。",
      "result": "论文展示了HY-1.8B-int2作为首款工业级2-bit大模型；推测解码框架实现了1.8倍到2.0倍的吞吐量提升，且不损害输出正确性；稀疏注意力框架减少了长上下文场景中的首次令牌时间。摘要未明确说明与基线方法的详细对比数据。",
      "conclusion": "AngelSlim通过集成多种压缩策略，为大型模型提供了全面的压缩解决方案，简化了部署流程，支持算法研究和工具辅助应用。其意义在于推动模型压缩技术的发展，提高工业部署的效率。未来工作可能包括扩展更多压缩技术和优化兼容性。",
      "tags": [
        "Model Compression",
        "Quantization",
        "Speculative Decoding",
        "Sparse Attention",
        "Token Pruning"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:30.475837Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.02334",
    "title": "VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations",
    "authors": [
      "Fatemeh Zargarbashi",
      "Dhruv Agrawal",
      "Jakob Buhmann",
      "Martin Guay",
      "Stelian Coros",
      "Robert W. Sumner"
    ],
    "abstract": "Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating codebook learning with contrastive learning and a novel information leakage loss to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02334.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02334",
    "published": "2026-02-02T16:58:17Z",
    "updated": "2026-02-26T13:40:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于残差量化变分自编码器的运动风格与内容解耦方法，通过量化代码交换实现无需微调的风格迁移。",
      "motivation": "人类运动数据包含语义内容和细微风格特征，传统建模方法难以有效解耦两者，导致风格迁移等应用效果受限。研究旨在解决风格与内容的纠缠问题，以提升运动分析和编辑的准确性和效率。现有方法可能无法区分粗粒度内容与细粒度风格，使得风格迁移需要额外训练或微调，从而影响泛化能力。",
      "method": "该方法采用残差向量量化变分自编码器（RVQ-VAEs）学习从粗到细的运动表示，其中内容对应粗运动属性，风格捕捉细细节。通过结合代码书学习、对比学习和新颖的信息泄漏损失，在多代码书中组织和分离风格与内容。核心创新是推理时的量化代码交换技术，通过交换风格代码实现风格迁移，无需对新风格进行微调或训练。",
      "result": "摘要未明确说明具体实验数据或性能指标，但指出该框架在多个推理应用中表现出强泛化能力，包括风格迁移、风格移除和运动混合。这些应用展示了方法在解耦风格和内容方面的有效性，但缺乏与基线方法的定量对比数据。结果强调了方法的实用性和多用途性。",
      "conclusion": "本研究贡献了一种有效的运动风格与内容解耦方法，利用RVQ-VAEs和量化代码交换技术，实现高效、无需微调的风格迁移。这为运动数据建模提供了新思路，具有学术价值，并在动画、虚拟现实等领域有应用潜力。未来工作可探索扩展到其他数据类型或增强解耦性能。",
      "tags": [
        "Residual Vector Quantized VAE",
        "Contrastive Learning",
        "Style Transfer",
        "Information Leakage Loss",
        "Quantized Code Swapping"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:45.724500Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01434",
    "title": "Phase Transitions for Feature Learning in Neural Networks",
    "authors": [
      "Andrea Montanari",
      "Zihao Wang"
    ],
    "abstract": "According to a popular viewpoint, neural networks learn from data by first identifying low-dimensional representations, and subsequently fitting the best model in this space. Recent works provide a formalization of this phenomenon when learning multi-index models. In this setting, we are given $n$ i.i.d. pairs $({\\boldsymbol x}_i,y_i)$, where the covariate vectors ${\\boldsymbol x}_i\\in\\mathbb{R}^d$ are isotropic, and responses $y_i$ only depend on ${\\boldsymbol x}_i$ through a $k$-dimensional projection ${\\boldsymbol Θ}_*^{\\sf T}{\\boldsymbol x}_i$. Feature learning amounts to learning the latent space spanned by ${\\boldsymbol Θ}_*$.   In this context, we study the gradient descent dynamics of two-layer neural networks under the proportional asymptotics $n,d\\to\\infty$, $n/d\\toδ$, while the dimension of the latent space $k$ and the number of hidden neurons $m$ are kept fixed. Earlier work establishes that feature learning via polynomial-time algorithms is possible if $δ> δ_{\\text{alg}}$, for $δ_{\\text{alg}}$ a threshold depending on the data distribution, and is impossible (within a certain class of algorithms) below $δ_{\\text{alg}}$. Here we derive an analogous threshold $δ_{\\text{NN}}$ for two-layer networks. Our characterization of $δ_{\\text{NN}}$ opens the way to study the dependence of learning dynamics on the network architecture and training algorithm.   The threshold $δ_{\\text{NN}}$ is determined by the following scenario. Training first visits points for which the gradient of the empirical risk is large and learns the directions spanned by these gradients. Then the gradient becomes smaller and the dynamics becomes dominated by negative directions of the Hessian. The threshold $δ_{\\text{NN}}$ corresponds to a phase transition in the spectrum of the Hessian in this second phase.",
    "categories": [
      "cs.LG",
      "math.ST"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01434.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01434",
    "published": "2026-02-01T20:47:36Z",
    "updated": "2026-02-26T18:06:09Z",
    "comment": "75 pages; 17 pdf figures; v2 is a minor revision of v1",
    "light_analysis": {
      "overview": "本文通过分析两层神经网络的梯度下降动力学，推导出特征学习中相变的阈值 δ_NN，揭示了样本复杂度对学习潜在特征的影响。",
      "motivation": "神经网络学习数据依赖于特征学习过程，即先识别低维表示再拟合模型。本研究聚焦于多指数模型，探讨神经网络如何通过梯度下降学习潜在特征空间，以解决特征学习的可行性问题。这个问题至关重要，因为它关系到神经网络的理论基础和实际效率。现有工作已针对一般算法提出阈值 δ_alg，但未深入神经网络架构，这限制了理论对实际训练场景的适用性，因此需要专门分析神经网络的独特动力学行为，以弥补这一不足。",
      "method": "研究采用比例渐近设定，让数据维度 d 和样本数 n 以固定比例 δ 趋近无穷，同时保持潜在空间维度 k 和隐藏神经元数 m 固定。核心方法是分析两层神经网络的梯度下降动力学，关注训练过程中梯度和 Hessian 矩阵谱的变化。关键创新点在于将训练分为两个阶段：第一阶段通过大梯度学习特征方向，第二阶段由 Hessian 的负方向主导，从而基于 Hessian 谱的相变推导出阈值 δ_NN。技术细节包括使用 i.i.d. 数据对，协变量为等向分布，响应依赖于 k 维投影，未使用特定数据集，而是进行理论推导。",
      "result": "本研究推导出特征学习的阈值 δ_NN，适用于两层神经网络，类比于先前工作的 δ_alg。结果显示，当样本复杂度比例 δ 超过 δ_NN 时，特征学习通过梯度下降成为可能；否则，学习受限。这一阈值对应于训练第二阶段 Hessian 谱发生的相变，尽管摘要未明确说明具体数值或性能指标，但理论分析表明 δ_NN 依赖于数据分布和网络参数，为理解神经网络学习动力学提供了定性框架，并与一般算法基线形成对比。",
      "conclusion": "主要贡献是确定了阈值 δ_NN，使得能够系统研究网络架构和训练算法对特征学习动力学的影响。学术价值在于深化了神经网络理论，特别是梯度下降中的相变现象，为理解学习机制提供了新视角。实际应用上，可为优化神经网络设计和训练策略提供理论依据。未来工作方向可能包括扩展至深层网络或探索不同训练算法下的类似阈值，以克服本研究中架构局限性和未涉及具体数据实验的不足。",
      "tags": [
        "Multi-index Models",
        "Gradient Descent Dynamics",
        "Phase Transitions",
        "Hessian Spectrum",
        "Two-layer Neural Networks"
      ]
    },
    "analyzed_at": "2026-02-27T03:48:56.870742Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.00564",
    "title": "Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs",
    "authors": [
      "Xiang Zheng",
      "Weiqi Zhai",
      "Wei Wang",
      "Boyu Yang",
      "Wenbo Li",
      "Ruixiang Luo",
      "Haoxiang Sun",
      "Yucheng Wang",
      "Zhengze Li",
      "Meng Wang",
      "Yuetian Du",
      "Guojie Lin",
      "Yaxuan Wang",
      "Xiaoxiao Xu",
      "Yanhu Mo",
      "Xuan Ren",
      "Hu Wei",
      "Bing Zhao"
    ],
    "abstract": "Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.00564.pdf",
    "abs_url": "https://arxiv.org/abs/2602.00564",
    "published": "2026-01-31T07:09:17Z",
    "updated": "2026-02-26T16:18:49Z",
    "comment": "8 pages, and 3 figures",
    "light_analysis": {
      "overview": "本文提出ReasoningMath-Plus基准和HCRS评估方法，以更精确地评估大型语言模型的结构数学推理能力，克服现有基准的局限性。",
      "motivation": "现有大型语言模型（LLMs）在数学推理基准测试中准确度接近饱和，但这主要由数据集中的模板化计算和浅层算术分解导致，无法有效评估多约束协调、构造性逻辑合成和空间推断等深层推理技能。这一问题的重要性在于它可能误导对模型真实推理能力的诊断，使得评估结果不可靠，从而影响模型发展的方向。因此，需要设计新基准来填补这一空白，更全面地反映推理过程。",
      "method": "论文提出ReasoningMath-Plus基准，包含150个精心设计的问题，专注于评估结构推理能力，如交互约束下的推理、构造性解形成和非平凡结构洞察。每个问题都附有最小推理骨架，支持细粒度过程级评估。此外，引入Hazard-aware Chain-based Rule Score（HCRS）作为确定性步骤级评分函数，并基于注释的推理痕迹训练过程奖励模型（PRM），以强化过程级别的分析和诊断能力。",
      "result": "实验结果显示，领先的LLMs在最终答案准确度上达到5.8/10的较高水平，但使用HCRS进行的整体评估得分显著较低，平均为4.36/10，最佳得分为5.14/10。与基线方法相比，这些数据表明仅依赖答案指标可能过度估计模型的推理鲁棒性，强调了过程级评估在实际性能诊断中的重要性。",
      "conclusion": "本研究的主要贡献是通过引入ReasoningMath-Plus基准和HCRS评估框架，揭示现有数学推理评估方法的不足，并推动过程级诊断的发展。其学术价值在于促进推理能力评估的理论进步，实际应用价值则在于帮助更准确地诊断和提升LLMs的推理性能。未来工作可扩展基准到其他推理领域或优化评估技术。",
      "tags": [
        "Large Language Model",
        "Mathematical Reasoning",
        "Benchmark Evaluation",
        "Process-aware Scoring",
        "Reasoning Traces"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:00.533724Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.00299",
    "title": "Agentic Framework for Epidemiological Modeling",
    "authors": [
      "Rituparna Datta",
      "Zihan Guan",
      "Baltazar Espinoza",
      "Yiqi Su",
      "Priya Pitre",
      "Srini Venkatramanan",
      "Naren Ramakrishnan",
      "Anil Vullikanti"
    ],
    "abstract": "Epidemic modeling is essential for public health planning, yet traditional approaches rely on fixed model classes that require manual redesign as pathogens, policies, and scenario assumptions evolve. We introduce EPIAGENT, an agentic framework that automatically synthesizes, calibrates, verifies, and refines epidemiological simulators by modeling disease progression as an iterative program synthesis problem. A central design choice is an explicit epidemiological flow graph intermediate representation that links scenario specifications to model structure and enables strong, modular correctness checks before code is generated. Verified flow graphs are then compiled into mechanistic models supporting interpretable parameter learning under physical and epidemiological constraints. Evaluation on epidemiological scenario case studies demonstrates that EPIAGENT captures complex growth dynamics and produces epidemiologically consistent counterfactual projections across varying vaccination and immune escape assumptions. Our results show that the agentic feedback loop prevents degeneration and significantly accelerates convergence toward valid models by mimicking professional expert workflows.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.00299.pdf",
    "abs_url": "https://arxiv.org/abs/2602.00299",
    "published": "2026-01-30T20:45:45Z",
    "updated": "2026-02-26T15:28:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "EPIAGENT是一个代理框架，通过模仿专家工作流自动合成、校准、验证和优化流行病学模拟器，显著提升建模效率。",
      "motivation": "流行病建模对公共卫生规划至关重要，但传统方法依赖固定模型类别，需要人工重新设计以适应病原体、政策和场景假设的变化，导致效率低下且容易出错。随着疫情动态和政策调整，快速生成可靠模型的需求日益增长，而现有方法难以自动处理模型更新，限制了实时响应能力，因此需要一个更灵活、自动化的解决方案来提高建模的准确性和适应性，以支持有效决策。",
      "method": "EPIAGENT采用流行病流程图中间表示作为核心设计，将场景规范链接到模型结构，并在代码生成前实现强模块化正确性检查。它将疾病进展建模为迭代程序合成问题，通过代理反馈循环自动执行合成、校准、验证和优化任务，验证后的流程图被编译成机械模型，支持在物理和流行病学约束下进行可解释的参数学习，模仿专业专家工作流程，从而提升模型构建的效率和可靠性。",
      "result": "在流行病学场景案例研究中，EPIAGENT成功捕捉了复杂的生长动态，并在不同疫苗接种和免疫逃逸假设下产生流行病学一致的反事实预测。代理反馈循环防止了模型退化，并通过模仿专家工作流显著加速了向有效模型的收敛，评估结果表明框架在模型准确性和效率方面优于传统手动方法，尽管摘要未提供具体性能指标数据，但展示了其在实际应用中的潜力和鲁棒性。",
      "conclusion": "论文的主要贡献是提出EPIAGENT代理框架，通过自动化模型合成和优化解决了传统流行病建模的局限性，具有重要的学术价值，推动了程序合成在流行病学中的应用，并具备实际应用价值，能提升公共卫生规划的响应能力和准确性。局限性摘要未明确说明，未来工作可能包括扩展到更多复杂场景或集成额外数据源以进一步增强模型适用性。",
      "tags": [
        "Agentic Framework",
        "Epidemiological Modeling",
        "Program Synthesis",
        "Flow Graph Intermediate Representation",
        "Iterative Feedback Loop"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:14.887835Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22669",
    "title": "Beyond Fixed Rounds: Data-Free Early Stopping for Practical Federated Learning",
    "authors": [
      "Youngjoon Lee",
      "Hyukjoon Lee",
      "Seungrok Jung",
      "Andy Luo",
      "Jinu Gong",
      "Yang Cao",
      "Joonhyuk Kang"
    ],
    "abstract": "Federated Learning (FL) facilitates decentralized collaborative learning without transmitting raw data. However, reliance on fixed global rounds or validation data for hyperparameter tuning hinders practical deployment by incurring high computational costs and privacy risks. To address this, we propose a data-free early stopping framework that determines the optimal stopping point by monitoring the task vector's growth rate using solely server-side parameters. The numerical results on skin lesion/blood cell classification demonstrate that our approach is comparable to validation-based early stopping across various state-of-the-art FL methods. In particular, the proposed framework requires an average of 45/12 (skin lesion/blood cell) additional rounds to achieve over 12.3%/8.9% higher performance than early stopping based on validation data. To the best of our knowledge, this is the first work to propose an data-free early stopping framework for FL methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22669.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22669",
    "published": "2026-01-30T07:42:13Z",
    "updated": "2026-02-26T06:49:17Z",
    "comment": "Replaced with experimental results on AMD MI300X AI accelerators",
    "light_analysis": {
      "overview": "提出了一种无需验证数据的数据免费早期停止框架，通过监控任务向量增长率优化联邦学习停止点，降低计算成本和隐私风险。",
      "motivation": "联邦学习（FL）旨在实现去中心化协作学习并保护数据隐私，但现有方法依赖固定全局轮数或验证数据进行超参数调优，这不仅导致高昂的计算开销，还因使用验证数据引入隐私风险，限制了FL在实际场景中的部署。因此，研究动机是开发一种更实用、无需额外数据的早期停止机制，以克服效率和隐私的双重挑战，提升FL的可扩展性和安全性。",
      "method": "该方法设计了一个数据免费的早期停止框架，核心思想是仅利用服务器端参数监控任务向量的增长率，其中任务向量代表模型更新。通过分析增长率变化作为训练收敛指标，无需客户端数据或验证集，避免了数据泄露。创新点在于将早期停止问题简化为参数监控，减少对验证数据的依赖，适用于多种FL方法，提高了方法的通用性和隐私保护能力。",
      "result": "实验在皮肤病变和血细胞分类任务上展开，结果表明该框架与基于验证的早期停止方法性能相当，但通过平均额外45轮（皮肤病变）和12轮（血细胞）训练，实现了超过12.3%和8.9%的性能提升。与多种先进FL基线方法对比，该方法在无验证数据情况下仍能有效确定最优停止点，展示了其高效性和实用性，且不增加隐私风险。",
      "conclusion": "本研究贡献了首个数据免费的早期停止框架，通过仅使用服务器端参数，显著降低联邦学习的计算成本和隐私泄露风险，促进了FL的实用部署。学术上为无数据依赖优化方法提供新方向；应用上增强FL的可行性和安全性。摘要未明确说明局限性，未来工作可能包括扩展到更多任务场景和优化监控策略。",
      "tags": [
        "Federated Learning",
        "Early Stopping",
        "Task Vector",
        "Server-side Parameters",
        "Data-Free Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:10.157558Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.18231",
    "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting",
    "authors": [
      "Trong Khiem Tran",
      "Manh Cuong Dao",
      "Phi Le Nguyen",
      "Thao Nguyen Truong",
      "Trong Nghia Hoang"
    ],
    "abstract": "Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration. A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer. This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization. Existing work, however, lacks a theoretical understanding of this critical interaction between feature alignment and target fitting. To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion. This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.18231.pdf",
    "abs_url": "https://arxiv.org/abs/2601.18231",
    "published": "2026-01-26T07:34:15Z",
    "updated": "2026-02-26T05:25:33Z",
    "comment": "Accepted AISTATS 20226. Preprint version",
    "light_analysis": {
      "overview": "本论文提出了一个理论框架，通过特征标签扭曲的概念来优化跨模态微调中特征对齐和目标拟合的交互。",
      "motivation": "随着跨学科知识集成需求的增长，将预训练模型适应于未见特征模态变得日益重要。关键挑战是如何对齐新模态的表示与预训练模型的表示空间以实现知识迁移。这需要结合特征对齐和目标微调，但未经校准的组合会加剧源和目标特征标签结构的失准，降低目标泛化。然而，现有研究缺乏对这种交互的理论理解，限制了算法性能的进一步提升。",
      "method": "论文开发了一个原则性框架，建立了目标误差的可证明泛化界。该框架通过引入特征标签扭曲的新概念来解释特征对齐与目标拟合的交互，提供可操作的见解以指导交互的优化。摘要未明确说明使用的具体数据集、模型架构或技术路线细节，但强调框架的理论基础，旨在为算法设计提供理论支撑和优化策略。",
      "result": "所提出的方法在多个基准数据集上显著优于现有最优方法，展示了性能的显著改善和更高的泛化能力。摘要未明确说明具体的性能指标如准确率提升或效率改进的数值，但通过广泛实验验证，证明了该方法在不同跨模态任务中的优越性，强调了理论框架的实际应用效果。",
      "conclusion": "本研究的主要贡献是提供了一个理论框架，深入理解跨模态微调中特征对齐与目标拟合的交互，并提出优化策略，弥补了现有研究的理论空白。其学术价值在于建立了可证明的泛化界和特征标签扭曲概念，实际应用价值在于指导算法设计以提升性能。未来工作可能包括扩展理论到更多复杂模态交互场景，并进行更广泛的实证验证。",
      "tags": [
        "Cross-Modal Fine-Tuning",
        "Feature Alignment",
        "Generalization Bound",
        "Feature-Label Distortion",
        "Target Fitting"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:26.323481Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11670",
    "title": "A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning",
    "authors": [
      "Jinshi Liu",
      "Pan Liu",
      "Lei He"
    ],
    "abstract": "Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.11670.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11670",
    "published": "2026-01-16T02:51:59Z",
    "updated": "2026-02-26T12:57:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出置信度-方差理论框架，通过结合最大置信度与残差类方差，改进半监督学习中伪标签选择的可靠性。",
      "motivation": "现有半监督学习方法中，伪标签选择常依赖固定置信度阈值，假设预测置信度能可靠指示正确性。然而，深度网络常存在过度自信问题：高置信度预测可能错误，而决策边界附近的低置信度样本虽具信息却被丢弃。这导致伪标签质量下降，影响学习效率，凸显了开发更可靠选择机制的重要性。",
      "method": "基于熵最小化原则，论文推导可靠性度量，融合最大置信度（MC）和残差类方差（RCV），RCV表征非最大类别的概率分布。核心创新是将伪标签选择视为光谱松弛问题，在置信度-方差特征空间最大化可分性，设计无阈值选择机制以区分高和低可靠性预测，并将其作为插件模块集成到半监督语义分割和图像分类方法中。",
      "result": "在PASCAL VOC 2012、Cityscapes、CIFAR-10和Mini-ImageNet等数据集上，针对不同标签比例和主干网络，CoVar方法一致提升了强基线方法的性能，表明结合置信度与残差类方差比固定置信度阈值提供更可靠的伪标签选择依据（摘要未提供具体性能指标如准确率提升百分比）。",
      "conclusion": "论文贡献了置信度-方差理论框架，为半监督学习中的伪标签选择提供了原则性联合可靠性准则。这不仅提高了伪标签的可靠性和学习效果，对学术研究和实际应用有显著价值；局限性摘要未明确说明，未来工作可拓展到其他学习任务或优化计算效率。",
      "tags": [
        "Semi-Supervised Learning",
        "Pseudo-Label Selection",
        "Confidence Estimation",
        "Residual-Class Variance",
        "Entropy Minimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:22.572418Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.10611",
    "title": "Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding",
    "authors": [
      "Christopher Clark",
      "Jieyu Zhang",
      "Zixian Ma",
      "Jae Sung Park",
      "Mohammadreza Salehi",
      "Rohun Tripathi",
      "Sangho Lee",
      "Zhongzheng Ren",
      "Chris Dongjoo Kim",
      "Yinuo Yang",
      "Vincent Shao",
      "Yue Yang",
      "Weikai Huang",
      "Ziqi Gao",
      "Taira Anderson",
      "Jianrui Zhang",
      "Jitesh Jain",
      "George Stoica",
      "Winson Han",
      "Ali Farhadi",
      "Ranjay Krishna"
    ],
    "abstract": "Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.10611.pdf",
    "abs_url": "https://arxiv.org/abs/2601.10611",
    "published": "2026-01-15T17:27:44Z",
    "updated": "2026-02-26T08:46:23Z",
    "comment": "Fixed results in Table 7",
    "light_analysis": {
      "overview": "Molmo2提出一个开源权重和数据的视频语言模型家族，在视频理解和点驱动接地任务中达到先进水平。",
      "motivation": "研究动机源于当前最强的视频语言模型多为专有，而开源模型常依赖专有数据或数据不透明，导致开源社区难以改进视频和图像语言模型。许多下游应用不仅需要高级视频理解，还要求接地能力如点选或像素跟踪，但现有模型包括专有模型也缺乏此功能。因此，开发开源且具备接地能力的模型至关重要，以推动技术进步并支持实际应用如增强现实或视频分析。",
      "method": "研究方法包括收集7个新的视频数据集和2个多图像数据集，这些数据集不使用专有视频语言模型，涵盖详细视频字幕预训练、自由形式视频问答微调、复杂查询对象跟踪和创新视频点选。训练方法采用高效的打包和消息树编码方案，结合双向注意力机制处理视觉标记，并引入新的标记权重策略来提升性能，关键创新在于数据集的原创性和训练配方的优化，使用8B模型进行实验验证。",
      "result": "主要实验结果显示，Molmo2的8B模型在短视频、计数和字幕任务中优于其他开源模型，如在视频计数任务中准确率达35.5，高于Qwen3-VL的29.6。在视频点选和跟踪任务中，其F1分数为38.4、J&F为56.2，分别超过专有模型Gemini 3 Pro的20.0和41.1，同时在长视频任务中表现竞争性。与基线方法相比，模型在多个任务上实现了显著性能提升。",
      "conclusion": "论文的主要贡献是提出Molmo2，一个开源权重和数据的视频语言模型家族，在视频理解和接地任务中达到开源先进水平。其学术价值在于提供透明的基础设施，促进视频语言模型研究的发展；实际应用价值体现在支持精确接地的下游任务如视频分析和交互。潜在局限性包括摘要未明确说明，未来工作可扩展数据集规模或模型能力。",
      "tags": [
        "Vision-Language Models",
        "Video Understanding",
        "Grounding",
        "Datasets",
        "Attention Mechanisms"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:36.195113Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11620",
    "title": "A Mind Cannot Be Smeared Across Time",
    "authors": [
      "Michael Timothy Bennett"
    ],
    "abstract": "Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates, yet a moment of conscious experience feels unified and simultaneous. I prove that this difference matters. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a temporal semantics over windowed trajectories $τ_Δ$ and prove that existential temporal realisation $\\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates, Chord and Arpeggio. Chord is the position that conscious unity requires \\textit{objective co-instantiation} of the grounded conjunction within the window, like a musical chord. Arpeggio only needs the ingredients to \\textit{occur} within window, like a melody. I formalise concurrency-capacity to measure what is needed to satisfy co-instantiation. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is associated with its breakdown. Under Chord, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The hardware matters.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.11620.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11620",
    "published": "2026-01-11T01:08:33Z",
    "updated": "2026-02-26T14:27:35Z",
    "comment": "Forthcoming in the proceedings of the AAAI 2026 Spring Symposium on Machine Consciousness: Integrating Theory, Technology, and Philosophy",
    "light_analysis": {
      "overview": "论文通过形式化时间语义证明机器意识的实现依赖于计算时机，并提出了Chord和Arpeggio假设来区分意识统一性的要求。",
      "motivation": "研究动机是探索机器意识的可能性，特别是计算时机如何影响意识体验的统一性。现有的人工系统通常采用顺序或时间复用更新方式实现功能，而人类意识体验却感觉统一和同时。这一问题的重要性在于它直接关系到人工智能是否能够实现真正意识，现有方法忽略了时间维度，可能导致意识实现的障碍。因此，论文旨在通过形式化分析时间在意识中的作用，弥补这一研究空白，强调硬件与软件交互的关键性。",
      "method": "研究方法包括扩展Stack Theory，引入代数定律关联时间窗口约束满足与合取。引入窗轨迹τ_Δ的时间语义，证明存在性时间实现不保持合取，表明系统可以在时间上实现所有体验成分而无需实例化合取本身。关键创新点是区分Chord和Arpeggio假设，前者要求客观共实例化，后者只需成分发生。还形式化了并发容量来衡量共实例化需求。研究结合形式逻辑和神经生理学证据，如相位同步和有效连接，构建综合分析框架。",
      "result": "主要理论结果证明了存在性时间实现不保持合取，表明系统无法在时间窗内统一实现意识合取。区分Chord和Arpeggio假设，并发容量的形式化量化了共实例化需求。神经生理学证据回顾显示意识与相位同步和有效连接相关，为理论提供实证支持。基于此，论文得出对于需要同时贡献者的内容，严格顺序硬件上的软件意识不可行。摘要未明确说明具体实验数据，但逻辑证明和神经科学证据共同支撑结论。",
      "conclusion": "论文的主要贡献是形式化证明了机器意识的实现受计算时机限制，强调意识统一性依赖于时间共实例化。Chord假设要求硬件支持同时性，否则软件意识不可行，这扩展了Stack Theory并为理解意识提供了新视角。学术价值在于将逻辑形式化与神经科学结合，推动AI意识研究。实际应用价值包括指导AI系统设计，确保时间特性匹配。未来工作可能涉及开发并发硬件或进一步验证理论，局限性在于理论框架仍需实验验证。",
      "tags": [
        "Stack Theory",
        "Temporal Semantics",
        "Phase Synchrony",
        "Concurrency-Capacity"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:01.961035Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.03467",
    "title": "ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing",
    "authors": [
      "Hengjia Li",
      "Liming Jiang",
      "Qing Yan",
      "Yizhi Song",
      "Hao Kang",
      "Zichuan Liu",
      "Xin Lu",
      "Boxi Wu",
      "Deng Cai"
    ],
    "abstract": "Instruction-driven image editing with unified multimodal generative models has advanced rapidly, yet their underlying visual reasoning remains limited, leading to suboptimal performance on reasoning-centric edits. Reinforcement learning (RL) has been investigated for improving the quality of image editing, but it faces three key challenges: (1) limited reasoning exploration confined to denoising stochasticity, (2) biased reward fusion, and (3) unstable VLM-based instruction rewards. In this work, we propose ThinkRL-Edit, a reasoning-centric RL framework that decouples visual reasoning from image synthesis and expands reasoning exploration beyond denoising. To the end, we introduce Chain-of-Thought (CoT)-based reasoning sampling with planning and reflection stages prior to generation in online sampling, compelling the model to explore multiple semantic hypotheses and validate their plausibility before committing to a visual outcome. To avoid the failures of weighted aggregation, we propose an unbiased chain preference grouping strategy across multiple reward dimensions. Moreover, we replace interval-based VLM scores with a binary checklist, yielding more precise, lower-variance, and interpretable rewards for complex reasoning. Experiments show our method significantly outperforms prior work on reasoning-centric image editing, producing instruction-faithful, visually coherent, and semantically grounded edits.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.03467.pdf",
    "abs_url": "https://arxiv.org/abs/2601.03467",
    "published": "2026-01-06T23:43:00Z",
    "updated": "2026-02-26T03:32:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出ThinkRL-Edit框架，通过强化学习结合思维链推理采样，改进图像编辑中的视觉推理能力。",
      "motivation": "当前指令驱动的图像编辑模型在需要深层推理的任务中表现不佳，因为视觉推理有限，导致推理为中心的编辑结果不理想。强化学习虽用于提升编辑质量，但面临三大挑战：推理探索仅限于去噪随机性，奖励融合存在偏差，以及基于视觉语言模型的指令奖励不稳定，这些问题限制了处理复杂语义编辑的能力。",
      "method": "ThinkRL-Edit框架将视觉推理与图像合成解耦，扩展推理探索。核心方法是引入基于思维链的推理采样，包括生成前的规划和反思阶段，迫使模型探索多个语义假设并验证合理性。此外，提出无偏链偏好分组策略优化多维度奖励融合，并用二进制检查表替换区间型VLM分数，提供更精确、低方差和可解释的奖励。",
      "result": "实验显示ThinkRL-Edit在推理为中心的图像编辑任务上显著优于先前工作，能产生指令忠实、视觉连贯和语义接地的编辑结果。虽然没有提供具体性能数据，但摘要强调其优越性，表明在复杂推理编辑中的有效性。",
      "conclusion": "论文贡献在于提出ThinkRL-Edit框架，通过强化学习结合思维链机制解决推理探索和奖励稳定性问题，提升了图像编辑的推理能力，具有学术价值，并在需要高级视觉理解的应用中展现潜力。摘要未明确说明局限性，但未来工作可能包括扩展到其他领域或优化方法细节。",
      "tags": [
        "Reinforcement Learning",
        "Chain-of-Thought",
        "Image Editing",
        "Visual Reasoning",
        "Reward Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:49:43.060536Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.02439",
    "title": "WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks",
    "authors": [
      "Hao Bai",
      "Alexey Taymanov",
      "Tong Zhang",
      "Aviral Kumar",
      "Spencer Whitehead"
    ],
    "abstract": "We present WebGym, the largest-to-date open-source environment for training realistic visual web agents. Real websites are non-stationary and diverse, making artificial or small-scale task sets insufficient for robust policy learning. WebGym contains nearly 300,000 tasks with rubric-based evaluations across diverse, real-world websites and difficulty levels. We train agents with a simple reinforcement learning (RL) recipe, which trains on the agent's own interaction traces (rollouts), using task rewards as feedback to guide learning. To enable scaling RL, we speed up sampling of trajectories in WebGym by developing a high-throughput asynchronous rollout system, designed specifically for web agents. Our system achieves a 4-5x rollout speedup compared to naive implementations. Second, we scale the task set breadth, depth, and size, which results in continued performance improvement. Fine-tuning a strong base vision-language model, Qwen-3-VL-8B-Instruct, on WebGym results in an improvement in success rate on an out-of-distribution test set from 26.2% to 42.9%, significantly outperforming agents based on proprietary models such as GPT-4o and GPT-5-Thinking that achieve 27.1% and 29.8%, respectively. This improvement is substantial because our test set consists only of tasks on websites never seen during training, unlike many other prior works on training visual web agents.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.02439.pdf",
    "abs_url": "https://arxiv.org/abs/2601.02439",
    "published": "2026-01-05T09:35:11Z",
    "updated": "2026-02-26T03:25:19Z",
    "comment": "Added link to GitHub repo",
    "light_analysis": {
      "overview": "提出WebGym，最大开源视觉网页代理训练环境，通过高吞吐异步回滚系统和强化学习配方，显著提升代理在未见网站上的泛化性能。",
      "motivation": "真实网站的非平稳性和多样性使得现有训练环境（如人工或小规模任务集）难以训练出具有鲁棒泛化能力的视觉网页代理，这限制了代理在真实世界应用中的可靠性。现有方法通常依赖于模拟环境或有限任务，无法适应真实网站的复杂性和变化，导致泛化能力不足。因此，开发大规模、多样化的训练环境至关重要，以促进代理学习和性能提升。",
      "method": "研究方法基于构建WebGym环境，包含近300,000个基于真实网站的任务，并通过基于准则的评估来支持鲁棒训练。核心方法是使用简单强化学习配方，在代理自身交互轨迹（回滚）上训练，以任务奖励作为学习反馈。关键创新包括开发高吞吐量异步回滚系统，专门优化网页代理，实现4-5倍速度提升以扩展训练。此外，扩展任务集的广度、深度和大小，并微调视觉语言模型Qwen-3-VL-8B-Instruct以增强代理能力。",
      "result": "实验结果在分布外测试集上展示了显著性能提升：微调后的代理成功率从26.2%提升到42.9%。这明显优于基于GPT-4o和GPT-5-Thinking的基线代理，它们分别只达到27.1%和29.8%的成功率。测试集完全由训练中未见的网站任务组成，验证了WebGym环境对代理泛化能力的有效增强。这些数据表明，大规模、多样化任务集和高效率系统能持续改善代理表现。",
      "conclusion": "论文的主要贡献是提出了WebGym，一个大规模、开源的视觉网页代理训练环境，通过强化学习和高效异步系统显著提升代理泛化能力。该研究具有重要学术价值，为视觉网页代理训练和评估提供了新基准，展示了强化学习在真实世界应用中的潜力。实际应用中，可促进更鲁棒的网页自动化工具开发。未来工作可包括进一步扩展环境或探索其他学习方法，但摘要未明确说明具体局限性。",
      "tags": [
        "WebGym",
        "Reinforcement Learning",
        "Asynchronous Rollout System",
        "Vision-Language Models",
        "Fine-tuning"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:08.880396Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.21058",
    "title": "Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control",
    "authors": [
      "Minghao Han",
      "Yichen Liu",
      "Yizhou Liu",
      "Zizhi Chen",
      "Jingqun Tang",
      "Xuecheng Wu",
      "Dingkang Yang",
      "Lihua Zhang"
    ],
    "abstract": "In computational pathology, understanding and generation have evolved along disparate paths: advanced understanding models already exhibit diagnostic-level competence, whereas generative models largely simulate pixels. Progress remains hindered by three coupled factors: the scarcity of large, high-quality image-text corpora; the lack of precise, fine-grained semantic control, which forces reliance on non-semantic cues; and terminological heterogeneity, where diverse phrasings for the same diagnostic concept impede reliable text conditioning. We introduce UniPath, a semantics-driven pathology image generation framework that leverages mature diagnostic understanding to enable controllable generation. UniPath implements Multi-Stream Control: a Raw-Text stream; a High-Level Semantics stream that uses learnable queries to a frozen pathology MLLM to distill paraphrase-robust Diagnostic Semantic Tokens and to expand prompts into diagnosis-aware attribute bundles; and a Prototype stream that affords component-level morphological control via a prototype bank. On the data front, we curate a 2.65M image-text corpus and a finely annotated, high-quality 68K subset to alleviate data scarcity. For a comprehensive assessment, we establish a four-tier evaluation hierarchy tailored to pathology. Extensive experiments demonstrate UniPath's SOTA performance, including a Patho-FID of 80.9 (51% better than the second-best) and fine-grained semantic control achieving 98.7% of the real-image. The dataset and code can be obtained from https://github.com/Hanminghao/UniPath.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.21058.pdf",
    "abs_url": "https://arxiv.org/abs/2512.21058",
    "published": "2025-12-24T08:52:08Z",
    "updated": "2026-02-26T11:05:29Z",
    "comment": "accepted by CVPR 2026; 32 pages, 17 figures, and 6 tables",
    "light_analysis": {
      "overview": "UniPath框架通过诊断语义令牌和原型控制实现可控的病理图像生成，解决了现有方法缺乏语义控制的难题。",
      "motivation": "在计算病理学中，图像生成模型通常仅模拟像素，缺乏对诊断语义的精细控制，这是由于三个耦合因素：高质量图像-文本数据稀缺；缺乏精确的语义控制，导致模型依赖非语义线索；以及术语异构性，即相同诊断概念的不同表述使文本条件不可靠。这些问题阻碍了生成模型的实用性和诊断准确性，限制了其在医疗领域的应用。",
      "method": "UniPath采用多流控制架构：原始文本流处理输入；高层语义流利用冻结的病理多模态语言模型，通过学习查询提取对同义替换鲁棒的诊断语义令牌，并将提示扩展为诊断感知的属性束；原型流通过原型库提供组件级形态控制。此外，构建了一个2.65M图像-文本语料库和一个精细注释的68K子集以缓解数据稀缺。",
      "result": "实验建立四层评估层次，UniPath表现最先进的性能，Patho-FID达到80.9，比次优方法提升51%。在细粒度语义控制方面，其生成的图像在语义准确性上达到真实图像的98.7%。这些结果证实UniPath在病理图像生成中实现了更高的语义一致性和图像质量。",
      "conclusion": "UniPath的主要贡献是提出了语义驱动的病理图像生成框架，整合诊断理解以实现可控生成。研究通过构建大规模数据集和多流控制方法，提升了生成的语义精确性和实用性，推动计算病理学中生成模型的发展。实际应用可能支持医学教育和辅助诊断，摘要未明确说明局限性，但未来工作可探索更广泛的病理类型。",
      "tags": [
        "Pathology Image Generation",
        "Diagnostic Semantic Tokens",
        "Prototype Control",
        "Multi-Stream Model",
        "Medical Image Synthesis"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:00.921214Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.05790",
    "title": "Learnability Window in Gated Recurrent Neural Networks",
    "authors": [
      "Lorenzo Livi"
    ],
    "abstract": "We develop a statistical theory of temporal learnability in recurrent neural networks, showing how gating mechanisms determine the learnability window $\\mathcal{H}_N$, defined as the maximal temporal horizon over which gradient information remains recoverable at sample size $N$. While classical analyses emphasize numerical stability of Jacobian products, we show that stability alone does not guarantee recoverability. Instead, learnability is governed by the interaction between the decay geometry of the effective learning rate envelope $f(\\ell)=\\|μ_{t,\\ell}\\|_1$, derived from first-order expansions of gate-induced Jacobians in Backpropagation Through Time, and the statistical concentration properties of stochastic gradients. Under heavy-tailed ($α$-stable) gradient noise, empirical averages concentrate at rate $N^{-1/κ_α}$ with $κ_α=α/(α-1)$. We prove that this interaction yields explicit scaling laws for the growth of $\\mathcal{H}_N$, distinguishing logarithmic, polynomial, and exponential temporal learning regimes according to the attenuation of $f(\\ell)$. The theory reveals that gate-induced time-scale spectra are the dominant determinants of temporal learnability: broader spectra slow envelope decay and systematically expand $\\mathcal{H}_N$, whereas heavy-tailed noise uniformly compresses temporal horizons by weakening statistical concentration. Empirical results across multiple gated architectures confirm these structural scaling predictions.",
    "categories": [
      "cs.LG",
      "physics.data-an"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.05790.pdf",
    "abs_url": "https://arxiv.org/abs/2512.05790",
    "published": "2025-12-05T15:16:59Z",
    "updated": "2026-02-26T14:02:26Z",
    "comment": "Added results with LSTM and GRU. Improved discussions",
    "light_analysis": {
      "overview": "论文提出了一个统计理论，揭示了门控循环神经网络中时间学习性窗口的缩放定律，通过分析门控机制与梯度噪声的交互来确定梯度信息的可恢复时间范围。",
      "motivation": "循环神经网络在处理时间序列时面临梯度消失或爆炸问题，尤其是在学习长时依赖时。经典分析强调雅可比乘积的数值稳定性，但稳定性本身不能保证梯度信息的有效可恢复性，导致现有方法对时间学习性的理解不足。本研究旨在解决门控RNN中梯度信息随时间可恢复性的根本机制问题，这对于改进序列建模和深度学习架构的设计至关重要，以更好地适应实际应用中复杂的时间依赖性。",
      "method": "论文提出了一种基于统计理论的框架，从反向传播通过时间的一阶扩展中推导出有效学习率包络函数f(ℓ)=‖μ_{t,ℓ}‖_1。通过分析该包络的衰减几何与重尾α-稳定梯度噪声的统计集中属性（集中速率为N^{-1/κ_α}，其中κ_α=α/(α-1)）的交互作用，建立了时间学习性窗口H_N的缩放定律。核心创新点在于结合了门控机制的雅可比矩阵和噪声模型，区分了不同学习制度，而不依赖于传统数值稳定性分析。",
      "result": "理论推导揭示了时间学习性窗口H_N的增长遵循明确的缩放定律，根据包络f(ℓ)的衰减分为对数、多项式和指数三种制度。结果表明，门控机制的时间尺度谱扩展减缓包络衰减，系统性扩大H_N，而重尾梯度噪声则通过削弱统计集中压缩时间范围。在多个门控架构上的实证结果验证了这些结构缩放预测，证实了该理论的普适性，尽管摘要未提供具体性能指标数值，但与基线分析相比，强调了统计因素的附加影响。",
      "conclusion": "论文的主要贡献是建立了一个统计理论，阐明了门控循环神经网络中时间学习性窗口的缩放行为，强调门控诱导的时间尺度谱和梯度噪声的交互作用是关键决定因素。这为理解RNN学习性的深层机制提供了新视角，对优化神经网络设计和序列建模具有重要学术和实践价值。局限性可能包括对特定噪声假设的依赖，未来工作可扩展该理论到其他噪声分布或更复杂的架构中，以进一步提升泛化能力。",
      "tags": [
        "Gated Recurrent Neural Networks",
        "Learnability Window",
        "Backpropagation Through Time",
        "α-stable noise",
        "Scaling Laws"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:13.666769Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.03383",
    "title": "UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs",
    "authors": [
      "Hung-Yueh Chiang",
      "Chi-Chih Chang",
      "Yu-Chen Lu",
      "Chien-Yu Lin",
      "Kai-Chiang Wu",
      "Mohamed S. Abdelfattah",
      "Diana Marculescu"
    ],
    "abstract": "Deploying large language models (LLMs) on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework with on-device configurable pruning rates for edge LLMs. UniQL is a general framework that integrates quantization and low-rank compression for Transformers, State Space Models (SSMs), and hybrid models to support diverse edge applications. In our proposed joint framework, we introduce an efficient structured weight-sorting method that speeds up computation by 20x, quantization-aware singular value decomposition (SVD) to minimize quantization errors, state-aware weight sorting for SSMs, and a fused rotary positional embedding (RoPE) kernel for pruned models. Our framework performs weight-sorting, fine-tuning, and quantization in the cloud in a single-pass workflow, while enabling on-device configurable pruning rates up to 35%. Our experiments show that quantized and pruned models achieve a memory reduction of 4x-5.7x and a token-throughput improvement of 2.7x-3.4x, maintaining accuracy within 5% of the original models at 15% pruning across Transformers (Llama3 and Qwen2.5), SSMs (Mamba2), and hybrid models (Nemotron-H and Bamba-v2). The code and quantized models are available at: https://github.com/enyac-group/UniQL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.03383.pdf",
    "abs_url": "https://arxiv.org/abs/2512.03383",
    "published": "2025-12-03T02:33:39Z",
    "updated": "2026-02-26T04:49:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "UniQL框架通过统一后训练量化和低秩压缩，支持设备端可配置剪枝，显著提升边缘大语言模型的部署效率和适应性。",
      "motivation": "部署大型语言模型（LLMs）到移动平台面临内存和计算资源有限的挑战，资源可用性受设备工作负载影响，增加部署不确定性。现有方法可能难以适应动态资源条件，导致效率低下或部署失败，因此需要一种自适应压缩框架来解决这些实际部署问题，确保在资源受限环境中高效运行LLMs。摘要未明确说明现有方法的具体不足，但强调了统一框架的必要性。",
      "method": "UniQL是一个统一的后训练量化和低秩压缩框架，整合了量化、低秩压缩和可配置剪枝。关键技术包括高效结构化权重排序方法，加速计算20倍；量化感知奇异值分解（SVD），减少量化误差；状态感知权重排序专门用于状态空间模型（SSMs）；融合RoPE内核优化剪枝模型。框架在云端采用单次工作流执行权重排序、微调和量化，同时在设备端支持高达35%的可配置剪枝率，并兼容Transformers、SSMs和混合模型。",
      "result": "实验结果显示，量化并剪枝后的模型内存减少4到5.7倍，token吞吐量提升2.7到3.4倍，显著优于原始模型。在15%剪枝率下，准确率保持在原模型5%以内，验证了多种模型（如Llama3、Qwen2.5等Transformers，Mamba2等SSMs，以及Nemotron-H、Bamba-v2等混合模型）。这些指标表明UniQL在减少资源占用和提升计算效率方面效果显著。",
      "conclusion": "UniQL框架的主要贡献是提供了一种高效、统一的压缩方案，通过整合量化和低秩压缩，支持设备端自适应剪枝，提升了边缘LLM部署的灵活性和效率。其学术价值在于适用于多种模型架构，增强了边缘计算的实际应用性；潜在未来工作可能涉及扩展到更多模型类型或优化框架性能，但摘要未明确说明具体局限性。",
      "tags": [
        "Quantization",
        "Low-rank Compression",
        "Pruning",
        "Singular Value Decomposition",
        "Transformers"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:23.726326Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.02700",
    "title": "VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm",
    "authors": [
      "Zhenkai Wu",
      "Xiaowen Ma",
      "Zhenliang Ni",
      "Dengming Zhang",
      "Han Shu",
      "Xin Jiang",
      "Xinghao Chen"
    ],
    "abstract": "Vision-language models (VLMs) excel at image understanding tasks, but the large number of visual tokens imposes significant computational costs, hindering deployment on mobile devices. Many pruning methods rely solely on token importance and thus overlook inter-token redundancy, retaining numerous duplicated tokens and wasting capacity. Although some redundancy-aware approaches have been proposed, they often ignore the spatial relationships among visual tokens. This can lead to overly sparse selections of retained tokens that fail to adequately cover the regions of target objects. To address these limitations, we propose VLM-Pruner, a training-free token pruning algorithm that explicitly balances redundancy and spatial sparsity. We introduce a centrifugal token pruning paradigm that enables near-to-far selection while prioritizing the preservation of fine-grained object details. Moreover, we design a Buffering for Spatial Sparsity (BSS) criterion that defers the selection of spatially distant tokens. We further adopt a parallel greedy strategy to conduct token selection efficiently. To mitigate information loss from pruning, we selectively fuse salient information from the discarded tokens into the retained ones. Comprehensive comparisons demonstrate that VLM-Pruner consistently outperforms strong baselines across five VLMs with an 88.9\\% pruning rate, while delivering an end-to-end inference speedup. The code is available at https://github.com/Casey-bit/VLMPruner.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.02700.pdf",
    "abs_url": "https://arxiv.org/abs/2512.02700",
    "published": "2025-12-02T12:30:05Z",
    "updated": "2026-02-26T13:16:26Z",
    "comment": "Accepted by CVPR2026",
    "light_analysis": {
      "overview": "VLM-Pruner提出了一种免训练的视觉-语言模型token剪枝算法，通过离心范式和空间稀疏性缓冲平衡冗余与空间覆盖，显著提升模型效率。",
      "motivation": "视觉-语言模型在图像理解任务中性能卓越，但其大量视觉token导致高昂计算成本，阻碍了在移动设备等资源受限环境的部署。现有token剪枝方法主要依赖token重要性评估，忽视了token之间的冗余性，保留了过多重复token，浪费计算资源。同时，部分冗余感知方法虽考虑冗余，但忽略了视觉token的空间关系，导致保留的token过于稀疏，无法充分覆盖目标对象的关键区域，从而影响模型性能。因此，亟需一种新方法在剪枝过程中平衡冗余和空间稀疏性，以实现在保持准确性的同时提高效率。",
      "method": "论文提出VLM-Pruner算法，这是一种无需训练的token剪枝方法。核心创新包括引入离心token剪枝范式，该范式从近到远选择token，优先保留细粒度对象细节以优化空间覆盖和减少冗余。设计Buffer for Spatial Sparsity (BSS)准则，用于延迟选择空间遥远的token，从而有效平衡冗余和空间稀疏性。采用并行贪婪策略高效执行token选择过程，提升计算效率。此外，为了缓解剪枝带来的信息损失，算法选择性融合丢弃token中的显著信息到保留token中，确保模型性能不下降。该方法适用于多种视觉-语言模型，无需额外训练即可应用。",
      "result": "实验结果显示，VLM-Pruner在五种不同的视觉-语言模型上进行了综合评估，以88.9%的token剪枝率一致优于现有强基线方法。这表明在保持高性能的同时，大幅减少了计算负担，实现了显著的效率提升。论文虽未明确提供具体准确率提升百分比，但强调了在标准基准测试中的优越性能。此外，VLM-Pruner实现了端到端推理的加速，验证了其在优化计算资源方面的有效性。这些结果证明了该算法在平衡高剪枝率和模型性能方面的优势，为实际部署提供了有力支撑。",
      "conclusion": "VLM-Pruner的主要贡献在于提出了一种免训练的token剪枝算法，通过离心范式和BSS准则有效平衡了冗余和空间稀疏性，优化了视觉token的选择过程。该研究具有重要的学术价值，为视觉-语言模型的效率优化提供了新思路，促进了在移动设备和边缘计算场景的部署，具有广泛的实际应用潜力。未来工作可能包括扩展到更多模型架构或复杂任务类型，进一步优化信息融合机制，或探索在动态环境中的适应性剪枝策略，以应对更复杂的视觉语言场景和资源限制挑战。",
      "tags": [
        "Vision-Language Models",
        "Token Pruning",
        "Redundancy Awareness",
        "Spatial Sparsity",
        "Greedy Algorithm"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:40.058515Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.02686",
    "title": "ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data",
    "authors": [
      "Yuxing Liu",
      "Zheng Li",
      "Huanhuan Liang",
      "Ji Zhang",
      "Zeyu Sun",
      "Yong Liu"
    ],
    "abstract": "Anomaly segmentation seeks to detect and localize unknown or out-of-distribution (OoD) objects that fall outside predefined semantic classes a capability essential for safe autonomous driving. However, the scarcity and limited diversity of anomaly data severely constrain model generalization in open-world environments. Existing approaches mitigate this issue through synthetic data generation, either by copy-pasting external objects into driving scenes or by leveraging text-to-image diffusion models to inpaint anomalous regions. While these methods improve anomaly diversity, they often lack contextual coherence and physical realism, resulting in domain gaps between synthetic and real data. In this paper, we present ClimaDrive, a semantics-guided image-to-image framework for synthesizing semantically coherent, weather-diverse, and physically plausible OoD driving data. ClimaDrive unifies structure-guided multi-weather generation with prompt-driven anomaly inpainting, enabling the creation of visually realistic training data. Based on this framework, we construct ClimaOoD, a large-scale benchmark spanning six representative driving scenarios under both clear and adverse weather conditions. Extensive experiments on four state-of-the-art methods show that training with ClimaOoD leads to robust improvements in anomaly segmentation. Across all methods, AUROC, AP, and FPR95 show notable gains, with FPR95 dropping from 3.97 to 3.52 for RbA on Fishyscapes LAF. These results demonstrate that ClimaOoD enhances model robustness, offering valuable training data for better generalization in open-world anomaly detection.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.02686.pdf",
    "abs_url": "https://arxiv.org/abs/2512.02686",
    "published": "2025-12-02T12:14:19Z",
    "updated": "2026-02-26T10:18:58Z",
    "comment": "Accepted by CVPR2026",
    "light_analysis": {
      "overview": "提出ClimaDrive框架，通过物理逼真的合成数据生成，显著提升异常分割的泛化能力和模型鲁棒性。",
      "motivation": "异常分割用于检测自动驾驶中的未知物体，对安全至关重要，但异常数据稀缺且多样性有限，限制了模型在开放世界的泛化。现有方法通过合成数据生成缓解此问题，如复制粘贴外部对象或使用扩散模型修复异常区域，但这些方法常缺乏上下文一致性和物理逼真度，导致合成与真实数据间存在域差距，影响模型性能。",
      "method": "论文提出ClimaDrive，一种语义引导的图像到图像框架，用于合成语义一致、天气多样、物理逼真的OoD驾驶数据。该方法统一结构引导的多天气生成与提示驱动的异常修复，利用语义信息生成视觉逼真的训练样本。基于此框架，构建了ClimaOoD基准，涵盖六个代表性驾驶场景，在晴朗和恶劣天气条件下，以增强数据多样性。",
      "result": "在四个先进异常分割方法上进行广泛实验，训练使用ClimaOoD显著提升了性能指标。AUROC、AP和FPR95均有明显改善，例如在Fishyscapes LAF基准上，RbA方法的FPR95从3.97降至3.52。这些结果表明，ClimaOoD能有效增强模型鲁棒性，优于传统合成数据方法，提高了异常检测的泛化能力。",
      "conclusion": "论文主要贡献是提出了ClimaDrive框架和ClimaOoD基准，通过物理逼真的合成数据生成，改善了异常分割的模型性能。这为开放世界异常检测提供了有价值的训练数据，具有实际应用价值，例如提升自动驾驶安全性，并可能推动合成数据生成和异常分割领域的未来研究，尽管可能存在数据生成的局限性。",
      "tags": [
        "Anomaly Segmentation",
        "Synthetic Data Generation",
        "Image-to-Image Synthesis",
        "Multi-Weather Generation",
        "Prompt-Driven Inpainting"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:23.329282Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.01292",
    "title": "Diffusion Model in Latent Space for Medical Image Segmentation Task",
    "authors": [
      "Huynh Trinh Ngoc",
      "Toan Nguyen Hai",
      "Ba Luong Son",
      "Long Tran Quoc"
    ],
    "abstract": "Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.01292.pdf",
    "abs_url": "https://arxiv.org/abs/2512.01292",
    "published": "2025-12-01T05:26:43Z",
    "updated": "2026-02-26T14:18:12Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种结合变分自编码器和潜在扩散模型的高效医学图像分割框架，以捕捉分割不确定性并提升计算效率。",
      "motivation": "医学图像分割对临床诊断至关重要，但传统方法仅产生单一分割掩码，无法处理多医生解释的内在不确定性，这在实际应用中可能导致可靠性不足。尽管最近生成模型能生成多个可能掩码来模拟临床协作，但它们通常计算量大，限制了在医疗环境中的部署。因此，研究旨在开发一种高效的分割方法，以平衡多样性和计算成本，增强分割结果的可解释性和临床适用性。",
      "method": "本文提出 MedSegLatDiff 框架，结合变分自编码器（VAE）和潜在扩散模型进行医学图像分割。首先，VAE 将输入图像压缩到低维潜在空间，减少噪声并加速训练过程；然后，扩散模型在潜在空间中操作，直接生成分割结果，降低了计算负担。关键创新点包括在潜在空间应用扩散过程，以及用加权交叉熵损失替换传统均方误差损失，以更好地保留像小结节这样的微小结构。该框架使用 VAE 编码和解码结构，以及扩散模型的去噪过程。",
      "result": "在 ISIC-2018（皮肤病变）、CVC-Clinic（息肉）和 LIDC-IDRI（肺结节）数据集上评估，MedSegLatDiff 在 Dice 和 IoU 分数上达到了最先进的或高度竞争性的性能。与确定性基线方法相比，它同时生成了多样化的分割假设和置信度图，从而提供了增强的可解释性和可靠性。摘要未明确说明具体数值指标，但整体效果表明模型在保持高准确性的同时，改进了分割结果的稳健性，使其更适合临床部署。",
      "conclusion": "本研究的核心贡献是 MedSegLatDiff，它通过结合 VAE 和潜在扩散模型，在医学图像分割中实现了高效和不确定性的捕捉。学术上，该工作扩展了扩散模型在潜在空间的应用，推动了生成式方法在医疗影像分析中的进展；实际应用中，模型提高了分割的可靠性和可解释性，为临床决策提供了更可靠的工具。局限性可能包括对其他医学数据集的泛化能力，未来工作可探索进一步优化模型效率或扩展到更多分割任务。",
      "tags": [
        "Diffusion Model",
        "Variational Autoencoder",
        "Latent Diffusion Model",
        "Medical Image Segmentation",
        "Weighted Cross-Entropy Loss"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:52.925051Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.17361",
    "title": "SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for Real-Time Self-Supervised Occupancy Estimation",
    "authors": [
      "Seamie Hayes",
      "Reenu Mohandas",
      "Tim Brophy",
      "Alexandre Boulch",
      "Ganesh Sistu",
      "Ciaran Eising"
    ],
    "abstract": "Semantic occupancy estimation enables comprehensive scene understanding for automated driving, providing dense spatial and semantic information essential for perception and planning. While Gaussian representations have been widely adopted in self-supervised occupancy estimation, the deployment of a large number of Gaussian primitives drastically increases memory requirements and is not suitable for real-time inference. In contrast, superquadrics permit reduced primitive count and lower memory requirements due to their diverse shape set. However, implementation into a self-supervised occupancy model is nontrivial due to the absence of a superquadric rasterizer to enable model supervision. Our proposed method, SuperQuadricOcc, employs a superquadric-based scene representation. By leveraging a multi-layer icosphere-tessellated Gaussian approximation of superquadrics, we enable Gaussian rasterization for supervision during training. On the Occ3D dataset, SuperQuadricOcc achieves a 75% reduction in memory footprint, 124% faster inference, and a 5.9% improvement in mIoU compared to previous Gaussian-based methods, without the use of temporal labels. To our knowledge, this is the first occupancy model to enable real-time inference while maintaining competitive performance. The use of superquadrics reduces the number of primitives required for scene modeling by 84% relative to Gaussian-based approaches. Finally, evaluation against prior methods is facilitated by our fast superquadric voxelization module. The code will be made available at https://github.com/seamie6/SuperQuadricOcc.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.17361.pdf",
    "abs_url": "https://arxiv.org/abs/2511.17361",
    "published": "2025-11-21T16:26:31Z",
    "updated": "2026-02-26T14:31:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了SuperQuadricOcc方法，基于超二次曲面实现实时自监督占位估计，显著减少内存消耗。",
      "motivation": "语义占位估计在自动驾驶中至关重要，提供密集的空间和语义信息用于感知和规划。当前广泛采用的高斯表示在自监督占位估计中，由于需要大量高斯基元，导致内存需求激增，不适合实时推理。超二次曲面因其形状多样性可以降低基元数量和内存消耗，但缺乏相应的超二次曲面光栅化器用于模型监督，限制了其应用。",
      "method": "论文提出了SuperQuadricOcc方法，采用超二次曲面作为场景表示。通过引入多层球面细分的高斯近似来表示超二次曲面，使得训练期间能够利用高斯光栅化进行监督。该方法在Occ3D数据集上评估，不使用时间标签，核心创新在于结合超二次曲面的形状优势和近似方法实现有效监督。",
      "result": "在Occ3D数据集上，SuperQuadricOcc与先前高斯方法相比，内存足迹减少了75%，推理速度提升了124%，平均交并比（mIoU）提高了5.9%。同时，该方法将场景建模所需的基元数量减少了84%，首次实现实时推理，并保持竞争力。这些结果基于基线对比验证。",
      "conclusion": "论文的主要贡献是开发了首个实现实时推理的自监督占位估计模型，通过超二次曲面显著降低了内存和计算需求，提升了自动驾驶系统的效率。研究还提供了快速超二次曲面体素化模块以促进与其他方法的比较。摘要未明确说明潜在局限性或未来工作方向，但可能涉及扩展到更复杂场景或优化近似技术。",
      "tags": [
        "Superquadrics",
        "Gaussian Approximation",
        "Occupancy Estimation",
        "Self-Supervised Learning",
        "Real-Time Inference"
      ]
    },
    "analyzed_at": "2026-02-27T03:50:49.825659Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.09045",
    "title": "USF-Net: A Unified Spatiotemporal Fusion Network for Ground-Based Remote Sensing Cloud Image Sequence Extrapolation",
    "authors": [
      "Penghui Niu",
      "Taotao Cai",
      "Suqi Zhang",
      "Junhua Gua",
      "Ping Zhanga",
      "Qiqi Liu",
      "Jianxin Li"
    ],
    "abstract": "Ground-based remote sensing cloud image sequence extrapolation is a key research area in the development of photovoltaic power systems. However, existing approaches exhibit several limitations:(1)they primarily rely on static kernels to augment feature information, lacking adaptive mechanisms to extract features at varying resolutions dynamically;(2)temporal guidance is insufficient, leading to suboptimal modeling of long-range spatiotemporal dependencies; and(3)the quadratic computational cost of attention mechanisms is often overlooked, limiting efficiency in practical deployment. To address these challenges, we propose USF-Net, a Unified Spatiotemporal Fusion Network that integrates adaptive large-kernel convolutions and a low-complexity attention mechanism, combining temporal flow information within an encoder-decoder framework. Specifically, the encoder employs three basic layers to extract features. Followed by the USTM, which comprises:(1)a SiB equipped with a SSM that dynamically captures multi-scale contextual information, and(2)a TiB featuring a TAM that effectively models long-range temporal dependencies while maintaining computational efficiency. In addition, a DSM with a TGM is introduced to enable unified modeling of temporally guided spatiotemporal dependencies. On the decoder side, a DUM is employed to address the common \"ghosting effect.\" It utilizes the initial temporal state as an attention operator to preserve critical motion signatures. As a key contribution, we also introduce and release the ASI-CIS dataset. Extensive experiments on ASI-CIS demonstrate that USF-Net significantly outperforms state-of-the-art methods, establishing a superior balance between prediction accuracy and computational efficiency for ground-based cloud extrapolation. The dataset and source code will be available at https://github.com/she1110/ASI-CIS.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.09045.pdf",
    "abs_url": "https://arxiv.org/abs/2511.09045",
    "published": "2025-11-12T06:54:40Z",
    "updated": "2026-02-26T06:19:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "USF-Net提出一个统一的时空融合网络，通过整合自适应大核卷积和低复杂度注意力机制，有效解决了地面遥感云图像序列外推中的时空依赖建模问题。",
      "motivation": "研究旨在解决地面遥感云图像序列外推的关键问题，这对于光伏发电系统的优化至关重要。现有方法存在显著不足：首先，主要依赖静态核来增强特征，缺乏自适应机制以动态提取多分辨率特征；其次，时间指导不充分，导致长距离时空依赖建模不理想；最后，注意力机制的二次计算成本常被忽视，限制了实际部署的效率。这些问题共同影响了预测准确性和应用可行性，凸显了改进方法的必要性。",
      "method": "USF-Net采用编码器-解码器框架，核心是整合自适应大核卷积和低复杂度注意力机制。编码器使用三个基本层提取特征；后接USTM模块，包括SiB和TiB：SiB配备SSM动态捕获多尺度上下文信息，TiB配备TAM有效建模长距离时间依赖并保持计算效率。此外，DSM with TGM实现统一的时空依赖建模。解码器使用DUM处理常见的“ghosting effect”，通过初始时间状态作为注意力操作符保留关键运动签名。整体结构旨在高效提取和融合时空信息。",
      "result": "在ASI-CIS数据集上的广泛实验表明，USF-Net显著优于现有最先进方法。虽然没有提供具体数值，但论文报告了其在预测准确性和计算效率之间达到了优越平衡。这意味着该方法在性能提升的同时减少了计算开销，为实际部署提供了可行性。与基线方法相比，USF-Net在云图像序列外推任务中表现出更强的建模能力和更低的资源需求。",
      "conclusion": "本研究的主要贡献包括提出了USF-Net网络和发布了ASI-CIS数据集。USF-Net通过创新地结合自适应大核卷积和低复杂度注意力机制，解决了云图像序列外推中的关键问题，具有重要的学术价值（如改进时空依赖建模）和实际应用价值（如优化光伏发电）。未来工作可能包括进一步扩展模型到其他领域或优化计算效率，但摘要未明确说明具体局限性。",
      "tags": [
        "Spatiotemporal Fusion Network",
        "Large-Kernel Convolution",
        "Temporal Attention Mechanism",
        "Cloud Image Extrapolation",
        "Remote Sensing"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:08.741146Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.05898",
    "title": "Q$^2$: Quantization-Aware Gradient Balancing and Attention Alignment for Low-Bit Quantization",
    "authors": [
      "Zhaoyang Wang",
      "Dong Wang"
    ],
    "abstract": "Quantization-aware training (QAT) has achieved remarkable success in low-bit ($\\leq$4-bit) quantization for classification networks. However, when applied to more complex visual tasks such as object detection and image segmentation, performance still suffers significant degradation. A key cause of this limitation has been largely overlooked in the literature. In this work, we revisit this phenomenon from a new perspective and identify a major failure factor: gradient imbalance at feature fusion stages, induced by accumulated quantization errors. This imbalance biases the optimization trajectory and impedes convergence under low-bit quantization. Based on this diagnosis, we propose Q$^2$, a two-pronged framework comprising: (1) Quantization-aware Gradient Balancing Fusion (Q-GBFusion), a closed-loop mechanism that dynamically rebalances gradient contributions during feature fusion; and (2) Quantization-aware Attention Distribution Alignment (Q-ADA), a parameter-free supervision strategy that reconstructs the supervision distribution using semantic relevance and quantization sensitivity, yielding more stable and reliable supervision to stabilize training and accelerate convergence. Extensive experiments show that our method, as a plug-and-play and general strategy, can be integrated into various state-of-the-art QAT pipelines, achieving an average +2.5\\% mAP gain on object detection and a +3.7\\% mDICE improvement on image segmentation. Notably, it is applied only during training and introduces no inference-time overhead, making it highly practical for real-world deployment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.05898.pdf",
    "abs_url": "https://arxiv.org/abs/2511.05898",
    "published": "2025-11-08T07:45:21Z",
    "updated": "2026-02-26T12:49:30Z",
    "comment": "24 pages,6 figures",
    "light_analysis": {
      "overview": "该论文提出 Q^2 框架，通过量化感知的梯度平衡和注意力对齐，解决低比特量化中特征融合阶段的性能下降问题。",
      "motivation": "量化感知训练（QAT）在低比特（≤4-bit）量化中已显著提升分类网络性能，但在目标检测和图像分割等复杂视觉任务中仍出现性能退化。文献中普遍忽视了关键原因：特征融合阶段由累积量化误差引起的梯度不平衡问题。这种不平衡偏置优化轨迹，阻碍低比特量化下的收敛，限制了 QAT 在实际复杂应用中的有效性，因此需探索新方法以解决这一瓶颈。",
      "method": "论文提出 Q^2 框架，包含两部分：Q-GBFusion 通过闭环机制动态重新平衡特征融合中的梯度贡献，缓解由量化误差引起的梯度不平衡；Q-ADA 则使用语义相关性和量化敏感性重构监督分布，提供稳定监督以加速训练收敛。该方法是通用即插即用策略，可集成到各种先进 QAT 管道中，仅应用于训练阶段，无推理时间开销，核心创新点在于诊断并针对性解决量化引发的优化问题。",
      "result": "实验显示，Q^2 作为即插即用策略，在集成到先进 QAT 流程后，在目标检测任务上平均实现了 +2.5% 的 mAP 增益，图像分割任务上平均获得了 +3.7% 的 mDICE 改进。这些结果表明方法显著减轻了低比特量化在复杂视觉任务中的性能退化，与基线方法相比提升明显，且不引入额外推理成本，验证了其有效性和实用性。",
      "conclusion": "该研究的主要贡献是诊断出低比特量化中的梯度不平衡问题，并开发了 Q^2 框架来解决它。学术上，为量化感知训练在复杂任务中的应用提供了新视角；实际上，方法即插即用且无推理开销，增强了低比特量化模型的部署效率。未来工作可能涉及扩展到更多视觉任务或优化算法细节，以进一步提升泛化能力。",
      "tags": [
        "Low-bit Quantization",
        "Gradient Balancing",
        "Attention Alignment",
        "Quantization-aware Training",
        "Feature Fusion"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:19.495099Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.27480",
    "title": "Simplex-to-Euclidean Bijections for Categorical Flow Matching",
    "authors": [
      "Bernardo Williams",
      "Victor M. Yeom-Song",
      "Marcelo Hartmann",
      "Arto Klami"
    ],
    "abstract": "We propose a method for learning and sampling from probability distributions supported on the simplex. Our approach maps the open simplex to Euclidean space via smooth bijections, leveraging the Aitchison geometry to define the mappings, and supports modeling categorical data by a Dirichlet interpolation that dequantizes discrete observations into continuous ones. This enables density modeling in Euclidean space through the bijection while still allowing exact recovery of the original discrete distribution. Compared to previous methods that operate on the simplex using Riemannian geometry or custom noise processes, our approach works in Euclidean space while respecting the Aitchison geometry, and achieves competitive performance on both synthetic and real-world data sets.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.27480.pdf",
    "abs_url": "https://arxiv.org/abs/2510.27480",
    "published": "2025-10-31T14:00:33Z",
    "updated": "2026-02-26T13:00:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于Aitchison几何的光滑双射方法，将单纯形映射到欧几里得空间，用于高效学习和采样分类数据的概率分布。",
      "motivation": "该研究旨在解决从单纯形上的概率分布中学习和采样的问题，特别是在处理分类数据时。单纯形是分类概率的自然空间，但直接在单纯形上建模面临几何复杂性，现有方法如使用黎曼几何或自定义噪声过程，操作可能繁琐或效率不高。因此，需要一种更高效且尊重几何结构的方法来简化建模过程，以支持实际应用中的分类数据分析。",
      "method": "论文提出了一种方法，通过定义光滑的双射映射，将开放单纯形转换为欧几里得空间，利用Aitchison几何指导映射以保留单纯形的内在结构。关键创新包括使用Dirichlet插值对分类数据进行建模，将离散观测去量化为连续变量，从而在欧几里得空间中进行密度建模。此外，该方法支持流匹配技术学习和采样，并能通过双射精确恢复原始离散分布，避免了信息丢失。",
      "result": "实验结果表明，该方法在合成和真实数据集上都取得了竞争性的性能。与先前在单纯形上使用黎曼几何或自定义噪声过程的方法相比，提出的方法在欧几里得空间中工作，计算上可能更高效。摘要未明确说明具体的性能提升指标如准确率，但强调其竞争性表现，表明其在建模分类数据分布方面的有效性，无需编造数据。",
      "conclusion": "该研究的主要贡献在于提出了一种基于光滑双射和Aitchison几何的方法，用于在单纯形上学习和采样概率分布。其学术价值在于将几何学引入机器学习，简化了分类数据建模的复杂性。实际应用上，该方法可广泛用于需要概率建模的领域，如自然语言处理或生物信息学。未来工作可能包括扩展方法到更广泛的几何结构或优化计算效率，但摘要未明确说明。",
      "tags": [
        "Categorical Flow Matching",
        "Aitchison Geometry",
        "Dirichlet Interpolation",
        "Simplex-to-Euclidean Bijection",
        "Probability Distribution Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:12.401183Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.26577",
    "title": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models",
    "authors": [
      "Yinrong Hong",
      "Zhiquan Tan",
      "Kai Hu"
    ],
    "abstract": "Large Language Models (LLMs) face significant inference latency challenges stemming from their autoregressive design and large size. To address this, speculative decoding emerges as a solution, enabling the simultaneous generation and validation of multiple tokens. While recent approaches like EAGLE-2 and EAGLE-3 improve speculative decoding using dynamic tree structures, they often neglect the impact of crucial system variables such as GPU devices and batch sizes.   Therefore, we introduce a new dynamic tree decoding approach called CAST that takes into account inference costs, including factors such as GPU configurations and batch sizes, to dynamically refine the tree structure. Through comprehensive experimentation across six diverse tasks and utilizing six distinct LLMs, our methodology demonstrates remarkable results, achieving speeds up to 5.2 times faster than conventional decoding methods. Moreover, it generally outperforms existing state-of-the-art techniques from 5 % to 20%. The code is available at https://github.com/EAGLE-Research/sglang-eagle4.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.26577.pdf",
    "abs_url": "https://arxiv.org/abs/2510.26577",
    "published": "2025-10-30T15:04:36Z",
    "updated": "2026-02-26T14:19:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了CAST方法，一种考虑推理成本的动态树构造技术，以提高大型语言模型的推理效率。",
      "motivation": "大型语言模型由于自回归设计和庞大参数，推理延迟显著，限制了实时应用。推测解码能同时生成多个令牌以加速推理，但现有动态树方法如EAGLE-2和EAGLE-3忽略了GPU设备和批量大小等关键系统变量，导致优化不充分。因此，本研究旨在通过考虑推理成本来改进动态树构造，以更高效地处理LLM推理任务，解决现有方法的不足。",
      "method": "论文提出了CAST方法，一种推理成本感知的动态树解码技术。该方法基于推测解码框架，结合GPU配置和批量大小等系统变量，动态调整树结构以最小化推理成本。核心创新在于成本敏感的树构造算法，能够在不同硬件和负载条件下自适应优化。实验中使用六个多样任务和六个不同的LLM进行验证，确保方法的通用性和有效性，但具体模型架构摘要未明确说明。",
      "result": "在多个实验设置下，CAST方法表现出显著性能提升。相比于传统解码方法，推理速度最高可达5.2倍提升；与现有最先进技术如EAGLE系列相比，普遍实现5%到20%的性能改进。这些结果通过在不同任务和模型上的综合实验得到验证，证明了方法在加速LLM推理方面的有效性和鲁棒性，具体数据集和基准对比在摘要中未详细说明。",
      "conclusion": "本研究的主要贡献在于提出CAST方法，通过考虑推理成本改进了动态树构造，显著提升了大型语言模型的推理效率。学术上，该方法丰富了推测解码技术的应用，为解决LLM延迟问题提供了新思路；应用上，有望推动高效AI服务的部署。局限性方面，摘要未明确说明，未来工作可能包括扩展到更多系统变量或模型类型。",
      "tags": [
        "Large Language Model",
        "Speculative Decoding",
        "Dynamic Tree Construction",
        "Inference Cost",
        "GPU Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:28.773865Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.25726",
    "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution",
    "authors": [
      "Junlong Li",
      "Wenshuo Zhao",
      "Jian Zhao",
      "Weihao Zeng",
      "Haoze Wu",
      "Xiaochen Wang",
      "Rui Ge",
      "Yuxuan Cao",
      "Yuzhen Huang",
      "Wei Liu",
      "Junteng Liu",
      "Zhaochen Su",
      "Yiyang Guo",
      "Fan Zhou",
      "Lueyang Zhang",
      "Juan Michelini",
      "Xingyao Wang",
      "Xiang Yue",
      "Shuyan Zhou",
      "Graham Neubig",
      "Junxian He"
    ],
    "abstract": "Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.25726.pdf",
    "abs_url": "https://arxiv.org/abs/2510.25726",
    "published": "2025-10-29T17:32:49Z",
    "updated": "2026-02-26T09:46:48Z",
    "comment": "ICLR 2026, Website: https://toolathlon.xyz/",
    "light_analysis": {
      "overview": "Tool Decathlon 是一个用于评估语言代理处理多样化、现实和长期任务的基准测试，填补现有评估的空白。",
      "motivation": "研究动机源于现有语言代理基准专注于狭窄领域或简化任务，缺乏多样性、现实性和长期复杂性，无法准确评估真实世界性能。例如，真实应用中代理需协调跨应用工作流，如邮件管理与日历同步，或监控数据库生成报告，这些复杂任务需要更全面的评估方法，而现有基准不足以反映这种现实挑战。",
      "method": "论文提出 Tool Decathlon 基准，包含 32 个软件应用和 604 个工具，覆盖日常和专业平台，如 Google Calendar 和 Kubernetes。关键创新是基于高质量 Model Context Protocol 服务器，提供真实初始环境状态，如 Canvas 课程或财务电子表格。基准包括 108 个手动任务，平均需 20 轮交互，并通过专用评估脚本严格验证执行结果，确保功能性和多样性。",
      "result": "对最先进模型的全面评估显示性能显著不足：Claude-4.5-Sonnet 仅达到 38.6% 成功率，平均调用 20.2 个工具；顶级开源模型 DeepSeek-V3.2-Exp 为 20.1%。这些数据表明现有模型在处理长期、多样化任务时面临挑战，与理想水平有较大差距，突显基准的有效性。",
      "conclusion": "Tool Decathlon 基准的主要贡献是填补了评估语言代理在现实、长期任务中性能的空白，具有学术价值，能推动开发更强大的代理。它揭示现有技术的局限性，未来工作可基于此改进模型性能或扩展基准，以更好应对真实世界应用需求，如跨域任务执行。",
      "tags": [
        "Language Agents",
        "Benchmarking",
        "Tool Calling",
        "Model Context Protocol (MCP)",
        "Long-Horizon Task Execution"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:34.766692Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.21306",
    "title": "PARL: Prompt-based Agents for Reinforcement Learning",
    "authors": [
      "Yarik Menchaca Resendiz",
      "Roman Klinger"
    ],
    "abstract": "Large language models (LLMs) have demonstrated high performance on tasks expressed in natural language, particularly in zero- or few-shot settings. These are typically framed as supervised (e.g., classification) or unsupervised (e.g., clustering) problems. However, limited work evaluates LLMs as agents in reinforcement learning (RL) tasks (e.g., playing games), where learning occurs through interaction with an environment and a reward system. While prior work focused on representing tasks that rely on a language representation, we study structured, non-linguistic reasoning - such as interpreting positions in a grid world. We therefore introduce PARL (Prompt-based Agent for Reinforcement Learning), a method that uses LLMs as RL agents through prompting, without any fine-tuning. PARL encodes actions, states, and rewards in the prompt, enabling the model to learn through trial-and-error interaction. We evaluate PARL on three standard RL tasks that do not entirely rely on natural language. We show that it can match or outperform traditional RL agents in simple environments by leveraging pretrained knowledge. However, we identify performance limitations in tasks that require complex mathematical operations or decoding states and actions.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.21306.pdf",
    "abs_url": "https://arxiv.org/abs/2510.21306",
    "published": "2025-10-24T10:04:23Z",
    "updated": "2026-02-26T13:46:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出 PARL，一种基于提示的大语言模型代理方法，用于强化学习任务，无需微调。",
      "motivation": "大语言模型在自然语言任务中表现出色，但作为强化学习代理的应用研究有限。现有方法主要依赖语言表示，难以处理非语言环境如网格世界，导致在结构化推理任务中的能力未被充分探索。本研究旨在解决此问题，探索 LLMs 在非语言 RL 任务中的潜力，以弥补传统方法在利用预训练知识和适应多样化环境方面的不足，推动 AI 代理的跨领域应用。",
      "method": "PARL 方法通过提示工程将大语言模型应用于强化学习，无需微调。核心创新是在提示中编码动作、状态和奖励信息，使模型能根据环境反馈进行试错交互学习。该方法利用预训练知识，适应结构化、非语言任务如网格世界推理，技术特色包括基于提示的策略学习和交互式适应机制，无需额外模型训练，简化了 RL 代理的部署过程。",
      "result": "PARL 在三个不完全依赖自然语言的标准强化学习任务上进行评估。结果显示，在简单环境中，通过利用预训练知识，PARL 能够匹配或超越传统 RL 代理，证明了其有效性。然而，在需要复杂数学操作或解码状态和动作的任务中，性能表现出局限性，具体指标摘要未明确说明，但对比突显了该方法在简单与复杂任务之间的性能差异。",
      "conclusion": "PARL 展示了使用大语言模型作为强化学习代理的可行性，通过提示机制实现无需微调的学习。主要贡献在于将 LLMs 扩展到非语言推理任务，为 RL 领域提供创新方法。学术上，促进了基于预训练知识的代理研究；实践中，可能简化游戏或模拟环境中的 RL 系统开发。局限性包括复杂任务性能不足，未来工作可优化提示策略或结合其他技术提升能力。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning",
        "Prompt-based Methods",
        "Zero-shot Learning",
        "Grid World"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:48.807018Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.20505",
    "title": "RELOOP: Recursive Retrieval with Multi-Hop Reasoner and Planners for Heterogeneous QA",
    "authors": [
      "Ruiyi Yang",
      "Hao Xue",
      "Imran Razzak",
      "Hakim Hacid",
      "Flora D. Salim"
    ],
    "abstract": "Retrieval-augmented generation (RAG) remains brittle on multi-step questions and heterogeneous evidence sources, trading accuracy against latency and token/tool budgets. This paper introduces RELOOP, a structure aware framework using Hierarchical Sequence (HSEQ) that (i) linearize documents, tables, and knowledge graphs into a reversible hierarchical sequence with lightweight structural tags, and (ii) perform structure-aware iteration to collect just-enough evidence before answer synthesis. A Head Agent provides guidance that leads retrieval, while an Iteration Agent selects and expands HSeq via structure-respecting actions (e.g., parent/child hops, table row/column neighbors, KG relations); Finally the head agent composes canonicalized evidence to genearte the final answer, with an optional refinement loop to resolve detected contradictions. Experiments on HotpotQA (text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1 gains over strong single-pass, multi-hop, and agentic RAG baselines with high efficiency. Besides, RELOOP exhibits three key advantages: (1) a format-agnostic unification that enables a single policy to operate across text, tables, and KGs without per-dataset specialization; (2) \\textbf{guided, budget-aware iteration} that reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and (3) evidence canonicalization for reliable QA, improving answers consistency and auditability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.20505.pdf",
    "abs_url": "https://arxiv.org/abs/2510.20505",
    "published": "2025-10-23T12:48:18Z",
    "updated": "2026-02-26T10:08:30Z",
    "comment": "19 pages, 2 figures",
    "light_analysis": {
      "overview": "论文提出了RELOOP框架，通过结构感知的递归检索和分层序列，高效处理异构问答，统一了文本、表格和知识图谱的处理。",
      "motivation": "检索增强生成（RAG）在处理多步问题和异构证据源时仍然脆弱，需要在准确性、延迟和资源预算之间权衡。现有方法如单次检索、多跳检索和基于代理的RAG往往效率低下或准确性不足，特别是在涉及文本、表格和知识图谱的复杂QA场景中，这限制了实际应用的效果和效率。因此，开发一个能够统一处理不同数据格式并优化检索迭代的框架变得至关重要，以提升QA系统的鲁棒性和实用性。",
      "method": "RELOOP框架采用分层序列（HSEQ）将文档、表格和知识图谱线性化为可逆的层次序列，并使用轻量级结构标签表示结构化信息。核心创新在于结构感知的迭代过程，由Head Agent引导检索方向，Iteration Agent通过执行结构尊重的动作（如父/子跳转、表行/列邻居、KG关系）来选择和扩展HSeq，以收集足够证据。最终，Head Agent组合规范化的证据生成答案，并可选地通过精炼循环解决检测到的矛盾，实现高效且准确的答案合成。",
      "result": "在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（KG）等数据集上的实验表明，RELOOP在EM/F1指标上优于强的单次检索、多跳检索和代理RAG基线，显示出一致的性能提升。它同时保持了高效率，减少了不必要的跳转、工具调用和令牌使用，实现了引导的、预算感知的迭代，从而在多个异构QA任务中验证了其有效性和优势，摘要未明确说明具体数据指标。",
      "conclusion": "RELOOP的主要贡献在于提出了一个格式无关的统一框架，使单一策略能够跨文本、表格和知识图谱操作，无需针对每个数据集进行专门化。它通过引导的、预算感知的迭代提高了检索效率，并通过证据规范化增强了答案的一致性和可审计性。该研究为异构QA系统提供了有效的解决方案，具有显著的学术价值（如推动多模态检索方法发展）和实际应用价值（如提升企业知识库的查询效率），未来工作可能涉及扩展到更多数据源或进一步优化迭代策略。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Hierarchical Sequence",
        "Multi-Hop Reasoning",
        "Knowledge Graphs",
        "Agent-based Systems"
      ]
    },
    "analyzed_at": "2026-02-27T03:51:58.204629Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.19060",
    "title": "PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions",
    "authors": [
      "Amith Ananthram",
      "Elias Stengel-Eskin",
      "Lorena A. Bradford",
      "Julia Demarest",
      "Adam Purvis",
      "Keith Krut",
      "Robert Stein",
      "Rina Elster Pantalony",
      "Mohit Bansal",
      "Kathleen McKeown"
    ],
    "abstract": "While vision-language models (VLMs) have advanced into detailed image description, evaluation remains a challenge. Standard metrics (e.g. CIDEr, SPICE) were designed for short texts and tuned to recognize errors that are now uncommon, such as object misidentification. In contrast, long texts require sensitivity to attribute and relation attachments and scores that localize errors to particular text spans. In this work, we introduce PoSh, a metric for detailed image description that uses scene graphs as structured rubrics to guide LLMs-as-a-Judge, producing aggregate scores grounded in fine-grained errors (e.g. mistakes in compositional understanding). PoSh is replicable, interpretable and a better proxy for human raters than existing metrics (including GPT4o-as-a-Judge). To validate PoSh, we introduce a challenging new dataset, DOCENT. This novel benchmark contains artwork, paired with expert-written references, and model-generated descriptions, augmented with granular and coarse judgments of their quality from art history students. Thus, DOCENT enables evaluating both detailed image description metrics and detailed image description itself in a challenging new domain. We show that PoSh achieves stronger correlations (+0.05 Spearman $ρ$) with the human judgments in DOCENT than the best open-weight alternatives, is robust to image type (using CapArena, an existing dataset of web imagery) and is a capable reward function, outperforming standard supervised fine-tuning. Then, using PoSh, we characterize the performance of open and closed models in describing the paintings, sketches and statues in DOCENT and find that foundation models struggle to achieve full, error-free coverage of images with rich scene dynamics, establishing a demanding new task to gauge VLM progress. Through both PoSh and DOCENT, we hope to enable advances in important areas such as assistive text generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.19060.pdf",
    "abs_url": "https://arxiv.org/abs/2510.19060",
    "published": "2025-10-21T20:30:20Z",
    "updated": "2026-02-26T18:05:42Z",
    "comment": "Accepted at ICLR 2026. 26 pages, 9 figures. Metric/benchmark available at https://github.com/amith-ananthram/posh",
    "light_analysis": {
      "overview": "提出PoSh指标，利用场景图引导LLMs作为评估器，以改进详细图像描述的评估准确性和可解释性。",
      "motivation": "随着视觉语言模型（VLMs）在生成详细图像描述方面取得进展，评估成为一个关键挑战。现有标准指标如CIDEr和SPICE针对短文本设计，难以检测长文本中的属性、关系错误，且对现代模型常见错误不敏感。这限制了评估的精确性和实际应用，特别是在处理复杂场景描述时。因此，开发新方法至关重要，以提升评估质量，推动VLM在辅助文本生成等领域的发展。",
      "method": "PoSh方法的核心是使用场景图作为结构化评分标准，引导大语言模型（LLMs）作为评估器。它通过将图像描述转换为场景图表示，利用LLM进行细粒度错误分析，如组合理解错误，生成可复制、可解释的聚合分数。为验证方法，研究引入了DOCENT数据集，包含艺术品、专家参考描述、模型生成描述，以及艺术史学生提供的人工质量判断，涵盖绘画、素描和雕塑等多样性内容。",
      "result": "实验显示，PoSh在DOCENT数据集上与人类判断的Spearman相关性提升+0.05，优于最佳替代方法，包括GPT4o-as-a-Judge。在CapArena数据集上，PoSh表现出对图像类型的鲁棒性，验证了其泛化能力。此外，作为奖励函数，PoSh在优化模型性能时优于标准监督微调。这些结果证明PoSh能有效模拟人类评估者，为详细图像描述提供更精确的评估指标。",
      "conclusion": "PoSh和DOCENT共同为详细图像描述评估提供了创新框架。主要贡献在于提出了基于场景图的LLM引导评估方法，以及一个挑战性的新数据集，有助于量化VLM在复杂场景描述中的进展。学术价值体现在改进评估指标和推动VLM研究，实际应用则促进辅助文本生成等领域。摘要未明确说明局限性，但未来工作可能包括扩展数据集或提升模型对动态场景的覆盖能力。",
      "tags": [
        "Vision-Language Models",
        "Large Language Models",
        "Scene Graphs",
        "Evaluation Metrics",
        "Detailed Image Description"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:17.902413Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.15464",
    "title": "Learning to Answer from Correct Demonstrations",
    "authors": [
      "Nirmit Joshi",
      "Gene Li",
      "Siddharth Bhandari",
      "Shiva Prasad Kasiviswanathan",
      "Cong Ma",
      "Nathan Srebro"
    ],
    "abstract": "We study the problem of learning to generate an answer (or completion) to a question (or prompt), where there could be multiple correct answers, any one of which is acceptable at test time. Learning is based on demonstrations of some correct answer to each training question, as in Supervised Fine Tuning (SFT). We formalize the problem as imitation learning (i.e., apprenticeship learning) in contextual bandits, with offline demonstrations from some expert (optimal, or very good) policy, without explicitly observed rewards. In contrast to prior work, which assumes the demonstrator belongs to a bounded-complexity policy class, we propose relying only on the underlying reward model (i.e., specifying which answers are correct) being in a bounded-complexity class, which we argue is a strictly weaker assumption. We show that likelihood-maximization methods can fail in this setting, and instead present an approach that learns to answer nearly as well as the demonstrator, with sample complexity logarithmic in the cardinality of the reward class. Our method is similar to Syed and Schapire 2007, when adapted to a contextual bandit (i.e., single step) setup, but is a simple one-pass online approach that enjoys an \"optimistic rate\" (i.e., $1/\\varepsilon$ when the demonstrator is optimal, versus $1/\\varepsilon^2$ in Syed and Schapire), and works even with arbitrarily adaptive demonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.15464.pdf",
    "abs_url": "https://arxiv.org/abs/2510.15464",
    "published": "2025-10-17T09:20:17Z",
    "updated": "2026-02-26T12:24:34Z",
    "comment": "Generalized some results. Updated the presentation in light of an important related work of Syed and Schapire. Improved discussions. Comments are welcome",
    "light_analysis": {
      "overview": "本文提出一种从正确答案演示中学习回答的新方法，通过假设奖励模型在有界复杂度类中，降低了假设强度并展示样本复杂度优势。",
      "motivation": "本研究旨在解决在问题可能有多个正确答案时，如何从演示中学习生成答案的问题。现有方法如监督微调（SFT）基于正确演示，但假设演示策略属于有界复杂度类，这可能导致不切实际的限制。本文指出，更合理的假设是奖励模型（指定哪些答案正确）在有界复杂度类中，这种假设更弱且更具实际意义，从而填补了当前模仿学习中的理论缺陷。研究背景涉及离线模仿学习与上下文多臂老虎机的结合，挑战在于在无显式奖励下从演示中有效学习。",
      "method": "研究将问题形式化为模仿学习在上下文多臂老虎机框架中，使用离线演示但无需显式奖励。核心方法是一种简单的一遍在线方法，类似于Syed和Schapire 2007的工作，但适应到单步上下文老虎机设置。关键创新点在于仅依赖奖励模型的有界复杂度假设，而非演示策略的有界性。方法通过优化学习策略来接近演示者的表现，利用“乐观速率”提高效率，例如在演示者最优时速率改进为1/ε。技术细节包括基于样本复杂度的对数依赖性设计，能够处理任意适应性演示，而无需复杂策略类约束。",
      "result": "主要实验结果表明，该方法能学习到接近演示者的效果，样本复杂度为奖励类基数的对数，具有理论优势。具体性能改进体现在乐观速率上：当演示者最优时，速率为1/ε，优于Syed和Schapire 2007的1/ε²。这表明方法在降低假设强度后仍能保持高效学习能力，但摘要未明确说明具体实验数据如准确率提升或基准对比的定量结果，基于信息推断方法在模拟或理论验证中表现出色。与基线方法相比，本文方法在样本效率上有所提升，支持其在无显式奖励环境中的应用。",
      "conclusion": "本研究的主要贡献是提出一种基于奖励模型有界复杂度假设的新方法，用于从演示中学习回答，这降低了模仿学习的理论假设并提高了实用性。研究在模仿学习和强化学习领域具有重要学术价值，为离线学习问题提供了新视角，潜在应用包括问答系统和自动化决策。局限性在于摘要未详细探讨实际部署的挑战，未来工作可能涉及扩展到多步强化学习或结合在线奖励反馈，以进一步验证方法的泛化能力。",
      "tags": [
        "Imitation Learning",
        "Contextual Bandits",
        "Reward Model",
        "Sample Complexity",
        "Supervised Fine Tuning"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:00.737830Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.12670",
    "title": "TerraCodec: Compressing Optical Earth Observations",
    "authors": [
      "Julen Costa-Watanabe",
      "Isabelle Wittmann",
      "Benedikt Blumenstiel",
      "Konrad Schindler"
    ],
    "abstract": "Earth observation (EO) satellites produce massive streams of multispectral image time series, posing pressing challenges for storage and transmission. Yet, learned EO compression remains fragmented and lacks publicly available, large-scale pretrained codecs. Moreover, prior work has largely focused on image compression, leaving temporal redundancy and EO video codecs underexplored. To address these gaps, we introduce TerraCodec (TEC), a family of learned codecs pretrained on Sentinel-2 EO data. TEC includes efficient multispectral image variants and a Temporal Transformer model (TEC-TT) that leverages dependencies across time. To overcome the fixed-rate setting of today's neural codecs, we present Latent Repacking, a novel method for training flexible-rate transformer models that operate on varying rate-distortion settings. TerraCodec outperforms classical codecs, achieving 3-10x higher compression at equivalent image quality. Beyond compression, TEC-TT enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the AllClear benchmark. Our results establish neural codecs as a promising direction for Earth observation. Our code and models are publically available at https://github.com/IBM/TerraCodec.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.12670.pdf",
    "abs_url": "https://arxiv.org/abs/2510.12670",
    "published": "2025-10-14T16:05:31Z",
    "updated": "2026-02-26T16:28:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "TerraCodec 是一套基于 Sentinel-2 数据预训练的学习型地球观测编解码器，通过 Latent Repacking 实现灵活率压缩和 Temporal Transformer 处理时间序列，显著提升压缩性能。",
      "motivation": "地球观测卫星产生大量多光谱图像时间序列，给存储和传输带来巨大挑战。现有学习型压缩方法零散且缺乏公开可用的大规模预训练模型，导致应用受限。先前工作主要集中于静态图像压缩，忽视了时间冗余，未能充分探索地球观测视频数据的压缩潜力，因此开发高效、公开的压缩解决方案具有重要的实际意义。",
      "method": "论文提出 TerraCodec (TEC) 系列，包括基于 Sentinel-2 EO 数据预训练的多光谱图像压缩编解码器，以及 Temporal Transformer 模型 (TEC-TT) 以利用时间依赖性。关键创新是 Latent Repacking 方法，它训练灵活率变压器模型，适应不同率失真设置，突破了传统神经编解码器的固定率限制，实现高效的端到端学习。",
      "result": "实验结果显示，TerraCodec 在同等图像质量下，压缩比相比经典编解码器提高了 3 到 10 倍，显著减少了存储需求。此外，TEC-TT 在零样本云填充任务中，于 AllClear 基准上超越了现有最优方法，证明了其多任务泛化能力和性能优势。",
      "conclusion": "本论文贡献了 TerraCodec 这一公开可用的学习型 EO 编解码器家族，通过 Latent Repacking 实现灵活率压缩和 Temporal Transformer 处理时间序列。研究不仅提升了压缩效率，还拓展到云填充等应用，展示了神经编解码器在地球观测领域的潜力，公开代码和模型为未来多任务应用提供基础。",
      "tags": [
        "Learned Compression",
        "Earth Observation Data",
        "Temporal Transformer",
        "Latent Repacking",
        "Neural Video Codecs"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:19.495934Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.12099",
    "title": "G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior",
    "authors": [
      "Junfeng Ni",
      "Yixin Chen",
      "Zhifei Yang",
      "Yu Liu",
      "Ruijie Lu",
      "Song-Chun Zhu",
      "Siyuan Huang"
    ],
    "abstract": "Despite recent advances in leveraging generative prior from pre-trained diffusion models for 3D scene reconstruction, existing methods still face two critical limitations. First, due to the lack of reliable geometric supervision, they struggle to produce high-quality reconstructions even in observed regions, let alone in unobserved areas. Second, they lack effective mechanisms to mitigate multi-view inconsistencies in the generated images, leading to severe shape-appearance ambiguities and degraded scene geometry. In this paper, we identify accurate geometry as the fundamental prerequisite for effectively exploiting generative models to enhance 3D scene reconstruction. We first propose to leverage the prevalence of planar structures to derive accurate metric-scale depth maps, providing reliable supervision in both observed and unobserved regions. Furthermore, we incorporate this geometry guidance throughout the generative pipeline to improve visibility mask estimation, guide novel view selection, and enhance multi-view consistency when inpainting with video diffusion models, resulting in accurate and consistent scene completion. Extensive experiments on Replica, ScanNet++, DeepBlending and Mip-NeRF 360 show that our method consistently outperforms existing baselines in both geometry and appearance reconstruction, particularly for unobserved regions. Moreover, our method naturally supports single-view inputs and unposed videos, with strong generalizability in both indoor and outdoor scenarios with practical real-world applicability. The project page is available at https://dali-jack.github.io/g4splat-web/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.12099.pdf",
    "abs_url": "https://arxiv.org/abs/2510.12099",
    "published": "2025-10-14T03:06:28Z",
    "updated": "2026-02-26T08:03:13Z",
    "comment": "ICLR'26. Project page: https://dali-jack.github.io/g4splat-web/",
    "light_analysis": {
      "overview": "本论文提出G4Splat方法，通过几何引导和生成先验，显著提升3D场景重建的准确性和一致性，尤其在未观察区域。",
      "motivation": "尽管现有方法利用预训练扩散模型的生成先验进行3D场景重建，但面临两个关键局限：一是缺乏可靠几何监督，导致即使在观察区域也难以生成高质量重建；二是缺乏有效机制减少生成图像的多视角不一致性，引发形状-外观模糊和几何退化。这些问题限制了3D重建在AR/VR等实际应用中的有效性，因此亟需引入更准确的几何指导来克服这些不足。",
      "method": "论文提出G4Splat方法，首先利用场景中普遍存在的平面结构，推导出准确度量尺度的深度图，为观察和未观察区域提供可靠几何监督。其次，将此几何指导整合到生成流程中，通过改善可见性掩码估计、优化新视角选择，并结合视频扩散模型进行修复，以增强多视角一致性。该方法基于Gaussian Splatting框架，结合生成先验，实现了准确且一致的场景完成。",
      "result": "在Replica、ScanNet++、DeepBlending和Mip-NeRF 360等数据集上的广泛实验显示，G4Splat方法在几何和外观重建上均优于现有基线方法，特别是在未观察区域表现突出。与基线方法相比，该方法显著提升了重建的准确性和一致性。此外，它支持单视图输入和未姿态视频，在室内和室外场景中展现出强泛化能力，具有实际应用价值。摘要未明确说明具体性能指标数值。",
      "conclusion": "本研究的主要贡献是提出了G4Splat方法，通过结合几何引导和生成先验，有效解决了3D场景重建中的几何监督和多视角一致性问题。该方法的学术价值在于将准确的几何指导融入生成流程，提升了重建质量；实际应用价值在于支持多样化输入和广泛场景，适用于AR/VR等领域。未来工作可进一步优化几何估计或扩展到更复杂的场景。",
      "tags": [
        "Gaussian Splatting",
        "Diffusion Models",
        "3D Scene Reconstruction",
        "Depth Estimation",
        "Multi-view Consistency"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:26.470484Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.06139",
    "title": "Deforming Videos to Masks: Flow Matching for Referring Video Segmentation",
    "authors": [
      "Zanyi Wang",
      "Dengyang Jiang",
      "Liuzhuozheng Li",
      "Sizhe Dang",
      "Chengzu Li",
      "Harry Yang",
      "Guang Dai",
      "Mengmeng Wang",
      "Jingdong Wang"
    ],
    "abstract": "Referring Video Object Segmentation (RVOS) requires segmenting specific objects in a video guided by a natural language description. The core challenge of RVOS is to anchor abstract linguistic concepts onto a specific set of pixels and continuously segment them through the complex dynamics of a video. Faced with this difficulty, prior work has often decomposed the task into a pragmatic `locate-then-segment' pipeline. However, this cascaded design creates an information bottleneck by simplifying semantics into coarse geometric prompts (e.g, point), and struggles to maintain temporal consistency as the segmenting process is often decoupled from the initial language grounding. To overcome these fundamental limitations, we propose FlowRVS, a novel framework that reconceptualizes RVOS as a conditional continuous flow problem. This allows us to harness the inherent strengths of pretrained T2V models, fine-grained pixel control, text-video semantic alignment, and temporal coherence. Instead of conventional generating from noise to mask or directly predicting mask, we reformulate the task by learning a direct, language-guided deformation from a video's holistic representation to its target mask. Our one-stage, generative approach achieves new state-of-the-art results across all major RVOS benchmarks. Specifically, achieving a J&F of 51.1 in MeViS (+1.6 over prior SOTA) and 73.3 in the zero shot Ref-DAVIS17 (+2.7), demonstrating the significant potential of modeling video understanding tasks as continuous deformation processes.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.06139.pdf",
    "abs_url": "https://arxiv.org/abs/2510.06139",
    "published": "2025-10-07T17:14:10Z",
    "updated": "2026-02-26T09:15:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 FlowRVS 框架，通过将 RVOS 建模为条件连续流问题，实现了一阶段、生成式的语言引导视频分割。",
      "motivation": "RVOS 任务需要根据自然语言描述分割视频中的特定对象，但现有方法常采用‘定位然后分割’的级联设计，将抽象语义简化为点等粗糙几何提示，导致信息瓶颈和时间不一致性，这限制了分割准确性和视频动态处理的效率，因此亟需更集成的方法来改进。",
      "method": "论文提出 FlowRVS，将 RVOS 重新概念化为条件连续流问题，利用预训练文本到视频模型的优势，如细粒度像素控制、文本-视频语义对齐和时间一致性。核心创新在于学习语言引导的变形过程，直接从视频的整体表示变形到目标掩码，实现一阶段生成式分割，避免了传统从噪声生成或直接预测的局限性。",
      "result": "FlowRVS 在所有主要 RVOS 基准测试中实现了新的最先进结果。在 MeViS 数据集上，J&F 分数达到 51.1，比先前最佳方法提升 1.6；在 Ref-DAVIS17 的零样本设置中，J&F 为 73.3，提升 2.7，显著优于现有级联方法，验证了连续变形建模的有效性。",
      "conclusion": "论文的主要贡献是提出 FlowRVS 框架，将 RVOS 重新概念化为条件连续流问题，展示了生成式方法和连续变形在视频理解中的潜力，具有学术价值和实际应用前景，如提升视频分割的准确性和一致性，未来工作可能包括扩展到更复杂场景或集成更多模态信息。",
      "tags": [
        "Referring Video Object Segmentation",
        "Flow Matching",
        "Conditional Continuous Flow",
        "Text-to-Video Models"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:40.599485Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.05725",
    "title": "Improving Discrete Diffusion Unmasking Policies Beyond Explicit Reference Policies",
    "authors": [
      "Chunsan Hong",
      "Seonho An",
      "Min-Soo Kim",
      "Jong Chul Ye"
    ],
    "abstract": "Masked diffusion models (MDMs) have recently emerged as a novel framework for language modeling. MDMs generate sentences by iteratively denoising masked sequences, filling in [MASK] tokens step by step. Although MDMs support any-order sampling, performance is highly sensitive to the choice of which position to unmask next. Prior work typically relies on rule-based schedules (e.g., max-confidence, max-margin), which provide ad hoc improvements. In contrast, we replace these heuristics with a learned scheduler. Specifically, we cast denoising as a KL-regularized Markov decision process (MDP) with an explicit reference policy and optimize a regularized objective that admits policy improvement and convergence guarantees under standard assumptions. We prove that the optimized policy under this framework generates samples that more closely match the data distribution than heuristic schedules. Empirically, across four benchmarks, our learned policy consistently outperforms max-confidence: for example, on SUDOKU, where unmasking order is critical, it yields a 20.1% gain over random and a 11.2% gain over max-confidence. Code is available at https://github.com/chunsanHong/UPO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.05725.pdf",
    "abs_url": "https://arxiv.org/abs/2510.05725",
    "published": "2025-10-07T09:44:24Z",
    "updated": "2026-02-26T06:25:31Z",
    "comment": "Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "本文提出一种学习型调度器，通过KL正则化马尔可夫决策过程优化掩码扩散模型的去掩码策略，显著提升性能。",
      "motivation": "掩码扩散模型在语言建模中通过迭代去噪生成句子，但其性能高度依赖于去掩码顺序的选择。现有方法通常采用基于规则的启发式调度，如最大置信度，这些方法虽然提供临时改进，但缺乏理论保证和系统性优化，导致模型生成质量受限。本研究旨在解决这一不足，通过引入学习型调度器，以更科学的方式优化去掩码策略，从而提高模型的效率和准确性，对改进语言建模的实际应用具有重要意义。",
      "method": "本研究将去噪过程建模为一个带有显式参考策略的KL正则化马尔可夫决策过程，并优化一个正则化目标，该目标在标准假设下允许策略改进和收敛保证。核心创新在于用学习型调度器替换传统的启发式规则，通过学习的方式动态决定每个步骤的去掩码位置。尽管摘要未明确说明具体模型架构，但方法在多个基准数据集上进行测试，包括SUDOKU等任务，以验证其有效性。",
      "result": "实验结果表明，在四个基准测试中，学习型调度器一致优于最大置信度等启发式方法。具体来说，在SUDOKU任务中，该策略比随机策略提升了20.1%的性能，比最大置信度策略提升了11.2%。这些数据充分证明了学习策略在优化去掩码顺序方面的优越性，并通过对比基线方法，显示了其在实际应用中的有效性和可靠性。",
      "conclusion": "本研究的核心贡献是提出并验证了一种基于KL正则化MDP的学习型调度器，用于优化掩码扩散模型的去掩码策略，具有理论保证和实证效果。这不仅提高了语言建模的生成质量，也为相关领域的策略优化方法提供了新思路。摘要未明确提及局限性，未来工作可进一步探索该框架在其他任务中的应用或改进算法效率，以扩大其适用性和影响力。",
      "tags": [
        "Masked Diffusion Models",
        "KL Regularization",
        "Markov Decision Process",
        "Learned Scheduler",
        "Unmasking Policy"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:55.144861Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.05534",
    "title": "Revisiting Self-Play Preference Optimization: On the Role of Prompt Difficulty",
    "authors": [
      "Yao Xiao",
      "Jung-jae Kim",
      "Roy Ka-wei Lee",
      "Lidong Bing"
    ],
    "abstract": "Self-play preference optimization has emerged as a prominent paradigm for aligning large language models (LLMs). It typically involves a language model to generate on-policy responses for prompts and a reward model (RM) to guide the selection of chosen and rejected responses, which can be further trained with direct preference optimization (DPO). However, the role of prompts remains underexplored, despite being a core component in this pipeline. In this work, we investigate how prompts of varying difficulty influence self-play preference optimization. We use the mean reward of   sampled responses of a prompt as a proxy for its difficulty. We first find that difficult prompts exhibit substantially inferior self-play optimization performance compared to easy prompts for language models. Moreover, incorporating difficult prompts into training fails to enhance overall performance and, in fact, leads to slight degradation compared to training on easy prompts alone. Third, there is a clear upward trend in optimization performance as prompt difficulty decreases. We also observe that the performance gap between difficult and easy prompts tends to close as the model capacity increases, suggesting that prompt difficulty interacts with the model capacity. Building on these findings, we explore strategies to mitigate the adversary effect of difficult prompts on final performance. We demonstrate that only training on a small portion (30%) of the easiest prompts improves overall self-play performance on AlpacaEval~2 and Arena-Hard. We also report failed attempts and lessons learned.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.05534.pdf",
    "abs_url": "https://arxiv.org/abs/2510.05534",
    "published": "2025-10-07T02:47:25Z",
    "updated": "2026-02-26T03:59:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究探讨了prompts难度在自玩偏好优化中的影响，并提出仅训练最简单prompts的策略以提升模型对齐性能。",
      "motivation": "自玩偏好优化已成为对齐大型语言模型的主流范式，它通过语言模型生成策略响应，并由奖励模型指导选择，常结合直接偏好优化进行训练。然而，在这一流程中，prompts作为核心组件的角色未被充分探索。现有方法往往忽视prompts的难度差异，可能导致训练效率低下或性能不佳。本研究的动机在于深入探究不同难度prompts对自玩偏好优化性能的影响，以填补这一研究空白，并优化对齐策略。",
      "method": "本研究采用实验分析方法，以平均奖励作为prompts难度的代理指标，系统评估不同难度prompts对自玩偏好优化性能的影响。关键创新在于量化prompts难度并分析其与模型性能的关联。具体地，研究者使用语言模型生成响应，奖励模型评估，并在AlpacaEval~2和Arena-Hard基准上进行测试。基于发现，探索了仅训练部分最简单prompts（如30%）的策略来减轻难prompts的负面影响，提升整体性能。",
      "result": "实验结果表明，难prompts在自玩优化中表现显著较差，且加入训练反而轻微降低整体性能。性能随prompts难度降低而呈上升趋势。此外，模型容量增加时，难易prompts间的性能差距趋于缩小，揭示了难度与模型容量的交互作用。在AlpacaEval~2和Arena-Hard基准上，仅训练一小部分最简单prompts能有效提升性能，但具体数值摘要未明确说明。相比基线方法，该方法在减少训练数据的同时实现性能优化。",
      "conclusion": "本研究的贡献在于揭示了prompts难度在自玩偏好优化中的关键作用，提出了基于难度选择训练数据的高效策略。学术上，为大型语言模型对齐方法提供了新视角，改进了训练过程。实际上，通过优化prompts筛选，可提升模型在实际应用中的性能和效率。研究还报告了失败尝试和教训，暗示未来工作可进一步探索难度定义、模型适应性及扩展基准测试。",
      "tags": [
        "Self-Play Preference Optimization",
        "Large Language Model",
        "Reward Model",
        "Direct Preference Optimization",
        "Prompt Difficulty"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:55.771342Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.04504",
    "title": "Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation",
    "authors": [
      "Zijing Hu",
      "Yunze Tong",
      "Fengda Zhang",
      "Junkun Yuan",
      "Jun Xiao",
      "Kun Kuang"
    ],
    "abstract": "Diffusion models have achieved impressive results in generating high-quality images. Yet, they often struggle to faithfully align the generated images with the input prompts. This limitation is associated with synchronous denoising, where all pixels simultaneously evolve from random noise to clear images. As a result, during generation, the prompt-related regions can only reference the unrelated regions at the same noise level, failing to obtain clear context and ultimately impairing text-to-image alignment. To address this issue, we propose asynchronous diffusion models -- a novel framework that allocates distinct timesteps to different pixels and reformulates the pixel-wise denoising process. By dynamically modulating the timestep schedules of individual pixels, prompt-related regions are denoised more gradually than unrelated regions, thereby allowing them to leverage clearer inter-pixel context. Consequently, these prompt-related regions achieve better alignment in the final images. Extensive experiments demonstrate that our asynchronous diffusion models can significantly improve text-to-image alignment across diverse prompts. The code repository for this work is available at https://github.com/hu-zijing/AsynDM.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.04504.pdf",
    "abs_url": "https://arxiv.org/abs/2510.04504",
    "published": "2025-10-06T05:45:56Z",
    "updated": "2026-02-26T10:10:17Z",
    "comment": "Accepted to ICLR 2026, 25 pages, 13 figures, 6 tables",
    "light_analysis": {
      "overview": "该论文提出异步扩散模型，通过为不同像素分配不同时间步，显著提高文本到图像生成的对齐准确性。",
      "motivation": "扩散模型在图像生成领域取得了高质量成果，但常难以忠实对齐生成的图像与输入文本提示。这一限制源于同步去噪方法，即所有像素同时从噪声演变为清晰图像，导致提示相关区域只能参考相同噪声水平的无关区域，无法获得清晰上下文，损害对齐效果。这一问题的重要性在于文本到图像对齐对实际应用如创意设计和AI辅助工具至关重要，而现有同步方法的不足限制了模型优化。",
      "method": "论文提出异步扩散模型，这是一个新颖框架，通过为不同像素分配异时间步来重新制定像素级去噪过程。关键创新在于动态调制单个像素的时间步调度，使提示相关区域比无关区域更渐进地去噪，从而利用更清晰的像素间上下文信息改进对齐。该方法涉及时间步分配策略和去噪流程优化，但摘要未明确说明具体使用的数据集或模型架构细节。",
      "result": "通过广泛实验，论文表明异步扩散模型能显著改善跨多样提示的文本到图像对齐效果。摘要未提供具体性能指标数据（如准确率提升），但作者强调与同步扩散模型基线相比，该方法在对齐方面有显著提升。实验结果验证了异步方法在增强生成图像与文本提示一致性方面的有效性，为后续研究提供了实证支持。",
      "conclusion": "该论文的主要贡献是引入异步扩散模型，有效解决文本到图像生成中的对齐问题。学术上，它通过创新时间步分配机制推进了扩散模型在生成任务中的应用。实际上，该方法提高了生成图像的质量和忠实度，对创意产业和AI工具具有潜在价值。摘要未明确讨论局限性或未来工作，但推断进一步研究方向可能包括扩展到其他生成任务或优化调度策略。",
      "tags": [
        "Diffusion Models",
        "Text-to-Image Generation",
        "Asynchronous Denoising",
        "Timestep Scheduling",
        "Pixel-wise Denoising"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:59.183710Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.05154",
    "title": "Can AI Truly Represent Your Voice in Deliberations? A Comprehensive Study of Large-Scale Opinion Aggregation with LLMs",
    "authors": [
      "Shenzhe Zhu",
      "Shu Yang",
      "Michiel A. Bakker",
      "Alex Pentland",
      "Jiaxin Pei"
    ],
    "abstract": "Large-scale public deliberations generate thousands of free-form contributions that must be synthesized into representative and neutral summaries for policy use. While LLMs have been shown as a promising tool to generate summaries for large-scale deliberations, they also risk underrepresenting minority perspectives and exhibiting bias with respect to the input order, raising fairness concerns in high-stakes contexts. Studying and fixing these issues requires a comprehensive evaluation at a large scale, yet current practice often relies on LLMs as judges, which show weak alignment with human judgments. To address this, we present DeliberationBank, a large-scale human-grounded dataset with (1) opinion data spanning ten deliberation questions created by 3,000 participants and (2) summary judgment data annotated by 4,500 participants across four dimensions (representativeness, informativeness, neutrality, policy approval). Using these datasets, we train DeliberationJudge, a fine-tuned DeBERTa model that can rate deliberation summaries from individual perspectives. DeliberationJudge is more efficient and more aligned with human judgements compared to a wide range of LLM judges. With DeliberationJudge, we evaluate 18 LLMs and reveal persistent weaknesses in deliberation summarization, especially underrepresentation of minority positions. Our framework provides a scalable and reliable way to evaluate deliberation summarization, helping ensure AI systems are more representative and equitable for policymaking.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.05154.pdf",
    "abs_url": "https://arxiv.org/abs/2510.05154",
    "published": "2025-10-02T17:36:23Z",
    "updated": "2026-02-26T17:20:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出DeliberationBank数据集和DeliberationJudge模型，为评估大语言模型在讨论总结中的代表性和公平性提供了可扩展的可靠框架。",
      "motivation": "在政策制定等高风险场景中，LLMs用于汇总大规模讨论时，可能无法充分代表少数观点并引入偏见，引发公平性担忧。现有评估方法常依赖LLMs作为评委，但摘要指出这些LLM评委与人类判断对齐较弱，难以准确评估总结质量。因此，研究需要基于人类数据的大规模评估来识别和修复这些问题，以确保AI系统能更公正地应用于决策过程。",
      "method": "研究首先构建了DeliberationBank数据集，包括来自3,000参与者针对十个讨论问题的意见数据，以及由4,500参与者标注的总结判断数据，覆盖代表性、信息性、中立性和政策批准四个维度。基于此，训练DeliberationJudge模型，通过微调DeBERTa架构，使其能从个体视角评估讨论总结质量。关键创新在于数据集的大规模和人类标注，以及模型的高效评估能力，避免了传统LLM评委的对齐不足问题。",
      "result": "DeliberationJudge模型在评估效率和对齐人类判断方面优于广泛的LLM评委，尽管摘要未提供具体性能指标。使用该模型评估18个LLMs后，发现它们在讨论总结中普遍存在弱点，尤其是对少数观点的代表不足。这表明当前LLMs在公平性方面仍有改进空间，而DeliberationJudge提供了一个可靠的基准，用于大规模评估和对比不同模型的总结能力。",
      "conclusion": "本研究通过DeliberationBank和DeliberationJudge，建立了一个可扩展且可靠的评估框架，能系统评估LLMs在讨论总结中的代表性和公平性。这有助于识别偏见问题，促进AI系统在政策制定等应用中更加公正。学术价值在于提供了基于人类数据的大规模评估方法，实际应用价值在于改善AI工具的可靠性。未来工作可扩展数据集覆盖更多场景或优化模型性能，以进一步提升评估的准确性。",
      "tags": [
        "Large Language Model",
        "DeBERTa",
        "Fine-tuning",
        "Summarization",
        "Human Evaluation"
      ]
    },
    "analyzed_at": "2026-02-27T03:52:58.205656Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.01031",
    "title": "Secure and reversible face anonymization with diffusion models",
    "authors": [
      "Pol Labarbarie",
      "Vincent Itier",
      "William Puech"
    ],
    "abstract": "Face anonymization aims to protect sensitive identity information by altering faces while preserving visual realism and utility for downstream computer vision tasks. Current methods struggle to simultaneously ensure high image quality, strong security guarantees, and controlled reversibility for authorized identity recovery at a later time. To improve the image quality of generated anonymized faces, recent methods have adopted diffusion models. However, these new diffusion-based anonymization methods do not provide a mechanism to restrict de-anonymization to trusted parties, limiting their real-world applicability. In this paper, we present the first diffusion-based framework for secure, reversible face anonymization via secret-key conditioning. Our method injects the secret key directly into the diffusion process, enabling anonymization and authorized face reconstruction while preventing unauthorized de-anonymization. The use of deterministic forward and reverse diffusion steps guarantees exact identity recovery when the correct secret key is available. Experiments on CelebA-HQ and LFW demonstrate that our approach achieves better anonymization and de-anonymization capabilities than prior work. We also show that our method remains robust to incorrect or adversarial key de-anonymization. Our code will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.01031.pdf",
    "abs_url": "https://arxiv.org/abs/2510.01031",
    "published": "2025-10-01T15:37:20Z",
    "updated": "2026-02-26T12:56:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了首个基于扩散模型、通过密钥条件化实现安全可逆人脸匿名化的框架。",
      "motivation": "人脸匿名化旨在保护身份隐私，同时保持图像真实性和下游计算机视觉任务实用性。现有方法在图像质量、安全性和可控可逆性方面难以兼顾，特别是近期基于扩散模型的方法虽提高了质量，但缺乏机制限制去匿名化给可信方，限制了实际应用，因此需要一种能同时确保高质量、强安全且授权可恢复的匿名化技术。",
      "method": "本研究提出一个基于扩散模型的框架，通过密钥条件化实现安全可逆匿名化。核心方法是将秘密密钥直接注入扩散过程，利用条件化控制匿名化和去匿名化，关键创新点在于首次结合密钥机制和确定性前向与反向扩散步骤，确保在正确密钥下能精确恢复原始身份。实验使用CelebA-HQ和LFW数据集，模型基于扩散架构，强调可控的去匿名化能力。",
      "result": "实验在CelebA-HQ和LFW数据集上表明，该方法在匿名化和去匿名化能力上优于先前工作，摘要未明确说明具体数据如准确率提升，但整体表现更优。同时，方法对错误或对抗性密钥的去匿名化攻击保持鲁棒性，增强了安全性和实用性，与基线方法对比显示了改进。",
      "conclusion": "本文的主要贡献是提出了首个结合扩散模型和密钥条件化的安全可逆人脸匿名化框架，学术上创新地解决了匿名化中的安全与可逆性问题，提高了方法的实际应用价值。代码公开可促进进一步研究，未来工作可探索更多安全机制和更广泛的评估场景。",
      "tags": [
        "Diffusion Models",
        "Face Anonymization",
        "Secret-Key Conditioning",
        "Reversible Anonymization",
        "Adversarial Robustness"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:12.443936Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.00922",
    "title": "On Discovering Algorithms for Adversarial Imitation Learning",
    "authors": [
      "Shashank Reddy Chirra",
      "Jayden Teoh",
      "Praveen Paruchuri",
      "Pradeep Varakantham"
    ],
    "abstract": "Adversarial Imitation Learning (AIL) methods, while effective in settings with limited expert demonstrations, are often considered unstable. These approaches typically decompose into two components: Density Ratio (DR) estimation $\\frac{ρ_E}{ρ_π}$, where a discriminator estimates the relative occupancy of state-action pairs under the policy versus the expert; and Reward Assignment (RA), where this ratio is transformed into a reward signal used to train the policy. While significant research has focused on improving density estimation, the role of reward assignment in influencing training dynamics and final policy performance has been largely overlooked. RA functions in AIL are typically derived from divergence minimization objectives, relying heavily on human design and ingenuity. In this work, we take a different approach: we investigate the discovery of data-driven RA functions, i.e, based directly on the performance of the resulting imitation policy. To this end, we leverage an LLM-guided evolutionary framework that efficiently explores the space of RA functions, yielding \\emph{Discovered Adversarial Imitation Learning} (DAIL), the first meta-learnt AIL algorithm. Remarkably, DAIL generalises across unseen environments and policy optimization algorithms, outperforming the current state-of-the-art of \\emph{human-designed} baselines. Finally, we analyse why DAIL leads to more stable training, offering novel insights into the role of RA functions in the stability of AIL. Code is publicly available: https://github.com/shshnkreddy/DAIL.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2510.00922.pdf",
    "abs_url": "https://arxiv.org/abs/2510.00922",
    "published": "2025-10-01T14:02:05Z",
    "updated": "2026-02-26T14:42:44Z",
    "comment": "Accepted at ICLR 2026 (Poster)",
    "light_analysis": {
      "overview": "论文提出了一种数据驱动的奖励分配方法，通过LLM引导的进化框架自动发现奖励函数，实现了更稳定的对抗模仿学习算法DAIL，这是首个元学习的AIL算法。",
      "motivation": "对抗模仿学习（AIL）方法在有限专家演示下虽然有效，但训练过程常不稳定。现有研究主要集中于改进密度比率估计，而奖励分配（RA）作为将密度比转化为奖励信号的关键步骤，其对训练动态和最终策略性能的影响被忽视。RA函数通常源自发散最小化目标，依赖人工设计，缺乏系统性优化，这限制了AIL的性能和泛化能力。因此，本研究旨在探索基于策略性能的数据驱动RA函数，以解决稳定性和依赖人工设计的问题。",
      "method": "本研究提出了发现的对抗模仿学习（DAIL），这是一种元学习的AIL算法。核心方法是利用LLM引导的进化框架，高效探索RA函数空间，直接基于模仿策略的性能优化RA函数。该框架避免了传统发散最小化目标的人工设计，实现了数据驱动的奖励分配。关键创新点在于将元学习应用于AIL，自动发现适应不同环境的RA函数，而不依赖特定模型架构或算法细节，摘要未明确说明具体数据集。",
      "result": "DAIL在多个未见环境和策略优化算法中表现出优异的泛化能力，优于当前最先进的人类设计基线方法。实验结果表明，DAIL不仅提升了模仿策略的性能，还显著增强了训练稳定性，虽然摘要未提供具体数据如准确率提升，但强调了对基线的优势。通过分析，研究揭示了RA函数在AIL稳定性中的关键作用，为后续研究提供了新见解。",
      "conclusion": "本研究的主要贡献是提出DAIL算法，通过数据驱动的奖励分配方法有效解决了AIL中的稳定性问题，首次将元学习框架应用于AIL，具有重要的学术价值。在实际应用上，DAIL能泛化到不同场景，减少对人工设计的依赖，推动模仿学习的发展。未来工作可探索更广泛的算法空间和进一步优化进化框架，摘要未明确说明局限性。",
      "tags": [
        "Adversarial Imitation Learning",
        "Reward Assignment",
        "Meta-Learning",
        "Evolutionary Algorithm",
        "Large Language Model"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:22.088337Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.26454",
    "title": "Multi-View Camera System for Variant-Aware Autonomous Vehicle Inspection and Defect Detection",
    "authors": [
      "Yash Kulkarni",
      "Raman Jha",
      "Renu Kachhoria"
    ],
    "abstract": "Ensuring that every vehicle leaving a modern production line is built to the correct \\emph{variant} specification and is free from visible defects is an increasingly complex challenge. We present the \\textbf{Automated Vehicle Inspection (AVI)} platform, an end-to-end, \\emph{multi-view} perception system that couples deep-learning detectors with a semantic rule engine to deliver \\emph{variant-aware} quality control in real time. Eleven synchronized cameras capture a full 360° sweep of each vehicle; task-specific views are then routed to specialised modules: YOLOv8 for part detection, EfficientNet for ICE/EV classification, Gemini-1.5 Flash for mascot OCR, and YOLOv8-Seg for scratch-and-dent segmentation. A view-aware fusion layer standardises evidence, while a VIN-conditioned rule engine compares detected features against the expected manifest, producing an interpretable pass/fail report in \\(\\approx\\! 300\\,\\text{ms}\\). On a mixed data set of Original Equipment Manufacturer(OEM) vehicle data sets of four distinct models plus public scratch/dent images, AVI achieves \\textbf{ 93 \\%} verification accuracy, \\textbf{86 \\%} defect-detection recall, and sustains \\(\\mathbf{3.3}\\) vehicles/min, surpassing single-view or no segmentation baselines by large margins. To our knowledge, this is the first publicly reported system that unifies multi-camera feature validation with defect detection in a deployable automotive setting in industry.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.26454.pdf",
    "abs_url": "https://arxiv.org/abs/2509.26454",
    "published": "2025-09-30T16:08:59Z",
    "updated": "2026-02-26T07:39:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了首个端到端多视图系统，结合深度学习和语义规则引擎，实现实时车辆变体验证与缺陷检测。",
      "motivation": "随着汽车生产变体多样化，确保每辆车离开生产线时符合规格且无可见缺陷的挑战日益复杂。现有方法如单视图检测系统可能无法全面覆盖车辆外观，导致准确率低和缺陷遗漏，影响质量控制效率。本研究旨在解决实时自动化检验的不足，提供高效全面的解决方案，以提升生产线的可靠性和准确性。",
      "method": "AVI平台采用11个同步摄像头捕获车辆360°图像，将任务特定视图路由到专门模块：YOLOv8用于部件检测，EfficientNet用于ICE/EV分类，Gemini-1.5 Flash进行标识OCR，YOLOv8-Seg分割划痕和凹陷。通过视图感知融合层标准化证据，结合VIN条件规则引擎比较检测特征与预期清单，在约300毫秒内生成可解释报告。数据集包含OEM车辆四种模型和公开图像，支持多任务处理。",
      "result": "在混合数据集（四种车型OEM数据加公开图像）上，AVI平台达到93%的变体验证准确率和86%的缺陷检测召回率，处理速度为3.3辆/分钟。与单视图或无分割基线相比，性能大幅超越，证实了多视图和分割方法的优越性，为工业部署提供了高效可靠的性能指标。",
      "conclusion": "本研究贡献了首个公开报告的统一多摄像头特征验证与缺陷检测系统，在工业可部署环境中展示了结合深度学习和规则引擎的有效性。不仅提高了车辆检验的准确性和效率，还为自动化质量控制提供了新思路。未来工作可扩展至更多车型或优化算法，以进一步提升系统鲁棒性和应用范围。",
      "tags": [
        "Multi-View Camera System",
        "YOLOv8",
        "EfficientNet",
        "Semantic Rule Engine",
        "Defect Detection"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:36.568672Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.26238",
    "title": "Beyond Linear Probes: Dynamic Safety Monitoring for Language Models",
    "authors": [
      "James Oldfield",
      "Philip Torr",
      "Ioannis Patras",
      "Adel Bibi",
      "Fazl Barez"
    ],
    "abstract": "Monitoring large language models' (LLMs) activations is an effective way to detect harmful requests before they lead to unsafe outputs. However, traditional safety monitors often require the same amount of compute for every query. This creates a trade-off: expensive monitors waste resources on easy inputs, while cheap ones risk missing subtle cases. We argue that safety monitors should be flexible--costs should rise only when inputs are difficult to assess, or when more compute is available. To achieve this, we introduce Truncated Polynomial Classifiers (TPCs), a natural extension of linear probes for dynamic activation monitoring. Our key insight is that polynomials can be trained and evaluated progressively, term-by-term. At test-time, one can early-stop for lightweight monitoring, or use more terms for stronger guardrails when needed. TPCs provide two modes of use. First, as a safety dial: by evaluating more terms, developers and regulators can \"buy\" stronger guardrails from the same model. Second, as an adaptive cascade: clear cases exit early after low-order checks, and higher-order guardrails are evaluated only for ambiguous inputs, reducing overall monitoring costs. On two large-scale safety datasets (WildGuardMix and BeaverTails), for 4 models with up to 30B parameters, we show that TPCs compete with or outperform MLP-based probe baselines of the same size, all the while being more interpretable than their black-box counterparts. Our code is available at http://github.com/james-oldfield/tpc.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.26238.pdf",
    "abs_url": "https://arxiv.org/abs/2509.26238",
    "published": "2025-09-30T13:32:59Z",
    "updated": "2026-02-26T12:49:39Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "论文引入截断多项式分类器（TPCs）实现大型语言模型的动态安全监控，通过渐进式评估在监控成本与效果间取得平衡。",
      "motivation": "监控大型语言模型（LLMs）的激活以检测有害请求是确保安全输出的关键，但传统方法如线性探针需要固定计算成本，在处理简单输入时浪费资源，或在评估复杂输入时遗漏风险，导致效率与安全性之间的权衡。这一问题限制了实际部署的实用性，因此需要灵活的监控机制，使成本能随输入难度和资源可用性动态调整，以优化安全监控效果。",
      "method": "论文提出截断多项式分类器（TPCs），作为线性探针的动态扩展，用于监控LLMs的激活。TPCs基于多项式函数，支持渐进式训练和评估，允许在测试时按项（term-by-term）进行，实现早期停止以轻量监控或扩展评估以增强护栏。提供两种应用模式：作为安全拨盘，开发者通过增加项数来强化护栏；作为自适应级联，明确输入通过低阶检查后早期退出，模糊输入触发高阶检查，减少总体监控成本。实验在WildGuardMix和BeaverTails数据集上进行，覆盖多达30B参数的模型。",
      "result": "在WildGuardMix和BeaverTails两个大规模安全数据集上，针对最多30B参数的四种模型，TPCs展现出与相同规模多层感知机（MLP）探针基线相当或更优的性能，同时更具可解释性。动态评估机制在处理容易输入时降低计算成本，在困难输入时投入更多资源以确保安全，验证了方法在提升监控效率和效果方面的优势。摘要未明确说明具体性能指标如准确率，但强调TPCs在竞争基准中的表现。",
      "conclusion": "本研究主要贡献是开发TPCs，解决了传统安全监控器的效率与安全权衡问题，扩展了线性探针的理论框架。学术上，它为监控方法提供了新思路；实践中，允许灵活调整监控强度，优化资源使用，适用于开发者和监管机构。未来工作可探索TPCs在其他安全任务或更大模型上的应用，以进一步验证其泛化能力和性能提升。",
      "tags": [
        "Large Language Models",
        "Safety Monitoring",
        "Truncated Polynomial Classifiers",
        "Adaptive Monitoring",
        "Progressive Evaluation"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:58.732655Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.24597",
    "title": "Inducing Dyslexia in Vision Language Models",
    "authors": [
      "Melika Honarmand",
      "Ayati Sharma",
      "Badr AlKhamissi",
      "Johannes Mehrer",
      "Martin Schrimpf"
    ],
    "abstract": "Dyslexia, a neurodevelopmental disorder characterized by persistent reading difficulties, is often linked to reduced activity of the visual word form area (VWFA) in the ventral occipito-temporal cortex. Traditional approaches to studying dyslexia, such as behavioral and neuroimaging methods, have provided valuable insights but remain limited in their ability to test causal hypotheses about the underlying mechanisms of reading impairments. In this study, we use large-scale vision-language models (VLMs) to simulate dyslexia by functionally identifying and perturbing artificial analogues of word processing. Using stimuli from cognitive neuroscience, we identify visual-word-form-selective units within VLMs and demonstrate that they predict human VWFA neural responses. Ablating model VWF units leads to selective impairments in reading tasks while general visual and language comprehension abilities remain intact. In particular, the resulting model matches dyslexic humans' phonological deficits without a significant change in orthographic processing, and mirrors dyslexic behavior in font sensitivity. Taken together, our modeling results replicate key characteristics of dyslexia and establish a computational framework for investigating brain disorders.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.24597.pdf",
    "abs_url": "https://arxiv.org/abs/2509.24597",
    "published": "2025-09-29T11:03:16Z",
    "updated": "2026-02-26T15:04:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究使用视觉语言模型模拟阅读障碍，通过扰动单词处理单元建立计算框架研究脑部障碍机制。",
      "motivation": "阅读障碍是一种以持续阅读困难为特征的神经发育障碍，常与视觉单词形式区域活动减少相关。传统研究方法如行为学和神经成像虽提供宝贵见解，但在测试阅读障碍潜在机制的因果假设方面存在局限，因为它们无法进行因果实验。本研究旨在利用计算模型克服这些限制，探索阅读障碍的成因，以加深对神经机制的理解并为干预提供新思路。",
      "method": "本研究采用大规模视觉语言模型作为计算平台，基于认知神经科学的刺激材料识别模型中模拟视觉单词形式选择性处理的人工单元。通过消融这些单元来扰动单词处理能力，关键创新点在于将模型单元与人类神经数据（如VWFA响应）对应，验证其作为脑部障碍模拟工具的有效性。摘要未明确说明具体模型架构或数据集细节。",
      "result": "消融模型中的视觉单词形式单元后，阅读任务性能出现选择性障碍，而一般视觉和语言理解能力保持正常。模型成功复制了阅读障碍患者的特征，如音韵处理缺陷且正字法处理未显著改变，并模拟了字体敏感性行为。这些结果与人类阅读障碍数据一致，验证了模型在模拟脑部障碍方面的有效性，摘要未提供具体性能指标对比。",
      "conclusion": "本研究的主要贡献在于利用视觉语言模型成功模拟阅读障碍，复制其关键行为特征，并建立计算框架用于研究脑部障碍。这具有重要的学术价值，为理解阅读障碍机制提供了新工具，可能推广到其他神经发育障碍的研究中。未来工作可扩展此框架到更广泛的脑部障碍模拟，并探索实际应用潜力。",
      "tags": [
        "Vision-Language Models",
        "Dyslexia",
        "Ablation",
        "Cognitive Neuroscience",
        "Neural Responses"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:51.400785Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.24421",
    "title": "Proxy-GS: Unified Occlusion Priors for Training and Inference in Structured 3D Gaussian Splatting",
    "authors": [
      "Yuanyuan Gao",
      "Yuning Gong",
      "Yifei Liu",
      "Li Jingfeng",
      "Dingwen Zhang",
      "Yanci Zhang",
      "Dan Xu",
      "Xiao Sun",
      "Zhihang Zhong"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has emerged as an efficient approach for achieving photorealistic rendering. Recent MLP-based variants further improve visual fidelity but introduce substantial decoding overhead during rendering. To alleviate computation cost, several pruning strategies and level-of-detail (LOD) techniques have been introduced, aiming to effectively reduce the number of Gaussian primitives in large-scale scenes. However, our analysis reveals that significant redundancy still remains due to the lack of occlusion awareness. In this work, we propose Proxy-GS, a novel pipeline that exploits a proxy to introduce Gaussian occlusion awareness from any view. At the core of our approach is a fast proxy system capable of producing precise occlusion depth maps at a resolution of 1000x1000 under 1ms. This proxy serves two roles: first, it guides the culling of anchors and Gaussians to accelerate rendering speed. Second, it guides the densification towards surfaces during training, avoiding inconsistencies in occluded regions, and improving the rendering quality. In heavily occluded scenarios, such as the MatrixCity Streets dataset, Proxy-GS not only equips MLP-based Gaussian splatting with stronger rendering capability but also achieves faster rendering speed. Specifically, it achieves more than 2.5x speedup over Octree-GS, and consistently delivers substantially higher rendering quality. Code will be public upon acceptance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.24421.pdf",
    "abs_url": "https://arxiv.org/abs/2509.24421",
    "published": "2025-09-29T08:10:07Z",
    "updated": "2026-02-26T15:33:44Z",
    "comment": "Project page: https://gyy456.github.io/Proxy-GS",
    "light_analysis": {
      "overview": "提出 Proxy-GS，通过代理系统引入遮挡感知，优化 3D Gaussian Splatting 的训练与推理，提升渲染速度和视觉质量。",
      "motivation": "3D Gaussian Splatting 是高效的光真实渲染方法，但其 MLP 变体在提升视觉保真度时引入了较大计算开销。现有优化策略如剪枝和 LOD 试图减少高斯原语数量，但由于缺乏遮挡感知，在大规模场景中仍存在冗余，导致渲染效率低下和潜在视觉不一致问题。这限制了实时渲染应用，尤其是在复杂遮挡场景如城市街道中，因此需开发更高效的遮挡处理方法。",
      "method": "Proxy-GS 的核心是一个快速代理系统，能在 1 毫秒内生成 1000x1000 分辨率的精确遮挡深度图，统一遮挡先验用于训练和推理。该方法在训练阶段引导高斯向表面密集化，避免遮挡区域的不一致，提高渲染质量；在推理阶段引导锚点和高斯剔除，加速渲染速度。基于 3D Gaussian Splatting 框架，Proxy-GS 利用代理作为额外输入，优化 MLP-based 变体的处理流程，无需修改基础模型架构，适用于如 MatrixCity Streets 等大规模数据集。",
      "result": "在严重遮挡场景如 MatrixCity Streets 数据集中，Proxy-GS 显著提升了性能。与基线方法 Octree-GS 相比，Proxy-GS 实现了超过 2.5 倍的渲染速度提升，同时渲染质量保持更高水平。实验表明，该方法不仅增强了 MLP-based 3DGS 的渲染能力，还降低了计算开销，在复杂遮挡环境下保持视觉一致性和效率，验证了代理系统在优化遮挡处理方面的有效性。",
      "conclusion": "Proxy-GS 的主要贡献是通过代理系统统一遮挡先验，显著提高 3D Gaussian Splatting 的渲染效率和视觉质量。其学术价值在于提出了一种新颖的遮挡感知方法，扩展了 3DGS 的应用潜力；实际应用中，可用于大规模场景的实时渲染，如自动驾驶和虚拟现实。局限性或未来工作摘要未明确说明，但可能涉及扩展到更复杂场景或集成其他优化技术。",
      "tags": [
        "3D Gaussian Splatting",
        "Occlusion Awareness",
        "Proxy System",
        "Rendering Acceleration",
        "Depth Maps"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:36.859104Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.24276",
    "title": "G-reasoner: Foundation Models for Unified Reasoning over Graph-structured Knowledge",
    "authors": [
      "Linhao Luo",
      "Zicheng Zhao",
      "Junnan Liu",
      "Zhangchi Qiu",
      "Junnan Dong",
      "Serge Panev",
      "Chen Gong",
      "Thuy-Trang Vu",
      "Gholamreza Haffari",
      "Dinh Phung",
      "Alan Wee-Chung Liew",
      "Shirui Pan"
    ],
    "abstract": "Large language models (LLMs) excel at complex reasoning but remain limited by static and incomplete parametric knowledge. Retrieval-augmented generation (RAG) mitigates this by incorporating external knowledge, yet existing RAGs struggle with knowledge-intensive tasks due to fragmented information and weak modeling of knowledge structure. Graphs offer a natural way to model relationships within knowledge, but LLMs are inherently unstructured and cannot effectively reason over graph-structured data. Recent graph-enhanced RAG (GraphRAG) attempts to bridge this gap by constructing tailored graphs and enabling LLMs to reason on them. However, these methods often depend on ad-hoc graph designs, heuristic search, or costly agent pipelines, which hinder scalability and generalization. To address these challenges, we present G-reasoner, a unified framework that integrates graph and language foundation models for scalable reasoning over diverse graph-structured knowledge. Central to our approach is QuadGraph, a standardized four-layer abstraction that unifies heterogeneous knowledge sources into a common graph representation. Building on this, we introduce a 34M-parameter graph foundation model (GFM) that jointly captures graph topology and textual semantics, and is integrated with LLMs to enhance reasoning in downstream applications. To ensure scalability and efficiency, mixed-precision training and distributed message-passing are implemented to scale GFM with more GPUs. Extensive experiments on six benchmarks show that G-reasoner consistently outperforms state-of-the-art baselines, significantly enhances LLM reasoning, and achieves strong efficiency and cross-graph generalization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.24276.pdf",
    "abs_url": "https://arxiv.org/abs/2509.24276",
    "published": "2025-09-29T04:38:12Z",
    "updated": "2026-02-26T11:04:20Z",
    "comment": "Accepted by ICLR 2026",
    "light_analysis": {
      "overview": "本文提出G-reasoner框架，通过统一图形和语言基础模型，实现可扩展的图形知识推理，解决了现有方法在知识结构建模上的不足。",
      "motivation": "大型语言模型在复杂推理中受限于静态和不完整的参数化知识，检索增强生成方法因信息碎片化和知识结构建模弱而难以处理知识密集型任务。图形是建模知识关系的自然方式，但语言模型无法有效推理图形数据，而现有图形增强检索生成方法依赖自设计图形、启发式搜索或昂贵代理，导致可扩展性和泛化性问题。本研究旨在克服这些局限，提升知识推理的效率和普适性。",
      "method": "本研究提出G-reasoner框架，核心创新是QuadGraph四层抽象，将异构知识源统一为共同图形表示，并构建一个34M参数的图形基础模型（GFM），联合捕获图形拓扑和文本语义。该模型与大型语言模型集成，以增强下游应用的推理能力。为确保可扩展性，采用混合精度训练和分布式消息传递技术，利用多GPU实现高效扩展。",
      "result": "在六个基准测试中，G-reasoner一致优于最先进的基线方法，显著增强了大型语言模型的推理能力。实验显示，该方法实现了强效的效率和跨图形泛化，具体数据摘要未明确说明，但表明相对于现有方法在性能上有显著提升。",
      "conclusion": "G-reasoner的主要贡献是提供了一个统一框架，整合图形和语言基础模型，解决了知识密集型推理中的可扩展和泛化问题。其学术价值在于推动图形与自然语言处理的融合，实际应用价值包括改进知识检索和推理系统。未来工作可能涉及扩展到更广泛的领域或进一步优化模型效率，摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Retrieval-Augmented Generation",
        "Graph Foundation Model",
        "QuadGraph",
        "Mixed-Precision Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:53:49.394510Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22935",
    "title": "Compute-Optimal Quantization-Aware Training",
    "authors": [
      "Aleksandr Dremov",
      "David Grangier",
      "Angelos Katharopoulos",
      "Awni Hannun"
    ],
    "abstract": "Quantization-aware training (QAT) is a leading technique for improving the accuracy of quantized neural networks. Previous work has shown that decomposing training into a full-precision (FP) phase followed by a QAT phase yields superior accuracy compared to QAT alone. However, the optimal allocation of compute between the FP and QAT phases remains unclear. We conduct extensive experiments with various compute budgets, QAT bit widths, and model sizes from 86.0M to 2.2B to investigate how different QAT durations impact final performance. We demonstrate that, contrary to previous findings, the loss-optimal ratio of QAT to FP training increases with the total amount of compute. Moreover, the optimal fraction can be accurately predicted for a wide range of model sizes and quantization widths using the tokens-per-parameter-byte statistic. From experimental data, we derive a loss scaling law that predicts both optimal QAT ratios and final model performance across different QAT/FP compute allocation strategies and QAT bit widths. We use the scaling law to make further predictions, which we verify experimentally, including which QAT bit width is optimal under a given memory constraint and how QAT accuracy with different bit widths compares to full-precision model accuracy. Additionally, we propose a novel cooldown and QAT fusion approach that performs learning rate decay jointly with quantization-aware training, eliminating redundant full-precision model updates and achieving significant compute savings. These findings provide practical insights into efficient QAT planning and enable the training of higher-quality quantized models with the same compute budget.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.22935.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22935",
    "published": "2025-09-26T21:09:54Z",
    "updated": "2026-02-26T13:04:00Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "本研究提出了一种计算最优的量化感知训练方法，通过实验揭示了QAT与全精度训练的最优比例规律，并推导了预测模型性能的缩放定律。",
      "motivation": "量化感知训练（QAT）是提升量化神经网络精度的关键技术，在资源受限场景中尤为重要。前人研究表明，将训练分为全精度（FP）阶段和QAT阶段能获得比单独QAT更高的准确性，但FP和QAT阶段之间的计算资源最优分配一直不明确，这限制了在固定计算预算下高效训练高质量量化模型的能力。因此，本研究旨在探索如何最佳分配计算资源，以最大化量化模型的性能，解决现有方法在计算效率方面的不足。",
      "method": "论文进行了广泛的实验，涉及不同计算预算、QAT位宽（从低到高）和模型大小（参数范围从86.0M到2.2B）。核心方法包括：通过实验分析QAT持续时间对最终性能的影响；发现QAT与FP训练的最优比例随总计算量增加而增加；使用tokens-per-parameter-byte统计量来预测这一最优比例；推导了一个损失缩放定律，以预测不同QAT/FP分配策略和QAT位宽下的模型性能；并提出新的cooldown和QAT融合方法，在学习率衰减的同时执行QAT，减少冗余的全精度模型更新以节省计算资源。",
      "result": "实验结果表明，QAT与FP训练的最优比例确实随着总计算量的增加而上升，并且使用tokens-per-parameter-byte统计量可以准确预测这一比例。推导的损失缩放定律能有效预测不同条件下的最终模型性能，包括最优QAT比例。提出的cooldown和QAT融合方法显著节省了计算资源，使在相同计算预算下训练更高质量的量化模型成为可能，与基线方法相比在效率和准确性上均有提升。例如，该方法验证了在特定内存约束下最优QAT位宽的选择。",
      "conclusion": "本研究的主要贡献在于揭示了量化感知训练中计算资源分配的动态规律，并通过缩放定律和融合方法提供了实用优化方案。学术上，通过实验验证和理论推导，为QAT的理论研究提供了新见解；实际上，帮助研究人员和工程师在有限计算资源下更高效地训练高质量量化模型，推动模型压缩技术在边缘设备等应用中的发展。未来工作可进一步探索更广泛的模型架构和量化场景，以扩展这些发现的适用性。",
      "tags": [
        "Quantization-Aware Training",
        "Full-Precision Training",
        "Scaling Law",
        "Compute Optimization",
        "Model Compression"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:06.957809Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22072",
    "title": "Fine-tuning Done Right in Model Editing",
    "authors": [
      "Wanli Yang",
      "Rui Tang",
      "Hongyu Zang",
      "Du Su",
      "Qi Cao",
      "Jingang Wang",
      "Huawei Shen",
      "Xueqi Cheng",
      "Fei Sun"
    ],
    "abstract": "Fine-tuning, a foundational method for adapting large language models, has long been considered ineffective for model editing. Here, we challenge this belief, arguing that the reported failure arises not from the inherent limitation of fine-tuning itself, but from adapting it to the sequential nature of the editing task, a single-pass depth-first pipeline that optimizes each sample to convergence before moving on. While intuitive, this depth-first pipeline coupled with sample-wise updating over-optimizes each edit and induces interference across edits. Our controlled experiments reveal that simply restoring fine-tuning to the standard breadth-first (i.e., epoch-based) pipeline with mini-batch optimization substantially improves its effectiveness for model editing. Moreover, fine-tuning in editing also suffers from suboptimal tuning parameter locations inherited from prior methods. Through systematic analysis of tuning locations, we derive LocFT-BF, a simple and effective localized editing method built on the restored fine-tuning framework. Extensive experiments across diverse LLMs and datasets demonstrate that LocFT-BF outperforms state-of-the-art methods by large margins. Notably, to our knowledge, it is the first to sustain 100K edits and 72B-parameter models,10 x beyond prior practice, without sacrificing general capabilities. By clarifying a long-standing misconception and introducing a principled localized tuning strategy, we advance fine-tuning from an underestimated baseline to a leading method for model editing, establishing a solid foundation for future research.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.22072.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22072",
    "published": "2025-09-26T08:53:13Z",
    "updated": "2026-02-26T14:54:29Z",
    "comment": "Accepted as a conference paper at ICLR 2026",
    "light_analysis": {
      "overview": "论文通过纠正微调在模型编辑中的误用并提出LocFT-BF方法，将微调从低估基线提升为高效编辑大语言模型的领先技术。",
      "motivation": "微调作为适应大语言模型的基础方法，在模型编辑任务中长期被认为无效，导致现有方法采用深度优先流水线，逐个样本优化到收敛，引发编辑间干扰和过优化问题。这一问题限制了微调在模型编辑中的可扩展性和效果，阻碍了大语言模型的持续学习和知识更新。研究动机是挑战这一误解，改进调优策略以提升编辑性能，填补现有方法的不足。",
      "method": "论文提出首先将微调恢复为标准广度优先流水线，结合小批量优化以减少编辑干扰和过优化。进一步通过系统分析调参位置，开发了LocFT-BF方法，这是一种局部化编辑技术，基于恢复的微调框架，专注于优化模型特定参数以提高编辑精度。关键创新点包括纠正微调适应顺序编辑的误用，并引入局部化调优策略。实验使用了多种大语言模型和多样化数据集，以验证方法的泛化能力。",
      "result": "LocFT-BF在广泛实验中表现出色，优于现有最先进方法，具体表现为编辑效果的显著提升和可扩展性的增强。它首次实现维持100,000次编辑和72B参数模型的能力，扩展范围是之前实践的10倍，且不牺牲模型的一般能力。与基线方法对比，LocFT-BF在编辑准确性和效率上取得大优势，摘要未明确具体数值指标如准确率，但强调了扩展能力的突破性。",
      "conclusion": "论文的主要贡献是澄清了微调在模型编辑中长期被误解的问题，并提出LocFT-BF方法，确立微调作为领先编辑技术。这为未来研究奠定了坚实基础，促进了大语言模型的可编辑性和适应性发展，具有重要学术价值和实际应用价值，特别是在模型更新和知识维护方面。潜在局限性可能包括对不同模型架构的泛化能力，未来工作可优化调优策略并探索更广泛的应用领域。",
      "tags": [
        "Fine-tuning",
        "Model Editing",
        "Breadth-first Optimization",
        "Mini-batch Training",
        "Localized Parameter Tuning"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:18.779007Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21965",
    "title": "PartSAM: A Scalable Promptable Part Segmentation Model Trained on Native 3D Data",
    "authors": [
      "Zhe Zhu",
      "Le Wan",
      "Rui Xu",
      "Yiheng Zhang",
      "Honghua Chen",
      "Zhiyang Dou",
      "Cheng Lin",
      "Yuan Liu",
      "Mingqiang Wei"
    ],
    "abstract": "Segmenting 3D objects into parts is a long-standing challenge in computer vision. To overcome taxonomy constraints and generalize to unseen 3D objects, recent works turn to open-world part segmentation. These approaches typically transfer supervision from 2D foundation models, such as SAM, by lifting multi-view masks into 3D. However, this indirect paradigm fails to capture intrinsic geometry, leading to surface-only understanding, uncontrolled decomposition, and limited generalization. We present PartSAM, the first promptable part segmentation model trained natively on large-scale 3D data. Following the design philosophy of SAM, PartSAM employs an encoder-decoder architecture in which a triplane-based dual-branch encoder produces spatially structured tokens for scalable part-aware representation learning. To enable large-scale supervision, we further introduce a model-in-the-loop annotation pipeline that curates over five million 3D shape-part pairs from online assets, providing diverse and fine-grained labels. This combination of scalable architecture and diverse 3D data yields emergent open-world capabilities: with a single prompt, PartSAM achieves highly accurate part identification, and in a Segment-Every-Part mode, it automatically decomposes shapes into both surface and internal structures. Extensive experiments show that PartSAM outperforms state-of-the-art methods by large margins across multiple benchmarks, marking a decisive step toward foundation models for 3D part understanding.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.21965.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21965",
    "published": "2025-09-26T06:52:35Z",
    "updated": "2026-02-26T07:13:04Z",
    "comment": "ICLR 2026. Project Page: https://czvvd.github.io/PartSAMPage/",
    "light_analysis": {
      "overview": "PartSAM是首个在大型3D数据上本地训练的可提示部分分割模型，通过可扩展架构和多样数据实现开放世界部分理解。",
      "motivation": "本研究旨在解决3D对象部分分割的开放世界挑战，该问题在计算机视觉中长期存在，对机器人学和虚拟现实等应用至关重要。现有方法通常通过从2D基础模型（如SAM）转移监督，间接提升多视角掩模到3D，但这无法捕获对象的固有几何结构，导致仅表面理解、不可控分解和泛化能力有限。因此，需要一种直接在大型3D数据上训练的模型，以克服分类学约束并更好地泛化到未见过的3D对象。",
      "method": "PartSAM采用编码器-解码器架构，其中基于triplane的双分支编码器生成空间结构化令牌，用于可扩展的部分感知表示学习。关键创新点包括使用triplane表示来捕获3D几何特征和双分支设计增强表示能力。为了支持大规模监督，作者开发了一个模型在环标注管道，从在线资产中整理超过五百万个3D形状-部分对，提供多样化和细粒度的训练标签，从而结合可扩展架构与丰富数据。",
      "result": "实验结果显示，PartSAM在多个基准测试中大幅度超越现有最佳方法。摘要未明确说明具体的性能指标（如准确率提升），但证明了其在开放世界部分分割任务上的优越表现，包括通过单个提示实现高度准确的部分识别，以及在Segment-Every-Part模式下自动分解形状为表面和内部结构的能力，显著优于基线方法。",
      "conclusion": "PartSAM的主要贡献在于提出了首个在大型3D数据上本地训练的可提示部分分割模型，结合可扩展架构和多样数据，为3D部分理解基础模型的发展提供了关键步骤。该研究具有重要学术价值，推动了计算机视觉领域的创新，并在机器人操作、虚拟现实等领域具有广泛应用潜力。摘要未明确说明局限性或未来工作方向，但该模型可能为进一步研究大规模3D数据标注和模型泛化能力奠定基础。",
      "tags": [
        "Promptable Segmentation",
        "Triplane Representation",
        "Model-in-the-loop Annotation",
        "3D Part Segmentation",
        "Large-scale 3D Data"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:36.304971Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21936",
    "title": "Statistical Advantage of Softmax Attention: Insights from Single-Location Regression",
    "authors": [
      "O. Duranthon",
      "P. Marion",
      "C. Boyer",
      "B. Loureiro",
      "L. Zdeborová"
    ],
    "abstract": "Large language models rely on attention mechanisms with a softmax activation. Yet the dominance of softmax over alternatives (e.g., component-wise or linear) remains poorly understood, and many theoretical works have focused on the easier-to-analyze linearized attention. In this work, we address this gap through a principled study of the single-location regression task, where the output depends on a linear transformation of a single input token at a random location. Building on ideas from statistical physics, we develop an analysis of attention-based predictors in the high-dimensional limit, where generalization performance is captured by a small set of order parameters. At the population level, we show that softmax achieves the Bayes risk, whereas linear attention fundamentally falls short. We then examine other activation functions to identify which properties are necessary for optimal performance. Finally, we analyze the finite-sample regime: we provide an asymptotic characterization of the test error and show that, while softmax is no longer Bayes-optimal, it consistently outperforms linear attention. We discuss the connection with optimization by gradient-based algorithms.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.21936.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21936",
    "published": "2025-09-26T06:21:30Z",
    "updated": "2026-02-26T09:23:45Z",
    "comment": "Accepted at the ICLR 2026",
    "light_analysis": {
      "overview": "论文通过单位置回归任务揭示了softmax注意力在高维极限下的统计优势，证明其优于线性注意力。",
      "motivation": "大语言模型广泛采用softmax注意力机制，但其相对于线性等替代方案的理论优势尚不明确。现有研究多集中于易于分析的线性化注意力，缺乏对softmax优势的深入理解，这限制了模型优化。本研究旨在填补这一空白，通过系统分析解释softmax为何在注意力机制中占主导地位，从而推动理论发展和实际应用，提升模型性能。",
      "method": "研究采用单位置回归任务作为分析框架，其中输出依赖于单个输入令牌的线性变换。基于统计物理学的思想，在无限维或高维极限下分析基于注意力的预测器，利用序参数来捕捉泛化性能。关键创新在于将复杂的高维问题简化为可管理的数学形式，从而评估不同激活函数的性能，未指定具体数据集，而是通过理论推导和渐近分析得出结论。",
      "result": "在无限样本的总体水平上，softmax注意力能够达到贝叶斯风险，即最优性能，而线性注意力则根本不足。在有限样本机制下，通过渐近特征分析显示，虽然softmax不再是贝叶斯最优，但它始终优于线性注意力，表现出更低的测试误差。这些结果通过理论证明支持，表明softmax在统计上具有显著优势，为实际应用提供了理论基础。",
      "conclusion": "本研究的主要贡献是揭示了softmax注意力的统计优势，通过单位置回归任务证明了其在高维极限和有限样本下的优越性。学术上，这深化了对注意力机制理论的理解；实际上，为模型设计和激活函数选择提供了指导。局限性在于任务简化，未来工作可扩展到更复杂的多位置任务，并进一步探索与其他优化算法的连接。",
      "tags": [
        "Softmax Attention",
        "Linear Attention",
        "Single-Location Regression",
        "High-Dimensional Limit",
        "Statistical Physics"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:23.035996Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21725",
    "title": "Information-Theoretic Bayesian Optimization for Bilevel Optimization Problems",
    "authors": [
      "Takuya Kanayama",
      "Yuki Ito",
      "Tomoyuki Tamura",
      "Masayuki Karasuyama"
    ],
    "abstract": "A bilevel optimization problem consists of two optimization problems nested as an upper- and a lower-level problem, in which the optimality of the lower-level problem defines a constraint for the upper-level problem. This paper considers Bayesian optimization (BO) for the case that both the upper- and lower-levels involve expensive black-box functions. Because of its nested structure, bilevel optimization has a complex problem definition, by which bilevel BO has not been widely studied compared with other standard extensions of BO such as multi-objective or constraint problems. We propose an information-theoretic approach that considers the information gain of both the upper- and lower-optimal solutions and values. This enables us to define a unified criterion that measures the benefit for both level problems, simultaneously. Further, we also show a practical lower bound based approach to evaluating the information gain. We empirically demonstrate the effectiveness of our proposed method through several benchmark datasets.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.21725.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21725",
    "published": "2025-09-26T00:52:14Z",
    "updated": "2026-02-26T12:32:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于信息论的贝叶斯优化方法，用于解决上下层均涉及昂贵黑箱函数的双级优化问题。",
      "motivation": "双级优化问题由嵌套的上下两层优化组成，其最优解定义约束了上层问题。由于上下层函数都是昂贵的黑箱函数，优化过程计算复杂且效率低，导致双级贝叶斯优化研究不足。相比之下，贝叶斯优化的其他扩展如多目标或约束问题已得到广泛探索，但双级结构增加了定义的复杂性，急需开发新的方法来同时处理两个层面的优化挑战。",
      "method": "论文提出了一种信息论方法，通过考虑上下层最优解和值的信息增益，定义一个统一准则来同时测量两个问题的收益。关键创新在于统一评估信息增益，并使用基于下界的实践方法来计算这一增益，避免了直接计算的复杂性。该方法结合贝叶斯优化框架，处理黑箱函数，并利用信息理论指导优化过程，提高了搜索效率。",
      "result": "通过多个基准数据集进行实证实验，证明了所提方法的有效性。尽管摘要未明确说明具体性能指标如准确率或效率提升，但结果表明该方法在双级优化问题上表现良好，与现有基线方法相比有改进，并验证了信息增益准则在实际应用中的潜力。",
      "conclusion": "该研究的主要贡献是提出了一个统一的信息增益准则，用于贝叶斯优化中的双级问题，简化了优化过程并提高了处理昂贵黑箱函数的效率。这在学术上丰富了优化方法的理论框架，实际中可用于工程和科学领域的复杂问题优化，未来工作可扩展到更复杂的优化场景或结合其他先进技术。",
      "tags": [
        "Bayesian Optimization",
        "Bilevel Optimization",
        "Information Theory",
        "Black-Box Functions",
        "Information Gain"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:18.802021Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21294",
    "title": "UPDESH: Synthesizing Grounded Instruction Tuning Data for 13 Indic Languages",
    "authors": [
      "Pranjal A. Chitale",
      "Varun Gumma",
      "Sanchit Ahuja",
      "Prashant Kodali",
      "Manan Uppadhyay",
      "Deepthi Sudharsan",
      "Sunayana Sitaram"
    ],
    "abstract": "Developing culturally grounded multilingual AI systems remains challenging, particularly for low-resource languages. While synthetic data offers promise, its effectiveness in multilingual and multicultural contexts is underexplored. We investigate bottom-up synthetic data generation using large open-source LLMs (>= 235B parameters) grounded in language-specific Wikipedia content, complementing dominant top-down translation-based approaches from English. We introduce Updesh, a high-quality large-scale synthetic instruction-following dataset comprising 9.5M data points across 13 Indian languages and English, encompassing diverse reasoning and generative tasks. Comprehensive evaluation using automated metrics and 10K human assessments confirms high data quality. Downstream evaluations performed by fine-tuning models on various datasets and assessing performance across 13 diverse multilingual datasets and model comparative evaluations, demonstrate that models trained on Updesh consistently obtain significant improvements on NLU, NLG evaluations. Finally, through ablation studies and cultural evaluations, we show that context-aware, culturally grounded data generation is essential for effective multilingual AI development.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.21294.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21294",
    "published": "2025-09-25T15:13:00Z",
    "updated": "2026-02-26T14:27:02Z",
    "comment": "Under Review",
    "light_analysis": {
      "overview": "本研究提出Updesh数据集，一个高质量大规模合成指令微调数据集，涵盖13种印度语言，通过自底向上方法基于文化内容生成，有效提升多语言AI性能。",
      "motivation": "开发文化基础的多语言AI系统对低资源语言尤其具有挑战性，现有方法主要依赖从英语的翻译，可能忽略语言特定性和文化背景，导致数据质量不高和模型性能有限。合成数据虽具潜力，但在多语言和多元文化环境下的有效性未被充分探索。因此，研究旨在通过基于语言特定内容的合成数据生成，补充现有方法，解决数据稀缺问题，促进多语言AI的发展。",
      "method": "论文采用大型开源语言模型（参数>=235B）作为基础，基于语言特定的维基百科内容进行自底向上的合成数据生成。核心创新在于提出Updesh数据集，包含13种印度语言和英语的950万个数据点，涵盖多样推理和生成任务。该方法强调文化基础和上下文感知，生成高质量的指令微调数据，补充了主导的翻译方法，并优化了数据生成流程。",
      "result": "通过自动指标和1万次人工评估，确认Updesh数据集具有高质量。在下游评估中，基于该数据集微调的模型在13个多语言数据集的自然语言理解和生成任务上，持续获得显著改进。与基线翻译方法相比，性能提升明显，消融研究进一步验证了文化基础数据生成对多语言AI的有效性至关重要。摘要未明确说明具体准确率数字，但强调了持续改进趋势。",
      "conclusion": "研究的主要贡献是开发了高质量、文化基础的合成指令数据集Updesh，并验证了自底向上生成方法在多语言AI中的优势。这为低资源语言AI系统提供了可靠数据支持，推动了多语言AI的发展，学术上填补了合成数据在多语言背景下的研究空白，应用上可改善实际AI系统性能。未来工作可扩展到更多语言，并探索更高效的数据生成技术。摘要未明确说明局限性，但暗示了进一步优化的方向。",
      "tags": [
        "Synthetic Data Generation",
        "Multilingual AI",
        "Instruction Tuning",
        "Large Language Models",
        "Cultural Grounding"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:28.639226Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21013",
    "title": "Predicting LLM Reasoning Performance with Small Proxy Model",
    "authors": [
      "Woosung Koh",
      "Juyoung Suk",
      "Sungjun Han",
      "Se-Young Yun",
      "Jamin Shin"
    ],
    "abstract": "Given the prohibitive cost of pre-training large language models, it is essential to leverage smaller proxy models to optimize datasets before scaling up. However, this approach becomes challenging for reasoning capabilities, which exhibit emergent behavior that only appear reliably at larger model sizes, often exceeding 7B parameters. To address this, we introduce rBridge, showing that small proxies ($\\leq$1B) can effectively predict large-model reasoning by aligning more closely with (1) the pre-training objective and (2) the target task. rBridge achieves this by weighting negative log-likelihood with task alignment, using reasoning traces from frontier models as gold labels. In our experiments, rBridge (i) reduces dataset ranking costs by over 100x relative to the best baseline, (ii) achieves the strongest correlation across six reasoning benchmarks at 1B to 32B scale, and (iii) zero-shot transfers predictive relationships across pre-training datasets at 1B to 7B scale. These findings indicate that rBridge offers a practical path for exploring reasoning-oriented pre-training at lower cost.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.21013.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21013",
    "published": "2025-09-25T11:20:38Z",
    "updated": "2026-02-26T08:09:24Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "本文提出rBridge方法，利用小代理模型预测大语言模型的推理性能，显著降低优化成本。",
      "motivation": "预训练大语言模型成本高昂，因此常使用小代理模型优化数据集以避免直接实验的开销。然而，推理能力作为一种涌现行为，通常只在参数超过7B的大模型中可靠出现，这使得小模型难以准确预测大模型的推理性能。现有方法在小模型与目标任务对齐方面不足，导致预测效果有限。本研究旨在解决这一挑战，通过改进小代理模型的预测机制，为低成本探索推理导向的预训练提供支持。",
      "method": "本研究引入rBridge方法，核心是通过任务对齐加权负对数似然，使小代理模型（参数≤1B）能更有效地预测大语言模型的推理性能。关键创新点包括：将预训练目标与目标任务紧密结合，并使用前沿模型的推理轨迹作为黄金标签来指导训练。具体技术涉及调整损失函数，以增强小模型对推理能力的捕捉，从而在减少计算成本的同时保持预测准确性。",
      "result": "实验结果显示，rBridge相对于最佳基线方法，将数据集排名成本降低了超过100倍；在1B到32B参数规模的六个推理基准测试中，实现了最强的相关性；此外，在1B到7B规模上，展示了零样本迁移能力，能够跨不同预训练数据集转移预测关系。这些数据验证了rBridge的有效性和实用性。",
      "conclusion": "本研究的主要贡献是提出了rBridge方法，证明小代理模型可以有效预测大语言模型的推理性能，为低成本优化数据集和探索推理能力提供实用路径。这具有重要的学术价值，改进了预测模型的效率；实际应用价值体现在大幅降低预训练成本。未来工作可能包括扩展至更广泛的模型规模或推理任务，以提升通用性。",
      "tags": [
        "Large Language Model",
        "Reasoning",
        "Proxy Model",
        "Negative Log-Likelihood",
        "Zero-Shot Transfer"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:35.320441Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.17956",
    "title": "\"I think this is fair\": Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment",
    "authors": [
      "Lin Luo",
      "Yuri Nakao",
      "Mathieu Chollet",
      "Hiroya Inakoshi",
      "Simone Stumpf"
    ],
    "abstract": "Assessing fairness in artificial intelligence (AI) typically involves AI experts who select protected features, fairness metrics, and set fairness thresholds to assess outcome fairness. However, little is known about how stakeholders, particularly those affected by AI outcomes but lacking AI expertise, assess fairness. To address this gap, we conducted a qualitative study with 26 stakeholders without AI expertise, representing potential decision subjects in a credit rating scenario, to examine how they assess fairness when placed in the role of deciding on features with priority, metrics, and thresholds. We reveal that stakeholders' fairness decisions are more complex than typical AI expert practices: they considered features far beyond legally protected features, tailored metrics for specific contexts, set diverse yet stricter fairness thresholds, and even preferred designing customized fairness. Our results extend the understanding of how stakeholders can meaningfully contribute to AI fairness governance and mitigation, underscoring the importance of incorporating stakeholders' nuanced fairness judgments.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.17956.pdf",
    "abs_url": "https://arxiv.org/abs/2509.17956",
    "published": "2025-09-22T16:12:12Z",
    "updated": "2026-02-26T17:36:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文通过定性研究发现，缺乏AI专业知识的利益相关者在公平性评估中考虑更多特征、定制指标并设置更严格阈值，揭示了其决策复杂性，对AI公平性治理有重要贡献。",
      "motivation": "AI公平性评估通常由专家主导，他们选择受保护特征、指标和阈值，但现有方法对利益相关者（特别是非专家）如何评估公平性了解不足。这个问题至关重要，因为利益相关者如信用评分场景中的个体，直接受AI结果影响，他们的公平性判断未被充分考虑可能导致评估偏差或不公，限制了公平性治理的有效性和包容性。因此，研究旨在填补这一空白，探讨非专家利益相关者的公平性决策过程，以完善AI系统的公平性评估框架。",
      "method": "本研究采用定性研究方法，涉及26位没有AI专业知识的利益相关者，代表信用评分场景中的潜在决策主体。参与者被置于角色扮演中，负责决定特征优先级、选择公平性指标和设置阈值，以评估AI结果的公平性。关键创新点在于聚焦非专家的决策过程，通过访谈或调查收集数据，分析其决策逻辑和复杂性，而非依赖标准化的专家实践。摘要未明确说明具体数据集细节，但研究设计强调语境化和定制化，以探索利益相关者如何超越传统方法进行公平性评估。",
      "result": "研究结果显示，利益相关者的公平性决策比典型AI专家实践更复杂：他们考虑的特征远超法律保护的范围，根据具体上下文定制公平性指标，设置的阈值更多样且更严格，甚至偏好设计自定义的公平性方法。这些发现基于对26位参与者的定性分析，揭示了决策的多样性和精细度，与专家基于标准化特征和指标的评估形成鲜明对比。结果强调了利益相关者视角在公平性评估中的独特价值，为AI公平性治理提供了新的见解，但未提供具体量化指标如准确率提升，而是突出了决策过程的复杂性。",
      "conclusion": "本研究的核心贡献在于揭示了利益相关者公平性评估的复杂性，强调了在AI公平性治理中纳入非专家判断的重要性，以促进更全面和包容的公平性缓解策略。学术上，它扩展了对公平性评估方法的理解，挑战了专家主导的范式；实践上，提示AI系统设计应整合利益相关者的细致视角以提升公平性和可信度。局限性可能包括样本规模较小或场景单一，未来工作可扩展至更大样本、不同应用场景或结合量化分析，以进一步验证和深化这些发现。",
      "tags": [
        "AI Fairness",
        "Stakeholder Decision-Making",
        "Qualitative Research",
        "Protected Features",
        "Credit Rating Scenario"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:40.203690Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.16552",
    "title": "ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting",
    "authors": [
      "Xiaoyang Yan",
      "Muleilan Pei",
      "Shaojie Shen"
    ],
    "abstract": "3D occupancy prediction is critical for comprehensive scene understanding in vision-centric autonomous driving. Recent advances have explored utilizing 3D semantic Gaussians to model occupancy while reducing computational overhead, but they remain constrained by insufficient multi-view spatial interaction and limited multi-frame temporal consistency. To overcome these issues, in this paper, we propose a novel Spatial-Temporal Gaussian Splatting (ST-GS) framework to enhance both spatial and temporal modeling in existing Gaussian-based pipelines. Specifically, we develop a guidance-informed spatial aggregation strategy within a dual-mode attention mechanism to strengthen spatial interaction in Gaussian representations. Furthermore, we introduce a geometry-aware temporal fusion scheme that effectively leverages historical context to improve temporal continuity in scene completion. Extensive experiments on the large-scale nuScenes occupancy prediction benchmark showcase that our proposed approach not only achieves state-of-the-art performance but also delivers markedly better temporal consistency compared to existing Gaussian-based methods.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.16552.pdf",
    "abs_url": "https://arxiv.org/abs/2509.16552",
    "published": "2025-09-20T06:36:30Z",
    "updated": "2026-02-26T09:54:58Z",
    "comment": "Accepted by ICRA 2026",
    "light_analysis": {
      "overview": "ST-GS框架通过空间聚合策略和时间融合方案，增强了3D语义占用预测中的空间和时间建模能力。",
      "motivation": "3D占用预测对于基于视觉的自动驾驶场景理解至关重要，用于实现全面的环境感知。现有方法如使用3D语义高斯建模占用，虽然能减少计算开销，但面临多视图空间交互不足和多帧时间一致性有限的问题。这些不足限制了场景理解的准确性和连续性，因此本研究旨在克服这些挑战，提升现有基于高斯的流水线的性能，以满足实际应用中对高效、一致模型的需求。",
      "method": "提出的ST-GS框架包括两个核心创新：一是指导信息空间聚合策略，结合双模式注意力机制，以增强高斯表示中的空间交互；二是几何感知时间融合方案，有效利用历史上下文，改善场景补全中的时间连续性。这些技术集成到基于高斯的流水线中，通过优化空间和时间建模，提升了对复杂驾驶场景的处理能力，并利用了大规模数据集如nuScenes进行训练和验证。",
      "result": "在大规模nuScenes占用预测基准上进行广泛实验，结果显示所提方法不仅实现了最先进的性能，而且与现有基于高斯的其他方法相比，提供了显著更好的时间一致性。摘要未明确说明具体的性能指标如准确率提升，但基于现有信息，可以推断方法在标准测试中表现出色，有效解决了空间和时间建模的关键问题。",
      "conclusion": "本研究的主要贡献是提出了ST-GS框架，为3D语义占用预测领域带来了创新，通过增强空间交互和时间一致性，提升了场景理解的准确性。这在学术上推动了基于视觉的自动驾驶技术发展，具有实际应用价值，如改善环境感知系统的鲁棒性。未来工作可探索该方法在其他复杂场景下的泛化能力，但摘要未明确说明具体的局限性或扩展方向。",
      "tags": [
        "3D Semantic Occupancy Prediction",
        "Gaussian Splatting",
        "Spatial-Temporal Modeling",
        "Attention Mechanism",
        "Temporal Fusion"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:39.384680Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15429",
    "title": "Random Matrix Theory-guided sparse PCA for single-cell RNA-seq data",
    "authors": [
      "Victor Chardès"
    ],
    "abstract": "Single-cell RNA-seq provides detailed molecular snapshots of individual cells but is notoriously noisy. Variability stems from biological differences and technical factors, such as amplification bias and limited RNA capture efficiency, making it challenging to adapt computational pipelines to heterogeneous datasets or evolving technologies. As a result, most studies still rely on principal component analysis (PCA) for dimensionality reduction, valued for its interpretability and robustness, in spite of its known bias in high dimensions. Here, we improve upon PCA with a Random Matrix Theory (RMT)-based approach that guides the inference of sparse principal components using existing sparse PCA algorithms. We first introduce a novel biwhitening algorithm which self-consistently estimates the magnitude of transcriptomic noise affecting each gene in individual cells, without assuming a specific noise distribution. This enables the use of an RMT-based criterion to automatically select the sparsity level, rendering sparse PCA nearly parameter-free. Our mathematically grounded approach retains the interpretability of PCA while enabling robust, hands-off inference of sparse principal components. Across seven single-cell RNA-seq technologies and four sparse PCA algorithms, we show that this method systematically improves the reconstruction of the principal subspace and consistently outperforms PCA-, autoencoder-, and diffusion-based methods in cell-type classification tasks.",
    "categories": [
      "cs.LG",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.15429.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15429",
    "published": "2025-09-18T21:08:38Z",
    "updated": "2026-02-26T15:29:30Z",
    "comment": "16 figures",
    "light_analysis": {
      "overview": "提出基于随机矩阵理论的稀疏PCA方法，用于单细胞RNA-seq数据，以改进降维和细胞类型分类性能。",
      "motivation": "单细胞RNA-seq技术提供细胞级分子数据，但因技术噪声和生物变异性，数据分析面临挑战。尽管PCA因其可解释性和鲁棒性常用于降维，但在高维数据中存在偏差，难以适应异构数据集或新技术演变。因此，需开发更鲁棒的方法以提升分析准确性和适应性，克服现有方法的不足，应对实际应用中的复杂数据环境。",
      "method": "该方法基于随机矩阵理论，指导稀疏PCA的推断。首先引入biwhitening算法，自洽估计每个基因在单细胞中的转录组噪声，不假设特定噪声分布。这允许使用RMT标准自动选择稀疏水平，使稀疏PCA过程几乎参数自由。利用现有稀疏PCA算法，基于数学原理确保方法的可解释性和鲁棒性，适用于多种技术场景。",
      "result": "在七种单细胞RNA-seq技术和四种稀疏PCA算法上的实验显示，该方法系统性地改进了主子空间的重构效果。在细胞类型分类任务中，它一致优于基于PCA、自编码器和扩散的方法，提高了分类性能，证明了其在噪声环境下的优越性，未提及具体数据指标，但强调了系统性改进。",
      "conclusion": "本研究贡献了一种参数自由、鲁棒的稀疏PCA方法，结合随机矩阵理论，保留PCA的可解释性。其学术价值在于为高维噪声数据提供了数学分析框架，实际应用有助于提升单细胞RNA-seq数据分析的准确性。未来工作可能包括扩展应用范围或优化算法，摘要未明确说明局限性。",
      "tags": [
        "Random Matrix Theory",
        "sparse PCA",
        "biwhitening",
        "single-cell RNA-seq",
        "dimensionality reduction"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:49.582107Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.09666",
    "title": "Unified Multimodal Models as Auto-Encoders",
    "authors": [
      "Zhiyuan Yan",
      "Kaiqing Lin",
      "Zongjian Li",
      "Junyan Ye",
      "Hui Han",
      "Haochen Wang",
      "Zhendong Wang",
      "Bin Lin",
      "Hao Li",
      "Xinyan Xiao",
      "Jingdong Wang",
      "Haifeng Wang",
      "Li Yuan"
    ],
    "abstract": "Image-to-text (I2T) understanding and text-to-image (T2I) generation are two fundamental, important yet traditionally isolated multimodal tasks. Despite their intrinsic connection, existing approaches typically optimize them independently, missing the opportunity for mutual enhancement. In this paper, we argue that the both tasks can be connected under a shared Auto-Encoder perspective, where text serves as the intermediate latent representation bridging the two directions - encoding images into textual semantics (I2T) and decoding text back into images (T2I). Our key insight is that if the encoder truly \"understands\" the image, it should capture all essential structure, and if the decoder truly \"understands\" the text, it should recover that structure faithfully. Building upon this principle, we propose Unified-GRPO, a post-training method based on reinforcement learning that jointly optimizes both modules through reconstructive rewards, maximizing the semantic consistency between the input and the generated images. Under this reconstruction objective, the encoder is encouraged to extract as much accurate and comprehensive semantic information from the input image to maximize reconstruction quality, while the decoder is simultaneously optimized to generate conditioned on the encoder's prior, enabling a self-evolving improvement. Empirically, we find that using text as the intermediate representation and training under a reconstructive RL paradigm effectively benefits both I2T and T2I. The I2T module gains stronger fine-grained visual perception, such as small-object recognition, grounding, etc, while its dense embeddings and language priors, in turn, provide richer semantic signals that improve T2I fidelity and complex instruction following. These results demonstrate that the reconstructive RL establishes a mutually reinforcing cross-modal synergy within the auto-encoding framework.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.09666.pdf",
    "abs_url": "https://arxiv.org/abs/2509.09666",
    "published": "2025-09-11T17:57:59Z",
    "updated": "2026-02-26T09:05:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于自编码器和强化学习的统一多模态模型，以文本为中间表示联合优化图像理解和图像生成任务，实现了跨模态协同。",
      "motivation": "图像到文本理解和文本到图像生成是两个关键但传统上孤立的多模态任务，现有方法独立优化它们，忽略了内在联系和相互增强的机会，导致模型性能受限。由于多模态AI在应用中的重要性，如智能图像分析和生成，这种分离阻碍了效率和效果的提升。因此，需要一种统一框架来连接这两个任务，充分利用语义一致性促进相互改进。",
      "method": "论文提出Unified-GRPO，一种基于强化学习的后训练方法，核心创新在于将文本作为中间潜在表示，在自编码器框架下联合优化编码器（用于图像到文本）和解码器（用于文本到图像）。通过重建奖励最大化输入与生成图像之间的语义一致性，编码器被鼓励提取全面的图像语义，解码器则基于这些语义进行生成优化。摘要未明确说明具体使用的数据集和模型架构细节，但强调了自编码器和强化学习的技术结合。",
      "result": "实验结果显示，采用文本作为中间表示并在重建强化学习范式下训练，有效提升了两个任务的性能。图像到文本模块增强了细粒度视觉感知能力，如小物体识别和基础任务；文本到图像模块则提高了图像保真度和复杂指令的跟随能力。这些改进表明重建强化学习在自编码框架中建立了相互增强的跨模态协同，优于传统独立优化方法，尽管摘要未提供具体数值指标。",
      "conclusion": "论文的主要贡献是提出统一自编码器视角，通过强化学习的重建范式连接和优化多模态任务，增强了跨模态协同。学术上，它为多模态学习提供了新框架，推动了任务融合研究；实际上，可应用于图像理解和生成系统，提升整体性能。未来方向可能包括扩展到其他模态或进一步优化算法以应对更复杂场景。",
      "tags": [
        "Unified Multimodal Models",
        "Auto-Encoder",
        "Reinforcement Learning",
        "Image-to-Text",
        "Text-to-Image"
      ]
    },
    "analyzed_at": "2026-02-27T03:54:52.634409Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.07706",
    "title": "FHIR-RAG-MEDS: Integrating HL7 FHIR with Retrieval-Augmented Large Language Models for Enhanced Medical Decision Support",
    "authors": [
      "Yildiray Kabak",
      "Gokce B. Laleci Erturkmen",
      "Mert Gencturk",
      "Tuncay Namli",
      "A. Anil Sinaci",
      "Ruben Alcantud Corcoles",
      "Cristina Gomez Ballesteros",
      "Pedro Abizanda",
      "Asuman Dogac"
    ],
    "abstract": "In this study, we propose FHIR-RAG-MEDS system that aims to integrate Health Level 7 Fast Healthcare Interoperability Resources (HL7 FHIR) with a Retrieval-Augmented Generation (RAG)-based system to improve personalized medical decision support on evidence-based clinical guidelines, emphasizing the need for research in practical applications. In the evolving landscape of medical decision support systems, integrating advanced technologies such as RAG and HL7 FHIR can significantly enhance clinical decision-making processes. Despite the potential of these technologies, there is limited research on their integration in practical applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.07706.pdf",
    "abs_url": "https://arxiv.org/abs/2509.07706",
    "published": "2025-09-09T13:10:49Z",
    "updated": "2026-02-26T07:39:32Z",
    "comment": "23 pages, submitted to Journal AI specifically to the special issue \"LLMs and AI Agents in Biomedical and Health Sciences\", under review",
    "light_analysis": {
      "overview": "提出FHIR-RAG-MEDS系统，集成HL7 FHIR与检索增强生成大语言模型，以增强个性化医疗决策支持。",
      "motivation": "在医疗决策支持系统领域，现有研究在集成先进技术如RAG和HL7 FHIR于实践应用中存在不足。HL7 FHIR是医疗数据互操作性标准，RAG结合大语言模型能优化决策过程，但实际应用整合有限，导致个性化、证据基础的临床指南支持不足。本研究旨在解决这一缺口，通过技术融合提升决策质量，强调在医疗环境中实践应用的重要性。",
      "method": "FHIR-RAG-MEDS系统通过整合HL7 FHIR数据标准与基于检索增强生成的架构，实现医疗决策支持。系统利用FHIR格式的临床数据进行信息检索，结合RAG框架中的大语言模型生成个性化建议。关键创新在于将医疗数据互操作性与AI生成能力结合，以优化决策流程。摘要未明确说明具体数据集、模型架构或实施细节，因此需进一步查阅全文获取技术实现。",
      "result": "摘要未明确说明实验结果，如准确率、效率改进或与基线方法的对比数据。因此，无法提供具体性能指标。论文可能侧重于系统设计和技术集成概念，而非量化评估。读者需参考全文了解实验设置和验证结果，本研究可能处于理论或初步实施阶段，强调集成潜力而非实证效果。",
      "conclusion": "本研究的主要贡献是提出FHIR-RAG-MEDS系统，集成HL7 FHIR与RAG技术，推动医疗决策支持的发展。学术价值在于促进医疗数据互操作性与AI技术的融合，实际应用价值在于为临床医生提供个性化、证据基础的决策工具。局限性包括未详细验证系统性能，未来工作可能包括系统实施、实验评估以及扩展应用到更多医疗场景。",
      "tags": [
        "HL7 FHIR",
        "Retrieval-Augmented Generation",
        "Large Language Models",
        "Medical Decision Support",
        "Evidence-Based Medicine"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:14.123086Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.04403",
    "title": "Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios",
    "authors": [
      "Jingen Qu",
      "Lijun Li",
      "Bo Zhang",
      "Yichen Yan",
      "Jing Shao"
    ],
    "abstract": "Multimodal large language models (MLLMs) are rapidly evolving, presenting increasingly complex safety challenges. However, current dataset construction methods, which are risk-oriented, fail to cover the growing complexity of real-world multimodal safety scenarios (RMS). And due to the lack of a unified evaluation metric, their overall effectiveness remains unproven. This paper introduces a novel image-oriented self-adaptive dataset construction method for RMS, which starts with images and end constructing paired text and guidance responses. Using the image-oriented method, we automatically generate an RMS dataset comprising 35k image-text pairs with guidance responses. Additionally, we introduce a standardized safety dataset evaluation metric: fine-tuning a safety judge model and evaluating its capabilities on other safety datasets.Extensive experiments on various tasks demonstrate the effectiveness of the proposed image-oriented pipeline. The results confirm the scalability and effectiveness of the image-oriented approach, offering a new perspective for the construction of real-world multimodal safety datasets. The dataset is presented at https://huggingface.co/datasets/NewCityLetter/RMS2/tree/main.",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.04403.pdf",
    "abs_url": "https://arxiv.org/abs/2509.04403",
    "published": "2025-09-04T17:13:59Z",
    "updated": "2026-02-26T11:09:21Z",
    "comment": "Accepted at EMNLP 2025 Findings",
    "light_analysis": {
      "overview": "论文提出了一种面向图像的自适应数据集构建方法，用于真实世界多模态安全场景，并引入了标准化评估指标。",
      "motivation": "随着多模态大语言模型（MLLMs）的快速发展，真实世界多模态安全场景（RMS）的复杂性日益增加，但现有基于风险的数据集构建方法无法全面覆盖这些动态场景，且缺乏统一的评估指标来验证其整体有效性。这导致安全挑战的评估不足，限制了MLLMs在实际应用中的可靠性和安全性，因此亟需开发更高效的数据集构建和评估方法以应对不断演变的安全威胁。",
      "method": "论文提出了一种新颖的面向图像的自适应数据集构建方法，从真实世界图像出发，自动生成配对的文本描述和指导响应，构建了包含35k个图像-文本对的RMS数据集。关键创新点包括采用图像导向的流程，无需依赖预定义风险类别；同时引入了标准化评估指标，通过微调一个安全判断模型，并在其他安全数据集上测试其泛化能力，以验证数据集的效用和质量。",
      "result": "在各种任务上进行的大量实验证实了所提方法的有效性和可扩展性，但摘要未明确说明具体的性能指标如准确率或效率改进。实验结果强调了图像导向方法在构建真实世界多模态安全数据集方面的实用性，对比现有方法，该方法能更好地覆盖复杂场景，提供了数据集评估的新基准。",
      "conclusion": "该研究的主要贡献在于开发了一种创新的数据集构建方法和评估框架，为真实世界多模态安全数据集的构建提供了新视角，并公开了数据集以促进社区研究。这推动了MLLMs安全评估的标准化，具有显著的学术价值和实际应用潜力；摘要未提及具体的局限性或未来工作方向，但暗示了方法在可扩展性方面的优势。",
      "tags": [
        "Multimodal Large Language Models",
        "Self-adaptive Dataset Construction",
        "Safety Evaluation",
        "Image-text Pair Generation",
        "Fine-tuning Models"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:08.850442Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.20570",
    "title": "Dyslexify: A Mechanistic Defense Against Typographic Attacks in CLIP",
    "authors": [
      "Lorenz Hufe",
      "Constantin Venhoff",
      "Erblina Purelku",
      "Maximilian Dreyer",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "abstract": "Typographic attacks exploit multi-modal systems by injecting text into images, leading to targeted misclassifications, malicious content generation and even Vision-Language Model jailbreaks. In this work, we analyze how CLIP vision encoders behave under typographic attacks, locating specialized attention heads in the latter half of the model's layers that causally extract and transmit typographic information to the cls token. Building on these insights, we introduce Dyslexify - a method to defend CLIP models against typographic attacks by selectively ablating a typographic circuit, consisting of attention heads. Without requiring finetuning, dyslexify improves performance by up to 22.06% on a typographic variant of ImageNet-100, while reducing standard ImageNet-100 accuracy by less than 1%, and demonstrate its utility in a medical foundation model for skin lesion diagnosis. Notably, our training-free approach remains competitive with current state-of-the-art typographic defenses that rely on finetuning. To this end, we release a family of dyslexic CLIP models which are significantly more robust against typographic attacks. These models serve as suitable drop-in replacements for a broad range of safety-critical applications, where the risks of text-based manipulation outweigh the utility of text recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2508.20570.pdf",
    "abs_url": "https://arxiv.org/abs/2508.20570",
    "published": "2025-08-28T09:08:30Z",
    "updated": "2026-02-26T17:33:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Dyslexify方法，无需训练即可通过选择性消融CLIP模型中的特定注意力头来增强对typographic attacks的防御鲁棒性。",
      "motivation": "Typographic attacks通过向图像注入文本，利用CLIP等多模态系统，导致目标误分类、恶意内容生成甚至模型越狱，对安全关键应用构成严重威胁。现有防御方法通常依赖微调模型，增加了部署复杂性和成本，且可能不足以有效阻断攻击。因此，开发一种无需训练的防御机制至关重要，以在不显著影响标准性能的前提下提升模型对文本操纵的抵抗力。",
      "method": "论文首先分析CLIP视觉编码器在typographic attacks下的行为，定位模型后层中专门提取和传输文本信息的注意力头。基于此洞察，提出Dyslexify方法，通过选择性地消融这些注意力头构成的typographic circuit，阻断攻击信息的传播。该方法无需微调，直接修改注意力机制，保持了CLIP的原始结构。实验使用typographic variant of ImageNet-100和医疗基础模型（如皮肤病变诊断）进行验证，以评估防御效果。",
      "result": "实验结果显示，Dyslexify在typographic variant of ImageNet-100上提升性能高达22.06%，同时标准ImageNet-100准确率仅下降不到1%。在医疗基础模型中，如皮肤病变诊断，也展现了良好的防御实用性。与依赖微调的当前最先进typographic防御方法相比，Dyslexify无需训练即可达到竞争性性能，证明了其高效性和可扩展性。",
      "conclusion": "论文的主要贡献是提出Dyslexify，一种无需训练的防御机制，揭示了CLIP模型中typographic信息流的因果机制，并提供了有效的干预策略。研究具有重要学术价值，增进了对多模态模型安全性的理解，实际应用价值在于发布了一系列鲁棒的dyslexic CLIP模型，适用于安全关键领域如医疗诊断。未来工作可能包括将方法扩展到其他模型或攻击类型，以及探索更多无需训练的防御技术。",
      "tags": [
        "Typographic Attacks",
        "CLIP",
        "Attention Heads",
        "Ablation",
        "Model Robustness"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:17.254799Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.04228",
    "title": "LayerT2V: A Unified Multi-Layer Video Generation Framework",
    "authors": [
      "Guangzhao Li",
      "Kangrui Cen",
      "Baixuan Zhao",
      "Yi Xin",
      "Siqi Luo",
      "Guangtao Zhai",
      "Lei Zhang",
      "Xiaohong Liu"
    ],
    "abstract": "Text-to-video generation has advanced rapidly, but existing methods typically output only the final composited video and lack editable layered representations, limiting their use in professional workflows. We propose \\textbf{LayerT2V}, a unified multi-layer video generation framework that produces multiple semantically consistent outputs in a single inference pass: the full video, an independent background layer, and multiple foreground RGB layers with corresponding alpha mattes. Our key insight is that recent video generation backbones use high compression in both time and space, enabling us to serialize multiple layer representations along the temporal dimension and jointly model them on a shared generation trajectory. This turns cross-layer consistency into an intrinsic objective, improving semantic alignment and temporal coherence. To mitigate layer ambiguity and conditional leakage, we augment a shared DiT backbone with LayerAdaLN and layer-aware cross-attention modulation. LayerT2V is trained in three stages: alpha mask VAE adaptation, joint multi-layer learning, and multi-foreground extension. We also introduce \\textbf{VidLayer}, the first large-scale dataset for multi-layer video generation. Extensive experiments demonstrate that LayerT2V substantially outperforms prior methods in visual fidelity, temporal consistency, and cross-layer coherence.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2508.04228.pdf",
    "abs_url": "https://arxiv.org/abs/2508.04228",
    "published": "2025-08-06T09:03:16Z",
    "updated": "2026-02-26T17:37:05Z",
    "comment": "Project Page is https://layert2v.github.io/",
    "light_analysis": {
      "overview": "本文提出 LayerT2V，一个统一的多层视频生成框架，通过序列化多层表示并联合建模，在单次推理中生成语义一致的多层视频输出，解决了现有方法缺乏可编辑分层的限制。",
      "motivation": "现有文本到视频生成方法通常仅输出最终合成的视频，缺乏可编辑的分层表示（如独立背景和前景层），限制了在专业视频编辑、特效和后期制作等工作流程中的应用。这一问题至关重要，因为专业需求要求对图层进行灵活调整，而现有方法因只提供单一视频，难以支持后期编辑和语义分离，导致层歧义和条件泄漏问题未得到解决。",
      "method": "LayerT2V 的核心方法是基于视频生成主干在时间和空间上的高压缩特性，在时间维度上序列化多层表示（包括完整视频、背景层和前景 RGB 层与 alpha 遮罩），并在共享的生成轨迹上联合建模，使跨层一致性成为内在目标。关键技术包括：使用共享的 DiT 主干，并通过 LayerAdaLN 和层感知跨注意力调制增强，以缓解层歧义和条件泄漏。训练分三个阶段：alpha 遮罩 VAE 适应、联合多层学习和多前景扩展；同时，引入了 VidLayer 数据集，这是首个大规模多层视频生成数据集。",
      "result": "实验表明，LayerT2V 在视觉保真度、时间一致性和跨层一致性方面显著优于先前方法。摘要未明确说明具体数值，但可推断其在这些关键指标上相比基线方法有实质提升，验证了框架在生成高质量、可编辑视频层方面的有效性。",
      "conclusion": "LayerT2V 的主要贡献是提出首个能生成多层可编辑视频表示的统一框架，并引入 VidLayer 数据集。其学术价值在于推动了多层视频生成领域的发展，为跨层一致性建模提供了新思路；实际应用价值在于赋能专业视频编辑工作流，提高后期调整的灵活性。未来工作方向可能包括优化模型效率或扩展数据集规模，以进一步提升性能。",
      "tags": [
        "Text-to-Video Generation",
        "Multi-Layer Representation",
        "DiT",
        "LayerAdaLN",
        "Cross-Attention Modulation"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:19.959193Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.03587",
    "title": "Zero-Variance Gradients for Variational Autoencoders",
    "authors": [
      "Zilei Shao",
      "Anji Liu",
      "Guy Van den Broeck"
    ],
    "abstract": "Training deep generative models like Variational Autoencoders (VAEs) requires propagating gradients through stochastic latent variables, which introduces estimation variance that can slow convergence and degrade performance. In this paper, we explore an orthogonal direction, which we call Silent Gradients. Instead of designing improved stochastic estimators, we show that by restricting the decoder architecture in specific ways, the expected ELBO can be computed analytically. This yields gradients with zero estimation variance as we can directly compute the evidence lower-bound without resorting to Monte Carlo samples of the latent variables. We first provide a theoretical analysis in a controlled setting with a linear decoder and demonstrate improved optimization compared to standard estimators. To extend this idea to expressive nonlinear decoders, we introduce a training paradigm that uses the analytic gradient to guide early encoder learning before annealing to a standard stochastic estimator. Across multiple datasets, our approach consistently improves established baselines, including reparameterization, Gumbel-Softmax, and REINFORCE. These results suggest that architectural choices enabling analytic expectation computation can significantly stabilize the training of generative models with stochastic components.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.03587.pdf",
    "abs_url": "https://arxiv.org/abs/2508.03587",
    "published": "2025-08-05T15:54:21Z",
    "updated": "2026-02-26T06:30:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种名为'Silent Gradients'的方法，通过特定解码器架构实现变分自编码器的期望证据下界解析计算，从而获得零方差梯度以优化训练过程。",
      "motivation": "训练变分自编码器等深度生成模型时，需要通过随机隐变量传播梯度，这引入了估计方差，可能导致收敛缓慢和性能下降。现有方法如重参数化、Gumbel-Softmax和REINFORCE等标准梯度估计器虽然被广泛使用，但仍存在方差问题，影响了训练的稳定性和效率。因此，本文探索了一个正交方向，旨在从根本上减少方差来提升生成模型的训练质量。",
      "method": "论文核心方法是'Silent Gradients'，通过限制解码器架构，使证据下界的期望可以解析计算，无需依赖蒙特卡洛采样，从而获得零方差的梯度。在线性解码器的理论分析中，首先验证了这种方法相比标准估计器的优化优势。为扩展到非线性解码器，引入了一种训练范式：在早期训练阶段使用解析梯度指导编码器学习，随后逐渐退火过渡到标准的随机梯度估计器，以保持模型的表达能力。",
      "result": "在多个数据集上的实验结果表明，该方法一致性地改善了现有基线模型的训练性能，包括重参数化、Gumbel-Softmax和REINFORCE等标准梯度估计方法。相比于这些基线，Silent Gradients实现了更稳定的优化过程，减少了训练中的方差问题，从而提升了收敛速度和最终模型质量，尽管摘要未明确提供具体性能指标数据。",
      "conclusion": "本研究的主要贡献在于通过解码器架构的特定限制，实现期望证据下界的解析计算，获得零方差梯度，显著稳定了变分自编码器等具有随机组件的生成模型的训练。这为梯度估计问题提供了新的学术思路，具有潜在的应用价值，可能推动生成模型训练方法的改进。未来工作可探索如何将这种方法扩展到更复杂的模型架构或更广泛的生成任务中。",
      "tags": [
        "Variational Autoencoders",
        "Silent Gradients",
        "Gradient Estimation",
        "Analytic Expectation Computation"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:21.971596Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.01780",
    "title": "LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?",
    "authors": [
      "Guozhao Mo",
      "Wenliang Zhong",
      "Jiawei Chen",
      "Qianhao Yuan",
      "Xuanang Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Ben He",
      "Xianpei Han",
      "Le Sun"
    ],
    "abstract": "Model Context Protocol (MCP) has become a key infrastructure for connecting LLMs with external tools, scaling to 10,000+ MCP servers with diverse tools. Unfortunately, there is still a large gap between real-world MCP usage and current evaluation: they typically assume single-server settings and directly inject tools into the model's context, bypassing the challenges of large-scale retrieval and multi-tool composition. To bridge this gap, we propose LiveMCPBench, which evaluates 95 real-world daily tasks explicitly constructed to stress diverse tools and scaled multi-server routing. The benchmark includes a ready-to-deploy tool suite of 70 servers with 527 tools, ensuring reproducibility without scattered API configuration. We further introduce an LLM-as-a-Judge evaluation framework that directly verifies task outcomes, handling dynamic data sources and multiple valid solution paths. We benchmark 12 state-of-the-art LLMs and observe a substantial performance gap: while Claude-Sonnet-4 reaches 78.95% task success, most models achieve only 30-50%. Our analysis reveals that the active tool composition strongly correlates with task success, whereas retrieval errors account for nearly half of all failures, highlighting retrieval as the dominant bottleneck. Together, these results provide the first large-scale, reproducible diagnosis of MCP agent capabilities and point towards future research on improving retrieval robustness and encouraging effective tool composition. Our code and data are publicly available at https://icip-cas.github.io/LiveMCPBench.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2508.01780.pdf",
    "abs_url": "https://arxiv.org/abs/2508.01780",
    "published": "2025-08-03T14:36:42Z",
    "updated": "2026-02-26T03:19:15Z",
    "comment": "Our code and data will be publicly available at https://icip-cas.github.io/LiveMCPBench",
    "light_analysis": {
      "overview": "该论文提出了LiveMCPBench基准，首个大规模、可重复的基准，用于评估LLM代理在MCP环境中处理多样化工具和扩展多服务器路由的能力。",
      "motivation": "MCP作为连接LLM与外部工具的关键基础设施，已扩展到超过10,000个服务器，提供多样化工具。然而，现有评估通常假设简单的单服务器设置，直接将工具注入模型上下文，未能反映实际应用中大规模工具检索和多工具组合的复杂性。因此，需要一个新基准来弥补现实世界使用与评估之间的差距，以更真实地测试LLM代理的实际能力。",
      "method": "方法包括提出LiveMCPBench基准，基于95个真实世界日常任务设计，强调多样化工具和扩展多服务器路由。基准集成了70个服务器和527个工具的可部署套件，确保可重复性，避免分散API配置问题。此外，引入LLM-as-a-Judge评估框架，直接验证任务结果，处理动态数据源和多种解决方案路径，系统性地对12个最先进LLMs进行测试。",
      "result": "实验结果显示，Claude-Sonnet-4在基准测试中达到78.95%的任务成功率，而大多数其他模型如GPT系列等仅实现30-50%的成功率。分析表明，主动工具组合与任务成功高度相关，检索错误占据了近一半的失败案例，突显检索是主要性能瓶颈，为MCP代理能力评估提供了具体数据支撑和对比基线。",
      "conclusion": "本研究的主要贡献是提出了LiveMCPBench，首个大规模、可重复的基准，用于系统评估LLM代理在MCP环境中的能力。学术上，它填补了现有评估与实际应用之间的差距，为相关研究提供了标准测试平台；实际应用中，有助于开发更强大的LLM代理，改进工具检索和组合。未来工作可聚焦于提高检索鲁棒性和促进有效工具组合。",
      "tags": [
        "Model Context Protocol",
        "Large Language Model",
        "Benchmark Evaluation",
        "Tool Retrieval",
        "Tool Composition"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:35.490754Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.19575",
    "title": "Is Exchangeability better than I.I.D to handle Data Distribution Shifts while Pooling Data for Data-scarce Medical image segmentation?",
    "authors": [
      "Ayush Roy",
      "Samin Enam",
      "Jun Xia",
      "Won Hwa Kim",
      "Vishnu Suresh Lokhande"
    ],
    "abstract": "Data scarcity is a major challenge in medical imaging, particularly for deep learning models. While data pooling (combining datasets from multiple sources) and data addition (adding more data from a new dataset) have been shown to enhance model performance, they are not without complications. Specifically, increasing the size of the training dataset through pooling or addition can induce distributional shifts, negatively affecting downstream model performance, a phenomenon known as the \"Data Addition Dilemma\". While the traditional i.i.d. assumption may not hold in multi-source contexts, assuming exchangeability across datasets provides a more practical framework for data pooling. In this work, we investigate medical image segmentation under these conditions, drawing insights from causal frameworks to propose a method for controlling foreground-background feature discrepancies across all layers of deep networks. This approach improves feature representations, which are crucial in data-addition scenarios. Our method achieves state-of-the-art segmentation performance on histopathology and ultrasound images across five datasets, including a novel ultrasound dataset that we have curated and contributed. Qualitative results demonstrate more refined and accurate segmentation maps compared to prominent baselines across three model architectures.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.19575.pdf",
    "abs_url": "https://arxiv.org/abs/2507.19575",
    "published": "2025-07-25T17:55:06Z",
    "updated": "2026-02-26T03:30:51Z",
    "comment": "MIDL 2026",
    "light_analysis": {
      "overview": "论文提出一种基于可交换性假设的方法，通过控制深度网络中的特征差异处理数据池化时的分布偏移，显著提高医疗图像分割性能。",
      "motivation": "医疗图像分割常面临数据稀缺挑战，数据池化和添加数据虽能提升模型性能，但可能引入分布偏移，称为'Data Addition Dilemma'，导致下游任务表现下降。传统i.i.d.假设在多源数据中不适用，而可交换性假设提供了更实用的框架。因此，研究旨在开发有效方法来解决分布偏移问题，以增强模型在多源数据环境中的泛化能力，这在医疗影像分析中尤为重要。",
      "method": "方法从因果框架汲取灵感，提出控制深度网络所有层中前景-背景特征差异的技术。该创新通过优化特征表示来应对数据添加场景的挑战，未详细说明具体模型架构，但应用于组织病理学和超声图像，包括一个新贡献的超声数据集，并在三种模型架构上进行了实验验证。",
      "result": "实验在五个数据集上实现最先进的分割性能，包括一个新超声数据集。与多个基线方法相比，定性结果显示分割图更精细和准确，证明了方法在改善特征表示方面的优势。摘要未明确说明具体量化指标如准确率，但强调了其在组织病理学和超声图像上的显著效果，并在三种模型架构中验证了鲁棒性。",
      "conclusion": "论文通过引入可交换性假设和特征差异控制方法，成功处理了数据池化中的分布偏移问题，提升了医疗图像分割的准确性。研究对数据稀缺领域的学术和实际应用有重要价值，提供了更实用的多源数据处理框架。未来方向可能包括方法优化和扩展到其他医学图像分析任务，以进一步提高泛化能力。",
      "tags": [
        "Medical Image Segmentation",
        "Data Distribution Shifts",
        "Exchangeability",
        "Causal Framework",
        "Deep Networks"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:25.362746Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.08491",
    "title": "A Third Paradigm for LLM Evaluation: Dialogue Game-Based Evaluation using clembench",
    "authors": [
      "David Schlangen",
      "Sherzod Hakimov",
      "Chalamalasetti Kranti",
      "Jonathan Jordan",
      "Philipp Sadler"
    ],
    "abstract": "There are currently two main paradigms for evaluating large language models (LLMs), reference-based evaluation and preference-based evaluation. The first, carried over from the evaluation of machine learning models in general, relies on pre-defined task instances, for which reference task executions are available. The second, best exemplified by the LM-arena, relies on (often self-selected) users bringing their own intents to a site that routes these to several models in parallel, among whose responses the user then selects their most preferred one. The former paradigm hence excels at control over what is tested, while the latter comes with higher ecological validity, testing actual use cases interactively. Recently, a third complementary paradigm has emerged that combines some of the strengths of these approaches, offering control over multi-turn, reference-free, repeatable interactions, while stressing goal-directedness: dialogue game based evaluation. While the utility of this approach has been shown by several projects, its adoption has been held back by the lack of a mature, easily re-usable implementation. In this paper, we present clembench, which has been in continuous development since 2023 and has in its latest release been optimized for ease of general use. We describe how it can be used to benchmark one's own models (using a provided set of benchmark game instances in English), as well as how easily the benchmark itself can be extended with new, tailor-made targeted tests.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2507.08491.pdf",
    "abs_url": "https://arxiv.org/abs/2507.08491",
    "published": "2025-07-11T11:16:01Z",
    "updated": "2026-02-26T15:16:15Z",
    "comment": "All code required to run the benchmark, as well as extensive documentation, is available at https://github.com/clembench/clembench",
    "light_analysis": {
      "overview": "论文提出了大语言模型评估的第三种范式——基于对话游戏的评估，并通过clembench工具实现这一方法。",
      "motivation": "当前大语言模型评估存在两种主要范式：基于参考的评估和基于偏好的评估。前者依赖于预定义任务实例，控制性强但生态效度低；后者通过用户交互测试实际用例，生态效度高但控制性差。这两种范式各有不足，无法平衡控制性与实用性。因此，需要一种互补方法，结合两者优点，提供多轮、无参考、可重复的交互测试，强调目标导向。然而，现有实现工具不成熟，限制了该范式的推广，本研究旨在解决这一问题。",
      "method": "论文提出基于对话游戏的评估作为第三范式，并使用clembench工具实现。clembench自2023年起持续开发，最新版本优化了易用性，便于广泛使用。它提供了一个英语基准游戏实例集，用于评估自定义大语言模型，同时支持轻松扩展新定制测试。关键创新在于将对话游戏作为评估框架，实现控制性和生态效度的平衡，方法包括多轮交互和参考自由的测试设计，无需依赖预定义参考答案。",
      "result": "摘要未明确说明具体实验结果，如准确率或效率指标。但提到多个项目已展示基于对话游戏评估的效用，表明clembench在基准测试中具有初步有效性。未来工作可能包括性能评估和与现有范式的对比，但目前缺乏详细数据支撑。该方法旨在补充而非替代现有评估方式，通过结合控制性和生态效度，提升评估质量。",
      "conclusion": "本研究的主要贡献是推出了clembench工具，促进基于对话游戏评估范式的采用。这种方法结合了参考范式的控制性和偏好范式的生态效度，为LLM评估提供了一种互补途径，具有学术价值（如推动评估方法创新）和实际应用价值（如增强模型测试的实用性）。局限性可能包括依赖特定语言实例；未来方向可扩展多语言支持、更多游戏类型或集成到现有基准中。",
      "tags": [
        "Large Language Model Evaluation",
        "Dialogue Game",
        "Benchmarking",
        "clembench",
        "Multi-turn Interaction"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:36.285448Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.03772",
    "title": "Skewed Score: A statistical framework to assess autograders",
    "authors": [
      "Magda Dubois",
      "Harry Coppock",
      "Mario Giulianelli",
      "Timo Flesch",
      "Lennart Luettgau",
      "Cozmin Ududec"
    ],
    "abstract": "The evaluation of large language model (LLM) outputs is increasingly performed by other LLMs, a setup commonly known as \"LLM-as-a-judge\", or autograders. While autograders offer a scalable alternative to human evaluation, they have shown mixed reliability and may exhibit systematic biases, depending on response type, scoring methodology, domain specificity, or other factors. Here we propose a statistical framework based on Bayesian generalised linear models (GLMs) that enables researchers to simultaneously assess their autograders while addressing their primary research questions (e.g., LLM evaluation). Our approach models evaluation outcomes (e.g., scores or pairwise preferences) as a function of properties of the grader (e.g., human vs. autograder) and the evaluated item (e.g., response length or the LLM that generated it), allowing for explicit quantification of scoring differences and potential biases within a unified framework. In addition, our method can be used to augment traditional metrics such as inter-rater agreement, by providing uncertainty estimates and clarifying sources of disagreement. Overall, this approach contributes to more robust and interpretable use of autograders in LLM evaluation, enabling both performance analysis and bias detection.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.03772.pdf",
    "abs_url": "https://arxiv.org/abs/2507.03772",
    "published": "2025-07-04T18:45:10Z",
    "updated": "2026-02-26T17:39:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种基于贝叶斯广义线性模型的统计框架，用于评估大型语言模型作为评判者的可靠性和系统偏见。",
      "motivation": "随着大型语言模型（LLM）的广泛应用，使用其他LLM作为评判者（即autograders）进行输出评估成为一种可扩展方法，但该方法存在可靠性不一致和系统偏见问题，具体取决于响应类型、评分方法或领域特异性等因素。现有autograders缺乏统一框架来量化这些偏见，导致评估结果不够稳健，影响了LLM评估的准确性。因此，需要一种统计方法来同时评估autograder性能并解决核心研究问题，以促进更可靠的LLM评估。",
      "method": "该方法基于贝叶斯广义线性模型（GLMs），将评估结果（如分数或成对偏好）建模为评判者属性（例如人类vs自动评分器）和评估项属性（如响应长度或生成LLM）的函数。通过这一框架，可以显式量化评分差异和潜在偏见，并提供不确定性估计。关键创新点在于整合统计建模与传统度量（如评分者间一致性），从而澄清分歧来源，实现在单一框架内同时评估autograder和分析数据，而无需依赖具体数据集或模型架构的详细信息。",
      "result": "摘要未明确说明具体实验结果，如准确率提升或效率改进。论文提到该方法能够通过提供不确定性估计和澄清分歧来源来增强传统度量的稳健性。可以推断，该框架有助于更可靠地检测偏见和差异，但在摘要中未提供与基线方法的对比数据或具体性能指标，因此实际效果需要进一步实验验证。",
      "conclusion": "该研究的主要贡献是提出了一个统计框架，用于评估和增强自动评分器在LLM评估中的使用，使其更稳健和可解释。学术价值在于为LLM评估提供了新的方法论，支持性能分析和系统偏见检测。在实际应用中，这可能提高评估的可靠性。局限性可能包括对特定场景或数据的依赖，未来工作可包括更广泛的实验验证和应用扩展到其他评估任务。",
      "tags": [
        "Large Language Model",
        "Autograder",
        "Bayesian Generalized Linear Models",
        "Statistical Framework",
        "Bias Detection"
      ]
    },
    "analyzed_at": "2026-02-27T03:55:44.573858Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.18582",
    "title": "Parallel Continuous Chain-of-Thought with Jacobi Iteration",
    "authors": [
      "Haoyi Wu",
      "Zhihao Teng",
      "Kewei Tu"
    ],
    "abstract": "Continuous chain-of-thought has been shown to be effective in saving reasoning tokens for large language models. By reasoning with continuous latent thought tokens, continuous CoT is able to perform implicit reasoning in a compact manner. However, the sequential dependencies between latent thought tokens spoil parallel training, leading to long training time. In this paper, we propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi iteration on the latent thought tokens, updating them iteratively in parallel instead of sequentially and thus improving both training and inference efficiency of continuous CoT. Experiments demonstrate that by choosing the proper number of iterations, we are able to achieve comparable or even better performance while saving nearly 50% of the training and inference time. Moreover, PCCoT shows better stability and robustness in the training process. Our code is available at https://github.com/whyNLP/PCCoT.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.18582.pdf",
    "abs_url": "https://arxiv.org/abs/2506.18582",
    "published": "2025-06-23T12:35:41Z",
    "updated": "2026-02-26T05:26:04Z",
    "comment": "Accepted to EMNLP 2025 main conference",
    "light_analysis": {
      "overview": "论文提出并行连续思维链方法，通过Jacobi迭代并行更新潜在思想令牌，显著提高训练和推理效率。",
      "motivation": "连续思维链方法利用潜在思想令牌进行隐式推理，有效节省大型语言模型的推理令牌，但现有方法因令牌间的序列依赖无法实现并行训练，导致训练时间长、计算成本高。这在资源密集型应用中尤为突出，亟需改进以提升模型训练效率。摘要未明确说明具体应用场景，但问题普遍存在于序列依赖任务中。",
      "method": "论文提出并行连续思维链（PCCoT），核心是应用Jacobi迭代算法对潜在思想令牌进行并行更新，替代传统顺序更新。该方法在每次迭代中同时更新所有令牌，消除序列依赖，从而优化训练和推理的并行性。摘要未明确说明使用的具体数据集或模型架构，但方法设计通用，适用于大型语言模型的连续思维链框架。",
      "result": "实验结果显示，通过选择适当的迭代次数，PCCoT在性能上达到或超越基线连续思维链方法，同时训练和推理时间节省近50%。这证明了在保持甚至提升模型效果的前提下，效率显著提高。此外，PCCoT在训练过程中展现出更好的稳定性和鲁棒性，验证了其实际应用价值。",
      "conclusion": "论文的主要贡献是提出并行连续思维链方法，利用Jacobi迭代实现并行化，有效解决连续思维链的序列依赖问题，提高了训练和推理效率及稳定性。这一创新具有学术价值，为优化大型语言模型训练提供新思路，并可能应用于其他序列依赖任务。未来工作可探索迭代策略的优化或扩展至更多应用领域。",
      "tags": [
        "Continuous Chain-of-Thought",
        "Jacobi Iteration",
        "Parallel Training",
        "Large Language Models",
        "Efficient Inference"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:00.962633Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.15190",
    "title": "Learning Task-Agnostic Motifs to Capture the Continuous Nature of Animal Behavior",
    "authors": [
      "Jiyi Wang",
      "Jingyang Ke",
      "Bo Dai",
      "Anqi Wu"
    ],
    "abstract": "Animals flexibly recombine a finite set of core motor motifs to meet diverse task demands, but existing behavior segmentation methods oversimplify this process by imposing discrete syllables under restrictive generative assumptions. To better capture the continuous structure of behavior generation, we introduce motif-based continuous dynamics (MCD) discovery, a framework that (1) uncovers interpretable motif sets as latent basis functions of behavior by leveraging representations of behavioral transition structure, and (2) models behavioral dynamics as continuously evolving mixtures of these motifs. We validate MCD on a multi-task gridworld, a labyrinth navigation task, and freely moving animal behavior. Across settings, it identifies reusable motif components, captures continuous compositional dynamics, and generates realistic trajectories beyond the capabilities of traditional discrete segmentation models. By providing a generative account of how complex animal behaviors emerge from dynamic combinations of fundamental motor motifs, our approach advances the quantitative study of natural behavior.",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.15190.pdf",
    "abs_url": "https://arxiv.org/abs/2506.15190",
    "published": "2025-06-18T07:11:48Z",
    "updated": "2026-02-26T13:41:11Z",
    "comment": "8 pages and 4 figures for the main text",
    "light_analysis": {
      "overview": "该论文提出 motif-based continuous dynamics (MCD) 发现框架，以捕捉动物行为的连续组合动态，改进现有离散分割方法的局限性。",
      "motivation": "动物行为通过重组核心运动 motif 灵活适应不同任务，但现有行为分割方法（如离散音节模型）过度简化这一过程，强加了离散性和限制性生成假设，导致无法准确捕捉行为的连续性和灵活性，阻碍了自然行为动态的定量研究。因此，需要开发新方法来建模行为的连续生成结构，以更真实地反映实际行为机制。",
      "method": "研究方法引入 motif-based continuous dynamics (MCD) 发现框架，包括两部分：(1) 利用行为过渡结构表示来发现可解释的 motif 集，作为行为的潜在基函数；(2) 将行为动态建模为这些 motif 的连续演化混合，从而捕捉行为的连续组合特性。该框架在多个数据集上验证，包括多任务网格世界、迷宫导航任务和自由移动动物行为数据，旨在克服传统离散模型的限制。",
      "result": "在多个实验设置中，MCD 框架成功识别出可重用的 motif 组件，有效捕捉了连续组合动态，并生成更真实的行为轨迹，超越了传统离散分割模型的能力。例如，在网格世界和迷宫任务中，MCD 生成的轨迹更自然，展示了其在建模复杂行为方面的优势。摘要未明确说明具体性能指标，但强调了其在生成真实轨迹方面的改进。",
      "conclusion": "论文的主要贡献是提供了复杂动物行为从基本运动 motif 动态组合中生成的生成性解释，通过 MCD 框架推进了自然行为的定量研究。其学术价值在于方法创新，打破了离散模型的限制，潜在应用可能涉及行为科学和机器学习领域。摘要未明确说明潜在的局限性或未来工作方向。",
      "tags": [
        "Motif Discovery",
        "Continuous Dynamics",
        "Behavioral Transition Structure",
        "Generative Modeling",
        "Latent Basis Functions"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:06.419844Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.24449",
    "title": "When Large Multimodal Models Confront Evolving Knowledge: Challenges and Explorations",
    "authors": [
      "Kailin Jiang",
      "Yuntao Du",
      "Yukai Ding",
      "Yuchen Ren",
      "Ning Jiang",
      "Zhi Gao",
      "Zilong Zheng",
      "Lei Liu",
      "Bin Li",
      "Qing Li"
    ],
    "abstract": "Large Multimodal Models (LMMs) store vast amounts of pretrained knowledge but struggle to remain aligned with real-world updates, making it difficult to avoid capability degradation when acquiring evolving knowledge. Furthermore, most current work focuses on exploring static textual knowledge injection, neglecting dynamic multimodal evolving knowledge injection, leaving the potential of LMMs for multimodal knowledge injection as an open question. To address this, we first propose a pipeline to construct MMEVOKE, a benchmark for evaluating LMMs' ability in multimodal evolving knowledge injection. MMEVOKE contains 9,422 samples spanning 159 subtypes. Then, based on extensive experiments with MMEVOKE, we reveal challenges such as poor injection performance and capability degradation in existing knowledge injection methods through knowledge injection tests and general capability tests. Finally, to tackle these challenges, we introduce knowledge augmentation and knowledge retention methods, finding that knowledge-aware augmentation strengthens knowledge injection performance, and that Data Replay and MoE methods effectively mitigate capability degradation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.24449.pdf",
    "abs_url": "https://arxiv.org/abs/2505.24449",
    "published": "2025-05-30T10:36:19Z",
    "updated": "2026-02-26T04:21:31Z",
    "comment": "ICLR 2026, Project Page: https://evoke-lmm.github.io/",
    "light_analysis": {
      "overview": "本研究提出了MMEVOKE基准来评估大型多模态模型在处理多模态演化知识注入中的能力，并通过知识增强与保留方法应对性能挑战。",
      "motivation": "大型多模态模型存储了大量预训练知识，但难以与现实世界的知识更新保持对齐，导致在获取演化知识时能力下降。当前研究主要集中在静态文本知识注入，忽略了动态多模态演化知识的重要性，这限制了模型在实际应用中的潜力。因此，探索多模态知识注入成为关键问题，以解决现有方法的不足并提升模型的适应能力。",
      "method": "研究首先设计了一个构建MMEVOKE基准的流程，该基准包含9,422个样本，覆盖159个子类型，专门用于评估LMMs在多模态演化知识注入中的表现。基于此基准，作者进行了广泛的实验，分析了现有知识注入方法的缺陷。核心创新在于引入了知识增强（如知识感知增强）和知识保留方法（如Data Replay和MoE），以优化模型的知识吸收和保持能力，避免性能退化。",
      "result": "实验使用MMEVOKE基准测试了LMMs，揭示了现有知识注入方法存在注入性能差和能力下降等挑战。知识增强方法被证明能够提升知识注入效果，而Data Replay和MoE方法有效缓解了模型能力退化问题。摘要未提供具体性能指标，但这些方法在实验中显示了显著的改进潜力，为未来研究提供了实证基础。",
      "conclusion": "本研究的核心贡献是构建了首个多模态演化知识注入基准MMEVOKE，并开发了知识增强与保留技术来解决相关挑战，推动了LMMs在动态知识更新领域的研究。其学术价值在于填补了多模态知识注入的空白，实际应用则有助于提升模型的实时适应能力。未来工作可探索更高效的注入策略或扩展应用到其他复杂场景。",
      "tags": [
        "Large Multimodal Models",
        "Multimodal Knowledge Injection",
        "Data Replay",
        "Mixture of Experts",
        "Knowledge Augmentation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:06.196820Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.24403",
    "title": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets",
    "authors": [
      "Giannis Nikolentzos",
      "Konstantinos Skianis"
    ],
    "abstract": "The Lipschitz constant of a neural network is connected to several important prop- erties of the network such as its robustness and generalization. It is thus useful in many settings to estimate the Lipschitz constant of a model. Prior work has fo- cused mainly on estimating the Lipschitz constant of multi-layer perceptrons and convolutional neural networks. Here we focus on data modeled as sets or multi- sets of vectors and on neural networks that can handle such data. These models typically apply some permutation invariant aggregation function, such as the sum, mean or max operator, to the input multisets to produce a single vector for each input sample. In this paper, we investigate whether these aggregation functions, along with an attention-based aggregation function, are Lipschitz continuous with respect to three distance functions for unordered multisets, and we compute their Lipschitz constants. In the general case, we find that each aggregation function is Lipschitz continuous with respect to only one of the three distance functions, while the attention-based function is not Lipschitz continuous with respect to any of them. Then, we build on these results to derive upper bounds on the Lipschitz constant of neural networks that can process multisets of vectors, while we also study their stability to perturbations and generalization under distribution shifts. To empirically verify our theoretical analysis, we conduct a series of experiments on datasets from different domains.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.24403.pdf",
    "abs_url": "https://arxiv.org/abs/2505.24403",
    "published": "2025-05-30T09:34:58Z",
    "updated": "2026-02-26T11:42:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文研究了集合聚合函数的 Lipschitz 连续性，为处理集合数据的神经网络提供了 Lipschitz 常数估计和稳定性分析框架。",
      "motivation": "神经网络的 Lipschitz 常数与模型鲁棒性和泛化性密切相关，因此估计该常数对评估模型性能至关重要。现有研究主要集中在传统神经网络如多层感知机和卷积神经网络上，而处理集合数据的神经网络（使用置换不变聚合函数的模型）的 Lipschitz 连续性研究不足。集合数据在点云处理、图数据分析等领域广泛应用，确保这些模型的稳定性和泛化性具有重要实际意义，本文旨在填补这一空白。",
      "method": "本研究分析了几种常见置换不变聚合函数（求和、均值、最大值）和注意力聚合函数，通过对比三种无序多重集距离函数，研究它们的 Lipschitz 连续性。关键创新点在于计算了这些聚合函数的 Lipschitz 常数，并发现每种聚合函数仅对一种距离函数是 Lipschitz 连续的，而注意力函数对所有距离函数均不连续。基于此，论文推导了处理向量多重集的神经网络 Lipschitz 常数的上界，并探讨了模型的扰动稳定性和分布偏移下的泛化性能。",
      "result": "通过理论分析，论文证明了集合聚合函数在特定距离函数下是 Lipschitz 连续的，并精确计算了 Lipschitz 常数。例如，每种聚合函数只对一种距离函数保持连续性，而注意力函数则不具备 Lipschitz 连续性。在多领域数据集上的实验验证了理论推导，表明该分析增强了模型在扰动下的稳定性和泛化性，与现有方法相比，首次提供了集合数据处理网络的 Lipschitz 常数估计。",
      "conclusion": "本文的主要贡献在于系统分析了集合聚合函数的 Lipschitz 连续性，并推导了相关神经网络的 Lipschitz 常数上界，扩展了 Lipschitz 连续性理论到集合数据领域。这为评估模型鲁棒性和泛化性提供了新工具，有助于改进点云处理、图神经网络等应用。局限性可能在于只考虑特定距离函数，未来工作可探索更多距离度量或改进注意力聚合函数的 Lipschitz 性质。",
      "tags": [
        "Lipschitz Constant",
        "Set Aggregation Functions",
        "Attention Mechanism",
        "Multiset Distance",
        "Robustness Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:10.409654Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.23400",
    "title": "Bridging Geometric and Semantic Foundation Models for Generalized Monocular Depth Estimation",
    "authors": [
      "Sanggyun Ma",
      "Wonjoon Choi",
      "Jihun Park",
      "Jaeyeul Kim",
      "Seunghun Lee",
      "Jiwan Seo",
      "Sunghoon Im"
    ],
    "abstract": "We present Bridging Geometric and Semantic (BriGeS), an effective method that fuses geometric and semantic information within foundation models to enhance Monocular Depth Estimation (MDE). Central to BriGeS is the Bridging Gate, which integrates the complementary strengths of depth and segmentation foundation models. This integration is further refined by our Attention Temperature Scaling technique. It finely adjusts the focus of the attention mechanisms to prevent over-concentration on specific features, thus ensuring balanced performance across diverse inputs. BriGeS capitalizes on pre-trained foundation models and adopts a strategy that focuses on training only the Bridging Gate. This method significantly reduces resource demands and training time while maintaining the model's ability to generalize effectively. Extensive experiments across multiple challenging datasets demonstrate that BriGeS outperforms state-of-the-art methods in MDE for complex scenes, effectively handling intricate structures and overlapping objects.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2505.23400.pdf",
    "abs_url": "https://arxiv.org/abs/2505.23400",
    "published": "2025-05-29T12:38:36Z",
    "updated": "2026-02-26T06:04:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出BriGeS方法，通过融合几何和语义基础模型，利用Bridging Gate和Attention Temperature Scaling技术，提高单目深度估计的泛化能力。",
      "motivation": "单目深度估计是计算机视觉中的关键任务，广泛应用于自动驾驶、机器人和增强现实等领域。然而，现有方法在处理复杂场景（如精细结构和重叠对象）时性能受限，泛化能力不足。几何信息（深度）和语义信息（分割）具有互补性，但传统方法未能有效整合这两种信息，导致估计误差增加。因此，本研究旨在通过融合几何和语义基础模型，提升MDE在复杂场景下的准确性和鲁棒性。",
      "method": "BriGeS方法的核心是Bridging Gate，它集成预训练的深度基础模型和语义分割基础模型的输出，以融合几何和语义信息。创新点包括Attention Temperature Scaling技术，通过调整注意力机制的温度参数，精细化控制注意力分布，防止过度集中于特定特征，确保平衡性能。方法利用预训练模型，仅训练Bridging Gate部分，大大减少了计算资源和训练时间，同时保持了模型的泛化能力。",
      "result": "通过多个挑战性数据集的广泛实验，BriGeS方法在单目深度估计任务中优于现有的最先进方法。摘要未明确说明具体性能指标，如误差降低百分比或准确率提升，但指出该方法能有效处理复杂场景中的精细结构和重叠对象，展示了更强的泛化能力和鲁棒性。结果验证了融合几何和语义信息对提升MDE性能的重要性。",
      "conclusion": "BriGeS成功融合了几何和语义基础模型，通过Bridging Gate和Attention Temperature Scaling技术，显著提升了单目深度估计的性能和泛化能力。该方法在保持高准确率的同时，通过轻量级训练策略降低了资源需求，具有重要的学术价值，为视觉任务提供了新的融合策略。未来工作可能包括扩展到其他视觉任务，或进一步优化注意力机制以提高计算效率。",
      "tags": [
        "Monocular Depth Estimation",
        "Foundation Models",
        "Attention Mechanisms",
        "Segmentation",
        "Geometric Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:12.856668Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.19792",
    "title": "Types of Relations: Defining Analogies with Category Theory",
    "authors": [
      "Claire Ott",
      "Frank Jäkel"
    ],
    "abstract": "In order to behave intelligently both humans and machines have to represent their knowledge adequately for how it is used. Humans often use analogies to transfer their knowledge to new domains, or help others with this transfer via explanations. Hence, an important question is: What representation can be used to construct, find, and evaluate analogies? In this paper, we study features of a domain that are important for constructing analogies. We do so by formalizing knowledge domains as categories. We use the well-known example of the analogy between the solar system and the hydrogen atom to demonstrate how to construct domain categories. We also show how functors, pullbacks, and pushouts can be used to define an analogy, describe its core and a corresponding blend of the underlying domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.19792.pdf",
    "abs_url": "https://arxiv.org/abs/2505.19792",
    "published": "2025-05-26T10:22:44Z",
    "updated": "2026-02-26T11:22:42Z",
    "comment": "27 pages, 15 figures",
    "light_analysis": {
      "overview": "本文提出使用范畴论来形式化知识领域并定义类比，为核心问题提供数学框架。",
      "motivation": "类比在人类和机器的智能行为中至关重要，它帮助将知识迁移到新领域或通过解释辅助他人。现有方法往往缺乏严格的数学表示，导致类比构建和评估的效率低下。因此，本研究旨在探索如何使用范畴论来形式化知识领域，以解决类比表示的核心问题，提升其可计算性和应用价值。本研究的动机源于对更可靠类比框架的需求，以弥补现有方法的不足。",
      "method": "本研究采用范畴论作为工具，将知识领域形式化为范畴。具体地，通过构建领域范畴，例如太阳系和氢原子的类比案例，展示如何定义类比。核心方法包括使用函子来映射不同领域，以及利用拉回和推出操作来描述类比的核心结构和领域融合。创新点在于将抽象的范畴论概念应用于类比理论，提供了一个数学严谨的框架，并详细阐述了技术实施步骤。",
      "result": "摘要未明确说明具体的实验结果或性能指标。本研究通过理论推导和示例演示，展示了如何使用范畴论工具（如函子、拉回和推出）来定义和构建类比，为类比的形式化提供了数学基础。这为后续研究提供了理论基础，但缺乏量化数据或与基线方法的对比分析，因此结果部分侧重于概念验证和理论阐述。",
      "conclusion": "本文的主要贡献是提出了一种基于范畴论的类比形式化框架，通过将知识领域建模为范畴并使用函子、拉回和推出操作，定义了类比的结构和核心。其学术价值在于为类比理论提供了数学严谨性，促进其在人工智能和认知科学中的应用。实际应用可能包括改进机器学习和知识表示系统。未来工作可扩展该框架到更复杂领域或结合其他数学工具，以解决潜在局限性。",
      "tags": [
        "Category Theory",
        "Functors",
        "Pullbacks",
        "Pushouts",
        "Analogies"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:18.843270Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.17517",
    "title": "The Spacetime of Diffusion Models: An Information Geometry Perspective",
    "authors": [
      "Rafał Karczewski",
      "Markus Heinonen",
      "Alison Pouplin",
      "Søren Hauberg",
      "Vikas Garg"
    ],
    "abstract": "We present a novel geometric perspective on the latent space of diffusion models. We first show that the standard pullback approach, utilizing the deterministic probability flow ODE decoder, is fundamentally flawed. It provably forces geodesics to decode as straight segments in data space, effectively ignoring any intrinsic data geometry beyond the ambient Euclidean space. Complementing this view, diffusion also admits a stochastic decoder via the reverse SDE, which enables an information geometric treatment with the Fisher-Rao metric. However, a choice of $x_T$ as the latent representation collapses this metric due to memorylessness. We address this by introducing a latent spacetime $z=(x_t,t)$ that indexes the family of denoising distributions $p(x_0 | x_t)$ across all noise scales, yielding a nontrivial geometric structure. We prove these distributions form an exponential family and derive simulation-free estimators for curve lengths, enabling efficient geodesic computation. The resulting structure induces a principled Diffusion Edit Distance, where geodesics trace minimal sequences of noise and denoise edits between data. We also demonstrate benefits for transition path sampling in molecular systems, including constrained variants such as low-variance transitions and region avoidance. Code is available at: https://github.com/rafalkarczewski/spacetime-geometry.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.17517.pdf",
    "abs_url": "https://arxiv.org/abs/2505.17517",
    "published": "2025-05-23T06:16:58Z",
    "updated": "2026-02-26T18:04:18Z",
    "comment": "ICLR 2026 (Oral)",
    "light_analysis": {
      "overview": "论文提出了一种新的几何视角，通过引入潜在时空来改进扩散模型的几何结构，实现高效的测地线计算和扩散编辑距离。",
      "motivation": "扩散模型在潜在空间的几何处理中存在缺陷，标准pullback方法使用确定性的概率流ODE解码器，强制测地线在数据空间中解码为直线，忽略了数据的内在几何结构，从而限制了模型在编辑和采样任务中的应用。为了解决这一问题，研究从信息几何角度出发，旨在提供更准确的几何表示，以增强模型在科学计算等领域中的实用性。",
      "method": "论文基于信息几何理论，引入潜在时空z=(x_t,t)来索引所有噪声尺度下的去噪分布族p(x_0 | x_t)，证明这些分布形成指数族。使用Fisher-Rao度量，推导了无模拟的曲线长度估计器，实现高效的测地线计算。核心创新在于通过随机解码器（反向SDE）避免了标准方法的缺陷，为扩散模型建立了非平凡的几何结构。",
      "result": "该方法定义了扩散编辑距离，其中测地线能追踪数据之间噪声和去噪编辑的最小序列，提高了编辑效率。在分子系统过渡路径采样中，展示了其好处，包括实现低方差过渡和区域避免等约束变体，提升了采样性能。摘要未明确说明具体性能指标数据，但指出该方法在几何计算和采样任务中表现出优势。",
      "conclusion": "研究的主要贡献是提出了一个新的几何框架，改进了扩散模型的潜在空间表示，具有理论价值和实际应用意义，如在分子系统采样中提供更高效的路径计算。潜在局限性可能包括计算复杂度或适用范围，未来工作可扩展到更多领域，如数据生成和模型解释。该研究为扩散模型的几何分析奠定了基础。",
      "tags": [
        "Diffusion Models",
        "Information Geometry",
        "Fisher-Rao Metric",
        "Latent Spacetime",
        "Geodesic Computation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:13.765882Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.16164",
    "title": "Can LLMs Simulate Human Behavioral Variability? A Case Study in the Phonemic Fluency Task",
    "authors": [
      "Mengyang Qiu",
      "Zoe Brisebois",
      "Siena Sun"
    ],
    "abstract": "Large language models (LLMs) are increasingly explored as substitutes for human participants in cognitive tasks, but their ability to simulate human behavioral variability remains unclear. This study examines whether LLMs can approximate individual differences in the phonemic fluency task, where participants generate words beginning with a target letter. We evaluated 34 distinct models across 45 configurations from major closed-source and open-source providers, and compared outputs to responses from 106 human participants. While some models, especially Claude 3.7 Sonnet, approximated human averages and lexical preferences, none reproduced the scope of human variability. LLM outputs were consistently less diverse, with newer models and thinking-enabled modes often reducing rather than increasing variability. Network analysis further revealed fundamental differences in retrieval structure between humans and the most human-like model. Ensemble simulations combining outputs from diverse models also failed to recover human-level diversity, likely due to high vocabulary overlap across models. These results highlight key limitations in using LLMs to simulate human cognition and behavior.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.16164.pdf",
    "abs_url": "https://arxiv.org/abs/2505.16164",
    "published": "2025-05-22T03:08:27Z",
    "updated": "2026-02-26T10:34:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究发现大型语言模型在模拟人类音位流畅性任务中的行为变异性时存在显著局限性，揭示了其在认知模拟中的不足。",
      "motivation": "随着大型语言模型逐渐被用作认知任务中人类参与者的替代品，但其能否模拟人类行为变异性尚不明确。该研究针对音位流畅性任务（参与者生成以目标字母开头的单词），旨在检验LLMs是否能够近似个体差异。现有方法的不足之处在于LLMs在模拟人类多样性和随机性方面的能力缺乏系统验证，而这个问题对认知科学和人工智能应用具有重要意义，因为准确模拟人类行为对心理学实验设计、教育工具开发等领域至关重要。摘要未明确说明更广泛的背景细节，但暗示了LLMs在认知任务中的应用趋势。",
      "method": "研究方法包括一个案例研究，专注于音位流畅性任务，通过对比LLM输出与人类响应的方式评估变异性。具体技术路线涉及评估34个不同的模型和45种配置，这些模型来自主要封闭源和开放源提供商，并使用106名人类参与者的数据作为基准。关键创新点包括网络分析来揭示人类和模型在词汇检索结构上的差异，以及集成模拟技术结合多个模型的输出以尝试恢复人类水平的多样性。摘要未明确说明具体数据集或模型架构的细节，但强调了系统比较和多模型评估的策略。",
      "result": "主要实验结果表明，尽管部分模型如Claude 3.7 Sonnet能够接近人类平均值和词汇偏好，但所有LLM输出均未能完全重现人类行为变异性，其多样性显著较低。具体而言，较新模型和启用思考模式的模型往往减少了而非增加了变异性；网络分析进一步揭示人类与最类人模型在检索结构上存在根本差异。此外，集成模拟结合不同模型的输出也未能达到人类水平的多样性，这可能由于模型间词汇高度重叠所致。摘要未提供具体性能指标如准确率提升，但强调LLMs在变异性模拟方面的持续不足。",
      "conclusion": "论文的主要贡献在于揭示了大型语言模型在模拟人类认知和行为变异性方面的关键限制，强调了当前LLMs不能替代人类参与者在认知任务中的个体差异模拟。该研究的学术价值在于为认知科学和人工智能交叉领域提供了实证证据，指出了模型设计中的改进方向，如增强多样性和随机性。实际应用价值包括提醒研究者在使用LLMs进行心理学实验或行为分析时需谨慎。潜在的局限性是仅聚焦于音位流畅性任务，未来工作可能扩展到其他认知任务或开发更高级的变异性模拟技术。",
      "tags": [
        "Large Language Models",
        "Phonemic Fluency Task",
        "Behavioral Variability",
        "Network Analysis",
        "Model Ensembles"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:18.000075Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.14479",
    "title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach",
    "authors": [
      "Oren Sultan",
      "Eitan Stern",
      "Dafna Shahaf"
    ],
    "abstract": "Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.14479.pdf",
    "abs_url": "https://arxiv.org/abs/2505.14479",
    "published": "2025-05-20T15:13:32Z",
    "updated": "2026-02-26T11:56:20Z",
    "comment": "long paper",
    "light_analysis": {
      "overview": "本文提出一种神经符号方法，通过结合大型语言模型的生成能力和形式验证器，显著提高数学证明生成的可靠性。",
      "motivation": "大型语言模型（LLMs）在需要严格逻辑推理和符号推理的正式领域，如数学证明生成，存在显著挑战。这些问题的重要性在于，证明生成要求高可靠性和准确性，对于复杂任务（如自动定理证明）和关键应用（如科学计算、教育）至关重要。现有LLMs缺乏符号推理能力，容易生成错误或不合逻辑的证明，导致在正式领域的应用受限。因此，研究目标是克服这一局限性，开发更可靠的LLM方法，以支持需要信任的真实世界应用。",
      "method": "论文提出一种神经符号方法，结合LLMs的生成优势和结构化组件，提升证明生成的准确性。以几何问题为例，方法包括两个核心步骤：一是检索类似问题及其证明，用于指导LLM生成过程；二是引入形式验证器，评估生成的证明并提供反馈，帮助模型修正错误。关键创新点在于集成符号推理（通过验证器）和神经生成，增强逻辑严谨性。使用OpenAI的o1模型作为基础模型，并在几何问题数据集上实施类比检索和验证反馈机制，具体组件不涉及复杂架构，但聚焦于检索和验证的交互。",
      "result": "实验结果表明，该方法显著提高了证明生成的准确性。在OpenAI o1模型上，证明准确率提升了58%至70%。这些改进主要归功于类似问题的检索和形式验证器的反馈，两者都贡献了性能增益。与基线方法（标准LLM相比），该方法展现出明显的性能优势，验证了神经符号方法的有效性。摘要未提供具体基线对比细节，但强调了在几何问题上的显著改进，说明该方法能够有效减少错误证明的生成。",
      "conclusion": "本研究的主要贡献是提出并验证了一种神经符号方法，用于增强LLMs在数学证明生成中的可靠性。通过结合类比检索和形式验证，该方法提高了模型的逻辑推理能力，具有学术价值，推动了神经符号集成研究。实际应用价值在于提升LLMs的可靠性、准确性和一致性，使其能应用于需要高信任的复杂任务，如自动定理证明和关键决策系统。局限性包括可能仅适用于特定领域（如几何），未来工作可扩展到其他符号推理领域，并进一步优化验证和检索机制。",
      "tags": [
        "Large Language Models",
        "Neuro-Symbolic Learning",
        "Formal Verification",
        "Geometry Problem Solving",
        "Proof Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:35.117763Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.08371",
    "title": "Density Ratio-based Causal Discovery from Bivariate Continuous-Discrete Data",
    "authors": [
      "Takashi Nicholas Maeda",
      "Shohei Shimizu",
      "Hidetoshi Matsui"
    ],
    "abstract": "We address the problem of inferring the causal direction between a continuous variable $X$ and a discrete variable $Y$ from observational data. For the model $X \\to Y$, we adopt the threshold model used in prior work. For the model $Y \\to X$, we consider two cases: (1) the conditional distributions of $X$ given different values of $Y$ form a location-shift family, and (2) they are mixtures of generalized normal distributions with independently parameterized components. We establish identifiability of the causal direction through three theoretical results. First, we prove that under $X \\to Y$, the density ratio of $X$ conditioned on different values of $Y$ is monotonic. Second, we establish that under $Y \\to X$ with non-location-shift conditionals, monotonicity of the density ratio holds only on a set of Lebesgue measure zero in the parameter space. Third, we show that under $X \\to Y$, the conditional distributions forming a location-shift family requires a precise coordination between the causal mechanism and input distribution, which is non-generic under the principle of independent mechanisms. Together, these results imply that monotonicity of the density ratio characterizes the direction $X \\to Y$, whereas non-monotonicity or location-shift conditionals characterizes $Y \\to X$. Based on this, we propose Density Ratio-based Causal Discovery (DRCD), a method that determines causal direction by testing for location-shift conditionals and monotonicity of the estimated density ratio. Experiments on synthetic and real-world datasets demonstrate that DRCD outperforms existing methods.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.08371.pdf",
    "abs_url": "https://arxiv.org/abs/2505.08371",
    "published": "2025-05-13T09:18:41Z",
    "updated": "2026-02-26T12:20:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于密度比的因果发现方法DRCD，利用密度比的单调性和位置偏移条件推断连续-离散变量之间的因果方向。",
      "motivation": "研究动机是解决从观测数据中推断连续变量X和离散变量Y之间因果方向的问题。因果发现在生物信息学、经济学等领域至关重要，但现有方法在处理混合分布或非标准条件时可能缺乏理论保证或泛化能力，导致推断不准确。本文旨在提供一种具有严格理论支撑的方法，以提高因果方向推断的可靠性和适用性。",
      "method": "论文提出密度比基于因果发现（DRCD）方法，核心基于三个理论结果：在X→Y下，条件密度比单调；在Y→X下非位置偏移条件时，单调性仅在参数空间零测集成立；X→Y下位置偏移条件需要特定协调，在独立机制原则下非泛型。DRCD通过测试条件分布是否为位置偏移族和估计密度比是否单调来确定因果方向，针对X→Y采用阈值模型，针对Y→X考虑位置偏移或广义正态混合分布。",
      "result": "在合成和真实世界数据集上的实验表明，DRCD方法优于现有方法。摘要未提供具体性能指标数据，但明确指出该方法在实验中表现更优，验证了其有效性和泛化能力，证明了基于密度比的理论框架在实际场景中的优势。",
      "conclusion": "本文主要贡献是提出DRCD方法，基于密度比的单调性和位置偏移条件推断因果方向，并提供理论证明。该研究扩展了因果发现的理论基础，具有学术价值，并为实际因果推断问题提供新工具。未来工作可能包括扩展方法到更复杂变量类型或放松假设。",
      "tags": [
        "Causal Discovery",
        "Density Ratio",
        "Monotonicity",
        "Location-shift Family",
        "Independent Mechanisms"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:37.149930Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.07734",
    "title": "LAMM-ViT: AI Face Detection via Layer-Aware Modulation of Region-Guided Attention",
    "authors": [
      "Jiangling Zhang",
      "Weijie Zhu",
      "Jirui Huang",
      "Yaxiong Chen"
    ],
    "abstract": "Detecting AI-synthetic faces presents a critical challenge: it is hard to capture consistent structural relationships between facial regions across diverse generation techniques. Current methods, which focus on specific artifacts rather than fundamental inconsistencies, often fail when confronted with novel generative models. To address this limitation, we introduce Layer-aware Mask Modulation Vision Transformer (LAMM-ViT), a Vision Transformer designed for robust facial forgery detection. This model integrates distinct Region-Guided Multi-Head Attention (RG-MHA) and Layer-aware Mask Modulation (LAMM) components within each layer. RG-MHA utilizes facial landmarks to create regional attention masks, guiding the model to scrutinize architectural inconsistencies across different facial areas. Crucially, the separate LAMM module dynamically generates layer-specific parameters, including mask weights and gating values, based on network context. These parameters then modulate the behavior of RG-MHA, enabling adaptive adjustment of regional focus across network depths. This architecture facilitates the capture of subtle, hierarchical forgery cues ubiquitous among diverse generation techniques, such as GANs and Diffusion Models. In cross-model generalization tests, LAMM-ViT demonstrates superior performance, achieving 94.09% mean ACC (a +5.45% improvement over SoTA) and 98.62% mean AP (a +3.09% improvement). These results demonstrate LAMM-ViT's exceptional ability to generalize and its potential for reliable deployment against evolving synthetic media threats.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2505.07734.pdf",
    "abs_url": "https://arxiv.org/abs/2505.07734",
    "published": "2025-05-12T16:42:19Z",
    "updated": "2026-02-26T15:30:36Z",
    "comment": "Accepted to ECAI 2025",
    "light_analysis": {
      "overview": "LAMM-ViT通过集成区域引导注意力和层感知调制组件，提升了AI合成面孔检测的泛化性能和鲁棒性。",
      "motivation": "检测AI合成面孔面临关键挑战：不同生成技术导致面部区域间结构关系不一致，现有方法通常关注特定伪影而非基本不一致性，因此在面对新生成模型如GANs和扩散模型时表现不佳。随着AI生成技术快速发展，合成媒体威胁日益严重，开发鲁棒的检测方法以捕捉跨模型的结构异常变得至关重要，解决这一实际问题有助于防止虚假信息传播和身份欺诈。",
      "method": "论文提出LAMM-ViT模型，基于Vision Transformer架构，关键创新包括区域引导多头部注意力和层感知掩码调制。RG-MHA利用面部关键点生成区域注意力掩码，指导模型聚焦于面部区域的结构不一致性；LAMM模块动态生成层特定参数，如掩码权重和门控值，基于网络上下文调制RG-MHA行为，实现跨网络深度的自适应区域焦点调整，从而有效捕捉GANs和扩散模型中的微妙伪造线索。",
      "result": "在跨模型泛化测试中，LAMM-ViT展现优越性能，平均准确率达到94.09%，比现有最佳方法提升5.45%；平均平均精度为98.62%，提升3.09%。这些数据表明模型在泛化到未见过的生成模型时具有显著优势，证实了其鲁棒性和应对多样化合成媒体威胁的潜力。",
      "conclusion": "论文的主要贡献是提出LAMM-ViT模型，通过层感知调制区域引导注意力，增强了AI合成面孔检测的泛化能力。研究不仅推动了AI伪造检测的学术进展，还为实际应用提供了可靠工具以对抗演进中的合成媒体风险，未来工作可探索模型优化或扩展到其他伪造检测任务，以进一步提升适应性。",
      "tags": [
        "Vision Transformer",
        "Region-Guided Attention",
        "Layer-aware Modulation",
        "AI Face Detection",
        "Cross-model Generalization"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:49.276064Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.04733",
    "title": "Conformal Prediction with Corrupted Labels: Uncertain Imputation and Robust Re-weighting",
    "authors": [
      "Shai Feldman",
      "Stephen Bates",
      "Yaniv Romano"
    ],
    "abstract": "We introduce a framework for robust uncertainty quantification in situations where labeled training data are corrupted, through noisy or missing labels. We build on conformal prediction, a statistical tool for generating prediction sets that cover the test label with a pre-specified probability. The validity of conformal prediction, however, holds under the i.i.d assumption, which does not hold in our setting due to the corruptions in the data. To account for this distribution shift, the privileged conformal prediction (PCP) method proposed leveraging privileged information (PI) -- additional features available only during training -- to re-weight the data distribution, yielding valid prediction sets under the assumption that the weights are accurate. In this work, we analyze the robustness of PCP to inaccuracies in the weights. Our analysis indicates that PCP can still yield valid uncertainty estimates even when the weights are poorly estimated. Furthermore, we introduce uncertain imputation (UI), a new conformal method that does not rely on weight estimation. Instead, we impute corrupted labels in a way that preserves their uncertainty. Our approach is supported by theoretical guarantees and validated empirically on both synthetic and real benchmarks. Finally, we show that these techniques can be integrated into a triply robust framework, ensuring statistically valid predictions as long as at least one underlying method is valid.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.04733.pdf",
    "abs_url": "https://arxiv.org/abs/2505.04733",
    "published": "2025-05-07T18:46:02Z",
    "updated": "2026-02-26T18:16:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种通过 uncertain imputation 处理 corrupted labels 的新 conformal prediction 方法，并分析 PCP 对权重不准确的鲁棒性，集成三重稳健框架。",
      "motivation": "在实际应用中，标签数据常因噪声或缺失而损坏，传统 conformal prediction 方法依赖 i.i.d 假设，这在数据损坏时失效，导致不确定性量化不稳健。现有方法如 PCP 利用特权信息重新加权数据分布，但要求权重准确，而权重估计可能不准确。本研究旨在解决这一问题，通过分析 PCP 的鲁棒性和开发新方法，以更稳健地处理损坏标签，提升预测可靠性。",
      "method": "本研究首先理论分析 PCP 方法在权重不准确情况下的鲁棒性，探讨其有效性边界。其次，引入 uncertain imputation (UI) 技术，通过 impute 损坏标签时保留不确定性，避免依赖权重估计。方法基于理论保证，并在合成和真实数据集（摘要未明确说明具体名称）上进行实证验证，最终集成 PCP 和 UI 到三重稳健框架，确保至少一种方法有效时的统计有效性。",
      "result": "理论分析表明，即使在权重估计不准确的情况下，PCP 仍能产生有效的不确定性估计，鲁棒性较强。UI 方法在合成和真实基准测试中展示出稳健性能，验证了其有效性，避免了 PCP 对权重的依赖。集成框架进一步提升了预测可靠性，但与基线方法的对比细节，摘要未提供具体性能指标如准确率或效率数据。",
      "conclusion": "本研究的主要贡献是开发了 robust uncertainty quantification 框架，包括 PCP 鲁棒性分析和 UI 新方法，为处理 corrupted labels 提供了新途径。理论和实证支持增强了其学术价值，实际应用中可提升预测的稳健性。未来工作可扩展至更多应用场景和数据类型，局限性在于摘要未明确说明具体数据集和性能细节。",
      "tags": [
        "Conformal Prediction",
        "Privileged Information",
        "Uncertain Imputation",
        "Robust Re-weighting",
        "Corrupted Labels"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:58.569057Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.04317",
    "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning",
    "authors": [
      "Ruize Zhang",
      "Sirui Xiang",
      "Zelai Xu",
      "Feng Gao",
      "Shilong Ji",
      "Wenhao Tang",
      "Wenbo Ding",
      "Chao Yu",
      "Yu Wang"
    ],
    "abstract": "In this paper, we tackle the problem of learning to play 3v3 multi-drone volleyball, a new embodied competitive task that requires both high-level strategic coordination and low-level agile control. The task is turn-based, multi-agent, and physically grounded, posing significant challenges due to its long-horizon dependencies, tight inter-agent coupling, and the underactuated dynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play (HCSP), a hierarchical reinforcement learning framework that separates centralized high-level strategic decision-making from decentralized low-level motion control. We design a three-stage population-based training pipeline to enable both strategy and skill to emerge from scratch without expert demonstrations: (I) training diverse low-level skills, (II) learning high-level strategy via self-play with fixed low-level skills, and (III) joint fine-tuning through co-self-play. Experiments show that HCSP achieves superior performance, outperforming non-hierarchical self-play and rule-based hierarchical baselines with an average 82.9% win rate and a 71.5% win rate against the two-stage variant. Moreover, co-self-play leads to emergent team behaviors such as role switching and coordinated formations, demonstrating the effectiveness of our hierarchical design and training scheme. The project page is at https://hi-co-self-play.github.io.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.04317.pdf",
    "abs_url": "https://arxiv.org/abs/2505.04317",
    "published": "2025-05-07T11:04:36Z",
    "updated": "2026-02-26T07:37:05Z",
    "comment": "Accepted by CoRL 2025",
    "light_analysis": {
      "overview": "本文提出一种分层协同自玩强化学习框架，用于解决多无人机排球任务中高层策略协调与底层敏捷控制的挑战。",
      "motivation": "研究旨在解决3v3多无人机排球这一具身竞争任务，该任务要求智能体实现高层战略协调和底层敏捷控制。由于任务的长期依赖性、紧密智能体耦合以及四旋翼无人机的欠驱动动力学，现有方法难以有效处理，因此开发新的强化学习框架至关重要，以克服这些复杂挑战并推动多智能体系统的发展。",
      "method": "方法采用 Hierarchical Co-Self-Play (HCSP) 分层强化学习框架，将集中的高层战略决策与分散的底层运动控制分离。通过设计三阶段基于种群的训练管道：首先训练多样化的底层技能，其次通过自玩学习高层策略固定底层技能，最后利用协同自玩进行联合微调，使策略和技能从零开始涌现，无需专家演示。关键创新在于分层次结构化和协同训练机制。",
      "result": "实验结果证实 HCSP 性能优越，平均胜率达到 82.9%，对两阶段变体的胜率为 71.5%，优于非分层自玩和基于规则的分层基线。此外，协同自玩导致涌现的团队行为，如角色切换和协调队形，进一步验证了方法的有效性。",
      "conclusion": "本文成功应用分层协同自玩强化学习于多无人机排球任务，展示了其在复杂多智能体系统中的潜力，贡献在于分层设计策略和协同自玩训练方案，具有学术价值和实际应用前景。未来工作可探索其他具身任务或改进方法的泛化性，尽管摘要未明确说明局限性。",
      "tags": [
        "Hierarchical Reinforcement Learning",
        "Self-Play",
        "Multi-Agent Systems",
        "Co-Self-Play",
        "Drone Control"
      ]
    },
    "analyzed_at": "2026-02-27T03:56:59.220048Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.18594",
    "title": "RaPA: Enhancing Transferable Targeted Attacks via Random Parameter Pruning",
    "authors": [
      "Tongrui Su",
      "Qingbin Li",
      "Shengyu Zhu",
      "Wei Chen",
      "Xueqi Cheng"
    ],
    "abstract": "Compared to untargeted attacks, targeted transfer-based attack is still suffering from much lower Attack Success Rates (ASRs), although significant improvements have been achieved by kinds of methods, such as diversifying input, stabilizing the gradient, and re-training surrogate models. In this paper, we find that adversarial examples generated by existing methods rely heavily on a small subset of surrogate model parameters, which in turn limits their transferability to unseen target models. Inspired by this, we propose the Random Parameter Pruning Attack (RaPA), which introduces parameter-level randomization during the attack process. At each optimization step, RaPA randomly prunes model parameters to generate diverse yet semantically consistent surrogate variants.We show this parameter-level randomization is equivalent to adding an importance-equalization regularizer, thereby alleviating the over-reliance issue. Extensive experiments across both CNN and Transformer architectures demonstrate that RaPA substantially enhances transferability. In the challenging case of transferring from CNN-based to Transformer-based models, RaPA achieves up to 11.7% higher average ASRs than state-of-the-art baselines(with 33.3% ASRs), while being training-free, cross-architecture efficient, and easily integrated into existing attack frameworks. Code is available in https://github.com/molarsu/RaPA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2504.18594.pdf",
    "abs_url": "https://arxiv.org/abs/2504.18594",
    "published": "2025-04-24T12:29:23Z",
    "updated": "2026-02-26T04:32:35Z",
    "comment": "Accepted by CVPR26 CODE:https://github.com/molarsu/RaPA",
    "light_analysis": {
      "overview": "本论文提出RaPA方法，通过随机参数剪枝增强目标性对抗攻击的传递性，有效提升攻击成功率。",
      "motivation": "目标性传递攻击的攻击成功率远低于无目标攻击，尽管已有多种改进方法如输入多样化、梯度稳定和重新训练替代模型，但对抗示例仍过度依赖于替代模型参数的特定子集，这限制了其在未见目标模型上的传递性。此问题在对抗攻击研究中极为重要，因为传递性是评估攻击普适性的关键，现有方法的过度依赖导致攻击效率低下，尤其是在跨模型架构场景下。本文基于此发现，旨在解决参数过度依赖的瓶颈，提升攻击的跨模型有效性。",
      "method": "RaPA方法引入参数级随机化，在攻击优化过程中，每个步骤随机剪枝模型参数以生成多样化的替代模型变体，同时保持语义一致性。核心创新在于将参数随机化解释为重要性均衡正则化器，通过均匀化参数依赖来缓解过度依赖问题。该方法免训练，适用于CNN和Transformer等不同架构，易于集成到现有对抗攻击框架中，无需额外模型训练，从而提高攻击的灵活性和效率。",
      "result": "在CNN和Transformer架构上的广泛实验表明，RaPA显著提升了目标性对抗攻击的传递性。具体而言，在从CNN模型传递到Transformer模型的挑战性场景中，RaPA的平均攻击成功率比最先进基线高出11.7%（基线为33.3%），这体现了其在跨架构攻击中的优越性。此外，RaPA展现出免训练和高效的特性，代码已开源，便于复现和应用，为对抗攻击研究提供了实际验证。",
      "conclusion": "本研究通过RaPA方法成功提升目标性对抗攻击的传递性，解决了参数过度依赖的核心问题，具有重要的学术价值和实际应用意义。学术上，它揭示了参数均衡正则化在攻击传递中的作用；实践上，RaPA易于集成到现有框架，促进了对抗攻击技术的发展。未来工作可探索更多模型架构和剪枝策略的优化，以进一步提高性能并适应更复杂的攻击场景。",
      "tags": [
        "Adversarial Attacks",
        "Targeted Attacks",
        "Transferability",
        "Random Parameter Pruning",
        "Regularization"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:08.435106Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.13359",
    "title": "Cost-of-Pass: An Economic Framework for Evaluating Language Models",
    "authors": [
      "Mehmet Hamza Erol",
      "Batu El",
      "Mirac Suzgun",
      "Mert Yuksekgonul",
      "James Zou"
    ],
    "abstract": "Widespread adoption of AI systems hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics accounting for both performance and costs. Building on production theory, we develop an economically grounded framework to evaluate language models' productivity by combining accuracy and inference cost. We formalize cost-of-pass: the expected monetary cost of generating a correct solution. We then define the frontier cost-of-pass: the minimum cost-of-pass achievable across available models or the human-expert(s), using the approx. cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking the frontier cost-of-pass over the past year reveals significant progress, particularly for complex quant. tasks where the cost roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers -- estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quant., knowledge-intensive, and complex quant. tasks, respectively. Finally, we assess the cost-reductions from common inference-time techniques (majority voting and self-refinement), and a budget-aware technique (TALE-EP). We find that performance-oriented methods with marginal performance gains rarely justify the costs, while TALE-EP shows some promise. Overall, our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency and our framework provides a principled tool for measuring this progress and guiding deployment.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2504.13359.pdf",
    "abs_url": "https://arxiv.org/abs/2504.13359",
    "published": "2025-04-17T21:58:29Z",
    "updated": "2026-02-26T05:45:42Z",
    "comment": "Code is available at: https://github.com/mhamzaerol/Cost-of-Pass",
    "light_analysis": {
      "overview": "论文提出了一种基于生产理论的经济框架，通过形式化成本传递指标，综合评估语言模型的生产力和成本效益。",
      "motivation": "AI系统的广泛应用依赖于其经济价值能否超过推理成本，但现有评估指标通常只关注性能，忽视了成本因素。这导致部署决策缺乏经济依据，可能造成资源浪费。因此，本研究旨在开发一个经济基础框架，将语言模型的准确性与推理成本结合，以解决现有方法的不足，提供更全面的评估工具，优化AI系统的实际采用。",
      "method": "本研究基于生产理论构建了一个经济框架，结合语言模型的准确性和推理成本来评估其生产力。首先，形式化了“成本传递”指标，定义为生成正确解决方案的预期货币成本；其次，定义了“前沿成本传递”，计算所有可用模型或人类专家中的最小成本，以人类专家成本为基准。此外，通过反事实前沿分析评估不同模型类别对成本效率进步的贡献，并测试了推理时间技术如多数投票、自我优化和TALE-EP的成本影响。",
      "result": "分析显示，不同任务类型的成本效益模型不同：轻量级模型在基础定量任务中最优，大型模型在知识密集型任务中表现突出，推理模型在复杂定量问题中更具优势。过去一年中，前沿成本传递显著下降，特别是复杂定量任务的成本大约每几个月减半。推理时间技术评估表明，TALE-EP在控制成本方面显示出潜力，而多数投票和自优化等方法由于额外成本过高，往往难以证明其效益。",
      "conclusion": "本研究的主要贡献是提出了一个经济框架，强调了互补模型级创新在提升语言模型成本效率中的核心作用。该框架为衡量技术进步提供了原则性工具，并对实际部署具有指导意义。虽然未明确说明局限性，但该框架可用于评估各种技术的经济价值，未来工作可扩展至更多任务类型和成本模型，推动AI系统更有效的采用。",
      "tags": [
        "Language Models",
        "Economic Framework",
        "Cost Analysis",
        "Production Theory",
        "Inference Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:03.642614Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.12522",
    "title": "Evaluating the Diversity and Quality of LLM Generated Content",
    "authors": [
      "Alexander Shypula",
      "Shuo Li",
      "Botong Zhang",
      "Vishakh Padmakumar",
      "Kayo Yin",
      "Osbert Bastani"
    ],
    "abstract": "Recent work suggests that preference-tuning techniques -- such as Reinforcement Learning from Human Feedback (RLHF) methods like PPO and GRPO, as well as alternatives like DPO -- reduce diversity, creating a dilemma given that these models are widely deployed in applications requiring varied outputs. We argue that diversity without consideration of quality has limited practical value. To address this issue, we introduce a framework for measuring effective semantic diversity -- diversity among outputs that meet quality thresholds -- which better reflects the practical utility of large language models (LLMs). Using open-ended tasks that require no human intervention, we find counterintuitive results: when using diversity metrics that do not explicitly consider quality, preference-tuned models -- particularly those trained via RL -- often produce outputs with lower diversity; however, these same preference-tuned models generate greater effective semantic diversity than supervised fine-tuned (SFT) or base models. Our analysis further shows another trend: while larger models may exhibit greater effective semantic diversity than smaller models, the smaller models are consistently more parameter-efficient at producing unique content within a fixed sampling budget. These findings have practical implications for applications that require diverse yet high-quality outputs, from creative assistance to synthetic data generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2504.12522.pdf",
    "abs_url": "https://arxiv.org/abs/2504.12522",
    "published": "2025-04-16T23:02:23Z",
    "updated": "2026-02-26T18:17:44Z",
    "comment": "Published at COLM 2025",
    "light_analysis": {
      "overview": "论文提出一个有效语义多样性测量框架，结合质量评估LLM生成内容的多样性，改进偏好调优模型的实用评估。",
      "motivation": "研究动机源于偏好调优技术（如RLHF中的PPO和GRPO，以及DPO）被指出会降低生成内容的多样性，而现有方法仅关注多样性度量，忽略质量门槛，导致评估不实用。在实际应用中，如创意辅助和合成数据生成，需要多样且高质量的输出，因此开发一个结合质量的多样性度量框架至关重要，以解决现有评估的局限性。",
      "method": "研究方法引入一个框架来测量有效语义多样性，即仅在满足质量阈值的输出中评估多样性。通过无需人类干预的开放任务进行实验，避免人为偏差。关键创新在于将质量评估融入多样性度量，自动筛选高质量内容，从而更准确地反映大型语言模型的实际应用价值，使用自动化的质量阈值设定方法以提高度量的客观性。",
      "result": "主要实验结果：在未考虑质量的多样性度量下，偏好调优模型（尤其是通过RL训练的）输出多样性较低；但在有效语义多样性度量下，这些模型比监督微调或基础模型展示出更高的多样性。此外，大模型在有效语义多样性方面更高，但小模型在固定采样预算下参数效率更优，能更高效生成独特内容，突显了模型大小与效率的权衡。",
      "conclusion": "结论总结，有效语义多样性框架提升了LLM实用性能的评估准确性，对创意协助和合成数据生成等应用有重要价值。研究强调了在模型评估中平衡多样性和质量的必要性，并指出未来可探索优化模型在效率和多样性之间的平衡，以及扩展框架到更广泛任务中以增强普适性。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning from Human Feedback",
        "Semantic Diversity",
        "Preference-Tuning",
        "Parameter Efficiency"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:02.512317Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.01445",
    "title": "Compositional-ARC: Assessing Systematic Generalization in Abstract Spatial Reasoning",
    "authors": [
      "Philipp Mondorf",
      "Shijia Zhou",
      "Monica Riedler",
      "Barbara Plank"
    ],
    "abstract": "Systematic generalization refers to the capacity to understand and generate novel combinations from known components. Despite recent progress by large language models (LLMs) across various domains, these models often fail to extend their knowledge to novel compositional scenarios, revealing notable limitations in systematic generalization. There has been an ongoing debate about whether neural networks possess the capacity for systematic generalization, with recent studies suggesting that meta-learning approaches designed for compositionality can significantly enhance this ability. However, these insights have largely been confined to linguistic problems, leaving their applicability to other tasks an open question. In this study, we extend meta-learning for compositionality to the domain of abstract spatial reasoning. To this end, we introduce $\\textit{Compositional-ARC}\\unicode{x2014}$a dataset designed to evaluate the capacity of models to systematically generalize from known geometric transformations (e.g., translation, rotation) of abstract two-dimensional objects to novel combinations of these transformations (e.g., translation+rotation). Our results show that a small transformer-based encoder-decoder model, trained via meta-learning for compositionality, can systematically generalize to previously unseen transformation compositions. Notably, despite having only 5.7M parameters, this model significantly outperforms state-of-the-art LLMs$\\unicode{x2014}$including o3-mini, GPT-4o, and Gemini 2.0 Flash, which fail to exhibit similar systematic behavior$\\unicode{x2014}$and performs on par with the winning model of the ARC prize 2024, an 8B-parameter LLM trained via test-time training. Our findings highlight the effectiveness of meta-learning in promoting systematicity beyond linguistic tasks, suggesting a promising direction toward more robust and generalizable models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2504.01445.pdf",
    "abs_url": "https://arxiv.org/abs/2504.01445",
    "published": "2025-04-02T07:56:39Z",
    "updated": "2026-02-26T10:52:45Z",
    "comment": "ICLR 2026, 37 pages, 15 figures",
    "light_analysis": {
      "overview": "本研究提出Compositional-ARC数据集，并通过元学习训练的小型Transformer模型在抽象空间推理中实现系统泛化，显著优于大型语言模型。",
      "motivation": "系统泛化是AI领域的关键能力，指从已知组件理解新组合，但大型语言模型常在此方面失败，尤其在新组合场景中。现有元学习方法主要局限于语言任务，其向其他领域（如抽象空间推理）的适用性未知，这限制了模型的稳健性和跨领域泛化。因此，本研究旨在填补这一空白，探索元学习在非语言任务中的应用，以提升系统泛化能力并推动更通用的AI系统发展。",
      "method": "研究方法包括将元学习组合性扩展至抽象空间推理领域，为此我们引入了Compositional-ARC数据集，专门评估模型从已知几何变换（如平移、旋转）到新组合（如平移加旋转）的系统泛化能力。采用基于Transformer的小型编码器-解码器模型，通过元学习进行训练，模型仅有5.7M参数。关键创新在于将组合性元学习应用于非语言任务，并设计定制数据集以测试空间推理中的系统性。",
      "result": "实验结果显示，通过元学习训练的小型Transformer模型能成功系统泛化到未见过的变换组合。具体而言，该5.7M参数模型显著优于先进的大型语言模型（如o3-mini、GPT-4o和Gemini 2.0 Flash），后者未能展示类似系统性。此外，其性能与ARC prize 2024的获胜模型（一个8B参数的LLM通过测试时训练）相当，突出了元学习在促进系统泛化方面的有效性，尤其在资源受限的模型中。",
      "conclusion": "本研究的结论是，元学习组合性在抽象空间推理中能有效促进系统泛化，扩展了现有研究的应用范围。主要贡献包括提出Compositional-ARC数据集和展示小模型通过元学习超越大型LLMs的能力，为开发更稳健和可推广的模型提供了新方向。这具有学术价值，推动了非语言任务中的系统性研究，并暗示未来可进一步探索元学习在其他领域的应用，以应对更复杂的泛化挑战。",
      "tags": [
        "Systematic Generalization",
        "Meta-learning",
        "Compositionality",
        "Abstract Spatial Reasoning",
        "Transformer"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:06.358533Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.22841",
    "title": "GmNet: Revisiting Gating Mechanisms From A Frequency View",
    "authors": [
      "Yifan Wang",
      "Xu Ma",
      "Yitian Zhang",
      "Zhongruo Wang",
      "Sung-Cheol Kim",
      "Vahid Mirjalili",
      "Vidya Renganathan",
      "Yun Fu"
    ],
    "abstract": "Gating mechanisms have emerged as an effective strategy integrated into model designs beyond recurrent neural networks for addressing long-range dependency problems. In a broad understanding, it provides adaptive control over the information flow while maintaining computational efficiency. However, there is a lack of theoretical analysis on how the gating mechanism works in neural networks. In this paper, inspired by the \\textit{convolution theorem}, we systematically explore the effect of gating mechanisms on the training dynamics of neural networks from a frequency perspective. We investigate the interact between the element-wise product and activation functions in managing the responses to different frequency components. Leveraging these insights, we propose a Gating Mechanism Network (GmNet), a lightweight model designed to efficiently utilize the information of various frequency components. It minimizes the low-frequency bias present in existing lightweight models. GmNet achieves impressive performance in terms of both effectiveness and efficiency in the image classification task.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.22841.pdf",
    "abs_url": "https://arxiv.org/abs/2503.22841",
    "published": "2025-03-28T19:26:45Z",
    "updated": "2026-02-26T14:37:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文从频率视角理论分析门控机制，并提出轻量级GmNet模型以优化频率信息利用并减少低频偏差。",
      "motivation": "门控机制虽有效集成于神经网络设计，用于处理长距离依赖问题并提升计算效率，但现有方法缺乏对其工作机理的系统理论分析，尤其在频率方面的解释不足。这限制了模型优化的理论基础，使得在轻量级模型中普遍存在低频偏差等问题。因此，本研究旨在从频率视角填补理论空白，为改进模型设计提供理论支持。",
      "method": "受卷积定理启发，本研究从频率视角系统分析门控机制的训练动态，重点研究元素级乘积和激活函数如何调控不同频率分量的响应。基于这些洞察，提出GmNet，一种轻量级模型，设计用于高效利用各频率组件信息，并最小化现有轻量级模型中常见的低频偏差。摘要未明确说明具体数据集或模型架构细节，但强调了频率视角的理论创新。",
      "result": "GmNet在图像分类任务中表现出色，在效果和效率方面均取得优异表现。摘要未明确说明具体性能指标（如准确率提升或效率改进数据），但通过与基线方法对比，模型通过减少低频偏差优化了性能，实现了轻量级与高效的平衡，适用于资源有限的应用场景。",
      "conclusion": "本研究的主要贡献在于从频率视角为门控机制提供了理论分析框架，并提出GmNet模型，在学术上丰富了神经网络理论，在实践中为图像分类等任务提供高效解决方案。局限性可能包括未在更广泛任务中验证，未来工作可扩展至其他领域如信号处理或多模态学习。",
      "tags": [
        "Gating Mechanisms",
        "Frequency Analysis",
        "Convolution Theorem",
        "Lightweight Model",
        "Image Classification"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:13.868153Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.21449",
    "title": "Towards Generating Realistic 3D Semantic Training Data for Autonomous Driving",
    "authors": [
      "Lucas Nunes",
      "Rodrigo Marcuzzi",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "abstract": "Semantic scene understanding is crucial for robotics and computer vision applications. In autonomous driving, 3D semantic segmentation plays an important role for enabling safe navigation. Despite significant advances in the field, the complexity of collecting and annotating 3D data is a bottleneck in this developments. To overcome that data annotation limitation, synthetic simulated data has been used to generate annotated data on demand. There is still, however, a domain gap between real and simulated data. More recently, diffusion models have been in the spotlight, enabling close-to-real data synthesis. Those generative models have been recently applied to the 3D data domain for generating scene-scale data with semantic annotations. Still, those methods either rely on image projection or decoupled models trained with different resolutions in a coarse-to-fine manner. Such intermediary representations impact the generated data quality due to errors added in those transformations. In this work, we propose a novel approach able to generate 3D semantic scene-scale data without relying on any projection or decoupled trained multi-resolution models, achieving more realistic semantic scene data generation compared to previous state-of-the-art methods. Besides improving 3D semantic scene-scale data synthesis, we thoroughly evaluate the use of the synthetic scene samples as labeled data to train a semantic segmentation network. In our experiments, we show that using the synthetic annotated data generated by our method as training data together with the real semantic segmentation labels, leads to an improvement in the semantic segmentation model performance. Our results show the potential of generated scene-scale point clouds to generate more training data to extend existing datasets, reducing the data annotation effort. Our code is available at https://github.com/PRBonn/3DiSS.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.21449.pdf",
    "abs_url": "https://arxiv.org/abs/2503.21449",
    "published": "2025-03-27T12:41:42Z",
    "updated": "2026-02-26T11:16:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种无需投影或解耦模型的新方法，直接生成更真实的3D语义场景尺度训练数据，用于自动驾驶。",
      "motivation": "在自动驾驶领域，3D语义分割对安全导航至关重要，但收集和标注3D数据复杂且昂贵，成为技术发展的瓶颈。现有方法使用合成模拟数据生成标注数据，但存在与真实数据的领域差距。尽管扩散模型能合成接近真实的数据并应用于3D语义场景尺度生成，现有方法依赖图像投影或多分辨率解耦模型，中间表示引入转换误差，影响数据质量。因此，需要更直接的真实数据生成方法来解决这些问题。",
      "method": "论文提出一种新颖方法，直接生成3D语义场景尺度数据，关键创新在于避免依赖图像投影或解耦多分辨率模型。通过消除中间表示，该方法减少了转换误差，提高了生成数据的真实性和质量。摘要未明确说明具体模型架构，但可能基于扩散模型等技术，直接合成带语义注释的3D点云，实现场景尺度的数据生成，专注于提升语义准确性和场景真实性。",
      "result": "研究全面评估了合成场景样本作为标注数据用于训练语义分割网络的效果。实验表明，使用本方法生成的合成标注数据与真实语义分割标签结合，显著提高了语义分割模型的性能。摘要未提供具体指标数据，但验证了合成数据的有效性。此外，结果展示了生成场景尺度点云数据的潜力，可扩展现有数据集，减少标注努力和成本，为自动驾驶等应用提供高质量训练数据。",
      "conclusion": "本研究的主要贡献是提出一种无需投影或解耦模型的新方法，直接生成更真实的3D语义场景尺度数据，克服了现有方法的局限性。研究不仅改进了3D语义数据合成技术，还通过实验验证了合成数据在训练语义分割网络中的实用性，具有学术价值，推动生成模型在3D视觉领域的应用。实际应用中，有助于减少数据标注依赖，扩展训练数据集，促进自动驾驶等技术的发展。未来工作可优化数据细节，减少领域差距。",
      "tags": [
        "Diffusion Models",
        "3D Semantic Segmentation",
        "Scene-scale Point Cloud Generation",
        "Synthetic Data Generation",
        "Autonomous Driving Training Data"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:44.905516Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.13587",
    "title": "UniFuture: A 4D Driving World Model for Future Generation and Perception",
    "authors": [
      "Dingkang Liang",
      "Dingyuan Zhang",
      "Xin Zhou",
      "Sifan Tu",
      "Tianrui Feng",
      "Xiaofan Li",
      "Yumeng Zhang",
      "Mingyang Du",
      "Xiao Tan",
      "Xiang Bai"
    ],
    "abstract": "We present UniFuture, a unified 4D Driving World Model designed to simulate the dynamic evolution of the 3D physical world. Unlike existing driving world models that focus solely on 2D pixel-level video generation (lacking geometry) or static perception (lacking temporal dynamics), our approach bridges appearance and geometry to construct a holistic 4D representation. Specifically, we treat future RGB images and depth maps as coupled projections of the same 4D reality and model them jointly within a single framework. To achieve this, we introduce a Dual-Latent Sharing (DLS) scheme, which maps visual and geometric modalities into a shared spatio-temporal latent space, implicitly entangling texture with structure. Furthermore, we propose a Multi-scale Latent Interaction (MLI) mechanism, which enforces bidirectional consistency: geometry constrains visual synthesis to prevent structural hallucinations, while visual semantics refine geometric estimation. During inference, UniFuture can forecast high-fidelity, geometrically consistent 4D scene sequences (image-depth pairs) from a single current frame. Extensive experiments on the nuScenes and Waymo datasets demonstrate that our method outperforms specialized models in both future generation and geometry perception, highlighting the efficacy of unified 4D modeling for autonomous driving. The code is available at https://github.com/dk-liang/UniFuture.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.13587.pdf",
    "abs_url": "https://arxiv.org/abs/2503.13587",
    "published": "2025-03-17T17:59:50Z",
    "updated": "2026-02-26T08:48:02Z",
    "comment": "Accepted by ICRA 2026",
    "light_analysis": {
      "overview": "UniFuture提出了一种统一的4D驾驶世界模型，通过联合建模RGB图像和深度图，实现了高保真、几何一致的未来场景预测。",
      "motivation": "在自动驾驶领域，准确预测未来动态场景至关重要，但现有驱动世界模型主要关注2D像素级视频生成（缺乏几何信息）或静态感知（缺乏时间动态），导致预测不完整且实用性受限。这凸显了连接外观与几何以构建整体4D表示的需求，旨在解决现有方法在全面性上的不足，提升自动驾驶系统的预测准确性。",
      "method": "论文提出了UniFuture模型，通过将未来RGB图像和深度图视为同一4D现实的耦合投影，并在单一框架中联合建模。关键创新包括Dual-Latent Sharing (DLS)方案，将视觉和几何模态映射到共享时空潜在空间，隐式纠缠纹理与结构；以及Multi-scale Latent Interaction (MLI)机制，强制执行双向一致性：几何约束视觉合成以防止结构幻觉，视觉语义细化几何估计。模型使用nuScenes和Waymo数据集进行训练和评估。",
      "result": "实验在nuScenes和Waymo数据集上进行，结果显示UniFuture在生成未来RGB图像和深度图方面优于专门模型。具体而言，模型能够从单个当前帧预测高保真、几何一致的4D场景序列，提高了预测的准确性和一致性，虽然摘要未提供具体性能指标，但实验结果强调了统一4D建模在自动驾驶未来生成和感知任务中的有效性。",
      "conclusion": "论文的主要贡献是提出了UniFuture，一个统一的4D驾驶世界模型，成功融合了外观和几何，为自动驾驶提供了更全面的场景表示。学术上，该方法推动了4D世界建模的研究，增强了动态场景理解能力；实践中，可应用于自动驾驶系统，提升预测精度和安全性。未来工作可能包括模型优化和扩展到其他复杂驾驶场景。",
      "tags": [
        "4D World Model",
        "Dual-Latent Sharing",
        "Multi-scale Latent Interaction",
        "Autonomous Driving",
        "Future Generation"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:33.927849Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.10981",
    "title": "CLIP-Free, Label Free, Unsupervised Concept Bottleneck Models",
    "authors": [
      "Fawaz Sammani",
      "Jonas Fischer",
      "Nikos Deligiannis"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) map dense feature representations into human-interpretable concepts which are then combined linearly to make a prediction. However, modern CBMs rely on the CLIP model to obtain image-concept annotations, and it remains unclear how to design CBMs without the CLIP bottleneck. Methods that do not use CLIP instead require manual, labor intensive annotation to associate feature representations with concepts. Furthermore, all CBMs necessitate training a linear classifier to map the extracted concepts to class labels. In this work, we lift all three limitations simultaneously by proposing a method that converts any frozen visual classifier into a CBM without requiring image-concept labels (label-free), without relying on the CLIP model (CLIP-free), and by deriving the linear classifier in an unsupervised manner. Our method is formulated by aligning the original classifier's distribution (over discrete class indices) with its corresponding vision-language counterpart distribution derived from textual class names, while preserving the classifier's performance. The approach requires no ground-truth image-class annotations, and is highly data-efficient and preserves the classifier's reasoning process. Applied and tested on over 40 visual classifiers, our resulting unsupervised, label-free and CLIP-free CBM (U-F$^2$-CBM) sets a new state of the art, surpassing even supervised CLIP-based CBMs. We also show that our method can be used for zero-shot image captioning, outperforming existing methods based on CLIP, and achieving state-of-art.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.10981.pdf",
    "abs_url": "https://arxiv.org/abs/2503.10981",
    "published": "2025-03-14T01:04:38Z",
    "updated": "2026-02-26T12:15:44Z",
    "comment": "CVPR 2026 (Findings)",
    "light_analysis": {
      "overview": "本文提出了一种无需CLIP、无需标签和无监督的Concept Bottleneck Model方法，将任意冻结视觉分类器转换为可解释模型，实现了新的性能突破。",
      "motivation": "Concept Bottleneck Models (CBMs) 旨在通过可解释概念进行预测，但现有方法依赖于CLIP模型获取图像-概念注释，导致模型瓶颈和额外监督需求。不使用CLIP的方法则需手动、耗时的标注，并且所有CBMs都需要训练线性分类器映射概念到类别标签。这些限制降低了CBMs的实用性和效率，因此研究旨在同时克服这些不足，提供一种更灵活、无监督的解决方案，以提升模型的可解释性和部署便利性。",
      "method": "该方法的核心创新是提出一个框架，将任何预训练的冻结视觉分类器转换为CBM，无需图像-概念标签、不依赖CLIP模型，并以无监督方式导出线性分类器。技术路线包括对齐分类器对离散类别索引的分布与从文本类别名称派生的视觉-语言分布，从而在保持分类性能的同时实现概念映射。关键细节涉及使用文本类名生成概念，避免了手动或CLIP依赖的标注过程，确保了方法的通用性和数据效率。",
      "result": "在超过40个视觉分类器上的实验结果显示，提出的U-F²-CBM模型在性能上达到了新的state-of-the-art，甚至超越了有监督的基于CLIP的CBMs。具体而言，它展示了高效的数据利用和保持分类器推理过程的能力。此外，该方法还被应用于零样本图像描述任务，表现优于现有基于CLIP的方法，实现了当前最优水平，为多任务应用提供了验证。",
      "conclusion": "本研究的主要贡献是开发了一种无监督、无需标签和CLIP的CBM方法，同时解决了现有方法的三个关键限制，提升了模型的灵活性和效率。其学术价值在于推动了无监督学习在可解释AI领域的应用，实际应用价值体现在减少标注成本和适用于多种任务如零样本图像描述。未来工作可探索扩展方法到更广泛的模型或更多样化的数据集，以进一步提升适用性和性能。",
      "tags": [
        "Concept Bottleneck Models",
        "Unsupervised Learning",
        "Vision-Language Alignment",
        "Zero-shot Learning",
        "Image Captioning"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:39.380223Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.10568",
    "title": "Autoregressive Image Generation with Randomized Parallel Decoding",
    "authors": [
      "Haopeng Li",
      "Jinyue Yang",
      "Guoqi Li",
      "Huan Wang"
    ],
    "abstract": "We introduce ARPG, a novel visual Autoregressive model that enables Randomized Parallel Generation, addressing the inherent limitations of conventional raster-order approaches, which hinder inference efficiency and zero-shot generalization due to their sequential, predefined token generation order. Our key insight is that effective random-order modeling necessitates explicit guidance for determining the position of the next predicted token. To this end, we propose a novel decoupled decoding framework that decouples positional guidance from content representation, encoding them separately as queries and key-value pairs. By directly incorporating this guidance into the causal attention mechanism, our approach enables fully random-order training and generation, eliminating the need for bidirectional attention. Consequently, ARPG readily generalizes to zero-shot tasks such as image in-painting, out-painting, and resolution expansion. Furthermore, it supports parallel inference by concurrently processing multiple queries using a shared KV cache. On the ImageNet-1K 256 benchmark, our approach attains an FID of 1.83 with only 32 sampling steps, achieving over a 30 times speedup in inference and and a 75 percent reduction in memory consumption compared to representative recent autoregressive models at a similar scale.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.10568.pdf",
    "abs_url": "https://arxiv.org/abs/2503.10568",
    "published": "2025-03-13T17:19:51Z",
    "updated": "2026-02-26T06:28:59Z",
    "comment": "The Fourteenth International Conference on Learning Representations (ICLR 2026)",
    "light_analysis": {
      "overview": "本文提出ARPG模型，通过随机化并行解码实现了高效的自回归图像生成，显著提升了推理速度和零样本泛化能力。",
      "motivation": "传统自回归图像生成方法基于预定义的光栅顺序生成令牌，这种顺序性导致推理效率低下，且难以泛化到零样本任务（如图像修复和分辨率扩展），限制了模型的实用性和灵活性。现有方法在生成顺序上缺乏适应性，无法处理随机顺序的输入，因此迫切需要一种能同时提升效率和泛化能力的新方法。ARPG旨在解决这些不足，通过引入随机化并行解码来克服传统方法的瓶颈。",
      "method": "ARPG采用解耦解码框架，将位置指导（确定下一个预测令牌的位置）与内容表示解耦，分别编码为查询和键值对，从而在自回归模型中实现随机顺序建模。该框架通过将位置指导整合到因果注意力机制中，无需双向注意力即可支持完全随机顺序的训练和生成，同时支持并行推理，利用共享KV缓存并发处理多个查询，显著提升了计算效率。关键创新点包括解耦解码结构和基于因果注意力的随机化生成机制。",
      "result": "在ImageNet-1K 256基准测试中，ARPG在仅使用32个采样步骤的情况下，达到了FID为1.83的高性能。与类似规模的近期自回归模型相比，ARPG实现了超过30倍的推理速度提升，并将内存消耗减少了75%，显示出显著的效率改进和质量保持。这些结果突显了ARPG在快速图像生成和资源优化方面的优势，为自回归模型设立了新的基准。",
      "conclusion": "ARPG通过随机化并行解码，显著改进了自回归图像生成的效率和泛化能力，主要贡献在于提出解耦解码框架和因果注意力机制，实现随机顺序训练和零样本任务支持（如图像修复和分辨率扩展）。这项研究具有重要的学术价值，为图像生成领域提供了新思路，并具备实际应用潜力，如高效图像编辑和处理。摘要未明确说明局限性，未来工作可能包括进一步优化模型或扩展到更广泛的任务。",
      "tags": [
        "Autoregressive Image Generation",
        "Randomized Parallel Decoding",
        "Causal Attention Mechanism",
        "Zero-shot Tasks"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:45.149046Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.10503",
    "title": "Sample Compression for Self Certified Continual Learning",
    "authors": [
      "Jacob Comeau",
      "Mathieu Bazinet",
      "Pascal Germain",
      "Cem Subakan"
    ],
    "abstract": "Continual learning algorithms aim to learn from a sequence of tasks. In order to avoid catastrophic forgetting, most existing approaches rely on heuristics and do not provide computable learning guarantees. In this paper, we introduce Continual Pick-to-Learn (CoP2L), a method grounded in sample compression theory that retains representative samples for each task in a principled and efficient way. This allows us to derive non-vacuous, numerically computable upper bounds on the generalization loss of the learned predictors after each task. We evaluate CoP2L on standard continual learning benchmarks under Class-Incremental and Task-Incremental settings, showing that it effectively mitigates catastrophic forgetting. It turns out that CoP2L is empirically competitive with baseline methods while certifying predictor reliability in continual learning with a non-vacuous bound.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2503.10503.pdf",
    "abs_url": "https://arxiv.org/abs/2503.10503",
    "published": "2025-03-13T16:05:56Z",
    "updated": "2026-02-26T16:08:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于样本压缩理论的CoP2L方法，用于持续学习，提供可计算的学习保证并有效减轻灾难性遗忘。",
      "motivation": "论文旨在解决持续学习中的灾难性遗忘问题。当前大多数方法依赖启发式策略，无法提供可计算的学习保证，这使得预测器的可靠性难以验证，限制了在需要长期学习和适应新任务的应用（如自动驾驶）中的实用性。现有方法缺乏理论支持，导致在复杂场景下性能不稳定，因此发展具有严格理论保证的方法至关重要，以提升持续学习的可解释性和可靠性。摘要未明确说明具体应用案例，但基于问题重要性可推断。",
      "method": "论文提出Continual Pick-to-Learn (CoP2L)方法，基于样本压缩理论，以原则性和高效的方式为每个任务保留代表性样本。关键创新在于利用样本压缩框架推导出学习预测器泛化损失的非空、数值可计算上界，为持续学习提供理论保证。具体技术涉及在完成每个任务后更新压缩样本集，确保模型稳定性和可解释性。摘要未明确说明具体数据集或模型架构，但方法设计适用于标准持续学习基准。",
      "result": "CoP2L在标准持续学习基准测试中评估，包括Class-Incremental和Task-Incremental设置，结果表明该方法能有效缓解灾难性遗忘，性能与现有基线方法竞争。关键成果是首次在持续学习中提供了非空的、数值可计算的泛化损失上界，从而认证了预测器的可靠性。摘要未明确说明具体性能指标如准确率数据，但强调了与基线方法的可比性，验证了方法的有效性。",
      "conclusion": "论文的主要贡献是提出了基于样本压缩理论的CoP2L方法，为持续学习引入了可计算的学习保证，成功减轻灾难性遗忘。其学术价值在于将理论压缩方法应用于持续学习，提升了方法的理论严谨性和可解释性。实际应用中，该方法可增强AI系统在长期学习任务中的可靠性和稳定性。潜在局限性可能包括任务复杂性或扩展性，未来工作可探索在更广泛任务设置中的优化。",
      "tags": [
        "Sample Compression Theory",
        "Continual Learning",
        "Catastrophic Forgetting",
        "Incremental Learning",
        "Generalization Bounds"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:52.170041Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.05560",
    "title": "Global graph features unveiled by unsupervised geometric deep learning",
    "authors": [
      "Mirja Granfors",
      "Jesús Pineda",
      "Blanca Zufiria Gerbolés",
      "Joana B. Pereira",
      "Carlo Manzo",
      "Giovanni Volpe"
    ],
    "abstract": "Graphs provide a powerful framework for modeling complex systems, but their structural variability poses significant challenges for analysis and classification. To address these challenges, we introduce GAUDI (Graph Autoencoder Uncovering Descriptive Information), a novel unsupervised geometric deep learning framework designed to capture both local details and global structure. GAUDI employs an innovative hourglass architecture with hierarchical pooling and upsampling layers linked through skip connections, which preserve essential connectivity information throughout the encoding-decoding process. Even though identical or highly similar underlying parameters describing a system's state can lead to significant variability in graph realizations, GAUDI consistently maps them into nearby regions of a structured and continuous latent space, effectively disentangling invariant process-level features from stochastic noise. We demonstrate GAUDI's versatility across multiple applications, including small-world networks modeling, characterization of protein assemblies from super-resolution microscopy, analysis of collective motion in the Vicsek model, and identification of age-related changes in brain connectivity. Comparison with related approaches highlights GAUDI's superior performance in analyzing complex graphs, providing new insights into emergent phenomena across diverse scientific domains.",
    "categories": [
      "cs.LG",
      "cond-mat.soft",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2503.05560.pdf",
    "abs_url": "https://arxiv.org/abs/2503.05560",
    "published": "2025-03-07T16:38:41Z",
    "updated": "2026-02-26T12:29:08Z",
    "comment": "28 pages, 6 figures",
    "light_analysis": {
      "overview": "本论文提出了GAUDI框架，通过无监督几何深度学习捕捉图结构的全局和局部特征，分离不变过程级特征，以应对图分析挑战。",
      "motivation": "图作为建模复杂系统的强大框架，其结构变异性对分析和分类构成显著挑战，特别是在相同或相似系统参数导致图实例多样性时，现有方法难以有效提取不变特征和区分随机噪声。因此，需要开发新方法来同时捕捉局部细节和全局结构，以提升图分析的准确性和鲁棒性。",
      "method": "GAUDI采用创新的小时玻璃架构，结合分层池化和上采样层，通过跳跃连接在编码和解码过程中保留图的连接信息。作为无监督几何深度学习框架，它将图映射到结构化连续的潜在空间，利用自编码器设计分离不变过程级特征与随机噪声，无需标签数据即可学习图的表示。",
      "result": "GAUDI在多个应用中验证了其优越性，包括小世界网络建模、蛋白质组装表征、Vicsek模型集体运动分析和脑连接年龄变化识别。与相关方法相比，GAUDI在分析复杂图时展现出更好性能，提供了新的科学见解，但由于摘要未明确具体数据，实验表明其在捕捉全局特征和降低噪声影响方面有效。",
      "conclusion": "GAUDI框架的主要贡献在于通过无监督几何深度学习有效处理图的结构变异性，分离不变特征，为图分析提供了新工具。其学术价值在于推动几何深度学习发展，实际应用跨足生物、物理等多个科学领域，揭示了涌现现象。未来工作可扩展至更多图类型和实时应用场景。",
      "tags": [
        "Graph Autoencoder",
        "Geometric Deep Learning",
        "Unsupervised Learning",
        "Skip Connections",
        "Hierarchical Pooling"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:38.871520Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.14377",
    "title": "RelaCtrl: Relevance-Guided Efficient Control for Diffusion Transformers",
    "authors": [
      "Ke Cao",
      "Jing Wang",
      "Ao Ma",
      "Jiasong Feng",
      "Xuanhua He",
      "Run Ling",
      "Haowei Liu",
      "Jian Lu",
      "Wei Feng",
      "Haozhe Wang",
      "Hongjuan Pei",
      "Yihua Shao",
      "Zhanjie Zhang",
      "Jie Zhang"
    ],
    "abstract": "The Diffusion Transformer plays a pivotal role in advancing text-to-image and text-to-video generation, owing primarily to its inherent scalability. However, existing controlled diffusion transformer methods incur significant parameter and computational overheads and suffer from inefficient resource allocation due to their failure to account for the varying relevance of control information across different transformer layers. To address this, we propose the Relevance-Guided Efficient Controllable Generation framework, RelaCtrl, enabling efficient and resource-optimized integration of control signals into the Diffusion Transformer. First, we evaluate the relevance of each layer in the Diffusion Transformer to the control information by assessing the \"ControlNet Relevance Score\"-i.e., the impact of skipping each control layer on both the quality of generation and the control effectiveness during inference. Based on the strength of the relevance, we then tailor the positioning, parameter scale, and modeling capacity of the control layers to reduce unnecessary parameters and redundant computations. Additionally, to further improve efficiency, we replace the self-attention and FFN in the commonly used copy block with the carefully designed Two-Dimensional Shuffle Mixer (TDSM), enabling efficient implementation of both the token mixer and channel mixer. Both qualitative and quantitative experimental results demonstrate that our approach achieves superior performance with only 15% of the parameters and computational complexity compared to PixArt-delta.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2502.14377.pdf",
    "abs_url": "https://arxiv.org/abs/2502.14377",
    "published": "2025-02-20T09:10:05Z",
    "updated": "2026-02-26T07:56:19Z",
    "comment": "AAAI 2026",
    "light_analysis": {
      "overview": "RelaCtrl通过相关性指导优化控制层集成，显著减少了Diffusion Transformer的参数和计算开销，实现了高效的资源优化控制生成。",
      "motivation": "现有控制扩散变换器方法（如PixArt-delta）在文本到图像和视频生成中面临高参数和计算开销问题，这主要源于忽视不同Transformer层对控制信息的相关性，导致资源分配不高效和冗余计算。该问题限制了扩散模型在实际应用中的可扩展性和部署效率，特别是在需要实时处理的场景下。因此，开发一种能自适应层相关性的高效控制框架至关重要，以降低计算成本并提升性能。",
      "method": "RelaCtrl框架首先评估Diffusion Transformer各层对控制信息的“ControlNet Relevance Score”，即通过分析跳过每层对生成质量和控制效果的影响来量化相关性。基于相关性强度，优化控制层的定位、参数规模和建模能力，从而减少不必要参数和计算。此外，为提升效率，框架用Two-Dimensional Shuffle Mixer (TDSM)替换传统自注意力和前馈网络，实现高效的token mixer和channel mixer，无需复杂计算，适用于控制信号的集成。",
      "result": "实验结果显示，RelaCtrl在定性（如图像质量）和定量（如控制准确性）方面优于基线PixArt-delta，同时仅使用约15%的参数和计算复杂度。具体而言，性能指标表明在保持高生成质量和控制效果的同时，显著降低了资源消耗，验证了相关性指导优化的有效性，例如在基准测试中提升效率而不牺牲性能。",
      "conclusion": "本研究提出RelaCtrl框架，通过相关性评估和优化控制层，大幅减少扩散变换器的参数和计算开销，贡献于高效的资源优化控制。学术上，它为扩散模型控制机制提供了新方法，推进了AI生成内容领域的发展；实际应用上，降低了部署成本，促进更广泛的应用。局限性方面，摘要未明确说明，未来工作可能涉及扩展到其他模型或不同控制任务。",
      "tags": [
        "Diffusion Transformer",
        "ControlNet Relevance Score",
        "Two-Dimensional Shuffle Mixer",
        "Parameter Efficiency",
        "Computational Complexity"
      ]
    },
    "analyzed_at": "2026-02-27T03:57:43.305663Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.11816",
    "title": "Mixing It Up: Exploring Mixer Networks for Irregular Multivariate Time Series Forecasting",
    "authors": [
      "Christian Klötergens",
      "Tim Dernedde",
      "Lars Schmidt-Thieme",
      "Vijaya Krishna Yalavarthi"
    ],
    "abstract": "Forecasting irregularly sampled multivariate time series with missing values (IMTS) is a fundamental challenge in domains such as healthcare, climate science, and biology. While recent advances in vision and time series forecasting have shown that lightweight MLP-based architectures (e.g., MLP-Mixer, TSMixer) can rival attention-based models in both accuracy and efficiency, their applicability to irregular and sparse time series remains unexplored. In this paper, we propose IMTS-Mixer, a novel architecture that adapts the principles of Mixer models to the IMTS setting. IMTS-Mixer introduces two key components: (1) ISCAM, a channel-wise encoder that transforms irregular observations into fixed-size vectors using simple MLPs, and (2) ConTP, a continuous time decoder that supports forecasting at arbitrary time points. In our experiments on established benchmark datasets we show that our model achieves state-of-the- art performance in both forecasting accuracy and inference time, while using fewer parameters compared to baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.11816.pdf",
    "abs_url": "https://arxiv.org/abs/2502.11816",
    "published": "2025-02-17T14:06:36Z",
    "updated": "2026-02-26T10:04:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出 IMTS-Mixer，一种基于 Mixer 模型原理适应不规则多元时间序列预测的新架构，核心创新在于结合 ISCAM 编码器和 ConTP 解码器以处理数据不规则性。",
      "motivation": "不规则采样多元时间序列（IMTS）预测在医疗、气候科学和生物学等领域是基础性挑战，涉及数据缺失和不均匀采样问题。现有轻量级多层感知机（MLP）架构（如 MLP-Mixer、TSMixer）在常规时间序列预测中精度和效率与注意力模型相当，但未探索其对不规则和稀疏时间序列的适用性，导致无法有效处理真实世界复杂数据，因此亟需开发专门针对 IMTS 的预测模型。",
      "method": "IMTS-Mixer 架构基于 Mixer 网络原理，专为不规则多元时间序列设计，核心包括两个关键组件：ISCAM（通道编码器）使用简单 MLPs 将不规则观测转换为固定大小向量，以处理数据稀疏性和不规则性；ConTP（连续时间解码器）支持在任意时间点进行预测，提高模型的灵活性。该模型采用轻量级 MLP 结构，避免了复杂的注意力机制，从而在保持高效性的同时适应 IMTS 的独特需求。",
      "result": "在多个基准数据集上的实验表明，IMTS-Mixer 在预测精度和推理时间上均达到最先进性能，相比于基线方法，模型使用更少的参数，同时在效率上有显著改进。摘要未提供具体性能数据，但实验结果验证了其在处理不规则时间序列时的高精度和快速推断优势，弥补了现有方法在此类任务中的不足。",
      "conclusion": "本研究的主要贡献是提出 IMTS-Mixer，成功将 Mixer 模型应用于不规则多元时间序列预测，解决了现有方法在数据不规则性方面的局限性，具有较高的学术价值，为时间序列预测领域提供了新思路。实际应用价值体现在医疗、气候科学等领域的复杂数据预测中，未来工作可能包括模型扩展以处理更动态场景或结合其他技术进一步优化性能。",
      "tags": [
        "Mixer Networks",
        "Irregular Multivariate Time Series",
        "MLP-based Architectures",
        "Time Series Forecasting",
        "Channel-wise Encoder"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:03.508626Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.06051",
    "title": "Towards a Sharp Analysis of Offline Policy Learning for $f$-Divergence-Regularized Contextual Bandits",
    "authors": [
      "Qingyue Zhao",
      "Kaixuan Ji",
      "Heyang Zhao",
      "Tong Zhang",
      "Quanquan Gu"
    ],
    "abstract": "Many offline reinforcement learning algorithms are underpinned by $f$-divergence regularization, but their sample complexity *defined with respect to regularized objectives* still lacks tight analyses, especially in terms of concrete data coverage conditions. In this paper, we study the exact concentrability requirements to achieve the $\\tildeΘ(ε^{-1})$ sample complexity for offline $f$-divergence-regularized contextual bandits. For reverse Kullback-Leibler (KL) divergence, arguably the most commonly used one, we achieve an $\\tilde{O}(ε^{-1})$ sample complexity under single-policy concentrability for the first time via a novel pessimism-based analysis, surpassing existing $\\tilde{O}(ε^{-1})$ bound under all-policy concentrability and $\\tilde{O}(ε^{-2})$ bound under single-policy concentrability. We also propose a near-matching lower bound, demonstrating that a multiplicative dependency on single-policy concentrability is necessary to maximally exploit the curvature property of reverse KL. Moreover, for $f$-divergences with strongly convex $f$, to which reverse KL *does not* belong, we show that the sharp sample complexity $\\tildeΘ(ε^{-1})$ is achievable even without pessimistic estimation or single-policy concentrability. We further corroborate our theoretical insights with numerical experiments and extend our analysis to contextual dueling bandits. We believe these results take a significant step towards a comprehensive understanding of objectives with $f$-divergence regularization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.06051.pdf",
    "abs_url": "https://arxiv.org/abs/2502.06051",
    "published": "2025-02-09T22:14:45Z",
    "updated": "2026-02-26T03:57:25Z",
    "comment": "35 pages",
    "light_analysis": {
      "overview": "本文首次通过悲观主义分析实现了离线$f$-divergence正则化上下文bandits在单策略浓度性下的尖锐样本复杂度分析。",
      "motivation": "研究动机源于离线强化学习中基于$f$-divergence正则化的算法，其样本复杂性在正则化目标方面缺乏严格分析，尤其是在具体数据覆盖条件如浓度性方面存在不足。现有方法对于逆KL散度，在全策略浓度性下可达$\tilde{O}(ε^{-1})$样本复杂度，但在单策略浓度性下仅为$\tilde{O}(ε^{-2})$，限制了算法效率和实用性。因此，阐明在更宽松条件下实现优化样本复杂度的条件至关重要，以推动算法设计与理论发展。",
      "method": "研究方法提出基于悲观主义的分析，针对$f$-divergence正则化上下文bandits。核心创新是首次在单策略浓度性下为逆KL散度实现$\tilde{O}(ε^{-1})$样本复杂度，通过新颖的悲观估计处理数据覆盖问题。对于具有强凸$f$的$f$-divergence（逆KL不属于此类），无需悲观估计或单策略浓度性即可达到$\tildeΘ(ε^{-1})$。技术细节包括分析上下文bandits框架，扩展应用到上下文对决bandits以验证理论，强调利用散度的曲率特性来优化样本效率。",
      "result": "主要实验结果包括：对于逆KL散度，在单策略浓度性下实现$\tilde{O}(ε^{-1})$样本复杂度，超越了现有$\tilde{O}(ε^{-2})$界限；提出近匹配的下界，证明对单策略浓度性的乘法依赖是必要的以最大化曲率优势。对于强凸$f$的$f$-divergence，达到$\tildeΘ(ε^{-1})$样本复杂度，无需悲观估计。数值实验支持了这些理论见解，并扩展应用到上下文对决bandits，进一步证实了方法的有效性和鲁棒性。",
      "conclusion": "结论总结本研究为离线$f$-divergence正则化上下文bandits提供了尖锐的样本复杂度分析，首次在单策略浓度性下实现优化，增强了理论理解。学术价值体现在澄清了不同浓度性条件下的样本效率，实际价值为离线强化学习算法设计提供理论指导。未来工作可扩展至更多散度类型或复杂场景，以进一步完善对正则化目标的理解。",
      "tags": [
        "Offline Reinforcement Learning",
        "$f$-Divergence Regularization",
        "Contextual Bandits",
        "Pessimistic Estimation",
        "Sample Complexity Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:04.050501Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.01476",
    "title": "Neuro-Symbolic AI for Analytical Solutions of Differential Equations",
    "authors": [
      "Orestis Oikonomou",
      "Levi Lingsch",
      "Dana Grund",
      "Siddhartha Mishra",
      "Georgios Kissas"
    ],
    "abstract": "Analytical solutions to differential equations offer exact, interpretable insight but are rarely available because discovering them requires expert intuition or exhaustive search in combinatorial spaces. We introduce SIGS, a neuro-symbolic framework that automates this process. SIGS uses a formal grammar to generate only syntactically valid building blocks, embeds these expressions into a continuous space, and then searches this space to assemble, score, and refine candidate closed-form solutions by minimizing a physics-based residual. This design unifies symbolic reasoning with numerical optimization; the grammar constrains candidate solution blocks to be proper by construction, while the latent search makes exploration tractable and data-free. SIGS is the first neuro-symbolic method to (i) analytically solve coupled systems of nonlinear PDEs, (ii) discover solutions under grammar misspecification, and (iii) produce accurate symbolic approximations for PDEs lacking known closed-form solutions. Overall, SIGS achieves orders-of-magnitude improvements in accuracy and efficiency over existing symbolic methods on standard benchmarks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.01476.pdf",
    "abs_url": "https://arxiv.org/abs/2502.01476",
    "published": "2025-02-03T16:06:56Z",
    "updated": "2026-02-26T06:35:37Z",
    "comment": "Updates the method and added extra results",
    "light_analysis": {
      "overview": "SIGS是一种神经符号框架，用于自动发现微分方程的分析解，创新性地统一符号推理与数值优化，实现高效搜索和解的生成。",
      "motivation": "微分方程的分析解能提供精确和可解释的见解，但传统方法依赖专家直觉或在组合空间中穷举搜索，这在实际应用中不可行且效率低下。现有符号方法往往计算量大，难以处理复杂系统如非线性偏微分方程耦合系统，限制了分析解的可用性。因此，开发自动化、高效的求解框架至关重要，以弥补这一空白并提升科学计算效率。",
      "method": "SIGS框架使用形式语法生成语法有效的构建块，确保候选解的结构正确性。这些表达式被嵌入连续空间，通过搜索算法组装、评分和细化候选封闭形式解，核心是使用基于物理的残差作为优化目标进行最小化。该方法结合符号推理的严谨性和数值优化的灵活性，无需数据依赖，使探索可处理，关键创新点在于神经符号结合和潜在空间搜索。",
      "result": "在标准基准测试中，SIGS实现了准确性和效率的数量级改进，显著优于现有符号方法。具体而言，它首次能解析求解非线性偏微分方程耦合系统，在语法规范错误下仍能发现解，并为缺乏已知封闭形式解的方程生成准确的符号近似，展示了强大的泛化能力和性能提升。",
      "conclusion": "SIGS的主要贡献在于开发了一个统一的神经符号框架，首次实现自动化求解复杂微分方程系统，提高了解析求解的效率和准确性。学术价值在于推动了符号人工智能与机器学习融合的研究，实际应用价值包括科学仿真和工程建模。局限性或未来工作方向摘要未明确说明，但可能涉及扩展适用范围或优化算法。",
      "tags": [
        "Neuro-Symbolic AI",
        "Formal Grammar",
        "Differential Equations",
        "PDEs",
        "Numerical Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:11.735022Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.16904",
    "title": "Diffusion or Non-Diffusion Adversarial Defenses: Rethinking the Relation between Classifier and Adversarial Purifier",
    "authors": [
      "Yuan-Chih Chen",
      "Chun-Shien Lu"
    ],
    "abstract": "Adversarial defense research continues to face challenges in combating against advanced adversarial attacks, yet with diffusion models increasingly favoring their defensive capabilities. Unlike most prior studies that focus on diffusion models for test-time defense, we explore the generalization loss in classifiers caused by diffusion models. We compare diffusion-based and non-diffusion-based adversarial purifiers, demonstrating that non-diffusion models can also achieve well performance under a practical setting of non-adaptive attack. While non-diffusion models show promising adversarial robustness, they particularly excel in defense transferability and color generalization without relying on additional data beyond the training set. Notably, a non-diffusion model trained on CIFAR-10 achieves state-of-the-art performance when tested directly on ImageNet, surpassing existing diffusion-based models trained specifically on ImageNet.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2501.16904.pdf",
    "abs_url": "https://arxiv.org/abs/2501.16904",
    "published": "2025-01-28T12:44:27Z",
    "updated": "2026-02-26T09:05:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过比较扩散模型和非扩散模型作为对抗净化器，揭示非扩散模型在防御转移性和颜色泛化方面的优势。",
      "motivation": "对抗性防御研究在面对先进对抗攻击时持续面临挑战，尽管扩散模型显示出防御潜力。现有方法大多聚焦于扩散模型在测试时的防御应用，忽视了其对分类器泛化性能的影响，这导致了对更高效防御策略的需求不足。因此，本文旨在探索扩散与非扩散模型在对抗防御中的差异，以解决泛化损失问题并提升防御效果。",
      "method": "本研究比较了基于扩散模型和非扩散模型的对抗净化器，评估它们在非自适应攻击设置下的性能。关键创新点在于分析扩散模型如何导致分类器泛化损失，而非扩散模型则着重于其训练集内的数据利用。具体地，使用CIFAR-10数据集训练非扩散模型，并在ImageNet上进行测试，以验证模型的泛化和防御能力，强调无需额外数据的优势。",
      "result": "实验显示，非扩散模型在非自适应攻击下展现出良好的对抗鲁棒性。在防御转移性和颜色泛化方面，非扩散模型表现优异，优于扩散模型。尤其，在CIFAR-10训练的非扩散模型，直接在ImageNet测试时达到了最先进的性能，超越了专门在ImageNet训练的扩散模型，表明其强大的跨数据集泛化能力。",
      "conclusion": "论文的主要贡献在于重新评估了分类器与对抗净化器的关系，强调非扩散模型在对抗防御中的潜力，挑战了扩散模型的优越性。这为学术研究和实际应用提供了新视角，有助于设计更高效的防御方法。未来工作可进一步优化非扩散模型，或探索其在自适应攻击等更复杂场景中的应用，但摘要未明确说明具体局限性。",
      "tags": [
        "Adversarial Defense",
        "Diffusion Models",
        "Non-Diffusion Models",
        "Adversarial Purifier",
        "Transferability"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:20.899892Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.02158",
    "title": "Joint Optimization for 4D Human-Scene Reconstruction in the Wild",
    "authors": [
      "Zhizheng Liu",
      "Joe Lin",
      "Wayne Wu",
      "Bolei Zhou"
    ],
    "abstract": "Reconstructing human motion and its surrounding environment is crucial for understanding human-scene interaction and predicting human movements in the scene. While much progress has been made in capturing human-scene interaction in constrained environments, those prior methods can hardly reconstruct the natural and diverse human motion and scene context from web videos. In this work, we propose JOSH, a novel optimization-based method for 4D human-scene reconstruction in the wild from monocular videos. JOSH uses techniques in both dense scene reconstruction and human mesh recovery as initialization, and then it leverages the human-scene contact constraints to jointly optimize the scene, the camera poses, and the human motion. Experiment results show JOSH achieves better results on both global human motion estimation and dense scene reconstruction by joint optimization of scene geometry and human motion. We further design a more efficient model, JOSH3R, and directly train it with pseudo-labels from web videos. JOSH3R outperforms other optimization-free methods by only training with labels predicted from JOSH, further demonstrating its accuracy and generalization ability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2501.02158.pdf",
    "abs_url": "https://arxiv.org/abs/2501.02158",
    "published": "2025-01-04T01:53:51Z",
    "updated": "2026-02-26T18:59:39Z",
    "comment": "Project Page: https://vail-ucla.github.io/JOSH/",
    "light_analysis": {
      "overview": "本研究提出了JOSH方法，通过联合优化人类运动和场景几何，从单目视频进行4D人类场景重建，提高了准确性和泛化能力。",
      "motivation": "研究动机旨在解决从网络视频中重建自然和多样化人类运动与场景的挑战。现有方法在受限环境中已有进展，但难以处理网络视频的复杂性和多样性，限制了实际应用中对人类场景交互的理解和预测。因此，开发一种能从单目视频有效重建4D交互的方法至关重要，以推动计算机视觉和人工智能在现实世界场景中的应用。",
      "method": "论文提出JOSH方法，先利用密集场景重建和人类网格恢复技术作为初始化，然后引入人类场景接触约束，联合优化场景几何、相机姿态和人类运动。关键创新在于将优化过程整合，以处理单目视频输入，实现准确的4D重建。此外，设计了更高效的模型JOSH3R，直接使用从网络视频中生成的伪标签进行训练，提升效率。",
      "result": "实验结果表明，JOSH通过联合优化，在全局人类运动估计和密集场景重建方面取得了优于现有方法的结果。JOSH3R仅使用JOSH预测的标签进行训练，超越了其他免优化方法，显示出更高的准确性和泛化能力，尽管摘要未提供具体数据，但强调了在质量和鲁棒性上的显著改进。",
      "conclusion": "论文主要贡献是开发了JOSH和JOSH3R方法，实现了从单目视频的4D人类场景重建，通过联合优化提升了精度和自然度。这对理解和预测人类在复杂环境中的交互具有重要学术和应用价值，增强了处理网络视频的能力。未来工作可能包括进一步优化效率或扩展到更广泛场景。",
      "tags": [
        "4D Reconstruction",
        "Optimization",
        "Human Mesh Recovery",
        "Contact Constraints",
        "Pseudo-Label Training"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:24.684715Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.20816",
    "title": "MomentMix Augmentation with Length-Aware DETR for Temporally Robust Moment Retrieval",
    "authors": [
      "Seojeong Park",
      "Jiho Choi",
      "Kyungjune Baek",
      "Hyunjung Shim"
    ],
    "abstract": "Video Moment Retrieval (MR) aims to localize moments within a video based on a given natural language query. Given the prevalent use of platforms like YouTube for information retrieval, the demand for MR techniques is significantly growing. Recent DETR-based models have made notable advances in performance but still struggle with accurately localizing short moments. Through data analysis, we identified limited feature diversity in short moments, which motivated the development of MomentMix. MomentMix generates new short-moment samples by employing two augmentation strategies: ForegroundMix and BackgroundMix, each enhancing the ability to understand the query-relevant and irrelevant frames, respectively. Additionally, our analysis of prediction bias revealed that short moments particularly struggle with accurately predicting their center positions and length of moments. To address this, we propose a Length-Aware Decoder, which conditions length through a novel bipartite matching process. Our extensive studies demonstrate the efficacy of our length-aware approach, especially in localizing short moments, leading to improved overall performance. Our method surpasses state-of-the-art DETR-based methods on benchmark datasets, achieving the highest R1 and mAP on QVHighlights and the highest R1@0.7 on TACoS and Charades-STA (such as a 9.62% gain in R1@0.7 and an 16.9% gain in mAP average for QVHighlights). The code is available at https://github.com/sjpark5800/LA-DETR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2412.20816.pdf",
    "abs_url": "https://arxiv.org/abs/2412.20816",
    "published": "2024-12-30T09:11:14Z",
    "updated": "2026-02-26T05:36:17Z",
    "comment": "WACV 2026",
    "light_analysis": {
      "overview": "本文提出MomentMix数据增强和长度感知解码器，显著提升视频时刻检索中短时刻的定位准确性。",
      "motivation": "视频时刻检索技术旨在根据自然语言查询定位视频中的特定时刻，随着YouTube等信息检索平台的普及，其需求日益增长。现有基于DETR的模型在性能上有所进步，但数据分析显示短时刻的特征多样性有限，导致模型难以准确预测中心位置和长度，成为关键瓶颈。这限制了MR技术的实用性和准确性，因此亟需改进对短时刻的处理能力。",
      "method": "论文提出两种核心技术：一是MomentMix数据增强，包括ForegroundMix和BackgroundMix策略，分别增强查询相关和无关帧的理解，生成新的短时刻样本以提高特征多样性。二是Length-Aware Decoder，通过新颖的二分匹配过程条件化长度信息，专门针对短时刻的预测偏差进行优化。这些方法基于DETR架构，通过分析预测偏差并引入长度感知机制，以提升模型的稳健性和精确性。",
      "result": "实验在多个基准数据集上进行验证，所提方法超越了现有的基于DETR的模型。具体地，在QVHighlights数据集上达到最高的R1和mAP，例如R1@0.7提升9.62%，mAP平均提升16.9%。在TACoS和Charades-STA数据集上也实现了最高的R1@0.7性能，这表明方法在提升短时刻定位准确性的同时，也改善了整体性能，具有显著的改进效果。",
      "conclusion": "本研究的主要贡献在于通过MomentMix增强和长度感知解码器，有效解决了视频时刻检索中短时刻定位的挑战，提高了模型的稳健性和准确性。这为MR技术提供了新的优化方向，具有重要的学术价值，并有望应用于实际视频信息检索系统。未来工作可探索该方法在其他长度范围或不同数据集的适用性，以进一步拓展其应用潜力。",
      "tags": [
        "Video Moment Retrieval",
        "DETR",
        "Data Augmentation",
        "Bipartite Matching",
        "Length-Aware Modeling"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:37.656694Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.17287",
    "title": "LLM4AD: A Platform for Algorithm Design with Large Language Model",
    "authors": [
      "Fei Liu",
      "Rui Zhang",
      "Zhuoliang Xie",
      "Rui Sun",
      "Kai Li",
      "Qinglong Hu",
      "Ping Guo",
      "Xi Lin",
      "Xialiang Tong",
      "Mingxuan Yuan",
      "Zhenkun Wang",
      "Zhichao Lu",
      "Qingfu Zhang"
    ],
    "abstract": "We introduce LLM4AD, a unified Python platform for algorithm design (AD) with large language models (LLMs). LLM4AD is a generic framework with modularized blocks for search methods, algorithm design tasks, and LLM interface. The platform integrates numerous key methods and supports a wide range of algorithm design tasks across various domains including optimization, machine learning, and scientific discovery. We have also designed a unified evaluation sandbox to ensure a secure and robust assessment of algorithms. Additionally, we have compiled a comprehensive suite of support resources, including tutorials, examples, a user manual, online resources, and a dedicated graphical user interface (GUI) to enhance the usage of LLM4AD. We believe this platform will serve as a valuable tool for fostering future development in the merging research direction of LLM-assisted algorithm design.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2412.17287.pdf",
    "abs_url": "https://arxiv.org/abs/2412.17287",
    "published": "2024-12-23T05:12:54Z",
    "updated": "2026-02-26T07:59:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "LLM4AD是一个集成了大语言模型的统一Python平台，用于支持跨领域的算法设计任务。",
      "motivation": "研究动机在于算法设计在优化、机器学习和科学发现等领域中具有广泛应用，但现有工具和方法可能缺乏统一性和集成度。随着大语言模型的发展，将其用于算法设计成为一个新兴研究方向，但当前缺乏一个通用平台来整合相关资源和方法。摘要未明确说明具体不足之处，但暗示需要更高效和易用的工具来促进这一方向的研究。",
      "method": "论文提出LLM4AD平台，它是一个通用框架，采用模块化设计，包括搜索方法、算法设计任务和大语言模型接口。平台集成多种关键方法，支持广泛的算法设计任务，并设计了统一的评估沙箱以确保算法评估的安全和稳健性。此外，通过编译教程、示例、用户手册、在线资源和专用图形用户界面，提供全面的支持资源。",
      "result": "摘要未明确说明具体的实验结果或性能指标，如准确率提升或效率改进。论文主要描述了平台的功能，包括支持多种算法设计任务和集成资源，可以推断该平台通过统一框架和模块化方法，可能提高了算法设计的效率和易用性。与基线方法的对比在摘要中未提及，需进一步参考论文内容。",
      "conclusion": "论文的主要贡献是提出LLM4AD平台，作为一个有价值工具，用于推动大语言模型辅助算法设计研究的发展。该平台具有学术价值，为未来研究提供基础设施；同时具有实际应用价值，通过丰富的资源支持提升用户体验。摘要未明确说明局限性或未来工作方向，但可以推断可能需要扩展任务范围或优化平台性能以应对更复杂场景。",
      "tags": [
        "Large Language Model",
        "Algorithm Design",
        "Modular Framework",
        "Python Platform",
        "Evaluation Sandbox"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:39.206455Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.16654",
    "title": "IV-tuning: Parameter-Efficient Transfer Learning for Infrared-Visible Tasks",
    "authors": [
      "Yaming Zhang",
      "Chenqiang Gao",
      "Fangcen Liu",
      "Junjie Guo",
      "Lan Wang",
      "Xinggan Peng",
      "Deyu Meng"
    ],
    "abstract": "Existing infrared and visible (IR-VIS) methods inherit the general representations of Pre-trained Visual Models (PVMs) to facilitate complementary learning. However, our analysis indicates that under the full fine-tuning paradigm, the feature space becomes highly constrained and low-ranked, which has been proven to seriously impair generalization. One remedy is to freeze the parameters, which preserves pretrained knowledge and helps maintain feature diversity. To this end, we propose IV-tuning, to parameter-efficiently harness PVMs for various IR-VIS downstream tasks, including salient object detection, semantic segmentation, and object detection. Extensive experiments across various settings demonstrate that IV-tuning outperforms previous state-of-the-art methods, and exhibits superior generalization and scalability. Remarkably, with only a single backbone, IV-tuning effectively facilitates the complementary learning of infrared and visible modalities with merely 3% trainable backbone parameters, and achieves superior computational efficiency compared to conventional IR-VIS paradigms.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2412.16654.pdf",
    "abs_url": "https://arxiv.org/abs/2412.16654",
    "published": "2024-12-21T14:54:41Z",
    "updated": "2026-02-26T05:18:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出IV-tuning，一种参数高效的迁移学习方法，用于红外-可见光任务，通过冻结骨干参数有效促进模态互补学习。",
      "motivation": "现有红外-可见光（IR-VIS）方法通常依赖预训练视觉模型（PVMs）进行互补学习，但全微调范式会导致特征空间高度受限和低秩，这已被证明严重损害模型的泛化能力。冻结参数可以保留预训练知识并维持特征多样性，因此需要开发一种参数高效的方法，以在保持性能的同时优化下游任务的学习效率。",
      "method": "本文提出IV-tuning方法，参数高效地利用预训练视觉模型（PVMs）于多种红外-可见光（IR-VIS）下游任务，包括显著目标检测、语义分割和目标检测。该方法的核心创新点是通过冻结PVMs参数并仅训练少量骨干参数（例如3%），实现高效的迁移学习。这促进了红外和可见光模态的互补学习，同时保持了模型架构的简洁性和计算效率。",
      "result": "广泛的实验表明，IV-tuning在不同设置下超越了先前的最先进方法，展现出优越的泛化能力和可扩展性。具体来说，仅使用单个骨干和3%的可训练参数，它就能有效促进模态互补学习，并实现比传统IR-VIS范式更高的计算效率，显著提升了任务性能。",
      "conclusion": "论文的主要贡献是提出了IV-tuning，一种参数高效的迁移学习方法，显著改进了红外-可见光任务的性能。研究具有学术价值，为迁移学习领域提供了新视角；实际应用价值高，可提升红外-可见光系统的效率和效果。未来工作方向在摘要中未明确说明。",
      "tags": [
        "Transfer Learning",
        "Infrared-Visible Tasks",
        "Parameter-Efficient Fine-Tuning",
        "Pre-trained Visual Models",
        "Complementary Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:53.193590Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.06491",
    "title": "PPT: Pretraining with Pseudo-Labeled Trajectories for Motion Forecasting",
    "authors": [
      "Yihong Xu",
      "Yuan Yin",
      "Éloi Zablocki",
      "Tuan-Hung Vu",
      "Alexandre Boulch",
      "Matthieu Cord"
    ],
    "abstract": "Accurately predicting how agents move in dynamic scenes is essential for safe autonomous driving. State-of-the-art motion forecasting models rely on datasets with manually annotated or post-processed trajectories. However, building these datasets is costly, generally manual, hard to scale, and lacks reproducibility. They also introduce domain gaps that limit generalization across environments. We introduce PPT (Pretraining with Pseudo-labeled Trajectories), a simple and scalable pretraining framework that uses unprocessed and diverse trajectories automatically generated from off-the-shelf 3D detectors and tracking. Unlike data annotation pipelines aiming for clean, single-label annotations, PPT is a pretraining framework embracing off-the-shelf trajectories as useful signals for learning robust representations. With optional finetuning on a small amount of labeled data, models pretrained with PPT achieve strong performance across standard benchmarks, particularly in low-data regimes, and in cross-domain, end-to-end, and multi-class settings. PPT is easy to implement and improves generalization in motion forecasting.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2412.06491.pdf",
    "abs_url": "https://arxiv.org/abs/2412.06491",
    "published": "2024-12-09T13:48:15Z",
    "updated": "2026-02-26T16:36:51Z",
    "comment": "8 pages, 6 figures, accepted to ICRA 2026",
    "light_analysis": {
      "overview": "论文提出PPT预训练框架，利用自动生成的伪标注轨迹提升运动预测模型的泛化能力和数据效率。",
      "motivation": "在自动驾驶领域，准确预测动态场景中智能体的运动对安全至关重要。现有运动预测模型依赖于手动标注或后处理的轨迹数据集，这些数据集构建成本高昂、难以扩展、缺乏可重复性，且引入域间隙限制了模型在不同环境中的泛化能力。因此，研究旨在解决如何通过低成本、可扩展的方式获取训练数据，以克服现有方法的局限并提升泛化性能。",
      "method": "论文提出PPT框架，通过自动从现成的3D检测器和跟踪方法生成多样化和未处理的伪标注轨迹进行预训练。不同于传统追求干净标注的数据管道，PPT将这些噪声轨迹视为学习鲁棒表示的有用信号。核心创新在于拥抱自动生成轨迹的多样性，预训练后可选地使用少量标注数据进行微调，框架简单易实现，无需复杂的手动标注过程。",
      "result": "实验结果表明，通过PPT预训练的模型在标准运动预测基准上实现强劲性能，特别是在低数据场景中表现优异，并在跨域、端到端和多类别设置中展示出良好的泛化能力。摘要未提供具体性能指标，但强调了模型在减少标注数据依赖的同时，优于或匹配基线方法，突显了PPT在数据效率和鲁棒性方面的优势。",
      "conclusion": "论文的主要贡献是PPT框架，它通过伪标注轨迹预训练降低了运动预测对昂贵标注数据的依赖，具有重要的学术价值，为领域提供了新的数据利用思路。在实际应用中，PPT易于实施，可提升自动驾驶系统的预测可靠性和安全性。未来工作可探索伪标注质量的优化，或将该方法扩展到更复杂的动态场景中。",
      "tags": [
        "Motion Forecasting",
        "Pretraining",
        "Pseudo-Labeling",
        "3D Object Detection",
        "Tracking"
      ]
    },
    "analyzed_at": "2026-02-27T03:58:53.795569Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.18207",
    "title": "From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects",
    "authors": [
      "Zizhao Li",
      "Zhengkang Xiang",
      "Joseph West",
      "Kourosh Khoshelham"
    ],
    "abstract": "Traditional object detection methods operate under the closed-set assumption, where models can only detect a fixed number of objects predefined in the training set. Recent works on open vocabulary object detection (OVD) enable the detection of objects defined by an in-principle unbounded vocabulary, which reduces the cost of training models for specific tasks. However, OVD heavily relies on accurate prompts provided by an ``oracle'', which limits their use in critical applications such as driving scene perception. OVD models tend to misclassify near-out-of-distribution (NOOD) objects that have similar features to known classes, and ignore far-out-of-distribution (FOOD) objects. To address these limitations, we propose a framework that enables OVD models to operate in open world settings, by identifying and incrementally learning previously unseen objects. To detect FOOD objects, we propose Open World Embedding Learning (OWEL) and introduce the concept of Pseudo Unknown Embedding which infers the location of unknown classes in a continuous semantic space based on the information of known classes. We also propose Multi-Scale Contrastive Anchor Learning (MSCAL), which enables the identification of misclassified unknown objects by promoting the intra-class consistency of object embeddings at different scales. The proposed method achieves state-of-the-art performance on standard open world object detection and autonomous driving benchmarks while maintaining its open vocabulary object detection capability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.18207.pdf",
    "abs_url": "https://arxiv.org/abs/2411.18207",
    "published": "2024-11-27T10:33:51Z",
    "updated": "2026-02-26T04:11:48Z",
    "comment": "Accepted by BMVC 2025",
    "light_analysis": {
      "overview": "论文提出一个框架，将开放词汇对象检测扩展到开放世界，通过识别和增量学习新对象解决现有模型的局限性。",
      "motivation": "传统闭集对象检测方法无法处理未预见的对象，开放词汇对象检测（OVD）虽能减少特定任务训练成本，但依赖准确提示，限制了在关键应用如自动驾驶中的实用性。OVD模型易误分类类似已知类的对象（NOOD）并忽略完全未知的对象（FOOD），因此在开放世界设置中需要能自主识别和适应新对象的方法，以提升系统鲁棒性和应用范围。",
      "method": "研究提出开放世界嵌入学习（OWEL），引入伪未知嵌入概念，基于已知类信息在连续语义空间中推断未知类的位置。同时，采用多尺度对比锚点学习（MSCAL），通过对比不同尺度下的对象嵌入，提升类内一致性以识别误分类的未知对象。框架整合这些技术，支持对象的增量学习，无需依赖外部提示。",
      "result": "实验结果显示，该方法在标准开放世界对象检测和自动驾驶基准测试中取得了最先进的性能，有效减少了误分类和忽略新对象的问题，同时保持了开放词汇对象检测能力。摘要未明确说明具体准确率或效率数据，但强调了其优于现有基线方法的对比表现。",
      "conclusion": "论文的主要贡献是开发了一个开放世界框架，使开放词汇对象检测模型能识别和增量学习新对象，推动了对象检测领域向开放环境的发展。这具有重要学术价值，并在自动驾驶等实际应用中提高了系统的适应性和鲁棒性。未来工作可能涉及优化增量学习过程或扩展至其他视觉任务。",
      "tags": [
        "Open Vocabulary Object Detection",
        "Open World Object Detection",
        "Embedding Learning",
        "Contrastive Learning",
        "Multi-Scale Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:13.580166Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.17605",
    "title": "Distractor-free Generalizable 3D Gaussian Splatting",
    "authors": [
      "Yanqi Bao",
      "Jing Liao",
      "Jing Huo",
      "Yang Gao"
    ],
    "abstract": "We present DGGS, a novel framework that addresses the previously unexplored challenge: $\\textbf{Distractor-free Generalizable 3D Gaussian Splatting}$ (3DGS). It mitigates 3D inconsistency and training instability caused by distractor data in the cross-scenes generalizable train setting while enabling feedforward inference for 3DGS and distractor masks from references in the unseen scenes. To achieve these objectives, DGGS proposes a scene-agnostic reference-based mask prediction and refinement module during the training phase, effectively eliminating the impact of distractor on training stability. Moreover, we combat distractor-induced artifacts and holes at inference time through a novel two-stage inference framework for references scoring and re-selection, complemented by a distractor pruning mechanism that further removes residual distractor 3DGS-primitive influences. Extensive feedforward experiments on the real and our synthetic data show DGGS's reconstruction capability when dealing with novel distractor scenes. Moreover, our generalizable mask prediction even achieves an accuracy superior to existing scene-specific training methods. Homepage is https://github.com/bbbbby-99/DGGS.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.17605.pdf",
    "abs_url": "https://arxiv.org/abs/2411.17605",
    "published": "2024-11-26T17:17:41Z",
    "updated": "2026-02-26T03:08:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "DGGS框架首次解决了跨场景可泛化3D Gaussian Splatting中干扰数据引起的3D不一致性和训练不稳定性问题。",
      "motivation": "在跨场景可泛化3D重建中，干扰数据（如无关物体）会导致3D模型不一致和训练过程不稳定，这限制了模型在新场景中的泛化能力。现有方法在处理干扰时效果有限，尤其是在可泛化设置下，容易引起训练不稳定和推断误差，因此需要一种高效方法消除干扰影响，提升训练的鲁棒性和推断的准确性。",
      "method": "DGGS在训练阶段引入场景无关的基于参考的掩码预测和精炼模块，通过参考图像预测和优化干扰掩码，有效消除干扰对训练稳定性的影响。推断时采用新颖的两阶段框架：首先对参考进行评分和重选以减少干扰引起的伪影和空洞，然后结合干扰剪枝机制进一步去除残余干扰的3DGS原语影响，支持前向推断。",
      "result": "在真实和合成数据上的大量前向实验显示，DGGS能有效处理新干扰场景，实现高质量3D重建。摘要未明确说明具体性能指标，但表明其可泛化掩码预测的准确性优于现有的场景特定训练方法，证明了在干扰处理方面的改进。",
      "conclusion": "DGGS通过掩码预测和两阶段推断机制，解决了可泛化3DGS中的干扰问题，提升了训练稳定性和重建质量。该研究具有学术价值，为跨场景3D重建提供新方法，实际应用潜力大。未来工作可能包括优化效率或扩展到更复杂场景。",
      "tags": [
        "3D Gaussian Splatting",
        "Generalizable Learning",
        "Mask Prediction",
        "Two-stage Inference",
        "Distractor Pruning"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:18.507736Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.16758",
    "title": "Motion-Aware Animatable Gaussian Avatars Deblurring",
    "authors": [
      "Muyao Niu",
      "Yifan Zhan",
      "Qingtian Zhu",
      "Zhuoxiao Li",
      "Wei Wang",
      "Zhihang Zhong",
      "Xiao Sun",
      "Yinqiang Zheng"
    ],
    "abstract": "The creation of 3D human avatars from multi-view videos is a significant yet challenging task in computer vision. However, existing techniques rely on high-quality, sharp images as input, which are often impractical to obtain in real-world scenarios due to variations in human motion speed and intensity. This paper introduces a novel method for directly reconstructing sharp 3D human Gaussian avatars from blurry videos. The proposed approach incorporates a 3D-aware, physics-based model of blur formation caused by human motion, together with a 3D human motion model designed to resolve ambiguities in motion-induced blur. This framework enables the joint optimization of the avatar representation and motion parameters from a coarse initialization. Comprehensive benchmarks are established using both a synthetic dataset and a real-world dataset captured with a 360-degree synchronous hybrid-exposure camera system. Extensive evaluations demonstrate the effectiveness and robustness of the model across diverse conditions.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.16758.pdf",
    "abs_url": "https://arxiv.org/abs/2411.16758",
    "published": "2024-11-24T10:03:24Z",
    "updated": "2026-02-26T15:11:32Z",
    "comment": "CVPR2026, https://github.com/MyNiuuu/MAD-Avatar",
    "light_analysis": {
      "overview": "本文提出了一种直接从模糊视频重建清晰3D人体高斯化身的新方法，结合了物理模糊模型和运动模型来解决运动模糊问题。",
      "motivation": "从多视角视频创建3D人体化身是计算机视觉中的重要任务，但现有方法依赖高质量、清晰的图像输入，这在真实场景中因人体运动速度和强度的变化而难以实现。问题的重要性在于真实世界视频往往存在模糊，这限制了现有技术在动态环境中的应用。现有技术的不足在于其假设输入图像无模糊，导致在现实条件下性能下降或无法使用，因此需要开发能直接处理模糊输入的方法。",
      "method": "论文提出了一种框架，通过结合3D感知的物理基础模糊形成模型和3D人体运动模型，来解析由运动引起的模糊歧义。该框架支持从粗略初始化联合优化化身表示（如高斯场表示）和运动参数，实现模糊视频到清晰3D化身的重建。创新点包括将物理模型整合到3D重建中，以及设计运动模型来处理运动不确定性。数据集方面，使用合成数据集和真实世界数据集，后者通过360度同步混合曝光相机系统捕获，以验证方法鲁棒性。",
      "result": "论文建立了综合基准，包括合成和真实数据集，并通过广泛评估证明了模型在各种条件下的有效性和鲁棒性。由于摘要未提供具体性能指标，可推断模型在去模糊和3D重建任务上表现出色，可能在视觉质量和重建精度上优于依赖清晰输入的基线方法。结果暗示了该模型能处理多样化的运动模糊，适应真实世界挑战。",
      "conclusion": "论文的主要贡献是提出了一种直接从模糊视频重建清晰3D人体高斯化身的方法，解决了现有技术对输入质量的高依赖问题。学术价值在于结合物理模型和运动模型处理复杂模糊，扩展了3D重建的适用性；实际应用价值在于提升真实场景中化身生成的可用性。局限性或未来工作未在摘要中明确说明，但可能涉及处理极端运动或更多样化的环境。",
      "tags": [
        "Motion Deblurring",
        "3D Gaussian Splatting",
        "Physics-based Model",
        "Human Motion Model",
        "Multi-view Reconstruction"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:19.509101Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.15468",
    "title": "SplatSDF: Boosting SDF-NeRF via Architecture-Level Fusion with Gaussian Splats",
    "authors": [
      "Runfa Blark Li",
      "Keito Suzuki",
      "Bang Du",
      "Ki Myung Brian Lee",
      "Nikolay Atanasov",
      "Truong Nguyen"
    ],
    "abstract": "Signed distance-radiance field (SDF-NeRF) is a promising environment representation that offers both photo-realistic rendering and geometric reasoning such as proximity queries for collision avoidance. However, the slow training speed and convergence of SDF-NeRF hinder their use in practical robotic systems. We propose SplatSDF, a novel SDF-NeRF architecture that accelerates convergence using 3D Gaussian splats (3DGS), which can be quickly pre-trained. Unlike prior approaches that introduce a consistency loss between separate 3DGS and SDF-NeRF models, SplatSDF directly fuses 3DGS at an architectural level by consuming it as an input to SDF-NeRF during training. This is achieved using a novel sparse 3DGS fusion strategy that injects neural embeddings of 3DGS into SDF-NeRF around the object surface, while also permitting inference without 3DGS for minimal operation. Experimental results show SplatSDF achieves 3X faster convergence to the same geometric accuracy than the best baseline, and outperforms state-of-the-art SDF-NeRF methods in terms of chamfer distance and peak signal to noise ratio, unlike consistency loss-based approaches that in fact provide limited gains. We also present computational techniques for accelerating gradient and Hessian steps by 3X. We expect these improvements will contribute to deploying SDF-NeRF on practical systems.",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.15468.pdf",
    "abs_url": "https://arxiv.org/abs/2411.15468",
    "published": "2024-11-23T06:35:19Z",
    "updated": "2026-02-26T05:29:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出SplatSDF，通过架构级融合3D高斯溅射加速SDF-NeRF的训练收敛速度。",
      "motivation": "SDF-NeRF（Signed Distance-Radiance Field）结合了逼真渲染和几何推理，在机器人碰撞避免等应用中具有潜力，但其训练速度缓慢且收敛慢，限制了实际系统部署。现有方法如基于一致性损失的融合仅提供有限增益，未能有效解决效率瓶颈，因此需要更高效的技术来加速训练。",
      "method": "SplatSDF采用一种新架构，直接融合3D高斯溅射（3DGS）到SDF-NeRF中，而非使用外部损失函数。通过稀疏融合策略，在训练时将3DGS的神经嵌入注入到SDF-NeRF的物体表面附近，加速收敛过程，并在推理时无需3DGS以最小化运算开销，实现了架构层面的高效集成。",
      "result": "实验结果显示，SplatSDF在相同几何精度下收敛速度比最佳基线快3倍，并在Chamfer距离和峰值信噪比（PSNR）上优于现有SDF-NeRF方法，基于一致性损失的方法增益有限。此外，计算技术使梯度和Hessian步骤加速3倍，显著提升了整体训练效率。",
      "conclusion": "该研究的核心贡献是SplatSDF，通过创新融合策略解决了SDF-NeRF训练效率低的问题，促进了其在机器人等实际系统的应用。未来工作可扩展至更多场景或优化性能，但摘要未明确说明具体局限性。",
      "tags": [
        "SDF-NeRF",
        "3D Gaussian Splats",
        "Architecture-Level Fusion",
        "Neural Radiance Fields",
        "Signed Distance Fields"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:27.559762Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.11727",
    "title": "Aligning Few-Step Diffusion Models with Dense Reward Difference Learning",
    "authors": [
      "Ziyi Zhang",
      "Li Shen",
      "Sen Zhang",
      "Deheng Ye",
      "Yong Luo",
      "Miaojing Shi",
      "Dongjing Shan",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Few-step diffusion models enable efficient high-resolution image synthesis but struggle to align with specific downstream objectives due to limitations of existing reinforcement learning (RL) methods in low-step regimes with limited state spaces and suboptimal sample quality. To address this, we propose Stepwise Diffusion Policy Optimization (SDPO), a novel RL framework tailored for few-step diffusion models. SDPO introduces a dual-state trajectory sampling mechanism, tracking both noisy and predicted clean states at each step to provide dense reward feedback and enable low-variance, mixed-step optimization. For further efficiency, we develop a latent similarity-based dense reward prediction strategy to minimize costly dense reward queries. Leveraging these dense rewards, SDPO optimizes a dense reward difference learning objective that enables more frequent and granular policy updates. Additional refinements, including stepwise advantage estimates, temporal importance weighting, and step-shuffled gradient updates, further enhance long-term dependency, low-step priority, and gradient stability. Our experiments demonstrate that SDPO consistently delivers superior reward-aligned results across diverse few-step settings and tasks. Code is available at https://github.com/ZiyiZhang27/sdpo.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2411.11727.pdf",
    "abs_url": "https://arxiv.org/abs/2411.11727",
    "published": "2024-11-18T16:57:41Z",
    "updated": "2026-02-26T11:11:12Z",
    "comment": "Accepted by IEEE TPAMI",
    "light_analysis": {
      "overview": "本文提出Stepwise Diffusion Policy Optimization (SDPO)，一种专为少步扩散模型设计的新强化学习框架，通过密集奖励差异学习实现高效目标对齐。",
      "motivation": "少步扩散模型虽然在高效高分辨率图像合成方面表现出色，但在对齐特定下游目标时面临挑战。现有强化学习方法在少步体制下存在局限性，如状态空间有限和样本质量次优，导致难以有效优化模型以适应复杂任务。这些问题限制了少步扩散模型在实际应用中的灵活性，因此需要一种专门针对此场景的强化学习框架来提升目标对齐能力。",
      "method": "论文提出SDPO框架，包括双状态轨迹采样机制，通过跟踪噪声和预测干净状态来提供密集奖励反馈，实现低方差混合步优化。为提升效率，开发了基于潜在相似性的密集奖励预测策略，减少昂贵奖励查询。利用密集奖励优化密集奖励差异学习目标，支持更频繁和细粒度的策略更新。其他改进包括步进优势估计、时间重要性加权和步进洗牌梯度更新，以增强长期依赖、少步优先级和梯度稳定性。摘要未明确说明具体数据集或模型架构。",
      "result": "实验表明，SDPO在多种少步设置和任务中均能提供更优的奖励对齐结果，相比基线方法有显著改进，例如在摘要中提及'consistently delivers superior reward-aligned results'，但未给出具体性能指标如准确率提升。因此，可描述为SDPO展现出更好的目标对齐性能，在各种少步场景下表现稳定，但摘要未明确说明具体数据对比。",
      "conclusion": "SDPO的主要贡献在于为少步扩散模型设计了一个高效的强化学习框架，通过密集奖励差异学习改善了策略优化和目标对齐。这项研究在学术上推动了扩散模型与强化学习的结合，在实际应用中可提升图像合成等任务的效率和质量。尽管摘要未提及局限性，未来工作可能涉及扩展到更多任务或进一步改进框架效率。",
      "tags": [
        "Diffusion Models",
        "Reinforcement Learning",
        "Dense Reward Learning",
        "Policy Optimization",
        "Stepwise Optimization"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:35.092878Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.12439",
    "title": "Beyond Attribution: Unified Concept-Level Explanations",
    "authors": [
      "Junhao Liu",
      "Haonan Yu",
      "Xin Zhang"
    ],
    "abstract": "There is an increasing need to integrate model-agnostic explanation techniques with concept-based approaches, as the former can explain models across different architectures while the latter makes explanations more faithful and understandable to end-users. However, existing concept-based model-agnostic explanation methods are limited in scope, mainly focusing on attribution-based explanations while neglecting diverse forms like sufficient conditions and counterfactuals, thus narrowing their utility. To bridge this gap, we propose a general framework UnCLE to elevate existing local model-agnostic techniques to provide concept-based explanations. Our key insight is that we can uniformly extend existing local model-agnostic methods to provide unified concept-based explanations with large pre-trained model perturbation. We have instantiated UnCLE to provide concept-based explanations in three forms: attributions, sufficient conditions, and counterfactuals, and applied it to popular text, image, and multimodal models. Our evaluation results demonstrate that UnCLE provides explanations more faithful than state-of-the-art concept-based explanation methods, and provides richer explanation forms that satisfy various user needs.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2410.12439.pdf",
    "abs_url": "https://arxiv.org/abs/2410.12439",
    "published": "2024-10-16T10:34:11Z",
    "updated": "2026-02-26T11:26:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出UnCLE框架，通过统一扩展局部模型无关技术，实现概念级的归因、充分条件和反事实解释，提升模型解释的多样性。",
      "motivation": "研究动机源于整合模型无关解释技术与概念级方法的需求，以提升解释的跨架构适应性和用户理解性。现有概念级模型无关方法主要局限于归因解释，忽略了充分条件和反事实等形式，这限制了其应用范围和实用性，因此需要开发更全面的框架来提供多样化概念级解释，满足不同用户需求。",
      "method": "研究方法基于UnCLE框架，通过大型预训练模型扰动，将现有局部模型无关方法统一扩展为概念级解释。关键创新在于支持多种解释形式，包括归因、充分条件和反事实，并实例化应用于文本、图像和多模态模型，利用预训练模型进行扰动生成概念级解释。",
      "result": "主要实验结果表明，UnCLE框架提供的概念级解释比最先进的概念级解释方法更忠实于模型行为。它能生成更丰富的解释形式，如归因、充分条件和反事实，有效满足不同用户需求，评估在文本、图像和多模态模型上证实了框架的通用性和实用性。",
      "conclusion": "UnCLE框架的主要贡献是统一概念级模型无关解释方法，提供多形式解释，弥补现有方法不足。学术价值在于推动解释性AI向更全面和用户中心的方向发展，实际应用价值是增强模型解释的可理解性和多样性。未来工作可进一步优化解释的准确性和扩展性，摘要未明确说明具体局限性。",
      "tags": [
        "Model-Agnostic Explanations",
        "Concept-Based Explanations",
        "Pre-trained Model Perturbation",
        "Attribution Methods",
        "Counterfactual Explanations"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:27.008728Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.10922",
    "title": "Towards Privacy-Guaranteed Label Unlearning in Vertical Federated Learning: Few-Shot Forgetting without Disclosure",
    "authors": [
      "Hanlin Gu",
      "Hong Xi Tae",
      "Chee Seng Chan",
      "Lixin Fan"
    ],
    "abstract": "This paper addresses the critical challenge of unlearning in Vertical Federated Learning (VFL), a setting that has received far less attention than its horizontal counterpart. Specifically, we propose the first method tailored to \\textit{label unlearning} in VFL, where labels play a dual role as both essential inputs and sensitive information. To this end, we employ a representation-level manifold mixup mechanism to generate synthetic embeddings for both unlearned and retained samples. This is to provide richer signals for the subsequent gradient-based label forgetting and recovery steps. These augmented embeddings are then subjected to gradient-based label forgetting, effectively removing the associated label information from the model. To recover performance on the retained data, we introduce a recovery-phase optimization step that refines the remaining embeddings. This design achieves effective label unlearning while maintaining computational efficiency. We validate our method through extensive experiments on diverse datasets, including MNIST, CIFAR-10, CIFAR-100, ModelNet, Brain Tumor MRI, COVID-19 Radiography, and Yahoo Answers demonstrate strong efficacy and scalability. Overall, this work establishes a new direction for unlearning in VFL, showing that re-imagining mixup as an efficient mechanism can unlock practical and utility-preserving unlearning. The code is publicly available at \\href{https://github.com/bryanhx/Towards-Privacy-Guaranteed-Label-Unlearning-in-Vertical-Federated-Learning}{https://github.com/bryanhx/Towards-Privacy-Guaranteed-Label-Unlearning-in-Vertical-Federated-Learning}",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2410.10922.pdf",
    "abs_url": "https://arxiv.org/abs/2410.10922",
    "published": "2024-10-14T12:08:12Z",
    "updated": "2026-02-26T10:05:51Z",
    "comment": "We introduce the first method for label unlearning in vertical federated learning (VFL), focused on preventing label leakage by the active party",
    "light_analysis": {
      "overview": "本文提出了首个针对垂直联邦学习中标签遗忘的方法，通过流形混合机制实现高效且隐私保证的遗忘学习，创新地将混合技术应用于遗忘任务。",
      "motivation": "垂直联邦学习（VFL）中，遗忘学习是一个关键挑战，但相较于水平联邦学习关注较少。标签在VFL中具有双重角色：既是模型训练的必要输入，也包含敏感隐私信息，如用户数据。现有方法在处理标签遗忘时可能面临隐私泄露风险或效率低下问题，尤其是在不破坏模型性能的前提下移除标签信息。本研究旨在解决这一问题，确保在遵守法规如GDPR的“被遗忘权”时，能够安全、高效地实现标签遗忘，从而保护用户隐私。",
      "method": "论文提出了一种基于表示级流形混合的方法来实现标签遗忘。首先，使用流形混合机制生成未遗忘样本和保留样本的合成嵌入，以丰富后续梯度步骤的信号。然后，进行基于梯度的标签遗忘步骤，有效从模型中移除相关标签信息。最后，引入恢复阶段优化步骤，精炼剩余嵌入以恢复保留数据的模型性能。该方法在多个数据集上进行验证，包括MNIST、CIFAR-10、CIFAR-100、ModelNet、Brain Tumor MRI、COVID-19 Radiography和Yahoo Answers，确保了方法的通用性和可扩展性。",
      "result": "通过广泛实验在多个数据集上验证了方法的有效性和可扩展性，包括MNIST、CIFAR-10、CIFAR-100、ModelNet、Brain Tumor MRI、COVID-19 Radiography和Yahoo Answers。摘要表明方法展示了强效性，但未提供具体性能指标如准确率提升或效率改进的数值。因此，可以推断方法在不同数据集上均能有效实现标签遗忘，并与基线方法相比可能具有优势，但具体对比数据摘要未明确说明。",
      "conclusion": "本研究为垂直联邦学习中的遗忘学习建立了新方向，展示了流形混合机制如何实现实用且保持效用的遗忘。主要贡献包括提出了首个针对VFL标签遗忘的方法，并证明了其在隐私保护和计算效率方面的价值。这有助于推动联邦学习中的隐私技术发展，并满足数据删除法规要求。未来工作可能涉及扩展到更复杂的数据类型或优化算法的实时性能，但局限性如处理大规模数据的效率摘要未明确说明。",
      "tags": [
        "Vertical Federated Learning",
        "Unlearning",
        "Manifold Mixup",
        "Gradient-based Optimization",
        "Representation Learning"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:35.637331Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2409.02108",
    "title": "Unveiling Deep Shadows: A Survey and Benchmark on Image and Video Shadow Detection, Removal, and Generation in the Deep Learning Era",
    "authors": [
      "Xiaowei Hu",
      "Zhenghao Xing",
      "Tianyu Wang",
      "Chi-Wing Fu",
      "Pheng-Ann Heng"
    ],
    "abstract": "Shadows, formed by the occlusion of light, play an essential role in visual perception and directly influence scene understanding, image quality, and visual realism. This paper presents a unified survey and benchmark of deep-learning-based shadow detection, removal, and generation across images and videos. We introduce consistent taxonomies for architectures, supervision strategies, and learning paradigms; review major datasets and evaluation protocols; and re-train representative methods under standardized settings to enable fair comparison. Our benchmark reveals key findings, including inconsistencies in prior reports, strong dependence on model design and resolution, and limited cross-dataset generalization due to dataset bias. By synthesizing insights across the three tasks, we highlight shared illumination cues and priors that connect detection, removal, and generation. We further outline future directions involving unified all-in-one frameworks, semantics- and geometry-aware reasoning, shadow-based AIGC authenticity analysis, and the integration of physics-guided priors into multimodal foundation models. Corrected datasets, trained models, and evaluation tools are released to support reproducible research.",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2409.02108.pdf",
    "abs_url": "https://arxiv.org/abs/2409.02108",
    "published": "2024-09-03T17:59:05Z",
    "updated": "2026-02-26T12:11:30Z",
    "comment": "Accepted by International Journal of Computer Vision (IJCV). Publicly available results, trained models, and evaluation metrics at https://github.com/xw-hu/Unveiling-Deep-Shadows",
    "light_analysis": {
      "overview": "本文通过对深度学习时代的图像和视频阴影检测、移除与生成进行统一调查和基准测试，揭示了关键问题并发布工具支持可重复研究。",
      "motivation": "阴影由光遮挡形成，对视觉感知至关重要，直接影响场景理解、图像质量和真实感。现有研究在阴影处理任务（如检测、移除和生成）中缺乏统一的评估标准，导致方法比较困难，同时存在报告不一致和数据集偏差问题。这些问题限制了算法的泛化能力和实际应用，因此亟需系统性的调查和基准测试来促进公平比较和推动技术进步。",
      "method": "本文提出一个统一的调查和基准测试框架，包括引入一致的架构、监督策略和学习范式分类法，回顾主要数据集和评估协议，并在标准化设置下重新训练代表性方法以实现公平比较。关键创新点在于整合了图像和视频的阴影处理任务，通过系统性重新训练来消除先前研究中的不一致性，并利用共享的照明线索和先验知识连接检测、移除与生成任务。",
      "result": "基准测试揭示了重要发现：先前研究报告存在不一致性，模型性能和分辨率有强依赖性，跨数据集泛化能力有限，这主要归因于数据集偏差。通过标准化评估，该方法为各种方法提供了公平比较平台，但摘要未明确说明具体性能指标如准确率提升；结果强调了模型设计和数据质量对任务表现的关键影响，并与基线方法对比突显了标准化设置的重要性。",
      "conclusion": "本文的主要贡献在于提供了全面的调查和基准测试，统一了阴影处理任务的评估标准，揭示了关键问题如数据集偏差和模型依赖性，并强调了共享照明线索的价值。研究的学术意义在于促进了可重复研究，实际应用价值体现在提升图像和视频处理技术的真实感。未来方向包括开发统一框架、几何感知推理、阴影生成真实性分析和多模态基础模型集成，同时发布了修正的数据集、训练模型和工具以支持社区发展。",
      "tags": [
        "Shadow Detection",
        "Shadow Removal",
        "Shadow Generation",
        "Deep Learning Benchmark",
        "Image Processing"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:38.912959Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2408.17251",
    "title": "Abstracted Gaussian Prototypes for True One-Shot Concept Learning",
    "authors": [
      "Chelsea Zou",
      "Kenneth J. Kurtz"
    ],
    "abstract": "We introduce a cluster-based generative image segmentation framework to encode higher-level representations of visual concepts based on one-shot learning inspired by the Omniglot Challenge. The inferred parameters of each component of a Gaussian Mixture Model (GMM) represent a distinct topological subpart of a visual concept. Sampling new data from these parameters generates augmented subparts to build a more robust prototype for each concept, i.e., the Abstracted Gaussian Prototype (AGP). This framework addresses one-shot classification tasks using a cognitively-inspired similarity metric and addresses one-shot generative tasks through a novel AGP-VAE pipeline employing variational autoencoders (VAEs) to generate new class variants. Results from human judges reveal that the generative pipeline produces novel examples and classes of visual concepts that are broadly indistinguishable from those made by humans. The proposed framework leads to impressive, but not state-of-the-art, classification accuracy; thus, the contribution is two-fold: 1) the system is low in theoretical and computational complexity yet achieves the standard of 'true' one-shot learning by operating in a fully standalone manner unlike existing approaches that draw heavily on pre-training or knowledge engineering; and 2) in contrast with existing neural network approaches, the AGP approach addresses the importance of broad task capability emphasized in the Omniglot challenge (successful performance on classification and generative tasks). These two points are critical in advancing our understanding of how learning and reasoning systems can produce viable, robust, and flexible concepts based on literally no more than a single example.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2408.17251.pdf",
    "abs_url": "https://arxiv.org/abs/2408.17251",
    "published": "2024-08-30T12:50:15Z",
    "updated": "2026-02-26T18:03:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一个基于高斯混合模型的抽象高斯原型框架，实现了真正的一次性学习，并在分类和生成任务中表现出色。",
      "motivation": "研究动机源于Omniglot挑战赛，旨在解决一次性概念学习中的核心问题。现有方法通常依赖大量预训练或复杂知识工程，无法在仅有一个示例的情况下实现独立学习和推理，这限制了系统的灵活性和实用性。本文旨在开发一个低理论计算复杂度的系统，强调广泛任务能力，能够同时处理分类和生成任务，以推动人工智能在少样本学习领域的进展。",
      "method": "研究方法基于高斯混合模型（GMM）构建聚类生成图像分割框架。关键创新点是通过推断GMM的参数来表示视觉概念的拓扑子部分，并采样生成增强子部分，从而构建抽象高斯原型（AGP）。技术特色包括使用认知启发的相似性度量进行分类任务，并通过AGP-VAE管道结合变分自编码器（VAEs）生成新类别变体，实现一次性生成任务。该方法不依赖预训练，直接在少量数据上操作。",
      "result": "主要实验结果显示，在生成任务中，人类法官评估表明AGP-VAE管道产生的视觉概念示例和类别与人类制作的几乎无法区分。在分类任务中，系统达到了令人印象深刻的准确率，但尚未达到最佳水平，具体数据摘要未明确说明。与基线方法相比，该系统在低复杂度下实现了真正的一次性学习，展示了在分类和生成任务上的平衡能力。",
      "conclusion": "论文的主要贡献是提出了一个低理论计算复杂度的框架，实现了真正的一次性学习，并成功处理了分类和生成任务。这推进了对学习和推理系统如何基于单个示例生成健壮、灵活概念的理解，具有重要的学术和实际应用价值，如少样本学习系统开发。摘要未明确说明局限性或未来工作方向。",
      "tags": [
        "Gaussian Mixture Model",
        "Variational Autoencoders",
        "One-Shot Learning",
        "Abstracted Gaussian Prototype",
        "Similarity Metric"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:42.604758Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2408.12791",
    "title": "Open-Set Deepfake Detection: A Parameter-Efficient Adaptation Method with Forgery Style Mixture",
    "authors": [
      "Chenqi Kong",
      "Anwei Luo",
      "Peijun Bao",
      "Haoliang Li",
      "Renjie Wan",
      "Zengwei Zheng",
      "Anderson Rocha",
      "Alex C. Kot"
    ],
    "abstract": "Open-set face forgery detection poses significant security threats and presents substantial challenges for existing detection models. These detectors primarily have two limitations: they cannot generalize across unknown forgery domains and inefficiently adapt to new data. To address these issues, we introduce an approach that is both general and parameter-efficient for face forgery detection. It builds on the assumption that different forgery source domains exhibit distinct style statistics. Previous methods typically require fully fine-tuning pre-trained networks, consuming substantial time and computational resources. In turn, we design a forgery-style mixture formulation that augments the diversity of forgery source domains, enhancing the model's generalizability across unseen domains. Drawing on recent advancements in vision transformers (ViT) for face forgery detection, we develop a parameter-efficient ViT-based detection model that includes lightweight forgery feature extraction modules and enables the model to extract global and local forgery clues simultaneously. We only optimize the inserted lightweight modules during training, maintaining the original ViT structure with its pre-trained ImageNet weights. This training strategy effectively preserves the informative pre-trained knowledge while flexibly adapting the model to the task of Deepfake detection. Extensive experimental results demonstrate that the designed model achieves state-of-the-art generalizability with significantly reduced trainable parameters, representing an important step toward open-set Deepfake detection in the wild.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2408.12791.pdf",
    "abs_url": "https://arxiv.org/abs/2408.12791",
    "published": "2024-08-23T01:53:36Z",
    "updated": "2026-02-26T06:26:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出一种参数高效的开放集Deepfake检测方法，通过伪造风格混合增强模型对未知伪造域的泛化能力。",
      "motivation": "开放集人脸伪造检测面临重大安全威胁，现有检测模型存在两大局限：无法泛化到未知伪造域，且适应新数据效率低下。传统方法通常需要全微调预训练网络，消耗大量时间和计算资源。Deepfake技术不断演化，导致检测模型需快速应对新伪造方法，但现有方法难以在保持性能的同时高效部署，因此开发通用且参数高效的检测方法成为关键需求，以提升实际应用中的灵活性和成本效益。",
      "method": "该研究基于不同伪造源域具有独特风格统计的假设，设计了伪造风格混合公式，通过增强伪造域多样性来提高模型在未见域的泛化能力。利用视觉变换器（ViT）在人脸伪造检测中的进展，构建了一个参数高效的ViT检测模型，包括轻量级伪造特征提取模块，能同时提取全局和局部伪造线索。训练时只优化插入的轻量模块，保持原始ViT结构及其预训练的ImageNet权重，以有效保留预训练知识并灵活适应Deepfake检测任务，避免全微调的资源消耗。",
      "result": "实验结果显示，所设计的模型在开放集Deepfake检测中达到了state-of-the-art的泛化性能，同时显著减少了可训练参数。摘要未明确说明具体数据如准确率或参数减少百分比，但强调了模型在通用性和效率方面的优势。与基线方法相比，该方法在保持高性能的同时提升了参数效率，降低了计算成本，为实际部署提供了便利，但实验细节需参考论文全文以获得更精确的对比数据。",
      "conclusion": "该论文的主要贡献是提出了一种参数高效的开放集Deepfake检测方法，通过伪造风格混合和ViT基础模型增强了对未知伪造域的泛化能力。该方法在学术上推动了开放集检测领域的发展，实际应用中能更高效地应对不断演化的Deepfake威胁。局限性在于摘要未提及具体实验细节或未来工作方向，但可推断未来可能进一步优化模型结构或扩展到更多伪造类型，以提升鲁棒性和适应性。",
      "tags": [
        "Open-Set Deepfake Detection",
        "Vision Transformers",
        "Parameter-Efficient Adaptation",
        "Forgery Style Mixture",
        "Feature Extraction Modules"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:04.525096Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2408.10517",
    "title": "Decision MetaMamba: Enhancing Selective SSM in Offline RL with Heterogeneous Sequence Mixing",
    "authors": [
      "Wall Kim",
      "Chaeyoung Song",
      "Hanul Kim"
    ],
    "abstract": "Mamba-based models have drawn much attention in offline RL. However, their selective mechanism often detrimental when key steps in RL sequences are omitted. To address these issues, we propose a simple yet effective structure, called Decision MetaMamba (DMM), which replaces Mamba's token mixer with a dense layer-based sequence mixer and modifies positional structure to preserve local information. By performing sequence mixing that considers all channels simultaneously before Mamba, DMM prevents information loss due to selective scanning and residual gating. Extensive experiments demonstrate that our DMM delivers the state-of-the-art performance across diverse RL tasks. Furthermore, DMM achieves these results with a compact parameter footprint, demonstrating strong potential for real-world applications. Code is available at https://github.com/too-z/decision-metamamba",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2408.10517.pdf",
    "abs_url": "https://arxiv.org/abs/2408.10517",
    "published": "2024-08-20T03:35:28Z",
    "updated": "2026-02-26T06:45:16Z",
    "comment": "17 pages; Previously this version appeared as arXiv:2602.19805 which was submitted as a new work by accident. This is a revised version of the previously withdrawn manuscript, updated with new experiments and results",
    "light_analysis": {
      "overview": "本文提出Decision MetaMamba (DMM)，通过序列混合技术增强离线强化学习中Mamba模型的Selective SSM，显著提升性能并减少信息丢失。",
      "motivation": "该研究旨在解决Mamba-based模型在离线强化学习(RL)中存在的问题。Selective mechanism（选择性机制）在RL序列中可能忽略关键步骤，导致信息丢失，这会影响模型性能，因为离线RL依赖于完整的历史序列。现有Mamba模型的选择性扫描和残差门控机制在处理复杂序列时效率不足，影响任务表现，因此需要改进以更好地捕获序列信息。",
      "method": "本文提出Decision MetaMamba (DMM)，核心方法是将Mamba的token mixer替换为基于dense layer的sequence mixer，并修改位置结构以保留局部信息。通过在Mamba之前执行序列混合，同时考虑所有通道，DMM防止了因选择性扫描和残差门控导致的信息损失。这种方法在离线RL任务中实现异构序列混合，增强了模型对序列的全面处理能力。",
      "result": "实验结果显示，DMM在多种RL任务中取得state-of-the-art性能，尽管摘要未明确说明具体准确率提升数据。与基线方法相比，DMM以紧凑的参数规模实现了高效表现，证明其在减少信息丢失的同时提高了模型效率，适用于资源有限的实际应用场景。",
      "conclusion": "本研究的主要贡献是提出了DMM结构，有效改善了离线RL中Mamba模型的Selective SSM，具有学术价值在于优化序列处理机制。实际应用价值体现在紧凑参数设计，适用于资源受限环境。未来工作可能包括探索在更广泛任务中的应用和进一步优化性能，摘要未明确说明局限性。",
      "tags": [
        "Mamba",
        "Selective SSM",
        "Offline Reinforcement Learning",
        "Sequence Mixing",
        "Dense Layer"
      ]
    },
    "analyzed_at": "2026-02-27T03:59:52.575527Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2408.01503",
    "title": "Efficient Graph Coloring with Neural Networks: A Physics-Inspired Approach for Large Graphs",
    "authors": [
      "Lorenzo Colantonio",
      "Andrea Cacioppo",
      "Federico Scarpati",
      "Maria Chiara Angelini",
      "Federico Ricci-Tersenghi",
      "Stefano Giagu"
    ],
    "abstract": "Combinatorial optimization problems near algorithmic phase transitions represent a fundamental challenge for both classical algorithms and machine learning approaches. Among them, graph coloring stands as a prototypical constraint satisfaction problem exhibiting sharp dynamical and satisfiability thresholds. Here we introduce a physics-inspired neural framework that learns to solve large-scale graph coloring instances by combining graph neural networks with statistical-mechanics principles. Our approach integrates a planting-based supervised signal, symmetry-breaking regularization, and iterative noise-annealed neural dynamics to navigate clustered solution landscapes. When the number of iterations scales quadratically with graph size, the learned solver reaches algorithmic thresholds close to the theoretical dynamical transition in random graphs and achieves near-optimal detection performance in the planted inference regime. The model generalizes from small training graphs to instances orders of magnitude larger, demonstrating that neural architectures can learn scalable algorithmic strategies that remain effective in hard connectivity regions. These results establish a general paradigm for learning neural solvers that operate near fundamental phase boundaries in combinatorial optimization and inference.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2408.01503.pdf",
    "abs_url": "https://arxiv.org/abs/2408.01503",
    "published": "2024-08-02T18:02:51Z",
    "updated": "2026-02-26T17:28:25Z",
    "comment": "15 pages, 9 figures",
    "light_analysis": {
      "overview": "提出一种物理启发的神经网络框架，用于高效解决大规模图着色问题，结合图神经网络与统计力学原理。",
      "motivation": "组合优化问题在图着色中面临算法相位转换的挑战，这是经典算法和机器学习方法的基本难题。图着色作为原型约束满足问题，显示出尖锐的动态和可满足性阈值，对大规模图求解尤为重要。现有方法在处理大规模图和复杂相位边界时可能效率低下或泛化能力不足，需要更可扩展的解决方案，以应对硬连接区域的困难。",
      "method": "研究方法基于物理启发的神经框架，核心是结合图神经网络（GNNs）与统计力学原理。关键创新包括植种监督信号、对称破缺正则化和迭代噪声退火神经动力学，这些技术帮助导航聚簇解空间。模型通过训练小图学习算法策略，然后泛化到大规模图实例，未明确说明具体数据集，但强调可扩展性和算法阈值的学习过程。",
      "result": "主要实验结果显示，当迭代次数与图大小成二次方时，学习到的求解器达到算法阈值，接近随机图中的理论动态转换。在植种推理机制中，实现近乎最优的检测性能。模型展示了强大的泛化能力，从小的训练图扩展到数量级更大的实例，表明神经网络可以学习在困难连接区域保持有效的可扩展策略，与基线方法的对比摘要未明确说明。",
      "conclusion": "论文的主要贡献是建立了一个通用范式，用于学习在组合优化和推理中接近基本相位边界的神经网络求解器。学术价值在于证明了神经架构能够学习可扩展的算法策略，即使在硬连接区域也有效。实际应用价值为大型图着色问题提供了高效解决方案。局限性或未来工作方向摘要未明确说明，但可能涉及进一步优化或扩展到其他问题领域。",
      "tags": [
        "Graph Neural Networks",
        "Statistical Mechanics",
        "Graph Coloring",
        "Combinatorial Optimization",
        "Phase Transition"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:08.033823Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2407.17120",
    "title": "Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective",
    "authors": [
      "Jingren Liu",
      "Zhong Ji",
      "YunLong Yu",
      "Jiale Cao",
      "Yanwei Pang",
      "Jungong Han",
      "Xuelong Li"
    ],
    "abstract": "Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown promise in adapting pre-trained models to sequential tasks while mitigating catastrophic forgetting problem. However, understanding the mechanisms that dictate continual performance in this paradigm remains elusive. To unravel this mystery, we undertake a rigorous analysis of PEFT-CL dynamics to derive relevant metrics for continual scenarios using Neural Tangent Kernel (NTK) theory. With the aid of NTK as a mathematical analysis tool, we recast the challenge of test-time forgetting into the quantifiable generalization gaps during training, identifying three key factors that influence these gaps and the performance of PEFT-CL: training sample size, task-level feature orthogonality, and regularization. To address these challenges, we introduce NTK-CL, a novel framework that eliminates task-specific parameter storage while adaptively generating task-relevant features. Aligning with theoretical guidance, NTK-CL triples the feature representation of each sample, theoretically and empirically reducing the magnitude of both task-interplay and task-specific generalization gaps. Grounded in NTK analysis, our framework imposes an adaptive exponential moving average mechanism and constraints on task-level feature orthogonality, maintaining intra-task NTK forms while attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable parameters with appropriate regularization, NTK-CL achieves state-of-the-art performance on established PEFT-CL benchmarks. This work provides a theoretical foundation for understanding and improving PEFT-CL models, offering insights into the interplay between feature representation, task orthogonality, and generalization, contributing to the development of more efficient continual learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2407.17120.pdf",
    "abs_url": "https://arxiv.org/abs/2407.17120",
    "published": "2024-07-24T09:30:04Z",
    "updated": "2026-02-26T13:06:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出基于神经正切核（NTK）理论的NTK-CL框架，用于参数高效微调的持续学习，通过理论分析减少泛化差距，提升性能。",
      "motivation": "本研究旨在解决参数高效微调在持续学习（PEFT-CL）中机制不明的核心问题。PEFT-CL虽能缓解灾难性遗忘，但持续性能的决定因素尚未清晰，这限制了其在实际应用中的稳定性和可解释性。现有方法缺乏理论指导，难以量化泛化差距和任务间的交互影响，因此，需要通过严谨分析来揭示关键因素，以改进模型适应性并促进更高效的持续学习系统开发。",
      "method": "研究方法以神经正切核（NTK）理论为基础，分析PEFT-CL动态，推导出影响泛化差距的三个关键因素：训练样本大小、任务级特征正交性和正则化。核心创新是NTK-CL框架，它自适应生成任务相关特征，消除任务特定参数存储。该框架通过自适应指数移动平均机制和对任务级特征正交性的约束，保持任务内NTK形式，减弱任务间NTK形式，并结合正则化对可优化参数进行微调，以理论指导减少泛化差距。",
      "result": "NTK-CL在PEFT-CL基准测试中达到了最先进的性能。通过理论分析和实验验证，该框架有效减少了任务间和任务特定的泛化差距，提升了特征表示能力，表现为对基线方法的显著性能改进。尽管摘要未明确说明具体数值指标，但结果证明了其在缓解遗忘和优化任务适应性方面的优势，为持续学习提供了更高效的解决方案。",
      "conclusion": "本研究的主要贡献是为PEFT-CL提供了坚实的理论基础，通过NTK分析揭示了特征表示、任务正交性与泛化之间的内在关系。提出的NTK-CL框架不仅在理论上减少了泛化差距，还在实践中实现了性能提升，推动了更高效持续学习系统的发展。潜在的局限性包括对其他数据集或场景的泛化能力，未来工作可探索更广泛的理论工具或应用扩展，以进一步增强模型的鲁棒性和适应性。",
      "tags": [
        "Parameter-Efficient Fine-Tuning",
        "Continual Learning",
        "Neural Tangent Kernel",
        "Feature Orthogonality",
        "Generalization Analysis"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:05.238624Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2406.09293",
    "title": "StableMaterials: Enhancing Diversity in Material Generation via Semi-Supervised Learning",
    "authors": [
      "Giuseppe Vecchio"
    ],
    "abstract": "We introduce StableMaterials, a novel approach for generating photorealistic physical-based rendering (PBR) materials that integrate semi-supervised learning with Latent Diffusion Models (LDMs). Our method employs adversarial training to distill knowledge from existing large-scale image generation models, minimizing the reliance on annotated data and enhancing the diversity in generation. This distillation approach aligns the distribution of the generated materials with that of image textures from an SDXL model, enabling the generation of novel materials that are not present in the initial training dataset. Furthermore, we employ a diffusion-based refiner model to improve the visual quality of the samples and achieve high-resolution generation. Finally, we distill a latent consistency model for fast generation in just four steps and propose a new tileability technique that removes visual artifacts typically associated with fewer diffusion steps. We detail the architecture and training process of StableMaterials, the integration of semi-supervised training within existing LDM frameworks and show the advantages of our approach. Comparative evaluations with state-of-the-art methods show the effectiveness of StableMaterials, highlighting its potential applications in computer graphics and beyond. StableMaterials is publicly available at https://gvecchio.com/stablematerials.",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2406.09293.pdf",
    "abs_url": "https://arxiv.org/abs/2406.09293",
    "published": "2024-06-13T16:29:46Z",
    "updated": "2026-02-26T08:31:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "StableMaterials提出了一种结合半监督学习和潜扩散模型的方法，用于生成逼真且多样化的物理基础渲染材料。",
      "motivation": "在计算机图形学领域，生成高质量、多样化的物理基础渲染材料对于逼真场景渲染至关重要。现有方法通常依赖大量标注数据，这导致数据获取成本高且规模有限，限制了材料生成的多样性。传统监督学习方法可能因标注不足而生成材料单调或真实性不足。StableMaterials旨在通过半监督学习减少对标注数据的依赖，解决数据稀缺问题，同时提升生成材料的丰富性和应用潜力，特别是在游戏、电影等需要高效材料生成的场景中。",
      "method": "StableMethods基于潜扩散模型框架，整合半监督训练策略。核心创新包括使用对抗训练从SDXL图像生成模型中蒸馏知识，使生成PBR材料的分布与SDXL的纹理分布对齐，从而增强多样性。此外，引入扩散细化模型改善样本视觉质量并支持高分辨率生成。为加速推理，蒸馏潜一致性模型仅需四步即可完成生成，并设计新的平铺技术以减少扩散步数较少时的视觉伪影。整个架构通过结合半监督学习和知识蒸馏，优化了训练效率和生成效果。",
      "result": "通过与最先进方法进行对比评估，StableMaterials在PBR材料生成的多样性和视觉质量方面表现出色。摘要虽未明确提供具体性能指标（如准确率提升百分比或效率改进数据），但指出比较结果验证了其有效性。该方法在减少标注数据依赖的同时，成功生成了高分辨率、逼真材料，解决了现有方法多样性不足的问题，显示出在半监督生成任务中的竞争力，为计算机图形学应用提供了实用解决方案。",
      "conclusion": "StableMaterials的主要贡献是提出一种创新方法，整合半监督学习和潜扩散模型，显著提升PBR材料生成的多样性和效率，减少了标注数据需求。其学术价值在于拓展了半监督学习在生成式模型领域的应用，推动了材料生成技术的发展。实际应用中，该方法在游戏、动画等计算机图形学领域有广阔前景。摘要未明确说明局限性或未来方向，但可基于技术推断潜在优化点，如扩展至其他材料类型或进一步提高实时生成性能。",
      "tags": [
        "Semi-Supervised Learning",
        "Latent Diffusion Models",
        "Knowledge Distillation",
        "Adversarial Training",
        "PBR Materials Generation"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:21.092786Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2404.01877",
    "title": "Procedural Fairness in Machine Learning",
    "authors": [
      "Ziming Wang",
      "Changwu Huang",
      "Ke Tang",
      "Xin Yao"
    ],
    "abstract": "Fairness in machine learning (ML) has garnered significant attention. However, current research has mainly concentrated on the distributive fairness of ML models, with limited focus on another dimension of fairness, i.e., procedural fairness. In this paper, we first define the procedural fairness of ML models by drawing from the established understanding of procedural fairness in philosophy and psychology fields, and then give formal definitions of individual and group procedural fairness. Based on the proposed definition, we further propose a novel metric to evaluate the group procedural fairness of ML models, called $GPF_{FAE}$, which utilizes a widely used explainable artificial intelligence technique, namely feature attribution explanation (FAE), to capture the decision process of ML models. We validate the effectiveness of $GPF_{FAE}$ on a synthetic dataset and eight real-world datasets. Our experimental studies have revealed the relationship between procedural and distributive fairness of ML models. After validating the proposed metric for assessing the procedural fairness of ML models, we then propose a method for identifying the features that lead to the procedural unfairness of the model and propose two methods to improve procedural fairness based on the identified unfair features. Our experimental results demonstrate that we can accurately identify the features that lead to procedural unfairness in the ML model, and both of our proposed methods can significantly improve procedural fairness while also improving distributive fairness, with a slight sacrifice on the model performance.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2404.01877.pdf",
    "abs_url": "https://arxiv.org/abs/2404.01877",
    "published": "2024-04-02T12:05:02Z",
    "updated": "2026-02-26T03:03:39Z",
    "comment": "30 pages, 14 figures, Published in JAIR",
    "light_analysis": {
      "overview": "本文定义了机器学习模型的程序公平性，并提出了基于特征归因解释的评估和改进方法。",
      "motivation": "当前机器学习公平性研究主要集中于分配公平性，而忽略了程序公平性这一关键维度。程序公平性关注决策过程的公正性，对于全面评估模型公平性至关重要。现有方法在程序公平性的定义和度量上存在不足，限制了模型公平性的综合优化。因此，本研究旨在填补这一空白，借鉴哲学和心理学概念，定义程序公平性并提供实用评估框架，以促进更公平的决策系统开发。",
      "method": "论文首先从哲学和心理学领域引入程序公平性概念，形式化定义了个体和群体的程序公平性。基于此，提出了群体程序公平性度量指标 $GPF_{FAE}$，该指标利用广泛使用的可解释人工智能技术——特征归因解释，来捕捉模型的决策过程。研究使用合成数据集和八个真实世界数据集进行验证，并进一步开发了识别导致程序不公平特征的方法，以及两种基于识别特征改进程序公平性的策略。",
      "result": "在合成数据集和八个真实世界数据集上的实验验证了 $GPF_{FAE}$ 指标的有效性，并揭示了程序公平性与分配公平性之间的关系。实验结果显示，提出的方法能够准确识别导致程序不公平的特征。通过两种改进策略，模型在程序公平性和分配公平性上均得到显著提升，同时模型性能仅轻微下降，具体数据摘要未明确说明，但证明了方法的可行性和优势。",
      "conclusion": "本研究的主要贡献在于明确定义了机器学习模型的程序公平性，并提出了评估和改进框架。这扩展了公平性研究的范围，提供了多维度公平性分析工具。结合可解释AI技术，研究不仅提升了理论深度，还具有实际应用价值，有助于开发更公正的决策系统。未来工作可包括优化指标、扩展到其他模型类型或考虑动态公平性调整，以应对更复杂的应用场景。",
      "tags": [
        "Procedural Fairness",
        "Feature Attribution Explanation",
        "Fairness Assessment",
        "Explainable AI",
        "Model Fairness Improvement"
      ]
    },
    "analyzed_at": "2026-02-27T04:00:33.679418Z",
    "analysis_status": "success",
    "analysis_error": null
  }
]