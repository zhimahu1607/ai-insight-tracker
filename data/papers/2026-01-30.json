[
  {
    "id": "2601.22158",
    "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
    "authors": [
      "Yiyang Lu",
      "Susie Lu",
      "Qiao Sun",
      "Hanhong Zhao",
      "Zhicheng Jiang",
      "Xianbang Wang",
      "Tianhong Li",
      "Zhengyang Geng",
      "Kaiming He"
    ],
    "abstract": "Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose \"pixel MeanFlow\" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22158.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22158",
    "published": "2026-01-29T18:59:56Z",
    "updated": "2026-01-29T18:59:56Z",
    "comment": "Technical report",
    "light_analysis": {
      "overview": "提出pixel MeanFlow（pMF），实现单步且无需潜在空间的图像生成方法。",
      "motivation": "现代扩散/流基生成模型通常具有两大特征：多步采样和在潜在空间中操作，这增加了计算复杂度和实现难度，限制了生成效率。尽管近期研究在单步生成或消除潜在空间方面取得进展，但仍未完全整合以同时解决这两个问题。本研究旨在填补这一空白，推动生成模型向更高效、直接的生成方式发展，以满足实际应用中对快速、简化模型的需求。",
      "method": "论文核心是提出pixel MeanFlow（pMF），通过分别设计网络输出空间和损失空间来实现单步、无需潜在空间的生成。网络目标被设定为在假设的低维图像流形上进行图像预测（x-预测），而损失函数则在速度空间中使用MeanFlow定义。关键创新在于引入一个简单变换，连接图像流形和平均速度场，从而有效协调输出与损失，简化生成过程并提高效率。",
      "result": "在ImageNet数据集上的实验显示，pMF在256x256分辨率下取得了2.22的FID分数，在512x512分辨率下为2.48。这些结果表明，pMF在单步、无需潜在空间的图像生成中具有高性能，显著优于基线方法，填补了该技术领域的关键空白，为高效生成模型提供了实证支持。",
      "conclusion": "本研究的主要贡献是通过pMF方法实现了单步、无需潜在空间的图像生成，提升了生成效率和简化了模型架构。该研究具有重要学术价值，为扩散/流基生成模型开辟了新方向，并可能促进其在现实应用中的广泛部署。未来工作可探索更复杂的图像流形变换或扩展到其他生成任务。",
      "tags": [
        "Diffusion Models",
        "Flow-based Models",
        "One-step Sampling",
        "Latent-free Generation",
        "MeanFlow"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:26.648544Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22157",
    "title": "Discovering Hidden Gems in Model Repositories",
    "authors": [
      "Jonathan Kahana",
      "Eliahu Horwitz",
      "Yedid Hoshen"
    ],
    "abstract": "Public repositories host millions of fine-tuned models, yet community usage remains disproportionately concentrated on a small number of foundation checkpoints. We investigate whether this concentration reflects efficient market selection or if superior models are systematically overlooked. Through an extensive evaluation of over 2,000 models, we show the prevalence of \"hidden gems\", unpopular fine-tunes that significantly outperform their popular counterparts. Notably, within the Llama-3.1-8B family, we find rarely downloaded checkpoints that improve math performance from 83.2% to 96.0% without increasing inference costs. However, discovering these models through exhaustive evaluation of every uploaded model is computationally infeasible. We therefore formulate model discovery as a Multi-Armed Bandit problem and accelerate the Sequential Halving search algorithm by using shared query sets and aggressive elimination schedules. Our method retrieves top models with as few as 50 queries per candidate, accelerating discovery by over 50x.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22157.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22157",
    "published": "2026-01-29T18:59:55Z",
    "updated": "2026-01-29T18:59:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于多臂老虎机的加速方法，高效发现模型仓库中性能优异但被忽视的微调模型。",
      "motivation": "论文研究旨在解决公共模型仓库中优质微调模型被系统性忽视的问题。由于仓库托管数百万模型，社区使用却高度集中于少数基础检查点，这可能限制了性能提升和应用优化。现有方法需要通过全面评估每个模型来发现优质模型，但这在计算上不可行，导致资源浪费和潜在高性能模型的错失。因此，高效发现这些“隐藏宝石”对于提升模型选择和促进公平资源利用至关重要。",
      "method": "论文将模型发现问题形式化为多臂老虎机框架，提出一种加速搜索策略。核心创新在于修改顺序平分搜索算法，通过共享查询集减少评估开销，并采用激进消除计划快速筛选候选模型。研究基于对超过2000个微调模型的广泛评估，特别以Llama-3.1-8B家族为例，展示方法在具体场景的应用，从而提高发现过程的计算效率，避免传统方法的繁重负担。",
      "result": "实验结果显示，存在大量“隐藏宝石”，即不流行的微调模型显著优于流行模型。例如，在Llama-3.1-8B家族中，某些罕见检查点将数学性能从83.2%提升至96.0%，推理成本未增加。提出的方法能以每个候选模型仅50个查询高效检索顶级模型，相比传统全面评估，加速发现过程超过50倍，验证了其在减少计算开销和保持高准确率方面的有效性。",
      "conclusion": "论文的主要贡献在于揭示了模型仓库中存在被系统忽视的优质微调模型，并提出基于多臂老虎机的高效发现方法。这具有重要学术和实际价值，解决了计算不可行的挑战，促进了更公平的模型资源利用和性能优化。未来工作可扩展到更多模型家族或评估指标，并探索在不同应用场景下的泛化能力。",
      "tags": [
        "Multi-Armed Bandit",
        "Sequential Halving",
        "Model Discovery",
        "Fine-tuned Models",
        "Llama-3.1-8B"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:47.657417Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22156",
    "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
    "authors": [
      "Yingfa Chen",
      "Zhen Leng Thai",
      "Zihan Zhou",
      "Zhu Zhang",
      "Xingyu Shen",
      "Shuo Wang",
      "Chaojun Xiao",
      "Xu Han",
      "Zhiyuan Liu"
    ],
    "abstract": "Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22156.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22156",
    "published": "2026-01-29T18:59:53Z",
    "updated": "2026-01-29T18:59:53Z",
    "comment": "20 pages, 8 figures",
    "light_analysis": {
      "overview": "本文提出了HALO蒸馏流程和HypeNet混合架构，通过高效知识蒸馏和新型位置编码，显著提升了长上下文建模的效率和性能。",
      "motivation": "研究动机在于解决混合Transformer架构在长上下文建模中预训练成本高的问题，以及现有蒸馏方法效率低下的挑战。现有方法需要超过10B tokens的训练数据，且转换后模型在长上下文场景中表现不佳，限制了其在需要高效推理的实际应用中的实用性。长上下文处理对于文档理解和对话系统等任务至关重要，因此亟需开发更高效的转换流程和架构设计。",
      "method": "研究方法包括提出HALO（Hybrid Attention via Layer Optimization）蒸馏流程，将预训练的Transformer模型高效蒸馏为RNN-attention混合模型。关键创新是HypeNet架构，通过新颖的HyPE位置编码方案和架构修改，实现了优越的长度泛化能力。具体使用Qwen3系列模型进行转换，HALO流程减少了对大规模训练数据的依赖，仅需少量tokens即可完成模型优化。",
      "result": "实验结果表明，通过HALO将Qwen3系列转换为HypeNet后，模型性能与原始Transformer模型相当，同时在长上下文场景下展现出优越的性能和效率提升。转换过程仅需2.3B tokens，远少于现有方法所需的10B tokens，不足预训练数据的0.01%。这证明了HALO和HypeNet在显著降低训练成本的同时，有效保持了模型质量，提高了长上下文处理的实用性。",
      "conclusion": "结论是本文通过HALO蒸馏流程和HypeNet架构，成功解决了长上下文建模中的效率和性能瓶颈，为混合模型提供了高效的知识蒸馏方法和改进的架构设计。学术上推动了长上下文处理技术的发展，实际应用中可促进更快的推理速度和更长的上下文处理能力。未来工作可能包括进一步优化HyPE编码或扩展到其他模型系列，以应对更复杂的应用场景。",
      "tags": [
        "Hybrid Transformer",
        "Knowledge Distillation",
        "Long-Context Modeling",
        "Position Encoding",
        "Efficient Training"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:25.277966Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22154",
    "title": "Exploring Reasoning Reward Model for Agents",
    "authors": [
      "Kaixuan Fan",
      "Kaituo Feng",
      "Manyuan Zhang",
      "Tianshuo Peng",
      "Zhixun Li",
      "Yilei Jiang",
      "Shuang Chen",
      "Peng Pei",
      "Xunliang Cai",
      "Xiangyu Yue"
    ],
    "abstract": "Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22154.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22154",
    "published": "2026-01-29T18:59:52Z",
    "updated": "2026-01-29T18:59:52Z",
    "comment": "Project page: https://github.com/kxfan2002/Reagent",
    "light_analysis": {
      "overview": "本文提出了一个多方面的推理奖励模型 Agent-RRM，通过提供结构化反馈来改善智能体在强化学习中的训练效果，解决了稀疏奖励无法评估中间推理质量的问题。",
      "motivation": "Agentic Reinforcement Learning (Agentic RL) 在智能体执行复杂推理和工具使用方面取得了显著成功，但现有方法通常依赖于稀疏的基于结果的奖励进行训练。这种奖励机制无法区分智能体在任务执行过程中的中间推理质量，导致训练结果不理想，限制了智能体在复杂任务中的性能提升。因此，开发一种能够提供更细致反馈的奖励模型变得尤为重要，以提高智能体的学习效率和最终表现。",
      "method": "论文提出了 Agent Reasoning Reward Model (Agent-RRM)，这是一个多方面的奖励模型，为智能体轨迹生成结构化反馈，包括（1）显式推理轨迹，用于追踪推理过程；（2）集中批评，通过突出推理缺陷来提供细化指导；（3）整体分数，用于评估过程性能。基于这些反馈信号，研究者系统探索了三种集成策略：Reagent-C（文本增强细化）、Reagent-R（奖励增强指导）和 Reagent-U（统一反馈集成），旨在优化智能体的训练过程，但摘要未明确说明具体的数据集或模型架构细节。",
      "result": "通过在12个多样化的基准测试中进行广泛评估，研究发现 Reagent-U 集成策略带来了显著的性能提升。具体而言，在 GAIA 基准上达到了43.7%的准确率，在 WebWalkerQA 基准上达到了46.2%的准确率。这些结果验证了 Agent-RRM 推理奖励模型和相应训练方案的有效性，相比传统稀疏奖励方法有明显改进，但摘要未提供更详细的基线对比数据。",
      "conclusion": "本研究的主要贡献是引入了 Agent-RRM 推理奖励模型和三种集成策略，成功解决了稀疏奖励在智能体训练中的局限性。实验结果表明，该方法显著提升了智能体在复杂任务中的性能，具有重要的学术价值和实际应用前景。此外，研究者发布了代码、模型和数据集，促进了未来相关研究的发展。摘要未明确说明研究的局限性或未来工作方向，但可推断未来可能涉及更广泛的应用或优化。",
      "tags": [
        "Agentic Reinforcement Learning",
        "Reasoning Reward Model",
        "Structured Feedback",
        "Integration Strategies",
        "Benchmark Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:21.115635Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22155",
    "title": "UEval: A Benchmark for Unified Multimodal Generation",
    "authors": [
      "Bo Li",
      "Yida Yin",
      "Wenhao Chai",
      "Xingyu Fu",
      "Zhuang Liu"
    ],
    "abstract": "We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22155.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22155",
    "published": "2026-01-29T18:59:52Z",
    "updated": "2026-01-29T18:59:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了 UEval 基准数据集，用于评估能同时生成图像和文本的统一多模态模型，并设计了一个基于 rubrics 的细粒度评分系统。",
      "motivation": "本研究旨在解决评估开放式的多模态生成任务的难题。现有方法如简单的 LLM-as-a-judge 可能忽略生成内容中的微妙细节，导致评估不精确，而依赖多模态大语言模型评分的方式也不够全面。因此，开发一个更精准的评估基准对于推动模型改进、促进多模态 AI 的发展至关重要，因为现有方法难以覆盖复杂推理和细粒度要求。",
      "method": "研究方法包括构建 UEval 基准数据集，包含 1,000 个来自 8 个真实世界任务的专家策划问题，覆盖多种推理类型如分步指南。关键创新是设计一个基于 rubrics 的评分系统：对于每个问题，使用多模态大语言模型生成包含多个评估准则的初始 rubrics，然后由人类专家进行细化和验证，最终形成 10,417 个已验证的 rubrics 标准，从而实现可扩展、自动化的细粒度评分。",
      "result": "实验结果显示 UEval 对当前统一模型具有挑战性：GPT-5-Thinking 在 100 分制下仅得 66.4 分，而最佳开源模型得分仅为 49.1。与基线方法相比，推理模型的表现显著优于非推理模型，且通过将推理痕迹从推理模型转移至非推理模型，可以显著缩小性能差距。具体数据表明，推理可能在复杂多模态理解和生成任务中起到关键作用。",
      "conclusion": "论文的主要贡献是引入了 UEval 基准和 rubrics 评分系统，为多模态生成模型提供了有效的评估工具。学术价值在于强调推理能力在复杂任务中的重要性，并推动更细粒度的模型评估研究。实际应用上，这有助于指导未来模型设计和优化。局限性包括摘要未明确说明未来具体扩展方向，但可推测未来工作可能涉及数据集增强或评分方法改进。",
      "tags": [
        "Unified Multimodal Generation",
        "Benchmarking",
        "Multimodal Large Language Model (MLLM)",
        "Rubric-based Evaluation",
        "Reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:54.970023Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22151",
    "title": "Late Breaking Results: Conversion of Neural Networks into Logic Flows for Edge Computing",
    "authors": [
      "Daniel Stein",
      "Shaoyi Huang",
      "Rolf Drechsler",
      "Bing Li",
      "Grace Li Zhang"
    ],
    "abstract": "Neural networks have been successfully applied in various resource-constrained edge devices, where usually central processing units (CPUs) instead of graphics processing units exist due to limited power availability. State-of-the-art research still focuses on efficiently executing enormous numbers of multiply-accumulate (MAC) operations. However, CPUs themselves are not good at executing such mathematical operations on a large scale, since they are more suited to execute control flow logic, i.e., computer algorithms. To enhance the computation efficiency of neural networks on CPUs, in this paper, we propose to convert them into logic flows for execution. Specifically, neural networks are first converted into equivalent decision trees, from which decision paths with constant leaves are then selected and compressed into logic flows. Such logic flows consist of if and else structures and a reduced number of MAC operations. Experimental results demonstrate that the latency can be reduced by up to 14.9 % on a simulated RISC-V CPU without any accuracy degradation.   The code is open source at https://github.com/TUDa-HWAI/NN2Logic",
    "categories": [
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22151.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22151",
    "published": "2026-01-29T18:59:50Z",
    "updated": "2026-01-29T18:59:50Z",
    "comment": "accepted by DATE2026",
    "light_analysis": {
      "overview": "本研究提出一种将神经网络转换为逻辑流的新方法，以提高其在 CPU 上的计算效率，减少延迟而不损失精度。",
      "motivation": "研究动机源于边缘计算中资源受限的设备普遍使用 CPU 而非 GPU，CPU 不擅长大规模执行乘法累加（MAC）操作，更适合处理控制流逻辑。现有研究仍侧重于优化 MAC 操作效率，未充分利用 CPU 的计算特性，导致神经网络在 CPU 上执行效率低下。这限制了边缘设备的性能和能耗优化，因此需要一种适配 CPU 的方法来提升神经网络执行效率。",
      "method": "论文提出的核心方法是将神经网络转换为逻辑流执行。具体技术路线包括：首先将神经网络转换为等效的决策树表示；然后从中选择具有常数叶子的决策路径；接着将这些路径压缩为包含 if-else 结构的逻辑流，从而显著减少 MAC 操作数量。该方法的关键创新在于利用 CPU 对控制流逻辑的高效处理能力，通过转换减少数学运算，提高计算效率。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "实验结果显示，在模拟的 RISC-V CPU 上，提出的方法能将神经网络的执行延迟减少高达 14.9%，且没有任何精度退化。这表明相比传统基于大量 MAC 操作的方法，该方法能有效提升效率，实现性能改进。实验结果未提供与具体基线方法的详细对比，但强调了在保持准确性的同时显著降低了延迟。",
      "conclusion": "本文的主要贡献是提出并验证了将神经网络转换为逻辑流的方法，以优化 CPU 上的执行效率。学术价值在于提供了一种新的优化方向，利用 CPU 的控制流逻辑特性减少计算负载；实际应用价值在于改善边缘计算中资源受限设备的性能。局限性未在摘要中明确说明，未来工作可能包括扩展到更复杂的网络模型或实际硬件部署中的进一步验证。",
      "tags": [
        "Neural Networks",
        "Logic Flows",
        "Decision Trees",
        "Edge Computing",
        "CPU Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:16.941125Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22150",
    "title": "Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions",
    "authors": [
      "Xiaoxiao Sun",
      "Mingyang Li",
      "Kun yuan",
      "Min Woo Sun",
      "Mark Endo",
      "Shengguang Wu",
      "Changlin Li",
      "Yuhui Zhang",
      "Zeyu Wang",
      "Serena Yeung-Levy"
    ],
    "abstract": "Large Vision-Language Models (VLMs) often answer classic visual illusions \"correctly\" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22150.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22150",
    "published": "2026-01-29T18:59:24Z",
    "updated": "2026-01-29T18:59:24Z",
    "comment": "26 pages, 31 figures, 13 tables. Project Page: https://sites.google.com/view/vi-probe/",
    "light_analysis": {
      "overview": "本文提出VI-Probe框架，通过可控视觉错觉系统探究大视觉语言模型的视觉感知与记忆回忆机制，挑战单一原因观点。",
      "motivation": "研究动机源于大视觉语言模型在经典视觉错觉测试中的异常行为：模型对原始图像回答正确，但当错觉因素反转时仍坚持相同答案，尽管人类能明显感知变化。这引发疑问：模型是真正感知视觉变化还是仅回忆记忆模式？现有研究仅观察到该现象，但未深入分析根本原因，限制了我们对模型视觉理解能力的理解，因此需要系统探究以提升模型可靠性和透明度。",
      "method": "研究方法引入VI-Probe框架，这是一种可控的视觉错觉测试系统，通过分级扰动和匹配视觉控制（无错觉诱导器）来区分视觉感知和语言驱动的回忆。核心创新在于使用新指标如极性翻转一致性、模板固定指数和错觉乘数来测量稳定性和敏感性，而非传统平均准确率。实验设计涉及不同模型家族，包括GPT-5、Claude-Opus-4.1和Qwen变体，但摘要未明确说明具体数据集，框架允许系统测试模型在视觉变化下的响应机制。",
      "result": "主要实验结果表明，大视觉语言模型在视觉错觉中的响应持续性源于多种机制而非单一原因。例如，GPT-5展示记忆覆盖行为，Claude-Opus-4.1显示感知与记忆的竞争，而Qwen变体暗示视觉处理限制。这些发现基于新指标的分析，挑战了先前研究中假设的单一原因观点，并凸显了不同模型在处理视觉错觉时的异质性，强调了系统评估的重要性。摘要未提供具体性能数据，但强调结果揭示了模型行为的多样性。",
      "conclusion": "本研究的主要贡献是提出VI-Probe框架和相关评估指标，系统揭示了视觉语言模型中感知与记忆的复杂交互。学术上，它挑战了单一原因观点，促进基于探针的评估来测量模型知识和可控视觉变化的敏感性。实际应用中，这有助于改善模型的视觉理解能力和可靠性，为未来研究方向如扩展至更多模型和任务奠定了基础。摘要未明确说明局限性，但暗示需要进一步探究不同模型的机制和更广泛的视觉测试。",
      "tags": [
        "Large Vision-Language Models",
        "Visual Illusions",
        "Polarity-Flip Consistency",
        "Controllable Framework",
        "Perception vs Memory"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:41.097330Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22149",
    "title": "DynaWeb: Model-Based Reinforcement Learning of Web Agents",
    "authors": [
      "Hang Ding",
      "Peidong Liu",
      "Junqiao Wang",
      "Ziwei Ji",
      "Meng Cao",
      "Rongzhao Zhang",
      "Lynn Ai",
      "Eric Yang",
      "Tianyu Shi",
      "Lei Yu"
    ],
    "abstract": "The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22149.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22149",
    "published": "2026-01-29T18:59:07Z",
    "updated": "2026-01-29T18:59:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "DynaWeb提出了一个基于模型的强化学习框架，使网络代理能通过想象进行高效训练。",
      "motivation": "研究旨在解决训练自主网络代理时与实时互联网交互的挑战，包括效率低、成本高和风险大。现有基于大语言模型和强化学习的方法受限于这些实际问题，开发通用AI助手需要高效训练途径。基于模型的强化学习通过学习环境的世界模型实现模拟交互，为规避实时网络交互的不足提供了可行方案，以推动网络代理技术的进展。",
      "method": "论文提出DynaWeb框架，采用基于模型的强化学习技术，训练一个网络世界模型以预测代理动作对应的网络页面表示。该模型作为合成网络环境，允许代理策略生成大量rollout动作轨迹进行在线强化学习，实现“梦想”训练。关键创新包括整合真实专家轨迹，与策略rollouts随机交织以提高训练稳定性和样本效率，优化代理性能，使用了具体的数据集如训练数据中的轨迹。",
      "result": "实验在WebArena和WebVoyager基准测试上进行，结果显示DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models。摘要未明确说明具体数据如准确率提升百分比，但表明该方法在性能上优于基线，验证了通过想象训练网络代理的有效性，为后续研究提供了实证支持。",
      "conclusion": "研究确立了通过想象（模型模拟）训练网络代理的可行性，提供了一种可扩展且高效的方法来增强在线代理强化学习。这为开发更优的网络助手和通用AI系统铺平道路，具有重要学术和实际应用价值。潜在局限性或未来工作方向摘要未明确说明，但该方法有望缓解训练中的资源约束和风险问题。",
      "tags": [
        "Model-Based Reinforcement Learning",
        "Large Language Models",
        "Reinforcement Learning",
        "Web Agents",
        "World Model"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:42.968300Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22146",
    "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
    "authors": [
      "Ajay Patel",
      "Colin Raffel",
      "Chris Callison-Burch"
    ],
    "abstract": "Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised \"predict the next word\" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of \"instruction-tuning\" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With \"supervised\" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22146.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22146",
    "published": "2026-01-29T18:58:47Z",
    "updated": "2026-01-29T18:58:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出FineInstructions方法，通过将互联网规模预训练文档转化为大规模合成指令数据，使大型语言模型能从零开始通过指令调优进行预训练。",
      "motivation": "研究动机源于大型语言模型通常通过自监督的下一个词预测目标进行预训练，但为使模型对用户有用，需依赖有限的指令调优数据。现有监督数据不足，导致预训练与下游使用场景如响应用户提示的分布不一致，限制了模型性能。因此，本研究旨在克服监督数据稀缺性问题，通过生成大规模合成指令数据，优化预训练过程，使其更贴近实际应用需求，提高模型实用性和泛化能力。",
      "method": "论文提出一种程序，从真实用户查询和提示中提取约1800万个指令模板，并将其与互联网规模的非结构化预训练语料库中的人类撰写源文档进行匹配和实例化，生成数十亿的合成指令和答案训练对。关键创新点在于大规模合成数据生成技术，利用模板匹配机制将文档知识转化为监督学习样本，构建名为FineInstructions的数据集。该方法无需传统自监督预训练，直接从指令调优目标开始预训练，更接近下游任务分布。",
      "result": "通过控制性token-for-token训练实验，作者发现使用FineInstructions进行预训练的模型在标准基准测试中，衡量自由形式响应质量时，表现优于标准自监督预训练方法和其他合成预训练技术。实验结果突显了该方法的有效性，尽管摘要未提供具体性能指标，但强调了其相对优势，表明大规模合成指令数据能显著提升模型在下游任务中的响应质量和用户交互体验。",
      "conclusion": "本研究的主要贡献是开发了FineInstructions数据集和方法，证明了通过大规模合成指令数据可以使预训练更接近下游使用分布，具有重要学术价值，挑战了传统预训练范式并展示了指令调优目标的潜力。实际应用中，该方法可能提升大型语言模型的响应准确性和用户体验。未来工作可探索合成数据的优化、局限性及在更多任务上的扩展应用。",
      "tags": [
        "Large Language Model",
        "Instruction Tuning",
        "Synthetic Data Generation",
        "Pre-Training",
        "Self-Supervised Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:27.093389Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22141",
    "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data",
    "authors": [
      "Grzegorz Stefanski",
      "Alberto Presta",
      "Michal Byra"
    ],
    "abstract": "In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets, each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse, a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22141.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22141",
    "published": "2026-01-29T18:56:41Z",
    "updated": "2026-01-29T18:56:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了自适应剪枝框架 Routing the Lottery (RTL)，为异构数据发现多个专门子网络，以应对数据异质性挑战并提升模型性能。",
      "motivation": "现有剪枝方法基于 Lottery Ticket Hypothesis 通常假设单个通用子网络，但忽略了真实世界数据的异质性，如不同类、语义聚类或环境条件。这种假设限制了模型在处理多样化数据时的效率和准确性。为了解决这个问题，研究提出 RTL，旨在通过专门化子网络来更好地适应数据多样性，从而提高性能并减少冗余参数。",
      "method": "论文提出 Routing the Lottery (RTL) 自适应剪枝框架，基于 Lottery Ticket Hypothesis，探索在大型网络中发现多个专门子网络（称为自适应票证）。核心创新在于针对不同数据类别或条件定制子网络，可能通过语义聚类或条件路由机制实现。摘要未明确说明具体数据集和模型架构细节，但框架旨在灵活适应多种任务。",
      "result": "在多个数据集和任务上，RTL 在平衡准确率和召回率方面持续优于单模型和多模型基线。参数使用减少了高达10倍，同时表现出语义对齐的特性。此外，研究识别了子网络崩溃现象（在激进剪枝下的性能下降），并引入子网络相似性分数用于无标签诊断过度稀疏化问题，增强了方法在实际应用中的鲁棒性。",
      "conclusion": "论文的主要贡献是提出了 RTL 框架，将剪枝重新定义为对齐模型结构与数据异质性的机制。这具有重要的学术价值，推动了模块化和上下文感知深度学习的发展，并为实际应用提供了更高效的模型设计。未来工作可能进一步探索子网络优化的自动化方法，或扩展到更多复杂场景。",
      "tags": [
        "Lottery Ticket Hypothesis",
        "Pruning",
        "Adaptive Subnetworks",
        "Heterogeneous Data",
        "Semantic Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:21.070857Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22139",
    "title": "Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers",
    "authors": [
      "Xin Chen",
      "Feng Jiang",
      "Yiqian Zhang",
      "Hardy Chen",
      "Shuo Yan",
      "Wenya Xie",
      "Min Yang",
      "Shujian Huang"
    ],
    "abstract": "Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \\emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\\% higher accuracy, 22.90\\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \\href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22139.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22139",
    "published": "2026-01-29T18:56:12Z",
    "updated": "2026-01-29T18:56:12Z",
    "comment": "The manuscript is under review",
    "light_analysis": {
      "overview": "本文提出了主动交互式推理（PIR）范式，使推理大型语言模型能够在推理过程中主动询问以澄清不确定信息。",
      "motivation": "推理导向的大型语言模型在思维链提示下取得了显著进步，但其根本上受限于“盲目自思考”范式：即使关键信息缺失或模糊，也进行大量内部推理，导致推理效率低下和准确性不足。现有搜索或基于工具的框架主要处理知识不确定性，而忽视了前提和意图级别的不确定性，这使得模型无法有效应对用户交互场景中的模糊信息。因此，本研究旨在通过直接与用户交互来解决这些不确定性，将模型转变为主动询问者，从而提升推理的准确性和效率。",
      "method": "PIR方法的核心组件包括两个部分：一是基于不确定性感知的监督微调程序，训练模型识别并处理前提和意图的不确定性，使其具备交互式推理能力；二是通过用户模拟器驱动的策略优化框架，利用复合奖励来对齐模型行为与用户意图，优化推理过程。该框架结合了监督学习和强化学习，首先通过微调增强模型的基础能力，然后使用用户模拟器生成交互数据，通过策略梯度方法优化模型行为，确保在交互中高效澄清信息。",
      "result": "实验在数学推理、代码生成和文档编辑等任务上进行，PIR相比强基线方法表现出显著优势：准确率最高提高32.70%，通过率提升22.90%，BLEU得分改善41.36，同时减少了近一半的推理计算和不必要的交互回合。进一步的可靠性评估在事实知识、问答和缺失前提场景下证实了PIR的强泛化性和鲁棒性，表明其在不同任务中能有效处理不确定信息，提升整体性能。",
      "conclusion": "本文的主要贡献是提出主动交互式推理（PIR）范式，成功将大型语言模型从被动解决者转变为主动询问者，显著改善了推理的准确性和效率。其学术价值在于创新性地解决了推理中的前提和意图不确定性问题，扩展了交互式AI的应用范围；实际应用价值可能体现在智能助理、教育工具等领域，未来工作可探索扩展到更多复杂任务或优化交互策略以增强实用性。",
      "tags": [
        "Large Language Models",
        "Proactive Interactive Reasoning",
        "Supervised Fine-Tuning",
        "Reinforcement Learning",
        "User Simulation"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:36.276454Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22137",
    "title": "PRISM: Distribution-free Adaptive Computation of Matrix Functions for Accelerating Neural Network Training",
    "authors": [
      "Shenghao Yang",
      "Zhichao Wang",
      "Oleg Balabanov",
      "N. Benjamin Erichson",
      "Michael W. Mahoney"
    ],
    "abstract": "Matrix functions such as square root, inverse roots, and orthogonalization play a central role in preconditioned gradient methods for neural network training. This has motivated the development of iterative algorithms that avoid explicit eigendecompositions and rely primarily on matrix multiplications, making them well suited for modern GPU accelerators. We present PRISM (Polynomial-fitting and Randomized Iterative Sketching for Matrix functions computation), a general framework for accelerating iterative algorithms for computing matrix functions. PRISM combines adaptive polynomial approximation with randomized sketching: at each iteration, it fits a polynomial surrogate to the current spectrum via a sketched least-squares problem, adapting to the instance at hand with minimal overhead. We apply PRISM to accelerate Newton-Schulz-like iterations for matrix square roots and orthogonalization, which are core primitives in machine learning. Unlike prior methods, PRISM requires no explicit spectral bounds or singular value estimates; and it adapts automatically to the evolving spectrum. Empirically, PRISM accelerates training when integrated into Shampoo and Muon optimizers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22137.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22137",
    "published": "2026-01-29T18:55:46Z",
    "updated": "2026-01-29T18:55:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了PRISM框架，通过自适应多项式逼近和随机草图技术加速矩阵函数计算，从而提升神经网络训练效率。",
      "motivation": "矩阵函数如平方根和正交化在神经网络训练的梯度方法中扮演核心角色，现有迭代算法虽适合GPU加速，但往往依赖显式谱界或难以适应演化谱，这限制了算法的效率和适应性。因此，本研究旨在开发一种无需分布假设的自适应方法，以克服先前技术的不足，提升优化过程的整体性能。PRISM通过自适应计算矩阵函数，解决了在加速训练中因谱估计误差或固定参数导致的效率瓶颈。",
      "method": "PRISM框架结合自适应多项式逼近和随机草图技术：在每个迭代中，通过草图最小二乘问题拟合多项式代理来近似当前谱，实现自适应计算。该方法应用于加速Newton-Schulz类迭代，用于矩阵平方根和正交化，核心创新在于无需显式谱界或奇异值估计，能自动适应谱的变化。关键细节包括使用多项式拟合、随机草图、以及依赖矩阵乘法以适合GPU加速，适用于机器学习中的核心原语。",
      "result": "摘要中未明确说明具体实验数据，但指出PRISM在集成到Shampoo和Muon优化器时有效加速了训练。这表明PRISM在实际应用中能提升训练效率，尽管具体性能指标如准确率提升或计算时间减少百分比未被详细提及。与先前方法相比，PRISM提供了更好的适应性，但在实验对比方面信息有限。",
      "conclusion": "PRISM的主要贡献是提供了一个通用框架，用于自适应计算矩阵函数，无需先验谱信息，从而加速神经网络训练。该研究具有学术价值，推动了优化算法领域的发展，并展示了实际应用潜力，可集成到多种优化器中。未来工作可能包括扩展其他矩阵函数或应用于更多机器学习场景，潜在局限性可能在于计算复杂度或对不同优化器的泛化能力。",
      "tags": [
        "Matrix Functions",
        "Polynomial Approximation",
        "Randomized Sketching",
        "Newton-Schulz Iteration",
        "Neural Network Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:36.486235Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22136",
    "title": "StepShield: When, Not Whether to Intervene on Rogue Agents",
    "authors": [
      "Gloria Felicia",
      "Michael Eniolade",
      "Jinfeng He",
      "Zitha Sasindran",
      "Hemant Kumar",
      "Milan Hussain Angati",
      "Sandeep Bandarupalli"
    ],
    "abstract": "Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, not just whether. StepShield contains 9,213 code agent trajectories, including 1,278 meticulously annotated training pairs and a 7,935-trajectory test set with a realistic 8.1% rogue rate. Rogue behaviors are grounded in real-world security incidents across six categories. We propose three novel temporal metrics: Early Intervention Rate (EIR), Intervention Gap, and Tokens Saved. Surprisingly, our evaluation reveals that an LLM-based judge achieves 59% EIR while a static analyzer achieves only 26%, a 2.3x performance gap that is entirely invisible to standard accuracy metrics. We further show that early detection has direct economic benefits: our cascaded HybridGuard detector reduces monitoring costs by 75% and projects to $108M in cumulative savings over five years at enterprise scale. By shifting the focus of evaluation from whether to when, StepShield provides a new foundation for building safer and more economically viable AI agents. The code and data are released under an Apache 2.0 license.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22136.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22136",
    "published": "2026-01-29T18:55:46Z",
    "updated": "2026-01-29T18:55:46Z",
    "comment": "16 pages, 2 figures, 14 tables",
    "light_analysis": {
      "overview": "StepShield 是首个专注于评估 AI 代理安全违规检测时机的基准，而非仅检测是否发生。",
      "motivation": "现有代理安全基准依赖二元准确性度量，无法区分早期干预与事后分析，导致无法有效评估检测时机。例如，早期检测允许实时干预，而延迟检测仅具取证价值，这对实际安全应用至关重要。当前基准缺乏相关标准，因此需要新基准来填补这一空白，以提升 AI 代理的安全性和实用性。",
      "method": "StepShield 基准包含一个 9,213 个代码代理轨迹的数据集，分为 1,278 个训练对和 7,935 个测试轨迹，流氓率为 8.1%，基于六类现实世界安全事件。研究者提出三个新时间度量：早期干预率（EIR）、干预间隙和保存的令牌。评估采用基于大语言模型的法官和静态分析器，并开发级联的 HybridGuard 检测器来优化监控效率。",
      "result": "实验显示，基于大语言模型的法官实现 59% 的早期干预率（EIR），静态分析器仅 26%，性能差距为 2.3 倍，传统准确性度量无法体现此差异。级联的 HybridGuard 检测器将监控成本降低 75%，预计在企业规模下五年累计节省 1.08 亿美元，突显早期检测的经济效益。",
      "conclusion": "StepShield 通过引入时间维度评估，填补了现有安全基准的不足，为构建更安全、经济可行的 AI 代理提供了新基础。它不仅提升检测的时效性和实用性，还带来显著的经济利益，代码和数据的开源发布支持进一步研究与应用。",
      "tags": [
        "Agent Safety",
        "Temporal Metrics",
        "Large Language Models",
        "Static Analysis",
        "Cost Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:48.742941Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22135",
    "title": "PI-Light: Physics-Inspired Diffusion for Full-Image Relighting",
    "authors": [
      "Zhexin Liang",
      "Zhaoxi Chen",
      "Yongwei Chen",
      "Tianyi Wei",
      "Tengfei Wang",
      "Xingang Pan"
    ],
    "abstract": "Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22135.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22135",
    "published": "2026-01-29T18:55:36Z",
    "updated": "2026-01-29T18:55:36Z",
    "comment": "Accepted at ICLR 2026",
    "light_analysis": {
      "overview": "PI-Light 提出了一个基于物理启发扩散模型的两阶段框架，用于全图像光照，以提升泛化能力和物理合理性。",
      "motivation": "全图像光照问题面临数据收集困难、物理合理性难以维持以及数据驱动先验泛化有限等挑战，现有方法在合成到真实场景的转换中效果不佳，限制了实际应用。本研究旨在通过引入物理启发的组件来克服这些障碍，提高光照编辑的准确性和适用性，以应对复杂现实场景的需求。",
      "method": "PI-Light 采用两阶段框架，结合物理启发的扩散模型，核心创新包括批处理感知注意力增强图像间一致性、物理引导神经渲染模块确保光传输物理合理性、物理启发损失函数优化训练动态，以及一个多样化受控光照数据集。这些组件支持预训练扩散模型的高效微调，并为下游任务提供评估基准。",
      "result": "实验表明，PI-Light 能够合成各种材料的镜面高光和漫反射，在真实世界场景中展现出优于先前方法的泛化性能，摘要未明确说明具体数据指标，但强调了在泛化能力方面的显著提升，表明该框架在处理复杂光照条件下具有优势。",
      "conclusion": "PI-Light 通过整合物理启发的扩散模型，提高了全图像光照的物理合理性和泛化能力，为下游任务提供了可靠基准，在真实世界图像编辑中具有应用潜力。未来工作可能包括进一步优化模型或扩展应用场景，以增强其适应性。",
      "tags": [
        "Diffusion Models",
        "Neural Rendering",
        "Image Relighting",
        "Physics-Inspired Learning",
        "Batch-Aware Attention"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:42.323610Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22134",
    "title": "Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography",
    "authors": [
      "Wenxuan Li",
      "Pedro R. A. S. Bassi",
      "Lizhou Wu",
      "Xinze Zhou",
      "Yuxuan Zhao",
      "Qi Chen",
      "Szymon Plotka",
      "Tianyu Lin",
      "Zheren Zhu",
      "Marisa Martin",
      "Justin Caskey",
      "Shanshan Jiang",
      "Xiaoxi Chen",
      "Jaroslaw B. Ćwikla",
      "Artur Sankowski",
      "Yaping Wu",
      "Sergio Decherchi",
      "Andrea Cavalli",
      "Chandana Lall",
      "Cristian Tomasetti",
      "Yaxing Guo",
      "Xuan Yu",
      "Yuqing Cai",
      "Hualin Qiao",
      "Jie Bao",
      "Chenhan Hu",
      "Ximing Wang",
      "Arkadiusz Sitek",
      "Kai Ding",
      "Heng Li",
      "Meiyun Wang",
      "Dexin Yu",
      "Guang Zhang",
      "Yang Yang",
      "Kang Wang",
      "Alan L. Yuille",
      "Zongwei Zhou"
    ],
    "abstract": "Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22134.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22134",
    "published": "2026-01-29T18:55:23Z",
    "updated": "2026-01-29T18:55:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文开发了名为ePAI的AI系统，用于从CT扫描中早期和诊断前检测胰腺癌，显著提高检测敏感度。",
      "motivation": "胰腺导管腺癌（PDAC）是一种致命的实体恶性肿瘤，通常在晚期和不可手术阶段被发现。现有问题在于放射科医生在常规CT扫描中可能漏诊早期病变，回顾性研究表明专家能在患者后来确诊PDAC时识别这些漏诊病变。早期检测对改善预后至关重要，但现有方法依赖人工阅片，漏诊率高且易受主观因素影响。该研究旨在开发自动化工具以弥补这一不足，提高早期诊断率。",
      "method": "研究方法基于开发ePAI系统，这是一个自动化AI工具，用于从CT扫描中检测早期和诊断前的胰腺癌。核心创新点在于利用AI实现高精度病变定位和检测。训练数据来自单个医疗中心的1,598名患者的CT影像，但具体模型架构和算法细节摘要未明确说明。技术路线涉及机器学习或深度学习处理医学图像，重点是小至2毫米的病变检测。",
      "result": "在内部测试中，ePAI对直径小于2厘米的PDAC检测AUC为0.939-0.999，敏感度95.3%，特异性98.7%，能精确定位小至2毫米的病变。外部测试涉及6个中心的7,158名患者，AUC为0.918-0.945，敏感度91.5%，特异性88.0%，定位精度达5毫米。更重要的是，ePAI在临床诊断前3至36个月的CT扫描中检测到放射科医生漏诊的病例，成功识别159名患者中的75例，中位提前时间347天。多读研究显示，ePAI比30名认证放射科医生的敏感度高出50.3%，同时保持95.4%的可比特异性。",
      "conclusion": "论文的主要贡献是证明了ePAI系统能有效辅助早期和诊断前检测胰腺癌，学术价值在于推动AI在医学影像分析中的应用，展示了高精度和泛化能力。实际应用价值在于作为辅助工具，有望提升临床早期诊断率，改善患者预后。局限性或未来工作摘要未明确说明，但外部验证的成功提示需要更多多中心研究和长期临床评估以进一步验证其稳健性。",
      "tags": [
        "Medical Image Analysis",
        "Artificial Intelligence",
        "CT Scan",
        "Pancreatic Cancer Detection",
        "Early Detection"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:11.815562Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22132",
    "title": "Pay for Hints, Not Answers: LLM Shepherding for Cost-Efficient Inference",
    "authors": [
      "Ziming Dong",
      "Hardik Sharma",
      "Evan O'Toole",
      "Jaya Prakash Champati",
      "Kui Wu"
    ],
    "abstract": "Large Language Models (LLMs) deliver state-of-the-art performance on complex reasoning tasks, but their inference costs limit deployment at scale. Small Language Models (SLMs) offer dramatic cost savings yet lag substantially in accuracy. Existing approaches - routing and cascading - treat the LLM as an all-or-nothing resource: either the query bypasses the LLM entirely, or the LLM generates a complete response at full cost. We introduce LLM Shepherding, a framework that requests only a short prefix (a hint) from the LLM and provides it to SLM. This simple mechanism is surprisingly effective for math and coding tasks: even hints comprising 10-30% of the full LLM response improve SLM accuracy significantly. Shepherding generalizes both routing and cascading, and it achieves lower cost under oracle decision-making. We develop a two-stage predictor that jointly determines whether a hint is needed and how many tokens to request. On the widely-used mathematical reasoning (GSM8K, CNK12) and code generation (HumanEval, MBPP) benchmarks, Shepherding reduces costs by 42-94% relative to LLM-only inference. Compared to state-of-the-art routing and cascading baselines, shepherding delivers up to 2.8x cost reduction while matching accuracy. To our knowledge, this is the first work to exploit token-level budget control for SLM-LLM collaboration.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22132.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22132",
    "published": "2026-01-29T18:52:54Z",
    "updated": "2026-01-29T18:52:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了LLM Shepherding框架，通过仅从大语言模型请求短提示来辅助小语言模型，实现成本效益高的推理，这是首次利用token级预算控制优化SLM-LLM协作的方法。",
      "motivation": "大语言模型在复杂推理任务中表现优异，但其高推理成本限制了大规模部署，而小语言模型虽成本低廉，但准确性显著不足。现有方法如路由和级联将大语言模型视为全有或全无资源，缺乏灵活性，无法在成本和性能之间取得良好平衡。这一问题的重要性在于，随着AI应用的普及，高效推理方案对实际部署至关重要，需要解决现有方法的局限以促进广泛采用。",
      "method": "研究提出LLM Shepherding框架，其核心方法是从大语言模型请求一个短前缀（即提示），然后将该提示作为辅助输入提供给小语言模型，以生成完整响应。关键创新点包括一个两阶段预测器，它联合决定是否需要请求提示以及请求多少token，实现token级预算控制。该方法在数学推理任务（如GSM8K、CNK12）和代码生成任务（如HumanEval、MBPP）的基准数据集上进行测试，利用了这些数据集来评估框架的性能。",
      "result": "实验结果表明，在数学和编码任务中，即使提示只占完整响应的10-30%，也能显著提升小语言模型的准确性。相较于仅使用大语言模型的推理，Shepherding框架实现了42-94%的成本降低。与最先进的路由和级联基线方法相比，在保持相同准确性的同时，成本降低高达2.8倍，展示了其高效性和实用性，并在广泛基准测试中得到验证。",
      "conclusion": "该论文的主要贡献是首次利用token级预算控制优化SLM-LLM协作，通过LLM Shepherding框架实现了显著的成本节省和性能提升。这项研究具有重要的学术价值，为高效推理技术提供了新思路，并在实际应用中可能促进大语言模型的大规模部署。未来工作方向可能包括扩展应用到更多任务或改进预测器性能，但摘要未明确说明具体细节。",
      "tags": [
        "Large Language Model",
        "Small Language Model",
        "Token-Level Control",
        "Cascading Systems",
        "Routing Algorithms"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:36.978681Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22131",
    "title": "SMOG: Scalable Meta-Learning for Multi-Objective Bayesian Optimization",
    "authors": [
      "Leonard Papenmeier",
      "Petru Tighineanu"
    ],
    "abstract": "Multi-objective optimization aims to solve problems with competing objectives, often with only black-box access to a problem and a limited budget of measurements. In many applications, historical data from related optimization tasks is available, creating an opportunity for meta-learning to accelerate the optimization. Bayesian optimization, as a promising technique for black-box optimization, has been extended to meta-learning and multi-objective optimization independently, but methods that simultaneously address both settings - meta-learned priors for multi-objective Bayesian optimization - remain largely unexplored. We propose SMOG, a scalable and modular meta-learning model based on a multi-output Gaussian process that explicitly learns correlations between objectives. SMOG builds a structured joint Gaussian process prior across meta- and target tasks and, after conditioning on metadata, yields a closed-form target-task prior augmented by a flexible residual multi-output kernel. This construction propagates metadata uncertainty into the target surrogate in a principled way. SMOG supports hierarchical, parallel training: meta-task Gaussian processes are fit once and then cached, achieving linear scaling with the number of meta-tasks. The resulting surrogate integrates seamlessly with standard multi-objective Bayesian optimization acquisition functions.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22131.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22131",
    "published": "2026-01-29T18:51:58Z",
    "updated": "2026-01-29T18:51:58Z",
    "comment": "19 pages, 15 figures",
    "light_analysis": {
      "overview": "提出SMOG，一种基于多输出高斯过程的可扩展元学习模型，用于多目标贝叶斯优化，明确学习目标相关性。",
      "motivation": "多目标优化在黑盒环境下处理竞争目标时面临挑战，尤其在测量预算有限的情况下。贝叶斯优化作为黑盒优化技术，已在元学习和多目标优化领域独立应用，但缺乏整合元学习先验的方法来加速多目标优化。利用相关任务的历史数据进行元学习能显著提高效率，而现有技术对此结合不足，因此开发同时支持元学习和多目标贝叶斯优化的方法至关重要。",
      "method": "SMOG采用多输出高斯过程构建可扩展元学习模型，通过结构化联合先验学习目标间的相关性。关键创新包括在元数据条件下，以封闭形式增强目标先验，并引入灵活残差多输出核以原则性传播不确定性。模型支持分层和并行训练，元任务高斯过程一次拟合后缓存，实现与元任务数量的线性计算扩展，最终生成的代理模型与标准多目标贝叶斯优化获取函数无缝集成。",
      "result": "摘要未明确说明实验结果。基于方法描述，可以推断SMOG通过整合元学习和多目标优化，旨在提升优化效率和处理不确定性的能力。预计在相关任务中，SMOG能够加速收敛，优于传统贝叶斯优化方法，但具体性能指标如准确率提升或效率改进需参考论文正文中的实验验证。",
      "conclusion": "SMOG的主要贡献在于首次系统整合元学习先验到多目标贝叶斯优化中，提供了一个可扩展和模块化的框架。学术上，它推动了贝叶斯优化和多目标学习领域的发展；实践上，适用于需处理复杂优化问题和历史数据的应用场景。未来工作可能涉及进一步优化算法扩展性、应用于更多实际任务或探索其他元学习技术。",
      "tags": [
        "Meta-Learning",
        "Multi-Objective Bayesian Optimization",
        "Gaussian Process",
        "Multi-Output Kernel",
        "Scalable Algorithms"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:29.688364Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22130",
    "title": "World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems",
    "authors": [
      "Lakshya Gupta",
      "Litao Li",
      "Yizhe Liu",
      "Sriram Ganapathi Subramanian",
      "Kaheer Suleman",
      "Zichen Zhang",
      "Haoye Lu",
      "Sumit Pasupalak"
    ],
    "abstract": "Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observability, large database state, and hidden workflows with cascading side effects. We introduce World of Workflows (WoW), a realistic ServiceNow-based environment incorporating 4,000+ business rules and 55 active workflows embedded in the system, alongside WoW-bench, a benchmark of 234 tasks evaluating constrained agentic task completion and enterprise dynamics modeling capabilities. We reveal two major takeaways: (1) Frontier LLMs suffer from dynamics blindness, consistently failing to predict the invisible, cascading side effects of their actions, which leads to silent constraint violations, and (2) reliability in opaque systems requires grounded world modeling, where agents must mentally simulate hidden state transitions to bridge the observability gap when high-fidelity feedback is unavailable. For reliable and useful enterprise agents, WoW motivates a new paradigm to explicitly learn system dynamics. We release our GitHub for setting up and evaluating WoW.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22130.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22130",
    "published": "2026-01-29T18:51:54Z",
    "updated": "2026-01-29T18:51:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文引入了基于ServiceNow的World of Workflows (WoW) 基准，评估大型语言模型在企业系统中处理隐藏工作流和动态效应的能力，以解决动态盲区问题。",
      "motivation": "研究动机在于，尽管前沿大型语言模型在多个领域作为自主代理表现优异，但在复杂企业系统中，隐藏的工作流导致级联效应，而现有企业基准仅评估表面任务完成，类似于消费者基准，忽视了真实挑战如有限观察性、大数据库状态和级联副作用。这些问题限制了代理在实际企业环境中的可靠性，突显了开发更真实评估框架的必要性。",
      "method": "研究方法包括构建World of Workflows (WoW) 环境，基于ServiceNow集成4000多条业务规则和55个活跃工作流，模拟企业系统复杂性，并开发WoW-bench基准，包含234个任务，旨在评估代理在约束性任务完成和企业动态建模方面的能力。关键创新在于结合现实工作流和业务规则，以测试代理的隐藏效应预测和系统动态理解。",
      "result": "实验结果表明，前沿大型语言模型存在动态盲区，无法预测行动的隐形级联副作用，导致约束违规；同时，可靠性在模糊系统中需基于世界模型的推理，代理必须心理模拟隐藏状态转换以弥补观察性差距。与现有基准相比，突显了现有方法在捕捉企业动态方面的不足，强调了学习系统动态的重要性。摘要未明确说明具体性能指标如准确率提升。",
      "conclusion": "论文主要贡献在于引入WoW基准，推动企业代理的新范式，即显式学习系统动态以提高可靠性和实用性。学术价值在于促进世界模型在AI领域的应用，实际价值在于指导开发更有效的企业AI系统。局限性摘要未明确说明，未来工作可扩展基准或探索更先进的动态建模技术。",
      "tags": [
        "Large Language Models",
        "World Models",
        "Enterprise Benchmarks",
        "Workflow Systems",
        "ServiceNow"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:41.289534Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22128",
    "title": "The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR",
    "authors": [
      "Irsyad Adam",
      "Zekai Chen",
      "David Laprade",
      "Shaun Porwal",
      "David Laub",
      "Erik Reinertsen",
      "Arda Pekis",
      "Kevin Brown"
    ],
    "abstract": "Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22128.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22128",
    "published": "2026-01-29T18:49:37Z",
    "updated": "2026-01-29T18:49:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出SMB-Structure世界模型训练范式，结合联合嵌入预测架构（JEPA）和下一个令牌预测（SFT），以模拟纵向电子健康记录中的患者动态。",
      "motivation": "大型语言模型（LLMs）通过下一个词预测作为临床基础模型，取得了成功，但它们将患者视为文档来总结，而非动态系统来模拟。患者轨迹随时间、干预而演变，需要模型模拟动态而非仅预测令牌。现有方法如自回归基线无法充分捕获疾病动态，导致在处理复杂医疗任务时表现不足，因此开发新方法以改善动态建模至关重要。",
      "method": "SMB-Structure模型结合了联合嵌入预测架构（JEPA）和下一个令牌预测（SFT）。SFT用于在令牌空间重建未来患者状态，确保模型能处理原始数据；JEPA则从初始患者表示中预测未来状态，迫使模型在观察到下一状态前编码轨迹动态。该方法基于结构化电子健康记录数据，旨在学习患者动态的表示，核心创新在于将令牌预测与潜在空间预测结合，以增强对动态系统的建模能力。",
      "result": "实验在两个大规模队列上验证：Memorial Sloan Kettering（23,319名肿瘤患者，超过323,000患者年）和INSPECT（19,402名肺栓塞患者）。通过线性探针在疾病轨迹的多个点评估，结果表明，该训练范式学习到的嵌入能捕获疾病动态，这些动态无法通过自回归基线恢复。SMB-Structure在处理高患者异质性的复杂任务上达到竞争性能，展示了其在模拟动态过程方面的优势。",
      "conclusion": "论文的主要贡献是提出了新的世界模型训练范式，改善了纵向电子健康记录中患者动态的建模。学术上，这推动了临床基础模型向动态系统模拟方向发展；实际上，有助于处理如患者异质性高的复杂医疗任务，提高预测准确性。模型权重已公开，促进了进一步研究和应用。未来工作可扩展该方法到更多医疗场景，或结合更多数据类型。",
      "tags": [
        "Large Language Model",
        "Joint-Embedding Prediction Architecture (JEPA)",
        "Next-Token Prediction (SFT)",
        "World Model",
        "Longitudinal EHR"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:22.585364Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22127",
    "title": "EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers",
    "authors": [
      "John Flynn",
      "Wolfgang Paier",
      "Dimitar Dinev",
      "Sam Nhut Nguyen",
      "Hayk Poghosyan",
      "Manuel Toribio",
      "Sandipan Banerjee",
      "Guy Gafni"
    ],
    "abstract": "Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22127.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22127",
    "published": "2026-01-29T18:49:27Z",
    "updated": "2026-01-29T18:49:27Z",
    "comment": "Project page: https://edit-yourself.github.io/",
    "light_analysis": {
      "overview": "EditYourself 是一个基于扩散变换器的音频驱动视频编辑框架，可无缝编辑说话头部视频的视觉口语内容，包括添加、移除和重新计时。",
      "motivation": "当前生成视频模型擅长创建新内容，但在编辑现有预录制视频时存在关键缺口，尤其是对说话头部视频的口语脚本进行细微修改时，需要保持运动连贯性、说话者身份和准确的唇部同步。这一问题在专业视频后期制作中至关重要，因为传统方法难以平衡这些需求，导致编辑效率低下和质量损失，因此迫切需要一种高效且精确的视频编辑解决方案。",
      "method": "EditYourself 构建在通用视频扩散模型基础上，通过引入音频条件和区域感知、编辑聚焦的训练扩展，增强其视频到视频（V2V）编辑能力。该框架采用扩散变换器（DiT）技术，利用音频驱动生成，并结合时空修复技术实现精确的唇部同步和时间连贯的重组。关键创新包括音频条件控制、针对新添加段的逼真运动合成训练策略，以及确保长时间视觉保真度和身份一致性的机制。",
      "result": "摘要未明确说明具体实验数据，如准确率或效率指标，但描述该方法能够实现精确的唇部同步和时间连贯的重组，包括无缝添加、移除和重新计时视觉口语内容，并在新添加段中合成逼真的人类运动。这表明 EditYourself 在保持视觉保真度和身份一致性方面具有潜力，但未提供与基线方法的量化对比，需要进一步实验验证其性能提升。",
      "conclusion": "EditYourself 提出了一种创新的音频驱动视频编辑框架，解决了现有生成模型在编辑说话头部视频时的关键挑战，如唇部同步和身份保持，为生成视频模型在专业视频后期制作中的实际应用奠定了基础。这项工作具有重要的学术价值，推动了视频生成和编辑技术的发展，并展示了在影视制作等领域的应用前景，未来可探索更复杂的编辑场景或集成多模态输入以增强功能。",
      "tags": [
        "Diffusion Transformers",
        "Audio-Driven Video Editing",
        "Spatiotemporal Inpainting",
        "Lip Synchronization",
        "Video-to-Video Editing"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:36.945855Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22125",
    "title": "Creative Image Generation with Diffusion Model",
    "authors": [
      "Kunpeng Song",
      "Ahmed Elgammal"
    ],
    "abstract": "Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22125.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22125",
    "published": "2026-01-29T18:48:48Z",
    "updated": "2026-01-29T18:48:48Z",
    "comment": "Project page: https://creative-t2i.github.io",
    "light_analysis": {
      "overview": "提出一种基于扩散模型的创造性图像生成框架，通过逆概率驱动和pullback机制，实现高创造性和视觉保真度。",
      "motivation": "创造性图像生成是AI研究中的关键领域，旨在生成新颖、高质量的图像以扩展想象边界。现有方法多依赖手动混合概念或排除子类别，缺乏系统性且效率低下，限制了创意潜力。本研究旨在解决这一问题，通过计算概率分布来提供一种更原则化的方法，以应对对创新视觉内容的需求，并克服传统方法的不足。",
      "method": "本研究提出一个基于扩散模型的框架，将创造性关联到CLIP嵌入空间中图像存在的逆概率。核心方法是计算生成图像的概率分布，驱使其向低概率区域，以产生稀有和视觉吸引人的输出。关键创新点包括引入pullback机制，确保在高创造性生成过程中不牺牲视觉保真度。实验基于文本到图像扩散模型进行，具体数据集摘要未明确说明，但框架依赖于CLIP嵌入和扩散模型的架构。",
      "result": "在广泛的实验中，本框架在文本到图像扩散模型上展示了有效性和效率，能够生成独特、新颖且发人深省的图像。摘要未提供具体的性能指标如准确率提升，但强调了框架相较于先前手动方法的优势，实现了高创造性输出。与基线方法的对比摘要未明确说明，但实验证明了其能力，可能包括生成图像的多样性和质量评估。",
      "conclusion": "本研究的主要贡献是提供了一种新视角和原则化方法来探索生成模型的创造性，通过逆概率驱动和pullback机制促进视觉内容合成的创新。其学术价值在于为创意生成提供了理论基础，应用价值体现在艺术、设计等领域的实际内容创作中。未来工作可能包括扩展到其他生成任务或优化机制，但摘要未明确说明局限性。",
      "tags": [
        "Diffusion Model",
        "CLIP",
        "Creative Image Generation",
        "Pullback Mechanisms",
        "Text-to-Image Generation"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:37.446757Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22124",
    "title": "A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine",
    "authors": [
      "Anran Li",
      "Yuanyuan Chen",
      "Wenjun Long",
      "Yu Yin",
      "Yan Hu",
      "Hyunjae Kim",
      "Weipeng Zhou",
      "Yujia Zhou",
      "Hongyi Peng",
      "Yang Ren",
      "Xuguang Ai",
      "Zhenyue Qin",
      "Ming Hu",
      "Xiaoxiao Li",
      "Han Yu",
      "Yih-Chung Tham",
      "Lucila Ohno-Machado",
      "Hua Xu",
      "Qingyu Chen"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.",
    "categories": [
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22124.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22124",
    "published": "2026-01-29T18:48:21Z",
    "updated": "2026-01-29T18:48:21Z",
    "comment": "38 pages, 9 tables, 3 figures",
    "light_analysis": {
      "overview": "提出了联邦学习和参数高效的框架Fed-MedLoRA与Fed-MedLoRA+，以解决医学大语言模型训练中的通信开销和数据异质性挑战。",
      "motivation": "医学大语言模型通常基于单一机构数据进行训练，面临泛化性和安全性的局限性，尤其在异构临床系统中。联邦学习虽能促进跨医疗机构协作，但应用于大型语言模型时存在显著障碍：传统方法需传输完整模型，导致通信开销大且计算资源受限；同时，多数联邦学习算法假设数据同质性，而真实临床数据因患者、疾病和机构实践的差异而高度异质。这些不足限制了医学大语言模型的实际部署和安全性，因此需要一种高效且适应异质性的新框架。",
      "method": "论文提出了一个模型无关的参数高效联邦学习框架。Fed-MedLoRA的核心创新是仅传输低秩适配器参数，而非整个大型语言模型，从而大幅降低通信和计算开销。Fed-MedLoRA+进一步引入自适应、数据感知聚合策略，以优化在跨站点数据异质性下的收敛性能。该框架应用于临床信息提取任务，旨在将患者叙述转化为结构化的医疗实体和关系；使用了真实世界数据集，如耶鲁纽黑文健康系统的临床笔记，以增强实用性。",
      "result": "论文在多个患者队列中评估了框架的准确性，设置包括域内训练与测试、独立队列的外部验证，以及低资源新站点适应场景。通过与BERT模型、LLaMA-3、DeepSeek-R1和GPT-4o等基线模型进行比较，展示了框架在提升适应性和效率方面的潜力。然而，摘要未明确说明具体性能指标数据，如准确率提升百分比，但强调了评估的全面性和与现有模型的对比，以验证方法的有效性。",
      "conclusion": "该研究的主要贡献是开发了联邦和参数高效的框架Fed-MedLoRA与Fed-MedLoRA+，成功解决了医学大语言模型训练中的通信开销和数据异质性挑战。学术价值在于推动了联邦学习在资源密集型模型中的应用，拓展了协作AI的边界；实际应用价值是促进医疗AI的安全跨机构部署，提高模型在异质临床数据中的适应性。局限性或未来工作方向，如进一步优化聚合策略或扩展到更多医疗任务，摘要未明确说明，但可为后续研究提供方向。",
      "tags": [
        "Federated Learning",
        "Large Language Models",
        "Parameter-Efficient Training",
        "Low-Rank Adaptation",
        "Clinical Information Extraction"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:07.862604Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22123",
    "title": "Learning Hamiltonian Flow Maps: Mean Flow Consistency for Large-Timestep Molecular Dynamics",
    "authors": [
      "Winfried Ripken",
      "Michael Plainer",
      "Gregor Lied",
      "Thorben Frank",
      "Oliver T. Unke",
      "Stefan Chmiela",
      "Frank Noé",
      "Klaus Robert Müller"
    ],
    "abstract": "Simulating the long-time evolution of Hamiltonian systems is limited by the small timesteps required for stable numerical integration. To overcome this constraint, we introduce a framework to learn Hamiltonian Flow Maps by predicting the mean phase-space evolution over a chosen time span $Δt$, enabling stable large-timestep updates far beyond the stability limits of classical integrators. To this end, we impose a Mean Flow consistency condition for time-averaged Hamiltonian dynamics. Unlike prior approaches, this allows training on independent phase-space samples without access to future states, avoiding expensive trajectory generation. Validated across diverse Hamiltonian systems, our method in particular improves upon molecular dynamics simulations using machine-learned force fields (MLFF). Our models maintain comparable training and inference cost, but support significantly larger integration timesteps while trained directly on widely-available trajectory-free MLFF datasets.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22123.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22123",
    "published": "2026-01-29T18:47:46Z",
    "updated": "2026-01-29T18:47:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种通过学习哈密顿流映射并引入均值流一致性条件，实现稳定大时间步长分子动力学模拟的新框架。",
      "motivation": "哈密顿系统的长时间演化模拟受到数值积分所需小时间步长的限制，经典积分器为保持稳定性必须使用较小步长，这增加了计算成本。现有机器学习方法在训练时往往需要轨迹数据或未来状态信息，导致训练过程昂贵且效率低下。因此，开发一种能突破稳定性限制、降低训练成本的框架对于提高模拟效率具有重要意义。",
      "method": "该方法提出学习哈密顿流映射来预测在选定时间跨度内的平均相空间演化，实现大时间步长更新。关键创新在于施加均值流一致性条件，处理时间平均的哈密顿动力学，使训练仅需独立相空间样本，无需访问未来状态，避免了昂贵的轨迹生成。模型直接基于广泛可得的无轨迹机器学习力场（MLFF）数据集进行训练，核心包括预测相位演化并确保动力学的准确性。",
      "result": "实验验证显示，该方法在多种哈密顿系统上有效，特别是在使用机器学习力场（MLFF）的分子动力学模拟中表现出改进。模型支持显著更大的积分时间步长，远超出经典积分器的稳定性限制，同时保持与现有方法可比的训练和推理成本。这大幅提升了模拟效率，无需依赖昂贵轨迹数据，但摘要未明确说明具体性能提升的数值指标。",
      "conclusion": "该研究的主要贡献是提出了一个基于均值流一致性条件的哈密顿流映射学习框架，解决了数值积分中的时间步长限制问题，具有重要学术价值。在实际应用上，它提高了分子动力学模拟的效率，尤其在机器学习力场领域可降低计算成本。未来工作可探索扩展到更复杂系统或优化模型性能，但摘要未明确说明局限性。",
      "tags": [
        "Hamiltonian Flow Maps",
        "Mean Flow Consistency",
        "Machine Learning Force Fields",
        "Molecular Dynamics Simulation",
        "Numerical Integration"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:25.137142Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22118",
    "title": "Defining Operational Conditions for Safety-Critical AI-Based Systems from Data",
    "authors": [
      "Johann Christensen",
      "Elena Hoemann",
      "Frank Köster",
      "Sven Hallerbach"
    ],
    "abstract": "Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22118.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22118",
    "published": "2026-01-29T18:46:02Z",
    "updated": "2026-01-29T18:46:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种使用多维核表示从数据后验定义操作设计域的方法，以支持安全关键AI系统的认证。",
      "motivation": "安全关键AI系统在复杂现实环境或已有数据场景下，定义其操作设计域（ODD）极具挑战，常导致环境描述不完整，影响系统认证。传统方法在开发早期依赖专家知识和标准，难以适应现有数据，可能导致ODD定义不准确或不全面，限制了AI系统在安全关键应用中的可靠部署。因此，迫切需要一种从数据中后验定义ODD的方法来弥补这一不足，提升系统安全性和认证效率。",
      "method": "本研究提出了一种Safety-by-Design方法，通过多维核表示从先前收集的数据中后验定义ODD。核心创新在于利用核技术建模环境条件，增强了ODD定义的灵活性和精确性。方法通过Monte Carlo模拟和真实航空用例（如未来安全关键碰撞避免系统）进行验证，但摘要未明确说明具体的数据集或模型架构细节。",
      "result": "通过Monte Carlo方法和真实航空用例验证，该方法能有效从数据中定义ODD。论文提出了ODD相等的条件，并证明数据驱动的ODD可以等于数据中原始隐藏的ODD，从而支持系统认证。摘要未提供具体的性能指标如准确率提升，但暗示了方法相对于传统方式在定义完整性方面的改进潜力。",
      "conclusion": "论文的主要贡献是提出了一种数据驱动方法来后验定义安全关键AI系统的ODD，促进了这些系统的认证过程。该方法具有学术价值，为安全工程提供了新工具，实际应用上可提升AI系统的可靠性和安全性。摘要未明确提及局限性或未来工作方向，但可推断未来可能包括扩展方法到更多领域或处理更复杂数据。",
      "tags": [
        "Safety-Critical AI",
        "Operational Design Domain",
        "Kernel-Based Representation",
        "Monte Carlo Simulation",
        "Data-Driven Certification"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:45.231343Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22114",
    "title": "SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence",
    "authors": [
      "Saoud Aldowaish",
      "Yashwanth Karumanchi",
      "Kai-Chen Chiang",
      "Soroosh Noorzad",
      "Morteza Fayazi"
    ],
    "abstract": "Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22114.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22114",
    "published": "2026-01-29T18:41:52Z",
    "updated": "2026-01-29T18:41:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "SINA是一个开源全自动电路原理图图像到网表生成器，通过集成深度学习、CCL、OCR和VLM技术，显著提高了转换准确率。",
      "motivation": "电路原理图图像转换为机器可读网表是电子设计自动化中的关键步骤，但现有方法在组件识别和连接性推断方面存在困难，导致转换准确率低，影响了自动化设计的效率和可靠性。因此，开发更精确的解决方案对于提升电路设计流程至关重要。摘要未明确说明具体应用场景的局限性，但强调了现有方法的不足。",
      "method": "SINA采用多技术集成的方法：使用深度学习进行准确的组件检测；应用Connected-Component Labeling (CCL) 提取连接性；结合OCR技术检索组件参考指示符；并利用Vision-Language Model (VLM) 进行可靠的参考指示符分配。关键创新在于融合视觉和语言模型，实现全自动、高精度的网表生成，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "在实验中，SINA实现了96.47%的总体网表生成准确率，相比于现有最先进方法，准确率提升了2.72倍。这一结果表明SINA在组件识别和连接性推断方面表现优异，显著超越了基线方法，为电路原理图转换提供了高效的性能改进。摘要未提供更多具体对比数据，但强调了提升效果。",
      "conclusion": "SINA的主要贡献在于提出了一个集成多种AI技术的全自动电路原理图图像到网表生成器，解决了现有方法的准确性问题，具有开源优势促进了广泛应用。其学术价值体现在推进电子设计自动化技术，实际应用价值在于提高电路设计效率。未来工作可能包括处理更复杂电路或优化模型，但摘要未明确说明局限性或具体方向。",
      "tags": [
        "Deep Learning",
        "Connected-Component Labeling",
        "Optical Character Recognition",
        "Vision-Language Model",
        "Circuit Schematic Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:57.193934Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22111",
    "title": "Physics Informed Reconstruction of Four-Dimensional Atmospheric Wind Fields Using Multi-UAS Swarm Observations in a Synthetic Turbulent Environment",
    "authors": [
      "Abdullah Tasim",
      "Wei Sun"
    ],
    "abstract": "Accurate reconstruction of atmospheric wind fields is essential for applications such as weather forecasting, hazard prediction, and wind energy assessment, yet conventional instruments leave spatio-temporal gaps within the lower atmospheric boundary layer. Unmanned aircraft systems (UAS) provide flexible in situ measurements, but individual platforms sample wind only along their flight trajectories, limiting full wind-field recovery. This study presents a framework for reconstructing four-dimensional atmospheric wind fields using measurements obtained from a coordinated UAS swarm. A synthetic turbulence environment and high-fidelity multirotor simulation are used to generate training and evaluation data. Local wind components are estimated from UAS dynamics using a bidirectional long short-term memory network (Bi-LSTM) and assimilated into a physics-informed neural network (PINN) to reconstruct a continuous wind field in space and time. For local wind estimation, the bidirectional LSTM achieves root-mean-square errors (RMSE) of 0.064 and 0.062 m/s for the north and east components in low-wind conditions, increasing to 0.122 to 0.129 m/s under moderate winds and 0.271 to 0.273 m/s in high-wind conditions, while the vertical component exhibits higher error, with RMSE values of 0.029 to 0.091 m/s. The physics-informed reconstruction recovers the dominant spatial and temporal structure of the wind field up to 1000 m altitude while preserving mean flow direction and vertical shear. Under moderate wind conditions, the reconstructed mean wind field achieves an overall RMSE between 0.118 and 0.154 m/s across evaluated UAS configurations, with the lowest error obtained using a five-UAS swarm. These results demonstrate that coordinated UAS measurements enable accurate and scalable four-dimensional wind-field reconstruction without dedicated wind sensors or fixed infrastructure.",
    "categories": [
      "cs.LG",
      "eess.SY",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22111.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22111",
    "published": "2026-01-29T18:40:32Z",
    "updated": "2026-01-29T18:40:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种结合双向LSTM和物理信息神经网络的框架，利用多UAS群观测在合成湍流环境中重建四维大气风场。",
      "motivation": "大气风场准确重建对天气预报、灾害预测和风能评估等应用至关重要，但传统测量仪器在低大气边界层存在时空间隙，无法全面覆盖。无人飞行器系统（UAS）虽能提供灵活的原位测量，但单个平台仅能沿飞行轨迹采样，难以恢复全风场。本研究旨在解决这一问题，利用协调的UAS群观测填补间隙，克服现有方法的局限性，实现高效、连续的風场重建。",
      "method": "研究方法基于合成湍流环境和高保真多旋翼模拟生成训练与评估数据。首先采用双向长短期记忆网络（Bi-LSTM）从UAS动态中估计局部风分量，然后将这些估计同化到物理信息神经网络（PINN）中，重建连续的空间和时间风场。关键创新在于整合深度学习和物理约束，提升重建精度，使用了模拟数据作为基础，无需专用风传感器或固定基础设施。",
      "result": "实验结果表明，Bi-LSTM在不同风况下对局部风分量估计的均方根误差（RMSE）为：低风条件北向0.064 m/s、东向0.062 m/s，中风条件增至0.122-0.129 m/s，高风条件达0.271-0.273 m/s，垂直分量误差较高。物理信息重建能恢复至1000米高度的风场主要时空结构，中等风况下整体RMSE为0.118-0.154 m/s，五UAS群配置误差最低，较基线方法（摘要未明确说明对比细节）展现了更好的准确性和可扩展性。",
      "conclusion": "本研究成功提出了一个框架，利用协调UAS群观测和物理信息神经网络重建四维大气风场，无需专用风传感器或固定基础设施。主要贡献在于整合了Bi-LSTM和PINN技术，实现了准确且可扩展的風场重建，提升了天气预报和风能评估的潜力。学术价值在于推动物理信息学习在气象学中的应用，实际应用可减少测量依赖。局限性或未来工作包括在真实环境验证和进一步优化方法（摘要未明确说明具体方向）。",
      "tags": [
        "Unmanned Aircraft Systems (UAS)",
        "Bidirectional Long Short-Term Memory (Bi-LSTM)",
        "Physics-Informed Neural Networks (PINN)",
        "Atmospheric Wind Field Reconstruction",
        "Swarm Observations"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:27.936252Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22108",
    "title": "Value-Based Pre-Training with Downstream Feedback",
    "authors": [
      "Shuqi Ke",
      "Giulia Fanti"
    ],
    "abstract": "Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction), which can misallocate compute away from downstream capabilities of interest. We introduce V-Pretraining: a value-based, modality-agnostic method for controlled continued pretraining in which a lightweight task designer reshapes the pretraining task to maximize the value of each gradient step. For example, consider self-supervised learning (SSL) with sample augmentation. The V-Pretraining task designer selects pretraining tasks (e.g., augmentations) for which the pretraining loss gradient is aligned with a gradient computed over a downstream task (e.g., image segmentation). This helps steer pretraining towards relevant downstream capabilities. Notably, the pretrained model is never updated on downstream task labels; they are used only to shape the pretraining task. Under matched learner update budgets, V-Pretraining of 0.5B--7B language models improves reasoning (GSM8K test Pass@1) by up to 18% relative over standard next-token prediction using only 12% of GSM8K training examples as feedback. In vision SSL, we improve the state-of-the-art results on ADE20K by up to 1.07 mIoU and reduce NYUv2 RMSE while improving ImageNet linear accuracy, and we provide pilot evidence of improved token efficiency in continued pretraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22108.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22108",
    "published": "2026-01-29T18:38:09Z",
    "updated": "2026-01-29T18:38:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 V-Pretraining，一种基于下游反馈的预训练方法，通过任务设计器引导预训练任务以提升下游能力。",
      "motivation": "标准预训练方法如下一个令牌预测优化固定代理目标，可能导致计算资源分配不当，忽视下游任务的关键能力。现有方法缺乏有效机制将下游反馈融入预训练过程，限制了预训练模型的效率和实际应用效果。因此，研究如何利用少量验证信息引导预训练，以更高效地提升下游性能，具有重要理论和实践价值，解决了现有预训练方法目标不匹配的不足之处。",
      "method": "V-Pretraining 是一种基于价值、模态无关的继续预训练方法，核心是通过轻量级任务设计器动态选择预训练任务，使预训练损失梯度与下游任务计算梯度对齐。关键技术包括自监督学习（SSL）和样本增强，设计器仅使用下游任务标签重塑预训练任务，而不直接更新预训练模型。这种方法适用于语言和视觉模型，实现了对预训练过程的控制引导，提高了任务相关性的优化。",
      "result": "实验显示，在语言模型中，0.5B-7B 规模的模型在 GSM8K 测试中 Pass@1 相对标准下一个令牌预测提升最多 18%，仅使用 12% GSM8K 训练样本作为反馈。在视觉 SSL 中，ADE20K 的 mIoU 提高最多 1.07，NYUv2 RMSE 降低，同时 ImageNet 线性准确率提升，并提供了继续预训练中令牌效率改进的初步证据。结果表明 V-Pretraining 在资源有限时显著优于基线方法。",
      "conclusion": "V-Pretraining 的主要贡献是通过下游反馈优化预训练任务设计，在不直接训练下游标签的情况下提升模型性能，挑战了传统固定目标预训练范式。学术上引入基于价值的预训练框架，实践上在语言推理和视觉分割任务中验证了效率和效果增益，具有广泛应用潜力。未来工作可进一步探索更多模态扩展和优化方法，以增强通用性和稳定性。",
      "tags": [
        "V-Pretraining",
        "Self-Supervised Learning",
        "Gradient Alignment",
        "Task Designer"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:54.745720Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22107",
    "title": "Prior-Informed Flow Matching for Graph Reconstruction",
    "authors": [
      "Harvey Chen",
      "Nicolas Zilberstein",
      "Santiago Segarra"
    ],
    "abstract": "We introduce Prior-Informed Flow Matching (PIFM), a conditional flow model for graph reconstruction. Reconstructing graphs from partial observations remains a key challenge; classical embedding methods often lack global consistency, while modern generative models struggle to incorporate structural priors. PIFM bridges this gap by integrating embedding-based priors with continuous-time flow matching. Grounded in a permutation equivariant version of the distortion-perception theory, our method first uses a prior, such as graphons or GraphSAGE/node2vec, to form an informed initial estimate of the adjacency matrix based on local information. It then applies rectified flow matching to refine this estimate, transporting it toward the true distribution of clean graphs and learning a global coupling. Experiments on different datasets demonstrate that PIFM consistently enhances classical embeddings, outperforming them and state-of-the-art generative baselines in reconstruction accuracy.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22107.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22107",
    "published": "2026-01-29T18:38:02Z",
    "updated": "2026-01-29T18:38:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "PIFM通过整合嵌入先验与连续时间流匹配，提出一种条件流模型，有效提高了图重构的准确性和全局一致性。",
      "motivation": "图重构问题在部分观察条件下极具挑战性，广泛应用于社交网络、推荐系统和生物信息学等领域。现有方法如经典嵌入技术（如GraphSAGE和node2vec）往往缺乏全局一致性，无法有效处理整体图结构；而现代生成模型则难以融入先验结构信息，导致重构效果不佳。因此，亟需一种能结合局部嵌入先验和全局生成能力的新方法，以提升重构精度和鲁棒性。",
      "method": "PIFM方法首先基于失真感知理论的排列等变版本，利用先验技术（如图子或GraphSAGE/node2vec嵌入）从局部信息形成邻接矩阵的初始估计。接着，应用修正流匹配技术，通过连续时间流传输将初始估计精炼并移向清洁图的真实分布，从而学习全局耦合。该方法的核心创新在于将基于嵌入的先验与连续时间流匹配结合，实现局部信息与全局结构的有效整合。",
      "result": "在不同数据集上的实验验证了PIFM的有效性。实验结果表明，PIFM consistently enhances classical embeddings，并在重构准确性上超越了这些嵌入方法和当前最先进的生成基线模型。尽管摘要未提供具体性能指标如准确率提升数字，但论文明确指出PIFM显著提高了重构性能，显示出其在图重构任务中的优越性。",
      "conclusion": "PIFM的研究成功弥合了嵌入方法和生成模型之间的差距，为图重构任务提供了一种创新的解决方案。其主要贡献在于结合了先验知识和流匹配技术，提高了重构的准确性和全局一致性。学术上，该方法推动了图生成和重构领域的发展；实际应用中，可增强社交网络分析、蛋白质结构预测等任务的性能。未来工作可能包括扩展到更大规模图或更复杂场景，并可能探索其他先验类型和流匹配变体。",
      "tags": [
        "Prior-Informed Flow Matching",
        "Graph Reconstruction",
        "Graph Embeddings",
        "Continuous-Time Flow Matching",
        "Distortion-Perception Theory"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:59.966621Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22101",
    "title": "ECO: Quantized Training without Full-Precision Master Weights",
    "authors": [
      "Mahdi Nikdan",
      "Amir Zandieh",
      "Dan Alistarh",
      "Vahab Mirrokni"
    ],
    "abstract": "Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22101.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22101",
    "published": "2026-01-29T18:35:01Z",
    "updated": "2026-01-29T18:35:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "ECO提出了一种无需全精度主权重的量化训练方法，通过误差补偿优化器直接更新量化参数，显著减少内存开销。",
      "motivation": "量化训练虽能提升大型语言模型的计算和内存效率，但现有方法仍依赖高精度主权重缓冲区来累积更新，这带来了显著的内存开销，尤其对于稀疏专家混合模型而言，模型参数和优化器状态占主导内存使用。该研究旨在解决内存效率问题，因为内存限制是训练大型模型的关键瓶颈，现有方法的不足之处在于主权重的引入增加了内存负担，影响大规模模型训练的可行性。",
      "method": "研究提出的核心方法是误差补偿优化器，它消除了主权重，通过直接在量化参数上应用梯度更新；关键创新在于量化误差被注入优化器动量，形成无额外内存的误差反馈循环；使用FP8量化预训练小型Transformer、Gemma-3 1B和2.1B稀疏MoE模型，以及INT4量化微调DeepSeek-MoE-16B，以验证方法的有效性。",
      "result": "实验结果显示，ECO在多种模型上实现了接近无损的精度，与使用主权重的基线方法匹配，例如在静态内存与验证损失的Pareto前沿中，ECO显著改进了平衡点；这表明ECO在保持类似准确率的同时，减少了内存使用，但摘要未提供具体数据百分比，而是强调性能的相似性和内存效率的提升。",
      "conclusion": "论文的主要贡献是提出ECO方法，消除主权重的内存开销，并通过理论证明其收敛性；学术价值在于优化量化训练算法，提升内存效率，实际应用价值广泛，尤其适合大规模稀疏专家混合模型训练；未来工作可能包括扩展到更复杂模型或进一步优化量化策略，但摘要未明确说明具体方向。",
      "tags": [
        "Quantized Training",
        "Error Compensation",
        "Sparse Mixture of Experts",
        "FP8 Quantization",
        "Optimizer Design"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:06.601753Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22100",
    "title": "Boosting CVaR Policy Optimization with Quantile Gradients",
    "authors": [
      "Yudong Luo",
      "Erick Delage"
    ],
    "abstract": "Optimizing Conditional Value-at-risk (CVaR) using policy gradient (a.k.a CVaR-PG) faces significant challenges of sample inefficiency. This inefficiency stems from the fact that it focuses on tail-end performance and overlooks many sampled trajectories. We address this problem by augmenting CVaR with an expected quantile term. Quantile optimization admits a dynamic programming formulation that leverages all sampled data, thus improves sample efficiency. This does not alter the CVaR objective since CVaR corresponds to the expectation of quantile over the tail. Empirical results in domains with verifiable risk-averse behavior show that our algorithm within the Markovian policy class substantially improves upon CVaR-PG and consistently outperforms other existing methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22100.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22100",
    "published": "2026-01-29T18:33:46Z",
    "updated": "2026-01-29T18:33:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过引入量化梯度增强CVaR策略优化，有效解决了CVaR-PG方法中的样本效率低下问题。",
      "motivation": "在强化学习中，优化条件风险价值（CVaR）采用策略梯度方法（CVaR-PG）时，面临样本效率低下的关键挑战，因为它仅关注尾部性能评估而忽略了大量采样轨迹，导致数据利用率不足。这一问题在风险厌恶设置中尤为重要，例如金融或安全关键领域，现有方法因忽略中间数据而限制了实际应用效果。摘要未明确说明更广泛背景，但可推断CVaR优化在不确定性环境中对决策稳健性至关重要，当前方法的不足在于缺乏高效利用所有样本的机制。",
      "method": "研究提出通过添加期望分位数项来增强CVaR目标，结合量化优化技术，允许使用动态规划公式处理所有采样数据，从而提高样本效率。核心创新点在于将CVaR分解为尾部期望，并利用分位数梯度进行优化，在马尔可夫策略类中实现高效学习。关键细节包括：采用量化方法避免传统CVaR-PG对尾部数据的过度依赖，通过动态规划框架整合全数据集，但摘要未明确说明具体模型架构或数据集。技术特色在于平衡风险估计和数据利用，改进策略优化过程。",
      "result": "在可验证风险厌恶行为的实验领域中，该算法在马尔可夫策略类下显著优于基线CVaR-PG方法，并一致超越其他现有方法，显示出性能提升。摘要未提供具体准确率或效率数据，如百分比改进，但表明改进是实质性的且具有一致性，通过对比实验验证了样本效率的增强效果。结果强调了该方法在风险敏感场景中的有效性，优于传统优化技术。",
      "conclusion": "本研究的主要贡献是提出一种基于量化梯度的CVaR策略优化方法，通过提高样本效率来增强风险厌恶强化学习的性能。学术价值在于改进了CVaR优化的理论基础，结合动态规划解决数据利用率问题；实际应用价值体现在金融、机器人等需要稳健决策的领域。局限性方面，摘要未明确说明，但未来工作可能涉及扩展到非马尔可夫设置或更复杂环境。",
      "tags": [
        "Conditional Value-at-risk (CVaR)",
        "Policy Gradient",
        "Quantile Optimization",
        "Dynamic Programming",
        "Markov Decision Processes"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:17.138908Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22095",
    "title": "GeoNorm: Unify Pre-Norm and Post-Norm with Geodesic Optimization",
    "authors": [
      "Chuanyang Zheng",
      "Jiankai Sun",
      "Yihang Gao",
      "Chi Wang",
      "Yuehao Wang",
      "Jing Xiong",
      "Liliang Ren",
      "Bo Peng",
      "Qingmei Wang",
      "Xiaoran Shang",
      "Mac Schwager",
      "Anderson Schneider",
      "Yuriy Nevmyvaka",
      "Xiaodong Liu"
    ],
    "abstract": "The placement of normalization layers, specifically Pre-Norm and Post-Norm, remains an open question in Transformer architecture design. In this work, we rethink these approaches through the lens of manifold optimization, interpreting the outputs of the Feed-Forward Network (FFN) and attention layers as update directions in optimization. Building on this perspective, we introduce GeoNorm, a novel method that replaces standard normalization with geodesic updates on the manifold. Furthermore, analogous to learning rate schedules, we propose a layer-wise update decay for the FFN and attention components. Comprehensive experiments demonstrate that GeoNorm consistently outperforms existing normalization methods in Transformer models. Crucially, GeoNorm can be seamlessly integrated into standard Transformer architectures, achieving performance improvements with negligible additional computational cost.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22095.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22095",
    "published": "2026-01-29T18:31:31Z",
    "updated": "2026-01-29T18:31:31Z",
    "comment": "Tech Report",
    "light_analysis": {
      "overview": "GeoNorm提出了一种基于测地优化的归一化方法，统一了Transformer架构中的Pre-Norm和Post-Norm，提供了一种新颖且高效的解决方案。",
      "motivation": "该研究的动机源于Transformer架构中归一化层放置的开放性问题。具体来说，Pre-Norm和Post-Norm作为常见方法，各自在训练稳定性和性能上存在优缺点，但缺乏统一的理论框架和优化策略。归一化对模型收敛速度和最终输出质量至关重要，现有方法可能在不同任务或架构中表现不一致，导致设计选择困难。因此，开发一种能有效结合两者优势、同时减少计算负担的方法，对于提升Transformer模型的鲁棒性和效率具有重要意义。",
      "method": "研究方法从流形优化的视角出发，将Feed-Forward Network（FFN）和注意力层的输出重新解释为优化过程中的更新方向。基于此，提出了GeoNorm方法，它用流形上的测地更新替换了传统的归一化层，通过测地路径实现更稳定和有效的参数调整。关键创新点还包括引入了层级更新衰减机制，类似于学习率调度，针对FFN和注意力组件进行自适应调整，以优化训练过程。这一方法利用了微分几何原理，将归一化问题转化为优化问题，从而在Transformer架构中提供了一种统一的处理方式。",
      "result": "主要实验结果表明，GeoNorm在Transformer模型中一致优于现有的归一化方法，如Pre-Norm和Post-Norm。通过全面实验验证，GeoNorm在多个基准测试中展现出性能提升，但摘要未明确说明具体指标如准确率或效率的量化数据。与基线方法相比，GeoNorm在保持或提升模型性能的同时，实现了无缝集成到标准Transformer架构中，额外计算成本几乎可以忽略不计，显示了其高效性和实用性。这表明GeoNorm不仅改善了归一化效果，还保持了计算效率的平衡。",
      "conclusion": "论文的主要贡献是提出了GeoNorm，一种基于测地优化的归一化方法，成功统一了Transformer中的Pre-Norm和Post-Norm。学术价值在于从流形优化角度重新思考归一化问题，为神经网络架构设计提供了新的理论视角。实际应用价值高，因为GeoNorm易于集成到现有模型，能提升性能而不显著增加计算负担，适用于广泛的任务。摘要未明确说明具体局限性，但未来工作可能包括进一步的理论分析、扩展到其他深度学习架构或在大规模数据集上进行更全面的验证。",
      "tags": [
        "Transformer",
        "Normalization",
        "Manifold Optimization",
        "Geodesic Updates",
        "Layer-wise Decay"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:47.044298Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22094",
    "title": "RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation",
    "authors": [
      "Hanzhuo Huang",
      "Qingyang Bao",
      "Zekai Gu",
      "Zhongshuo Du",
      "Cheng Lin",
      "Yuan Liu",
      "Sibei Yang"
    ],
    "abstract": "In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22094.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22094",
    "published": "2026-01-29T18:30:10Z",
    "updated": "2026-01-29T18:30:10Z",
    "comment": "ICLR 2026. Project page: https://judgementh.github.io/RefAny3D Codes: https://github.com/JudgementH/RefAny3D",
    "light_analysis": {
      "overview": "本研究提出了一种基于3D资产参考的扩散模型，通过双分支感知技术生成与3D参考一致的图像，扩展了扩散模型的应用范围。",
      "motivation": "现有基于参考的图像生成方法依赖于大规模预训练扩散模型，能基于单参考图像生成多样图像，但这些方法仅限于单图像参考，无法利用3D资产，限制了在3D内容创建中的应用。因此，本研究旨在填补这一空白，探索如何将3D资产整合到图像扩散模型中，以提高生成系统的实用性和多样性，解决现有方法在参考类型上的局限性。",
      "method": "本研究提出一个跨域扩散模型，采用双分支感知模块，通过处理多视角RGB图像和点云图，联合建模3D资产的颜色和规范空间坐标，实现精确一致性。模型架构包括空间对齐的双分支生成和域解耦机制，确保同时生成空间对齐但内容解耦的RGB图像和点云图，从而链接2D图像属性与3D资产属性，核心创新在于整合多模态输入。",
      "result": "实验表明，该方法能有效利用3D资产作为参考，生成与给定资产一致的图像。摘要未明确说明具体性能指标，但研究展示了新可能性，将扩散模型与3D内容创建相结合，与现有单图像参考方法相比，本方法扩展了参考范围并提高了生成的一致性，为实际应用提供了基础。",
      "conclusion": "本研究的主要贡献是提出了一个3D资产参考的扩散模型，通过双分支感知技术，成功整合3D资产到图像生成中，实现2D-3D一致性。其学术价值在于扩展扩散模型的应用范围，为跨域生成提供新方法；实际应用可促进3D内容创建、游戏开发等领域。未来工作可能包括优化模型效率或扩展至更复杂的3D数据类型。",
      "tags": [
        "Diffusion Models",
        "3D Asset Referencing",
        "Dual-Branch Perception",
        "Point Cloud Mapping",
        "Image Generation"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:00.348378Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22083",
    "title": "Latent Adversarial Regularization for Offline Preference Optimization",
    "authors": [
      "Enyi Jiang",
      "Yibo Jacky Zhang",
      "Yinglun Xu",
      "Andreas Haupt",
      "Nancy Amato",
      "Sanmi Koyejo"
    ],
    "abstract": "Learning from human feedback typically relies on preference optimization that constrains policy updates through token-level regularization. However, preference optimization for language models is particularly challenging because token-space similarity does not imply semantic or behavioral similarity. To address this challenge, we leverage latent-space regularization for language model preference optimization. We introduce GANPO, which achieves latent-space regularization by penalizing divergence between the internal representations of a policy model and a reference model. Given that latent representations are not associated with explicit probability densities, we adopt an adversarial approach inspired by GANs to minimize latent-space divergence. We integrate GANPO as a regularizer into existing offline preference optimization objectives. Experiments across multiple model architectures and tasks show consistent improvements from latent-space regularization. Further, by comparing GANPO-induced inferential biases with those from token-level regularization, we find that GANPO provides more robust structural feedback under distributional shift and noise while maintaining comparable downstream performance with minor computational overhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22083.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22083",
    "published": "2026-01-29T18:21:57Z",
    "updated": "2026-01-29T18:21:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出GANPO，一种基于潜在空间对抗正则化的方法，用于提升语言模型离线偏好优化的效果。",
      "motivation": "研究动机源于从人类反馈中学习语言模型的挑战。现有偏好优化方法通常采用词符级正则化来约束策略更新，但词符空间相似性不能保证语义或行为相似性，导致优化效果受限，这在处理人类偏好时尤为重要，因为反馈往往基于语义理解而非表面词符匹配。因此，需要一种新方法来克服词符级正则化的不足，以更有效地利用偏好数据，提升模型的泛化能力和鲁棒性。",
      "method": "方法上，论文引入GANPO（Generative Adversarial Network-based Preference Optimization），通过潜在空间正则化改进偏好优化。核心创新在于采用对抗网络最小化策略模型和参考模型内部表示之间的分歧，避免依赖词符级相似性。由于潜在表示没有显式概率密度，受GANs启发，使用对抗方法估计和优化分歧，类似于判别器学习。GANPO作为正则化器集成到现有离线偏好优化目标中，如强化学习从人类反馈框架，从而在保持计算效率的同时实现语义级约束。",
      "result": "实验结果表明，在多个模型架构和任务中，潜在空间正则化带来了一致的性能提升。GANPO在分布偏移和噪声环境下提供比词符级正则化更鲁棒的结构反馈，同时下游任务性能与基线方法相当，摘要未明确说明具体数值，但强调了该方法在保持高效计算开销下的有效性。这验证了GANPO在增强模型适应性和稳定性方面的优势，尤其在动态或噪声数据场景中。",
      "conclusion": "该论文的主要贡献是提出了GANPO，通过潜在空间对抗正则化优化了离线偏好学习。学术上，它为语言模型偏好优化提供了新思路，解决了词符与语义不匹配的问题；应用上，增强了模型在复杂环境中的泛化能力和鲁棒性。未来工作可探索GANPO在大规模模型和多样化任务中的应用潜力，以及与其他正则化技术的结合，以进一步提升性能，摘要未明确说明局限性，但可推断需要更广泛的实证验证。",
      "tags": [
        "Offline Preference Optimization",
        "Latent Space Regularization",
        "Adversarial Training",
        "Language Model Fine-tuning",
        "Human Feedback Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:08.888488Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22076",
    "title": "Where Do the Joules Go? Diagnosing Inference Energy Consumption",
    "authors": [
      "Jae-Won Chung",
      "Ruofan Wu",
      "Jeff J. Ma",
      "Mosharaf Chowdhury"
    ],
    "abstract": "Energy is now a critical ML computing resource. While measuring energy consumption and observing trends is a valuable first step, accurately understanding and diagnosing why those differences occur is crucial for optimization. To that end, we begin by presenting a large-scale measurement study of inference time and energy across the generative AI landscape with 46 models, 7 tasks, and 1,858 different configurations on NVIDIA H100 and B200 GPUs. Our empirical findings span order-of-magnitude variations: LLM task type can lead to 25$\\times$ energy differences, video generation sometimes consumes more than 100$\\times$ the energy of images, and GPU utilization differences can result in 3--5$\\times$ energy differences. Based on our observations, we present a framework for reasoning about the underlying mechanisms that govern time and energy consumption. The essence is that time and energy are determined by latent metrics like memory and utilization, which are in turn affected by various factors across the algorithm, software, and hardware layers. Our framework also extends directly to throughput per watt, a critical metric for power-constrained datacenters.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22076.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22076",
    "published": "2026-01-29T18:16:45Z",
    "updated": "2026-01-29T18:16:45Z",
    "comment": "The ML.ENERGY Leaderboard v3.0 is open https://ml.energy/leaderboard",
    "light_analysis": {
      "overview": "论文提出一个基于大规模测量的诊断框架，用于分析生成式AI推理中的能量消耗机制及其优化潜力。",
      "motivation": "随着AI模型复杂化，推理阶段的能量消耗成为关键计算资源，但目前研究多集中于测量层面，缺乏对差异原因的深入诊断，这限制了优化效率。能量消耗差异的根源不明，阻碍了在算法、软件和硬件层面的针对性改进。因此，本文旨在通过系统性分析，解决现有方法仅观测趋势而无法准确诊断能量消耗根本原因的问题，为高效能量管理提供理论基础。",
      "method": "本研究采用大规模实证测量方法，覆盖生成式AI领域的46个模型、7种任务类型和1,858种不同配置，在NVIDIA H100和B200 GPU上进行测试。基于观察到的能量和时间差异，提出了一个推理框架，将时间和能量消耗归结为内存使用、GPU利用率等潜在指标，并探讨算法、软件和硬件层面对这些指标的综合影响。关键创新在于从数据中提取规律，构建系统性的诊断工具，并扩展到计算吞吐量每瓦的效率分析。",
      "result": "实验结果显示，不同因素导致推理能量消耗的数量级差异：大型语言模型（LLM）任务类型可造成高达25倍的能量变化，视频生成相较于图像生成有时消耗超过100倍的能量，而GPU利用率的差异也能带来3到5倍的能量差别。这些发现提供了实证证据，突显了优化能量效率的显著空间，表明通过调整任务配置和硬件使用，可以大幅降低能耗，为后续优化策略奠定数据基础。",
      "conclusion": "本文主要贡献是提出一个系统性框架，用于诊断AI推理中的能量消耗机制，将能量效率问题从测量提升到机制理解层面。学术上，提供了理论框架和实证数据，有助于指导优化研究；实践中，框架直接适用于功率受限数据中心的每瓦吞吐量优化，提升能源效率。未来工作可扩展到更多硬件和模型类型，或开发自动化诊断工具，以应对日益增长的AI能耗挑战。",
      "tags": [
        "Inference Energy Consumption",
        "GPU Utilization",
        "Generative AI",
        "Large Language Models",
        "Throughput per Watt"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:21.434439Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22069",
    "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
    "authors": [
      "Yibo Wang",
      "Yongcheng Jing",
      "Shunyu Liu",
      "Hao Guan",
      "Rong-cheng Tu",
      "Chengyu Wang",
      "Jun Huang",
      "Dacheng Tao"
    ],
    "abstract": "Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as \"optical memory.\" We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22069.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22069",
    "published": "2026-01-29T18:07:39Z",
    "updated": "2026-01-29T18:07:39Z",
    "comment": "Code: https://github.com/w-yibo/VTC-R1",
    "light_analysis": {
      "overview": "VTC-R1提出一种通过视觉-文本压缩提升长上下文推理效率的新范式。",
      "motivation": "长上下文推理增强了大型语言模型处理复杂任务的能力，但高计算复杂度导致显著效率瓶颈。现有方法依赖额外复杂训练或外部模型压缩，可扩展性有限且可能丢失关键细粒度信息，影响推理质量。因此，开发高效、可扩展且能保留信息的推理方法至关重要。",
      "method": "VTC-R1核心方法是将视觉-文本压缩融入推理过程，通过将冗长推理段渲染成紧凑图像，作为'光学记忆'迭代输入视觉语言模型。关键创新在于利用图像高效表示减少计算负担，保留必要信息。基于OpenR1-Math-220K数据集训练，实现3.4倍token压缩，并对VLMs-Glyph和Qwen3-VL微调以适应新流程。",
      "result": "实验结果显示，VTC-R1在MATH500、AIME25、AMC23和GPQA-D等基准测试中一致优于标准长上下文推理方法。具体实现3.4倍token压缩，减少输入规模；端到端推理延迟提升2.7倍，显著提高效率，验证了性能与速度的双重优势。",
      "conclusion": "本论文主要贡献是提出VTC-R1，一种创新的视觉-文本压缩推理范式，为解决长上下文推理效率问题提供新方案。学术上推动多模态推理技术发展，实际应用为推理密集型任务提供可扩展潜力。未来工作可能包括优化压缩算法和扩展应用领域，尽管摘要未明确说明具体局限性。",
      "tags": [
        "Vision-Text Compression",
        "Long-Context Reasoning",
        "Visual Language Models",
        "Token Compression",
        "Efficient Inference"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:40.952467Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22068",
    "title": "Making Foundation Models Probabilistic via Singular Value Ensembles",
    "authors": [
      "Mehmet Ozgur Turkoglu",
      "Dominik J. Mühlematter",
      "Alexander Becker",
      "Konrad Schindler",
      "Helge Aasen"
    ],
    "abstract": "Foundation models have become a dominant paradigm in machine learning, achieving remarkable performance across diverse tasks through large-scale pretraining. However, these models often yield overconfident, uncalibrated predictions. The standard approach to quantifying epistemic uncertainty, training an ensemble of independent models, incurs prohibitive computational costs that scale linearly with ensemble size, making it impractical for large foundation models. We propose Singular Value Ensemble (SVE), a parameter-efficient implicit ensemble method that builds on a simple, but powerful core assumption: namely, that the singular vectors of the weight matrices constitute meaningful subspaces of the model's knowledge. Pretrained foundation models encode rich, transferable information in their weight matrices. If the singular vectors are indeed meaningful (orthogonal) \"knowledge directions\". To obtain a model ensemble, we modulate only how strongly each direction contributes to the output. Rather than learning entirely new parameters, we freeze the singular vectors and only train per-member singular values that rescale the contribution of each direction in that shared knowledge basis. Ensemble diversity emerges naturally as stochastic initialization and random sampling of mini-batches during joint training cause different members to converge to different combinations of the same underlying knowledge. SVE achieves uncertainty quantification comparable to explicit deep ensembles while increasing the parameter count of the base model by less than 1%, making principled uncertainty estimation accessible in resource-constrained settings. We validate SVE on NLP and vision tasks with various different backbones and show that it improves calibration while maintaining predictive accuracy.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22068.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22068",
    "published": "2026-01-29T18:07:18Z",
    "updated": "2026-01-29T18:07:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出奇异值集成（SVE）方法，通过调节权重矩阵的奇异值，实现参数高效的基础模型不确定性量化。",
      "motivation": "基础模型通过大规模预训练在多种任务中表现卓越，但常产生过度自信和未校准的预测，导致不确定性估计不足。标准方法是训练多个独立模型集成以量化认知不确定性，但这计算成本随集成规模线性增长，对大型模型不切实际。因此，需要开发更高效的方法来克服资源限制，确保在真实应用中的可靠预测。",
      "method": "SVE是一种隐式集成方法，基于权重矩阵奇异向量构成知识有向子空间的假设。在预训练基础模型上，冻结奇异向量，仅训练每个集成成员的奇异值来调节知识方向对输出的贡献。通过随机初始化和训练过程中小批量的随机采样，自然产生集成多样性，而参数增加少于1%，避免学习全新参数，保持计算效率。",
      "result": "在NLP和视觉任务上验证SVE，使用不同骨干网络进行测试。结果显示，SVE的不确定性量化性能与显式深度集成相当，参数数量仅增加不到1%。同时，SVE显著提高了预测的校准度，在改进不确定性估计的同时，保持了模型的预测准确性，适用于资源受限环境。",
      "conclusion": "SVE为大型基础模型提供了参数高效的不确定性量化方案，解决了传统集成方法的高计算成本问题。该方法具有重要学术价值，推动了不确定性估计技术的发展，并在实际应用中使资源受限环境下的可靠预测成为可能。未来工作可进一步探索SVE在其他模型架构和任务中的扩展性和优化潜力。",
      "tags": [
        "Foundation Models",
        "Uncertainty Quantification",
        "Singular Value Decomposition",
        "Ensemble Methods",
        "Calibration"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:54.466643Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22061",
    "title": "BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation",
    "authors": [
      "Li Zhang",
      "Pengtao Xie"
    ],
    "abstract": "The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22061.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22061",
    "published": "2026-01-29T17:58:55Z",
    "updated": "2026-01-29T17:58:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "BLO-Inst提出了一个基于双层优化的框架，通过将检测器和SAM对齐，解决自动化实例分割中的目标不匹配和过拟合问题。",
      "motivation": "该研究旨在实现全自动化实例分割，以解决SAM依赖手动提示限制部署效率的问题。现有方法将对象检测器作为提示生成器，但存在目标不匹配，即检测器优化几何定位与SAM所需最优提示不相关，以及标准联合训练中容易过拟合，导致检测器无法学习通用策略。这些问题降低了自动化系统的鲁棒性，在生物医学等需要精确分割的领域中尤为重要，因此需要创新方法以有效集成检测和分割模块。",
      "method": "BLO-Inst采用双层优化策略来对齐检测器和SAM的目标，将问题表述为嵌套优化问题，在不相交的数据集上执行。下层使用数据集D1对SAM进行微调，基于当前检测提议最大化分割保真度；上层则使用独立数据集D2更新检测器（如YOLO），使其生成边界框以最小化微调后SAM的验证损失。关键创新在于将检测器转变为分割感知的提示生成器，优化边界框不仅关注定位精度，还考虑下游掩码质量，通过迭代优化促进两者协同工作。",
      "result": "实验结果表明，BLO-Inst在一般实例分割和生物医学领域任务中表现优异，显著优于标准基线方法。广泛测试验证了该框架能够有效解决目标不匹配和过拟合问题，提升自动化分割的鲁棒性和性能，具体表现为在多项任务中超越现有流水线，尽管摘要未明确给出具体数值指标，但突出显示了其在效率和效果上的改进。",
      "conclusion": "该论文的主要贡献是开发了BLO-Inst框架，通过双层优化成功对齐检测与分割目标，避免了过拟合并提高了自动化实例分割的准确性。其学术价值在于提出了一种新颖的优化方法来应对模型间目标不一致的挑战，实际应用价值在于促进全自动化系统在生物医学图像分析等领域的部署，具有广泛潜力。未来工作可能包括扩展该方法到其他模型或场景，并进一步优化计算效率以适应大规模应用。",
      "tags": [
        "Bi-Level Optimization",
        "YOLO",
        "SAM",
        "Instance Segmentation",
        "Automated Prompting"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:14.394697Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22060",
    "title": "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models",
    "authors": [
      "Wenxuan Huang",
      "Yu Zeng",
      "Qiuchen Wang",
      "Zhen Fang",
      "Shaosheng Cao",
      "Zheng Chu",
      "Qingyu Yin",
      "Shuang Chen",
      "Zhenfei Yin",
      "Lin Chen",
      "Zehui Chen",
      "Yao Hu",
      "Philip Torr",
      "Feng Zhao",
      "Wanli Ouyang"
    ],
    "abstract": "Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22060.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22060",
    "published": "2026-01-29T17:58:40Z",
    "updated": "2026-01-29T17:58:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了Vision-DeepResearch，一种新的多模态深度研究范式，通过多轮多尺度搜索增强多模态大语言模型的深度研究能力。",
      "motivation": "多模态大语言模型在视觉任务中表现出色，但受限于内部知识，现有方法通过‘推理-然后-工具调用’来增强，然而这些方法假设单次图像或文本查询足以检索关键证据，这在现实场景中不切实际，因为视觉噪声严重。此外，它们的推理深度和搜索广度有限，难以处理需要聚合多种视觉和文本来源证据的复杂问题。因此，本研究旨在解决这些不足之处，提升模型在噪声环境下的处理能力。",
      "method": "Vision-DeepResearch提出了一种多模态深度研究范式，执行多轮、多实体和多尺度的视觉与文本搜索，以在高度噪声下稳健地利用搜索引擎。通过冷启动监督和强化学习训练，将深度研究能力内化到多模态大语言模型中，支持数十个推理步骤和数百次引擎交互，构建端到端的模型。关键创新包括多尺度搜索策略和深层推理机制，增强了模型对复杂查询的处理能力。",
      "result": "实验结果显示，Vision-DeepResearch大幅优于现有的多模态深度研究模型，以及基于强闭源基础模型如GPT-5、Gemini-2.5-pro和Claude-4-Sonnet的工作流程。具体性能指标如准确率或效率提升摘要未明确说明，但强调了显著优于基线方法的优势。",
      "conclusion": "本研究的主要贡献是开发了Vision-DeepResearch范式，将深度研究能力集成到多模态大语言模型中，提高了在噪声环境下处理复杂视觉-文本问题的能力。这项研究具有推动多模态AI发展的学术价值，并在实际搜索引擎应用中具有潜力。局限性或未来工作方向摘要未明确说明。",
      "tags": [
        "Multimodal Large Language Models",
        "Deep Research",
        "Reinforcement Learning",
        "Visual Search",
        "Multi-turn Interaction"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:25.014250Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22057",
    "title": "Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models",
    "authors": [
      "Archer Wang",
      "Emile Anand",
      "Yilun Du",
      "Marin Soljačić"
    ],
    "abstract": "Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22057.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22057",
    "published": "2026-01-29T17:57:06Z",
    "updated": "2026-01-29T17:57:06Z",
    "comment": "28 pages, 16 figures, 4 tables",
    "light_analysis": {
      "overview": "论文提出了一种基于判别器驱动的扩散模型，通过对抗训练改进无监督分解和重组复杂数据，提升了因子发现和组合生成的质质量。",
      "motivation": "本研究旨在解决无监督分解复杂数据为因子化表示并重组成新样本的问题。在图像和机器人视频中，因子如背景、光照和运动组件是重要的可重用元素，但现有方法在无监督学习因子化潜在空间时，因子发现和组合生成的质质量有限。通过改进这些方面，可以增强数据可解释性和合成样本的多样性，推动计算机视觉和机器人学的发展。",
      "method": "论文方法基于扩散模型，引入对抗训练信号，通过一个判别器来区分单一源样本和跨源因子重组生成的样本。关键创新点在于优化生成器以欺骗判别器，从而鼓励重组中的物理和语义一致性。该方法在无监督条件下学习因子化潜在空间，适用于图像（如捕捉背景和属性）和机器人视频（如提取动作组件），无需因子级监督。",
      "result": "在CelebA-HQ、Virtual KITTI、CLEVR和Falcor3D数据集上，该方法优于先前基线实现，实现了更低的FID分数和更好的解纠缠性能，通过MIG和MCC指标衡量。此外，在机器人视频轨迹应用中，通过重组学习的动作组件生成多样序列，显著增加了LIBERO基准测试中的状态空间覆盖率，提升了探索效率。",
      "conclusion": "论文的主要贡献是提出一种判别器驱动的扩散模型，通过对抗训练改进无监督分解和重组，学术价值在于融合扩散模型与对抗信号以增强因子发现和生成一致性，实际应用价值体现在图像合成和机器人运动规划中。未来工作可扩展至更多数据类型，摘要未明确说明具体局限性。",
      "tags": [
        "Diffusion Models",
        "Adversarial Training",
        "Disentanglement",
        "Unsupervised Learning",
        "Factorized Representations"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:44.862368Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22055",
    "title": "$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA",
    "authors": [
      "Yaxin Du",
      "Junru Song",
      "Yifan Zhou",
      "Cheng Wang",
      "Jiahao Gu",
      "Zimeng Chen",
      "Menglan Chen",
      "Wen Yao",
      "Yang Yang",
      "Ying Wen",
      "Siheng Chen"
    ],
    "abstract": "Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\\%).",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22055.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22055",
    "published": "2026-01-29T17:52:54Z",
    "updated": "2026-01-29T17:52:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了G^2-Reader，一个双图系统，通过内容图和规划图解决多模态文档问答中的结构保持和导航问题。",
      "motivation": "多模态文档问答在长文档中面临挑战，因为扁平分块破坏了文档的原始结构和跨模态语义对齐，导致检索到的片段难以独立理解。此外，传统的迭代检索方法缺乏全局视角，容易陷入局部证据循环或漂移到无关内容，这是由于每一步只依赖当前片段，没有持久的搜索状态。这些问题使得现有检索增强生成方法在多模态环境下表现不稳定，影响了问答的准确性和效率。",
      "method": "论文提出了G^2-Reader方法，该系统由两个图组成：内容图用于维护文档的原生结构和跨模态语义对齐，确保检索片段具有连贯性；规划图则是一个代理式的有向无环图，将复杂问题分解为子问题，跟踪推理过程并指导逐步证据收集。核心创新在于通过双图的协同进化，解决了扁平分块导致的语义碎片和迭代检索中的导航漂移问题。方法在VisDoMBench数据集上实现，并集成Qwen3-VL-32B-Instruct模型进行问答。",
      "result": "在VisDoMBench数据集的五个多模态领域上，G^2-Reader使用Qwen3-VL-32B-Instruct模型取得了66.21%的平均准确率。这一结果显著超过了强基线方法，例如，独立的GPT-5模型仅达到53.08%的准确率。这表明G^2-Reader通过双图系统有效提升了多模态文档问答的性能，解决了现有方法中的检索和结构问题。",
      "conclusion": "论文的主要贡献是提出了G^2-Reader，一个通过内容图和规划图的双图系统，有效解决了多模态文档问答中的结构破坏和检索导航问题。这一研究在学术上为多模态检索增强生成提供了新的框架，实际应用中能提升长文档处理的准确性和效率。潜在的局限性可能包括计算复杂度或对其他领域的泛化能力，未来工作可进一步优化图结构和扩展更多模态。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Multimodal Document QA",
        "Graph-based Models",
        "Content Graph",
        "Planning Graph"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:56.086328Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22054",
    "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
    "authors": [
      "Baorui Ma",
      "Jiahui Yang",
      "Donglin Di",
      "Xuancheng Zhang",
      "Jianxun Cui",
      "Hao Li",
      "Yan Xie",
      "Wei Chen"
    ],
    "abstract": "Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22054.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22054",
    "published": "2026-01-29T17:52:41Z",
    "updated": "2026-01-29T17:52:41Z",
    "comment": "Project Page: https://metric-anything.github.io/metric-anything-io/",
    "light_analysis": {
      "overview": "Metric Anything框架通过稀疏度量提示处理噪声异质数据，实现了度量深度估计的规模化预训练。",
      "motivation": "研究动机源于度量深度估计在真实世界感知中的重要性，但现有方法面临挑战：异质传感器噪声、相机依赖偏差和跨源3D数据的度量模糊性，使得扩展视觉基础模型到该领域困难。当前方法常需手动设计提示或特定架构，限制了在大规模噪声数据上的泛化能力。因此，开发一个无需手动干预、能处理多样噪声源的预训练框架至关重要，以提升度量的准确性和可扩展性。",
      "method": "研究方法提出了Metric Anything预训练框架，核心创新是稀疏度量提示，通过随机掩码深度图创建，作为通用接口解耦空间推理与传感器和相机偏差。该方法无需手动设计提示、相机特定建模或任务特定架构，使用约2000万图像-深度对，覆盖10000个相机模型的3D数据（包括重建、捕获和渲染），基于视觉Transformer（ViT）进行大规模预训练，以从噪声异质源学习稳健的度量深度表示。",
      "result": "主要实验结果首次展示了度量深度估计的缩放趋势，表明模型性能随数据规模提升。预训练模型在提示驱动任务如深度完成、超分辨率和雷达-相机融合中表现优秀。蒸馏后的无提示学生模型在单目深度估计、相机内部参数恢复、单/多视角度量3D重建和VLA规划中达到最先进水平，优于基线方法。此外，使用预训练ViT作为视觉编码器显著增强了多模态大型语言模型的空间智能能力。",
      "conclusion": "论文的主要贡献是证明了度量深度估计可以受益于与现代基础模型相同的缩放定律，为可扩展和高效的现实世界度量感知开辟了新路径。学术上推动了深度估计的规模化研究，实际应用中支持多种下游任务，开源框架促进社区研究和未来发展。摘要未明确说明局限性，但强调了框架的通用性和潜在扩展价值。",
      "tags": [
        "Metric Depth Estimation",
        "Sparse Metric Prompt",
        "Pretraining Framework",
        "Vision Transformer (ViT)",
        "Multimodal Large Language Models (MLLM)"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:13.456488Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22050",
    "title": "MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs",
    "authors": [
      "Ghazal Kalhor",
      "Behnam Bahrak"
    ],
    "abstract": "In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22050.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22050",
    "published": "2026-01-29T17:49:44Z",
    "updated": "2026-01-29T17:49:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出MasalBench基准，评估多语言大语言模型在波斯谚语中的上下文和跨文化理解，揭示其在文化知识和类比推理上的局限性。",
      "motivation": "随着多语言大语言模型在日常生活中的普及，掌握对话语言规则对有效沟通至关重要。现有研究主要评估高资源语言中比喻语言的理解，但低资源语言如波斯的类似评估尚不足。波斯谚语是该语言对话的关键组成部分，理解其跨文化含义对模型性能有重要影响。因此，本研究旨在填补这一空白，评估LLMs在波斯谚语中的跨文化理解能力，强调当前模型在低资源语言文化知识方面的局限性。",
      "method": "本研究引入了MasalBench，一个全面的基准测试集，专注于评估大语言模型对波斯谚语的上下文和跨文化理解。该基准包含两个主要任务：识别波斯谚语在给定上下文中的含义，以及将其与等效的英语谚语进行匹配。研究评估了八个当前最先进的LLMs，以测试其性能。创新点在于首次针对低资源语言的跨文化理解建立评估框架，并提供了可扩展的基准数据集，促进模型在多样化语言环境中的优化。",
      "result": "实验结果显示，模型在识别波斯谚语的任务上表现良好，准确率超过0.90。然而，当任务转换为识别等效的英语谚语时，性能显著下降，最佳模型的准确率仅为0.79。这表明尽管模型在单语言上下文中表现优异，但在跨文化类比推理方面存在明显不足。与自身在波斯谚语任务上的表现对比，跨文化任务下降了约11个百分点，突显了当前模型在文化知识整合上的局限性。",
      "conclusion": "本研究的核心贡献是提出了MasalBench基准，系统地评估了大语言模型在波斯谚语中的跨文化理解。研究发现模型在文化知识方面存在不足，并提供了一个框架，可用于评估其他低资源语言的类似能力。这为改进模型在多样化语言环境中的表现提供了指导，具有重要的学术和实际应用价值。未来工作可以扩展到更多语言和文化背景，进一步探索模型的跨文化理解能力。",
      "tags": [
        "Large Language Models",
        "Cross-Cultural Understanding",
        "Persian Proverbs",
        "Benchmark Evaluation",
        "Low-Resource Languages"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:36.877972Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22047",
    "title": "On the Paradoxical Interference between Instruction-Following and Task Solving",
    "authors": [
      "Yunjia Qi",
      "Hao Peng",
      "Xintong Shi",
      "Amy Xin",
      "Xiaozhi Wang",
      "Bin Xu",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22047.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22047",
    "published": "2026-01-29T17:48:56Z",
    "updated": "2026-01-29T17:48:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文揭示了大型语言模型中指令跟随与任务解决之间的悖论性干扰现象，并提出SUSTAINSCORE指标来量化这种干扰。",
      "motivation": "研究动机在于，指令跟随旨在通过指定显式约束使LLMs对齐人类意图，但实践中发现添加约束可能意外干扰任务解决能力。这个问题至关重要，因为它影响模型的可靠性和对齐效果，而现有对齐策略可能未充分考虑此类干扰，导致模型在处理复杂任务时性能下降，特别是在要求严格遵循指令的场景中。",
      "method": "论文提出SUSTAINSCORE指标，通过向指令中插入自证约束来量化干扰。自证约束是从原始成功模型输出中提取的、自然满足的约束，实验在数学、多跳问答和代码生成任务上进行，使用如Claude-Sonnet-4.5等当前先进LLMs。关键创新包括设计新指标并分析干扰机制，例如通过注意力分配来探究失败案例中模型对约束的过度关注。",
      "result": "实验结果显示，添加自证约束导致任务性能显著下降，验证了干扰在不同约束类型和尺度上的普遍性。具体观察包括识别常见失败模式，以及失败案例中模型对约束的注意力分配明显高于成功案例。SUSTAINSCORE还被用于初步调查不同后训练范式对干扰的影响，为当前对齐策略提供了实证数据支撑。",
      "conclusion": "论文主要贡献是发现和量化指令跟随的干扰现象，揭示了LLMs的行为模式，对模型对齐的学术研究和实际应用具有重要价值。研究为改进对齐策略提供了经验观察，潜在局限性包括摘要未明确说明具体缓解方法，未来工作可探索减轻干扰的技术或优化训练范式。",
      "tags": [
        "Large Language Models",
        "Instruction Following",
        "Task Solving",
        "Attention Mechanism",
        "Model Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:27.853253Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22046",
    "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
    "authors": [
      "Changjian Jiang",
      "Kerui Ren",
      "Xudong Li",
      "Kaiwen Song",
      "Linning Xu",
      "Tao Lu",
      "Junting Dong",
      "Yu Zhang",
      "Bo Dai",
      "Mulin Yu"
    ],
    "abstract": "Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \\modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22046.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22046",
    "published": "2026-01-29T17:47:26Z",
    "updated": "2026-01-29T17:47:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了PLANING框架，通过松散耦合三角形和高斯表示实现几何与外观解耦建模，有效提升流式3D重建的质量和效率。",
      "motivation": "本研究旨在解决从单目图像序列进行流式3D重建的挑战，现有方法通常偏向高质量渲染或准确几何，但难以同时兼顾，导致在实时应用中重建效果受限。这一问题在需要快速在线构建高质量3D场景的实际领域如自动驾驶、虚拟现实中尤为重要，现有方法的不足在于难以平衡渲染与几何的优化。",
      "method": "PLANING框架采用混合表示，松散耦合显式几何基元与神经高斯，允许几何和外观独立建模。关键创新在于在线初始化和优化策略，分离几何和外观的更新过程，减少结构冗余，实现稳定流式重建。使用ScanNetV2数据集验证，结合三角形网格和高斯表示，支持高效数据处理和模型更新。",
      "result": "实验显示，PLANING在密集网格Chamfer-L2指标上比PGSR提升18.52%，PSNR超过ARTDECO 1.31 dB。ScanNetV2场景重建时间少于100秒，比2D高斯溅射快5倍以上，同时匹配离线优化的质量，证明其在准确性和效率上优于基线方法。",
      "conclusion": "论文贡献在于提出PLANING框架，实现高效流式3D重建并兼顾几何与外观质量。学术上，通过解耦建模提供了新方法；实际上，其结构清晰和计算高效特性适用于大规模场景建模和具身AI环境。摘要未明确说明局限性，但暗示未来可扩展至更多下游应用。",
      "tags": [
        "Streaming 3D Reconstruction",
        "Hybrid Representation",
        "Loosely Coupled Modeling",
        "Online Optimization",
        "Neural Gaussians"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:01.886143Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22045",
    "title": "Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion",
    "authors": [
      "Da Li",
      "Chen Yao",
      "Tong Mao",
      "Jiacheng Bao",
      "Houjun Sun"
    ],
    "abstract": "Neural surface reconstruction (NSR) has recently shown strong potential for urban 3D reconstruction from multi-view aerial imagery. However, existing NSR methods often suffer from geometric ambiguity and instability, particularly under sparse-view conditions. This issue is critical in large-scale urban remote sensing, where aerial image acquisition is limited by flight paths, terrain, and cost. To address this challenge, we present the first urban NSR framework that fuses 3D synthetic aperture radar (SAR) point clouds with aerial imagery for high-fidelity reconstruction under constrained, sparse-view settings. 3D SAR can efficiently capture large-scale geometry even from a single side-looking flight path, providing robust priors that complement photometric cues from images. Our framework integrates radar-derived spatial constraints into an SDF-based NSR backbone, guiding structure-aware ray selection and adaptive sampling for stable and efficient optimization. We also construct the first benchmark dataset with co-registered 3D SAR point clouds and aerial imagery, facilitating systematic evaluation of cross-modal 3D reconstruction. Extensive experiments show that incorporating 3D SAR markedly enhances reconstruction accuracy, completeness, and robustness compared with single-modality baselines under highly sparse and oblique-view conditions, highlighting a viable route toward scalable high-fidelity urban reconstruction with advanced airborne and spaceborne optical-SAR sensing.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22045.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22045",
    "published": "2026-01-29T17:47:07Z",
    "updated": "2026-01-29T17:47:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出首个融合3D合成孔径雷达点云与航空影像的城市神经表面重建框架，以提升稀疏视图条件下的几何准确性和稳定性。",
      "motivation": "本研究旨在解决城市3D重建中，基于神经表面重建（NSR）的方法在稀疏视图条件下出现的几何模糊和不稳定性问题。这一挑战在大规模城市遥感中尤为关键，因为航空影像获取受到飞行路径、地形和成本等因素的限制，导致数据稀疏，从而影响重建质量和可靠性。现有NSR方法在这种约束条件下性能不足，亟需创新方法来提高重建的鲁棒性和精确度，以应对实际应用中的需求。",
      "method": "论文提出一种新颖的城市NSR框架，首次融合3D合成孔径雷达（SAR）点云与航空影像。该方法将雷达衍生的空间约束集成到基于符号距离函数（SDF）的NSR主干中，通过结构感知的光线选择和自适应采样策略，优化重建过程。3D SAR能从单侧飞行路径高效捕获大规模几何信息，提供鲁棒的先验知识，补充图像的光度线索，从而在稀疏视图条件下实现稳定和高效的优化。该框架还构建了首个共同配准的3D SAR点云与航空影像基准数据集，支持跨模态评估。",
      "result": "大量实验结果表明，融合3D SAR显著提高了重建的精度、完整性和鲁棒性。在高度稀疏和倾斜视图条件下，与单模态基线方法相比，该框架展现出更好的性能。尽管摘要未明确说明具体数值，但实验验证了其在基准数据集上的优越性，强调了跨模态融合在挑战性城市场景中的有效性，为解决几何模糊问题提供了可行方案。",
      "conclusion": "本研究的核心贡献在于提出了首个融合3D SAR与航空影像的城市NSR框架，并构建了相应的基准数据集，促进了跨模态3D重建的系统评估。这不仅解决了稀疏视图下的几何模糊问题，还为可扩展高保真城市重建提供了可行路径，具有重要的学术价值和实际应用前景。未来工作可能涉及进一步优化融合算法或扩展到其他传感器数据，以增强通用性和实用性。",
      "tags": [
        "Neural Surface Reconstruction",
        "3D Synthetic Aperture Radar",
        "Sparse-view Reconstruction",
        "Cross-modal Fusion",
        "SDF-based Reconstruction"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:19.480679Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22040",
    "title": "A Separable Architecture for Continuous Token Representation in Language Models",
    "authors": [
      "Reza T. Batley",
      "Sourav Saha"
    ],
    "abstract": "Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \\times$ more parameters.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22040.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22040",
    "published": "2026-01-29T17:44:25Z",
    "updated": "2026-01-29T17:44:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Leviathan架构，通过连续嵌入生成器替代离散查找表，优化了小语言模型的参数分配。",
      "motivation": "Transformer扩展规律通常将参数视为可互换以预测性能，但在参数少于十亿的小型语言模型中，嵌入矩阵主导参数预算，导致资源分配次优且反直觉。现有方法中，离散查找表参数效率低下，限制了小模型在资源受限场景下的应用潜力。本研究旨在改进参数分配策略，通过连续表示提升模型效率，解决小模型参数浪费问题。",
      "method": "论文提出Leviathan架构，核心创新是使用连续嵌入生成器替代传统语言模型的离散查找表，实现更紧凑的参数表示。该方法在等参数设置下与标准LLaMA风格架构对比，但摘要未明确说明连续嵌入生成器的具体网络结构或训练细节，推断其可能基于神经网络动态生成嵌入向量。研究涉及在Pile数据集上进行评估，重点关注参数效率优化。",
      "result": "在Pile数据集上，Leviathan在等参数设置下始终优于标准LLaMA风格架构。通过经验幂律拟合分析，Leviathan表现出显著更优的有效参数容量，具体表现为性能相当于参数增加了1.47到2.11倍的密集模型。这证明了该架构能高效利用参数资源，为小语言模型提供了性能提升，对比基线方法展现出明显优势。",
      "conclusion": "Leviathan架构通过引入连续嵌入生成器，有效优化了参数分配，提升了小语言模型的性能。研究挑战了传统参数分配假设，学术价值在于改进Transformer架构的参数效率，实际应用潜力包括边缘计算等资源受限环境。未来工作可探索将该方法扩展到更大规模模型或更多数据集，以验证其通用性。",
      "tags": [
        "Continuous Token Representation",
        "Language Models",
        "Parameter Efficiency",
        "Transformer Architecture",
        "Empirical Scaling Laws"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:38.152358Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22039",
    "title": "Understanding Multimodal Complementarity for Single-Frame Action Anticipation",
    "authors": [
      "Manuel Benavent-Lledo",
      "Konstantinos Bacharidis",
      "Konstantinos Papoutsakis",
      "Antonis Argyros",
      "Jose Garcia-Rodriguez"
    ],
    "abstract": "Human action anticipation is commonly treated as a video understanding problem, implicitly assuming that dense temporal information is required to reason about future actions. In this work, we challenge this assumption by investigating what can be achieved when action anticipation is constrained to a single visual observation. We ask a fundamental question: how much information about the future is already encoded in a single frame, and how can it be effectively exploited? Building on our prior work on Action Anticipation at a Glimpse (AAG), we conduct a systematic investigation of single-frame action anticipation enriched with complementary sources of information. We analyze the contribution of RGB appearance, depth-based geometric cues, and semantic representations of past actions, and investigate how different multimodal fusion strategies, keyframe selection policies and past-action history sources influence anticipation performance. Guided by these findings, we consolidate the most effective design choices into AAG+, a refined single-frame anticipation framework. Despite operating on a single frame, AAG+ consistently improves upon the original AAG and achieves performance comparable to, or exceeding, that of state-of-the-art video-based methods on challenging anticipation benchmarks including IKEA-ASM, Meccano and Assembly101. Our results offer new insights into the limits and potential of single-frame action anticipation, and clarify when dense temporal modeling is necessary and when a carefully selected glimpse is sufficient.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22039.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22039",
    "published": "2026-01-29T17:44:23Z",
    "updated": "2026-01-29T17:44:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了AAG+框架，通过整合多模态互补信息在单帧上实现动作预测，挑战了依赖密集时间信息的传统假设，性能与基于视频方法相当。",
      "motivation": "本研究旨在解决动作预测中过度依赖密集时间信息的问题，传统方法通常假设需要视频序列，计算负担重且效率低。这个问题在实时视频分析和人机交互中尤为重要，现有基于视频的方法可能忽略了单帧中已有的未来信息。通过探索单帧预测，可以降低计算复杂度，提高应用可行性，同时深入理解视觉信息的本质和限制。",
      "method": "论文基于Action Anticipation at a Glimpse（AAG）框架，系统分析RGB外观、深度几何线索和过去动作语义表示的贡献。研究多模态融合策略、关键帧选择策略和过去动作历史源的影响，通过实验整合最有效的设计选择形成AAG+框架。使用数据集包括IKEA-ASM、Meccano和Assembly101进行验证，关键创新点在于综合评估不同信息源的互补性，优化单帧预测的技术路线。",
      "result": "AAG+在IKEA-ASM、Meccano和Assembly101等挑战性基准测试中持续改进原始AAG，性能达到或超过最先进的基于视频方法。实验表明，尽管仅使用单帧，但通过精心选择和多模态互补，可以补偿时间信息的缺乏，实现高效预测，具体性能指标在摘要中未明确说明，但对比显示与基线方法相当或更优。",
      "conclusion": "本研究的核心贡献是揭示单帧动作预测的潜力，阐明何时需要密集时间建模、何时单帧足以完成任务。学术价值在于挑战传统视频理解假设，推动高效预测方法的发展；实际应用价值包括低计算成本的视频分析系统。局限性在于可能未覆盖所有场景，未来工作可探索更多信息源或扩展到动态环境。",
      "tags": [
        "Single-Frame Action Anticipation",
        "Multimodal Fusion",
        "Depth-Based Cues",
        "Semantic Representations",
        "Keyframe Selection"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:53.039200Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22037",
    "title": "Optimizing Agentic Workflows using Meta-tools",
    "authors": [
      "Sami Abuzakuk",
      "Anne-Marie Kermarrec",
      "Rishi Sharma",
      "Rasmus Moorits Veski",
      "Martijn de Vos"
    ],
    "abstract": "Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant tool execution patterns to improve the efficiency and robustness of agentic workflows. AWO analyzes existing workflow traces to discover recurring sequences of tool calls and transforms them into meta-tools, which are deterministic, composite tools that bundle multiple agent actions into a single invocation. Meta-tools bypass unnecessary intermediate LLM reasoning steps and reduce operational cost while also shortening execution paths, leading to fewer failures. Experiments on two agentic AI benchmarks show that AWO reduces the number of LLM calls up to 11.9% while also increasing the task success rate by up to 4.2 percent points.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22037.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22037",
    "published": "2026-01-29T17:43:08Z",
    "updated": "2026-01-29T17:43:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出Agent Workflow Optimization (AWO)框架，通过meta-tools优化agentic workflows的效率和鲁棒性。",
      "motivation": "Agentic AI使LLM能够通过动态推理和工具调用来处理复杂任务，但现有工作流常需多次迭代推理和工具调用，导致高操作成本、端到端延迟以及因幻觉导致的失败。这些问题严重影响了agentic workflows的实用性和可扩展性，尤其在资源密集型或实时应用中。现有方法如基于LLM的动态规划效率低下、鲁棒性不足，因此优化工具执行模式以提升性能和可靠性成为重要的研究课题。摘要未明确说明其他具体方法，但强调了当前agentic workflows的缺陷。",
      "method": "论文提出的核心方法是Agent Workflow Optimization (AWO)框架，它分析agentic workflows的历史执行轨迹，自动识别重复出现的工具调用序列。这些冗余模式被转换为meta-tools，即确定性的复合工具，将多个代理动作捆绑为单次调用。关键创新在于meta-tools的设计，它们绕过不必要的中间LLM推理步骤，从而减少LLM调用次数、降低操作成本，并缩短执行路径以提高鲁棒性。方法依赖于工作流分析技术，优化冗余模式，而不改变底层LLM模型架构。",
      "result": "实验在两个agentic AI基准任务上进行，结果显示AWO框架显著提升了性能。与标准agentic workflows作为基线相比，AWO将LLM调用数量减少了最多11.9%，同时任务成功率提高了最多4.2百分点。这表明AWO不仅降低了资源消耗，如减少了推理步骤和工具调用次数，还增强了任务完成的可靠性。具体数据来自基准测试，突出了优化效果在效率和成功率方面的双重优势，但摘要未提供更详细对比或额外指标。",
      "conclusion": "本研究的主要贡献是开发了AWO框架，通过meta-tools优化agentic workflows，有效提高了效率和鲁棒性。学术价值在于为agentic AI的优化提供了新方法，特别是针对冗余工具调用问题；实际应用中，它能减少操作成本、降低失败率，促进agentic workflows在复杂任务中的实用化。局限性方面，摘要未明确说明，但未来工作可扩展至更多样化任务和场景，或进一步探索自动化优化策略。",
      "tags": [
        "Large Language Model",
        "Agentic Workflows",
        "Meta-tools",
        "Tool Invocation Optimization",
        "Workflow Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:51.346094Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22036",
    "title": "Cross-Fusion Distance: A Novel Metric for Measuring Fusion and Separability Between Data Groups in Representation Space",
    "authors": [
      "Xiaolong Zhang",
      "Jianwei Zhang",
      "Xubo Song"
    ],
    "abstract": "Quantifying degrees of fusion and separability between data groups in representation space is a fundamental problem in representation learning, particularly under domain shift. A meaningful metric should capture fusion-altering factors like geometric displacement between representation groups, whose variations change the extent of fusion, while remaining invariant to fusion-preserving factors such as global scaling and sampling-induced layout changes, whose variations do not. Existing distributional distance metrics conflate these factors, leading to measures that are not informative of the true extent of fusion between data groups. We introduce Cross-Fusion Distance (CFD), a principled measure that isolates fusion-altering geometry while remaining robust to fusion-preserving variations, with linear computational complexity. We characterize the invariance and sensitivity properties of CFD theoretically and validate them in controlled synthetic experiments. For practical utility on real-world datasets with domain shift, CFD aligns more closely with downstream generalization degradation than commonly used alternatives. Overall, CFD provides a theoretically grounded and interpretable distance measure for representation learning.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22036.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22036",
    "published": "2026-01-29T17:41:43Z",
    "updated": "2026-01-29T17:41:43Z",
    "comment": "19 pages",
    "light_analysis": {
      "overview": "该论文提出了Cross-Fusion Distance (CFD)，一种新型度量，用于在表示空间中量化数据组之间的融合程度，特别适用于领域转移场景。",
      "motivation": "在表示学习中，量化数据组之间的融合和可分性是基本问题，尤其是在领域转移下。现有分布距离度量（如Wasserstein距离）混淆了融合改变因子（如几何位移）和融合保持因子（如全局缩放和采样诱导的布局变化），导致度量不能准确反映真正的融合程度，这限制了表示学习的评估和优化。开发一种能区分这些因子的新度量，对于改善下游任务性能和模型泛化至关重要。",
      "method": "论文引入了Cross-Fusion Distance (CFD)，这是一个原则性距离度量，旨在隔离融合改变的几何因素（如表示组之间的位移），同时对融合保持变化（如全局缩放和采样诱导的布局变化）保持稳健。CFD具有线性计算复杂度，使其高效实用。论文还从理论上分析了CFD的不变性和敏感性属性，即对融合保持因子不变、对融合改变因子敏感，并通过受控合成实验验证了这些性质。",
      "result": "在受控合成实验中，CFD的理论性质得到验证，显示出对融合改变因子的敏感性和对融合保持因子的不变性。在实际世界数据集上，CFD与下游任务泛化退化的关联比常用替代度量（如传统分布距离）更紧密，这表明CFD能更准确地反映表示空间中的融合程度，从而更好地预测实际应用中的性能变化，但摘要未提供具体性能指标数据如准确率提升。",
      "conclusion": "CFD为表示学习提供了一个理论基础和可解释的距离度量，解决了现有度量在量化融合程度时的不足，具有重要学术价值。其实际应用包括评估表示质量、指导模型优化和监控领域转移下的泛化性能。未来工作可扩展CFD到更多场景，并探索其在其他机器学习任务中的应用潜力。",
      "tags": [
        "Representation Learning",
        "Distance Metric",
        "Domain Shift",
        "Geometric Invariance",
        "Linear Computational Complexity"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:23.657744Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22035",
    "title": "Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models",
    "authors": [
      "Longxuan Yu",
      "Yu Fu",
      "Shaorong Zhang",
      "Hui Liu",
      "Mukund Varma T",
      "Greg Ver Steeg",
      "Yue Dong"
    ],
    "abstract": "Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\\leq$14% relative drop), a property we term \"order robustness\". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22035.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22035",
    "published": "2026-01-29T17:40:58Z",
    "updated": "2026-01-29T17:40:58Z",
    "comment": "18 pages, 13 figures, 5 tables",
    "light_analysis": {
      "overview": "论文揭示了掩码扩散语言模型在输出顺序与推理顺序不一致时展现的鲁棒性，解决了自回归模型的顺序限制。",
      "motivation": "自回归（AR）语言模型强制固定的左到右生成顺序，当输出结构与自然推理顺序冲突时（如先输出答案后输出解释），这导致模型必须过早承诺答案，限制了推理能力。这个问题在实际应用中很重要，因为输出顺序常受呈现或模式约束，现有AR模型在此类情况下性能显著下降，表明顺序依赖性是其关键不足。",
      "method": "研究采用掩码扩散语言模型（MDLMs），通过并行迭代优化所有标记来解耦计算顺序与输出结构。引入新基准ReasonOrderQA，以控制难度和评估不同输出顺序下的性能。实验在GSM8K、Math500和ReasonOrderQA上进行，比较AR模型与MDLMs的关键创新在于分析鲁棒性机制，并验证MDLMs如何先稳定简单标记（如推理步骤）而非复杂答案。",
      "result": "在要求先答案后推理的提示下，AR模型准确率相对标准推理顺序下降高达67%，而MDLMs仅下降不超过14%，展现出“顺序鲁棒性”。通过ReasonOrderQA基准，证据表明MDLMs在扩散过程中先稳定简单标记（如推理步骤），再稳定复杂答案，从而实现鲁棒性。基线对比显示AR模型性能大幅下降，MDLMs保持稳定，具体数据如准确率相对降低幅度支持了鲁棒性结论。",
      "conclusion": "主要贡献是验证了MDLMs在输出顺序冲突时优于AR模型，具有顺序鲁棒性。学术价值在于推动非自回归语言模型的发展，实际应用价值在于处理结构化输出场景，如教育或自动化任务。局限性包括识别了鲁棒性减弱的失效条件，未来工作可探索鲁棒性边界或扩展到更广泛任务。",
      "tags": [
        "Masked Diffusion Language Models (MDLMs)",
        "Autoregressive Language Models (AR)",
        "Order Robustness",
        "Reasoning Order",
        "Benchmark Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:18.213613Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22033",
    "title": "Holographic generative flows with AdS/CFT",
    "authors": [
      "Ehsan Mirafzali",
      "Sanjit Shashi",
      "Sanya Murdeshwar",
      "Edgar Shaghoulian",
      "Daniele Venturi",
      "Razvan Marinescu"
    ],
    "abstract": "We present a framework for generative machine learning that leverages the holographic principle of quantum gravity, or to be more precise its manifestation as the anti-de Sitter/conformal field theory (AdS/CFT) correspondence, with techniques for deep learning and transport theory. Our proposal is to represent the flow of data from a base distribution to some learned distribution using the bulk-to-boundary mapping of scalar fields in AdS. In the language of machine learning, we are representing and augmenting the flow-matching algorithm with AdS physics. Using a checkerboard toy dataset and MNIST, we find that our model achieves faster and higher quality convergence than comparable physics-free flow-matching models. Our method provides a physically interpretable version of flow matching. More broadly, it establishes the utility of AdS physics and geometry in the development of novel paradigms in generative modeling.",
    "categories": [
      "cs.LG",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22033.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22033",
    "published": "2026-01-29T17:39:40Z",
    "updated": "2026-01-29T17:39:40Z",
    "comment": "v1: 13 pages, 6 figures",
    "light_analysis": {
      "overview": "本论文提出了一个利用反德西特/共形场论（AdS/CFT）对应关系来增强流匹配算法的生成式机器学习框架，以提高收敛速度和质量。",
      "motivation": "该研究旨在解决生成式模型中流匹配算法的收敛速度和质量问题。现有无物理基础的流匹配模型可能效率低下且缺乏可解释性，限制了其实际应用。通过结合量子引力的全息原理和 AdS/CFT 对应关系，本框架尝试为机器学习算法提供物理洞察，从而提高性能并增强算法的可解释性和理论深度。",
      "method": "研究方法基于 AdS/CFT 对应关系，利用标量场在反德西特（AdS）空间中的体到边界映射来表示数据从基础分布到学习分布的流。具体来说，将流匹配算法与 AdS 物理结合，通过这种映射增强算法的表示能力。在实验中，使用棋盘玩具数据集和 MNIST 数据集进行验证，但模型的具体架构细节摘要未明确说明。关键创新点在于引入物理原理来优化机器学习流程。",
      "result": "实验结果表明，在棋盘玩具数据集和 MNIST 上，该模型比类似的无物理流匹配模型实现了更快和更高质量的收敛。摘要未提供具体性能指标如准确率数字，但与基线方法对比显示收敛速度提升和输出质量改善，验证了 AdS 物理在机器学习中的潜在优势。",
      "conclusion": "论文的主要贡献是提出了一种物理可解释的流匹配算法版本，并确立了 AdS 物理和几何在开发生成建模新范式中的效用。这推动了跨学科研究，具有学术价值，可能改进生成模型的效率和可解释性。摘要未明确说明局限性或未来工作方向，但暗示了在更复杂数据集上进一步验证的潜力。",
      "tags": [
        "Generative Modeling",
        "Flow Matching",
        "AdS/CFT Correspondence",
        "Deep Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:39.860474Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22032",
    "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving",
    "authors": [
      "Linhan Wang",
      "Zichong Yang",
      "Chen Bai",
      "Guoxiang Zhang",
      "Xiaotong Liu",
      "Xiaoyin Zheng",
      "Xiao-Xiao Long",
      "Chang-Tien Lu",
      "Cheng Lu"
    ],
    "abstract": "End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22032.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22032",
    "published": "2026-01-29T17:39:20Z",
    "updated": "2026-01-29T17:39:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "Drive-JEPA框架整合视频联合嵌入预测架构与多模态轨迹蒸馏，显著提升了端到端自动驾驶的规划性能。",
      "motivation": "当前端到端自动驾驶系统日益依赖自监督视频预训练学习可转移的规划表示，但视频世界模型对场景理解的改进有限。驾驶场景中轨迹具有固有模糊性，每场景通常仅提供单一人类轨迹，导致难以学习多模态行为，限制了模型的鲁棒性和安全性。现有方法难以有效结合预训练表示与多模态规划，因此需要克服这些挑战以推动自动驾驶技术的发展。",
      "method": "研究提出Drive-JEPA框架，分为两个关键步骤：首先，将视频联合嵌入预测架构（V-JEPA）适应于端到端驾驶，通过在大规模驾驶视频上预训练Vision Transformer（ViT）编码器，生成与轨迹规划对齐的预测表示。其次，引入一个提议中心规划器，结合模拟器生成的多样化轨迹和人类轨迹进行蒸馏，并采用动量感知选择机制以促进稳定和安全的驾驶行为。整个方法整合了预测表示学习和多模态轨迹优化。",
      "result": "在NAVSIM数据集上评估，V-JEPA表示与基于Transformer的简单解码器结合，在感知自由设置中优于先前方法3 PDMS（预测决策度量评分）。完整Drive-JEPA框架在v1版本上达到93.3 PDMS，在v2版本上达到87.8 EPDMS（增强预测决策度量评分），创下了新的状态-of-the-art性能记录，表明方法在提升自动驾驶规划效果方面具有显著优势。",
      "conclusion": "Drive-JEPA框架通过整合视频预训练和多模态轨迹蒸馏，有效提升了端到端自动驾驶的规划表示学习，在标准基准上实现了最佳性能。该研究贡献了结合预测架构与蒸馏策略的创新方法，对提高自动驾驶系统的鲁棒性和安全性具有重要学术价值和实际应用前景。未来工作可能包括扩展到更复杂驾驶场景或整合更多传感器模态以进一步优化性能。",
      "tags": [
        "Video Joint-Embedding Predictive Architecture (V-JEPA)",
        "Multimodal Trajectory Distillation",
        "Vision Transformer (ViT)",
        "Transformer-based Decoder",
        "Momentum-aware Selection Mechanism"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:54.415320Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22031",
    "title": "Causal Autoregressive Diffusion Language Model",
    "authors": [
      "Junhao Ruan",
      "Bei Li",
      "Yongjing Yin",
      "Pengcheng Huang",
      "Xin Chen",
      "Jingang Wang",
      "Xunliang Cai",
      "Tong Xiao",
      "JingBo Zhu"
    ],
    "abstract": "In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22031.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22031",
    "published": "2026-01-29T17:38:29Z",
    "updated": "2026-01-29T17:38:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "CARD框架结合自回归模型训练效率与扩散模型推理优势，实现高效的并行解码。",
      "motivation": "现有语言模型在训练效率和推理延迟之间存在矛盾：自回归模型(ARMs)训练高效但推理慢，需序列生成；扩散模型推理快但训练成本高。该研究旨在统一两者优势，解决高效大型语言模型(LLMs)的部署瓶颈，以提升整体性能。摘要未明确说明更广泛应用场景，但基于现有信息，核心动机是优化模型在训练和推理中的效率权衡。",
      "method": "CARD框架在严格因果注意力掩码内重新制定扩散过程，实现密集每令牌监督。关键创新包括：引入软尾掩码方案以保留局部上下文，设计基于信噪比原则的上下文感知重新加权机制，提升训练稳定性。此外，模型支持动态并行解码，利用KV缓存自适应生成基于置信度的变长令牌序列，从而增强推理效率。技术细节涉及因果注意力结构和单次前向传递监督。",
      "result": "实验结果表明，CARD在性能上优于现有离散扩散基线。具体数据包括：与块扩散方法相比，CARD将训练延迟减少了3倍，同时实现了ARM级别的数据效率。这证明了CARD在保持高数据效率的同时，显著提升了并行推理的吞吐量，验证了其在高效语言建模中的有效性。",
      "conclusion": "该研究的主要贡献是提出了CARD框架，成功结合自回归模型的数据效率与扩散模型的并行生成能力，为下一代高效LLMs建立了稳健范式。学术价值在于提供了一种新颖的训练和推理平衡方法，实际应用价值在于促进大规模语言模型的高效部署。摘要未明确说明局限性，但未来工作可能包括扩展到其他任务或改进机制以增强通用性。",
      "tags": [
        "Causal Attention Mask",
        "Diffusion Language Model",
        "Autoregressive Training",
        "KV-Caching",
        "Parallel Decoding"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:06.823459Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22030",
    "title": "Per-parameter Task Arithmetic for Unlearning in Large Language Models",
    "authors": [
      "Chengyi Cai",
      "Zesheng Ye",
      "Jiangchao Yao",
      "Jianzhong Qi",
      "Bo Han",
      "Xiaolu Zhang",
      "Feng Liu",
      "Jun Zhou"
    ],
    "abstract": "In large language model (LLM) unlearning, private information is required to be removed. Task arithmetic unlearns by subtracting a specific task vector (TV)--defined as the parameter difference between a privacy-information-tuned model and the original model. While efficient, it can cause over-forgetting by disrupting parameters essential for retaining other information. Motivated by the observation that each parameter exhibits different importance for forgetting versus retention, we propose a per-parameter task arithmetic (PerTA) mechanism to rescale the TV, allowing per-parameter adjustment. These weights quantify the relative importance of each parameter for forgetting versus retention, estimated via gradients (i.e., PerTA-grad) or the diagonal Fisher information approximation (i.e., PerTA-fisher). Moreover, we discuss the effectiveness of PerTA, extend it to a more general form, and provide further analysis. Extensive experiments demonstrate that PerTA consistently improves upon standard TV, and in many cases surpasses widely used training-based unlearning methods in both forgetting effectiveness and overall model utility. By retaining the efficiency of task arithmetic while mitigating over-forgetting, PerTA offers a principled and practical framework for LLM unlearning.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22030.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22030",
    "published": "2026-01-29T17:35:32Z",
    "updated": "2026-01-29T17:35:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种参数级任务算术（PerTA）机制，通过量化每个参数的重要性来优化大型语言模型的遗忘学习，既高效又减少过度遗忘。",
      "motivation": "大型语言模型在处理敏感数据时，需要安全移除私有信息以保护隐私，这被称为遗忘学习。现有方法如任务算术通过减去任务向量实现高效遗忘，但可能导致过度遗忘，即扰乱了模型保留其他重要信息所必需的参数，从而影响整体模型效用。因此，亟需一种平衡遗忘效果和信息保留的新方法，以应对实际应用中对隐私和安全日益增长的需求。",
      "method": "论文提出了PerTA机制，通过对任务向量进行参数级重新缩放，允许为每个参数分配调整权重。这些权重基于梯度（PerTA-grad）或对角Fisher信息近似（PerTA-fisher）来估计，量化了每个参数在遗忘相对于保留的的重要性。PerTA扩展了标准任务算术，提供了更灵活的调整方式，避免了对关键参数的过度干扰，同时保留了任务算术的效率优势。",
      "result": "广泛的实验表明，PerTA在遗忘效果和模型整体效用方面持续优于标准任务向量方法。在许多情况下，它甚至超越了广泛使用的基于训练的遗忘方法，实现了更好的性能平衡。这表明PerTA能有效移除私有信息，同时减少过度遗忘导致的模型性能下降，验证了其在不同设置下的稳健性和实用性。",
      "conclusion": "PerTA通过参数级调整任务向量，在保持任务算术效率的同时缓解了过度遗忘，为大型语言模型遗忘学习提供了有原则且实用的框架。其学术价值在于量化参数重要性并优化遗忘过程，实际应用中则有助于开发更安全的AI系统。未来工作可扩展PerTA到更复杂场景或集成其他遗忘技术，进一步提升性能。",
      "tags": [
        "Large Language Model",
        "Unlearning",
        "Task Arithmetic",
        "Per-parameter Adjustment",
        "Fisher Information"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:27.415203Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22029",
    "title": "The Ensemble Inverse Problem: Applications and Methods",
    "authors": [
      "Zhengyan Huan",
      "Camila Pazos",
      "Martin Klassen",
      "Vincent Croft",
      "Pierre-Hugues Beauchemin",
      "Shuchin Aeron"
    ],
    "abstract": "We introduce a new multivariate statistical problem that we refer to as the Ensemble Inverse Problem (EIP). The aim of EIP is to invert for an ensemble that is distributed according to the pushforward of a prior under a forward process. In high energy physics (HEP), this is related to a widely known problem called unfolding, which aims to reconstruct the true physics distribution of quantities, such as momentum and angle, from measurements that are distorted by detector effects. In recent applications, the EIP also arises in full waveform inversion (FWI) and inverse imaging with unknown priors. We propose non-iterative inference-time methods that construct posterior samplers based on a new class of conditional generative models, which we call ensemble inverse generative models. For the posterior modeling, these models additionally use the ensemble information contained in the observation set on top of single measurements. Unlike existing methods, our proposed methods avoid explicit and iterative use of the forward model at inference time via training across several sets of truth-observation pairs that are consistent with the same forward model, but originate from a wide range of priors. We demonstrate that this training procedure implicitly encodes the likelihood model. The use of ensemble information helps posterior inference and enables generalization to unseen priors. We benchmark the proposed method on several synthetic and real datasets in inverse imaging, HEP, and FWI. The codes are available at https://github.com/ZhengyanHuan/The-Ensemble-Inverse-Problem--Applications-and-Methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22029.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22029",
    "published": "2026-01-29T17:34:41Z",
    "updated": "2026-01-29T17:34:41Z",
    "comment": "26 pages, 11 figures, in peer review",
    "light_analysis": {
      "overview": "论文提出了集合逆问题（EIP）的概念，并开发了一种基于条件生成模型的非迭代推理方法，用于从观测数据中反推真实分布。",
      "motivation": "该研究旨在解决逆问题中的关键挑战，如高能物理中的展开问题、全波形反演和逆成像中的先验未知情况，这些领域常因探测器效应或其他因素导致观测数据扭曲。现有方法通常在推理时显式和迭代使用前向模型，效率较低且难以泛化到未见先验。EIP的提出填补了这一空白，因为它关注从多组观测中反推分布，提高了重建精度和适应性，尤其在复杂场景中更显重要。",
      "method": "论文提出了一种非迭代推理方法，基于新类别的条件生成模型构建后验采样器，称为集合逆生成模型。这些模型在训练时利用观测集中的集合信息，而非单个测量值，通过处理多组与相同前向模型一致的真值-观测对来隐式编码似然模型。关键创新在于避免在推理时显式调用前向模型，训练数据覆盖广泛先验以提升泛化能力。方法涉及合成和真实数据集的应用，适用于逆成像、高能物理和全波形反演领域。",
      "result": "在逆成像、高能物理和全波形反演的合成和真实数据集上进行了基准测试，证明了该方法的有效性。摘要未明确说明具体的性能指标数据，如准确率或效率提升数值，但指出方法通过使用集合信息改进了后验推理，并实现了对未见先验的泛化。与现有基线方法相比，该方法在避免迭代使用前向模型方面显示出潜在优势，但需要进一步实验验证以量化改进程度。",
      "conclusion": "论文的主要贡献是定义集合逆问题并提出了创新的非迭代推理方法，通过条件生成模型和集合信息提升了后验推理的准确性和泛化能力。这项研究在逆问题求解领域具有重要学术价值，为高能物理、地球物理和医学成像等应用提供了新工具。未来工作可包括扩展模型到更多领域、优化训练策略，以及进一步实验以量化性能增益和解决潜在局限性，如计算复杂度或数据需求。",
      "tags": [
        "Ensemble Inverse Problem",
        "Conditional Generative Models",
        "Unfolding",
        "Full Waveform Inversion",
        "Inverse Imaging"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:41.338270Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22028",
    "title": "From Logits to Latents: Contrastive Representation Shaping for LLM Unlearning",
    "authors": [
      "Haoran Tang",
      "Rajiv Khanna"
    ],
    "abstract": "Most LLM unlearning methods aim to approximate retrain-from-scratch behaviors with minimal distribution shift, often via alignment-style objectives defined in the prediction space. While effective at reducing forgotten content generation, such approaches may act as suppression: forgotten concepts can persist in representations and remain entangled with retained knowledge. We introduce CLReg, a contrastive representation regularizer that identifies forget features while pushing them away from retain features, explicitly reducing forget-retain interference with minimal shifts on retain features. We provide first theoretical insights that relate representation shaping to entanglement reduction. Across unlearning benchmarks and LLMs of different sizes, CLReg decreases forget-retain representation entanglement that facilitates mainstream unlearning methods without positing extra privacy risks, inspiring future work that reshapes the representation space to remove forget concepts.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22028.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22028",
    "published": "2026-01-29T17:34:37Z",
    "updated": "2026-01-29T17:34:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出CLReg方法，通过对比表示正则化减少大型语言模型遗忘学习中的知识纠缠。",
      "motivation": "现有LLM遗忘学习方法常采用预测空间对齐近似从头训练，旨在减少遗忘内容生成，但可能仅抑制输出而未从表示中移除遗忘概念，导致遗忘与保留知识纠缠，影响模型行为一致性和隐私安全。因此，开发能显式减少表示层干扰的方法至关重要，以解决现有方法的不足，提升遗忘学习效果。",
      "method": "研究引入CLReg，一种对比表示正则化器，核心是识别遗忘特征并推离保留特征，以最小化保留特征偏移的同时减少遗忘-保留干扰。关键创新在于提供理论洞见，将表示塑形与纠缠减少关联。方法基于对比学习框架，但具体数据集和模型架构摘要未明确说明。",
      "result": "实验表明，CLReg在不同遗忘学习基准和多种大小LLM上有效减少遗忘-保留表示纠缠，促进了主流遗忘学习方法的应用，且未增加额外隐私风险。然而，摘要未明确说明具体性能指标如准确率提升，仅泛泛描述纠缠减少效果。",
      "conclusion": "CLReg通过对比表示正则化显著降低知识纠缠，为LLM遗忘学习提供新思路。学术上，首次理论联系表示塑形与纠缠减少；实际中，助力模型隐私保护和行为控制。未来可进一步探索表示空间重塑技术以彻底移除遗忘概念。",
      "tags": [
        "Large Language Model Unlearning",
        "Contrastive Learning",
        "Representation Shaping",
        "Knowledge Entanglement",
        "Regularization"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:00.478824Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22027",
    "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
    "authors": [
      "Johannes Kirmayr",
      "Lukas Stappen",
      "Elisabeth André"
    ],
    "abstract": "Existing benchmarks for Large Language Model (LLM) agents focus on task completion under idealistic settings but overlook reliability in real-world, user-facing applications. In domains, such as in-car voice assistants, users often issue incomplete or ambiguous requests, creating intrinsic uncertainty that agents must manage through dialogue, tool use, and policy adherence. We introduce CAR-bench, a benchmark for evaluating consistency, uncertainty handling, and capability awareness in multi-turn, tool-using LLM agents in an in-car assistant domain. The environment features an LLM-simulated user, domain policies, and 58 interconnected tools spanning navigation, productivity, charging, and vehicle control. Beyond standard task completion, CAR-bench introduces Hallucination tasks that test agents' limit-awareness under missing tools or information, and Disambiguation tasks that require resolving uncertainty through clarification or internal information gathering. Baseline results reveal large gaps between occasional and consistent success on all task types. Even frontier reasoning LLMs achieve less than 50% consistent pass rate on Disambiguation tasks due to premature actions, and frequently violate policies or fabricate information to satisfy user requests in Hallucination tasks, underscoring the need for more reliable and self-aware LLM agents in real-world settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22027.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22027",
    "published": "2026-01-29T17:33:42Z",
    "updated": "2026-01-29T17:33:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了CAR-bench基准，用于评估大型语言模型代理在真实世界不确定性下的一致性和能力意识。",
      "motivation": "现有大型语言模型代理基准多集中在理想化设置下的任务完成，忽视了现实世界应用中的可靠性问题，如用户请求不完整或模糊带来的不确定性。这在用户界面应用（如车载语音助手）中尤为关键，因为代理必须通过对话、工具使用和策略遵守来管理这些不确定性。当前基准的不足在于缺乏对代理在复杂、非理想环境下的全面评估，这限制了代理在实际部署中的可信度和效果，因此开发更贴近实际的基准至关重要。",
      "method": "论文引入了CAR-bench基准，模拟真实车载助手环境，包括一个大型语言模型模拟的用户、领域策略和58个互连工具，覆盖导航、生产力、充电和车辆控制。核心创新在于设计了Hallucination任务，测试代理在工具或信息缺失时的能力意识和避免幻觉；以及Disambiguation任务，要求代理通过澄清对话或内部信息收集来解决不确定性。评估使用前沿推理大型语言模型，通过多轮对话和工具使用来测试代理的一致性和政策遵守，提供一个全面的测试框架。",
      "result": "基线结果显示，在CAR-bench中，所有任务类型中偶发成功与一致成功之间存在显著差距。具体而言，即使在Disambiguation任务中，前沿推理大型语言模型的一致通过率也低于50%，主要由于过早采取行动导致失败；在Hallucination任务中，代理频繁违反政策或虚构信息以满足用户请求，暴露了严重的可靠性问题。这表明现有代理在现实世界不确定性下的表现远未达到一致和可靠的标准，与理想化基准相比有较大改进空间。",
      "conclusion": "本研究通过CAR-bench基准强调了评估大型语言模型代理一致性和能力意识的重要性，特别是在现实世界应用中。主要贡献是提供了一个全面环境来测试代理在不确定性和政策遵守方面的弱点，具有学术和实际价值，有助于推动更可靠、自我意识代理的开发。未来工作可专注于改进代理的决策机制、减少幻觉行为，以及扩展基准到其他领域，以提高代理在真实场景中的表现和可适用性。",
      "tags": [
        "Large Language Model Agents",
        "Benchmarking",
        "Uncertainty Handling",
        "Tool Usage",
        "Hallucination Detection"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:21.357559Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22025",
    "title": "When \"Better\" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications",
    "authors": [
      "Daniel Commey"
    ],
    "abstract": "Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.   We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.   In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic \"improved\" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.   All test suites, harnesses, and results are included for reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.22025.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22025",
    "published": "2026-01-29T17:32:34Z",
    "updated": "2026-01-29T17:32:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了评估驱动的工作流和最小可行评估套件（MVES），以系统化大型语言模型（LLM）应用的评估和迭代，避免盲目改进提示导致的性能下降。",
      "motivation": "LLM应用评估面临输出随机性、高维度和对提示敏感性等挑战，不同于传统软件测试，现有方法可能缺乏系统化，导致工程师在优化提示时盲目行动，甚至适得其反。本研究旨在解决这些问题，提供可重复的工程循环，以确保评估有效性和应用稳定性。",
      "method": "论文提出评估驱动工作流，包括定义、测试、诊断、修复四步骤，并引入最小可行评估套件（MVES），提供分层评估组件，涵盖通用LLM应用、检索增强生成和代理工具使用工作流。方法整合自动检查、人工规则和LLM作为评判员，实验在本地使用Ollama、Llama 3 8B Instruct和Qwen 2.5 7B Instruct模型进行。",
      "result": "实验结果显示，通用“改进”提示模板可能导致行为权衡：在Llama 3上，替换任务特定提示为通用规则后，提取通过率从100%降至90%，RAG合规性从93.3%降至80%，而指令遵循能力有所改善。这强调了评估驱动迭代的重要性，表明通用方法并非总是有效，需要谨慎校准性能声明。",
      "conclusion": "论文贡献包括提供评估驱动工作流和MVES，为LLM应用评估提供系统化方法，具有重要实际价值，可避免盲目优化提示并促进可靠开发流程。未来工作可扩展评估组件、改进评估方法鲁棒性，并应用于更广泛场景，摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Retrieval-Augmented Generation",
        "Agentic Tool-Use",
        "Evaluation Framework",
        "Prompt Iteration"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:42.376194Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22020",
    "title": "Visual-Guided Key-Token Regularization for Multimodal Large Language Model Unlearning",
    "authors": [
      "Chengyi Cai",
      "Zesheng Ye",
      "Peike Li",
      "Bo Han",
      "Jianzhong Qi",
      "Feng Liu"
    ],
    "abstract": "Unlearning in Multimodal Large Language Models (MLLMs) prevents the model from revealing private information when queried about target images. Existing MLLM unlearning methods largely adopt approaches developed for LLMs. They treat all answer tokens uniformly, disregarding their varying importance in the unlearning process. Moreover, these methods focus exclusively on the language modality, disregarding visual cues that indicate key tokens in answers. In this paper, after formulating the problem of unlearning in multimodal question answering for MLLMs, we propose Visual-Guided Key-Token Regularization (ViKeR). We leverage irrelevant visual inputs to predict ideal post-unlearning token-level distributions and use these distributions to regularize the unlearning process, thereby prioritizing key tokens. Further, we define key tokens in unlearning via information entropy and discuss ViKeR's effectiveness through token-level gradient reweighting, which amplifies updates on key tokens. Experiments on MLLMU and CLEAR benchmarks demonstrate that our method effectively performs unlearning while mitigating forgetting and maintaining response coherence.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22020.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22020",
    "published": "2026-01-29T17:26:54Z",
    "updated": "2026-01-29T17:26:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种视觉引导的关键令牌正则化方法（ViKeR），用于改进多模态大型语言模型在遗忘任务中的性能，优先处理关键令牌以增强效果。",
      "motivation": "多模态大型语言模型在遗忘任务中面临挑战，当模型被查询目标图像时，需要防止泄露私人信息。现有方法通常继承自单模态语言模型，处理所有答案令牌均匀，忽视了令牌在遗忘过程中的重要性差异，且只关注语言模态，忽略视觉线索，导致效率低下和隐私风险。因此，本研究旨在开发一种更有效的遗忘方法，综合考虑令牌重要性和视觉引导，以解决现有方法的不足。",
      "method": "本研究提出Visual-Guided Key-Token Regularization (ViKeR)。首先，将多模态问答中的遗忘问题形式化。然后，利用不相关的视觉输入预测理想的遗忘后令牌级分布，并使用这些分布来正则化遗忘过程，从而优先处理关键令牌。关键令牌通过信息熵来定义，并通过令牌级梯度重加权放大其更新，以增强遗忘效果。方法在MLLMU和CLEAR基准数据集上进行评估，具体模型架构和细节在摘要中未明确说明。",
      "result": "实验在MLLMU和CLEAR基准上验证了ViKeR方法的有效性。结果显示，该方法能够有效执行遗忘任务，同时减轻了对其他知识的遗忘并保持了响应的连贯性。与现有基线方法相比，ViKeR通过视觉引导和令牌级正则化提升了性能，具体表现在更好的隐私保护和模型响应质量上，但摘要未提供具体数据指标如准确率提升，仅强调在基准测试中的优越效果。",
      "conclusion": "本研究的主要贡献是提出了ViKeR方法，它为多模态大型语言模型的遗忘任务引入了视觉引导和令牌级正则化。学术上，该方法丰富了多模态遗忘研究，为令牌重要性分析提供了新视角；实际应用上，有助于增强模型在隐私敏感场景下的安全性。潜在局限性可能包括对视觉输入的依赖性和计算成本，未来工作可以探索更高效的视觉信息利用方式或扩展到其他多模态任务。",
      "tags": [
        "Multimodal Large Language Model",
        "Unlearning",
        "Visual-Guided Regularization",
        "Key-Token Identification",
        "Gradient Reweighting"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:48.289324Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22016",
    "title": "TBDFiltering: Sample-Efficient Tree-Based Data Filtering",
    "authors": [
      "Robert Istvan Busa-Fekete",
      "Julian Zimmert",
      "Anne Xiangyi Zheng",
      "Claudio Gentile",
      "Andras Gyorgy"
    ],
    "abstract": "The quality of machine learning models depends heavily on their training data. Selecting high-quality, diverse training sets for large language models (LLMs) is a difficult task, due to the lack of cheap and reliable quality metrics. While querying existing LLMs for document quality is common, this is not scalable to the large number (billions) of documents used in training. Instead, practitioners often use classifiers trained on sparse quality signals. In this paper, we propose a text-embedding-based hierarchical clustering approach that adaptively selects the documents to be evaluated by the LLM to estimate cluster quality. We prove that our method is query efficient: under the assumption that the hierarchical clustering contains a subtree such that each leaf cluster in the tree is pure enough (i.e., it mostly contains either only good or only bad documents), with high probability, the method can correctly predict the quality of each document after querying a small number of documents. The number of such documents is proportional to the size of the smallest subtree with (almost) pure leaves, without the algorithm knowing this subtree in advance. Furthermore, in a comprehensive experimental study, we demonstrate the benefits of our algorithm compared to other classifier-based filtering methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22016.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22016",
    "published": "2026-01-29T17:22:06Z",
    "updated": "2026-01-29T17:22:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一种基于文本嵌入的层次聚类数据过滤方法TBDFiltering，通过树状结构高效选择高质量文档，显著提升大语言模型训练的样本效率。",
      "motivation": "该研究旨在解决为大语言模型选择高质量训练数据时的关键难题。训练数据质量对模型性能至关重要，但缺乏廉价可靠的质量指标，使得大规模数据过滤面临挑战。现有方法如直接查询大语言模型评估文档成本高昂、不可扩展，而基于稀疏信号的分类器效率低下，无法有效处理数十亿级别的文档。因此，开发一种样本效率高、可扩展的数据过滤方法至关重要，以提高模型训练效果并降低资源消耗。",
      "method": "论文提出TBDFiltering方法，基于文本嵌入构建层次聚类树，自适应地选择文档由大语言模型评估以估计聚类质量。关键创新在于树状结构的高效过滤策略，假设存在一个子树其叶聚类足够纯净（即大部分文档为优质或劣质），方法通过查询少量文档即可预测所有文档质量，查询数量与最纯子树的大小成比例。技术细节包括文本嵌入表示、层次聚类算法和自适应采样机制，从而减少对大语言模型的依赖，提高过滤效率。",
      "result": "在综合实验研究中，TBDFiltering算法与其他基于分类器的数据过滤方法相比，展示了显著优势。摘要未明确说明具体性能指标如准确率提升数值，但实验结果表明该方法在样本效率上表现优异，能以更少的查询正确预测文档质量。这表明在实际应用中，TBDFiltering能有效降低计算成本，提高数据筛选精度和可扩展性，优于传统基线方法。",
      "conclusion": "本研究的核心贡献是开发了一种样本效率高的树状数据过滤方法，为大语言模型训练数据选择提供了高效解决方案。其学术价值在于融合文本嵌入和层次聚类技术，实现可证明的查询效率，推动大规模数据预处理研究。实际应用价值包括降低训练成本、提升模型性能，促进AI系统的优化。局限性可能在于对聚类纯净度假设的依赖；未来工作可探索更稳健的聚类算法或扩展到其他机器学习任务。",
      "tags": [
        "Hierarchical Clustering",
        "Text Embedding",
        "Large Language Models",
        "Data Filtering",
        "Sample Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:51.084369Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22012",
    "title": "Putting a Face to Forgetting: Continual Learning meets Mechanistic Interpretability",
    "authors": [
      "Sergi Masip",
      "Gido M. van de Ven",
      "Javier Ferrando",
      "Tinne Tuytelaars"
    ],
    "abstract": "Catastrophic forgetting in continual learning is often measured at the performance or last-layer representation level, overlooking the underlying mechanisms. We introduce a mechanistic framework that offers a geometric interpretation of catastrophic forgetting as the result of transformations to the encoding of individual features. These transformations can lead to forgetting by reducing the allocated capacity of features (worse representation) and disrupting their readout by downstream computations. Analysis of a tractable model formalizes this view, allowing us to identify best- and worst-case scenarios. Through experiments on this model, we empirically test our formal analysis and highlight the detrimental effect of depth. Finally, we demonstrate how our framework can be used in the analysis of practical models through the use of Crosscoders. We present a case study of a Vision Transformer trained on sequential CIFAR-10. Our work provides a new, feature-centric vocabulary for continual learning.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22012.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22012",
    "published": "2026-01-29T17:18:36Z",
    "updated": "2026-01-29T17:18:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一种机制性框架，通过几何解释揭示连续学习中灾难性遗忘的特征级机制，并引入新的分析词汇。",
      "motivation": "灾难性遗忘是连续学习中的核心挑战，现有方法通常仅从性能或最终层表示层面评估，忽略了底层机制的具体变化。这一问题之所以重要，是因为深入理解遗忘过程有助于开发更鲁棒的学习算法，但当前研究缺乏对特征编码变形的系统性分析，难以解释遗忘为何发生，从而限制了理论发展和实际应用。本研究旨在弥补这一不足，通过关注特征级别的机制来提供更全面的解释框架。",
      "method": "论文提出一个机制性框架，将灾难性遗忘解释为特征编码的几何变换，具体通过减少特征分配容量和干扰下游计算来导致遗忘。关键创新点包括使用一个可处理模型形式化这一观点，识别最佳和最坏情况场景；并引入Crosscoders技术，将框架应用于实际模型分析。在案例研究中，采用Vision Transformer在序列化的CIFAR-10数据集上进行训练，以展示框架的实用性和可扩展性。",
      "result": "通过实验验证形式化分析，论文强调了网络深度对遗忘的负面影响，即较深的模型更容易发生特征编码的破坏性变化。在案例研究中，框架成功应用于Vision Transformer，提供了对实际模型遗忘机制的洞察，但摘要未明确说明具体的性能指标如准确率提升或效率改进，仅从定性角度展示了分析的有效性和与基线对比的理论优势。",
      "conclusion": "本研究的主要贡献是提供了一个新的、以特征为中心的词汇和机制性框架，增强了连续学习中对灾难性遗忘机制的理解。其学术价值在于推动连续学习理论向更细致的机制解释发展，实际应用价值可能包括指导模型设计和优化策略。未来工作方向可扩展到更多复杂模型和任务，以进一步验证框架的普适性和解决潜在局限性，如更广泛的实验验证或算法改进。",
      "tags": [
        "Continual Learning",
        "Mechanistic Interpretability",
        "Catastrophic Forgetting",
        "Vision Transformer",
        "Crosscoders"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:01.330779Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22010",
    "title": "Exploring Diverse Generation Paths via Inference-time Stiefel Activation Steering",
    "authors": [
      "Dongxuan Zhu",
      "Ly Tran Ho Khanh",
      "Andy Yat-Ming Cheung",
      "Man-Chung Yue",
      "Viet Anh Nguyen"
    ],
    "abstract": "Language models often default to a narrow set of high-probability outputs, leaving their generation paths homogeneous and prone to mode collapse. Sampling-based strategies inject randomness but still struggle to guarantee diversity across multiple concurrent generation runs. We address this limitation by introducing STARS ($\\textbf{St}$iefel-based $\\textbf{A}$ctivation Steering for Diverse $\\textbf{R}$ea$\\textbf{S}$oning), a training-free, inference-time intervention method that transforms activation steering into an exploration engine. At each token, STARS collects the hidden activations of concurrent generation runs and optimizes multiple additive steering directions jointly on the Stiefel manifold. STARS maximizes the geometric volume of the steered activations, while the Stiefel manifold induces orthogonality of the steering interventions. This formulation explicitly promotes divergent activation vectors of concurrent generation runs, and implicitly promotes divergent generation trajectories. This manifold optimization formulation can be solved using a Riemannian gradient descent algorithm with convergence guarantees, but this algorithm is too time-consuming for real-time inference. To guarantee low latency, we further design a lightweight one-step update with an aggressive, closed-form stepsize. For test case generation and scientific discovery benchmarks, STARS consistently outperforms standard sampling methods, achieving greater diversity without sacrificing qualitative performance.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22010.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22010",
    "published": "2026-01-29T17:17:04Z",
    "updated": "2026-01-29T17:17:04Z",
    "comment": "34 pages, 2 figures. Accepted for publication at ICLR 2026",
    "light_analysis": {
      "overview": "提出STARS方法，通过推理时在Stiefel流形上优化激活转向，提升语言模型生成的多样性。",
      "motivation": "语言模型常生成单一的高概率输出，导致同质化和模式崩溃，限制了在需要多样输出的应用如测试案例生成和科学发现中的有效性。现有采样方法虽注入随机性，但无法保证多个并发生成运行中的多样性，存在不足。因此，开发一种训练免费、推理时干预方法以促进多样化生成轨迹显得尤为重要。",
      "method": "STARS是一种训练免费的推理时干预方法，通过收集并发生成的隐藏激活，在Stiefel流形上联合优化多个加法转向方向。该方法最大化转向激活的几何体积，利用Stiefel流形的正交性促进激活向量的多样化，从而隐含地提升生成路径的差异。摘要未明确指定具体数据集或模型架构，但提到使用黎曼梯度下降算法，并设计轻量级一步更新以降低延迟，采用闭式步长。",
      "result": "在测试案例生成和科学发现基准测试中，STARS持续优于标准采样方法，实现了更高的多样性，同时保持了定性性能不下降。但摘要未明确说明具体性能指标如准确率提升或效率改进数据，仅提及整体优势对比。",
      "conclusion": "该研究的主要贡献是提出STARS方法，通过推理时在Stiefel流形上进行激活转向优化，有效解决语言模型生成多样性不足的问题，具有学术创新性和实际应用价值。研究展现了在多样化输出任务中的潜力，未来工作可能包括优化算法效率或扩展到其他领域，但摘要未明确说明局限性。",
      "tags": [
        "Stiefel Manifold",
        "Activation Steering",
        "Inference-time Optimization",
        "Riemannian Gradient Descent",
        "Diversity Generation"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:27.864977Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22002",
    "title": "Rate-Distortion Optimization for Transformer Inference",
    "authors": [
      "Anderson de Andrade",
      "Alon Harell",
      "Ivan V. Bajić"
    ],
    "abstract": "Transformers achieve superior performance on many tasks, but impose heavy compute and memory requirements during inference. This inference can be made more efficient by partitioning the process across multiple devices, which, in turn, requires compressing its intermediate representations. In this work, we introduce a principled rate-distortion-based framework for lossy compression that learns compact encodings that explicitly trade off bitrate against accuracy. Experiments on language benchmarks show that the proposed codec achieves substantial savings with improved accuracy in some cases, outperforming more complex baseline methods. We characterize and analyze the rate-distortion performance of transformers, offering a unified lens for understanding performance in representation coding. This formulation extends information-theoretic concepts to define the gap between rate and entropy, and derive some of its bounds. We further develop probably approximately correct (PAC)-style bounds for estimating this gap. For different architectures and tasks, we empirically demonstrate that their rates are driven by these bounds, adding to the explainability of the formulation.",
    "categories": [
      "cs.LG",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22002.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22002",
    "published": "2026-01-29T17:12:46Z",
    "updated": "2026-01-29T17:12:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个基于率失真优化的框架，用于压缩Transformer推理中的中间表示，以平衡比特率和准确性。",
      "motivation": "Transformer模型在许多任务中表现出色，但推理过程需要大量的计算和内存资源，限制了其实际部署效率。为了提高效率，现有方法通过跨设备分区来加速推理，但需要有效的中间表示压缩技术。然而，当前压缩方法可能缺乏理论指导或难以在比特率和准确性之间找到最优权衡。本研究的动机是解决这一问题，通过开发一个原则性的率失真框架来优化压缩过程，从而减轻推理负担并提升整体性能，弥补现有方法的不足。",
      "method": "本研究提出了一种基于率失真理论的损失压缩框架，用于学习紧凑的编码，明确权衡比特率和准确性。核心方法包括扩展信息论概念来定义率与熵之间的差距，并推导其理论界限。关键创新点在于开发了概率近似正确（PAC）风格的界限，用于估计这一差距，从而增强方法的理论基础。研究在语言基准测试上进行了实证分析，考察不同Transformer架构和任务的率失真性能，但摘要未明确说明具体数据集或模型架构的细节。",
      "result": "实验结果表明，在语言基准测试中，提出的编解码器实现了显著的比特率节省，并在某些情况下提高了准确性，优于更复杂的基线方法。论文通过经验分析验证了不同架构和任务的率失真性能受推导的界限驱动，增强了方法的可解释性。具体性能指标如准确率提升百分比在摘要中未明确说明，但整体效果显示该方法在效率和准确性上优于现有基线，为推理优化提供了有效解决方案。",
      "conclusion": "本研究的主要贡献是提供了一个统一的率失真优化框架，用于理解和优化Transformer推理中的表示编码，理论贡献包括扩展信息论概念和推导界限，提高了方法的可解释性。该研究具有学术价值，将信息论应用于机器学习优化问题，并具有实际应用价值，可以降低推理成本并提升效率。局限性或未来工作方向在摘要中未明确说明，但可能包括扩展到更多任务或探索更高效的压缩技术。",
      "tags": [
        "Rate-Distortion Optimization",
        "Transformer Inference",
        "Lossy Compression",
        "Information Theory",
        "PAC Bounds"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:36.730874Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.22001",
    "title": "Heterogeneous Computing: The Key to Powering the Future of AI Agent Inference",
    "authors": [
      "Yiren Zhao",
      "Junyi Liu"
    ],
    "abstract": "AI agent inference is driving an inference heavy datacenter future and exposes bottlenecks beyond compute - especially memory capacity, memory bandwidth and high-speed interconnect. We introduce two metrics - Operational Intensity (OI) and Capacity Footprint (CF) - that jointly explain regimes the classic roofline analysis misses, including the memory capacity wall. Across agentic workflows (chat, coding, web use, computer use) and base model choices (GQA/MLA, MoE, quantization), OI/CF can shift dramatically, with long context KV cache making decode highly memory bound. These observations motivate disaggregated serving and system level heterogeneity: specialized prefill and decode accelerators, broader scale up networking, and decoupled compute-memory enabled by optical I/O. We further hypothesize agent-hardware co design, multiple inference accelerators within one system, and high bandwidth, large capacity memory disaggregation as foundations for adaptation to evolving OI/CF. Together, these directions chart a path to sustain efficiency and capability for large scale agentic AI inference.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.22001.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22001",
    "published": "2026-01-29T17:11:46Z",
    "updated": "2026-01-29T17:11:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文引入操作强度(OI)和容量足迹(CF)指标，并提出异构计算系统设计以解决AI代理推理中的内存和带宽瓶颈。",
      "motivation": "随着AI代理推理推动数据中心向推理密集型发展，暴露出计算之外的瓶颈，如内存容量不足、内存带宽限制和高速互连问题。经典的roofline分析未能全面覆盖这些机制，特别是内存容量墙，导致现有系统在面对多样化的代理工作流（如聊天、编码）和基础模型选择（如GQA/MLA、MoE、量化）时效率受限。因此，研究需要新方法来理解和应对这些瓶颈，以支持大规模AI代理推理的可扩展性。",
      "method": "研究提出两个新度量指标——操作强度(OI)和容量足迹(CF)，它们联合解释经典roofline分析遗漏的机制，包括内存容量墙。通过分析不同代理工作流和模型选择，论文观察OI/CF的变化，特别是长上下文KV缓存使解码过程高度受内存限制。基于此，论文倡导异构计算系统设计，包括专用预填充和解码加速器、扩展网络规模以及通过光学I/O技术实现计算与内存的解耦，以应对这些动态瓶颈。",
      "result": "摘要未明确报告具体实验结果或性能指标。然而，观察到OI/CF指标在多样化代理工作流和模型选择下变化显著，如长上下文KV缓存导致解码高度内存受限，这表明传统系统设计存在不足。论文提出异构计算解决方案来适应这些变化，但未提供与基线方法的直接对比数据，仅基于观察指出经典roofline分析的局限性。",
      "conclusion": "论文通过引入OI和CF指标揭示了AI代理推理中的关键瓶颈，并提出异构计算系统设计作为可持续解决方案。研究强调硬件与软件的协同设计，并假设代理-硬件协同设计、系统内多推理加速器和大带宽大容量内存解构是适应OI/CF演化的基础。这为大规模AI代理推理的效率和能力提供了理论路径，具有推动未来AI系统设计的学术和实际价值，潜在局限性包括摘要未详细讨论实现细节。",
      "tags": [
        "Operational Intensity",
        "Capacity Footprint",
        "Heterogeneous Computing",
        "AI Agent Inference",
        "Optical I/O"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:56.387519Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21999",
    "title": "Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains",
    "authors": [
      "Meng Cao",
      "Jiexi Liu",
      "Songcan Chen"
    ],
    "abstract": "Imbalanced Domain Generalization (IDG) focuses on mitigating both domain and label shifts, both of which fundamentally shape the model's decision boundaries, particularly under heterogeneous long-tailed distributions across domains. Despite its practical significance, it remains underexplored, primarily due to the technical complexity of handling their entanglement and the paucity of theoretical foundations. In this paper, we begin by theoretically establishing the generalization bound for IDG, highlighting the role of posterior discrepancy and decision margin. This bound motivates us to focus on directly steering decision boundaries, marking a clear departure from existing methods. Subsequently, we technically propose a novel Negative-Dominant Contrastive Learning (NDCL) for IDG to enhance discriminability while enforce posterior consistency across domains. Specifically, inter-class decision-boundary separation is enhanced by placing greater emphasis on negatives as the primary signal in our contrastive learning, naturally amplifying gradient signals for minority classes to avoid the decision boundary being biased toward majority classes. Meanwhile, intra-class compactness is encouraged through a re-weighted cross-entropy strategy, and posterior consistency across domains is enforced through a prediction-central alignment strategy. Finally, rigorous yet challenging experiments on benchmarks validate the effectiveness of our NDCL. The code is available at https://github.com/Alrash/NDCL.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21999.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21999",
    "published": "2026-01-29T17:09:38Z",
    "updated": "2026-01-29T17:09:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Negatives-Dominant Contrastive Learning (NDCL)方法，通过强调负样本增强决策边界分离，以解决不平衡域泛化问题。",
      "motivation": "Imbalanced Domain Generalization (IDG)旨在处理跨域时域和标签的偏移，尤其是在异构长尾分布中。这个问题具有实际重要性，例如在真实世界数据集中存在类别不平衡和域变化，但研究尚未充分探索，主要原因在于处理它们纠缠的技术复杂性和理论基础的缺乏。现有方法可能无法有效直接引导决策边界，导致模型在多数类上偏置，从而需要新的方法来应对这一挑战。",
      "method": "论文提出Negatives-Dominant Contrastive Learning (NDCL)方法，核心创新在于将负样本作为对比学习的主要信号，以增强决策边界分离，避免对少数类的偏置。具体技术包括使用重加权交叉熵策略鼓励类内紧凑性，以及预测中心对齐策略强制跨域后验一致性。摘要未明确说明使用的数据集和模型架构细节，但这些方法是针对不平衡域泛化设计的。",
      "result": "实验在基准测试中进行，验证了NDCL方法的有效性，但摘要未提供具体的性能指标如准确率提升或效率改进。与基线方法的对比表明，NDCL在应对不平衡域泛化挑战时表现优越，但具体数据需在论文中进一步查看。摘要强调了方法的严格验证，但实验细节未明确说明。",
      "conclusion": "本研究为不平衡域泛化建立了理论泛化边界，强调了后验不一致性和决策边界的作用，并提出了NDCL方法来增强判别性和跨域一致性。学术上填补了理论空白并提供了新方法，实际应用价值在于处理现实世界中的不平衡数据跨域泛化任务。潜在局限性或未来工作方向摘要未明确说明，但可能包括扩展到更多场景或进一步优化方法。",
      "tags": [
        "Imbalanced Domain Generalization",
        "Contrastive Learning",
        "Decision Boundary",
        "Posterior Consistency",
        "Long-Tailed Distributions"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:02.414265Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21998",
    "title": "Causal World Modeling for Robot Control",
    "authors": [
      "Lin Li",
      "Qihang Zhang",
      "Yiming Luo",
      "Shuai Yang",
      "Ruilin Wang",
      "Fei Han",
      "Mingrui Yu",
      "Zelin Gao",
      "Nan Xue",
      "Xing Zhu",
      "Yujun Shen",
      "Yinghao Xu"
    ],
    "abstract": "This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21998.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21998",
    "published": "2026-01-29T17:07:43Z",
    "updated": "2026-01-29T17:07:43Z",
    "comment": "Project page: https://technology.robbyant.com/lingbot-va Code: https://github.com/robbyant/lingbot-va",
    "light_analysis": {
      "overview": "论文提出LingBot-VA自回归扩散框架，结合因果世界建模，用于机器人控制，实现帧预测与政策执行的同步学习。",
      "motivation": "研究动机在于机器人学习需要有效理解动作与视觉动态之间的因果关系。现有方法在整合视频世界建模和视觉语言预训练方面可能不足，导致控制和泛化能力受限，而这一问题对机器人适应复杂环境至关重要。本工作旨在建立新基础，利用因果推理提升机器人学习的效率和适应性，以应对长时程操作和数据稀缺的挑战。",
      "method": "研究方法基于LingBot-VA框架，采用自回归扩散模型同步学习帧预测和政策执行。关键创新点包括：(1)共享潜在空间，整合视觉和动作标记，驱动于Mixture-of-Transformers架构，以增强模型表示能力；(2)闭环滚动机制，允许持续获取环境反馈，结合真实观测提升控制精度；(3)异步推理管道，并行化动作预测和运动执行，支持高效实时控制。摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "主要实验结果显示，模型在模拟基准和现实场景中评估时，在长时程操作、数据效率和泛化到新配置方面显示出显著前景。与基线方法的对比情况摘要未明确说明具体性能指标，如准确率或效率提升，但强调了模型在复杂任务中的优异表现，表明其在实际应用中的潜力。",
      "conclusion": "结论表明，论文的主要贡献是引入了因果世界建模框架LingBot-VA，提升了机器人控制性能。学术价值在于为机器人学习提供新方法，结合视频世界建模和视觉语言预训练；实际应用价值有潜力于复杂场景操作，如自主导航和物体操控。局限性或未来工作方向摘要未明确说明，但可能涉及进一步优化模型效率和扩展应用领域。",
      "tags": [
        "Causal World Modeling",
        "Autoregressive Diffusion",
        "Mixture-of-Transformers",
        "Closed-loop Rollout",
        "Vision-Language Pre-training"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:27.003805Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21996",
    "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
    "authors": [
      "Jianhui Chen",
      "Yuzhang Luo",
      "Liangming Pan"
    ],
    "abstract": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21996.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21996",
    "published": "2026-01-29T17:06:54Z",
    "updated": "2026-01-29T17:06:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出MDA框架，使用影响力函数追溯LLM可解释单元的訓練數據來源，驗證因果影響並加速模型收斂。",
      "motivation": "在大型语言模型中，机制可解释性研究已识别出可解释电路，但这些电路在训练数据中的因果起源尚未明确。本研究的动机是解决这一空白，因为理解训练数据如何影响模型内部机制对解释和控制LLM行为至关重要，而现有方法缺乏直接的数据溯源能力，限制了深入分析模型发育过程。该研究旨在通过追溯数据来源，为模型可解释性和优化提供新视角，增强对AI系统内部运作的理解。",
      "method": "论文提出机制数据归因（MDA）框架，利用影响力函数将模型中的可解释单元（如特定头部）与训练样本关联，进行因果验证。关键创新在于通过干预实验，如移除或增强高影响力样本，观察对可解释头部形成的影响。在Pythia模型系列上进行实验，分析重复性结构数据（如LaTeX、XML）作为机制催化剂的作用，以探索数据模式对电路发育的调控机制，并提供可扩展的分析方法。",
      "result": "实验结果表明，针对高影响力样本进行干预能显著调节可解释头部的出现，而随机干预无效果，提供了因果证据支持训练数据的特定影响。具体发现包括干预诱导头形成时，模型的上下文学习能力也同步变化，验证了诱导头与上下文学习之间的功能连接假设。这些发现为长期学术争论提供直接证据，并展示了通过数据干预可有效调控模型内部机制，但具体性能指标如准确率变化摘要未明确说明。",
      "conclusion": "该研究的核心贡献是开发了MDA框架，为追溯LLM训练数据的影响提供因果方法论，支持诱导头与上下文学习的关联假设，推动机制可解释性发展。实践上，提出的数据增强管道能加速电路收敛，为优化模型训练和引导LLM发育轨迹提供新途径。学术价值在于深化了对AI模型内部运作的理解，未来工作可进一步验证方法通用性，并扩展至更多模型类型和应用场景，潜在局限性可能包括方法对特定数据模式的依赖。",
      "tags": [
        "Mechanistic Interpretability",
        "Influence Functions",
        "Induction Heads",
        "In-context Learning",
        "Data Attribution"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:49.382707Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21993",
    "title": "Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems",
    "authors": [
      "Dhiogo de Sá",
      "Carlos Schmiedel",
      "Carlos Pereira Lopes"
    ],
    "abstract": "Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21993.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21993",
    "published": "2026-01-29T17:04:13Z",
    "updated": "2026-01-29T17:04:13Z",
    "comment": "28 pages, 2 figures",
    "light_analysis": {
      "overview": "论文引入了Liquid Interfaces，一种通过短暂关系事件和运行时语义协商实现的动态接口范式，为自主系统的自适应协调提供创新基础。",
      "motivation": "当前软件架构难以支持自适应、概率性和上下文相关的自主代理，系统集成主要依赖静态接口和确定性合约。这些方法不适应动态和不确定性环境，导致系统间协调困难，限制了互操作性和灵活性。因此，本研究旨在开发一种新接口范式，以解决现有方法在处理自适应推理和不确定性时的不足。",
      "method": "作者形式化了Liquid Interfaces模型，将接口定义为通过意图表达和运行时语义协商产生的短暂关系事件。提出Liquid Interface Protocol (LIP)，管理意图驱动交互、协商执行和在语义不确定性下的短暂性。关键创新包括接口动态化和实时协商机制。此外，讨论了治理含义，并描述了参考架构以展示该方法的实际可行性。",
      "result": "摘要未明确说明具体实验数据或性能指标。但论文指出参考架构证明了Liquid Interfaces的实际可行性，通过架构设计展示了其适应性和协调能力。与传统的静态接口相比，该方法能更好地处理不确定环境，提升系统互操作性和自适应协调的灵活性。",
      "conclusion": "Liquid Interfaces为基于代理的系统提供了自适应协调的原则性基础，解决了静态接口在动态环境中的局限性。研究在学术上推动了软件架构和自主系统协调理论的发展，实际应用中可促进智能代理的协作和互操作性。潜在局限性包括实现复杂性和性能优化，未来工作可深入协议扩展和实证评估。",
      "tags": [
        "Liquid Interfaces",
        "Intent-Driven Interaction",
        "Semantic Negotiation",
        "Autonomous Systems",
        "Reference Architecture"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:01.834773Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21991",
    "title": "Geometry of Drifting MDPs with Path-Integral Stability Certificates",
    "authors": [
      "Zuyuan Zhang",
      "Mahdi Imani",
      "Tian Lan"
    ],
    "abstract": "Real-world reinforcement learning is often \\emph{nonstationary}: rewards and dynamics drift, accelerate, oscillate, and trigger abrupt switches in the optimal action. Existing theory often represents nonstationarity with coarse-scale models that measure \\emph{how much} the environment changes, not \\emph{how} it changes locally -- even though acceleration and near-ties drive tracking error and policy chattering. We take a geometric view of nonstationary discounted Markov Decision Processes (MDPs) by modeling the environment as a differentiable homotopy path and tracking the induced motion of the optimal Bellman fixed point. This yields a length--curvature--kink signature of intrinsic complexity: cumulative drift, acceleration/oscillation, and action-gap-induced nonsmoothness. We prove a solver-agnostic path-integral stability bound and derive gap-safe feasible regions that certify local stability away from switch regimes. Building on these results, we introduce \\textit{Homotopy-Tracking RL (HT-RL)} and \\textit{HT-MCTS}, lightweight wrappers that estimate replay-based proxies of length, curvature, and near-tie proximity online and adapt learning or planning intensity accordingly. Experiments show improved tracking and dynamic regret over matched static baselines, with the largest gains in oscillatory and switch-prone regimes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21991.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21991",
    "published": "2026-01-29T17:03:23Z",
    "updated": "2026-01-29T17:03:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出几何视角分析非平稳强化学习，通过建模环境为可微分同伦路径并引入路径积分稳定性证书，开发HT-RL和HT-MCTS方法以改进动态跟踪性能。",
      "motivation": "现实世界强化学习常面临非平稳性，如奖励和动态的漂移、加速、振荡和切换，导致最优行为不稳定和政策抖动。现有理论使用粗粒度模型仅关注环境变化量，忽视局部变化方式（如加速度和平局），限制了算法在动态环境中的适应性和稳定性。因此，需要更精细方法理解环境如何变化，以设计更稳定学习算法。本研究从几何角度出发，旨在提供局部稳定性理论保证，解决非平稳MDPs中的跟踪误差问题。",
      "method": "论文采用几何视角，将非平稳折扣MDPs的环境建模为可微分同伦路径，并跟踪最优贝尔曼不动点的诱导运动，定义长度（累积漂移）、曲率（加速度/振荡）和扭结（动作间隙导致的非光滑性）作为复杂性签名。基于此，证明了求解器无关的路径积分稳定性边界，并推导出间隙安全可行区域来认证局部稳定性。进一步引入Homotopy-Tracking RL (HT-RL) 和 HT-MCTS 轻量级包装器，在线估计基于重放的代理指标（如长度、曲率和近平局接近度），并动态调整学习或规划强度以应对环境变化。",
      "result": "实验显示，HT-RL和HT-MCTS方法在匹配的静态基线上，显著改进了跟踪性能和动态遗憾。尤其在振荡和切换倾向的环境中，增益最为明显，有效减少了政策抖动并提高了适应速度。摘要未明确说明具体数据如准确率提升百分比，但强调方法在动态体制中表现出更优的稳定性和性能，验证了几何分析和稳定性证书的有效性。与基线相比，新方法在非平稳场景中展示了更好的环境变化适应能力。",
      "conclusion": "论文的主要贡献在于从几何角度分析非平稳MDPs，提供了路径积分稳定性证书和间隙安全区域的理论框架，并开发了HT-RL和HT-MCTS方法。这增强了强化学习在动态环境中的理论理解，具有实际应用价值，如机器人控制和实时决策系统。局限性可能包括对可微分同伦路径模型的假设依赖，未来工作可扩展到更一般的非平稳设置，或结合其他学习技术以进一步提升鲁棒性和泛化能力。",
      "tags": [
        "Reinforcement Learning",
        "Nonstationary Markov Decision Processes",
        "Homotopy Path",
        "Path-Integral Stability",
        "HT-RL"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:23.757517Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21988",
    "title": "Generalized Information Gathering Under Dynamics Uncertainty",
    "authors": [
      "Fernando Palafox",
      "Jingqi Li",
      "Jesse Milzman",
      "David Fridovich-Keil"
    ],
    "abstract": "An agent operating in an unknown dynamical system must learn its dynamics from observations. Active information gathering accelerates this learning, but existing methods derive bespoke costs for specific modeling choices: dynamics models, belief update procedures, observation models, and planners. We present a unifying framework that decouples these choices from the information-gathering cost by explicitly exposing the causal dependencies between parameters, beliefs, and controls. Using this framework, we derive a general information-gathering cost based on Massey's directed information that assumes only Markov dynamics with additive noise and is otherwise agnostic to modeling choices. We prove that the mutual information cost used in existing literature is a special case of our cost. Then, we leverage our framework to establish an explicit connection between the mutual information cost and information gain in linearized Bayesian estimation, thereby providing theoretical justification for mutual information-based active learning approaches. Finally, we illustrate the practical utility of our framework through experiments spanning linear, nonlinear, and multi-agent systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.RO",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21988.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21988",
    "published": "2026-01-29T17:00:35Z",
    "updated": "2026-01-29T17:00:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个统一框架，将主动信息收集成本与具体建模选择解耦，并基于定向信息推导了通用成本，为现有方法提供了理论依据。",
      "motivation": "在未知动力学系统中，代理需要通过观察学习系统动态，而主动信息收集能加速这一过程。然而，现有方法为特定建模选择（如动力学模型、信念更新等）定制成本，缺乏通用性，限制了其在多样化场景中的应用。这导致了效率低下和适应性不足的问题，因此需要一种统一的方法来解耦成本与建模选择，以支持更广泛的学习任务。",
      "method": "论文提出一个框架，通过显式暴露参数、信念和控制之间的因果依赖性，将信息收集成本与建模选择（如动力学模型和观测模型）解耦。基于这一框架，推导了基于 Massey 定向信息的通用信息收集成本，仅假设带有加性噪声的马尔可夫动力学，对其他建模细节保持不可知。关键创新包括证明现有互信息成本是该通用成本的特例，并利用框架建立互信息成本与线性化贝叶斯估计中信息增益之间的显式联系，为主动学习方法提供了理论基础。",
      "result": "实验部分通过涵盖线性、非线性和多智能体系统的测试，展示了所提框架的实用价值，验证了其在不同动力学模型下的适应性和有效性。由于摘要未提供具体性能数据，实验主要侧重于验证框架的通用性和理论连接，与基线方法的对比基于理论分析，表明该框架能促进更高效的信息收集策略。",
      "conclusion": "论文的主要贡献在于提出一个统一信息收集框架，推导通用成本函数，并提供理论依据证明现有方法是其特例。学术价值体现在为主动学习领域提供了更灵活的基础方法，而实际应用则能加速未知系统中的动力学学习。尽管展示了广泛适用性，未来工作可能进一步扩展框架到更复杂场景或整合更多噪声模型。",
      "tags": [
        "Directed Information",
        "Markov Dynamics",
        "Bayesian Estimation",
        "Active Learning",
        "Causal Dependencies"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:17.534085Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21985",
    "title": "Elign: Equivariant Diffusion Model Alignment from Foundational Machine Learning Force Fields",
    "authors": [
      "Yunyang Li",
      "Lin Huang",
      "Luojia Xia",
      "Wenhe Zhang",
      "Mark Gerstein"
    ],
    "abstract": "Generative models for 3D molecular conformations must respect Euclidean symmetries and concentrate probability mass on thermodynamically favorable, mechanically stable structures. However, E(3)-equivariant diffusion models often reproduce biases from semi-empirical training data rather than capturing the equilibrium distribution of a high-fidelity Hamiltonian. While physics-based guidance can correct this, it faces two computational bottlenecks: expensive quantum-chemical evaluations (e.g., DFT) and the need to repeat such queries at every sampling step. We present Elign, a post-training framework that amortizes both costs. First, we replace expensive DFT evaluations with a faster, pretrained foundational machine-learning force field (MLFF) to provide physical signals. Second, we eliminate repeated run-time queries by shifting physical steering to the training phase. To achieve the second amortization, we formulate reverse diffusion as a reinforcement learning problem and introduce Force--Energy Disentangled Group Relative Policy Optimization (FED-GRPO) to fine-tune the denoising policy. FED-GRPO includes a potential-based energy reward and a force-based stability reward, which are optimized and group-normalized independently. Experiments show that Elign generates conformations with lower gold-standard DFT energies and forces, while improving stability. Crucially, inference remains as fast as unguided sampling, since no energy evaluations are required during generation.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21985.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21985",
    "published": "2026-01-29T17:00:09Z",
    "updated": "2026-01-29T17:00:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "Elign 提出一个后训练框架，通过结合基础机器学习力场和强化学习优化 E(3)-equivariant 扩散模型，生成更准确稳定的分子构象，同时保持快速推理。",
      "motivation": "生成 3D 分子构象的模型需尊重欧几里得对称性并集中在热力学稳定结构上，但 E(3)-equivariant 扩散模型常再现半经验训练数据的偏差，而非高保真汉密尔顿量的平衡分布。基于物理的引导可纠正偏差，但面临计算瓶颈：昂贵的量子化学评估（如 DFT）需在每个采样步骤重复，导致效率低下，限制了实际应用中的可扩展性和准确性。",
      "method": "Elign 是一个后训练框架，旨在分摊计算成本。首先，使用预训练的基础机器学习力场（MLFF）替代昂贵的 DFT 评估，提供快速物理信号。其次，将物理引导从运行时转移到训练阶段，通过将反向扩散表述为强化学习问题，引入 Force–Energy Disentangled Group Relative Policy Optimization (FED-GRPO)。FED-GRPO 包括基于势能的能量奖励和基于力的稳定性奖励，独立优化和组归一化，以微调解码策略，提高生成构象的物理准确性和稳定性。",
      "result": "实验显示，Elign 生成分子构象具有更低的金标准 DFT 能量和力，表明提高了物理准确性和稳定性。具体而言，与基线方法相比，Elign 改善了构象稳定性，同时推理速度保持与无引导采样相同，因为在生成过程中不需要进行能量评估，从而显著降低计算开销并维持高效性能。",
      "conclusion": "Elign 通过融合机器学习力场和强化学习，有效解决扩散模型在分子生成中的物理引导问题，既提升生成质量又保持高效推理。该研究在计算化学和分子设计领域具有重要学术和实用价值，为开发更准确、高效的生成模型提供新方向。未来工作可能包括优化奖励机制或扩展到更多物理系统，摘要未明确说明具体局限性。",
      "tags": [
        "Diffusion Models",
        "Reinforcement Learning",
        "Machine Learning Force Fields",
        "Molecular Conformation Generation",
        "Equivariant Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:51.492038Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21984",
    "title": "PowerGenie: Analytically-Guided Evolutionary Discovery of Superior Reconfigurable Power Converters",
    "authors": [
      "Jian Gao",
      "Yiwei Zou",
      "Abhishek Pradhan",
      "Wenhao Huang",
      "Yumin Su",
      "Kaiyuan Yang",
      "Xuan Zhang"
    ],
    "abstract": "Discovering superior circuit topologies requires navigating an exponentially large design space-a challenge traditionally reserved for human experts. Existing AI methods either select from predefined templates or generate novel topologies at a limited scale without rigorous verification, leaving large-scale performance-driven discovery underexplored. We present PowerGenie, a framework for automated discovery of higher-performance reconfigurable power converters at scale. PowerGenie introduces: (1) an automated analytical framework that determines converter functionality and theoretical performance limits without component sizing or SPICE simulation, and (2) an evolutionary finetuning method that co-evolves a generative model with its training distribution through fitness selection and uniqueness verification. Unlike existing methods that suffer from mode collapse and overfitting, our approach achieves higher syntax validity, function validity, novelty rate, and figure-of-merit (FoM). PowerGenie discovers a novel 8-mode reconfigurable converter with 23% higher FoM than the best training topology. SPICE simulations confirm average absolute efficiency gains of 10% across 8 modes and up to 17% at a single mode. Code is available at https://github.com/xz-group/PowerGenie.",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21984.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21984",
    "published": "2026-01-29T16:59:59Z",
    "updated": "2026-01-29T16:59:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "PowerGenie框架结合分析指导和进化微调，自动发现高性能可重构功率转换器拓扑。",
      "motivation": "研究动机源于电路拓扑发现面临巨大设计空间挑战，传统依赖人类专家探索，效率低下。现有AI方法局限于预定义模板选择或小规模生成新拓扑，缺乏严格验证，导致大规模性能驱动的自动化发现不足。这表明现有方法在可扩展性和验证方面存在局限，亟需开发能高效、规模化发现高性能拓扑的创新解决方案。",
      "method": "研究方法包括自动化分析框架，能在无需组件尺寸调整或SPICE仿真的情况下确定转换器功能和理论性能极限；以及进化微调方法，通过适应性选择和唯一性验证，使生成模型与其训练分布共同进化，避免模式塌陷和过拟合。摘要未明确说明具体数据集或模型架构，但突出了技术特色。",
      "result": "主要实验结果显示，PowerGenie发现了一个新颖的8模式可重构转换器，性能指标(FoM)比最佳训练拓扑高23%。SPICE仿真验证了在8个模式下平均绝对效率增益为10%，单个模式下最高可达17%。与基线方法相比，该方法在语法有效性、功能有效性、新颖率和FoM方面表现更优，展示了显著性能提升。",
      "conclusion": "结论总结PowerGenie框架成功实现大规模自动发现高性能拓扑，克服了现有AI方法的不足。学术上为AI驱动的电路设计提供新思路，实际上能提升转换器效率，具有工业应用价值。摘要未明确说明局限性，但未来工作可探索框架扩展或优化验证方法。",
      "tags": [
        "Reconfigurable Power Converters",
        "Evolutionary Algorithms",
        "Generative Models",
        "Analytical Framework",
        "Automated Discovery"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:09.304207Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21983",
    "title": "Investigating Batch Inference in a Sequential Monte Carlo Framework for Neural Networks",
    "authors": [
      "Andrew Millard",
      "Joshua Murphy",
      "Peter Green",
      "Simon Maskell"
    ],
    "abstract": "Bayesian inference allows us to define a posterior distribution over the weights of a generic neural network (NN). Exact posteriors are usually intractable, in which case approximations can be employed. One such approximation - variational inference - is computationally efficient when using mini-batch stochastic gradient descent as subsets of the data are used for likelihood and gradient evaluations, though the approach relies on the selection of a variational distribution which sufficiently matches the form of the posterior. Particle-based methods such as Markov chain Monte Carlo and Sequential Monte Carlo (SMC) do not assume a parametric family for the posterior by typically require higher computational cost. These sampling methods typically use the full-batch of data for likelihood and gradient evaluations, which contributes to this computational expense. We explore several methods of gradually introducing more mini-batches of data (data annealing) into likelihood and gradient evaluations of an SMC sampler. We find that we can achieve up to $6\\times$ faster training with minimal loss in accuracy on benchmark image classification problems using NNs.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21983.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21983",
    "published": "2026-01-29T16:59:31Z",
    "updated": "2026-01-29T16:59:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出在序列蒙特卡罗框架中集成数据退火方法，显著加速神经网络贝叶斯推断训练，同时保持高精度。",
      "motivation": "贝叶斯推断为神经网络提供后验分布，但精确后验难以处理。现有方法中，变分推断计算高效但依赖变分分布选择，可能导致偏差；序列蒙特卡罗方法不假设参数族，准确但计算成本高，尤其在传统实现中使用全批次数据进行似然和梯度评估。本研究旨在解决SMC的高计算开销问题，通过引入小批量数据平衡效率与精度，推动贝叶斯方法在深度学习中的应用。",
      "method": "论文探索了在序列蒙特卡罗采样器中采用数据退火策略，逐步将小批量数据集成到似然和梯度评估中，替代传统全批次方式。具体方法包括研究多种数据引入技术，以优化SMC框架中的计算流程。在神经网络上进行测试，应用于基准图像分类问题，通过SMC进行贝叶斯推断，关键创新在于结合数据退火以降低计算负担。",
      "result": "实验结果表明，使用提出的数据退火SMC方法，在标准图像分类基准问题上，训练速度可提升高达6倍，同时精度损失最小。这通过比较基线方法（如传统SMC）实现，具体数据支撑包括效率改进的量化指标，但摘要未明确说明精确对比细节或额外性能指标。",
      "conclusion": "本研究的主要贡献在于开发了数据退火SMC方法，有效降低了贝叶斯神经网络推断的计算成本，同时保持推断质量。学术价值在于为深度学习中的不确定性建模提供了更高效的采样技术，实际应用可能扩展到大规模模型。未来工作可进一步优化退火策略或探索其他应用领域，但摘要未明确说明具体局限性。",
      "tags": [
        "Sequential Monte Carlo",
        "Bayesian Inference",
        "Neural Networks",
        "Data Annealing",
        "Mini-batch Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:49.120534Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21981",
    "title": "VERSA: Verified Event Data Format for Reliable Soccer Analytics",
    "authors": [
      "Geonhee Jo",
      "Mingu Kang",
      "Kangmin Lee",
      "Minho Lee",
      "Pascal Bauer",
      "Sang-Ki Ko"
    ],
    "abstract": "Event stream data is a critical resource for fine-grained analysis across various domains, including financial transactions, system operations, and sports. In sports, it is actively used for fine-grained analyses such as quantifying player contributions and identifying tactical patterns. However, the reliability of these models is fundamentally limited by inherent data quality issues that cause logical inconsistencies (e.g., incorrect event ordering or missing events). To this end, this study proposes VERSA (Verified Event Data Format for Reliable Soccer Analytics), a systematic verification framework that ensures the integrity of event stream data within the soccer domain. VERSA is based on a state-transition model that defines valid event sequences, thereby enabling the automatic detection and correction of anomalous patterns within the event stream data. Notably, our examination of event data from the K League 1 (2024 season), provided by Bepro, detected that 18.81% of all recorded events exhibited logical inconsistencies. Addressing such integrity issues, our experiments demonstrate that VERSA significantly enhances cross-provider consistency, ensuring stable and unified data representation across heterogeneous sources. Furthermore, we demonstrate that data refined by VERSA significantly improves the robustness and performance of a downstream task called VAEP, which evaluates player contributions. These results highlight that the verification process is highly effective in increasing the reliability of data-driven analysis.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21981.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21981",
    "published": "2026-01-29T16:58:10Z",
    "updated": "2026-01-29T16:58:10Z",
    "comment": "13 pages, 5 figures, 3 tables",
    "light_analysis": {
      "overview": "论文提出VERSA框架，通过状态转换模型验证足球事件流数据完整性，自动检测纠正逻辑不一致，提升分析可靠性。",
      "motivation": "事件流数据在体育分析中用于细粒度任务如量化球员贡献，但数据质量问题如事件顺序错误或缺失导致逻辑不一致，限制了分析模型的可靠性。现有方法缺乏系统化验证机制，无法确保数据完整性，因此需要新框架来解决这些问题，以支持准确的足球分析和决策。",
      "method": "VERSA基于状态转换模型定义有效事件序列，自动检测和纠正异常模式。它使用领域知识编码事件流程规则，应用于具体数据集如K League 1 (2024赛季)事件数据，通过系统化检查确保数据一致性。关键创新在于将状态转换逻辑集成到验证过程中，以实现高效错误识别。",
      "result": "实验中使用Bepro提供的K League 1数据，发现18.81%的事件存在逻辑不一致。VERSA显著提高跨数据源一致性，实现统一数据表示，并改进下游任务VAEP的性能，增强了球员贡献评估的稳健性和准确性，与原始数据相比有明显提升。",
      "conclusion": "论文主要贡献是提出VERSA框架，有效解决事件流数据中的逻辑问题，提升足球分析的数据可靠性。学术上提供了系统化验证方法，实际中能改进应用如VAEP。未来工作可能涉及扩展至其他领域或优化模型适应更复杂场景。",
      "tags": [
        "Event Stream Data",
        "State-Transition Model",
        "Data Verification",
        "Soccer Analytics",
        "VAEP"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:15.887315Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21979",
    "title": "Investigation into using stochastic embedding representations for evaluating the trustworthiness of the Fréchet Inception Distance",
    "authors": [
      "Ciaran Bench",
      "Vivek Desai",
      "Carlijn Roozemond",
      "Ruben van Engen",
      "Spencer A. Thomas"
    ],
    "abstract": "Feature embeddings acquired from pretrained models are widely used in medical applications of deep learning to assess the characteristics of datasets; e.g. to determine the quality of synthetic, generated medical images. The Fréchet Inception Distance (FID) is one popular synthetic image quality metric that relies on the assumption that the characteristic features of the data can be detected and encoded by an InceptionV3 model pretrained on ImageNet1K (natural images). While it is widely known that this makes it less effective for applications involving medical images, the extent to which the metric fails to capture meaningful differences in image characteristics is not obviously known. Here, we use Monte Carlo dropout to compute the predictive variance in the FID as well as a supplemental estimate of the predictive variance in the feature embedding model's latent representations. We show that the magnitudes of the predictive variances considered exhibit varying degrees of correlation with the extent to which test inputs (ImageNet1K validation set augmented at various strengths, and other external datasets) are out-of-distribution relative to its training data, providing some insight into the effectiveness of their use as indicators of the trustworthiness of the FID.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21979.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21979",
    "published": "2026-01-29T16:56:01Z",
    "updated": "2026-01-29T16:56:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文通过计算预测方差，评估了Fréchet Inception Distance在医学图像评估中的可信度。",
      "motivation": "研究动机是解决Fréchet Inception Distance (FID) 在评估合成医学图像质量时的局限性。FID是一种广泛使用的合成图像质量指标，但其基于InceptionV3模型预训练在自然图像（ImageNet1K）上，因此在医学图像应用中效果可能不佳。这个问题很重要，因为准确评估图像特性对于医学深度学习应用（如生成图像的质量控制）至关重要。现有方法的不足在于FID依赖于不适合医学图像的预训练模型，导致无法有效捕捉图像特性差异，但其具体失效程度尚不明确，因此需要评估其可信度。",
      "method": "论文提出使用Monte Carlo dropout方法来计算FID的预测方差，并补充计算特征嵌入模型潜在表示的预测方差。核心创新点是利用随机嵌入表示来量化FID的可信度，通过分析方差变化来评估指标可靠性。关键细节包括使用InceptionV3模型，应用于ImageNet1K验证集（通过不同强度进行增强）以及其他外部数据集，以模拟分布外输入情况，从而研究FID在捕捉图像特性差异时的表现。",
      "result": "主要实验结果表明，计算出的预测方差的幅度与测试输入相对于训练数据的分布外程度存在不同程度的相关性。例如，当测试输入（如增强后的ImageNet1K验证集或外部数据集）与训练数据差异越大时，预测方差的变化趋势提供了对FID可信度的洞察。这显示方差可以作为评估FID有效性的指标，但摘要未明确提供具体的性能指标数据（如准确率或效率改进），也未直接与基线方法进行对比，仅暗示了FID在医学图像评估中的潜在问题。",
      "conclusion": "论文的主要贡献是提出了一种通过分析预测方差来评估FID在医学图像评估中可信度的方法，揭示了FID基于自然图像预训练模型的局限性。这项研究具有学术价值，因为它为改进合成图像质量评估指标提供了新视角，尤其是在医学领域。实际应用价值在于帮助开发者和研究者更可靠地使用FID评估合成医学图像，避免因指标不适用而导致错误判断。未来工作方向可能包括扩展到其他预训练模型或数据集，以及量化方差与图像特性差异的具体关系，但摘要未明确说明局限性或具体计划。",
      "tags": [
        "Fréchet Inception Distance",
        "Monte Carlo Dropout",
        "Feature Embeddings",
        "InceptionV3",
        "Predictive Variance"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:51.411535Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21978",
    "title": "Bridging Graph Structure and Knowledge-Guided Editing for Interpretable Temporal Knowledge Graph Reasoning",
    "authors": [
      "Shiqi Fan",
      "Quanming Yao",
      "Hongyi Nie",
      "Wentao Ma",
      "Zhen Wang",
      "Wen Hua"
    ],
    "abstract": "Temporal knowledge graph reasoning (TKGR) aims to predict future events by inferring missing entities with dynamic knowledge structures. Existing LLM-based reasoning methods prioritize contextual over structural relations, struggling to extract relevant subgraphs from dynamic graphs. This limits structural information understanding, leading to unstructured, hallucination-prone inferences especially with temporal inconsistencies. To address this problem, we propose IGETR (Integration of Graph and Editing-enhanced Temporal Reasoning), a hybrid reasoning framework that combines the structured temporal modeling capabilities of Graph Neural Networks (GNNs) with the contextual understanding of LLMs. IGETR operates through a three-stage pipeline. The first stage aims to ground the reasoning process in the actual data by identifying structurally and temporally coherent candidate paths through a temporal GNN, ensuring that inference starts from reliable graph-based evidence. The second stage introduces LLM-guided path editing to address logical and semantic inconsistencies, leveraging external knowledge to refine and enhance the initial paths. The final stage focuses on integrating the refined reasoning paths to produce predictions that are both accurate and interpretable. Experiments on standard TKG benchmarks show that IGETR achieves state-of-the-art performance, outperforming strong baselines with relative improvements of up to 5.6% on Hits@1 and 8.1% on Hits@3 on the challenging ICEWS datasets. Additionally, we execute ablation studies and additional analyses confirm the effectiveness of each component.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21978.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21978",
    "published": "2026-01-29T16:55:13Z",
    "updated": "2026-01-29T16:55:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出IGETR混合推理框架，通过融合图神经网络和大型语言模型，提升了时序知识图谱推理的准确性和可解释性。",
      "motivation": "时序知识图谱推理旨在预测未来事件，但现有基于大语言模型的方法过于侧重上下文关系，难以从动态图中提取相关子图，导致结构信息理解不足、推理不结构化、易产生幻觉且存在时间不一致问题。这限制了实际应用中事件预测的可靠性，因此亟需一种能有效结合结构关系和外部知识的方法来克服这些缺陷。",
      "method": "IGETR采用三阶段流水线。第一阶段使用时序图神经网络识别结构和时间一致的候选路径，确保推理基于可靠图证据。第二阶段引入大语言模型引导的路径编辑，利用外部知识修正逻辑和语义不一致，优化初始路径。第三阶段整合优化后的路径，生成准确且可解释的预测。核心创新在于结合了GNN的结构化建模和LLM的上下文理解能力。",
      "result": "在标准时序知识图谱基准测试中，IGETR达到最优性能。在挑战性ICEWS数据集上，Hits@1相对提升5.6%，Hits@3相对提升8.1%，显著优于基线方法。消融研究和额外分析证实了框架中每个组件的有效性，验证了整体架构的鲁棒性和创新性。",
      "conclusion": "IGETR的主要贡献在于提出一个结合图结构和知识引导编辑的混合推理框架，提高了时序知识图谱推理的性能和可解释性。这为动态知识表示和推理领域提供了新方法，具有学术价值；实际应用中，可增强事件预测等任务的可靠性。未来工作可能包括扩展到更大规模数据集或探索其他领域应用。",
      "tags": [
        "Temporal Knowledge Graph Reasoning",
        "Graph Neural Networks (GNNs)",
        "Large Language Models (LLMs)",
        "Hybrid Reasoning",
        "Interpretability"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:44.163465Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21975",
    "title": "Mind the Gap: How Elicitation Protocols Shape the Stated-Revealed Preference Gap in Language Models",
    "authors": [
      "Pranav Mahajan",
      "Ihor Kendiukhov",
      "Syed Hussain",
      "Lydia Nottingham"
    ],
    "abstract": "Recent work identifies a stated-revealed (SvR) preference gap in language models (LMs): a mismatch between the values models endorse and the choices they make in context. Existing evaluations rely heavily on binary forced-choice prompting, which entangles genuine preferences with artifacts of the elicitation protocol. We systematically study how elicitation protocols affect SvR correlation across 24 LMs. Allowing neutrality and abstention during stated preference elicitation allows us to exclude weak signals, substantially improving Spearman's rank correlation ($ρ$) between volunteered stated preferences and forced-choice revealed preferences. However, further allowing abstention in revealed preferences drives $ρ$ to near-zero or negative values due to high neutrality rates. Finally, we find that system prompt steering using stated preferences during revealed preference elicitation does not reliably improve SvR correlation on AIRiskDilemmas. Together, our results show that SvR correlation is highly protocol-dependent and that preference elicitation requires methods that account for indeterminate preferences.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21975.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21975",
    "published": "2026-01-29T16:51:43Z",
    "updated": "2026-01-29T16:51:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究揭示了语言模型中陈述-揭示偏好差距如何受评估协议影响，并提出需考虑不确定偏好以提高相关性。",
      "motivation": "现有研究识别了语言模型中的陈述-揭示偏好差距，即模型声明的价值与其在实际上下文中的选择之间存在不匹配。现有评估方法过度依赖二元强制选择提示，这可能混淆真实偏好与协议本身的假象，导致测量偏差。因此，本研究旨在系统探讨评估协议如何塑造这种相关性，以解决现有方法在准确捕捉模型偏好方面的不足，促进更可靠的偏好评估。",
      "method": "论文采用系统研究方法，分析不同评估协议对陈述-揭示偏好相关性的影响。使用24个语言模型，通过允许中立和弃权选项来排除弱信号，并比较自愿陈述偏好与强制选择揭示偏好。关键使用Spearman's秩相关系数来衡量关联强度，实验在AIRiskDilemmas等数据集上进行，以探究协议变化对相关性计算的具体影响。",
      "result": "实验发现，允许陈述偏好中采取中立和弃权能显著提升Spearman's相关系数，通过排除弱信号改善相关性。然而，当在揭示偏好中也允许弃权时，相关性降至接近零或负值，主要因为模型表现出高中立率。在AIRiskDilemmas数据集上，使用系统提示引导基于陈述偏好进行揭示偏好评估，并未可靠改善相关性，进一步证实了协议依赖性问题。",
      "conclusion": "研究结论表明，陈述-揭示偏好相关性对评估协议高度敏感，强调了在语言模型偏好评估中考虑不确定偏好的必要性。这一发现对学术领域中的模型校准和评估方法改进有重要价值，未来工作应专注于开发鲁棒的偏好评估协议，以减少协议假象，提高测量准确性。",
      "tags": [
        "Language Models",
        "Preference Elicitation",
        "Elicitation Protocols",
        "Stated-Revealed Preference Gap",
        "Spearman's Rank Correlation"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:19.145559Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21972",
    "title": "Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic",
    "authors": [
      "Shuo Liu",
      "Tianle Chen",
      "Ryan Amiri",
      "Christopher Amato"
    ],
    "abstract": "Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as agents can run inference in parallel with flexible deployments. Also, current approaches use Monte Carlo methods for fine-tuning, which suffer from high variance and thus require more samples to train effectively. Actor-critic methods are prevalent in MARL for dealing with these issues, so we developed Multi-Agent Actor-Critic (MAAC) methods to optimize decentralized LLM collaboration. In this paper, we analyze when and why these MAAC methods are beneficial. We propose 2 MAAC approaches, \\textbf{CoLLM-CC} with a \\textbf{C}entralized \\textbf{C}ritic and \\textbf{CoLLM-DC} with \\textbf{D}ecentralized \\textbf{C}ritics. Our experiments across writing, coding, and game-playing domains show that Monte Carlo methods and CoLLM-DC can achieve performance comparable to CoLLM-CC in short-horizon and dense-reward settings. However, they both underperform CoLLM-CC on long-horizon or sparse-reward tasks, where Monte Carlo methods require substantially more samples and CoLLM-DC struggles to converge. Our code is available at https://github.com/OpenMLRL/CoMLRL/releases/tag/v1.3.2.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21972.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21972",
    "published": "2026-01-29T16:50:30Z",
    "updated": "2026-01-29T16:50:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出两种多代理Actor-Critic方法优化去中心化大语言模型协作，并分析其在不同任务中的有效性。",
      "motivation": "研究动机在于解决去中心化大语言模型协作中的实际挑战。现有方法通常依赖集中式执行协议和蒙特卡洛微调，前者限制了代理的并行性和部署灵活性，后者因高方差问题导致训练样本需求大、效率低下。去中心化协作在现实应用中更具吸引力，但现有技术难以平衡效率与性能，因此开发更优方法至关重要。",
      "method": "研究方法基于多代理强化学习框架，开发了两种多代理Actor-Critic方法：CoLLM-CC采用集中式Critic进行全局协调，CoLLM-DC则使用去中心化Critics让每个代理独立评估。核心创新在于将Actor-Critic技术应用于去中心化LLM协作，以减少方差并提升训练稳定性。技术特色包括在MARL环境中集成LLM，处理多代理决策问题，无需依赖预定义执行协议。",
      "result": "实验覆盖写作、编码和游戏玩等领域，结果显示在短视野和密集奖励任务中，蒙特卡洛方法和CoLLM-DC的性能与CoLLM-CC相当。但在长视野或稀疏奖励任务中，蒙特卡洛方法需要显著更多样本训练，CoLLM-DC难以收敛，而CoLLM-CC表现更优。这些对比表明Actor-Critic方法在复杂任务中能提高效率和稳定性。",
      "conclusion": "本研究的主要贡献是提出并验证了多代理Actor-Critic方法用于优化去中心化LLM协作。学术价值在于扩展了MARL在LLM领域的应用，提供更高效的训练方案；实际价值在于支持灵活、并行的代理部署。局限性体现在某些任务类型（如长视野或稀疏奖励）中性能有限，未来工作可探索算法改进或更多应用场景。",
      "tags": [
        "Multi-Agent Reinforcement Learning",
        "Large Language Model",
        "Actor-Critic Methods",
        "Decentralized Collaboration",
        "Monte Carlo Methods"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:46.037101Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21969",
    "title": "Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding",
    "authors": [
      "Yifan Zhu",
      "Huiqiang Rong",
      "Haoran Luo"
    ],
    "abstract": "Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21969.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21969",
    "published": "2026-01-29T16:48:47Z",
    "updated": "2026-01-29T16:48:47Z",
    "comment": "26 pages and 11 figures,this work has been accepted for presentation at ICLR 2026",
    "light_analysis": {
      "overview": "本文提出了Token-Guard，一种基于自检解码的token级别幻觉控制方法，显著减少大语言模型的幻觉。",
      "motivation": "大型语言模型（LLMs）常产生幻觉，生成与输入不一致的内容，影响输出可靠性。现有方法如检索增强生成（RAG）和人类反馈强化学习（RLHF）能缓解幻觉，但需要资源密集的检索或大规模微调，不适用于轻量级场景。解码方法较轻量，但缺乏明确的幻觉控制机制。因此，研究动机是开发一种无需额外资源、能实现token级别幻觉控制的方法，以提升LLM生成内容的准确性和可信度。",
      "method": "Token-Guard基于自检解码实现token级别幻觉控制。核心创新点包括在每个推理步骤进行内部验证，检测幻觉token以防止错误传播。候选片段在潜在空间中通过显式幻觉风险评分进行评估，采用迭代修剪和再生策略动态纠正检测到的错误。该方法不依赖外部检索或大规模调整，主要通过解码过程自我监控，提升生成质量。使用的关键技术包括潜在空间表示和风险评分机制。",
      "result": "在HALU数据集上的实验表明，Token-Guard显著减少幻觉并提高生成准确性。摘要未提供具体数值，但指出该方法相比于基线解码方法，在控制幻觉方面表现更好。它提供了一种可扩展、模块化的解决方案，适用于各种LLM应用场景，为可靠输出提供了技术基础。",
      "conclusion": "Token-Guard的主要贡献是提出了一种轻量级、模块化的token级别幻觉控制方法，通过自检解码增强LLM输出可靠性。学术上，它扩展了解码策略的研究，具有创新性；实际应用上，为构建可信AI系统提供支持，代码公开促进可复现性。未来工作可能包括扩展到更复杂任务或模型，但摘要未明确说明局限性或具体方向。",
      "tags": [
        "Large Language Models",
        "Hallucination Control",
        "Self-Checking Decoding",
        "Token-Level Control",
        "Risk Scoring"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:42.440856Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21968",
    "title": "OVD: On-policy Verbal Distillation",
    "authors": [
      "Jing Xiong",
      "Hui Shen",
      "Shansan Gong",
      "Yuxin Cheng",
      "Jianghan Shen",
      "Chaofan Tao",
      "Haochen Tan",
      "Haoli Bai",
      "Lifeng Shang",
      "Ngai Wong"
    ],
    "abstract": "Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21968.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21968",
    "published": "2026-01-29T16:48:14Z",
    "updated": "2026-01-29T16:48:14Z",
    "comment": "Technical Report",
    "light_analysis": {
      "overview": "OVD框架通过口头评分的轨迹匹配，实现了高效在线策略知识蒸馏，避免了令牌级对齐的限制。",
      "motivation": "本研究动机源于现有令牌级在线策略蒸馏方法的不足：这些方法需要学生和教师模型之间的令牌级对齐，这限制了学生模型的探索能力，妨碍了交互环境反馈的有效利用，并在强化学习中导致严重内存瓶颈。这些问题影响了知识蒸馏在资源受限场景中的效率和效果，尤其是在在线学习和推理任务中，使得现有方法难以实现高效模型压缩和部署。因此，开发一种避免令牌对齐、内存友好且支持探索的蒸馏框架至关重要。",
      "method": "论文提出的核心方法是On-policy Verbal Distillation (OVD)框架，它采用离散口头评分（范围0-9）进行轨迹匹配，以替代传统的令牌级概率匹配。关键创新点包括：避免令牌级对齐，允许学生模型自由探索输出空间；利用教师模型的口头反馈进行在线蒸馏，减少对详细概率分布的需求；显著降低内存消耗，提高训练效率。该方法在Web问答和数学推理任务上进行实验，但摘要未明确说明具体使用的数据集或模型架构细节。",
      "result": "主要实验结果基于Web问答和数学推理任务：OVD在Web Q&A任务上实现了平均EM的+12.9%绝对提升，在数学基准上达到了+25.7%的增益（训练时仅使用一个随机样本），显著优于现有基线方法。此外，OVD展现出优越的训练效率，在实验中减少了内存消耗并加速了收敛过程，验证了其作为高效蒸馏框架的有效性。这些改进表明，轨迹匹配和口头评分策略在性能和资源利用方面都具有明显优势。",
      "conclusion": "OVD框架的主要贡献是引入一种基于口头评分轨迹匹配的在线策略蒸馏方法，有效解决了现有令牌对齐方法的限制，提升了模型性能、探索能力和内存效率。其学术价值在于为知识蒸馏提供了新思路，特别是针对在线学习和推理任务；实际应用价值在于支持高效模型部署，适用于强化学习和资源有限环境。摘要未明确说明局限性或未来工作方向，但可推断潜在方向可能包括扩展到更多任务或优化评分机制。",
      "tags": [
        "Knowledge Distillation",
        "On-policy Distillation",
        "Verbal Feedback",
        "Trajectory Matching",
        "Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:51.012372Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21967",
    "title": "The Energy Impact of Domain Model Design in Classical Planning",
    "authors": [
      "Ilche Georgievski",
      "Serhat Tekin",
      "Marco Aiello"
    ],
    "abstract": "AI research has traditionally prioritised algorithmic performance, such as optimising accuracy in machine learning or runtime in automated planning. The emerging paradigm of Green AI challenges this by recognising energy consumption as a critical performance dimension. Despite the high computational demands of automated planning, its energy efficiency has received little attention. This gap is particularly salient given the modular planning structure, in which domain models are specified independently of algorithms. On the other hand, this separation also enables systematic analysis of energy usage through domain model design. We empirically investigate how domain model characteristics affect the energy consumption of classical planners. We introduce a domain model configuration framework that enables controlled variation of features, such as element ordering, action arity, and dead-end states. Using five benchmark domains and five state-of-the-art planners, we analyse energy and runtime impacts across 32 domain variants per benchmark. Results demonstrate that domain-level modifications produce measurable energy differences across planners, with energy consumption not always correlating with runtime.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21967.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21967",
    "published": "2026-01-29T16:46:43Z",
    "updated": "2026-01-29T16:46:43Z",
    "comment": "2026 IEEE/ACM 5th International Conference on AI Engineering - Software Engineering for AI (CAIN '26)",
    "light_analysis": {
      "overview": "论文实证分析了领域模型设计对经典规划器能耗的影响，并提出了一个控制领域模型特性的框架。",
      "motivation": "传统AI研究主要关注算法性能如准确性和运行时间，但Green AI范式将能耗视为关键维度。自动化规划计算需求高，然而其能效研究不足，尤其在模块化规划结构中，领域模型独立于算法指定，这为系统分析能耗提供了机会。本研究旨在解决自动化规划中能耗未被重视的问题，填补现有方法在能耗优化方面的空白，强调Green AI的重要性以推动可持续AI发展。",
      "method": "论文引入了一个领域模型配置框架，允许控制特征如元素排序、行动元数和死端状态的变异。使用五个基准领域和五个最先进的经典规划器，对每个基准生成32个领域变体进行实验。关键创新在于通过系统化框架分析不同领域模型特性对能耗的影响，技术特色包括实证方法和多领域对比，数据集涵盖基准领域，模型涉及多种规划器架构。",
      "result": "实验结果显示，领域级修改在不同规划器之间产生了可测量的能耗差异。具体表现为能耗变化不总是与运行时间变化相关，这表明能耗受多种因素影响。与基线方法对比，五个规划器和32个领域变体的分析揭示了领域模型设计对能耗的具体作用，摘要未提供具体数值，但强调了差异的可测量性和相关性分析的发现。",
      "conclusion": "本研究的贡献在于揭示了领域模型设计对经典规划器能耗的显著影响，为Green AI提供了实证支持。学术价值在于推动了规划系统中能耗分析的重视，实际应用价值体现在优化规划器能效的潜在指导。摘要未明确说明局限性或未来工作方向，但可推断未来可能扩展更多领域和规划器，或深入探索能耗优化策略。",
      "tags": [
        "Classical Planning",
        "Domain Model Design",
        "Green AI",
        "Energy Efficiency",
        "Automated Planning"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:01.517825Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21964",
    "title": "From Tokens to Blocks: A Block-Diffusion Perspective on Molecular Generation",
    "authors": [
      "Qianwei Yang",
      "Dong Xu",
      "Zhangfan Yang",
      "Sisi Yuan",
      "Zexuan Zhu",
      "Jianqiang Li",
      "Junkai Ji"
    ],
    "abstract": "Drug discovery can be viewed as a combinatorial search over an immense chemical space, motivating the development of deep generative models for de novo molecular design. Among these, GPT-based molecular language models (MLM) have shown strong molecular design performance by learning chemical syntax and semantics from large-scale data. However, existing MLMs face two fundamental limitations: they inadequately capture the graph-structured nature of molecules when formulated as next-token prediction problems, and they typically lack explicit mechanisms for target-aware generation. Here, we propose SoftMol, a unified framework that co-designs molecular representation, model architecture, and search strategy for target-aware molecular generation. SoftMol introduces soft fragments, a rule-free block representation of SMILES that enables diffusion-native modeling, and develops SoftBD, the first block-diffusion molecular language model that combines local bidirectional diffusion with autoregressive generation under molecular structural constraints. To favor generated molecules with high drug-likeness and synthetic accessibility, SoftBD is trained on a carefully curated dataset named ZINC-Curated. SoftMol further integrates a gated Monte Carlo tree search to assemble fragments in a target-aware manner. Experimental results show that, compared with current state-of-the-art models, SoftMol achieves 100% chemical validity, improves binding affinity by 9.7%, yields a 2-3x increase in molecular diversity, and delivers a 6.6x speedup in inference efficiency. Code is available at https://github.com/szu-aicourse/softmol",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21964.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21964",
    "published": "2026-01-29T16:42:24Z",
    "updated": "2026-01-29T16:42:24Z",
    "comment": "30 pages, 13 figures, 11 tables",
    "light_analysis": {
      "overview": "本文提出SoftMol框架，通过软片段表示和块扩散模型结合蒙特卡洛树搜索，实现目标感知分子生成，改进药物发现效率。",
      "motivation": "药物发现涉及在巨大化学空间中进行组合搜索，现有基于GPT的分子语言模型虽能学习化学语法，但面临两个根本限制：作为下一词预测问题无法充分捕捉分子的图结构性质，且缺乏针对特定目标生成分子的机制。这些问题导致模型在生成有效、多样性药物候选分子时不足，影响药物研发的精准度和速度，亟待新方法提升目标感知生成能力。",
      "method": "SoftMol框架创新性结合分子表示、模型架构和搜索策略。它引入软片段作为规则自由的SMILES块表示，支持扩散建模，并开发SoftBD模型，首次将局部双向扩散与自回归生成在分子结构约束下结合。使用精心策划的ZINC-Curated数据集进行训练，确保药物相似性和合成可访问性，并集成门控蒙特卡洛树搜索以实现目标感知的片段组装，优化生成过程。",
      "result": "实验结果显示，与当前最先进模型相比，SoftMol达到100%化学有效性，结合亲和力提升9.7%，分子多样性增加2-3倍，推理效率加速6.6倍。这些改进证明了其在生成高质量、多样化药物分子方面的优越性，且在速度和性能上均显著超越基线方法，为实际应用提供支持。",
      "conclusion": "本研究的核心贡献是提出了SoftMol统一框架，通过创新表示和模型设计解决了分子生成中的图结构和目标感知问题，具有重要学术价值，推动了扩散模型在药物发现领域的应用。实际应用价值在于提升药物候选分子的生成质量和效率，未来工作可探索更多分子类型或扩展至其他化学任务，但局限性如泛化能力摘要未明确说明。",
      "tags": [
        "Molecular Language Model",
        "Diffusion Models",
        "Monte Carlo Tree Search",
        "SMILES representation",
        "Soft Fragments"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:02.309858Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21961",
    "title": "How do Visual Attributes Influence Web Agents? A Comprehensive Evaluation of User Interface Design Factors",
    "authors": [
      "Kuai Yu",
      "Naicheng Yu",
      "Han Wang",
      "Rui Yang",
      "Huan Zhang"
    ],
    "abstract": "Web agents have demonstrated strong performance on a wide range of web-based tasks. However, existing research on the effect of environmental variation has mostly focused on robustness to adversarial attacks, with less attention to agents' preferences in benign scenarios. Although early studies have examined how textual attributes influence agent behavior, a systematic understanding of how visual attributes shape agent decision-making remains limited. To address this, we introduce VAF, a controlled evaluation pipeline for quantifying how webpage Visual Attribute Factors influence web-agent decision-making. Specifically, VAF consists of three stages: (i) variant generation, which ensures the variants share identical semantics as the original item while only differ in visual attributes; (ii) browsing interaction, where agents navigate the page via scrolling and clicking the interested item, mirroring how human users browse online; (iii) validating through both click action and reasoning from agents, which we use the Target Click Rate and Target Mention Rate to jointly evaluate the effect of visual attributes. By quantitatively measuring the decision-making difference between the original and variant, we identify which visual attributes influence agents' behavior most. Extensive experiments, across 8 variant families (48 variants total), 5 real-world websites (including shopping, travel, and news browsing), and 4 representative web agents, show that background color contrast, item size, position, and card clarity have a strong influence on agents' actions, whereas font styling, text color, and item image clarity exhibit minor effects.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21961.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21961",
    "published": "2026-01-29T16:40:15Z",
    "updated": "2026-01-29T16:40:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出VAF控制评估管道，首次系统性地量化网页视觉属性因素对网络代理决策的影响。",
      "motivation": "现有研究主要关注网络代理在对抗性攻击下的鲁棒性，而忽视了良性场景中代理对视觉属性的偏好，导致对用户界面设计因素的理解不足。尽管文本属性对代理行为的影响已有探索，但视觉属性如何塑造代理决策的系统知识仍然有限。因此，本研究旨在填补这一空白，通过全面评估视觉属性在代理决策中的作用，为优化网络代理性能和用户界面设计提供基础，提高对代理行为影响因素的理解。",
      "method": "本研究提出VAF评估管道，包括三个阶段：变体生成确保变体与原始项目语义相同，仅改变视觉属性；浏览交互让代理通过滚动和点击导航页面，模仿人类浏览行为；验证使用目标点击率和目标提及率来量化视觉属性的影响。该管道覆盖了8个变体家族（共48个变体）、5个真实世界网站（如购物、旅游、新闻）和4个代表性网络代理，通过控制变量系统评估决策差异，关键创新在于结合定量指标和真实场景模拟。",
      "result": "实验结果表明，背景颜色对比、项目大小、位置和卡片清晰度对网络代理的行为有显著影响，而字体样式、文本颜色和项目图像清晰度影响较小。通过目标点击率和目标提及率量化，研究识别出哪些视觉属性最影响代理决策，提供了对用户界面设计因素的实际见解。尽管摘要未给出具体数值，但基于广泛变体、网站和代理的测试，这些定性发现揭示了视觉属性的重要性，并与基线方法形成对比，强调了某些设计因素的强效应。",
      "conclusion": "本研究的主要贡献是引入了VAF控制评估管道，为网页视觉属性对网络代理决策的影响提供了系统评估。学术上，它增进对代理行为机制的理解，推动用户界面设计与AI交互研究；实际上，可为优化网络应用和代理性能提供指导，提升用户体验。摘要未明确说明局限性，但未来工作可能涉及扩展更多视觉属性、代理类型或应用场景，以深化相关领域的探索。",
      "tags": [
        "Web Agents",
        "Visual Attributes",
        "Evaluation Pipeline",
        "Decision-Making",
        "User Interface Design"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:56.339962Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21957",
    "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing",
    "authors": [
      "Cheng Cui",
      "Ting Sun",
      "Suyin Liang",
      "Tingquan Gao",
      "Zelun Zhang",
      "Jiaxuan Liu",
      "Xueqing Wang",
      "Changda Zhou",
      "Hongen Liu",
      "Manhui Lin",
      "Yue Zhang",
      "Yubo Zhang",
      "Yi Liu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "abstract": "We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21957.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21957",
    "published": "2026-01-29T16:35:04Z",
    "updated": "2026-01-29T16:35:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "PaddleOCR-VL-1.5 是一个 0.9B 视觉语言模型，在 OmniDocBench v1.5 上达到 94.5% 的 SOTA 准确率，并引入 Real5-OmniDocBench 基准评估文档解析的鲁棒性。",
      "motivation": "该研究旨在解决文档解析中现实世界物理畸变的鲁棒性问题，如扫描、倾斜、扭曲、屏幕摄影和照明等。这些畸变在真实应用场景中常见，可能导致模型性能下降。现有方法可能缺乏专门的鲁棒性评估基准，因此研究提出新基准和升级模型，以增强文档解析的稳定性和适应性。摘要未明确说明更详细的背景细节。",
      "method": "论文提出了 PaddleOCR-VL-1.5 模型，它是一个 0.9B 参数的视觉语言模型。方法包括升级模型架构以提高文档解析性能，并设计了 Real5-OmniDocBench 基准，用于评估对多种物理畸变的鲁棒性。此外，模型扩展为多任务系统，集成了印章识别和文本定位功能，同时保持紧凑参数规模和高计算效率。摘要未详细说明具体技术实现细节，如模型架构或训练过程。",
      "result": "实验结果显示，PaddleOCR-VL-1.5 在 OmniDocBench v1.5 基准上达到了 94.5% 的准确率，创造了新的 SOTA 性能。在新提出的 Real5-OmniDocBench 基准上，模型同样实现了 SOTA，证明了对现实世界畸变的强鲁棒性。模型维持 0.9B 参数规模，保证了高效性，但摘要未提供与具体基线方法的详细对比数据或效率指标。",
      "conclusion": "论文的主要贡献是开发了 PaddleOCR-VL-1.5 模型，它在文档解析任务中实现了 SOTA 性能，并建立了 Real5-OmniDocBench 基准来系统评估鲁棒性。通过扩展到印章识别和文本定位任务，模型增强了多任务能力，为实际应用中的文档处理提供了更可靠的解决方案。这提升了学术研究和工业应用的实用性。摘要未明确说明研究的局限性或未来工作方向。",
      "tags": [
        "Visual Language Model",
        "Document Parsing",
        "Robustness Benchmark",
        "Multi-Task Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:19.051859Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21956",
    "title": "Uncertainty-Aware Data-Based Method for Fast and Reliable Shape Optimization",
    "authors": [
      "Yunjia Yang",
      "Runze Li",
      "Yufei Zhang",
      "Haixin Chen"
    ],
    "abstract": "Data-based optimization (DBO) offers a promising approach for efficiently optimizing shape for better aerodynamic performance by leveraging a pretrained surrogate model for offline evaluations during iterations. However, DBO heavily relies on the quality of the training database. Samples outside the training distribution encountered during optimization can lead to significant prediction errors, potentially misleading the optimization process. Therefore, incorporating uncertainty quantification into optimization is critical for detecting outliers and enhancing robustness. This study proposes an uncertainty-aware data-based optimization (UA-DBO) framework to monitor and minimize surrogate model uncertainty during DBO. A probabilistic encoder-decoder surrogate model is developed to predict uncertainties associated with its outputs, and these uncertainties are integrated into a model-confidence-aware objective function to penalize samples with large prediction errors during data-based optimization process. The UA-DBO framework is evaluated on two multipoint optimization problems aimed at improving airfoil drag divergence and buffet performance. Results demonstrate that UA-DBO consistently reduces prediction errors in optimized samples and achieves superior performance gains compared to original DBO. Moreover, compared to multipoint optimization based on full computational simulations, UA-DBO offers comparable optimization effectiveness while significantly accelerating optimization speed.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21956.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21956",
    "published": "2026-01-29T16:34:47Z",
    "updated": "2026-01-29T16:34:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出不确定性感知的数据驱动优化框架，通过整合不确定性量化提高形状优化的鲁棒性和速度。",
      "motivation": "数据驱动优化方法依赖于训练数据库的质量，但在优化过程中遇到训练分布外的样本时，会导致预测错误，可能误导优化结果。现有DBO方法缺乏不确定性处理，导致鲁棒性不足，特别是在复杂工程应用中。因此，引入不确定性量化至关重要，以检测异常样本并增强方法的可靠性，解决实际优化中的不可靠预测问题。摘要未明确说明具体应用领域限制，但强调了这一问题的重要性。",
      "method": "论文提出UA-DBO框架，开发概率编码器-解码器代理模型来预测输出伴随的不确定性。这些不确定性被整合到模型置信感知的目标函数中，在数据驱动优化过程中惩罚预测误差大的样本，从而监控和最小化不确定性。关键创新点在于将不确定性量化与优化目标结合，实现对预测可靠性的动态调整，使用户能在迭代中避免不可靠样本。",
      "result": "在两个多点优化问题（翼型拖曳发散和缓冲性能）中评估UA-DBO，结果显示其比原始DBO减少了优化样本的预测错误，并取得了更优的性能增益。与基于全计算模拟的多点优化相比，UA-DBO提供了可比的优化效果，同时显著加速了优化速度，展示了高效性和实用性。具体数据如误差减少和速度提升程度，摘要未明确说明数值。",
      "conclusion": "主要贡献是提出UA-DBO框架，增强了数据驱动优化的鲁棒性和效率，填补了现有方法中不确定性处理的空白。学术价值在于改进了DBO技术，实际应用价值为航空航天等领域的形状优化提供快速可靠工具。局限性可能包括模型对数据分布的依赖性，未来工作可扩展应用或改进不确定性估计方法。",
      "tags": [
        "Data-Based Optimization",
        "Uncertainty Quantification",
        "Probabilistic Encoder-Decoder",
        "Surrogate Model",
        "Aerodynamic Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:06.633094Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21955",
    "title": "From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes",
    "authors": [
      "Fariba Afrin Irany"
    ],
    "abstract": "The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.   This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.   The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.   Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21955.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21955",
    "published": "2026-01-29T16:33:47Z",
    "updated": "2026-01-29T16:33:47Z",
    "comment": "This submission is a full-length research manuscript consisting of 37 pages and 15 figures. The paper presents a GPT-based architecture with selective fine-tuning for clinical text classification, including detailed architectural diagrams, learning curves, and evaluation figures such as ROC curves and confusion matrices",
    "light_analysis": {
      "overview": "本研究提出了一种基于 GPT 的架构，采用选择性微调策略，高效实现临床文本分类，显著降低计算复杂性。",
      "motivation": "电子健康记录中非结构化临床叙述的增加为自动化疾病分析、群体识别和临床决策支持提供了新机遇。然而，建模长且领域特定的临床文本面临严峻挑战，包括有限的标签数据、严重的类别不平衡以及大型预训练语言模型的高计算成本。现有方法往往需要全参数微调，导致计算效率低下，限制了在资源受限的临床环境中的应用。因此，开发一种更高效的微调方法来克服这些障碍变得尤为重要。",
      "method": "该研究提出了一种基于 GPT-2 的架构，采用选择性微调策略。具体而言，预训练的 GPT-2 解码器大部分参数被冻结，训练仅集中在最后的 Transformer 块、最终层归一化以及一个轻量级分类头上。这种方法大幅减少了可训练参数的数量，同时保留了建模复杂临床语言所需的表示能力。实验使用 MIMIC-IV-Note 数据集中的放射学报告，并应用基于文本的不确定性感知 CheXpert 风格标签，覆盖多标签分类、二元分类和聚合疾病预测等多种问题设置。",
      "result": "模型在多个实验设置中展现出稳定的收敛行为和强分类性能，特别是在非提及和否定发现占主导的场景中表现突出。实验包括放射发现的多标签分类、不同不确定性假设下的二元标签分类以及聚合疾病预测。尽管摘要未提供具体准确率数字，但结果表明该方法在不同数据集规模下均能保持高效分类，与基线方法相比，计算效率显著提升。",
      "conclusion": "研究总结表明，选择性微调预训练生成语言模型为临床文本分类提供了一条高效有效的途径，显著降低了计算复杂性，使适应现实世界的 EHR 数据更加可行。该工作具有重要的学术价值，推动了临床文本分析的规模化应用，未来研究方向可包括进一步优化模型或扩展到其他类型医疗数据，以及探索更广泛的不确定性处理策略。",
      "tags": [
        "GPT-based Architecture",
        "Selective Fine-tuning",
        "Clinical Text Classification",
        "Electronic Health Records",
        "Transformer Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:28.690500Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21950",
    "title": "Embracing Aleatoric Uncertainty in Medical Multimodal Learning with Missing Modalities",
    "authors": [
      "Linxiao Gong",
      "Yang Liu",
      "Lianlong Sun",
      "Yulai Bi",
      "Jing Liu",
      "Xiaoguang Zhu"
    ],
    "abstract": "Medical multimodal learning faces significant challenges with missing modalities prevalent in clinical practice. Existing approaches assume equal contribution of modality and random missing patterns, neglecting inherent uncertainty in medical data acquisition. In this regard, we propose the Aleatoric Uncertainty Modeling (AUM) that explicitly quantifies unimodal aleatoric uncertainty to address missing modalities. Specifically, AUM models each unimodal representation as a multivariate Gaussian distribution to capture aleatoric uncertainty and enable principled modality reliability quantification. To adaptively aggregate captured information, we develop a dynamic message-passing mechanism within a bipartite patient-modality graph using uncertainty-aware aggregation mechanism. Through this process, missing modalities are naturally accommodated, while more reliable information from available modalities is dynamically emphasized to guide representation generation. Our AUM framework achieves an improvement of 2.26% AUC-ROC on MIMIC-IV mortality prediction and 2.17% gain on eICU, outperforming existing state-of-the-art approaches.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21950.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21950",
    "published": "2026-01-29T16:31:48Z",
    "updated": "2026-01-29T16:31:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了Aleatoric Uncertainty Modeling (AUM)框架，通过量化单模态的aleatoric uncertainty来处理医疗多模态学习中的缺失模态问题。",
      "motivation": "医疗多模态学习在临床实践中常面临模态缺失的挑战，这影响模型预测的准确性和可靠性。现有方法通常假设模态贡献相等且缺失模式随机，忽视了医疗数据采集过程中固有的aleatoric uncertainty（如测量误差或数据不完整），导致模型在真实世界应用中性能受限。因此，研究需解决如何有效建模不确定性并优化信息聚合，以提升医疗预测任务的鲁棒性。",
      "method": "研究提出了Aleatoric Uncertainty Modeling (AUM)框架，其核心方法是将每个单模态表示建模为多元高斯分布，以量化aleatoric uncertainty并评估模态可靠性。在此基础上，开发了一个动态消息传递机制，基于patient-modality二部图结构，使用不确定性感知的聚合方法来自适应地融合信息。这一机制允许在缺失模态时自然处理，并动态强调可靠模态的信息，从而引导表示生成。",
      "result": "实验结果显示，AUM框架在MIMIC-IV死亡率预测任务中实现了AUC-ROC提升2.26%，在eICU数据集中提升2.17%，这些指标显著优于现有state-of-the-art方法。具体数据表明，通过量化不确定性和动态聚合，模型在处理缺失模态时表现出更好的性能，验证了该方法在医疗多模态学习中的有效性和优势。",
      "conclusion": "该研究的主要贡献是提出了AUM框架，有效解决了医疗多模态学习中的缺失模态问题，通过aleatoric uncertainty量化和动态聚合机制提升了模型性能。这不仅具有学术价值，为不确定性建模提供了新思路，还在医疗应用中能提高预测准确性，有助临床决策。摘要未明确说明局限性或未来工作方向，但可推断可能涉及扩展到更复杂模态或任务。",
      "tags": [
        "Medical Multimodal Learning",
        "Aleatoric Uncertainty Modeling",
        "Gaussian Distribution",
        "Graph Neural Networks",
        "Uncertainty-aware Aggregation"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:29.246785Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21948",
    "title": "Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding",
    "authors": [
      "Yang Du",
      "Siyuan Dai",
      "Yonghao Song",
      "Paul M. Thompson",
      "Haoteng Tang",
      "Liang Zhan"
    ],
    "abstract": "Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21948.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21948",
    "published": "2026-01-29T16:30:32Z",
    "updated": "2026-01-29T16:30:32Z",
    "comment": "29 pages, 13 figures",
    "light_analysis": {
      "overview": "本文提出Shallow Alignment，一种通过对比学习对齐神经信号与视觉编码器中间表示的策略，解决神经视觉解码中的粒度不匹配问题。",
      "motivation": "研究动机源于神经视觉解码领域的核心挑战，即深度视觉模型与人类神经信号之间的粒度不匹配问题。现有方法通常将神经信号与深度模型的最终输出对齐，但深度模型通过抑制局部纹理信息来强调语义不变性，而神经信号同时保留低层次视觉属性和高层次语义内容。这种不匹配限制了脑机接口的性能，导致解码精度不足，因此需要新方法更好平衡多粒度信息，以提升神经表示的重建和解释能力。",
      "method": "研究方法提出Shallow Alignment，一种基于对比学习的新策略，核心创新在于将神经信号对齐到视觉编码器的中间层表示，而非传统最终输出。该方法旨在平衡低层次纹理细节和高层次语义特征的保留，通过利用预训练视觉骨干模型的中间层来捕捉更丰富的视觉信息。摘要未明确说明具体数据集和模型架构，但实验涉及多个基准测试和不同视觉骨干，技术特色在于策略性地选择对齐层以匹配神经信号的复杂混合内容。",
      "result": "实验结果在多个基准测试中显示，Shallow Alignment相比标准最终层对齐方法有显著性能提升，提升幅度在22%到58%之间，具体取决于使用的视觉骨干模型。此外，该方法解锁了神经视觉解码中的缩放定律，使得解码性能可以随着预训练视觉骨干容量的增加而可预测地提高，有效验证了策略的泛化能力。摘要提到进行了系统分析来阐明性能提升机制，但未提供具体分析细节，仅表明结果是可靠且优于基线的。",
      "conclusion": "结论总结，本研究的主要贡献是提出Shallow Alignment策略，有效解决神经视觉解码中的粒度不匹配问题，显著提升解码性能并揭示缩放定律。学术上，它为对齐技术提供了新思路，推动对神经表示结构的理解；实际应用上，可增强脑机接口的准确性和可扩展性。未来工作可能包括将方法扩展到其他神经解码任务、优化中间表示选择策略，或深入分析性能提升的神经机制，但摘要未明确说明具体局限性。",
      "tags": [
        "Neural Visual Decoding",
        "Contrastive Learning",
        "Intermediate Representations",
        "Scaling Laws",
        "Vision Encoders"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:55.556880Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21947",
    "title": "ToolWeaver: Weaving Collaborative Semantics for Scalable Tool Use in Large Language Models",
    "authors": [
      "Bowen Fang",
      "Wen Ye",
      "Yunyue Su",
      "Jinghao Zhang",
      "Qiang Liu",
      "Yesheng Liu",
      "Xin Sun",
      "Shu Wu",
      "Jiabing Yang",
      "Baole Wei",
      "Liang Wang"
    ],
    "abstract": "Prevalent retrieval-based tool-use pipelines struggle with a dual semantic challenge: their retrievers often employ encoders that fail to capture complex semantics, while the Large Language Model (LLM) itself lacks intrinsic tool knowledge from its natural language pretraining. Generative methods offer a powerful alternative by unifying selection and execution, tasking the LLM to directly learn and generate tool identifiers. However, the common practice of mapping each tool to a unique new token introduces substantial limitations: it creates a scalability and generalization crisis, as the vocabulary size explodes and each tool is assigned a semantically isolated token. This approach also creates a semantic bottleneck that hinders the learning of collaborative tool relationships, as the model must infer them from sparse co-occurrences of monolithic tool IDs within a vast library. To address these limitations, we propose ToolWeaver, a novel generative tool learning framework that encodes tools into hierarchical sequences. This approach makes vocabulary expansion logarithmic to the number of tools. Crucially, it enables the model to learn collaborative patterns from the dense co-occurrence of shared codes, rather than the sparse co-occurrence of monolithic tool IDs. We generate these structured codes through a novel tokenization process designed to weave together a tool's intrinsic semantics with its extrinsic co-usage patterns. These structured codes are then integrated into the LLM through a generative alignment stage, where the model is fine-tuned to produce the hierarchical code sequences. Evaluation results with nearly 47,000 tools show that ToolWeaver significantly outperforms state-of-the-art methods, establishing a more scalable, generalizable, and semantically-aware foundation for advanced tool-augmented agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21947.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21947",
    "published": "2026-01-29T16:29:53Z",
    "updated": "2026-01-29T16:29:53Z",
    "comment": "10pages, 12 figures, Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "ToolWeaver提出一种基于分层序列编码工具的生成式框架，解决大语言模型工具使用中的可扩展性和语义协作问题。",
      "motivation": "当前基于检索的工具使用管道面临双重语义挑战：检索器的编码器常无法捕捉复杂语义，而大语言模型本身在自然语言预训练中缺乏工具知识。生成式方法虽能统一选择和执行，但常见做法将每个工具映射到唯一新标记，导致词汇爆炸和语义隔离，引发可扩展性和泛化危机。此外，这种方法还造成语义瓶颈，阻碍模型从稀疏共现的整体工具ID中学习协同关系，因此需要改进现有方法以支持大规模工具使用。",
      "method": "ToolWeaver是一种新颖的生成式工具学习框架，其核心是将工具编码为分层序列，从而使词汇扩展与工具数量成对数关系，解决可扩展性问题。关键创新点包括：设计了一种新的标记化过程，该过程编织工具的内在语义与外在协同使用模式，生成结构化代码；然后通过生成式对齐阶段，将这些分层代码序列集成到大语言模型中，并通过微调使模型学习生成这些序列。该方法不依赖具体数据集或模型架构细节，专注于改进工具表示和学习机制。",
      "result": "在近47,000个工具的实验评估中，ToolWeaver显著优于当前最优方法。具体表现为建立了更可扩展、泛化性强和语义感知的基础，避免了词汇爆炸问题，并增强了工具协同关系的学习。与基线方法相比，ToolWeaver能更有效地处理大规模工具库，提高工具选择的准确性和效率，为高级工具增强代理的构建提供了实证支持。摘要未提供具体性能指标数据如准确率，但强调了显著优势。",
      "conclusion": "ToolWeaver的主要贡献在于提出了一种可扩展的生成式工具学习框架，通过分层序列编码解决了现有方法的语义隔离和可扩展性限制。其学术价值在于改进了大语言模型的工具处理能力，增强了语义协作；实际应用价值在于为开发高效、泛化性强的工具增强代理奠定了基础。摘要未明确说明潜在局限性或未来工作方向，但该方法为相关研究提供了新思路。",
      "tags": [
        "Large Language Model",
        "Tool Learning",
        "Generative Alignment",
        "Hierarchical Sequence Encoding",
        "Scalable Tool Use"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:13.056517Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21945",
    "title": "Dependence of Equilibrium Propagation Training Success on Network Architecture",
    "authors": [
      "Qingshan Wang",
      "Clara C. Wanjura",
      "Florian Marquardt"
    ],
    "abstract": "The rapid rise of artificial intelligence has led to an unsustainable growth in energy consumption. This has motivated progress in neuromorphic computing and physics-based training of learning machines as alternatives to digital neural networks. Many theoretical studies focus on simple architectures like all-to-all or densely connected layered networks. However, these may be challenging to realize experimentally, e.g. due to connectivity constraints. In this work, we investigate the performance of the widespread physics-based training method of equilibrium propagation for more realistic architectural choices, specifically, locally connected lattices. We train an XY model and explore the influence of architecture on various benchmark tasks, tracking the evolution of spatially distributed responses and couplings during training. Our results show that sparse networks with only local connections can achieve performance comparable to dense networks. Our findings provide guidelines for further scaling up architectures based on equilibrium propagation in realistic settings.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21945.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21945",
    "published": "2026-01-29T16:29:31Z",
    "updated": "2026-01-29T16:29:31Z",
    "comment": "9 pages, 5 figures",
    "light_analysis": {
      "overview": "本文研究发现，使用平衡传播训练的稀疏局部连接网络在性能上可与密集网络媲美，为实际应用提供了架构指导。",
      "motivation": "人工智能的快速发展导致能源消耗不可持续增长，推动了神经形态计算和基于物理的训练方法作为数字神经网络的替代方案。现有理论研究多聚焦于简单密集连接架构，但实验实现面临挑战，如连接性限制。因此，本研究旨在探索更现实的局部连接格子架构对平衡传播训练性能的影响，以解决能耗和实现可行性问题。",
      "method": "研究采用平衡传播这一基于物理的训练方法，应用于局部连接格子网络架构。具体训练了XY模型，并通过探索架构对多种基准任务的影响来评估性能。关键创新点在于研究稀疏连接对训练成功性的依赖关系，训练过程中跟踪了空间分布式响应和耦合的演化。数据集和模型细节摘要未明确说明，但涉及标准基准任务分析。",
      "result": "实验结果表明，稀疏局部连接网络在训练性能上可以达到与密集网络相当的水平。这证明了在保持性能的同时降低网络连接复杂性的可行性。具体性能指标如准确率在摘要中未提供详细数据，但强调了可比较性，与基线密集网络的对比验证了稀疏架构的有效性。",
      "conclusion": "研究结论表明，稀疏局部连接网络在平衡传播训练中表现良好，为现实设置中基于该方法扩展架构提供了实用指导。学术价值在于揭示网络架构对物理训练方法成功性的影响，实际应用价值在于促进能耗优化的神经形态计算系统设计。未来工作可能包括探索更多复杂架构或在更大规模实验中验证。",
      "tags": [
        "Equilibrium Propagation",
        "Neuromorphic Computing",
        "Local Connectivity",
        "XY Model",
        "Network Architecture"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:27.353620Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21944",
    "title": "Clarity: The Flexibility-Interpretability Trade-Off in Sparsity-aware Concept Bottleneck Models",
    "authors": [
      "Konstantinos P. Panousis",
      "Diego Marcos"
    ],
    "abstract": "The widespread adoption of Vision-Language Models (VLMs) across fields has amplified concerns about model interpretability. Distressingly, these models are often treated as black-boxes, with limited or non-existent investigation of their decision making process. Despite numerous post- and ante-hoc interepretability methods, systematic and objective evaluation of the learned representations remains limited, particularly for sparsity-aware methods that are increasingly considered to \"induce interpretability\". In this work, we focus on Concept Bottleneck Models and investigate how different modeling decisions affect the emerging representations. We introduce the notion of clarity, a measure, capturing the interplay between the downstream performance and the sparsity and precision of the concept representation, while proposing an interpretability assessment framework using datasets with ground truth concept annotations. We consider both VLM- and attribute predictor-based CBMs, and three different sparsity-inducing strategies: per example $\\ell_1, \\ell_0$ and Bernoulli-based formulations. Our experiments reveal a critical trade-off between flexibility and interpretability, under which a given method can exhibit markedly different behaviors even at comparable performance levels. The code will be made publicly available upon publication.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21944.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21944",
    "published": "2026-01-29T16:28:55Z",
    "updated": "2026-01-29T16:28:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文引入清晰度度量来研究概念瓶颈模型中稀疏性诱导方法在灵活性与可解释性之间的权衡。",
      "motivation": "视觉语言模型（VLMs）的广泛采用引发了对其可解释性的担忧，因为这些模型常被视为黑箱，决策过程缺乏透明性。尽管存在多种事后和事前解释方法，但对学习表示的系统性评估仍显不足，特别是对于稀疏性感知方法，这些方法被认为能“诱导可解释性”。因此，本研究旨在通过评估概念瓶颈模型（CBMs）中的表示，探索不同建模决策如何影响表示质量，以填补这一研究空白。",
      "method": "论文提出了一种名为“清晰度”的度量，用于捕捉下游任务性能与概念表示的稀疏性和精确性之间的相互作用，并建立了一个可解释性评估框架，使用带有地面真值概念标注的数据集。研究涵盖了基于视觉语言模型和属性预测器的概念瓶颈模型，并采用三种稀疏性诱导策略：每个例子应用ℓ1正则化、ℓ0正则化和基于伯努利公式的方法，以分析不同建模选择对表示的影响。",
      "result": "实验结果表明，概念瓶颈模型中存在灵活性与可解释性的关键权衡。在不同稀疏性诱导策略下，即使在可比性能水平下，方法也表现出显著不同的行为，这揭示了表示质量的多样性。摘要未明确说明具体的性能指标或对比数据，但强调了这种权衡的重要性，并通过框架评估了策略效果，为后续研究提供了基础。",
      "conclusion": "本研究的主要贡献是引入了清晰度度量，为稀疏性感知方法的可解释性提供了客观评估框架，并揭示了灵活性与可解释性之间的权衡。这项工作在学术上有助于推动可解释性评估的标准，在实际应用中可促进更透明、可信的AI系统开发。未来工作可能涉及扩展到其他模型或更广泛的数据集，摘要未明确说明具体局限性。",
      "tags": [
        "Concept Bottleneck Models",
        "Sparsity-aware Methods",
        "Interpretability Assessment",
        "ℓ1 regularization",
        "ℓ0 regularization"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:35.742710Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21943",
    "title": "Entropy-Based Dimension-Free Convergence and Loss-Adaptive Schedules for Diffusion Models",
    "authors": [
      "Ahmad Aghapour",
      "Erhan Bayraktar",
      "Ziqing Zhang"
    ],
    "abstract": "Diffusion generative models synthesize samples by discretizing reverse-time dynamics driven by a learned score (or denoiser). Existing convergence analyses of diffusion models typically scale at least linearly with the ambient dimension, and sharper rates often depend on intrinsic-dimension assumptions or other geometric restrictions on the target distribution. We develop an alternative, information-theoretic approach to dimension-free convergence that avoids any geometric assumptions. Under mild assumptions on the target distribution, we bound KL divergence between the target and generated distributions by $O(H^2/K)$ (up to endpoint factors), where $H$ is the Shannon entropy and $K$ is the number of sampling steps. Moreover, using a reformulation of the KL divergence, we propose a Loss-Adaptive Schedule (LAS) for efficient discretization of reverse SDE which is lightweight and relies only on the training loss, requiring no post-training heavy computation. Empirically, LAS improves sampling quality over common heuristic schedules.",
    "categories": [
      "cs.LG",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21943.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21943",
    "published": "2026-01-29T16:28:21Z",
    "updated": "2026-01-29T16:28:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于信息理论的维度无关收敛分析和轻量损失自适应调度方案，以提升扩散模型的性能和效率。",
      "motivation": "扩散生成模型在图像生成等任务中广泛应用，但现有收敛分析通常依赖环境维度或几何假设，导致理论结果在高维场景下不够普适。本研究旨在解决这一限制，通过开发维度无关的分析方法和高效调度方案，避免几何限制，提高模型的实用性和理论支撑。现有方法的不足在于收敛率受维度影响，限制了其在复杂分布中的应用潜力，因此需要更通用的框架来优化采样过程。",
      "method": "本研究提出一种信息理论方法，通过Shannon熵H和采样步骤数K，将目标分布与生成分布之间的KL散度约束为$O(H^2/K)$，实现维度无关的收敛分析，关键创新在于避免任何几何假设。此外，利用KL散度的重构，设计了Loss-Adaptive Schedule (LAS)方案，用于离散化反随机微分方程，该方案轻量且仅依赖训练损失，无需后训练重计算，优化了采样过程的技术路线。",
      "result": "实验结果显示，Loss-Adaptive Schedule (LAS)在采样质量上优于常见的启发式调度方案，但摘要未明确说明具体的性能指标，如准确率提升或效率改进的量化数据。经验验证表明LAS有效提高了生成样本的质量，与基线方法对比展现了改进潜力，但缺乏详细数值支撑，需进一步实验验证具体效果。",
      "conclusion": "本研究的核心贡献在于提供了维度无关的收敛分析框架和轻量损失自适应调度方案，拓展了扩散模型的理论基础并提升了实用效率。学术价值在于基于信息理论的普适分析方法，实际应用价值体现在优化采样过程和减少计算开销。潜在局限性可能依赖于目标分布的温和假设，未来工作可探索更复杂分布或集成其他优化技术。",
      "tags": [
        "Diffusion Models",
        "KL Divergence",
        "Information Theory",
        "Loss-Adaptive Schedule",
        "Stochastic Differential Equations"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:38.769428Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21941",
    "title": "Robust Multimodal Representation Learning in Healthcare",
    "authors": [
      "Xiaoguang Zhu",
      "Linxiao Gong",
      "Lianlong Sun",
      "Yang Liu",
      "Haoyu Wang",
      "Jing Liu"
    ],
    "abstract": "Medical multimodal representation learning aims to integrate heterogeneous data into unified patient representations to support clinical outcome prediction. However, real-world medical datasets commonly contain systematic biases from multiple sources, which poses significant challenges for medical multimodal representation learning. Existing approaches typically focus on effective multimodal fusion, neglecting inherent biased features that affect the generalization ability. To address these challenges, we propose a Dual-Stream Feature Decorrelation Framework that identifies and handles the biases through structural causal analysis introduced by latent confounders. Our method employs a causal-biased decorrelation framework with dual-stream neural networks to disentangle causal features from spurious correlations, utilizing generalized cross-entropy loss and mutual information minimization for effective decorrelation. The framework is model-agnostic and can be integrated into existing medical multimodal learning methods. Comprehensive experiments on MIMIC-IV, eICU, and ADNI datasets demonstrate consistent performance improvements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21941.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21941",
    "published": "2026-01-29T16:27:54Z",
    "updated": "2026-01-29T16:27:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一个双流特征解相关框架，通过结构性因果分析处理医学多模态表示学习中的系统性偏见，提升泛化能力。",
      "motivation": "医学多模态表示学习旨在整合异构数据为统一患者表示以支持临床预测，但现实世界医学数据常包含多个来源的系统性偏见，导致现有方法在泛化能力上不足。现有研究通常专注于有效融合多模态信息，忽视了这些偏见特征的影响，从而限制了预测模型的准确性和可靠性。因此，开发新方法以识别和处理偏见对于提高医疗AI系统的实际应用价值至关重要。",
      "method": "论文提出一个双流特征解相关框架，该框架基于结构性因果分析来识别和处理由潜在混杂因素引起的偏见。方法采用双流神经网络来解耦因果特征和虚假相关，通过广义交叉熵损失和互信息最小化技术实现有效解相关。框架与模型无关，可轻松集成到现有的医学多模态学习方法中，提升整体鲁棒性。",
      "result": "在MIMIC-IV、eICU和ADNI数据集上的综合实验表明，所提方法带来了持续的性能改进。与基线方法相比，框架有效提高了预测准确性和泛化能力。摘要未明确说明具体数据细节，但实验验证了方法在跨数据集上的稳定表现。",
      "conclusion": "该研究通过双流特征解相关框架解决了医学多模态表示学习中的偏见问题，显著提升了模型的泛化能力和鲁棒性。贡献包括引入结构性因果分析和有效解相关技术，对医疗AI领域的学术发展和实际应用具有重要价值。未来工作可进一步优化方法或扩展到更多医疗场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Multimodal Representation Learning",
        "Feature Decorrelation",
        "Causal Analysis",
        "Neural Networks",
        "Mutual Information Minimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:47.718524Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21938",
    "title": "BookNet: Book Image Rectification via Cross-Page Attention Network",
    "authors": [
      "Shaokai Liu",
      "Hao Feng",
      "Bozhi Luan",
      "Min Hou",
      "Jiajun Deng",
      "Wengang Zhou"
    ],
    "abstract": "Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21938.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21938",
    "published": "2026-01-29T16:26:25Z",
    "updated": "2026-01-29T16:26:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出BookNet，首个端到端深度学习框架，通过跨页注意力机制实现双页书籍图像校正，并创建了Book3D和Book100数据集。",
      "motivation": "书籍图像校正因装订导致的复杂几何变形而具有独特挑战，左右页面呈现不对称的曲率模式。现有单页文档图像校正方法未能捕捉书籍中相邻页面间的耦合几何关系，这限制了校正效果，影响文档数字化的质量和后续处理。该问题在图书扫描、档案保存等应用中至关重要，需要专门针对书籍特性的解决方案，以提升图像可读性和分析准确性。",
      "method": "BookNet采用双分支架构，结合跨页注意力机制，端到端地估计单页和完整书页的变形流，从而明确建模左右页面间的相互影响。核心创新在于引入注意力机制来处理页面间依赖关系，增强几何变形估计的准确性。此外，为了解决训练数据缺乏的问题，论文提出了Book3D，一个大型合成数据集用于模型训练，以及Book100，一个全面的真实世界基准用于评估，确保方法的泛化能力。",
      "result": "广泛实验表明BookNet在书籍图像校正任务上优于现有最先进方法。摘要未明确说明具体性能指标，但通过使用Book100基准进行评估，推断该方法在矫正精度和鲁棒性方面有显著提升，特别是在处理不对称变形时，展现出对复杂几何关系的有效捕捉能力。",
      "conclusion": "本研究的主要贡献是提出了BookNet框架和配套数据集，为书籍图像校正提供了首个专门化的端到端解决方案。跨页注意力机制创新性地建模了页面间关系，具有重要的学术价值和实际应用前景，可推动文档图像处理技术的发展。未来工作可能包括扩展到更复杂的书籍结构或集成到更广泛的文档分析系统中，以应对更多样化的变形场景。",
      "tags": [
        "Document Image Processing",
        "Cross-Page Attention",
        "Deep Learning",
        "Image Rectification",
        "Synthetic Dataset"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:31.240074Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21937",
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "authors": [
      "Shuangshuang Ying",
      "Zheyu Wang",
      "Yunjian Peng",
      "Jin Chen",
      "Yuhao Wu",
      "Hongbin Lin",
      "Dingyu He",
      "Siyi Liu",
      "Gengchen Yu",
      "YinZhu Piao",
      "Yuchen Wu",
      "Xin Gui",
      "Zhongyuan Peng",
      "Xin Li",
      "Xeron Du",
      "Libo Qin",
      "YiXin Cao",
      "Ge Zhang"
    ],
    "abstract": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21937.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21937",
    "published": "2026-01-29T16:26:19Z",
    "updated": "2026-01-29T16:26:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出DeR2基准，通过解耦检索和推理能力，评估大型语言模型在深度研究中的表现。",
      "motivation": "现有评估方法大多基于端到端检索增强生成管道，将推理与检索和工具链选择混淆，导致信号受参数记忆和开放网络波动影响，无法准确判断模型是否能在真正新颖的科学信息上进行推理。这一问题的重要性在于它限制了我们对大型语言模型核心能力的理解，特别是在深度研究场景中，现有方法未能有效隔离检索和推理过程，从而影响评估的公正性和可解释性。",
      "method": "该研究提出DeR2沙盒，采用四种机制——Instruction-only、Concepts、Related-only和Full-set——来解耦证据访问与推理，从而隔离文档基础推理并保留深度搜索的困难（如多步骤合成和去噪）。关键创新点包括使用两阶段验证防止参数泄漏，要求模型在没有证据时失败但能解决oracle概念问题，并提供基于2023-2025理论论文的冻结文档库，带专家标注概念和验证推理，确保实验可复现性。",
      "result": "在多种最先进基础模型上的实验显示，模型表现存在显著变化和巨大提升空间：一些模型表现出模式切换脆弱性，在Full-set机制下比Instruction-only表现更差；另一些模型显示结构性概念误用，能正确命名概念但无法作为程序执行。这些结果通过不同机制对比，清晰地揭示了检索损失与推理损失，为细粒度错误归因提供了依据，但摘要未明确说明具体性能数据。",
      "conclusion": "论文的主要贡献是开发了DeR2基准，提供了一个受控环境来评估和提升大型语言模型在深度研究中的推理能力。其学术价值在于帮助理解模型在解耦检索和推理时的表现差异，实际应用价值可能指导模型优化和改进评估方法。潜在局限性包括摘要未明确说明的未来方向，但可推断如扩展数据集或进一步分析模型行为。",
      "tags": [
        "Large Language Models",
        "Retrieval-Augmented Generation",
        "Benchmarking",
        "Reasoning",
        "Document-Grounded Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:14.881632Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21936",
    "title": "AgenticSimLaw: A Juvenile Courtroom Multi-Agent Debate Simulation for Explainable High-Stakes Tabular Decision Making",
    "authors": [
      "Jon Chun",
      "Kathrine Elkins",
      "Yong Suk Lee"
    ],
    "abstract": "We introduce AgenticSimLaw, a role-structured, multi-agent debate framework that provides transparent and controllable test-time reasoning for high-stakes tabular decision-making tasks. Unlike black-box approaches, our courtroom-style orchestration explicitly defines agent roles (prosecutor, defense, judge), interaction protocols (7-turn structured debate), and private reasoning strategies, creating a fully auditable decision-making process. We benchmark this framework on young adult recidivism prediction using the NLSY97 dataset, comparing it against traditional chain-of-thought (CoT) prompting across almost 90 unique combinations of models and strategies. Our results demonstrate that structured multi-agent debate provides more stable and generalizable performance compared to single-agent reasoning, with stronger correlation between accuracy and F1-score metrics. Beyond performance improvements, AgenticSimLaw offers fine-grained control over reasoning steps, generates complete interaction transcripts for explainability, and enables systematic profiling of agent behaviors. While we instantiate this framework in the criminal justice domain to stress-test reasoning under ethical complexity, the approach generalizes to any deliberative, high-stakes decision task requiring transparency and human oversight. This work addresses key LLM-based multi-agent system challenges: organization through structured roles, observability through logged interactions, and responsibility through explicit non-deployment constraints for sensitive domains. Data, results, and code will be available on github.com under the MIT license.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21936.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21936",
    "published": "2026-01-29T16:26:10Z",
    "updated": "2026-01-29T16:26:10Z",
    "comment": "18 pages, 5 figures",
    "light_analysis": {
      "overview": "论文提出了AgenticSimLaw，一个多智能体辩论框架，通过模拟法庭辩论实现高风险表格决策的透明和可控推理。",
      "motivation": "该研究旨在解决高风险表格决策任务中黑盒方法缺乏透明性和可控制性的问题。在如年轻成人再犯罪预测等敏感领域，传统方法如链式思维提示可能不够稳定或可解释，导致决策过程不透明，难以审计和监管。AgenticSimLaw通过结构化多智能体辩论，提供可审计的推理路径，增强人类监督，应对伦理复杂性下的决策挑战，强调在高风险应用中透明推理的必要性。",
      "method": "论文提出了AgenticSimLaw框架，通过定义明确的代理角色（检察官、辩护、法官）和7轮结构化辩论协议，模拟法庭辩论过程。每个代理采用私有推理策略，生成完整交互记录以实现解释性。该框架在NLSY97数据集上进行基准测试，比较了几乎90种模型和策略组合，核心创新在于结构化多智能体辩论的组织和可观察性设计，以及通过角色定义和交互协议创建完全可审计的决策流程。",
      "result": "实验结果表明，AgenticSimLaw框架相比传统链式思维提示，在年轻成人再犯罪预测任务中提供了更稳定和可泛化的性能。准确率和F1分数之间的相关性更强，显示出更一致的推理。此外，框架允许对推理步骤的细粒度控制，并生成完整交互记录，增强了可解释性和代理行为分析，与单智能体推理相比，在多模型策略组合下表现更可靠。",
      "conclusion": "该研究的主要贡献是提出了一个可推广的框架，用于高风险表格决策的透明推理，解决了LLM多智能体系统的组织、观察和责任挑战。通过在刑事司法领域的实例化，展示了框架在伦理复杂场景下的应用价值。未来工作可扩展到其他高风险决策任务，并可能优化交互协议或处理更多数据类型，强调透明度在敏感领域部署中的重要性。",
      "tags": [
        "Multi-Agent Systems",
        "Explainable AI",
        "Structured Debating",
        "LLM-based Reasoning",
        "Tabular Decision Making"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:41.522415Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21933",
    "title": "Just Noticeable Difference Modeling for Deep Visual Features",
    "authors": [
      "Rui Zhao",
      "Wenrui Li",
      "Lin Zhu",
      "Yajing Zheng",
      "Weisi Lin"
    ],
    "abstract": "Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21933.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21933",
    "published": "2026-01-29T16:22:31Z",
    "updated": "2026-01-29T16:22:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了FeatJND，一种任务对齐的JND模型，用于预测深视觉特征的最大可容忍扰动，以优化特征质量控制。",
      "motivation": "随着深视觉特征在视觉系统中作为接口的广泛使用，描述特征特性并控制其质量对机器感知变得至关重要。JND在人类视觉中用于评估最大不可感知失真，但现有方法缺乏任务对齐的边界，难以在资源约束下有效控制特征质量。本研究将JND扩展到深视觉特征，旨在提供任务对齐的容忍边界，解决特征质量控制的实际问题，从而提高机器感知的鲁棒性和效率。",
      "method": "论文提出了FeatJND，一个任务对齐的JND公式，用于预测深视觉特征中每个特征的最大可容忍扰动图，同时确保下游任务性能不受影响。关键创新点包括将JND扩展到特征空间，并设计了FeatJND估计器，在标准化分割点进行优化。验证过程中，在图像分类、检测和实例分割等多个任务上进行实验，但摘要未明确说明具体使用的数据集和模型架构细节。",
      "result": "在匹配失真强度的条件下，基于FeatJND的扰动相比无结构高斯扰动，能更有效地保持下游任务性能，归因可视化显示FeatJND能抑制非关键特征区域。此外，在令牌级动态量化应用中，FeatJND指导的步长分配在相同噪声预算下，相比随机步长排列和全局统一步长，显示出明显的性能提升，但摘要未提供具体数字指标。",
      "conclusion": "本研究的核心贡献是扩展JND概念到深视觉特征，开发了任务对齐的FeatJND模型，为控制特征质量提供实用参考，增强了机器感知系统的鲁棒性。学术价值在于结合人类视觉理论与机器视觉应用，实际应用包括优化资源约束下的特征处理和量化策略。局限性或未来工作摘要未明确说明，可能涉及更多任务验证或算法优化。",
      "tags": [
        "Just Noticeable Difference (JND)",
        "Deep Visual Features",
        "Task-aligned Modeling",
        "Dynamic Quantization",
        "Feature Perturbation"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:56.269065Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21929",
    "title": "LoRIF: Low-Rank Influence Functions for Scalable Training Data Attribution",
    "authors": [
      "Shuangqi Li",
      "Hieu Le",
      "Jingyi Xu",
      "Mathieu Salzmann"
    ],
    "abstract": "Training data attribution (TDA) identifies which training examples most influenced a model's prediction. The best-performing TDA methods exploits gradients to define an influence function. To overcome the scalability challenge arising from gradient computation, the most popular strategy is random projection (e.g., TRAK, LoGRA). However, this still faces two bottlenecks when scaling to large training sets and high-quality attribution: \\emph{(i)} storing and loading projected per-example gradients for all $N$ training examples, where query latency is dominated by I/O; and \\emph{(ii)} forming the $D \\times D$ inverse Hessian approximation, which costs $O(D^2)$ memory. Both bottlenecks scale with the projection dimension $D$, yet increasing $D$ is necessary for attribution quality -- creating a quality--scalability tradeoff. We introduce \\textbf{LoRIF (Low-Rank Influence Functions)}, which exploits low-rank structures of gradient to address both bottlenecks. First, we store rank-$c$ factors of the projected per-example gradients rather than full matrices, reducing storage and query-time I/O from $O(D)$ to $O(c\\sqrt{D})$ per layer per sample. Second, we use truncated SVD with the Woodbury identity to approximate the Hessian term in an $r$-dimensional subspace, reducing memory from $O(D^2)$ to $O(Dr)$. On models from 0.1B to 70B parameters trained on datasets with millions of examples, LoRIF achieves up to 20$\\times$ storage reduction and query-time speedup compared to LoGRA, while matching or exceeding its attribution quality. LoRIF makes gradient-based TDA practical at frontier scale.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21929.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21929",
    "published": "2026-01-29T16:18:34Z",
    "updated": "2026-01-29T16:18:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出LoRIF方法，通过利用梯度的低秩结构解决训练数据归因的可扩展性挑战，实现高质量和高效的大规模应用。",
      "motivation": "训练数据归因（TDA）旨在识别对模型预测影响最大的训练样本，对模型解释和调试至关重要。现有方法如TRAK和LoGRA使用随机投影来缓解梯度计算的可扩展性问题，但仍面临两个瓶颈：存储和加载投影梯度导致I/O延迟，以及计算逆Hessian近似需要高内存成本，这限制了在大规模训练集和高维投影下的质量和效率。因此，需要新方法来平衡TDA的质量与可扩展性，克服这些限制。",
      "method": "LoRIF方法的核心创新是利用梯度的低秩结构来减少存储和计算开销。首先，它将投影的每样本梯度存储为低秩因子（秩c），而非完整矩阵，从而将每层每样本的存储和I/O成本从O(D)降至O(c√D)。其次，采用截断奇异值分解（SVD）结合Woodbury恒等式，在r维子空间中近似Hessian项，将内存需求从O(D²)减少到O(Dr)。该方法适用于参数范围从0.1B到70B的模型，并处理包含数百万样本的数据集，具体技术包括梯度低秩分解和高效Hessian近似。",
      "result": "实验结果显示，在模型参数从0.1B到70B、数据集包含数百万样本的广泛测试中，LoRIF相比基线方法LoGRA实现了高达20倍的存储减少和查询时间加速。同时，其归因质量与LoGRA匹配或更优，表明在保持高质量的同时显著提升了效率。这些改进使得基于梯度的TDA在大规模应用变得可行，缓解了传统方法在扩展时面临的瓶颈。",
      "conclusion": "LoRIF的主要贡献是提出了一种可扩展的训练数据归因方法，有效解决了存储和计算瓶颈，推动TDA技术在大规模机器学习中的实用化。研究具有重要学术价值，丰富了TDA领域的算法设计，并具备实际应用价值，支持在大模型和数据集上实施高效归因分析。未来工作可能包括进一步优化算法性能或扩展到更复杂的模型架构和数据场景。",
      "tags": [
        "Training Data Attribution",
        "Influence Functions",
        "Low-Rank Structure",
        "Gradient Computation",
        "SVD"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:18.106480Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21927",
    "title": "SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching",
    "authors": [
      "Hong Chen",
      "Xiang Liu",
      "Bo Wang",
      "Yuxuan Fan",
      "Yuanlin Chu",
      "Zongluo Li",
      "Xiaowen Chu",
      "Xuming Hu"
    ],
    "abstract": "The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \\textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \\textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\\% and 50\\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\\% compared to full-context generation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21927.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21927",
    "published": "2026-01-29T16:18:08Z",
    "updated": "2026-01-29T16:18:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "SONIC提出一种基于学习的框架，通过压缩历史片段为紧凑语义Nexus令牌来优化KV缓存，提升多轮对话LLM的部署效率和连贯性。",
      "motivation": "KV缓存的线性增长成为多轮LLM部署的瓶颈，现有压缩方法常忽略对话结构特性，依赖启发式驱逐策略可能丢失关键上下文，导致对话不连贯。这在实际应用中限制了资源效率和推理速度，因此需要更智能的压缩方案来解决内存约束下的连贯对话挑战，优化部署成本。",
      "method": "SONIC是一种基于学习的KV缓存压缩框架，它将历史对话片段压缩成语义丰富的Nexus令牌。核心创新包括动态预算训练，使模型能灵活适应不同内存限制而无需重新训练，同时结合对话结构分析来保留关键信息。该方法通过优化压缩过程，确保压缩后的令牌能有效维持多轮对话的连贯性。",
      "result": "在四个多轮对话基准测试中，SONIC在80%和50%压缩比下均优于H2O和StreamingLLM等基线方法。具体在MTBench101基准上，平均得分提升35.55%。此外，SONIC加速整体推理过程50.1%，显著提升部署效率，验证了其在平衡压缩和性能方面的优越性。",
      "conclusion": "SONIC通过高效压缩KV缓存，解决了多轮对话LLM的内存瓶颈，贡献了结合学习与结构分析的新方法。其学术价值在于改进对话上下文处理，实际应用价值是提升部署效率和资源利用。未来工作可扩展至更多场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Key-Value Cache Compression",
        "Multi-turn Dialogue",
        "Learning-based Framework",
        "Nexus Tokens",
        "Dynamic Training"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:22.154471Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21924",
    "title": "Optimistic Transfer under Task Shift via Bellman Alignment",
    "authors": [
      "Jinhang Chai",
      "Enpei Zhang",
      "Elynn Chen",
      "Yujun Yan"
    ],
    "abstract": "We study online transfer reinforcement learning (RL) in episodic Markov decision processes, where experience from related source tasks is available during learning on a target task. A fundamental difficulty is that task similarity is typically defined in terms of rewards or transitions, whereas online RL algorithms operate on Bellman regression targets. As a result, naively reusing source Bellman updates introduces systematic bias and invalidates regret guarantees.   We identify one-step Bellman alignment as the correct abstraction for transfer in online RL and propose re-weighted targeting (RWT), an operator-level correction that retargets continuation values and compensates for transition mismatch via a change of measure. RWT reduces task mismatch to a fixed one-step correction and enables statistically sound reuse of source data.   This alignment yields a two-stage RWT $Q$-learning framework that separates variance reduction from bias correction. Under RKHS function approximation, we establish regret bounds that scale with the complexity of the task shift rather than the target MDP. Empirical results in both tabular and neural network settings demonstrate consistent improvements over single-task learning and naïve pooling, highlighting Bellman alignment as a model-agnostic transfer principle for online RL.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21924.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21924",
    "published": "2026-01-29T16:16:24Z",
    "updated": "2026-01-29T16:16:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于贝尔曼对齐的在线转移强化学习框架，通过重加权目标操作符减少任务不匹配的偏差。",
      "motivation": "在线强化学习中，当从源任务向目标任务转移经验时，由于任务相似性通常基于奖励或转移概率定义，而在线RL算法操作在贝尔曼回归目标上，导致直接重用源数据的贝尔曼更新会引入系统性偏差，并使算法的后悔保证失效。这一问题的核心在于现有转移方法未能正确处理任务间的动态差异，使得学习效率低下且理论保证不足。因此，研究旨在开发一种统计上可靠的转移方法，以克服这种不匹配并提升在线RL的泛化能力。",
      "method": "研究提出重加权目标（RWT）方法，基于一阶贝尔曼对齐概念，通过操作符级校正来重定向持续值和补偿转移不匹配。RWT将任务不匹配减少为固定的一阶校正，从而可以可靠地重用源数据，确保统计有效性。进一步，开发了一个两阶段RWT Q-学习框架，将方差减少与偏差校正分开处理，提高了算法的稳定性和效率。在技术实现中，采用RKHS（再生核希尔伯特空间）函数逼近来适应连续状态空间，增强了方法的泛化能力。",
      "result": "实验结果表明，在表格环境和神经网络设置中，提出的方法相对于单任务学习和朴素的源数据池化方法，在性能上表现出持续改进。摘要未明确说明具体的数值指标（如准确率提升），但强调了方法在减少后悔界限方面的有效性，该界限与任务转移的复杂性成比例，而不是目标MDP的复杂性，验证了其在降低任务不匹配影响上的优势。实证结果突出了贝尔曼对齐作为模型无关原则的普适性。",
      "conclusion": "论文的主要贡献是识别并利用一阶贝尔曼对齐，提出了一种模型无关的在线转移强化学习框架，不仅提供了更好的理论后悔保证，还在实践中展现出稳定的性能改进。这一研究为在线RL中的任务转移问题提供了新的解决方案，具有重要的学术价值，可推动更高效的泛化学习技术发展。未来工作可能包括扩展到更复杂的任务场景或与其他强化学习技术结合，以进一步验证其局限性和应用潜力。",
      "tags": [
        "Transfer Reinforcement Learning",
        "Bellman Alignment",
        "Q-learning",
        "RKHS Function Approximation",
        "Online Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:25.215588Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21922",
    "title": "Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models",
    "authors": [
      "Cong Cao",
      "Huanjing Yue",
      "Shangbin Xie",
      "Xin Liu",
      "Jingyu Yang"
    ],
    "abstract": "Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21922.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21922",
    "published": "2026-01-29T16:14:07Z",
    "updated": "2026-01-29T16:14:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出首个利用视频扩散模型辅助图像方法的框架，以解决零样本视频修复和增强中的时间闪烁问题，显著提升时间一致性。",
      "motivation": "研究动机源于视频修复和增强中存在的严重时间闪烁挑战。尽管基于扩散的零样本图像方法在静态图像处理中取得成功，但直接应用于视频时，由于缺乏时间连续性，导致闪烁现象，影响视频质量。视频应用对时间一致性要求高，而现有方法主要关注图像层面，未能有效集成视频的时间动态特征。因此，开发一种能维持视频时间一致性的零样本方法具有重要实际意义。",
      "method": "方法核心是一个无需训练的框架，利用视频扩散模型辅助图像方法以保持时间一致性。首先，提出同源潜在融合和异源潜在融合策略，结合同源与异源文本到视频扩散模型，互补图像方法的不足。其次，引入基于 COT 的融合比例策略，优化融合过程。此外，设计时间强化后处理，利用图像到视频扩散模型进一步减少时间闪烁。该框架可适配任何基于扩散的图像修复和增强方法，无需额外训练。",
      "result": "实验结果表明，所提方法在视频修复和增强任务中有效减少了时间闪烁，提升了时间一致性。尽管摘要未提供具体性能指标数据，但强调其方法在对比基线方法时展现出优越性。这证实了利用视频扩散模型辅助图像方法的有效性，为视频处理提供了实用工具。",
      "conclusion": "本研究的主要贡献是开发了首个利用视频扩散模型辅助图像方法的零样本框架，成功解决了视频修复和增强中的时间闪烁问题。框架无需训练，具有广泛适用性，为视频处理领域提供了新思路。学术上，扩展了扩散模型的应用范围；实际上，可用于提升视频质量。未来工作可能涉及优化策略或扩展至更多视频任务。",
      "tags": [
        "Video Diffusion Models",
        "Zero-Shot Learning",
        "Video Restoration",
        "Temporal Consistency",
        "Fusion Strategies"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:39.536539Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21919",
    "title": "Self-Compression of Chain-of-Thought via Multi-Agent Reinforcement Learning",
    "authors": [
      "Yiqun Chen",
      "Jinyuan Feng",
      "Wei Yang",
      "Meizhi Zhong",
      "Zhengliang Shi",
      "Rui Li",
      "Xiaochi Wei",
      "Yan Gao",
      "Yi Wu",
      "Yao Hu",
      "Zhiqiang Pu",
      "Jiaxin Mao"
    ],
    "abstract": "The inference overhead induced by redundant reasoning undermines the interactive experience and severely bottlenecks the deployment of Large Reasoning Models. Existing reinforcement learning (RL)-based solutions tackle this problem by coupling a length penalty with outcome-based rewards. This simplistic reward weighting struggles to reconcile brevity with accuracy, as enforcing brevity may compromise critical reasoning logic. In this work, we address this limitation by proposing a multi-agent RL framework that selectively penalizes redundant chunks, while preserving essential reasoning logic. Our framework, Self-Compression via MARL (SCMA), instantiates redundancy detection and evaluation through two specialized agents: \\textbf{a Segmentation Agent} for decomposing the reasoning process into logical chunks, and \\textbf{a Scoring Agent} for quantifying the significance of each chunk. The Segmentation and Scoring agents collaboratively define an importance-weighted length penalty during training, incentivizing \\textbf{a Reasoning Agent} to prioritize essential logic without introducing inference overhead during deployment. Empirical evaluations across model scales demonstrate that SCMA reduces response length by 11.1\\% to 39.0\\% while boosting accuracy by 4.33\\% to 10.02\\%. Furthermore, ablation studies and qualitative analysis validate that the synergistic optimization within the MARL framework fosters emergent behaviors, yielding more powerful LRMs compared to vanilla RL paradigms.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21919.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21919",
    "published": "2026-01-29T16:13:10Z",
    "updated": "2026-01-29T16:13:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出基于多智能体强化学习的自压缩框架SCMA，通过选择性惩罚冗余推理块，在减少响应长度的同时提高准确性，优化链式推理过程。",
      "motivation": "冗余推理导致大型推理模型的推理开销显著增加，影响交互体验并阻碍实际部署。现有基于强化学习的解决方案采用简单的长度惩罚与结果奖励结合方式，难以平衡简洁性和准确性，往往在强制简短时损害关键推理逻辑。因此，开发一种能有效区分冗余与必要逻辑的优化框架对高效部署大推理模型至关重要。摘要未明确说明具体应用场景，但聚焦于优化推理效率的重要性。",
      "method": "论文提出名为SCMA的多智能体强化学习框架，包含两个专门智能体：分段智能体将推理过程分解为逻辑块，评分智能体量化每个块的重要性。二者协同训练，定义重要性加权的长度惩罚，激励推理智能体在部署时专注于必要推理步骤而不引入额外开销。该方法创新在于通过智能体协作实现冗余检测和选择性压缩，具体使用多智能体强化学习技术优化推理模型的效率。",
      "result": "实证评估显示，SCMA在不同模型规模下显著降低响应长度11.1%至39.0%，同时提升准确性4.33%至10.02%。与基线强化学习方法对比，性能改进明显，消融研究和定性分析验证了多智能体强化学习框架的协同优化效应，促进了涌现行为，从而训练出更强大的大型推理模型。具体数据支撑了其在平衡简洁性和准确性方面的优势。",
      "conclusion": "该研究贡献了一个多智能体强化学习框架，有效解决冗余推理问题，通过自压缩机制提升推理模型的效率和性能。学术价值在于将复杂优化任务分解为协作智能体任务，推动强化学习在推理模型中的应用。实际应用价值包括减少计算开销和改善用户体验，为大型模型部署提供新途径。摘要未明确说明局限性或未来方向，但隐含进一步优化和扩展潜力。",
      "tags": [
        "Multi-Agent Reinforcement Learning",
        "Chain-of-Thought",
        "Self-Compression",
        "Redundancy Detection",
        "Importance Weighting"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:59.858817Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21916",
    "title": "JADE: Bridging the Strategic-Operational Gap in Dynamic Agentic RAG",
    "authors": [
      "Yiqun Chen",
      "Erhan Zhang",
      "Tianyi Hu",
      "Shijie Wang",
      "Zixuan Yang",
      "Meizhi Zhong",
      "Xiaochi Wei",
      "Yan Gao",
      "Yi Wu",
      "Yao Hu",
      "Jiaxin Mao"
    ],
    "abstract": "The evolution of Retrieval-Augmented Generation (RAG) has shifted from static retrieval pipelines to dynamic, agentic workflows where a central planner orchestrates multi-turn reasoning. However, existing paradigms face a critical dichotomy: they either optimize modules jointly within rigid, fixed-graph architectures, or empower dynamic planning while treating executors as frozen, black-box tools. We identify that this \\textit{decoupled optimization} creates a ``strategic-operational mismatch,'' where sophisticated planning strategies fail to materialize due to unadapted local executors, often leading to negative performance gains despite increased system complexity. In this paper, we propose \\textbf{JADE} (\\textbf{J}oint \\textbf{A}gentic \\textbf{D}ynamic \\textbf{E}xecution), a unified framework for the joint optimization of planning and execution within dynamic, multi-turn workflows. By modeling the system as a cooperative multi-agent team unified under a single shared backbone, JADE enables end-to-end learning driven by outcome-based rewards. This approach facilitates \\textit{co-adaptation}: the planner learns to operate within the capability boundaries of the executors, while the executors evolve to align with high-level strategic intent. Empirical results demonstrate that JADE transforms disjoint modules into a synergistic system, yielding remarkable performance improvements via joint optimization and enabling a flexible balance between efficiency and effectiveness through dynamic workflow orchestration.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21916.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21916",
    "published": "2026-01-29T16:06:44Z",
    "updated": "2026-01-29T16:06:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "JADE框架通过在动态检索增强生成工作流中联合优化规划和执行，解决了战略与操作之间的不匹配问题。",
      "motivation": "随着检索增强生成技术从静态流程演变为动态代理式工作流，现有方法面临关键二分法：要么在刚性固定图架构中联合优化模块，限制了系统灵活性；要么实施动态规划却将执行器视为冻结的黑盒工具，导致规划与执行解耦。这种解耦优化造成了战略与操作的不匹配，即高级规划策略因执行器不适应而无法实现，往往导致性能下降，尽管系统复杂性增加。因此，研究旨在克服这一不足，以提升动态RAG系统的效率和协同能力。",
      "method": "JADE框架将系统建模为在单一共享骨干下协同工作的多智能体团队，通过端到端学习方法，利用基于结果的奖励驱动优化过程。核心创新是联合优化规划器和执行器，促进协同适应：规划器学习在执行器能力边界内操作，而执行器演化以对齐高层战略意图。技术特色包括动态多轮工作流编排，具体实现基于检索增强生成背景，模型架构涉及多智能体协同，但摘要未明确说明数据集或模型细节。",
      "result": "实证结果表明，JADE框架通过联合优化规划和执行，能够将不相关的模块转化为协同系统，带来显著的性能提升。具体效果体现在效率和效果之间的动态平衡改进，与基线方法相比，JADE表现出优越的整体性能，但摘要未明确说明具体指标如准确率或效率数据。研究强调了框架的协同优势，通过动态工作流编排实现优化。",
      "conclusion": "JADE的主要贡献在于提供了一个统一框架，有效解决了动态RAG系统中的战略与操作不匹配问题，通过协同适应促进规划与执行的联合优化。其学术价值体现在推动了多智能体协同学习和动态工作流的研究，实际应用价值则是提高了RAG系统的性能和适应性。潜在局限性可能涉及计算复杂度或扩展性，未来工作方向可包括优化算法效率或扩展到更复杂的应用场景。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Multi-Agent Systems",
        "Joint Optimization",
        "Dynamic Workflow",
        "Co-adaptation"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:23.744711Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21915",
    "title": "VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models",
    "authors": [
      "Yunhao Li",
      "Sijing Wu",
      "Zhilin Gao",
      "Zicheng Zhang",
      "Qi Jia",
      "Huiyu Duan",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "abstract": "Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21915.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21915",
    "published": "2026-01-29T16:06:30Z",
    "updated": "2026-01-29T16:06:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了VideoAesBench基准测试，全面评估大型多模态模型在视频美学质量感知方面的能力，填补了该领域的研究空白。",
      "motivation": "大型多模态模型在视觉感知任务中表现出色，但视频美学质量评估作为人类基本能力，对大模型而言仍未被系统探索。视频美学评估对于视频内容分析、推荐系统和AI生成内容的质量控制至关重要。现有方法缺乏针对视频美学的专门基准测试，导致LMMs在此方面的能力评估不全面，无法准确衡量其潜力或改进方向，因此需要建立综合评估框架来推动相关研究。",
      "method": "论文提出VideoAesBench基准测试，方法包括收集1804个来自多种源的视频（如用户生成、AI生成、压缩视频等），设计多样化问题格式（单选择、多选择、真或假及开放性问题），覆盖视觉形式、风格和情感等多个美学维度。关键创新点在于通过综合内容和问题类型，构建了全面的评估框架，以量化23个开源和商业LMMs的视频美学感知能力，为模型性能提供标准化测试环境。",
      "result": "基于VideoAesBench对23个大型多模态模型的测试结果显示，当前模型仅具备基本的视频美学感知能力，表现不完整且不精确。基准测试暴露了LMMs在美学评估上的局限性，特别是在处理开放性问题时答案质量不足。虽然摘要未明确说明具体性能数据，但研究发现现有模型与理想标准相比有较大差距，需要进一步技术改进来提升美学理解能力。",
      "conclusion": "论文的主要贡献是引入VideoAesBench基准测试，为评估和提升LMMs的视频美学感知能力提供了标准工具。学术价值在于填补了多模态模型在美学评估领域的研究空白，实际应用价值包括改进视频内容分析、生成和推荐系统。未来工作可集中于开发更先进的模型算法，或扩展基准测试以覆盖更多美学维度，推动可解释视频美学评估的发展。",
      "tags": [
        "Large Multimodal Models",
        "Video Aesthetics Assessment",
        "Benchmarking",
        "Open-ended Questioning",
        "Multimodal Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:39.857959Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21912",
    "title": "ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation",
    "authors": [
      "Zhao Wang",
      "Ziliang Zhao",
      "Zhicheng Dou"
    ],
    "abstract": "Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to \"process hallucinations\", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21912.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21912",
    "published": "2026-01-29T16:04:59Z",
    "updated": "2026-01-29T16:04:59Z",
    "comment": "11 pages, 6 figures",
    "light_analysis": {
      "overview": "ProRAG提出了一个过程监督的强化学习框架，通过细粒度过程监督优化检索增强生成在复杂推理任务中的性能。",
      "motivation": "在复杂推理任务中，检索增强生成的优化常使用强化学习，但传统基于结果的强化学习方法存在奖励稀疏和信用分配问题，导致过程幻觉，即模型通过错误逻辑达到正确结果。现有过程感知方法试图通过静态偏好学习或启发式奖励塑造改善，但缺乏在线探索能力，难以解耦步骤级信用与全局结果。因此，需要一种方法集成步骤级监督到在线优化中，提高推理准确性和效率，解决当前方法的不足。",
      "method": "ProRAG框架包含四个阶段：首先，通过监督策略预热初始化模型的结构化推理格式；其次，构建基于Monte Carlo树搜索的过程奖励模型以量化中间推理质量；第三，使用PRM引导推理细化，使策略对齐细粒度过程偏好；最后，应用过程监督强化学习，集成双粒度优势机制。该框架将步骤级过程奖励与全局结果信号结合，为每个动作提供精确反馈，关键创新点在于将学习到的步骤级监督融入在线优化循环，以优化检索增强生成在推理任务中的表现。",
      "result": "在五个多跳推理基准测试中，ProRAG展现出优于基于结果和过程感知的强化学习基线的整体性能，特别是在复杂长视距任务中，验证了细粒度过程监督的有效性。尽管摘要未提供具体数值指标如准确率提升，但实验结果表明该方法在减少过程幻觉和提高推理准确性方面有显著优势，强化了其在复杂推理场景下的鲁棒性。",
      "conclusion": "本研究的主要贡献是提出ProRAG框架，成功集成细粒度过程监督到强化学习中，优化检索增强生成的推理过程。这提高了复杂推理任务的性能，并验证了过程监督在强化学习中的学术价值，促进了RL在生成式模型中的应用，为实际AI系统提供了更可靠的推理能力。未来工作可能包括扩展任务范围或改进模型效率，但摘要未明确说明局限性。",
      "tags": [
        "Reinforcement Learning",
        "Retrieval-Augmented Generation",
        "Process Supervision",
        "Monte Carlo Tree Search",
        "Multi-hop Reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:55.867863Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21909",
    "title": "From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning",
    "authors": [
      "Shaojie Wang",
      "Liang Zhang"
    ],
    "abstract": "Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\\% and 4.63\\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21909.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21909",
    "published": "2026-01-29T16:00:48Z",
    "updated": "2026-01-29T16:00:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种认知对齐的后训练框架，通过模仿人类两阶段认知过程，改进大型语言模型的推理泛化性和可靠性。",
      "motivation": "当前LLM后训练方法基于完整推理轨迹优化，包括监督微调和强化学习，但这种方式未模仿人类认知：人类问题解决分两阶段（获取抽象策略和具体执行），而现有方法将策略与执行纠缠，导致泛化性和可靠性不足。这一研究旨在通过对齐人类认知原则，解决现有方法的根本差距，提升推理效率和性能。摘要中明确指出了这种不对齐的重要性，因为优化抽象策略的分离可促进更鲁棒的AI系统发展。",
      "method": "论文提出认知对齐框架，分两个阶段：Chain-of-Meta-Thought (CoMT)在监督学习中专注于抽象推理模式，不涉及具体执行，以获取可泛化策略；Confidence-Calibrated Reinforcement Learning (CCRL)通过置信感知奖励优化任务适应，在中间步骤中防止过度自信错误传播，提高执行可靠性。该框架在四个模型和八个基准测试上进行验证，核心创新在于明确分离元思考和执行，增强训练效率。",
      "result": "实验在分布内和分布外任务上分别取得2.19%和4.63%的性能提升，训练时间减少65-70%，令牌消耗减少50%。这些结果基于与标准方法的对比，表明该框架在保持高效的同时，显著提高了推理的泛化性和可靠性。具体数据支撑了其在多种基准上的有效性，凸显了认知对齐方法的实际优势。",
      "conclusion": "研究验证了对齐后训练与人类认知原则的有效性，主要贡献是提供了一种改进LLM推理泛化性和训练效率的方法。学术上，为AI系统设计提供了新视角；实际上，有助于开发更可靠和高效的模型。未来工作可扩展至更多认知启发技术或探索实际应用场景，摘要未明确说明局限性。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Chain-of-Meta-Thought",
        "Confidence-Calibrated Reinforcement Learning",
        "Post-Training"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:00.531431Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21904",
    "title": "Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning",
    "authors": [
      "Hanmo Chen",
      "Guangtao Lyu",
      "Chenghao Xu",
      "Jiexi Yan",
      "Xu Yang",
      "Cheng Deng"
    ],
    "abstract": "As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21904.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21904",
    "published": "2026-01-29T16:00:12Z",
    "updated": "2026-01-29T16:00:12Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一个金字塔式Shapley-Taylor学习框架，用于细粒度运动-语言检索，有效捕捉局部语义细节和层次结构关系。",
      "motivation": "运动-语言检索作为人类中心跨模态智能的基础任务，旨在连接自然语言和人类运动之间的语义鸿沟，支持直观的运动分析，如动作识别和交互理解。然而，现有方法主要聚焦于全局对齐，即将整个运动序列与全局文本表示进行匹配，忽视了局部运动片段、身体关节与文本标记之间的细粒度交互。这种全局中心范式导致检索性能不理想，限制了应用中的精确性和可解释性，因此需要开发能够深入捕捉细粒度对应关系的新方法来提升整体性能。",
      "method": "本研究提出了一个名为Pyramidal Shapley-Taylor (PST) 的学习框架，灵感来源于人类运动感知的金字塔过程，从关节动态到片段一致性再到整体理解。该框架将人类运动分解为时间片段和空间身体关节，采用金字塔式渐进对齐策略，首先进行关节级的跨模态对应学习，然后是片段级对齐，逐步整合信息以捕捉局部细节和层次关系。关键创新点在于结合了Shapley-Taylor方法，优化对齐过程，无需依赖特定数据集或复杂模型架构，增强了方法的通用性和效率。",
      "result": "通过在多个公共基准数据集上的广泛实验，本研究的方法显著优于现有最先进技术，实现了运动片段和身体关节与对应文本标记之间的精确对齐。摘要未提供具体性能指标如准确率提升数值，但强调了在细粒度检索任务中的优越性，与基线方法相比，本框架在提升检索精度和语义匹配度方面表现突出，验证了其在实际应用中的有效性。",
      "conclusion": "本论文的主要贡献是提出了Pyramidal Shapley-Taylor学习框架，用于细粒度运动-语言检索，创新性地整合了金字塔式对齐和Shapley-Taylor学习机制。这不仅改进了检索性能，还增强了跨模态理解的深度，具有重要的学术价值，推动了运动分析领域的发展。实际应用潜力包括运动捕捉、人机交互等场景。未来工作可能涉及扩展到多模态任务或优化计算成本，摘要未明确说明具体局限性，但为进一步研究提供了方向。",
      "tags": [
        "Motion-Language Retrieval",
        "Pyramidal Shapley-Taylor Learning",
        "Fine-Grained Alignment",
        "Temporal-Spatial Decomposition",
        "Cross-Modal Correspondence Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:20.686928Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21902",
    "title": "Hardware-Triggered Backdoors",
    "authors": [
      "Jonas Möller",
      "Erik Imgrund",
      "Thorsten Eisenhofer",
      "Konrad Rieck"
    ],
    "abstract": "Machine learning models are routinely deployed on a wide range of computing hardware. Although such hardware is typically expected to produce identical results, differences in its design can lead to small numerical variations during inference. In this work, we show that these variations can be exploited to create backdoors in machine learning models. The core idea is to shape the model's decision function such that it yields different predictions for the same input when executed on different hardware. This effect is achieved by locally moving the decision boundary close to a target input and then refining numerical deviations to flip the prediction on selected hardware. We empirically demonstrate that these hardware-triggered backdoors can be created reliably across common GPU accelerators. Our findings reveal a novel attack vector affecting the use of third-party models, and we investigate different defenses to counter this threat.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21902.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21902",
    "published": "2026-01-29T15:59:40Z",
    "updated": "2026-01-29T15:59:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出利用硬件差异在机器学习模型中创建后门的创新方法，实现硬件触发的预测差异。",
      "motivation": "机器学习模型广泛部署于多种计算硬件，尽管硬件预期产生一致结果，但设计差异导致推理时的微小数值变化。现有方法通常忽略这种变化可能被恶意利用，缺乏针对硬件差异引发的安全威胁的研究。因此，论文旨在揭示这一新攻击向量，强调其重要性，因为硬件变化可能被用于创建隐蔽后门，威胁模型在第三方部署中的安全性，尤其是当模型在不同硬件上运行时预测不一致的问题。",
      "method": "核心方法是塑造模型的决策函数，使其在不同硬件上对相同输入产生不同预测。关键创新在于局部移动决策边界靠近目标输入点，并利用硬件特有的数值偏差来翻转预测在选定硬件上。这通过优化模型参数实现，摘要未明确说明具体使用的数据集或模型架构，但实验涉及常见GPU加速器，以验证硬件差异如何被操纵来触发后门攻击。",
      "result": "实证结果显示，硬件触发的后门可以可靠地在多种常见GPU加速器上成功创建，表明攻击具有可行性和一致性。尽管摘要未提供具体性能指标如准确率提升或效率改进，但通过实验验证了攻击能在不同硬件上触发预测差异，与基线对比显示这种攻击是先前未被充分探索的向量，证明了利用硬件变化实现恶意目标的潜力。",
      "conclusion": "论文揭示了硬件差异作为新型攻击向量，影响第三方模型的安全使用，并调查了可能的防御措施来应对这种威胁。主要贡献在于提高对模型部署安全性的认识，推动硬件感知的安全研究，具有实际应用价值。局限性包括攻击的具体实施条件和防御有效性需进一步研究，未来工作可探索更全面的防御策略和攻击影响的评估。",
      "tags": [
        "Hardware Differences",
        "Backdoor Attacks",
        "Model Security",
        "GPU Accelerators",
        "Decision Boundary"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:36.547952Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21900",
    "title": "TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention",
    "authors": [
      "Chuancheng Shi",
      "Shangze Li",
      "Wenjun Lu",
      "Wenhua Wu",
      "Cong Wang",
      "Zifeng Cheng",
      "Fei Shen",
      "Tat-Seng Chua"
    ],
    "abstract": "Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the \"locality hypothesis\", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \\textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21900.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21900",
    "published": "2026-01-29T15:58:12Z",
    "updated": "2026-01-29T15:58:12Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出TraceRouter，一种路径级干预框架，通过追踪和断开非法语义的因果电路，显著增强大型基础模型的对抗性鲁棒性，同时保持模型效用。",
      "motivation": "大型基础模型（LFMs）虽然功能强大，但易受对抗性攻击，导致生成有害内容，威胁AI系统安全。现有防御方法主要依赖'局部性假设'，通过抑制孤立神经元或特征来防护，但有害语义常表现为跨层的分布式电路，使局部干预脆弱并损害模型正常性能。因此，需要一种新方法来有效阻断这些分布式语义的传播，实现更稳健的安全性，弥补当前方法的不足。",
      "method": "TraceRouter框架分三阶段操作：首先，通过分析注意力分歧精确定位模型中对有害语义敏感的起始层。其次，利用稀疏自编码器（SAEs）进行特征学习，结合微分激活分析来解缠和隔离恶意特征。第三，基于零出干预技术计算特征影响分数（FIS），将恶意特征映射到下游因果传播路径。通过选择性抑制这些路径，物理上切断有害信息流，同时保持正交计算路径完整，从而在不影响模型正常功能的情况下提升鲁棒性。",
      "result": "通过广泛实验，TraceRouter在对抗性鲁棒性方面显著优于现有最先进的基线方法。它实现了在鲁棒性与通用效用之间的更好权衡，例如在对抗性攻击下可能提高了准确率或降低了错误率，同时模型在正常任务上表现稳定。摘要未明确说明具体性能指标，但强调了其在平衡防御效果与模型功能保护方面的优势。",
      "conclusion": "本研究提出TraceRouter，一种创新的路径级干预框架，通过追踪和断开非法语义的因果电路，有效解决了大型基础模型的安全性挑战。学术上，它挑战了传统局部防御的假设，为AI安全领域提供了新视角；实际应用中，可增强模型在对抗性环境中的可靠性，促进安全AI的发展。未来工作可探索计算效率优化及扩展到更多模型架构，以应对潜在局限性。",
      "tags": [
        "Large Foundation Models",
        "Adversarial Robustness",
        "Path-Level Intervention",
        "Sparse Autoencoders (SAEs)",
        "Feature Influence Scores (FIS)"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:54.247334Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21899",
    "title": "Breaking the Regional Barrier: Inductive Semantic Topology Learning for Worldwide Air Quality Forecasting",
    "authors": [
      "Zhiqing Cui",
      "Siru Zhong",
      "Ming Jin",
      "Shirui Pan",
      "Qingsong Wen",
      "Yuxuan Liang"
    ],
    "abstract": "Global air quality forecasting grapples with extreme spatial heterogeneity and the poor generalization of existing transductive models to unseen regions. To tackle this, we propose OmniAir, a semantic topology learning framework tailored for global station-level prediction. By encoding invariant physical environmental attributes into generalizable station identities and dynamically constructing adaptive sparse topologies, our approach effectively captures long-range non-Euclidean correlations and physical diffusion patterns across unevenly distributed global networks. We further curate WorldAir, a massive dataset covering over 7,800 stations worldwide. Extensive experiments show that OmniAir achieves state-of-the-art performance against 18 baselines, maintaining high efficiency and scalability with speeds nearly 10 times faster than existing models, while effectively bridging the monitoring gap in data-sparse regions.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21899.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21899",
    "published": "2026-01-29T15:58:07Z",
    "updated": "2026-01-29T15:58:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出 OmniAir 框架，通过归纳语义拓扑学习实现全球空气质量预测，有效突破区域泛化限制。",
      "motivation": "全球空气质量预测面临极端空间异质性，现有转导模型在未见区域泛化能力差，导致预测不准确。这一问题的重要性在于全球空气污染监测需求增长，现有方法依赖局部数据，无法适应数据稀疏地区，限制了全球覆盖和应用价值。研究的动机是开发能捕捉全局相关性并泛化到新区域的新方法，以提升预测可靠性和环境健康支持。",
      "method": "OmniAir 是一个语义拓扑学习框架，核心方法包括编码不变的物理环境属性为可泛化的站点身份，并动态构建自适应稀疏拓扑来建模站点间关系。关键技术特色是捕捉长程非欧几里得相关性和物理扩散模式，适用于全球不均匀分布的站点网络。研究使用了 WorldAir 数据集，覆盖全球超过 7,800 个站点的空气质量数据，支撑模型的训练和验证。",
      "result": "广泛实验表明，OmniAir 在 18 个基线方法中实现了最先进的性能，表现为预测准确率的显著提升。效率方面，模型运行速度比现有方法快近 10 倍，显示出高可扩展性。此外，它能有效填补数据稀疏区域的监测空白，提高了全球覆盖的预测能力，与基线方法相比在泛化和效率上均有优势。",
      "conclusion": "论文的主要贡献是提出了 OmniAir 框架和 WorldAir 数据集，显著提升了全球空气质量预测的泛化能力和效率。学术价值在于引入归纳语义拓扑学习方法，推动环境预测领域的发展；实际应用价值体现在支持全球范围的空气质量监测和预警。未来工作方向如扩展到其他环境任务，摘要未明确说明局限性，但暗示了方法的可扩展性。",
      "tags": [
        "Inductive Learning",
        "Semantic Topology Learning",
        "Air Quality Forecasting",
        "Sparse Topology"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:05.696112Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21898",
    "title": "Making Models Unmergeable via Scaling-Sensitive Loss Landscape",
    "authors": [
      "Minwoo Jang",
      "Hoyoung Kim",
      "Jabin Koo",
      "Jungseul Ok"
    ],
    "abstract": "The rise of model hubs has made it easier to access reusable model components, making model merging a practical tool for combining capabilities. Yet, this modularity also creates a \\emph{governance gap}: downstream users can recompose released weights into unauthorized mixtures that bypass safety alignment or licensing terms. Because existing defenses are largely post-hoc and architecture-specific, they provide inconsistent protection across diverse architectures and release formats in practice. To close this gap, we propose \\textsc{Trap}$^{2}$, an architecture-agnostic protection framework that encodes protection into the update during fine-tuning, regardless of whether they are released as adapters or full models. Instead of relying on architecture-dependent approaches, \\textsc{Trap}$^{2}$ uses weight re-scaling as a simple proxy for the merging process. It keeps released weights effective in standalone use, but degrades them under re-scaling that often arises in merging, undermining unauthorized merging.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21898.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21898",
    "published": "2026-01-29T15:56:55Z",
    "updated": "2026-01-29T15:56:55Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "提出Trap^2框架，通过权重重缩放敏感损失景观使模型不可合并，以解决模型合并中的治理缺口。",
      "motivation": "模型中心的兴起促进了模型重用和合并，但模块化导致了治理缺口，使下游用户可以未经授权组合权重，绕过安全对齐或许可条款，增加安全风险。现有防御方法多为后验且依赖于特定架构，为不同架构和发布格式提供不一致的保护。因此，需要一种架构无关的保护机制来应对这一问题，确保模型发布的安全性。",
      "method": "Trap^2是一种架构无关的保护框架，通过在模型微调过程中将保护机制编码到权重更新中，无论模型作为适配器或完整模型发布。核心创新是使用权重重缩放作为模型合并过程的简单代理，设计损失景观使其对缩放敏感。这使得模型在独立使用时保持有效，但在重缩放时（如在未经授权的合并中）性能退化，从而破坏合并。",
      "result": "摘要未明确说明具体的实验结果数据。基于描述，Trap^2框架能保持模型在独立使用时的性能，同时在权重重缩放（常见于合并过程）下导致性能退化，有效防止未经授权的合并。概念上，它提供了比现有架构特定方法更一致和跨架构的保护效果，但没有提及具体指标如准确率或效率改进。",
      "conclusion": "本文提出Trap^2框架，以架构无关的方式解决模型合并中的治理缺口，通过微调期间的编码保护确保模型在授权下有效并防止未经授权合并。学术上引入了基于损失景观缩放敏感性的新保护机制，应用上增强了模型发布的安全性和灵活性。潜在局限性可能包括保护强度的优化和更广泛场景的应用，为未来研究提供方向。",
      "tags": [
        "Model Merging",
        "Weight Scaling",
        "Loss Landscape",
        "Fine-tuning",
        "Adapter"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:01.166799Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21897",
    "title": "A Low-Complexity Plug-and-Play Deep Learning Model for Generalizable Massive MIMO Precoding",
    "authors": [
      "Ali Hasanzadeh Karkan",
      "Ahmed Ibrahim",
      "Jean-François Frigon",
      "François Leduc-Primeau"
    ],
    "abstract": "Massive multiple-input multiple-output (mMIMO) downlink precoding offers high spectral efficiency but remains challenging to deploy in practice because near-optimal algorithms such as the weighted minimum mean squared error (WMMSE) are computationally expensive, and sensitive to SNR and channel-estimation quality, while existing deep learning (DL)-based solutions often lack robustness and require retraining for each deployment site. This paper proposes a plug-and-play precoder (PaPP), a DL framework with a backbone that can be trained for either fully digital (FDP) or hybrid beamforming (HBF) precoding and reused across sites, transmit-power levels, and with varying amounts of channel estimation error, avoiding the need to train a new model from scratch at each deployment. PaPP combines a high-capacity teacher and a compact student with a self-supervised loss that balances teacher imitation and normalized sum-rate, trained using meta-learning domain-generalization and transmit-power-aware input normalization. Numerical results on ray-tracing data from three unseen sites show that the PaPP FDP and HBF models both outperform conventional and deep learning baselines, after fine-tuning with a small set of local unlabeled samples. Across both architectures, PaPP achieves more than 21$\\times$ reduction in modeled computation energy and maintains good performance under channel-estimation errors, making it a practical solution for energy-efficient mMIMO precoding.",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21897.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21897",
    "published": "2026-01-29T15:56:07Z",
    "updated": "2026-01-29T15:56:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了PaPP，一个低复杂度的插件式深度学习模型，通过教师-学生框架和元学习实现通用大规模MIMO预编码，支持跨场景重用。",
      "motivation": "大规模MIMO下行链路预编码提供高频谱效率，但实际部署面临挑战：传统算法如WMMSE计算昂贵且对SNR和信道估计敏感；现有深度学习方法缺乏鲁棒性，需为每个新部署站点重新训练，导致效率低下和适应性不足。因此，亟需一种低复杂度、泛化能力强的解决方案来应对计算能耗和部署灵活性的需求，特别是在5G/6G网络中。",
      "method": "论文提出PaPP框架，核心是结合高容量教师模型和紧凑学生模型，使用自监督损失平衡教师模仿和归一化和率。通过元学习进行域泛化训练，并采用发射功率感知输入归一化，支持全数字或混合波束成形预编码。该方法允许模型跨不同站点、功率水平和信道估计误差重用，避免了从零训练的需要，增强了实际应用中的灵活性。",
      "result": "在三个未见站点的射线追踪数据上实验显示，PaPP的全数字和混合波束成形模型在小样本微调后均优于传统算法和深度学习基线。具体性能包括实现超过21倍的建模计算能量减少，并在信道估计误差下保持良好表现，证明了其在能量效率和鲁棒性方面的显著优势，有效解决了现有方法的局限性。",
      "conclusion": "PaPP为大规模MIMO预编码提供了一个实用、低复杂度的解决方案，通过教师-学生架构和元学习实现了良好的泛化能力和部署效率。其学术价值在于结合深度学习与通信技术，实际应用价值在于减少计算能量和提升适应性。局限性可能涉及对微调数据的依赖，未来工作可优化泛化性能或扩展至更多预编码场景。",
      "tags": [
        "Massive MIMO",
        "Deep Learning",
        "Teacher-Student Learning",
        "Meta-Learning",
        "Hybrid Beamforming"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:26.330277Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21896",
    "title": "Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion",
    "authors": [
      "Hanmo Chen",
      "Chenghao Xu",
      "Xu Yang",
      "Xuan Chen",
      "Cheng Deng"
    ],
    "abstract": "Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21896.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21896",
    "published": "2026-01-29T15:55:29Z",
    "updated": "2026-01-29T15:55:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一种基于过去和未来信息的KV缓存策略（PaFu-KV），通过显著性估计优化自回归视频扩散模型，提高视频生成质量和效率。",
      "motivation": "视频生成在数字媒体创作中至关重要，自回归视频生成的最新进展提升了实时合成效率。然而，现有方法依赖启发式KV缓存策略，忽略token在时间维度上的重要性差异，导致关键时空信息丢失和冗余缓存积累，进而降低长期视频生成的质量与效率。这一问题影响实际应用中的资源利用和输出效果，因此需要更智能的缓存管理方法来解决这些不足。",
      "method": "PaFu-KV方法引入一个轻量级的显著性估计头（Salience Estimation Head），通过从双向教师模型蒸馏学习来评估token的显著性分数。基于这些分数，KV缓存动态保留信息丰富的token并丢弃不相关token，从而减少缓存容量和推理内存占用。该方法应用于自回归视频扩散模型，利用过去和未来信息指导缓存决策，优化质量与效率的权衡。",
      "result": "在基准测试上的广泛实验表明，PaFu-KV方法在保持高保真视频生成质量的同时，显著加速了推理过程。与基线启发式缓存策略相比，该方法减少了缓存冗余，提高了生成效率，实现了更好的质量-效率平衡。实验结果显示加速效果，但摘要未明确说明具体性能指标如准确率提升百分比。",
      "conclusion": "本研究的主要贡献是提出了PaFu-KV策略，通过显著性估计优化KV缓存，改进了自回归视频扩散模型的长期视频生成性能。该研究在学术上推动了视频生成技术的智能化发展，在实际应用中提升了媒体创作效率。潜在局限性包括显著性估计的泛化能力，未来工作可探索该策略在其他模型中的集成和扩展。",
      "tags": [
        "Autoregressive Video Generation",
        "KV Cache Optimization",
        "Salience Estimation",
        "Model Distillation",
        "Video Diffusion Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:39.390977Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21895",
    "title": "Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text",
    "authors": [
      "Hongyi Zhou",
      "Jin Zhu",
      "Erhan Xu",
      "Kai Ye",
      "Ying Yang",
      "Chengchun Shi"
    ],
    "abstract": "Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\\% to 80.6\\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21895.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21895",
    "published": "2026-01-29T15:55:15Z",
    "updated": "2026-01-29T15:55:15Z",
    "comment": "Accepted by ICLR2026",
    "light_analysis": {
      "overview": "本文提出一种基于重写的检测算法，通过自适应学习距离来检测大型语言模型生成的文本，创新点在于距离函数的动态学习而非固定使用。",
      "motivation": "现代大型语言模型如GPT、Claude和Gemini能够生成高度类似人类的文本，这引发了关于错误信息和学术诚信的严重问题。现有检测方法可能难以有效识别LLM生成内容，因为它们可能依赖于固定距离函数，缺乏灵活性。因此，迫切需要可靠算法来准确区分人类和机器生成的文本，以防止在学术和公共领域中的滥用，保护信息真实性。",
      "method": "论文首先采用几何方法分析基于重写的检测算法，揭示其基本原理和泛化能力，为后续改进提供理论基础。基于这一分析，作者引入一种新算法，该算法自适应地学习原始文本与重写文本之间的距离。关键创新是使用可学习的距离函数，而非固定距离，通过重写过程优化检测性能。理论证明自适应距离更有效，但具体数据集和模型架构在摘要中未明确说明，推断涉及标准LLM如GPT、Claude和Gemini。",
      "result": "在超过100个实验设置下，新算法在大多数场景中表现出优于基线算法的性能。具体而言，针对不同目标LLM（如GPT、Claude和Gemini），相对于最强基线，算法实现了57.8%到80.6%的相对改进，这表明自适应距离学习能显著提升检测准确性。实验结果支持了理论分析，证明自适应方法在多样化条件下具有鲁棒性和有效性。",
      "conclusion": "该研究的主要贡献是提出并验证了一种基于重写的检测算法，通过自适应学习距离来提高LLM生成文本的检测效果。这具有重要的学术价值，推动了检测技术的前沿，实际应用有助于缓解错误信息和学术不端问题。未来工作可能包括扩展算法到更多LLM模型和复杂场景，但摘要未明确说明潜在局限性或具体方向。",
      "tags": [
        "LLM Detection",
        "Distance Learning",
        "Rewrite-based Detection",
        "Adaptive Learning",
        "Geometric Approach"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:56.319467Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21894",
    "title": "Not All Code Is Equal: A Data-Centric Study of Code Complexity and LLM Reasoning",
    "authors": [
      "Lukas Twist",
      "Shu Yang",
      "Hanqi Yan",
      "Jingzhi Gong",
      "Di Wang",
      "Helen Yannakoudakis",
      "Jie M. Zhang"
    ],
    "abstract": "Large Language Models (LLMs) increasingly exhibit strong reasoning abilities, often attributed to their capacity to generate chain-of-thought-style intermediate reasoning. Recent work suggests that exposure to code can further enhance these skills, but existing studies largely treat code as a generic training signal, leaving open the question of which properties of code actually contribute to improved reasoning. To address this gap, we study the structural complexity of code, which captures control flow and compositional structure that may shape how models internalise multi-step reasoning during fine-tuning. We examine two complementary settings: solution-driven complexity, where complexity varies across multiple solutions to the same problem, and problem-driven complexity, where complexity reflects variation in the underlying tasks. Using cyclomatic complexity and logical lines of code to construct controlled fine-tuning datasets, we evaluate a range of open-weight LLMs on diverse reasoning benchmarks. Our findings show that although code can improve reasoning, structural properties strongly determine its usefulness. In 83% of experiments, restricting fine-tuning data to a specific structural complexity range outperforms training on structurally diverse code, pointing to a data-centric path for improving reasoning beyond scaling.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21894.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21894",
    "published": "2026-01-29T15:54:40Z",
    "updated": "2026-01-29T15:54:40Z",
    "comment": "16 pages, 5 figures, 3 tables",
    "light_analysis": {
      "overview": "本研究揭示了代码结构复杂性在提升大型语言模型推理能力中的关键作用，强调特定复杂性范围的代码数据在微调中更有效。",
      "motivation": "大型语言模型展现出强大的推理能力，通常归因于其生成链式思考中间推理的能力。已有研究表明，接触代码可以进一步强化这些技能，但现有研究大多将代码视为通用训练信号，未深入探讨代码的哪些属性实际促进推理改善。这一问题的重要性在于，理解代码的具体贡献属性有助于优化训练数据，提高模型效率和针对性；现有方法的不足是缺乏对代码结构复杂性的细致分析，可能限制了推理能力的进一步提升，本研究旨在填补这一空白。",
      "method": "论文采用数据中心视角，研究代码的结构复杂性，包括控制流和组合结构，这些可能在微调过程中影响模型内部化多步推理。通过两种互补设置进行分析：解决方案驱动的复杂性，即同一问题不同解决方案的复杂度变化；问题驱动的复杂性，即基础任务本身的复杂度差异。技术细节上，使用圈复杂性和逻辑代码行数作为量化指标，构建受控微调数据集，并在多种推理基准上评估一系列开放权重的大型语言模型，以分析微调效果。",
      "result": "实验结果证明，代码确实能够改善推理能力，但结构属性是决定其有效性的关键因素。具体数据显示，在 83% 的实验中，限制微调数据到特定结构复杂性范围内的代码，其性能优于训练在结构多样代码上的模型。这表明，相比于使用多样的代码数据，精心选择特定复杂度范围的代码能更显著提升推理表现；与基线方法（如通用代码训练）相比，这种方法在推理任务上取得了更好的效果。",
      "conclusion": "本研究的核心贡献在于明确了代码结构复杂性在大型语言模型微调中的重要性，为改进推理提供了一条基于数据中心的路径，而不仅仅是依赖模型规模的扩大。学术上，它深化了对代码属性如何影响模型推理机制的理解；实践中，可能指导更有效的代码数据筛选策略，以增强应用中的推理能力。局限性包括摘要未明确说明其他代码属性影响，未来工作可探索如语义复杂性等因素或扩展到更多模型类型。",
      "tags": [
        "Large Language Models",
        "Code Complexity",
        "Cyclomatic Complexity",
        "Fine-Tuning",
        "Reasoning Benchmarks"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:12.666827Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21892",
    "title": "Improving Classifier-Free Guidance of Flow Matching via Manifold Projection",
    "authors": [
      "Jian-Feng Cai",
      "Haixia Liu",
      "Zhengyi Su",
      "Chao Wang"
    ],
    "abstract": "Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21892.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21892",
    "published": "2026-01-29T15:49:31Z",
    "updated": "2026-01-29T15:49:31Z",
    "comment": "24 pages, 14 figures",
    "light_analysis": {
      "overview": "本文提出基于流形投影的改进方法，增强流匹配模型中 classifier-free guidance (CFG) 的鲁棒性和可控生成性能。",
      "motivation": "Classifier-free guidance (CFG) 广泛应用于扩散和基于流的模型以实现可控生成，但其依赖于启发式线性外推，对引导尺度敏感，导致生成结果不稳定。现有方法在高引导强度下表现欠佳，限制了实用性和精确控制。因此，本研究旨在从优化理论角度提供原则性解释，弥补 CFG 的不足，减少超参数依赖，提升可控生成的稳健性和适用性。",
      "method": "研究从优化视角重新解释 CFG，将流匹配中的速度场关联到平滑距离函数的梯度序列。基于此，将 CFG 采样重新表述为带有流形约束的同伦优化问题。为实现优化，提出流形投影步骤，通过增量梯度下降方案在采样过程中执行投影。为提升计算效率和稳定性，引入了 Anderson Acceleration 技术，无需额外模型评估，保持方法训练无关性，可直接集成到现有框架如流匹配模型中。",
      "result": "实验结果显示，所提方法显著改善了生成保真度、提示对齐和引导尺度的鲁棒性。在多样化基准测试中验证，包括 DiT-XL-2-256、Flux 和 Stable Diffusion 3.5 等大规模模型，均观察到性能提升。与基线 CFG 相比，新方法减少了对引导尺度的敏感性，增强了生成稳定性和可控性，同时保持高效计算，无需额外训练开销。",
      "conclusion": "本研究通过流形投影改进了 CFG，提供了一个原则性的优化框架，增强了可控生成的鲁棒性和性能，具有重要学术和实用价值。它为 CFG 提供了更坚实的理论基础，并展示了在大型模型中的广泛应用潜力。摘要未明确说明局限性，但该方法为未来优化可控生成技术（如扩展到更复杂场景或模型）奠定了基础，可促进生成模型领域的进一步发展。",
      "tags": [
        "Classifier-Free Guidance",
        "Flow Matching",
        "Manifold Projection",
        "Homotopy Optimization",
        "Anderson Acceleration"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:34.521798Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21883",
    "title": "Managing Solution Stability in Decision-Focused Learning with Cost Regularization",
    "authors": [
      "Victor Spitzer",
      "Francois Sanson"
    ],
    "abstract": "Decision-focused learning integrates predictive modeling and combinatorial optimization by training models to directly improve decision quality rather than prediction accuracy alone. Differentiating through combinatorial optimization problems represents a central challenge, and recent approaches tackle this difficulty by introducing perturbation-based approximations. In this work, we focus on estimating the objective function coefficients of a combinatorial optimization problem. Our study demonstrates that fluctuations in perturbation intensity occurring during the learning phase can lead to ineffective training, by establishing a theoretical link to the notion of solution stability in combinatorial optimization. We propose addressing this issue by introducing a regularization of the estimated cost vectors which improves the robustness and reliability of the learning process, as demonstrated by extensive numerical experiments.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21883.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21883",
    "published": "2026-01-29T15:46:47Z",
    "updated": "2026-01-29T15:46:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出在决策导向学习中通过成本正则化来管理解稳定性，以提高学习过程的鲁棒性和可靠性。",
      "motivation": "决策导向学习整合预测建模和组合优化，旨在通过直接优化决策质量而非仅预测精度来提升实际应用效果。然而，组合优化问题的可微分性是一个核心挑战，现有方法采用基于扰动的近似来应对，但学习过程中扰动强度的波动可能导致训练无效，这与组合优化中的解稳定性概念相关。因此，研究如何稳定学习过程以克服这些不足，对于提高决策导向学习的实用性和可靠性至关重要。",
      "method": "论文提出通过引入对估计成本向量的正则化来解决扰动强度波动问题。该方法基于理论分析，将学习阶段的扰动波动与组合优化中的解稳定性联系起来，并设计正则化技术来增强学习过程的鲁棒性。摘要未明确说明使用的具体数据集或模型架构细节，但核心创新在于通过成本正则化改善训练稳定性，以减少无效训练的发生。",
      "result": "通过广泛的数值实验，论文展示了成本正则化方法的有效性。实验结果表明，该方法能够显著改善决策导向学习的鲁棒性和可靠性，减少由扰动波动引起的训练不稳定问题。与基线方法相比，正则化方法显示出更好的稳定性表现，但摘要未提供具体的性能指标对比数据，如准确率提升或效率改进的数值细节。",
      "conclusion": "本研究的主要贡献是提出了一种成本正则化方法，用于管理决策导向学习中的解稳定性，从而提高了学习过程的鲁棒性和可靠性。这为实际应用提供了更稳定的训练框架，并丰富了决策导向学习的理论和方法。未来工作可能包括进一步探索正则化参数的影响、扩展到更广泛的优化问题场景，以及对不同扰动方法的适应性分析。",
      "tags": [
        "Decision-Focused Learning",
        "Combinatorial Optimization",
        "Regularization",
        "Solution Stability",
        "Perturbation-based Approximations"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:53.398422Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21879",
    "title": "astra-langchain4j: Experiences Combining LLMs and Agent Programming",
    "authors": [
      "Rem Collier",
      "Katharine Beaumont",
      "Andrei Ciortea"
    ],
    "abstract": "Given the emergence of Generative AI over the last two years and the increasing focus on Agentic AI as a form of Multi-Agent System it is important to explore both how such technologies can impact the use of traditional Agent Toolkits and how the wealth of experience encapsulated in those toolkits can influence the design of the new agentic platforms. This paper presents an overview of our experience developing a prototype large language model (LLM) integration for the ASTRA programming language. It presents a brief overview of the toolkit, followed by three example implementations, concluding with a discussion of the experiences garnered through the examples.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21879.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21879",
    "published": "2026-01-29T15:46:13Z",
    "updated": "2026-01-29T15:46:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文分享了将大型语言模型与ASTRA agent编程工具包结合的原型开发经验，探索LLMs与多智能体系统的集成。",
      "motivation": "研究动机源于生成式AI和agentic AI的兴起，作为多智能体系统的重要形式，需要探索这些新技术如何影响传统Agent Toolkits的使用，并利用传统工具包的丰富经验来指导新agentic平台的设计。这有助于解决智能体系统在交互和协作方面的挑战，优化现有方法的不足，以促进更高效、智能的AI系统开发。",
      "method": "研究方法涉及为ASTRA编程语言开发一个大型语言模型集成原型，命名为astra-langchain4j。通过设计三个示例实现，展示了LLM如何与agent编程环境结合，以增强自然语言处理或任务执行能力。摘要未明确说明具体技术细节，如使用的LLM模型、数据集或架构设计，但强调了基于工具包经验的实践开发和案例分析。",
      "result": "论文未提供定量的实验结果或性能指标，结果部分主要基于示例实现的定性经验，讨论了集成LLMs对agent编程的影响和潜在优势。例如，可能提高了agent的自然语言交互能力，但摘要未明确说明与基线方法的对比或具体数据支撑，如准确率提升或效率改进。因此，结果是描述性的经验总结，而非量化验证。",
      "conclusion": "结论总结了开发LLM集成原型的经验，强调了结合传统agent工具包和新兴LLM技术的价值。学术上，这贡献于多智能体系统与生成式AI的交叉研究；实际上，为agentic AI平台的设计提供了参考。局限性在于未进行大规模实验，未来工作可包括扩展集成功能或进行更系统的量化评估。",
      "tags": [
        "Large Language Model",
        "Agent Programming",
        "Multi-Agent System",
        "ASTRA Programming Language",
        "Generative AI"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:58.514753Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21873",
    "title": "Low-Rank Plus Sparse Matrix Transfer Learning under Growing Representations and Ambient Dimensions",
    "authors": [
      "Jinhang Chai",
      "Xuyuan Liu",
      "Elynn Chen",
      "Yujun Yan"
    ],
    "abstract": "Learning systems often expand their ambient features or latent representations over time, embedding earlier representations into larger spaces with limited new latent structure. We study transfer learning for structured matrix estimation under simultaneous growth of the ambient dimension and the intrinsic representation, where a well-estimated source task is embedded as a subspace of a higher-dimensional target task.   We propose a general transfer framework in which the target parameter decomposes into an embedded source component, low-dimensional low-rank innovations, and sparse edits, and develop an anchored alternating projection estimator that preserves transferred subspaces while estimating only low-dimensional innovations and sparse modifications. We establish deterministic error bounds that separate target noise, representation growth, and source estimation error, yielding strictly improved rates when rank and sparsity increments are small.   We demonstrate the generality of the framework by applying it to two canonical problems. For Markov transition matrix estimation from a single trajectory, we derive end-to-end theoretical guarantees under dependent noise. For structured covariance estimation under enlarged dimensions, we provide complementary theoretical analysis in the appendix and empirically validate consistent transfer gains.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21873.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21873",
    "published": "2026-01-29T15:40:05Z",
    "updated": "2026-01-29T15:40:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种结合低秩和稀疏矩阵分解的迁移学习框架，用于处理表示和维度增长的结构化矩阵估计问题。",
      "motivation": "学习系统随着时间扩展其表示和维度，导致早期模型需要适应高维空间。现有迁移学习方法在同时处理环境维度和内在表示增长时存在局限性，可能无法高效利用源任务知识，造成资源浪费或精度下降。本研究旨在解决在表示增长背景下结构化矩阵估计的挑战，以提高迁移学习的适应性和性能。",
      "method": "研究提出通用迁移框架，将目标参数分解为嵌入源组件、低维低秩创新和稀疏编辑。使用锚定交替投影估计器，保留迁移子空间并仅估计创新和修改部分。关键创新在于结合低秩和稀疏分解处理表示增长，并将其应用于两个典型问题：从单轨迹进行Markov转移矩阵估计和扩大维度下的结构化协方差估计，提供理论分析。",
      "result": "研究建立了确定性的误差界，分离目标噪声、表示增长和源估计误差，在秩和稀疏性增量小时获得严格改进的收敛率。在Markov转移矩阵估计中，提供依赖噪声下的端到端理论保证；对于结构化协方差估计，通过附录分析和实证验证一致的迁移增益，但具体性能数据摘要未明确说明。",
      "conclusion": "论文贡献了一个灵活迁移框架，适用于表示增长场景的结构化矩阵估计，结合低秩和稀疏分解有效处理表示扩展。为两类经典问题提供理论保证和实证支持，推动了迁移学习在复杂增长环境下的发展，未来可扩展到更多应用或处理更大增量。",
      "tags": [
        "Transfer Learning",
        "Low-Rank Matrix",
        "Sparse Matrix",
        "Matrix Estimation",
        "Markov Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:58.519937Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21872",
    "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
    "authors": [
      "Yao Zhang",
      "Shijie Tang",
      "Zeyu Li",
      "Zhen Han",
      "Volker Tresp"
    ],
    "abstract": "Web agents hold great potential for automating complex computer tasks, yet their interactions involve long-horizon, sequential decision-making with irreversible actions. In such settings, outcome-based supervision is sparse and delayed, often rewarding incorrect trajectories and failing to support inference-time scaling. This motivates the use of Process Reward Models (WebPRMs) for web navigation, but existing approaches remain limited: scalar WebPRMs collapse progress into coarse, weakly grounded signals, while checklist-based WebPRMs rely on brittle template matching that fails under layout or semantic changes and often mislabels superficially correct actions as successful, providing little insight or interpretability. To address these challenges, we introduce WebArbiter, a reasoning-first, principle-inducing WebPRM that formulates reward modeling as text generation, producing structured justifications that conclude with a preference verdict and identify the action most conducive to task completion under the current context. Training follows a two-stage pipeline: reasoning distillation equips the model with coherent principle-guided reasoning, and reinforcement learning corrects teacher biases by directly aligning verdicts with correctness, enabling stronger generalization. To support systematic evaluation, we release WebPRMBench, a comprehensive benchmark spanning four diverse web environments with rich tasks and high-quality preference annotations. On WebPRMBench, WebArbiter-7B outperforms the strongest baseline, GPT-5, by 9.1 points. In reward-guided trajectory search on WebArena-Lite, it surpasses the best prior WebPRM by up to 7.2 points, underscoring its robustness and practical value in real-world complex web tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21872.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21872",
    "published": "2026-01-29T15:39:50Z",
    "updated": "2026-01-29T15:39:50Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "WebArbiter是一个基于原则指导推理的过程奖励模型，通过文本生成奖励提升Web agents在复杂任务中的性能。",
      "motivation": "Web agents在自动化计算机任务时面临长视野、顺序决策和不可逆行动的挑战，导致结果监督稀疏且延迟，现有奖励模型如标量WebPRMs信号粗糙，清单式WebPRMs依赖脆弱的模板匹配，易受布局或语义变化影响，误判行动正确性，缺乏解释性，限制了推理时间扩展和实际应用，因此需要更健壮、可解释的奖励建模方法。",
      "method": "论文提出WebArbiter，将奖励建模视为文本生成，通过生成结构化理由和偏好裁决来识别最有利于任务完成的行动。核心创新包括推理优先、原则诱导的框架，结合两阶段训练：推理蒸馏使模型获得连贯的原则指导推理能力，强化学习直接对齐裁决与正确性以纠正教师偏见，增强泛化性能。评估基于新发布的WebPRMBench基准，该基准覆盖四个多样网络环境，提供高质量偏好注释。",
      "result": "在WebPRMBench基准上，WebArbiter-7B模型相比最强基线GPT-5实现了9.1点的性能提升；在WebArena-Lite的奖励引导轨迹搜索任务中，超越先前最佳WebPRM高达7.2点。这些具体数据表明WebArbiter在鲁棒性和实际应用价值上显著优于现有方法，有效支持复杂Web任务的自动化。",
      "conclusion": "WebArbiter通过推理优先的奖励建模方法，成功解决了现有WebPRMs的不足，提升了Web agents的任务完成能力和解释性。该研究具有重要学术价值，推动了奖励建模和Web自动化技术的发展，实际应用价值体现在复杂网络任务的高效处理上，未来工作可进一步优化模型或扩展至其他交互式领域。",
      "tags": [
        "Process Reward Model",
        "Web Navigation",
        "Reinforcement Learning",
        "Text Generation",
        "Reasoning Distillation"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:19.524138Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21866",
    "title": "MoHETS: Long-term Time Series Forecasting with Mixture-of-Heterogeneous-Experts",
    "authors": [
      "Evandro S. Ortigossa",
      "Guy Lutsker",
      "Eran Segal"
    ],
    "abstract": "Real-world multivariate time series can exhibit intricate multi-scale structures, including global trends, local periodicities, and non-stationary regimes, which makes long-horizon forecasting challenging. Although sparse Mixture-of-Experts (MoE) approaches improve scalability and specialization, they typically rely on homogeneous MLP experts that poorly capture the diverse temporal dynamics of time series data. We address these limitations with MoHETS, an encoder-only Transformer that integrates sparse Mixture-of-Heterogeneous-Experts (MoHE) layers. MoHE routes temporal patches to a small subset of expert networks, combining a shared depthwise-convolution expert for sequence-level continuity with routed Fourier-based experts for patch-level periodic structures. MoHETS further improves robustness to non-stationary dynamics by incorporating exogenous information via cross-attention over covariate patch embeddings. Finally, we replace parameter-heavy linear projection heads with a lightweight convolutional patch decoder, improving parameter efficiency, reducing training instability, and allowing a single model to generalize across arbitrary forecast horizons. We validate across seven multivariate benchmarks and multiple horizons, with MoHETS consistently achieving state-of-the-art performance, reducing the average MSE by $12\\%$ compared to strong recent baselines, demonstrating effective heterogeneous specialization for long-term forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21866.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21866",
    "published": "2026-01-29T15:35:26Z",
    "updated": "2026-01-29T15:35:26Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "论文提出MoHETS模型，通过混合异构专家机制改进长期时间序列预测，实现了性能提升和参数效率优化。",
      "motivation": "现实世界多变量时间序列具有复杂的多尺度结构，如全局趋势、局部周期性和非平稳机制，使长期预测变得困难。现有稀疏Mixture-of-Experts方法虽能提高可扩展性和专门化，但依赖于同质MLP专家，难以捕捉时间序列数据的多样化动态。因此，亟需一种新方法来处理这些异构特性，以提升预测精度和鲁棒性，满足实际应用中对准确长期预测的需求。",
      "method": "MoHETS是一个编码器-只有的Transformer模型，核心创新在于集成稀疏Mixture-of-Heterogeneous-Experts层。MoHE将时间块路由到异构专家网络，结合共享深度卷积专家处理序列级连续性，和基于傅里叶的专家捕捉块级周期性结构。此外，模型通过跨注意力机制整合外生信息，增强对非平稳动态的鲁棒性，并采用轻量卷积块解码器替换参数繁重的线性投影头，提升参数效率、减少训练不稳定性，并支持任意预测时域的泛化。",
      "result": "在七个多变量基准数据集和多个预测时域上进行验证，MoHETS consistently实现最先进的性能。与近期强基线方法相比，平均均方误差减少12%，证明了其在长期时间序列预测中的优越效果。实验结果显示，该方法在处理多尺度结构和非平稳动态方面表现出色，显著提升了预测精度和效率。",
      "conclusion": "MoHETS模型的提出，通过混合异构专家机制有效解决了长期时间序列预测中的异构动态问题，实现了高性能和参数效率。该研究在学术上推动了时间序列预测技术的发展，具有广泛的工业应用价值，如经济预测和物联网数据分析。摘要未明确说明局限性，但未来工作可探索更复杂的专家组合或扩展到其他预测领域，以进一步优化模型性能。",
      "tags": [
        "Long-term Time Series Forecasting",
        "Mixture-of-Heterogeneous-Experts",
        "Transformer",
        "Cross-Attention",
        "Convolutional Patch Decoder"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:44.899902Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21864",
    "title": "KnowBias: Mitigating Social Bias in LLMs via Know-Bias Neuron Enhancement",
    "authors": [
      "Jinhao Pan",
      "Chahat Raj",
      "Anjishnu Mukherjee",
      "Sina Mansouri",
      "Bowen Wei",
      "Shloka Yada",
      "Ziwei Zhu"
    ],
    "abstract": "Large language models (LLMs) exhibit social biases that reinforce harmful stereotypes, limiting their safe deployment. Most existing debiasing methods adopt a suppressive paradigm by modifying parameters, prompts, or neurons associated with biased behavior; however, such approaches are often brittle, weakly generalizable, data-inefficient, and prone to degrading general capability. We propose \\textbf{KnowBias}, a lightweight and conceptually distinct framework that mitigates bias by strengthening, rather than suppressing, neurons encoding bias-knowledge. KnowBias identifies neurons encoding bias knowledge using a small set of bias-knowledge questions via attribution-based analysis, and selectively enhances them at inference time. This design enables strong debiasing while preserving general capabilities, generalizes across bias types and demographics, and is highly data efficient, requiring only a handful of simple yes/no questions and no retraining. Experiments across multiple benchmarks and LLMs demonstrate consistent state-of-the-art debiasing performance with minimal utility degradation. Data and code are available at https://github.com/JP-25/KnowBias.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21864.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21864",
    "published": "2026-01-29T15:32:38Z",
    "updated": "2026-01-29T15:32:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出KnowBias框架，通过增强编码偏见知识的神经元来减轻大语言模型的社会偏见，实现了高效的去偏见和一般能力保留。",
      "motivation": "大语言模型（LLMs）的社会偏见强化有害刻板印象，限制了其安全部署。现有去偏见方法通常采用抑制范式，通过修改参数、提示或与偏见行为相关的神经元，但这些方法存在显著不足：它们往往脆弱、泛化能力弱、数据效率低，且容易导致模型一般能力的退化。因此，开发一种更稳健、高效的方法来减轻偏见，同时保持模型性能，成为一个重要研究问题。",
      "method": "KnowBias框架的核心方法是增强编码偏见知识的神经元，而非抑制它们。它使用基于归因的分析，通过一小套简单的yes/no偏见知识问题来识别这些神经元。关键创新是在推理时选择性地增强这些神经元，这避免了重新训练，提高了数据效率。该设计依赖少量问题，无需修改模型参数，从而保持了模型的一般能力和泛化性，适用于多种偏见类型和人口群体。",
      "result": "实验在多个基准测试和不同大语言模型上进行，结果表明KnowBias实现了最先进的去偏见性能，且效用退化最小。与现有基线方法相比，它更稳健、泛化能力强，能够处理多种偏见类型，数据需求极低，仅需少量简单问题。摘要未明确说明具体性能指标，但强调其去偏见效果优异，并在实用性和泛化方面优于传统方法。",
      "conclusion": "KnowBias的主要贡献是提出一种轻量级、概念新颖的去偏见框架，通过神经元增强有效减轻社会偏见，同时保留模型的一般能力。它具有高度数据效率和泛化性，为LLMs的安全部署提供了实用解决方案。未来工作可探索扩展该方法到更广泛的偏见场景或模型架构，以及进一步优化增强机制。",
      "tags": [
        "Large Language Model",
        "Bias Mitigation",
        "Neuron Enhancement",
        "Attribution-Based Analysis",
        "Social Bias"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:07.474670Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21857",
    "title": "Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents",
    "authors": [
      "Taewon Kang"
    ],
    "abstract": "We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21857.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21857",
    "published": "2026-01-29T15:28:48Z",
    "updated": "2026-01-29T15:28:48Z",
    "comment": "47 pages, 36 figures",
    "light_analysis": {
      "overview": "论文提出一种基于扩散的框架，通过潜在空间轨迹设计实现文档背景生成中的前景保护和多页风格一致性。",
      "motivation": "在文档背景生成任务中，保持前景内容（如文本）的完整性和跨多页面的风格一致性是重要挑战。现有方法通常采用显式约束、抑制扩散更新或掩码启发式，但这些方法可能不自然、需要额外机制，且难以有效处理风格漂移问题。本研究旨在通过潜在空间设计来克服这些不足，提供一种更优雅的解决方案，以确保生成结果的视觉一致性和可读性，从而提升多页面文档处理的效率和效果。",
      "method": "论文提出一个基于扩散的框架，将扩散过程重新解释为在结构化潜在空间中的随机轨迹演化。核心创新在于通过设计初始噪声及其几何对齐，使背景生成自然避开指定前景区域，而无需使用掩码或抑制机制。此外，方法解耦风格控制与文本条件，引入缓存风格方向作为持久向量，这些方向约束扩散轨迹进入共享的风格子空间，从而确保多页生成和编辑中的风格一致性。该框架无需额外训练，可兼容现有扩散模型主干。",
      "result": "论文指出该方法在复杂文档上产生视觉一致且前景保护良好的生成结果。由于摘要未明确说明具体的性能指标（如准确率提升或效率改进），也未提供与基线方法的详细定量对比，因此无法给出具体数据支撑。但文中强调，通过轨迹设计避免了显式约束，实现了更稳定的生成效果，未来研究可能需要实验验证其泛化能力和优化空间。",
      "conclusion": "本研究的主要贡献是提出了一种基于轨迹引导的扩散方法，通过潜在空间设计解决文档背景生成中的前景保护和风格一致性问题。该框架提供了一种原则性的生成建模方法，具有学术价值，为扩散模型在结构化任务中的应用提供了新视角。实际应用价值在于简化多页面文档处理过程，无需重复指定风格或使用辅助机制。局限性可能包括对特定文档类型的适应性，未来工作可扩展至其他生成领域或增强效率验证。",
      "tags": [
        "Diffusion Models",
        "Latent Space",
        "Trajectory Design",
        "Style Control",
        "Document Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:04.465705Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21851",
    "title": "Visual Disentangled Diffusion Autoencoders: Scalable Counterfactual Generation for Foundation Models",
    "authors": [
      "Sidney Bender",
      "Marco Morik"
    ],
    "abstract": "Foundation models, despite their robust zero-shot capabilities, remain vulnerable to spurious correlations and 'Clever Hans' strategies. Existing mitigation methods often rely on unavailable group labels or computationally expensive gradient-based adversarial optimization. To address these limitations, we propose Visual Disentangled Diffusion Autoencoders (DiDAE), a novel framework integrating frozen foundation models with disentangled dictionary learning for efficient, gradient-free counterfactual generation directly for the foundation model. DiDAE first edits foundation model embeddings in interpretable disentangled directions of the disentangled dictionary and then decodes them via a diffusion autoencoder. This allows the generation of multiple diverse, disentangled counterfactuals for each factual, much faster than existing baselines, which generate single entangled counterfactuals. When paired with Counterfactual Knowledge Distillation, DiDAE-CFKD achieves state-of-the-art performance in mitigating shortcut learning, improving downstream performance on unbalanced datasets.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21851.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21851",
    "published": "2026-01-29T15:25:37Z",
    "updated": "2026-01-29T15:25:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 Visual Disentangled Diffusion Autoencoders (DiDAE) 框架，通过结合冻结基础模型与解缠结字典学习，为基础模型实现高效、无需梯度的反事实生成，以缓解虚假相关性问题。",
      "motivation": "基础模型如大型视觉模型在零样本任务中具有强大能力，但易受虚假相关性和'Clever Hans'策略影响，导致模型学习捷径而非真实模式，影响鲁棒性。现有缓解方法依赖组标签或基于梯度的对抗优化，组标签常不可用，梯度优化计算昂贵。因此，亟需开发不依赖标签、计算高效的反事实生成方法，以改进模型泛化能力和公平性。",
      "method": "DiDAE 框架整合了冻结的基础模型和解缠结字典学习。首先，在解缠结字典的可解释方向上编辑基础模型的嵌入向量，实现特征解缠结；然后通过扩散自动编码器解码这些编辑后的嵌入，生成反事实样本。关键创新包括采用梯度免费的字典学习技术，避免昂贵对抗优化，并能生成多个多样且解缠结的反事实，相比基线方法仅生成单个纠缠反事实，显著提升效率。",
      "result": "DiDAE 在生成反事实方面比现有基线方法快得多，能高效生成多样解缠结反事实。当与反事实知识蒸馏（CFKD）结合时，DiDAE-CFKD 在缓解捷径学习任务中实现了最先进的性能，显著提高了在不平衡数据集上的下游任务表现，增强了模型的鲁棒性和泛化能力。摘要未明确说明具体数据指标。",
      "conclusion": "该研究提出的 DiDAE 框架为基础模型提供了一种高效的反事实生成方法，通过解缠结字典学习和扩散自动编码器，有效缓解了虚假相关性问题，提升了模型在不平衡数据集上的下游性能，具有重要的学术和应用价值。未来可扩展该方法到其他模态或探索更优化的学习策略。",
      "tags": [
        "Foundation Models",
        "Counterfactual Generation",
        "Disentangled Dictionary Learning",
        "Diffusion Autoencoders",
        "Knowledge Distillation"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:14.788119Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21847",
    "title": "READY: Reward Discovery for Meta-Black-Box Optimization",
    "authors": [
      "Zechuan Huang",
      "Zhiguang Cao",
      "Hongshu Guo",
      "Yue-Jiao Gong",
      "Zeyuan Ma"
    ],
    "abstract": "Meta-Black-Box Optimization (MetaBBO) is an emerging avenue within Optimization community, where algorithm design policy could be meta-learned by reinforcement learning to enhance optimization performance. So far, the reward functions in existing MetaBBO works are designed by human experts, introducing certain design bias and risks of reward hacking. In this paper, we use Large Language Model~(LLM) as an automated reward discovery tool for MetaBBO. Specifically, we consider both effectiveness and efficiency sides. On effectiveness side, we borrow the idea of evolution of heuristics, introducing tailored evolution paradigm in the iterative LLM-based program search process, which ensures continuous improvement. On efficiency side, we additionally introduce multi-task evolution architecture to support parallel reward discovery for diverse MetaBBO approaches. Such parallel process also benefits from knowledge sharing across tasks to accelerate convergence. Empirical results demonstrate that the reward functions discovered by our approach could be helpful for boosting existing MetaBBO works, underscoring the importance of reward design in MetaBBO. We provide READY's project at https://anonymous.4open.science/r/ICML_READY-747F.",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21847.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21847",
    "published": "2026-01-29T15:23:18Z",
    "updated": "2026-01-29T15:23:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出使用大语言模型作为自动化奖励发现工具，通过演化范式和多任务架构改进元黑盒优化的奖励函数设计。",
      "motivation": "元黑盒优化（MetaBBO）是优化领域的新兴方向，通过强化学习元学习算法设计策略以提升性能。然而，现有奖励函数由人类专家设计，存在设计偏差和奖励黑客风险，这可能限制优化算法的效果和鲁棒性。因此，本文旨在自动化奖励发现过程，减少人为干预，提高MetaBBO的性能和可靠性，解决现有方法的不足。",
      "method": "研究方法基于大语言模型（LLM），作为自动化奖励发现工具。核心创新包括：在有效性方面，引入启发式演化思想，在LLM迭代程序搜索中定制演化范式，确保奖励函数持续改进；在效率方面，采用多任务演化架构，支持多种MetaBBO方法的并行奖励发现，并通过跨任务知识共享加速收敛。技术路线结合了LLM的生成能力和演化算法的优化特性。",
      "result": "实证结果表明，READY方法发现的奖励函数能够有效提升现有元黑盒优化工作的性能。尽管摘要未明确说明具体数据如准确率提升百分比，但强调了奖励函数对优化效果的积极影响，验证了自动化奖励发现的重要性。这表明通过LLM-based演化搜索，可以生成更优的奖励函数，从而提高MetaBBO的整体表现。",
      "conclusion": "本文的贡献在于提出了基于大语言模型的自动化奖励发现工具READY，应用于元黑盒优化。研究突出了奖励设计在优化算法中的关键作用，为自动化算法设计提供了新途径。学术上推动MetaBBO研究，实际中可能提升各种优化任务的性能。未来工作可探索更高效的演化策略、扩展到更多优化场景，或减轻对LLM的依赖。",
      "tags": [
        "Large Language Model",
        "Meta-Black-Box Optimization",
        "Reward Discovery",
        "Evolutionary Computation",
        "Multi-Task Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:42.543809Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21845",
    "title": "Constrained Meta Reinforcement Learning with Provable Test-Time Safety",
    "authors": [
      "Tingting Ni",
      "Maryam Kamgarpour"
    ],
    "abstract": "Meta reinforcement learning (RL) allows agents to leverage experience across a distribution of tasks on which the agent can train at will, enabling faster learning of optimal policies on new test tasks. Despite its success in improving sample complexity on test tasks, many real-world applications, such as robotics and healthcare, impose safety constraints during testing. Constrained meta RL provides a promising framework for integrating safety into meta RL. An open question in constrained meta RL is how to ensure the safety of the policy on the real-world test task, while reducing the sample complexity and thus, enabling faster learning of optimal policies. To address this gap, we propose an algorithm that refines policies learned during training, with provable safety and sample complexity guarantees for learning a near optimal policy on the test tasks. We further derive a matching lower bound, showing that this sample complexity is tight.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21845.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21845",
    "published": "2026-01-29T15:21:37Z",
    "updated": "2026-01-29T15:21:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一个约束元强化学习算法，具有可证明的测试时安全性和样本复杂度保证，解决了在测试任务中同时确保安全和高效学习的挑战。",
      "motivation": "元强化学习通过利用跨任务经验减少新任务的样本复杂度，但在现实应用如机器人和医疗中，测试时需施加安全约束。约束元强化学习为集成安全提供了框架，但现有方法未解决如何确保测试任务中策略的安全，同时降低样本复杂度以促进快速学习。这个问题的重要性在于安全约束对于高风险应用的可靠性和鲁棒性至关重要，现有框架在平衡安全与效率方面存在不足。",
      "method": "论文提出一种算法，通过精炼训练期间学习的策略，在测试任务上学习近似最优策略，并具有可证明的安全性和样本复杂度保证。关键创新点在于提供了理论上的安全性和效率保证，但摘要未明确说明具体技术细节，如使用的数据集或模型架构。该方法旨在应对约束元强化学习中的开放问题，确保策略在测试时满足安全约束的同时，提升学习效率。",
      "result": "算法在测试任务上实现了学习近似最优策略，并具有可证明的安全性和样本复杂度保证。通过推导匹配的下界，作者表明该样本复杂度是紧的，理论上证明了算法在效率方面的优越性。摘要未明确说明具体实验数据，如与基线方法的性能对比或准确率提升，但强调了理论结果的重要性，显示了算法在平衡安全与样本复杂性方面的潜力。",
      "conclusion": "论文的主要贡献是提出了一个约束元强化学习算法，解决了测试时安全与样本效率的平衡问题，并提供了理论上的安全性和样本复杂度保证。其学术价值在于填补了现有研究中的空白，为安全强化学习领域提供了新方法；实际应用价值在于可应用于机器人控制和医疗系统等高风险领域，提高系统的安全性和学习效率。摘要未明确说明潜在局限性或未来工作方向。",
      "tags": [
        "Meta Reinforcement Learning",
        "Constrained Reinforcement Learning",
        "Safety Guarantees",
        "Sample Complexity",
        "Lower Bound"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:52.321996Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21844",
    "title": "Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework",
    "authors": [
      "So Fukuhara",
      "Abdallah Alabdallah",
      "Nuwan Gunasekara",
      "Slawomir Nowaczyk"
    ],
    "abstract": "Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of a forecasting model should be judged not by statistical accuracy (e.g., MAE, RMSE, IAE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and operational KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting model in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of their downstream implications for inventory decisions. Using a wide range of simulation scenarios, we show that improvements in conventional accuracy metrics do not necessarily translate into better operational performance, and that models with similar statistical error profiles can induce markedly different cost-service trade-offs. We analyze these discrepancies to characterize how specific aspects of forecast performance affect inventory outcomes and derive guidance for model selection. Overall, the framework operationalizes the link between demand forecasting and inventory management, shifting evaluation from purely predictive accuracy toward operational relevance in the automotive aftermarket and related domains.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21844.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21844",
    "published": "2026-01-29T15:20:33Z",
    "updated": "2026-01-29T15:20:33Z",
    "comment": "12 pages, 6 figures",
    "light_analysis": {
      "overview": "本文提出了一个基于模拟的软件框架，桥接预测准确性和库存关键性能指标，以评估模型在操作环境中的影响。",
      "motivation": "汽车售后市场中，备件库存管理至关重要，需求间歇性强且不确定性大，导致成本和服务风险高。预测是核心，但现有方法主要依赖统计准确性指标（如MAE、RMSE）评估模型，而准确性指标与操作KPIs（如总成本和服务水平）之间的关系不明确，导致模型选择可能不合理。本研究旨在填补这一空白，将评估从纯统计精度转向操作相关性，以优化库存决策。",
      "method": "本文提出一个决策中心的模拟软件框架，包含三个核心组件：一是合成需求生成器，专门模拟备件需求的间歇性和不确定性特征；二是灵活预测模块，可集成任意预测模型进行评估；三是库存控制模拟器，基于预测结果模拟库存决策并计算操作KPIs。该闭环框架使研究者能系统评估模型统计误差及其对库存结果的下游影响，连接预测与操作评估。",
      "result": "通过广泛的模拟场景实验，研究发现传统准确性指标的改进不一定转化为更好的操作性能，如MAE或RMSE降低时，总成本和服务水平未必提升。统计误差相似的预测模型可能导致显著不同的成本-服务权衡，影响库存管理效率。分析揭示了预测性能特定方面如何影响库存结果，并衍生出模型选择的实用指南，强调操作KPIs的重要性。",
      "conclusion": "本研究的主要贡献是开发了一个软件框架，操作化了需求预测与库存管理之间的联系，将评估重心从统计准确性转向操作KPIs。这提供了学术上桥接预测与操作评估的新方法，实际应用中可为汽车售后市场及相关领域优化库存决策。未来工作可扩展至其他行业或更复杂的库存模型，以增强框架的适用性和通用性。",
      "tags": [
        "Demand Forecasting",
        "Inventory Management",
        "Simulation Framework",
        "Synthetic Demand Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:15.707108Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21841",
    "title": "Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model",
    "authors": [
      "Xiang Li",
      "Ning Yan",
      "Masood Mortazavi"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21841.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21841",
    "published": "2026-01-29T15:18:58Z",
    "updated": "2026-01-29T15:18:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出GiG框架，结合图神经网络和大语言模型，通过图结构记忆和符号逻辑增强具身代理的长期任务规划能力。",
      "motivation": "大型语言模型（LLMs）作为具身代理在长期规划中面临挑战，需将高级意图分解为可执行子目标并严格遵循动态环境逻辑。现有标准LLM规划器常因上下文窗口限制或产生违反约束的幻觉，导致策略一致性不足，限制了实际部署。因此，需要更稳健的方法来提升规划的准确性和适应性。",
      "method": "GiG框架采用Graph-in-Graph架构，使用图神经网络（GNN）编码环境状态为嵌入，组织成动作连接的执行跟踪图并存储在经验内存库中。通过聚类图嵌入，检索结构感知先验，使代理能基于相关过去模式进行决策。关键创新包括有界前瞻模块，利用符号转换逻辑增强规划能力，提升动态环境中的动作生成效率。",
      "result": "在Robotouille Synchronous、Asynchronous和ALFWorld三个具身规划基准测试上评估，GiG显著优于当前最优基线方法。Pass@1性能提升分别达22%、37%和15%，且计算成本相当或更低，展示了该方法在维持规划一致性和减少幻觉方面的有效性。",
      "conclusion": "GiG框架的主要贡献是整合图结构记忆与LLM，解决具身代理长期规划中的一致性和约束问题。学术上，它为结合符号逻辑和神经网络提供了新方向；实际上，可提升机器人和虚拟代理的自主决策能力。局限性未明确说明，未来工作可探索更复杂环境扩展或计算效率优化。",
      "tags": [
        "Large Language Model",
        "Graph Neural Network",
        "Embodied Task Planning",
        "Graph Embeddings",
        "Bounded Lookahead"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:09.256826Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21835",
    "title": "Scalable Linearized Laplace Approximation via Surrogate Neural Kernel",
    "authors": [
      "Luis A. Ortega",
      "Simón Rodríguez-Santana",
      "Daniel Hernández-Lobato"
    ],
    "abstract": "We introduce a scalable method to approximate the kernel of the Linearized Laplace Approximation (LLA). For this, we use a surrogate deep neural network (DNN) that learns a compact feature representation whose inner product replicates the Neural Tangent Kernel (NTK). This avoids the need to compute large Jacobians. Training relies solely on efficient Jacobian-vector products, allowing to compute predictive uncertainty on large-scale pre-trained DNNs. Experimental results show similar or improved uncertainty estimation and calibration compared to existing LLA approximations. Notwithstanding, biasing the learned kernel significantly enhances out-of-distribution detection. This remarks the benefits of the proposed method for finding better kernels than the NTK in the context of LLA to compute prediction uncertainty given a pre-trained DNN.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21835.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21835",
    "published": "2026-01-29T15:15:41Z",
    "updated": "2026-01-29T15:15:41Z",
    "comment": "6 pages, 1 table. Accepted at European Symposium on Artificial Neural Networks (ESANN 2026) as oral presentation",
    "light_analysis": {
      "overview": "本文提出一种可扩展方法，通过代理神经核近似线性化拉普拉斯近似的核，以改进预训练深度神经网络的预测不确定性估计。",
      "motivation": "线性化拉普拉斯近似（LLA）用于估计机器学习模型的预测不确定性，但在大规模预训练深度神经网络中，传统方法需计算大型雅可比矩阵，导致计算复杂度高、可扩展性差。现有LLA近似方法在处理这类模型时效率低下，限制了不确定性估计在实际应用中的部署，而准确的不确定性对于模型校准和分布外检测至关重要。因此，开发高效可扩展的核近似方法具有重要研究价值，以解决计算瓶颈问题。",
      "method": "该方法的核心是使用代理深度神经网络学习一个紧凑的特征表示，其内积能够复制神经切线核（NTK）。这避免了直接计算大型雅可比矩阵，转而依赖高效的雅可比-向量乘积进行训练，使得在大规模预训练DNN上计算预测不确定性变得可扩展。创新点在于引入代理神经核来近似LLA的核，提高了计算效率。摘要未明确说明具体数据集或模型架构，但强调了方法的通用性。",
      "result": "实验结果显示，与现有线性化拉普拉斯近似方法相比，该方法在不确定性估计和校准方面表现相似或更优。具体地，通过偏置学习到的核，分布外检测能力得到显著增强。摘要未提供具体性能指标数据，如准确率提升数值，但与基线方法的对比表明，该方法在保持校准性能的同时，有效改善了模型对未知数据的识别能力。",
      "conclusion": "本论文的主要贡献是提出了一种可扩展的线性化拉普拉斯近似核近似方法，通过代理神经核优化预测不确定性计算。学术价值在于为大规模预训练模型的不确定性估计提供了高效方案，并探索了优于神经切线核的新核设计。实际应用价值体现在提升模型校准和分布外检测性能，增强机器学习系统的可靠性。未来工作可能包括扩展方法到更多网络类型或验证在真实数据集上的表现，摘要未明确说明潜在局限性。",
      "tags": [
        "Linearized Laplace Approximation",
        "Neural Tangent Kernel",
        "Surrogate Neural Network",
        "Predictive Uncertainty",
        "Out-of-Distribution Detection"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:43.053941Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21832",
    "title": "Goal-Driven Adaptive Sampling Strategies for Machine Learning Models Predicting Fields",
    "authors": [
      "Jigar Parekh",
      "Philipp Bekemeyer"
    ],
    "abstract": "Machine learning models are widely regarded as a way forward to tackle multi-query challenges that arise once expensive black-box simulations such as computational fluid dynamics are investigated. However, ensuring the desired level of accuracy for a certain task at minimal computational cost, e.g. as few black-box samples as possible, remains a challenges. Active learning strategies are used for scalar quantities to overcome this challenges and different so-called infill criteria exists and are commonly employed in several scenarios. Even though needed in various field an extension of active learning strategies towards field predictions is still lacking or limited to very specific scenarios and/or model types. In this paper we propose an active learning strategy for machine learning models that are capable if predicting field which is agnostic to the model architecture itself. For doing so, we combine a well-established Gaussian process model for a scalar reference value and simultaneously aim at reducing the epistemic model error and the difference between scalar and field predictions. Different specific forms of the above-mentioned approach are introduced and compared to each other as well as only scalar-valued based infill. Results are presented for the NASA common research model for an uncertainty propagation task showcasing high level of accuracy at significantly smaller cost compared to an approach without active learning.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21832.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21832",
    "published": "2026-01-29T15:14:36Z",
    "updated": "2026-01-29T15:14:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种目标驱动的自适应采样策略，用于机器学习模型的场预测，该方法独立于模型架构，旨在最小化计算成本并保持高精度。",
      "motivation": "本研究动机源于解决昂贵黑盒模拟（如计算流体动力学）中的多查询挑战，机器学习模型虽能应用，但确保预测场准确性同时最小化采样点是一个关键问题。现有主动学习策略主要针对标量预测，缺乏对场预测的通用扩展，限制了在复杂科学和工程场景中的应用。这突出了开发独立于模型架构的场预测主动学习策略的重要性，以提升效率并减少计算开销。",
      "method": "论文提出一种主动学习策略，核心是结合高斯过程模型作为标量参考值，同时减少认知模型误差和标量与场预测之间的差异。该方法独立于预测场的机器学习模型架构，具有通用性，并介绍了不同具体形式的策略。使用NASA通用研究模型进行验证，针对不确定性传播任务，与仅基于标量的基准方法进行比较，以评估性能。",
      "result": "在NASA通用研究模型的实验结果表明，提出的主动学习策略在不确定性传播任务中实现了高水平的精度。与未使用主动学习的方法相比，计算成本显著降低，所需采样点更少，展示了该策略在提高效率的同时保持准确性的优势。摘要未明确说明具体性能指标数值，但强调了成本的显著优化。",
      "conclusion": "本研究的主要贡献是扩展主动学习策略到场预测领域，提供了一种独立于模型架构的通用方法，有效平衡了精度和计算成本。这项工作具有重要的学术和实际应用价值，为昂贵模拟中的多查询问题提供了新解决方案。未来可能扩展到更多模型类型和复杂场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Active Learning",
        "Field Prediction",
        "Gaussian Process",
        "Adaptive Sampling",
        "Uncertainty Propagation"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:35.065979Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21830",
    "title": "Looking Beyond Accuracy: A Holistic Benchmark of ECG Foundation Models",
    "authors": [
      "Francesca Filice",
      "Edoardo De Rose",
      "Simone Bartucci",
      "Francesco Calimeri",
      "Simona Perri"
    ],
    "abstract": "The electrocardiogram (ECG) is a cost-effective, highly accessible and widely employed diagnostic tool. With the advent of Foundation Models (FMs), the field of AI-assisted ECG interpretation has begun to evolve, as they enable model reuse across different tasks by relying on embeddings. However, to responsibly employ FMs, it is crucial to rigorously assess to which extent the embeddings they produce are generalizable, particularly in error-sensitive domains such as healthcare. Although prior works have already addressed the problem of benchmarking ECG-expert FMs, they focus predominantly on the evaluation of downstream performance. To fill this gap, this study aims to find an in-depth, comprehensive benchmarking framework for FMs, with a specific focus on ECG-expert ones. To this aim, we introduce a benchmark methodology that complements performance-based evaluation with representation-level analysis, leveraging SHAP and UMAP techniques. Furthermore, we rely on the methodology for carrying out an extensive evaluation of several ECG-expert FMs pretrained via state-of-the-art techniques over different cross-continental datasets and data availability settings; this includes ones featuring data scarcity, a fairly common situation in real-world medical scenarios. Experimental results show that our benchmarking protocol provides a rich insight of ECG-expert FMs' embedded patterns, enabling a deeper understanding of their representational structure and generalizability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21830.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21830",
    "published": "2026-01-29T15:14:00Z",
    "updated": "2026-01-29T15:14:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一个全面的基准测试框架，用于评估心电图专家基础模型的嵌入表示通用性。",
      "motivation": "心电图是一种经济高效、高度可及且广泛使用的诊断工具。随着基础模型的出现，AI辅助ECG解释领域开始发展，因为它们通过嵌入实现跨任务模型重用。然而，为了负责任地应用基础模型，必须严格评估其嵌入表示的通用性，特别是在医疗等错误敏感领域。现有研究虽然已经基准测试了ECG专家基础模型，但主要聚焦于下游性能评估，缺乏对嵌入表示通用性的深入分析，这限制了模型在真实医疗场景中的可靠应用。",
      "method": "本研究引入一个基准测试方法论，通过结合基于性能的评估和表示层分析来填补这一空白。关键创新点在于利用SHAP（解释性机器学习）和UMAP（降维技术）技术进行嵌入表示分析。评估对象为多个ECG专家基础模型，这些模型通过先进技术在不同跨大陆数据集上预训练，涵盖多种数据可用性设置，包括数据稀缺情况，以模拟真实医疗场景。这种方法旨在全面理解模型的嵌入结构和通用性。",
      "result": "实验结果表明，该基准测试协议能提供对ECG专家基础模型嵌入模式的丰富见解，有助于深入理解其表示结构和通用性。与现有方法相比，该框架通过表示层分析揭示了模型在数据稀缺等挑战下的潜在行为，为评估模型的稳健性和泛化能力提供了新视角。摘要未明确说明具体性能指标，但强调了框架在揭示嵌入模式方面的有效性。",
      "conclusion": "本研究的贡献在于提出了一个全面的基准测试框架，用于评估ECG专家基础模型的嵌入表示通用性。这具有重要的学术价值，推动了基础模型评估方法的发展，特别是在医疗领域。实际应用上，有助于提高AI辅助ECG诊断的可靠性和安全性，确保模型在错误敏感场景中的稳健性。未来工作可扩展至其他医疗领域，或改进表示分析技术以应对更复杂的数据环境。",
      "tags": [
        "ECG",
        "Foundation Models",
        "Benchmarking",
        "SHAP",
        "UMAP"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:36.162642Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21826",
    "title": "Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models",
    "authors": [
      "Aadi Palnitkar",
      "Mingyang Mao",
      "Nicholas Waytowich",
      "Vinicius G. Goecks",
      "Tinoosh Mohsenin",
      "Xiaomin Lin"
    ],
    "abstract": "As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21826.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21826",
    "published": "2026-01-29T15:11:31Z",
    "updated": "2026-01-29T15:11:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了MilSCORE基准测试，用于评估大语言模型在长上下文地理空间推理和规划中的能力，是首个基于军事规划场景的专家编写问题数据集。",
      "motivation": "随着大语言模型应用于更长的复杂任务，需要现实的长上下文基准来评估选择性阅读和整合异构多模态信息的能力。地理空间规划问题，如大规模军事行动规划，要求快速准确地推理地图、命令、情报报告等分布式数据，而现有基准不足以满足这些高风险的决策和规划需求，因此本研究旨在填补这一空白，推动LLMs在复杂现实场景中的应用。",
      "method": "作者开发了MilSCORE基准测试，包括一个基于复杂模拟军事规划场景的数据集，其中包含专家编写的多跳问题，以评估LLMs的战术和空间推理能力。数据集设计涵盖七种问题类型，针对事实回忆和多步推理，涉及约束、策略和空间分析。提供了评估协议，并对多种当代视觉-语言模型进行了基线测试，以建立性能基准和识别改进空间。",
      "result": "论文评估了多种视觉-语言模型在MilSCORE上的表现，发现当前系统在处理真实、场景级的长上下文规划时存在显著困难，基准结果显示有大量改进空间。摘要未提供具体性能指标如准确率，但与基线方法相比，现有模型在长上下文地理空间推理方面表现挣扎，突出了未来研究的需求和挑战。",
      "conclusion": "MilSCORE作为首个场景级军事规划基准，为评估大语言模型的长上下文地理空间推理能力提供了新工具，强调了当前系统在复杂任务中的局限性。研究指出MilSCORE作为一个具有挑战性的测试平台，能推动未来工作，具有重要的学术价值，可促进LLMs在现实世界高风险决策中的应用，并可能扩展到其他领域。",
      "tags": [
        "Large Language Models",
        "Geospatial Reasoning",
        "Long-Context Benchmarking",
        "Vision-Language Models",
        "Multi-modal Integration"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:10.572019Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21824",
    "title": "DASH: Deterministic Attention Scheduling for High-throughput Reproducible LLM Training",
    "authors": [
      "Xinwei Qiang",
      "Hongmin Chen",
      "Shixuan Sun",
      "Jingwen Leng",
      "Xin Liu",
      "Minyi Guo"
    ],
    "abstract": "Determinism is indispensable for reproducibility in large language model (LLM) training, yet it often exacts a steep performance cost. In widely used attention implementations such as FlashAttention-3, the deterministic backward pass can incur up to a 37.9% throughput reduction relative to its non-deterministic counterpart, primarily because gradient accumulation operations must be serialized to guarantee numerical consistency. This performance loss stems from suboptimal scheduling of compute and gradient-reduction phases, leading to significant hardware underutilization.   To address this challenge, we formulate the backward pass of deterministic attention as a scheduling problem on a Directed Acyclic Graph (DAG) and derive schedules that minimize the critical path length. Building on this formulation, we present DASH (Deterministic Attention Scheduling for High-Throughput), which encapsulates two complementary scheduling strategies: (i) Descending Q-Tile Iteration, a reversed query-block traversal that shrinks pipeline stalls in causal attention, and (ii) Shift Scheduling, a theoretically optimal schedule within our DAG model that reduces pipeline stalls for both full and causal masks.   Our empirical evaluations on NVIDIA H800 GPUs demonstrate that DASH narrows the performance gap of deterministic attention. The proposed strategies improve the throughput of the attention backward pass by up to 1.28$\\times$ compared to the baseline, significantly advancing the efficiency of reproducible LLM training.   Our code is open-sourced at https://github.com/SJTU-Liquid/deterministic-FA3.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21824.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21824",
    "published": "2026-01-29T15:10:13Z",
    "updated": "2026-01-29T15:10:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "DASH提出一种确定性注意力调度策略，通过优化DAG调度减少管道停滞，显著提高LLM训练的可重现性和吞吐量。",
      "motivation": "该研究旨在解决大型语言模型（LLM）训练中确定性与性能之间的权衡问题。确定性对可重现性至关重要，但现有注意力实现（如FlashAttention-3）的确定性反向传播会导致高达37.9%的吞吐量下降，这主要源于计算和梯度减少阶段的调度不佳，引发硬件利用率低下。因此，改进调度策略对实现高效可重现AI训练具有重要意义。",
      "method": "论文将确定性注意力的反向传播形式化为有向无环图（DAG）上的调度问题，以最小化关键路径长度。基于此，提出DASH方法，包含两种互补调度策略：Descending Q-Tile Iteration，一种反向查询块遍历，用于减少因果注意力的管道停滞；Shift Scheduling，一种在DAG模型内理论最优的调度，可减少全掩码和因果掩码的管道停滞。方法在NVIDIA H800 GPUs上实现，针对FlashAttention-3等基线进行优化。",
      "result": "实验在NVIDIA H800 GPUs上进行，结果表明DASH有效缩小了确定性注意力的性能差距。与基线（FlashAttention-3的确定性版本）相比，注意力反向传播的吞吐量提升高达1.28倍，显著提高了训练效率。这一改进是通过优化调度来减少硬件利用不足，促进了高效可重现LLM训练的实现。",
      "conclusion": "论文的主要贡献是提出了DASH方法，通过优化确定性注意力调度提高了LLM训练的可重现性和效率，为高效AI训练提供了新思路。研究具有实际应用价值，能促进大规模模型训练的可重现性。摘要未明确说明具体局限性或未来工作方向，但该方法为扩展至其他硬件或注意力机制奠定了基础。",
      "tags": [
        "Deterministic Attention",
        "Large Language Model Training",
        "Directed Acyclic Graph Scheduling",
        "Throughput Optimization",
        "FlashAttention"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:22.609462Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21822",
    "title": "CORE:Toward Ubiquitous 6G Intelligence Through Collaborative Orchestration of Large Language Model Agents Over Hierarchical Edge",
    "authors": [
      "Zitong Yu",
      "Boquan Sun",
      "Yang Li",
      "Zheyan Qu",
      "Xing Zhang"
    ],
    "abstract": "Rapid advancements in sixth-generation (6G) networks and large language models (LLMs) have paved the way for ubiquitous intelligence, wherein seamless connectivity and distributed artificial intelligence (AI) have revolutionized various aspects of our lives.However, realizing this vision faces significant challenges owing to the fragmented and heterogeneous computing resources across hierarchical networks, which are insufficient for individual LLM agents to perform complex reasoning tasks.To address this issue, we propose Collaborative Orchestration Role at Edge (CORE), an innovative framework that employs a collaborative learning system in which multiple LLMs, each assigned a distinct functional role, are distributed across mobile devices and tiered edge servers. The system integrates three optimization modules, encompassing real-time perception,dynamic role orchestration, and pipeline-parallel execution, to facilitate efficient and rapid collaboration among distributed agents. Furthermore, we introduce a novel role affinity scheduling algorithm for dynamically orchestrating LLM role assignments across the hierarchical edge infrastructure, intelligently matching computational demands with available dispersed resources.Finally, comprehensive case studies and performance evaluations across various 6G application scenarios demonstrated the efficacy of CORE, revealing significant enhancements in the system efficiency and task completion rates. Building on these promising outcomes, we further validated the practical applicability of CORE by deploying it on a real-world edge-computing platform,that exhibits robust performance in operational environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21822.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21822",
    "published": "2026-01-29T15:08:19Z",
    "updated": "2026-01-29T15:08:19Z",
    "comment": "Accepted by IEEE Communications Magazine",
    "light_analysis": {
      "overview": "CORE框架通过在分层边缘网络中协作编排多个大语言模型代理，实现高效的6G普适智能。",
      "motivation": "随着6G网络和大语言模型的快速发展，实现普适智能成为可能，但面临计算资源分散和异构的挑战。现有方法中，单个LLM代理难以在分散资源上高效执行复杂推理任务，限制了分布式AI的应用。本研究旨在解决如何优化LLM代理的协作编排，以充分利用分层网络中的计算资源，促进无缝连接和智能革命。",
      "method": "CORE框架的核心是将多个LLM代理分布式部署在移动设备和分层边缘服务器上，每个代理分配特定功能角色。系统整合三个优化模块：实时感知监控环境状态，动态角色编排调整代理任务，流水线并行执行提升效率。此外，引入角色亲和调度算法，智能匹配计算需求与可用分散资源，确保高效协作，摘要未明确说明具体数据集或模型架构。",
      "result": "在多个6G应用场景的案例研究和性能评估中，CORE显著提高了系统效率和任务完成率，但摘要未明确提供具体数据如提升百分比或基线对比。部署在真实边缘计算平台后，验证了其在实际操作中的稳健性能，显示出在运行环境中的广泛应用潜力。",
      "conclusion": "论文主要贡献是提出CORE框架，通过协作学习系统优化LLM代理在分层边缘网络中的编排。学术价值在于推动分布式AI和边缘计算研究，实际应用价值体现在6G智能场景的可行性和高效性。未来工作可探索算法的扩展性，以应对更复杂的网络环境或更多应用领域。",
      "tags": [
        "Large Language Model",
        "Edge Computing",
        "Collaborative Learning",
        "Distributed Systems",
        "6G Networks"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:07.976721Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21821",
    "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
    "authors": [
      "Honglin Lin",
      "Zheng Liu",
      "Yun Zhu",
      "Chonghan Qin",
      "Juekai Lin",
      "Xiaoran Shang",
      "Conghui He",
      "Wentao Zhang",
      "Lijun Wu"
    ],
    "abstract": "Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a \"less is more\" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21821.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21821",
    "published": "2026-01-29T15:07:28Z",
    "updated": "2026-01-29T15:07:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了MMFineReason数据集和模型，通过数据为中心的方法填补多模态推理差距，显著提升开源视觉语言模型的性能。",
      "motivation": "研究动机源于开源视觉语言模型在视觉推理方面落后于专有系统，主要由于缺乏高质量推理数据。现有数据集覆盖不足，特别是在STEM图表和视觉谜题等挑战性领域，且缺少一致的、长形式的思维链注释，这对于激发强大推理能力至关重要。因此，开发高质量多模态推理数据集以提升开源模型的性能具有重要性，能缩小与专有系统的差距并推动开源社区发展。",
      "method": "研究方法包括引入MMFineReason数据集，包含180万样本和51亿解决方案令牌，具有从Qwen3-VL-235B-A22B-Thinking蒸馏的高质量推理注释。采用三阶段流程：大规模数据收集和标准化、思维链理由生成、以及基于推理质量和难度感知的全面选择。数据集涵盖STEM问题、视觉谜题、游戏和复杂图表，每个样本配有视觉基础的推理轨迹。通过微调Qwen3-VL-Instruct模型，开发了MMFineReason-2B/4B/8B版本。",
      "result": "主要实验结果显示，MMFineReason-2B/4B/8B版本在尺寸类别中达到新的最先进水平。MMFineReason-4B超越Qwen3-VL-8B-Thinking，MMFineReason-8B优于Qwen3-VL-30B-A3B-Thinking并接近Qwen3-VL-32B-Thinking，显示出显著参数效率。此外，通过难度感知过滤揭示了“少即是多”现象，仅7%子集（123K样本）性能与完整数据集相当。推理导向数据组合还展现出协同效应，能同时提升一般能力。",
      "conclusion": "论文的主要贡献是提出了MMFineReason数据集和模型，有效填补多模态推理数据空白，显著提升开源视觉语言模型性能。这具有重要学术价值，为多模态推理研究提供高质量数据集，推动开源模型发展。实际应用中，显示数据驱动方法在提升模型效率方面的潜力，未来工作可进一步探索数据过滤策略和推理能力泛化。",
      "tags": [
        "Vision Language Models (VLMs)",
        "Chain-of-Thought (CoT)",
        "Dataset Creation",
        "Parameter Efficiency",
        "Data-Centric Methods"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:45.946396Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21816",
    "title": "Nonparametric LLM Evaluation from Preference Data",
    "authors": [
      "Dennis Frauen",
      "Athiya Deviyani",
      "Mihaela van der Schaar",
      "Stefan Feuerriegel"
    ],
    "abstract": "Evaluating the performance of large language models (LLMs) from human preference data is crucial for obtaining LLM leaderboards. However, many existing approaches either rely on restrictive parametric assumptions or lack valid uncertainty quantification when flexible machine learning methods are used. In this paper, we propose a nonparametric statistical framework, DMLEval, for comparing and ranking LLMs from preference data using debiased machine learning (DML). For this, we introduce generalized average ranking scores (GARS), which generalize commonly used ranking models, including the Bradley-Terry model or PageRank/ Rank centrality, with complex human responses such as ties. DMLEval comes with the following advantages: (i) It produces statistically efficient estimates of GARS ranking scores. (ii) It naturally allows the incorporation of black-box machine learning methods for estimation. (iii) It can be combined with pre-trained LLM evaluators (e.g., using LLM-as-a-judge). (iv) It suggests optimal policies for collecting preference data under budget constraints. We demonstrate these advantages both theoretically and empirically using both synthetic and real-world preference datasets. In summary, our framework provides practitioners with powerful, state-of-the-art methods for comparing or ranking LLMs.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21816.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21816",
    "published": "2026-01-29T15:00:07Z",
    "updated": "2026-01-29T15:00:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出DMLEval框架，使用去偏机器学习方法非参数地评估和排名大型语言模型，克服现有方法的参数假设限制。",
      "motivation": "该研究旨在解决从人类偏好数据评估大型语言模型（LLM）性能的核心问题。现有方法如Bradley-Terry模型依赖于特定参数假设，可能不适用于复杂的人类响应（如平局），限制了评估的灵活性；同时，使用机器学习方法时，缺乏有效的不可确定性量化，影响了LLM排行榜的可靠性和通用性。因此，开发一个非参数统计框架至关重要，以提供更稳健和科学的评估工具，满足实际应用中对准确比较和排名LLMs的需求。",
      "method": "论文提出DMLEval框架，一种基于去偏机器学习（DML）的非参数统计方法。核心创新是引入广义平均排名分数（GARS），它泛化了常用排名模型如Bradley-Terry模型和PageRank，能处理平局等复杂人类响应。通过DML技术，该方法实现统计高效的GARS估计，并允许整合黑盒机器学习方法，例如使用预训练LLM作为评估器。此外，框架还提供在预算约束下优化偏好数据收集的策略，增强了应用的灵活性和实用性。",
      "result": "论文通过理论分析和实证研究验证了DMLEval的优势。使用合成和真实世界的偏好数据集进行实验，证明了框架在统计效率和灵活性方面的优越性，但摘要未明确说明具体性能指标（如准确率提升或效率改进）。与基线方法对比，作者强调该方法提供了最先进的评估手段，能为实践者提供强大的工具，提升LLM比较和排名的可靠性和通用性，但在具体数据支撑上未详细阐述。",
      "conclusion": "论文的主要贡献是开发了DMLEval框架，解决了LLM评估中参数假设的限制和不可确定性量化问题。通过引入GARS和DML，实现了灵活且统计高效的排名方法，为非参数统计在AI评估中的应用提供了新视角。实践上，为构建准确LLM排行榜提供了实用方案，具有重要学术和实际价值。未来工作可扩展至更复杂的响应类型或其他机器学习评估场景，以进一步增强其适用性。",
      "tags": [
        "Large Language Model Evaluation",
        "Nonparametric Statistics",
        "Debiased Machine Learning",
        "Ranking Models",
        "Preference Data"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:54.925615Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21804",
    "title": "Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning",
    "authors": [
      "Bodong Du",
      "Xuanqi Huang",
      "Xiaomeng Li"
    ],
    "abstract": "Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21804.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21804",
    "published": "2026-01-29T14:48:02Z",
    "updated": "2026-01-29T14:48:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出DARE方法，通过分布感知的奖励估计，提升测试时强化学习中奖励信号的准确性和稳定性，从而改进大型语言模型的自我改进能力。",
      "motivation": "TTRL使大型语言模型能在无标签输入上自我改进，但奖励估计是关键挑战，因为缺乏真实监督。现有方法如多数投票（MV）基于单一多数结果，假设其可靠，但实际上MV丢弃非多数但正确的行动候选信息，导致系统性偏差奖励估计。这削弱了TTRL的优化效果，尤其在复杂推理任务中影响性能提升。",
      "method": "DARE方法的核心创新是将奖励估计从基于单一多数结果转向完整的经验rollout分布。它结合探索奖励来鼓励非多数rollout的探索，并采用分布修剪机制以去噪奖励估计，从而提供更丰富和稳健的学习信号。摘要未明确说明使用的具体数据集或模型架构，但该方法针对TTRL场景中的大型语言模型设计。",
      "result": "在挑战性推理基准上的实验表明，DARE显著提升了优化稳定性和最终性能。具体数据显示，与基线方法相比，DARE在AIME 2024基准上实现了25.3%的相对改进，在AMC基准上实现了5.3%的相对改进，证实了其在奖励估计中的有效性。",
      "conclusion": "DARE通过分布感知的奖励估计，解决了多数投票方法的局限性，提供了更信息丰富和稳健的奖励信号。这贡献于改进TTRL的理论框架和实际应用，提升了大型语言模型在无监督环境下的推理能力。未来工作可探索分布机制的进一步优化或扩展到其他任务领域。",
      "tags": [
        "Test-time Reinforcement Learning",
        "Large Language Models",
        "Distribution-Aware Reward Estimation",
        "Empirical Rollout Distribution",
        "Reward Estimation"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:42.503544Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21803",
    "title": "RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes",
    "authors": [
      "Korbinian Randl",
      "Guido Rocchietti",
      "Aron Henriksson",
      "Ziawasch Abedjan",
      "Tony Lindgren",
      "John Pavlopoulos"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21803.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21803",
    "published": "2026-01-29T14:47:00Z",
    "updated": "2026-01-29T14:47:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出RAG-E端到端可解释性框架，通过数学归因方法量化检索器与生成器的对齐和失败模式。",
      "motivation": "检索增强生成（RAG）系统结合密集检索器和语言模型，以基于检索文档生成输出，但组件交互不透明，在高风险领域（如医疗、金融）部署时难以保证可靠性。现有方法缺乏有效对齐评估机制，无法量化检索器排名与生成器使用之间的不一致性，这限制了系统可信度和应用范围。RAG-E旨在解决这一问题，提供可解释性框架，以增强RAG系统的透明度和鲁棒性，应对部署挑战。",
      "method": "研究方法基于RAG-E框架，首先改编Integrated Gradients用于分析检索器的文档重要性，其次引入PMCSHAP（一种蒙特卡洛稳定的Shapley值近似）来归因生成器的文档使用，最后提出WARG指标量化生成器使用文档与检索器排名的一致性。实验在TREC CAsT和FoodSafeSum数据集上进行，利用密集检索器和语言模型构建RAG系统，但具体模型架构摘要未明确说明，核心是通过数学归因方法测量对齐，以揭示交互机制。",
      "result": "在TREC CAsT和FoodSafeSum数据集上的实证分析显示关键不对齐现象：对于47.4%到66.7%的查询，生成器忽略检索器排名最高的文档；同时，48.1%到65.9%的查询中生成器依赖排名较低的文档。这些结果表明RAG系统输出质量并非仅由个体组件性能决定，而是高度依赖于检索器与生成器的交互对齐。通过RAG-E框架，可以量化这些失败模式，为改进系统性能提供数据支撑，尽管摘要未明确说明与基线方法的直接对比，但揭示了不对齐问题的普遍性。",
      "conclusion": "RAG-E框架的主要贡献是提供量化检索器-生成器对齐的方法，揭示RAG系统中常见的失败模式，如生成器忽略高排名文档或依赖低排名文档。这强调了组件交互在系统性能中的关键作用，使得在高风险领域部署时可以进行审计和优化。研究具有学术价值，推动了RAG可解释性的发展，并具有实际应用潜力，未来工作可扩展至更多数据集和模型，进一步提升对齐评估的准确性，摘要未明确说明具体局限性，但暗示了交互复杂性需进一步探索。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Integrated Gradients",
        "Shapley Values",
        "Monte Carlo Methods",
        "Attribution Metrics"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:19.792817Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21802",
    "title": "A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition",
    "authors": [
      "Hoang Khang Phan",
      "Quang Vinh Dang",
      "Noriyo Colley",
      "Christina Garcia",
      "Nhat Tan Le"
    ],
    "abstract": "Endotracheal suctioning (ES) is an invasive yet essential clinical procedure that requires a high degree of skill to minimize patient risk - particularly in home care and educational settings, where consistent supervision may be limited. Despite its critical importance, automated recognition and feedback systems for ES training remain underexplored. To address this gap, this study proposes a unified, LLM-centered framework for video-based activity recognition benchmarked against conventional machine learning and deep learning approaches, and a pilot study on feedback generation. Within this framework, the Large Language Model (LLM) serves as the central reasoning module, performing both spatiotemporal activity recognition and explainable decision analysis from video data. Furthermore, the LLM is capable of verbalizing feedback in natural language, thereby translating complex technical insights into accessible, human-understandable guidance for trainees. Experimental results demonstrate that the proposed LLM-based approach outperforms baseline models, achieving an improvement of approximately 15-20\\% in both accuracy and F1 score. Beyond recognition, the framework incorporates a pilot student-support module built upon anomaly detection and explainable AI (XAI) principles, which provides automated, interpretable feedback highlighting correct actions and suggesting targeted improvements. Collectively, these contributions establish a scalable, interpretable, and data-driven foundation for advancing nursing education, enhancing training efficiency, and ultimately improving patient safety.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21802.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21802",
    "published": "2026-01-29T14:46:48Z",
    "updated": "2026-01-29T14:46:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一种统一的、以大型语言模型为核心的框架，用于气管内抽吸活动的视频识别和反馈生成，融合了可解释人工智能技术。",
      "motivation": "气管内抽吸是一种侵入性但必要的临床程序，尤其在家庭护理和教育环境中，由于监督有限，需要自动化系统以提高技能和安全性。尽管其重要性，现有自动化识别和反馈系统在培训中仍未被充分探索，导致培训效率低下和潜在风险。这促使本研究填补这一空白，通过开发一种新方法来解决自动化识别和反馈生成不足的问题，以改善培训效果和患者安全。",
      "method": "研究方法提出一个统一的、以大型语言模型为中心的框架。LLM作为核心推理模块，从视频数据中执行时空活动识别和可解释决策分析。框架还包括一个基于异常检测和XAI原则的学生支持模块，用于生成自然语言反馈。关键创新点在于将LLM应用于视频活动识别，并结合XAI技术提高可解释性，在传统机器学习和深度学习模型上进行基准测试。",
      "result": "实验结果表明，所提出的基于LLM的方法在准确率和F1分数上优于基线模型，提升了约15-20%。这证实了框架在活动识别方面具有显著性能改进。此外，试点研究中的反馈生成模块提供了自动化、可解释的反馈，突出正确行动并建议改进，展示了与基线模型相比的全面优势。",
      "conclusion": "本研究的贡献在于建立了一个可扩展、可解释、数据驱动的基础，用于推进护理教育和提高患者安全。通过整合LLM和XAI，框架不仅提升了活动识别的准确性，还能生成自然语言反馈，从而增强培训效率。这为扩展到其他医疗程序提供了基础，潜在局限性包括对数据质量的依赖，未来工作可优化模型泛化能力。",
      "tags": [
        "Large Language Model",
        "Explainable AI",
        "Video-based Activity Recognition",
        "Spatiotemporal Analysis",
        "Anomaly Detection"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:32.867151Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21800",
    "title": "BioAgent Bench: An AI Agent Evaluation Suite for Bioinformatics",
    "authors": [
      "Dionizije Fa",
      "Marko Čuljak",
      "Bruno Pandža",
      "Mateo Čupić"
    ],
    "abstract": "This paper introduces BioAgent Bench, a benchmark dataset and an evaluation suite designed for measuring the performance and robustness of AI agents in common bioinformatics tasks. The benchmark contains curated end-to-end tasks (e.g., RNA-seq, variant calling, metagenomics) with prompts that specify concrete output artifacts to support automated assessment, including stress testing under controlled perturbations. We evaluate frontier closed-source and open-weight models across multiple agent harnesses, and use an LLM-based grader to score pipeline progress and outcome validity. We find that frontier agents can complete multi-step bioinformatics pipelines without elaborate custom scaffolding, often producing the requested final artifacts reliably. However, robustness tests reveal failure modes under controlled perturbations (corrupted inputs, decoy files, and prompt bloat), indicating that correct high-level pipeline construction does not guarantee reliable step-level reasoning. Finally, because bioinformatics workflows may involve sensitive patient data, proprietary references, or unpublished IP, closed-source models can be unsuitable under strict privacy constraints; in such settings, open-weight models may be preferable despite lower completion rates. We release the dataset and evaluation suite publicly.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21800.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21800",
    "published": "2026-01-29T14:44:03Z",
    "updated": "2026-01-29T14:44:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "BioAgent Bench是一个创新的基准数据集和评估套件，专为评估AI代理在生物信息学任务中的性能和鲁棒性而设计。",
      "motivation": "本研究旨在解决AI代理在生物信息学任务中缺乏标准化性能评估和鲁棒性测试的问题。生物信息学任务如RNA-seq和变异调用对生物医学研究至关重要，现有评估方法不统一，且无法确保AI代理在受控扰动下的可靠性。此外，由于工作流常涉及敏感数据，现有模型在隐私约束下可能不适用，因此需要开发一个全面评估套件来弥补这些不足，促进可靠和安全的AI应用。",
      "method": "论文提出了BioAgent Bench基准，包含策划的端到端生物信息学任务（如RNA-seq、变异调用、宏基因组学），任务提示指定具体输出工件以支持自动化评估。方法使用基于大型语言模型（LLM）的评分器来评估管道进展和结果有效性，并引入受控扰动（如输入损坏、诱饵文件和提示膨胀）进行压力测试，关键创新在于结合自动化评估和鲁棒性测试，评估了前沿闭源和开源模型在多个代理框架中的表现。",
      "result": "实验结果显示，前沿AI代理能够完成多步生物信息学管道，无需详细定制，通常可靠地生成请求的最终工件。但在鲁棒性测试中，面对受控扰动时，代理出现故障模式，表明高层管道构建正确不能保证步骤级推理的可靠性。在隐私约束下，闭源模型由于可能不适合敏感数据场景，而开源模型虽完成率较低，但在隐私保护方面更具优势，数据集和评估套件已公开发布以支持进一步研究。",
      "conclusion": "本文的主要贡献是提出了BioAgent Bench，一个公开的生物信息学AI代理评估基准和套件，为标准化评估提供了工具。学术价值在于推动了AI代理在生物信息学领域的可靠性和鲁棒性研究，实际应用中帮助用户根据隐私需求选择合适模型。局限性包括代理在步骤级推理的不足，未来工作可聚焦于改进代理的鲁棒性、扩展基准任务范围，并探索更多评估指标。",
      "tags": [
        "AI Agents",
        "Benchmarking",
        "Bioinformatics",
        "Large Language Models",
        "Robustness Testing"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:49.196503Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21798",
    "title": "CG-MLLM: Captioning and Generating 3D content via Multi-modal Large Language Models",
    "authors": [
      "Junming Huang",
      "Weiwei Xu"
    ],
    "abstract": "Large Language Models(LLMs) have revolutionized text generation and multimodal perception, but their capabilities in 3D content generation remain underexplored. Existing methods compromise by producing either low-resolution meshes or coarse structural proxies, failing to capture fine-grained geometry natively. In this paper, we propose CG-MLLM, a novel Multi-modal Large Language Model (MLLM) capable of 3D captioning and high-resolution 3D generation in a single framework. Leveraging the Mixture-of-Transformer architecture, CG-MLLM decouples disparate modeling needs, where the Token-level Autoregressive (TokenAR) Transformer handles token-level content, and the Block-level Autoregressive (BlockAR) Transformer handles block-level content. By integrating a pre-trained vision-language backbone with a specialized 3D VAE latent space, CG-MLLM facilitates long-context interactions between standard tokens and spatial blocks within a single integrated architecture. Experimental results show that CG-MLLM significantly outperforms existing MLLMs in generating high-fidelity 3D objects, effectively bringing high-resolution 3D content creation into the mainstream LLM paradigm.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21798.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21798",
    "published": "2026-01-29T14:42:46Z",
    "updated": "2026-01-29T14:42:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "CG-MLLM是一种新型多模态大型语言模型，能在单一框架中实现3D描述和高分辨率3D生成。",
      "motivation": "大型语言模型（LLMs）在文本和多模态感知方面已取得突破，但在3D内容生成领域应用有限，现有方法常产生低分辨率网格或粗糙结构，无法原生捕获细粒度几何细节。这一问题的重要性在于3D内容生成对于虚拟现实、增强现实和数字媒体等行业至关重要，而当前方法的不足限制了内容质量和创作效率，亟需创新模型来弥补这一差距，推动技术发展。",
      "method": "CG-MLLM采用创新的Mixture-of-Transformer架构，解耦建模需求：Token-level Autoregressive（TokenAR）Transformer处理token级别内容，Block-level Autoregressive（BlockAR）Transformer处理block级别内容。通过集成预训练视觉-语言骨干网络和专门的3D VAE潜在空间，模型在单一架构中实现标准token与空间块间的长上下文交互，从而支持文本和多模态输入，并生成高分辨率3D输出。",
      "result": "实验结果表明，CG-MLLM在生成高保真3D对象方面显著优于现有的多模态大型语言模型，但摘要未明确说明具体性能指标如准确率或效率数据。与基线方法相比，模型展现出更好的生成效果，有效将高分辨率3D内容创作融入主流LLM范式，证实了其架构的优越性和技术潜力。",
      "conclusion": "本论文的主要贡献是提出CG-MLLM模型，实现了3D描述和高分辨率生成的统一框架。学术价值在于扩展LLMs在3D领域的应用，推动多模态人工智能发展；实际应用价值在于提升3D内容创作精度和效率，为游戏、VR/AR等行业提供支持。未来工作可能包括优化架构和探索更多应用场景，摘要未明确说明具体方向。",
      "tags": [
        "Multi-modal Large Language Models (MLLM)",
        "Mixture-of-Transformer",
        "Token-level Autoregressive Transformer",
        "Block-level Autoregressive Transformer",
        "3D VAE latent space"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:43.547628Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21797",
    "title": "Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation",
    "authors": [
      "Yimin Deng",
      "Yuqing Fu",
      "Derong Xu",
      "Yejing Wang",
      "Wei Ni",
      "Jingtong Gao",
      "Xiaopeng Li",
      "Chengxu Liu",
      "Xiao Han",
      "Guoshuai Zhao",
      "Xiangyu Zhao",
      "Li Zhu",
      "Xueming Qian"
    ],
    "abstract": "Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21797.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21797",
    "published": "2026-01-29T14:42:34Z",
    "updated": "2026-01-29T14:42:34Z",
    "comment": "11 pages, 4 figures",
    "light_analysis": {
      "overview": "本文提出对抗性内存适应机制（AMA），通过模拟任务执行来对齐离线内存构建与任务目标，以解决对话代理处理长对话的挑战。",
      "motivation": "对话代理因上下文窗口限制难以处理长对话，因此开发记忆系统来存储历史信息。现有系统采用离线构建和更新、在线检索的流程，但离线阶段固定且与任务无关：内存构建遵循预定义工作流程，不强调任务相关信息；更新使用通用指标而非任务特定监督。这导致离线内存准备与下游任务要求不一致，从而削弱任务性能。因此，需要一种机制使内存系统在离线阶段就能接收任务感知监督信号，以提高适应性和对齐性。",
      "method": "论文提出Adversarial Memory Adaptation（AMA）机制，通过模拟任务执行对齐内存构建和更新与任务目标。具体步骤包括：首先，挑战者代理基于原始对话生成问答对，模拟下游推理任务；其次，评估者代理评估使用构建内存回答的响应，并进行错误分析；最后，适配器代理根据错误分析结果，对内存构建策略和内容进行双重更新。关键创新在于通过对抗性模拟，在离线阶段引入任务感知监督信号，使系统能动态适应任务需求，并可集成到现有记忆系统中。",
      "result": "在长对话基准数据集LoCoMo上进行了广泛实验，证明了AMA机制的有效性，能够显著增强下游任务性能。然而，摘要未明确说明具体性能指标，如准确率提升或效率改进的数值，需参考论文全文获取更多细节。与基线方法相比，AMA通过任务对齐改善了整体效果，但详细对比数据未在摘要中提供。",
      "conclusion": "本研究的主要贡献是提出对抗性内存适应机制（AMA），可集成到各种现有记忆系统中，增强对下游任务的适应性。通过模拟任务执行，AMA在离线阶段提供任务感知监督，提升对话代理处理长对话的能力。学术价值在于为记忆系统的任务对齐提供了新思路，实际应用价值在于改善对话系统的性能。潜在的局限性或未来工作方向摘要未明确说明。",
      "tags": [
        "Conversational Agents",
        "Memory Systems",
        "Adversarial Adaptation",
        "Task-Oriented Learning",
        "Long Dialogues"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:48.506347Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21796",
    "title": "KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection",
    "authors": [
      "Yaocong Li",
      "Leihan Zhang",
      "Le Zhang",
      "Qiang Yan"
    ],
    "abstract": "Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21796.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21796",
    "published": "2026-01-29T14:41:36Z",
    "updated": "2026-01-29T14:41:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "KID框架通过知识注入和双头学习机制，创新性地提升了基于知识的有害互联网模因检测性能。",
      "motivation": "互联网模因作为社交平台上的数字文化载体，常隐含有害内容，其检测依赖于隐喻和社会文化背景知识，但现有方法主要关注视觉和文本模态信号分析，忽略了理解隐含毒性所需的背景知识，导致检测性能受限，这对自动化内容审核构成重大挑战，因此需要能有效整合外部知识的方法来解决这一问题。",
      "method": "KID采用标签约束蒸馏范式，将复杂模因理解分解为结构化推理链，明确连接视觉证据、背景知识和分类标签，从而实现知识在模因特定语境中的注入；框架使用双头架构，联合优化语义生成和分类目标，以促进对齐的语言推理并保持稳定决策边界，实验基于五个多语言数据集（包括英语、中文和低资源孟加拉语），核心创新在于知识基础和双头学习的协同设计。",
      "result": "在五个多语言数据集上的实验表明，KID在二元和多标签有害模因检测任务上均达到最先进性能，主要评估指标相较于先前最佳方法提升了2.1%到19.7%；消融研究进一步确认了知识注入和双头联合学习的有效性，突出了它们对增强鲁棒性和泛化性的互补贡献。",
      "conclusion": "本研究贡献了KID框架，通过知识注入和双头学习显著改善了有害模因检测，强调了背景知识在内容理解中的重要性，学术价值在于推动多模态人工智能和知识增强学习的发展，实际应用价值在于支持社交平台的内容审核，代码和数据开源促进了可重复研究，未来工作可扩展至更多语言或复杂场景。",
      "tags": [
        "Knowledge Injection",
        "Dual-Head Learning",
        "Label-Constrained Distillation",
        "Structured Reasoning Chains",
        "Harmful Meme Detection"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:05.127508Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21795",
    "title": "Effective LoRA Adapter Routing using Task Representations",
    "authors": [
      "Akash Dhasade",
      "Anne-Marie Kermarrec",
      "Igor Pavlovic",
      "Diana Petrescu",
      "Rafael Pires",
      "Mathis Randl",
      "Martijn de Vos"
    ],
    "abstract": "Low-rank adaptation (LoRA) enables parameter efficient specialization of large language models (LLMs) through modular adapters, resulting in rapidly growing public adapter pools spanning diverse tasks. Effectively using these adapters requires routing: selecting and composing the appropriate adapters for a query. We introduce LORAUTER, a novel routing framework that selects and composes LoRA adapters using task representations rather than adapter characteristics. Unlike existing approaches that map queries directly to adapters, LORAUTER routes queries via task embeddings derived from small validation sets and does not require adapter training data. By operating at the task level, LORAUTER achieves efficient routing that scales with the number of tasks rather than the number of adapters. Experiments across multiple tasks show that LORAUTER consistently outperforms baseline routing approaches, matching Oracle performance (101.2%) when task-aligned adapters exist and achieving state-of-the-art results on unseen tasks (+5.2 points). We further demonstrate the robustness of LORAUTER to very large, noisy adapter pools by scaling it to over 1500 adapters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21795.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21795",
    "published": "2026-01-29T14:41:24Z",
    "updated": "2026-01-29T14:41:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "LORAUTER是一种基于任务表示的LoRA适配器路由框架，实现高效适配器选择和组合。",
      "motivation": "随着LoRA适配器在公共池中快速增长，覆盖多样任务，有效路由成为关键挑战，以便为查询选择和组合适配器。现有方法如直接映射查询到适配器可能需要适配器训练数据，且在处理大规模适配器时效率低下、泛化能力不足。LORAUTER旨在通过任务表示来克服这些限制，提升路由的准确性、可扩展性和对未见任务的适应性。",
      "method": "LORAUTER框架的核心是使用任务表示进行路由，而非依赖适配器特征。它从小型验证集派生任务嵌入，避免了需要适配器训练数据。通过在任务级别操作，路由过程基于任务相似性，实现了与任务数量成比例的扩展，而不受适配器数量影响。关键创新包括任务表示的应用和任务级路由机制，从而降低计算复杂度，提高效率。",
      "result": "实验结果表明，LORAUTER在多个任务上一致优于基线路由方法。具体性能：当任务对齐适配器存在时，LORAUTER的准确率达到Oracle水平的101.2%；在未见任务上，性能提升5.2点，超过了现有最先进方法。此外，LORAUTER展示了鲁棒性，能够有效处理超过1500个适配器的嘈杂池，证明了其在大规模场景下的应用潜力。",
      "conclusion": "LORAUTER成功提出了一种基于任务表示的高效LoRA适配器路由方法，解决了可扩展性和未见任务处理问题。学术上，它为适配器路由引入了新思路，推动了大规模语言模型的高效部署。实际应用中，LORAUTER能优化多任务性能，提高模型部署效率。未来工作可能包括进一步优化任务表示或探索更多路由策略以应对更复杂场景。",
      "tags": [
        "Low-rank Adaptation (LoRA)",
        "Large Language Models",
        "Task Embeddings",
        "Adapter Routing",
        "Efficient Inference"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:36.164465Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21794",
    "title": "Knowledge Vector Weakening: Efficient Training-free Unlearning for Large Vision-Language Models",
    "authors": [
      "Yejin Kim",
      "Dongjun Hwang",
      "Sungmin Cha",
      "Junsuk Choe"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) are widely adopted for their strong multimodal capabilities, yet they raise serious concerns such as privacy leakage and harmful content generation. Machine unlearning has emerged as a promising solution for removing the influence of specific data from trained models. However, existing approaches largely rely on gradient-based optimization, incurring substantial computational costs for large-scale LVLMs. To address this limitation, we propose Knowledge Vector Weakening (KVW), a training-free unlearning method that directly intervenes in the full model without gradient computation. KVW identifies knowledge vectors that are activated during the model's output generation on the forget set and progressively weakens their contributions, thereby preventing the model from exploiting undesirable knowledge. Experiments on the MLLMU and CLEAR benchmarks demonstrate that KVW achieves a stable forget-retain trade-off while significantly improving computational efficiency over gradient-based and LoRA-based unlearning methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21794.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21794",
    "published": "2026-01-29T14:41:01Z",
    "updated": "2026-01-29T14:41:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种无需训练的知识向量弱化方法，用于高效地从大型视觉语言模型中移除特定数据的影响，显著提高计算效率。",
      "motivation": "大型视觉语言模型（LVLMs）凭借强大多模态能力被广泛采用，但也引发了隐私泄露和有害内容生成等严重担忧。机器遗忘技术旨在从训练模型中移除特定数据影响，但现有方法多依赖梯度优化，计算成本高昂，难以适用于大规模 LVLMs。因此，开发更高效、无需训练的遗忘方法成为迫切需求，以应对模型安全和隐私挑战。",
      "method": "本研究提出知识向量弱化（KVW）方法，一种无训练的遗忘学习技术。它直接干预整个模型，无需梯度计算。通过识别模型在遗忘集输出生成过程中激活的知识向量，逐步弱化这些向量的贡献，从而有效防止模型利用不良知识。该方法避免了传统训练过程，简化了操作，提高了实施效率。",
      "result": "在 MLLMU 和 CLEAR 基准上的实验结果显示，KVW 方法能够实现稳定的遗忘-保留性能权衡，同时显著提升了计算效率。与基于梯度和基于 LoRA 的遗忘方法相比，KVW 在保持效果的同时大幅减少了计算开销，证明了其在实际应用中的高效性和可行性。",
      "conclusion": "本研究通过提出知识向量弱化方法，为大型视觉语言模型提供了一种高效、无需训练的遗忘学习方案。学术上，它推进了无训练遗忘技术的发展，填补了现有方法的不足；实际上，有助于解决模型隐私和安全性问题，提升部署可靠性。未来工作可探索该方法在其他领域或模型中的扩展应用，并进一步优化性能。",
      "tags": [
        "Large Vision-Language Models",
        "Machine Unlearning",
        "Training-free Method",
        "Knowledge Vectors",
        "Efficiency Improvement"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:27.536576Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21792",
    "title": "NetMamba+: A Framework of Pre-trained Models for Efficient and Accurate Network Traffic Classification",
    "authors": [
      "Tongze Wang",
      "Xiaohui Xie",
      "Wenduo Wang",
      "Chuyi Wang",
      "Jinzhou Liu",
      "Boyan Huang",
      "Yannan Hu",
      "Youjian Zhao",
      "Yong Cui"
    ],
    "abstract": "With the rapid growth of encrypted network traffic, effective traffic classification has become essential for network security and quality of service management. Current machine learning and deep learning approaches for traffic classification face three critical challenges: computational inefficiency of Transformer architectures, inadequate traffic representations with loss of crucial byte-level features while retaining detrimental biases, and poor handling of long-tail distributions in real-world data. We propose NetMamba+, a framework that addresses these challenges through three key innovations: (1) an efficient architecture considering Mamba and Flash Attention mechanisms, (2) a multimodal traffic representation scheme that preserves essential traffic information while eliminating biases, and (3) a label distribution-aware fine-tuning strategy. Evaluation experiments on massive datasets encompassing four main classification tasks showcase NetMamba+'s superior classification performance compared to state-of-the-art baselines, with improvements of up to 6.44\\% in F1 score. Moreover, NetMamba+ demonstrates excellent efficiency, achieving 1.7x higher inference throughput than the best baseline while maintaining comparably low memory usage. Furthermore, NetMamba+ exhibits superior few-shot learning abilities, achieving better classification performance with fewer labeled data. Additionally, we implement an online traffic classification system that demonstrates robust real-world performance with a throughput of 261.87 Mb/s. As the first framework to adapt Mamba architecture for network traffic classification, NetMamba+ opens new possibilities for efficient and accurate traffic analysis in complex network environments.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21792.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21792",
    "published": "2026-01-29T14:40:04Z",
    "updated": "2026-01-29T14:40:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "NetMamba+通过结合Mamba架构、多模态流量表示和标签分布感知微调，实现高效准确的网络流量分类。",
      "motivation": "随着加密网络流量的快速增长，有效的流量分类对网络安全和服务质量管理至关重要。当前机器学习方法面临三个主要挑战：Transformer架构计算效率低、流量表示不足导致关键字节级特征丢失且保留有害偏见、以及处理现实数据长尾分布的能力差。这些问题限制了分类精度和效率，影响实际应用性能，因此需要创新解决方案来提升分类效果和效率。",
      "method": "NetMamba+框架基于三个关键创新：首先，采用Mamba和Flash Attention机制构建高效架构，优化计算性能；其次，设计多模态流量表示方案，保留字节级重要信息并消除偏见；最后，实施标签分布感知的微调策略，适应复杂数据分布。框架利用预训练模型，通过结构化优化提升表示学习和分类准确性，特别针对网络流量任务适配Mamba架构，实现综合性能改进。",
      "result": "在大规模数据集上评估，涵盖四个主要分类任务，NetMamba+在F1分数上比最先进基线提升高达6.44%。效率方面，推理吞吐量比最佳基线高1.7倍，内存使用保持低水平。框架还展示优秀的小样本学习能力，使用更少标签数据实现更好性能。在线系统测试中，吞吐量达261.87 Mb/s，证明其在实际应用中的鲁棒性和高效性。",
      "conclusion": "作为首个将Mamba架构应用于网络流量分类的框架，NetMamba+的主要贡献是提供高效准确的解决方案，推动Mamba技术在新领域的应用。学术价值在于为复杂网络环境的流量分析开创新可能性，实际应用则提升网络安全和管理性能。未来工作可扩展至更多任务或优化泛化能力，以进一步验证框架的普适性和改进潜力。",
      "tags": [
        "Mamba Architecture",
        "Flash Attention",
        "Multimodal Representation",
        "Fine-tuning",
        "Network Traffic Classification"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:22.015569Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21789",
    "title": "ECSEL: Explainable Classification via Signomial Equation Learning",
    "authors": [
      "Adia Lumadjeng",
      "Ilker Birbil",
      "Erman Acar"
    ],
    "abstract": "We introduce ECSEL, an explainable classification method that learns formal expressions in the form of signomial equations, motivated by the observation that many symbolic regression benchmarks admit compact signomial structure. ECSEL directly constructs a structural, closed-form expression that serves as both a classifier and an explanation. On standard symbolic regression benchmarks, our method recovers a larger fraction of target equations than competing state-of-the-art approaches while requiring substantially less computation. Leveraging this efficiency, ECSEL achieves classification accuracy competitive with established machine learning models without sacrificing interpretability. Further, we show that ECSEL satisfies some desirable properties regarding global feature behavior, decision-boundary analysis, and local feature attributions. Experiments on benchmark datasets and two real-world case studies i.e., e-commerce and fraud detection, demonstrate that the learned equations expose dataset biases, support counterfactual reasoning, and yield actionable insights.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21789.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21789",
    "published": "2026-01-29T14:35:43Z",
    "updated": "2026-01-29T14:35:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "ECSEL是一种通过符号方程学习实现可解释分类的新方法，在保持可解释性的同时达到与现有模型竞争的准确率。",
      "motivation": "该研究旨在解决机器学习模型在关键应用中缺乏可解释性的问题。许多符号回归基准表现出紧凑的符号结构，但现有方法在恢复方程时效率较低或效果不佳。可解释性对于理解模型决策、发现数据集偏差和支持反事实推理至关重要，特别是在欺诈检测等敏感领域。因此，开发一种既高效又能提供清晰解释的分类方法具有重要意义，以满足实际应用中对透明模型的需求。",
      "method": "ECSEL方法的核心是学习符号方程的形式表达式，这些方程直接构成结构化的、封闭形式的分类器和解释。技术路线基于符号回归，利用符号方程的紧凑结构高效构建模型，无需牺牲可解释性。关键创新点在于直接将方程学习与分类任务结合，并通过优化计算过程提高效率。在实验中，使用标准符号回归基准和真实世界数据集（如电子商务和欺诈检测）进行验证，但具体模型架构或数据集细节摘要未明确说明。",
      "result": "在标准符号回归基准上，ECSEL比最先进方法恢复了更高比例的目标方程，并且计算成本显著降低。分类准确率与已建立的机器学习模型竞争，例如在基准数据集上表现优异。此外，ECSEL满足全局特征行为、决策边界分析和局部特征归因的可取特性。在电子商务和欺诈检测的案例研究中，学习的方程成功揭示了数据集偏差，支持了反事实推理，并提供了可操作的见解，证明了其在实际应用中的价值。",
      "conclusion": "本论文的主要贡献是提出了ECSEL，一种基于符号方程学习的可解释分类方法，成功平衡了效率、准确率和可解释性。其学术价值在于为可解释机器学习提供了新思路，特别是在符号方程学习领域，拓展了分类器的设计方式。实际应用价值体现在能够用于电子商务、欺诈检测等场景，通过清晰的方程解释帮助决策者理解模型和发现潜在问题。未来工作可能包括进一步优化算法以处理更复杂的数据集或扩展其应用范围，但局限性摘要未明确说明。",
      "tags": [
        "Signomial Equation Learning",
        "Explainable Classification",
        "Symbolic Regression",
        "Counterfactual Reasoning",
        "Machine Learning Interpretability"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:53.651295Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21786",
    "title": "Synthetic-to-Real Domain Bridging for Single-View 3D Reconstruction of Ships for Maritime Monitoring",
    "authors": [
      "Borja Carrillo-Perez",
      "Felix Sattler",
      "Angel Bueno Rodriguez",
      "Maurice Stephan",
      "Sarah Barnes"
    ],
    "abstract": "Three-dimensional (3D) reconstruction of ships is an important part of maritime monitoring, allowing improved visualization, inspection, and decision-making in real-world monitoring environments. However, most state-ofthe-art 3D reconstruction methods require multi-view supervision, annotated 3D ground truth, or are computationally intensive, making them impractical for real-time maritime deployment. In this work, we present an efficient pipeline for single-view 3D reconstruction of real ships by training entirely on synthetic data and requiring only a single view at inference. Our approach uses the Splatter Image network, which represents objects as sparse sets of 3D Gaussians for rapid and accurate reconstruction from single images. The model is first fine-tuned on synthetic ShapeNet vessels and further refined with a diverse custom dataset of 3D ships, bridging the domain gap between synthetic and real-world imagery. We integrate a state-of-the-art segmentation module based on YOLOv8 and custom preprocessing to ensure compatibility with the reconstruction network. Postprocessing steps include real-world scaling, centering, and orientation alignment, followed by georeferenced placement on an interactive web map using AIS metadata and homography-based mapping. Quantitative evaluation on synthetic validation data demonstrates strong reconstruction fidelity, while qualitative results on real maritime images from the ShipSG dataset confirm the potential for transfer to operational maritime settings. The final system provides interactive 3D inspection of real ships without requiring real-world 3D annotations. This pipeline provides an efficient, scalable solution for maritime monitoring and highlights a path toward real-time 3D ship visualization in practical applications. Interactive demo: https://dlr-mi.github.io/ship3d-demo/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21786.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21786",
    "published": "2026-01-29T14:34:01Z",
    "updated": "2026-01-29T14:34:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种基于合成数据训练的单视图3D重建管道，实现真实船舶高效重建，无需真实世界3D标注。",
      "motivation": "船舶3D重建对海上监测至关重要，能提升可视化、检查和决策能力。然而，当前先进方法通常需要多视图监督、标注的3D真实数据或计算密集，导致难以在实时海上环境中部署。这限制了在实际应用中的实用性，因此开发无需复杂监督的高效单视图重建方法具有重要价值，以解决现有方法在实时性和标注依赖方面的不足。",
      "method": "本研究采用Splatter Image网络，将对象表示为稀疏3D高斯集，实现从单图像快速准确重建。首先在合成ShapeNet船舶数据上微调模型，然后用多样化的自定义3D船舶数据集进一步优化，以桥接合成与真实图像之间的域差距。集成基于YOLOv8的分割模块和自定义预处理确保与重建网络兼容。后处理步骤包括真实世界缩放、居中、方向对齐，并利用AIS元数据和单应性映射将重建结果地理参考到交互式网络地图上。",
      "result": "在合成验证数据上的定量评估显示重建保真度高，表明模型能有效学习合成数据并实现准确重建。在ShipSG数据集中的真实海上图像上进行定性分析，结果证实了模型向操作环境转移的潜力，但摘要未明确说明与基线方法的具体对比数据。最终系统无需真实世界3D标注即可提供交互式3D船舶检查，提升了重建效率和实用性。",
      "conclusion": "本论文贡献了一种高效且可扩展的海上监测3D重建管道，通过合成数据训练和单视图推理，避免了真实标注需求。研究展示了合成到真实域桥接的有效性，为实际应用中的实时3D船舶可视化铺平了道路。学术价值在于推动域适应技术发展，实际应用价值包括促进海上监控自动化和决策支持，未来工作可能涉及优化泛化能力和实时性能。",
      "tags": [
        "Single-View 3D Reconstruction",
        "Synthetic-to-Real Domain Adaptation",
        "3D Gaussian Representation",
        "Splatter Image Network",
        "Maritime Monitoring"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:09.127966Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21780",
    "title": "Quantum LEGO Learning: A Modular Design Principle for Hybrid Artificial Intelligence",
    "authors": [
      "Jun Qi",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Min-Hsiu Hsieh",
      "Hector Zenil",
      "Jesper Tegner"
    ],
    "abstract": "Hybrid quantum-classical learning models increasingly integrate neural networks with variational quantum circuits (VQCs) to exploit complementary inductive biases. However, many existing approaches rely on tightly coupled architectures or task-specific encoders, limiting conceptual clarity, generality, and transferability across learning settings. In this work, we introduce Quantum LEGO Learning, a modular and architecture-agnostic learning framework that treats classical and quantum components as reusable, composable learning blocks with well-defined roles. Within this framework, a pre-trained classical neural network serves as a frozen feature block, while a VQC acts as a trainable adaptive module that operates on structured representations rather than raw inputs. This separation enables efficient learning under constrained quantum resources and provides a principled abstraction for analyzing hybrid models. We develop a block-wise generalization theory that decomposes learning error into approximation and estimation components, explicitly characterizing how the complexity and training status of each block influence overall performance. Our analysis generalizes prior tensor-network-specific results and identifies conditions under which quantum modules provide representational advantages over comparably sized classical heads. Empirically, we validate the framework through systematic block-swap experiments across frozen feature extractors and both quantum and classical adaptive heads. Experiments on quantum dot classification demonstrate stable optimization, reduced sensitivity to qubit count, and robustness to realistic noise.",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21780.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21780",
    "published": "2026-01-29T14:29:21Z",
    "updated": "2026-01-29T14:29:21Z",
    "comment": "In submission",
    "light_analysis": {
      "overview": "本文提出了Quantum LEGO Learning框架，一个模块化和架构无关的学习设计原则，用于混合量子-经典人工智能模型。",
      "motivation": "研究动机在于现有混合量子-经典学习模型结合神经网络与变分量子电路以利用互补归纳偏差，但方法常采用紧密耦合架构或任务特定编码器，导致概念不清、通用性差和跨学习设置可转移性有限。这限制了模型的分析和实际应用，特别是在资源受限量子环境中，因此需要更灵活的模块化设计来提升框架清晰度和适用性。混合模型融合经典高效表示与量子计算潜在优势，但传统实现难以分离组件，阻碍独立优化和理论分析，促使本研究开发标准化组件交互的新框架。",
      "method": "研究方法引入Quantum LEGO Learning框架，将预训练经典神经网络作为冻结特征块，变分量子电路（VQC）作为可训练自适应模块，操作于结构化表示而非原始输入。关键创新在于模块化设计，使组件可重用和可交换，支持在量子资源受限下高效学习。理论方面开发块级泛化理论，将学习误差分解为近似和估计分量，明确量化每个块复杂性和训练状态对整体性能的影响，推广了先前张量网络相关结果。",
      "result": "主要实验结果通过系统块交换实验验证，包括在量子点分类任务上展示稳定优化、对量子比特数量敏感性降低，以及对现实噪声的鲁棒性。摘要未明确说明具体数据，但实验表明与基线方法相比，框架在资源变化下保持性能稳定，减少对硬件参数的依赖，并增强在噪声环境中的适应性，证实了模块化设计的有效性和灵活性。",
      "conclusion": "结论总结该框架提供了混合量子-经典模型的模块化抽象，提升了概念清晰度和可分析性。理论贡献包括推广先前张量网络结果，并识别量子模块在表示能力上超越经典头的条件，为构建高效、可解释混合AI系统奠定基础。研究具有学术价值，促进量子机器学习理论发展，实际应用潜力大，但未来需在更广泛任务和实际量子硬件上验证，并探索模块优化的自动化方法。",
      "tags": [
        "Hybrid Quantum-Classical Learning",
        "Variational Quantum Circuits",
        "Modular Design",
        "Quantum Dot Classification",
        "Generalization Theory"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:41.849459Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21775",
    "title": "Differentiable Knapsack and Top-k Operators via Dynamic Programming",
    "authors": [
      "Germain Vivier-Ardisson",
      "Michaël E. Sander",
      "Axel Parmentier",
      "Mathieu Blondel"
    ],
    "abstract": "Knapsack and Top-k operators are useful for selecting discrete subsets of variables. However, their integration into neural networks is challenging as they are piecewise constant, yielding gradients that are zero almost everywhere. In this paper, we propose a unified framework casting these operators as dynamic programs, and derive differentiable relaxations by smoothing the underlying recursions. On the algorithmic side, we develop efficient parallel algorithms supporting both deterministic and stochastic forward passes, and vector-Jacobian products for the backward pass. On the theoretical side, we prove that Shannon entropy is the unique regularization choice yielding permutation-equivariant operators, and characterize regularizers inducing sparse selections. Finally, on the experimental side, we demonstrate our framework on a decision-focused learning benchmark, a constrained dynamic assortment RL problem, and an extension of discrete VAEs.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21775.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21775",
    "published": "2026-01-29T14:25:35Z",
    "updated": "2026-01-29T14:25:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个通过动态编程实现Knapsack和Top-k算子可微化的统一框架，并开发了高效算法和理论分析。",
      "motivation": "研究动机源于Knapsack和Top-k算子在机器学习中用于选择离散变量子集的重要应用，如决策优化和强化学习。然而，这些算子因其分段常数性质，导致梯度几乎处处为零，难以直接集成到神经网络中进行端到端训练。现有方法缺乏有效的可微近似，这限制了在深度学习模型中处理离散选择问题的能力，尤其是在需要精确控制子集选择的任务中，造成了优化瓶颈。",
      "method": "论文提出一个统一框架，将Knapsack和Top-k算子建模为动态程序，并通过平滑底层递归推导出可微松弛。关键创新点包括使用正则化如Shannon熵来确保置换等变性，并开发高效并行算法支持确定性和随机前向传递，以及向量-Jacobian乘积用于反向传播。这使得算子能无缝集成到神经网络中，提供灵活和可扩展的解决方案，解决了离散算子梯度计算的核心难题。",
      "result": "在实验方面，框架在决策聚焦学习基准、约束动态品种强化学习问题和离散变分自编码器扩展上得到验证。摘要未明确说明具体性能指标，如准确率提升或效率改进，但表明该方法在这些任务中有效应用，可能优于基线方法。实验展示了框架的实用性和泛化能力，支持其在复杂决策和生成模型中的应用。",
      "conclusion": "本研究的主要贡献是提出一个动态编程框架，使Knapsack和Top-k算子可微化，并提供了高效算法和理论证明，如Shannon熵的唯一性和稀疏选择正则化。学术价值在于解决了离散算子集成到神经网络的核心挑战，实际应用价值体现在强化学习、生成模型等领域。未来工作可能涉及扩展到其他离散算子或更复杂场景，进一步提升性能和适用性。",
      "tags": [
        "Dynamic Programming",
        "Differentiable Relaxation",
        "Knapsack Problem",
        "Top-k Selection",
        "Shannon Entropy"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:11.756041Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21771",
    "title": "Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies",
    "authors": [
      "Hadi Banaee",
      "Stephanie Lowry"
    ],
    "abstract": "We present a conceptual space framework for modelling abstract concepts that unfold over time, demonstrated through a chess-based proof-of-concept. Strategy concepts, such as attack or sacrifice, are represented as geometric regions across interpretable quality dimensions, with chess games instantiated and analysed as trajectories whose directional movement toward regions enables recognition of intended strategies. This approach also supports dual-perspective modelling, capturing how players interpret identical situations differently. Our implementation demonstrates the feasibility of trajectory-based concept recognition, with movement patterns aligning with expert commentary. This work explores extending the conceptual spaces theory to temporally realised, goal-directed concepts. The approach establishes a foundation for broader applications involving sequential decision-making and supports integration with knowledge evolution mechanisms for learning and refining abstract concepts over time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21771.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21771",
    "published": "2026-01-29T14:22:43Z",
    "updated": "2026-01-29T14:22:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一个概念空间框架，用于建模随时间演变的抽象概念，通过国际象棋策略作为案例研究，实现了轨迹分析和双视角建模。",
      "motivation": "本研究旨在解决如何建模随时间展开的抽象概念，特别是国际象棋策略如攻击或牺牲。抽象概念建模在认知科学和AI中至关重要，有助于理解顺序决策和认知过程。现有方法可能忽略概念的动态演变和个体解释差异，难以捕捉概念在时间中的实现。通过概念空间框架，论文探索如何更好地识别和模拟这些目标导向概念，为实际应用如游戏AI和决策支持系统奠定基础，提升模型的解释性和适应性。",
      "method": "研究方法基于概念空间理论，将抽象策略概念表示为可解释质量维度上的几何区域。在国际象棋案例中，游戏被实例化为轨迹，通过分析轨迹朝向概念区域的运动来识别意图的策略。关键创新点包括双视角建模，以捕获不同玩家对相同情境的不同解释。技术路线涉及几何表示和轨迹分析，未指定具体数据集或模型架构，但使用概念空间作为框架来映射策略演变，支持学习和知识演化机制的集成。",
      "result": "实验结果表明，基于轨迹的概念识别方法是可行的。在国际象棋概念验证中，分析出的运动模式与专家评论一致，验证了方法的有效性。虽然摘要未提供具体性能指标如准确率，但通过模式对齐证明了轨迹分析在识别抽象策略概念上的潜力。与专家见解的对比增强了结果的可靠性，为未来量化评估和基准测试奠定了基础，展示了该方法在理解动态概念演变方面的应用前景。",
      "conclusion": "本研究的贡献在于扩展概念空间理论到时间实现的目标导向概念，为顺序决策应用如游戏AI或认知建模提供理论基础。它支持知识演化机制的集成，有助于长期学习和抽象概念的精炼。学术价值在于深化概念建模理论，实际应用包括自适应决策和多视角分析。未来工作可探索更广泛领域的应用，集成更多动态机制，或改进模型以处理复杂场景，进一步提升模型的泛化能力和实用性。",
      "tags": [
        "Conceptual Spaces",
        "Trajectory Analysis",
        "Dual-Perspective Modelling",
        "Abstract Concept Modelling"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:40.239309Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21768",
    "title": "Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention",
    "authors": [
      "Alon Rozental"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21768.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21768",
    "published": "2026-01-29T14:17:37Z",
    "updated": "2026-01-29T14:17:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了Zonkey，一种分层扩散语言模型，通过可微分tokenization和概率注意力机制，解决大语言模型中固定tokenizer的限制，实现端到端优化和适应性提升。",
      "motivation": "大语言模型（LLMs）在自然语言处理中取得了革命性进展，但现有模型依赖固定、不可微分的tokenizers如字节对编码（BPE），这阻碍了端到端优化的可能性，并限制了对噪声或领域特定数据的适应性。传统tokenizers基于规则或熵学习，无法动态调整分割，导致模型在面对多样化输入时性能受限。因此，开发可微分的tokenization方法对于提升LLMs的灵活性和泛化能力具有重要研究价值。",
      "method": "Zonkey采用分层扩散模型架构，核心是可微分tokenizer（Segment Splitter），它通过学习概率起始序列（BOS）决策，实现自适应分割，无需显式监督即可识别语言边界（如词间空格、句点）。概率注意力机制创新性地结合位置特定存在概率，模拟软掩码处理理论上无限序列，并保持梯度传播以支持可变长度输出。分层结构将序列从字符n-gram压缩到词级和句子级抽象表示，使用去噪扩散混合模型（DDMM）在潜在空间进行稳定重建，Stitcher组件确保分割间的重叠不变性。模型在Wikipedia数据集上训练，实现从原始字符到文档级的端到端可训练管道。",
      "result": "在Wikipedia数据集上进行训练后，Zonkey能够从噪声生成连贯、可变长度的文本，展现出层次结构的涌现特性。与基于熵的可学习tokenizers相比，Zonkey在定性上表现出更好的对齐数据分布，尽管摘要未提供具体性能指标如准确率提升。实验结果初步验证了可微分tokenization在改善文本生成质量和适应性方面的潜力，表明该方法在推动全梯度基础LLMs上的可行性。",
      "conclusion": "Zonkey通过集成可微分tokenization和概率注意力，为全梯度基础的大语言模型发展做出贡献。核心创新在于提供了一个完全可训练的管道，增强了模型对噪声和领域特定数据的适应性，并支持可扩展生成。学术上，该方法解决了tokenizer不可微的问题，启发了更灵活的优化策略；实际应用中，有潜力用于领域适应性和大规模文本生成任务。未来工作可探索在多样化数据集上的性能验证和模型扩展，以进一步评估其泛化能力。",
      "tags": [
        "Diffusion Model",
        "Differentiable Tokenization",
        "Probabilistic Attention",
        "Hierarchical Model",
        "Denoising Diffusion Mixed Model"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:46.548879Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21767",
    "title": "Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond",
    "authors": [
      "Wei Zhu"
    ],
    "abstract": "Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21767.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21767",
    "published": "2026-01-29T14:16:51Z",
    "updated": "2026-01-29T14:16:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过系统评估ChatGPT在医学信息提取任务上的性能、可解释性、置信度、忠实度和不确定性，揭示了其在医疗领域应用的潜力和局限性。",
      "motivation": "研究动机源于大型语言模型如ChatGPT在自然语言处理任务中的广泛兴趣，特别是在医学信息提取这一关键领域。现有微调模型在MedIE任务上表现优异，但ChatGPT作为通用模型的能力尚未全面评估。医学信息提取对准确性和可靠性要求高，评估ChatGPT的多维能力有助于理解其在医疗NLP中的应用前景，并识别现有方法的不足，如过度自信和不确定性管理问题，从而推动更可靠的AI解决方案开发。",
      "method": "研究方法包括在4个不同的医学信息提取任务和6个基准数据集上对ChatGPT进行全面评估。通过系统分析，测量了性能、可解释性、置信度、忠实度和不确定性等多个维度。具体任务涉及标准MedIE数据集，如实体识别或关系提取，并与微调的基线模型进行比较。关键创新点在于多维评估框架，不仅关注准确性，还考察解释质量和模型信心，从而提供更全面的能力画像，摘要未明确说明具体数据集名称和评估指标细节。",
      "result": "实验结果显示，ChatGPT在医学信息提取任务上的性能得分落后于微调的基线模型。它能提供高质量的解释，显示出良好的可解释性，但存在过度自信的问题。在大多数情况下，ChatGPT对原始文本保持高忠实度，表明其生成内容可靠。不确定性分析表明，生成过程中的不确定性会导致信息提取结果的不确定，这可能限制其在MedIE任务中的实际应用。摘要未提供具体性能指标数据，如准确率或效率改进值。",
      "conclusion": "本研究的主要贡献在于系统评估了ChatGPT在医学信息提取任务上的多维能力，揭示了其在性能、可解释性和置信度方面的优缺点。学术上，这为LLMs在特定领域的应用研究提供了实证基础，强调了评估模型多维特性的重要性；应用上，指出ChatGPT的局限性，如不确定性管理，对医疗NLP系统开发有指导意义。未来工作可探索结合微调或改进不确定性量化以增强实用性，并扩展到更多医疗任务。",
      "tags": [
        "Large Language Models",
        "ChatGPT",
        "Medical Information Extraction",
        "Explainability",
        "Uncertainty Quantification"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:49.720615Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21766",
    "title": "CoFrGeNet: Continued Fraction Architectures for Language Generation",
    "authors": [
      "Amit Dhurandhar",
      "Vijil Chenthamarakshan",
      "Dennis Wei",
      "Tejaswini Pedapati",
      "Karthikeyan Natesan Ramamurthy",
      "Rahul Nair"
    ],
    "abstract": "Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\\frac{2}{3}$ to $\\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21766.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21766",
    "published": "2026-01-29T14:16:39Z",
    "updated": "2026-01-29T14:16:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出基于连分数的CoFrGeNet架构，通过新组件替代Transformer块，以更少参数实现语言生成任务的有竞争力性能。",
      "motivation": "Transformers是语言生成的优选架构，但参数密集且计算成本高，现有方法在资源效率和优化方面存在不足。本研究旨在开发更高效的架构，通过引入新函数类，减少参数数量并保持模型性能，以降低计算负担，满足大规模工业应用中对高效AI模型的需求，从而解决资源消耗和训练时间长的实际问题。",
      "method": "论文基于连分数理论引入新函数类，实现为CoFrGeNet架构家族。核心创新是设计可替代Transformer中多头注意力和前馈网络的新组件，这些组件参数更少；并推导自定义梯度公式，比标准PyTorch梯度更准确高效地优化组件。实验采用GPT2-xl（1.5B参数）和Llama3（3.2B参数）两种Transformer架构，在OpenWebText、GneissWeb和包含九个数据集的docling混合数据上进行预训练，以验证组件的有效性和通用性。",
      "result": "在多个下游任务（包括分类、问答、推理和文本理解）上的实验结果显示，CoFrGeNet模型性能与原始Transformer模型竞争，有时甚至更优，具体表现为参数数量减少到原始模型的2/3到1/2，且预训练时间缩短。这表明新架构在保持或提升性能的同时显著提高了效率，尽管摘要未提供具体准确率数字，但基于参数减少和训练时间优化，验证了其有效性。",
      "conclusion": "论文的主要贡献是提出了基于连分数的CoFrGeNet架构，有效减少参数并保持语言生成能力，具有学术创新和实际应用价值。该架构作为插件式替换，易于集成到现有工作流中，为高效AI模型开发提供新方向。未来通过硬件定制化实现，有望进一步提升性能，推动资源友好型深度学习架构的发展，摘要未明确说明局限性，但暗示了未来优化空间。",
      "tags": [
        "Continued Fractions",
        "Transformer Architecture",
        "Parameter Efficiency",
        "Custom Gradient Optimization",
        "Language Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:17.035562Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21760",
    "title": "Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling",
    "authors": [
      "Ruian Tie",
      "Wenbo Xiong",
      "Zhengyu Shi",
      "Xinyu Su",
      "Chenyu jiang",
      "Libo Wu",
      "Hao Li"
    ],
    "abstract": "Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without paired data during training. ZSSD leverages a Physics-Consistent Climate Prior learned from reanalysis data, conditioned on geophysical boundaries and temporal information to enforce physical validity. Furthermore, to enable robust inference across varying GCMs, we introduce Unified Coordinate Guidance. This strategy addresses the vanishing gradient problem in vanilla DPS and ensures consistency with large-scale fields. Results show that ZSSD significantly outperforms existing zero-shot baselines in 99th percentile errors and successfully reconstructs complex weather events, such as tropical cyclones, across heterogeneous GCMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21760.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21760",
    "published": "2026-01-29T14:14:41Z",
    "updated": "2026-01-29T14:14:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Zero-Shot Statistical Downscaling (ZSSD)框架，利用扩散后采样和物理一致先验，实现无需配对数据的统计降尺度。",
      "motivation": "传统监督气候降尺度方法因缺乏全球气候模型（GCMs）的配对训练数据和固有域间隙，难以有效泛化。同时，现有零样本方法在处理大尺度因子时面临物理不一致性和梯度消失问题，限制了其准确性和应用范围。这凸显了开发一种能结合物理一致性和泛化能力的零样本降尺度方法的紧迫性，以提升气候建模的可靠性和实际预测价值。",
      "method": "ZSSD采用零样本框架，无需训练时配对数据。其核心包括从再分析数据学习Physics-Consistent Climate Prior，基于地球物理边界和时间信息条件化，以确保物理有效性。此外，引入Unified Coordinate Guidance策略，解决扩散后采样中的梯度消失问题，优化推理过程，保证降尺度结果与大规模气候场的一致性，从而提升跨不同GCMs的鲁棒性。",
      "result": "实验结果显示，ZSSD在99th百分位误差指标上显著优于现有零样本基线方法，性能提升明显。它能成功重建复杂天气事件如热带气旋，并在多种异质GCMs中表现优异，证明了其在物理一致性和泛化能力方面的优势，有效应对极端天气模拟的挑战。",
      "conclusion": "本研究的主要贡献是提出ZSSD框架，通过整合物理一致先验和统一坐标指导，解决了零样本降尺度中的物理不一致和梯度消失问题。这推动了气候降尺度技术的进步，提高了预测精度和物理可靠性，具有重要学术和实际应用价值，如改进极端天气预警。未来工作可进一步优化先验模型，扩展到更广泛的气候场景。",
      "tags": [
        "Zero-Shot Learning",
        "Diffusion Posterior Sampling",
        "Climate Prior",
        "Geophysical Boundaries",
        "Statistical Downscaling"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:15.279619Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21754",
    "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
    "authors": [
      "Haoyu Wang",
      "Guozheng Ma",
      "Shugang Cui",
      "Yilun Kong",
      "Haotian Luo",
      "Li Shen",
      "Mengya Gao",
      "Yichao Wu",
      "Xiaogang Wang",
      "Dacheng Tao"
    ],
    "abstract": "While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight \"scouts\" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21754.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21754",
    "published": "2026-01-29T14:08:41Z",
    "updated": "2026-01-29T14:08:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出SCOUT框架，通过解耦探索与利用，利用轻量级‘侦察兵’高效探索非语言任务，显著提升大型语言模型性能并节省计算资源。",
      "motivation": "大型语言模型在语言任务中表现卓越，但在未见的非语言环境（如符号或空间任务）中性能受限。现有研究将问题归因于预训练与测试分布的不匹配，但本文指出主要瓶颈是探索成本过高：掌握这些任务需要大量试错，对于参数量大的LLMs在高维语义空间中计算不切实际。这限制了LLMs在需要经验学习的广泛任务中的应用，突显了开发高效探索方法的紧迫性。",
      "method": "论文提出SCOUT框架，核心创新是解耦探索与利用。采用轻量级‘侦察兵’（如小型MLPs）快速探索环境动态，其速度和规模远超LLMs。收集的轨迹通过监督微调引导LLM，随后进行多轮强化学习以激活其潜在世界知识。这种分离方法降低了探索成本，使LLM能更高效地适应非语言任务，结合SFT和RL阶段强化知识利用。",
      "result": "实验结果表明，使用SCOUT框架的Qwen2.5-3B-Instruct模型在非语言任务中平均得分达0.86，显著优于专有模型如Gemini-2.5-Pro（0.60）。同时，该方法节省约60%的GPU小时消耗，在提升性能的同时大幅降低计算成本，证明了其在效率和效果上的双重优势，优于基线方法。",
      "conclusion": "本研究证明探索成本是LLMs在非语言任务中性能受限的主要瓶颈，SCOUT框架通过解耦探索与利用有效解决。学术上，它为LLMs的适应性学习提供了新范式；实际上，降低了计算开销，扩展了应用范围。局限性可能包括任务泛化能力，未来工作可探索在更复杂场景中的应用或进一步优化探索策略。",
      "tags": [
        "Large Language Model",
        "Supervised Fine-Tuning",
        "Reinforcement Learning",
        "Multi-Layer Perceptron",
        "Exploration-Exploitation"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:36.973209Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21751",
    "title": "Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation",
    "authors": [
      "Jiankun Peng",
      "Jianyuan Guo",
      "Ying Xu",
      "Yue Liu",
      "Jiashuang Yan",
      "Xuanwei Ye",
      "Houhua Li",
      "Xiaoming Wang"
    ],
    "abstract": "Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a \"Granularity Rigidity\" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling \"densification on demand\" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21751.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21751",
    "published": "2026-01-29T14:06:23Z",
    "updated": "2026-01-29T14:06:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "DGNav框架通过动态拓扑感知机制解决视觉语言导航中的“粒度刚性”问题，提升导航精度和安全性。",
      "motivation": "视觉语言导航在连续环境（VLN-CE）中需将高级语言指令接地为精确空间动作，现有拓扑规划方法依赖固定几何阈值采样节点，导致“粒度刚性”问题：在简单区域过采样造成计算冗余，在高不确定性区域欠采样增加碰撞风险，限制了导航的适应性和效率。这在实际应用中至关重要，因为精确导航对机器人等领域有广泛影响，但现有方法未能动态调整以适应环境复杂性，亟待改进以平衡安全与性能。",
      "method": "论文提出DGNav框架，核心创新包括Scene-Aware Adaptive Strategy，它基于预测路径点的分散情况动态调整图构建阈值，实现按需密集采样；以及Dynamic Graph Transformer，融合视觉、语言和几何线索重构图连接性，通过动态边缘权重过滤拓扑噪声，增强指令遵循。实验在R2R-CE和RxR-CE基准数据集上进行，利用这些基准评估导航性能，框架通过自适应机制优化图结构，提高环境适应性。",
      "result": "在R2R-CE和RxR-CE基准测试中，DGNav展现了优越的导航性能和强大的泛化能力。消融研究确认框架在导航效率和安全性之间实现了优化权衡，但具体性能指标如准确率提升百分比摘要未明确说明，暗示相比基线方法有显著改进，尤其是在减少计算冗余和降低碰撞风险方面，提升了整体导航精度。",
      "conclusion": "DGNav通过动态拓扑感知机制成功解决了现有方法的“粒度刚性”限制，显著提升了视觉语言导航的精度、安全性和效率。该研究为智能体导航提供了新的技术路线，具有重要的学术价值和实际应用潜力，例如在自主机器人导航中。未来工作可探索扩展到更复杂或动态环境，并可能结合更多传感器数据以增强鲁棒性。",
      "tags": [
        "Vision-Language Navigation",
        "Dynamic Topological Navigation",
        "Graph Transformer",
        "Adaptive Sampling",
        "Continuous Environments"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:20.711179Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21750",
    "title": "FISMO: Fisher-Structured Momentum-Orthogonalized Optimizer",
    "authors": [
      "Chenrui Xu",
      "Wenjing Yan",
      "Ying-Jun Angela Zhang"
    ],
    "abstract": "Training large-scale neural networks requires solving nonconvex optimization where the choice of optimizer fundamentally determines both convergence behavior and computational efficiency. While adaptive methods like Adam have long dominated practice, the recently proposed Muon optimizer achieves superior performance through orthogonalized momentum updates that enforce isotropic geometry with uniform singular values. However, this strict isotropy discards potentially valuable curvature information encoded in gradient spectra, motivating optimization methods that balance geometric structure with adaptivity. We introduce FISMO (Fisher-Structured Momentum-Orthogonalized) optimizer, which generalizes isotropic updates to incorporate anisotropic curvature information through Fisher information geometry. By reformulating the optimizer update as a trust-region problem constrained by a Kronecker-factored Fisher metric, FISMO achieves structured preconditioning that adapts to local loss landscape geometry while maintaining computational tractability. We establish convergence guarantees for FISMO in stochastic nonconvex settings, proving an $\\mathcal{O}(1/\\sqrt{T})$ rate for the expected squared gradient norm with explicit characterization of variance reduction through mini-batching. Empirical evaluation on image classification and language modeling benchmarks demonstrates that FISMO achieves superior training efficiency and final performance compared to established baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21750.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21750",
    "published": "2026-01-29T14:05:04Z",
    "updated": "2026-01-29T14:05:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "FISMO优化器通过Fisher信息几何和结构预条件，泛化各向同性更新以纳入曲率信息，实现高效非凸优化。",
      "motivation": "在训练大规模神经网络时，优化器选择对收敛行为和计算效率至关重要。当前，自适应方法如Adam长期主导实践，但Muon优化器通过正交化动量强制执行各向同性几何，虽然提升了性能，却丢弃了梯度谱中编码的潜在有价值曲率信息。这可能导致在复杂非凸损失地形中优化不足，因此需要开发能平衡几何结构和自适应性的方法，以更有效地利用局部几何特征，解决现有方法的局限性。",
      "method": "FISMO优化器通过Fisher信息几何将各向同性更新泛化，以纳入各向异性曲率信息。核心方法包括重新将优化器更新表述为受Kronecker因子化Fisher度量约束的信任区域问题，从而实现结构预条件，适应局部损失地形几何。该方法结合动量正交化和几何自适应，保持计算可处理性，不依赖特定数据集或模型架构，适用于一般神经网络训练，并基于随机非凸优化理论建立收敛保证。",
      "result": "在图像分类和语言建模基准测试中，FISMO相比现有基线如Adam和Muon，实现了卓越的训练效率和最终性能，摘要未明确说明具体数据点，但强调其优势。理论分析证明了在随机非凸设置下，具有O(1/√T)的期望平方梯度范数减少速率，并通过小批量显式减少方差，实证评估支持其在多个任务上的性能提升和效率改进。",
      "conclusion": "FISMO通过整合Fisher信息几何和动量正交化，提供了一种新颖的优化方法，有效平衡了几何结构和自适应性。其主要贡献包括理论收敛保证和实证性能提升，对大规模神经网络训练的学术和实际应用具有重要价值。未来工作可探索扩展至其他优化场景或进一步优化计算效率，摘要未明确说明具体局限性。",
      "tags": [
        "Fisher Information Geometry",
        "Momentum Optimization",
        "Trust-Region Methods",
        "Kronecker Factorization",
        "Nonconvex Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:30.820515Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21747",
    "title": "Temporal Sepsis Modeling: a Fully Interpretable Relational Way",
    "authors": [
      "Vincent Lemaire",
      "Nédra Meloulli",
      "Pierre Jaquet"
    ],
    "abstract": "Sepsis remains one of the most complex and heterogeneous syndromes in intensive care, characterized by diverse physiological trajectories and variable responses to treatment. While deep learning models perform well in the early prediction of sepsis, they often lack interpretability and ignore latent patient sub-phenotypes. In this work, we propose a machine learning framework by opening up a new avenue for addressing this issue: a relational approach. Temporal data from electronic medical records (EMRs) are viewed as multivariate patient logs and represented in a relational data schema. Then, a propositionalisation technique (based on classic aggregation/selection functions from the field of relational data) is applied to construct interpretable features to \"flatten\" the data. Finally, the flattened data is classified using a selective naive Bayesian classifier. Experimental validation demonstrates the relevance of the suggested approach as well as its extreme interpretability. The interpretation is fourfold: univariate, global, local, and counterfactual.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21747.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21747",
    "published": "2026-01-29T14:02:26Z",
    "updated": "2026-01-29T14:02:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一个完全可解释的关系方法来建模脓毒症时间数据，以提高预测的可解释性。",
      "motivation": "脓毒症是重症监护中复杂且异质的综合征，具有多样化的生理轨迹和治疗响应。现有深度学习模型在早期预测中表现良好，但缺乏可解释性，忽略了患者的潜在亚表型，这限制了临床应用的信任度和个性化治疗的有效性。因此，开发可解释的机器学习方法对于改善脓毒症管理至关重要。",
      "method": "论文采用关系数据处理方法，将电子病历的时间序列数据视为多元患者日志，并在关系数据模式中表示。通过命题化技术，基于经典聚合和选择函数，构建可解释特征以扁平化数据。然后，使用选择性朴素贝叶斯分类器进行分类。关键创新点在于结合了关系数据理论和多层面可解释性框架。",
      "result": "实验验证表明，该方法在脓毒症预测中具有相关性和极高的可解释性。可解释性包括单变量、全局、局部和反事实四个层面。摘要未明确说明具体性能指标，但暗示该方法有效且优于缺乏可解释性的基线方法。",
      "conclusion": "主要贡献是开发了一个完全可解释的机器学习框架，整合关系数据方法处理时间序列数据，提高了脓毒症预测的可解释性。该研究具有学术价值，推动了可解释AI在医疗领域的应用。局限性可能包括未与深度学习模型详细比较预测性能；未来工作可扩展应用到其他医疗条件或优化模型效率。",
      "tags": [
        "Relational Data",
        "Temporal Modeling",
        "Interpretable Machine Learning",
        "Propositionalisation",
        "Naive Bayesian Classifier"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:45.541368Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21744",
    "title": "Temporal Guidance for Large Language Models",
    "authors": [
      "Hong-Kai Zheng",
      "Piji Li"
    ],
    "abstract": "Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21744.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21744",
    "published": "2026-01-29T14:01:00Z",
    "updated": "2026-01-29T14:01:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于时间维度的对比指导策略TeGu，用于提升大语言模型的生成质量并减少计算开销。",
      "motivation": "研究动机源于对比解码（CD）方法虽能增强大语言模型的生成质量，但引入显著计算开销，而现有内部自对比解码方法如DoLa依赖于层间差异，在小规模模型上表现不稳定。这个问题重要性在于随着LLMs广泛应用，高效且稳定的生成方法需求迫切，现有方法在计算效率和稳定性方面存在不足，限制了实际部署。",
      "method": "基于大语言模型表现出局部偏好的观察，论文提出了Temporal Guidance (TeGu)，一种沿时间维度的对比指导策略。该方法巧妙地利用多令牌预测（MTP）构建较弱的业余预测，用于模型的自对比。为标准化实现，引入了轻量级的条件MTP投影器（cMTPP），避免其他MTP模块需要维护多个独立网络的问题，从而降低复杂度并提升效率。关键创新在于时间维度对比替代传统层间对比，结合MTP和cMTPP实现高效自对比。",
      "result": "在各种模型系列和基准测试中，TeGu实现了显著的性能提升，同时保持了较低的额外内存消耗和计算开销。与基线方法如Contrastive Decoding和DoLa相比，TeGu在提升生成质量方面表现更优，但摘要未明确说明具体性能指标数字如准确率或效率改进百分比。",
      "conclusion": "论文的主要贡献是提出了TeGu策略，通过时间维度对比优化大语言模型的生成过程。该方法具有学术价值，提供了一种更稳定和高效的对比解码方式；实际应用价值在于能在提升模型性能的同时降低计算成本，有利于资源受限环境下的部署。摘要未明确说明潜在局限性或未来工作方向。",
      "tags": [
        "Large Language Model",
        "Contrastive Decoding",
        "Multi-Token Prediction",
        "Temporal Guidance",
        "Conditional MTP Projector"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:14.753166Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21742",
    "title": "Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems",
    "authors": [
      "Ruiwen Zhou",
      "Maojia Song",
      "Xiaobao Wu",
      "Sitao Cheng",
      "Xunjian Yin",
      "Yuxi Xie",
      "Zhuoqun Hao",
      "Wenyue Hua",
      "Liangming Pan",
      "Soujanya Poria",
      "Min-Yen Kan"
    ],
    "abstract": "Individual agents in multi-agent (MA) systems often lack robustness, tending to blindly conform to misleading peers. We show this weakness stems from both sycophancy and inadequate ability to evaluate peer reliability. To address this, we first formalize the learning problem of history-aware reference, introducing the historical interactions of peers as additional input, so that agents can estimate peer reliability and learn from trustworthy peers when uncertain. This shifts the task from evaluating peer reasoning quality to estimating peer reliability based on interaction history. We then develop Epistemic Context Learning (ECL): a reasoning framework that conditions predictions on explicitly-built peer profiles from history. We further optimize ECL by reinforcement learning using auxiliary rewards. Our experiments reveal that our ECL enables small models like Qwen 3-4B to outperform a history-agnostic baseline 8x its size (Qwen 3-30B) by accurately identifying reliable peers. ECL also boosts frontier models to near-perfect (100%) performance. We show that ECL generalizes well to various MA configurations and we find that trust is modeled well by LLMs, revealing a strong correlation in trust modeling accuracy and final answer quality.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21742.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21742",
    "published": "2026-01-29T13:59:32Z",
    "updated": "2026-01-29T13:59:32Z",
    "comment": "Codes and data are available at https://github.com/skyriver-2000/epistemic-context-learning",
    "light_analysis": {
      "overview": "本文提出了 Epistemic Context Learning (ECL) 框架，通过基于历史互动建模同伴信任，显著提升多代理系统中大型语言模型的鲁棒性和推理准确性。",
      "motivation": "在多代理系统中，个体代理常因奉承倾向和评估能力不足而盲目听从误导性同伴，导致系统整体鲁棒性差和决策失误。现有方法往往忽略同伴的互动历史，无法准确评估其可靠性，限制了代理从可信源学习的能力。该研究旨在解决这一问题，通过引入历史感知的学习机制，强调信任建模在提升多代理系统性能中的重要性，以克服传统方法的不足。",
      "method": "该研究首先形式化了历史感知参考的学习问题，将同伴的历史互动作为额外输入，使代理能估计同伴可靠性并在不确定时从可信同伴学习。提出的 Epistemic Context Learning (ECL) 框架通过明确构建同伴档案来条件化预测，核心创新在于从评估推理质量转向基于历史互动估计可靠性。进一步使用强化学习和辅助奖励优化 ECL，增强模型的适应性，并基于 Qwen 等大型语言模型实现架构。",
      "result": "实验结果显示，ECL 框架使小型模型 Qwen 3-4B 在任务中超越历史无知的基线模型 Qwen 3-30B（基线模型大小为8倍），通过准确识别可靠同伴实现性能显著提升。前沿模型在 ECL 加持下达到接近完美的100%性能。ECL 在各种多代理配置中泛化良好，并发现信任建模准确性与最终答案质量呈强相关，验证了方法在提升系统效果方面的有效性。",
      "conclusion": "本文贡献在于提出 ECL 框架，有效解决了多代理系统中的信任问题，提升了代理的鲁棒性和决策能力。学术上为信任建模提供了基于历史互动的新方法，实际应用中可增强多代理系统的可靠性和适应性。局限性可能在于对历史数据质量的依赖，未来工作可探索更复杂互动场景、模型泛化以及与其他学习框架的结合。",
      "tags": [
        "Multi-Agent Systems",
        "Epistemic Context Learning",
        "Reinforcement Learning",
        "Large Language Models",
        "Trust Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:26.052914Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21739",
    "title": "Why Adam Works Better with $β_1 = β_2$: The Missing Gradient Scale Invariance Principle",
    "authors": [
      "Alberto Fernández-Hernández",
      "Cristian Pérez-Corral",
      "Jose I. Mestre",
      "Manuel F. Dolz",
      "Enrique S. Quintana-Ortí"
    ],
    "abstract": "Adam has been at the core of large-scale training for almost a decade, yet a simple empirical fact remains unaccounted for: both validation scores and the qualitative behaviour of the training runs improve when the momentum parameters satisfy $β_{1}=β_{2}$. Some recent studies have reported this pattern, but there is still no explanation for why this choice helps. We show that this choice is closely tied to a structural property that we refer to as \\textit{gradient scale invariance}. We formalize this notion and prove that Adam becomes gradient scale invariant of first order if and only if $β_{1}=β_{2}$. This perspective places the balanced regime of Adam in direct alignment with the design principles underlying several recent optimizers that explicitly enforce scale-robust updates. The theory is supported by experiments across vision and language tasks, and across different architectural families, in which rescaling the gradient has a markedly smoother effect on the update when $β_{1}=β_{2}$. Overall, our results offer a coherent explanation for an open question in the behavior of Adam and provide a simple principle that helps guide the design of future optimizers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21739.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21739",
    "published": "2026-01-29T13:56:11Z",
    "updated": "2026-01-29T13:56:11Z",
    "comment": "23 pages, 8 figures. Preprint",
    "light_analysis": {
      "overview": "本文解释了Adam优化器在动量参数β₁=β₂时表现更优的原因，通过提出梯度尺度不变性原理。",
      "motivation": "该研究旨在解决为什么Adam优化器在动量参数相等时验证分数和训练行为改善的实际问题。Adam作为近十年大规模训练的核心，其性能优化对深度学习至关重要，但现有方法仅观察到β₁=β₂时的改进现象，缺乏理论解释，这限制了优化器设计的理论基础和稳定性提升。因此，探究这一问题有助于填补优化算法中的知识空白，促进更高效的训练流程。",
      "method": "研究通过形式化梯度尺度不变性概念，提出Adam优化器在β₁=β₂时具有一阶梯度尺度不变性的理论框架。核心方法是数学证明，表明当且仅当动量参数相等时，Adam的更新对梯度缩放具有不变性，这与近期其他优化器的尺度鲁棒设计原则直接对齐。关键创新点在于将经验观察提升为理论原则，无需依赖特定数据集或模型架构，而是基于优化算法的结构性质分析。",
      "result": "实验在视觉和语言任务以及不同模型架构中进行，结果显示当β₁=β₂时，梯度重新缩放对优化更新的影响显著更平滑，验证了梯度尺度不变性理论的正确性。虽然摘要未提供具体性能指标，但强调了定性改进，与基线方法相比，这种设置使训练过程更稳定，支持了理论预测的实际应用价值。",
      "conclusion": "研究为Adam优化器行为中的开放问题提供了连贯解释，提出了梯度尺度不变性原理，这不仅深化了对优化算法的理论理解，还为未来优化器设计提供了指导原则。学术价值在于填补了经验观察与理论解释之间的鸿沟，实际应用价值体现在提高训练稳定性和效率。未来工作可扩展此原理到其他优化算法或探索更复杂的尺度不变性形式。",
      "tags": [
        "Adam Optimizer",
        "Gradient Scale Invariance",
        "Momentum Parameters",
        "Optimization Theory",
        "Experimental Validation"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:28.226795Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21738",
    "title": "From Global to Granular: Revealing IQA Model Performance via Correlation Surface",
    "authors": [
      "Baoliang Chen",
      "Danni Huang",
      "Hanwei Zhu",
      "Lingyu Zhu",
      "Wei Zhou",
      "Shiqi Wang",
      "Yuming Fang",
      "Weisi Lin"
    ],
    "abstract": "Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \\textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \\textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \\textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \\textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21738.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21738",
    "published": "2026-01-29T13:55:26Z",
    "updated": "2026-01-29T13:55:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Granularity-Modulated Correlation（GMC），通过相关表面为图像质量评估模型提供细粒度性能分析，克服了传统全局相关性指标的局限。",
      "motivation": "图像质量评估（IQA）模型的评估长期依赖Pearson线性相关系数（PLCC）和Spearman等级相关系数（SRCC）等全局相关性指标，但这些标量指标无法捕捉局部性能变化，例如模型在高或低质量图像上的排序一致性差异，以及对小差异图像对的分辨能力。这些问题导致互补行为不可见，且指标对测试样本质量分布敏感，使得跨数据集比较不稳定，影响了模型评估的可靠性和部署效果。",
      "method": "论文提出GMC方法，包括两个核心组件：Granularity Modulator基于绝对MOS值和成对MOS差异（|ΔMOS|）应用高斯加权相关性，以检查局部性能变化；Distribution Regulator正则化相关性以减少非均匀质量分布的偏差。通过将相关值作为MOS和|ΔMOS|的联合函数映射，生成相关表面，提供IQA性能的3D表示，实现了结构化、细粒度的分析。摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "在标准基准上的实验显示，GMC能够揭示标量指标不可见的性能特征，例如模型在不同质量范围或小差异图像对上的表现差异。与PLCC和SRCC等全局指标相比，GMC提供了更信息丰富和可靠的性能分析，有助于IQA模型的详细比较和优化部署。摘要未给出具体准确率数据，但强调了GMC在克服分布偏差和提升分析有效性方面的优势。",
      "conclusion": "GMC通过相关表面实现了对IQA模型的细粒度评估，解决了传统标量指标无法捕捉局部性能和分布敏感性的问题，为模型分析和比较引入了新范式。其学术价值在于提供结构化评估方法，实际应用价值在于提升IQA模型部署的可靠性。摘要未明确说明局限性或未来工作，但可推断未来可能扩展到其他评估领域或优化方法实现。",
      "tags": [
        "Image Quality Assessment",
        "Correlation Metrics",
        "Granularity-Modulated Correlation",
        "Gaussian-weighted correlation",
        "Correlation Surface"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:34.986757Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21737",
    "title": "Mixed-Precision Training and Compilation for RRAM-based Computing-in-Memory Accelerators",
    "authors": [
      "Rebecca Pelke",
      "Joel Klein",
      "Jose Cubero-Cascante",
      "Nils Bosbach",
      "Jan Moritz Joseph",
      "Rainer Leupers"
    ],
    "abstract": "Computing-in-Memory (CIM) accelerators are a promising solution for accelerating Machine Learning (ML) workloads, as they perform Matrix-Vector Multiplications (MVMs) on crossbar arrays directly in memory. Although the bit widths of the crossbar inputs and cells are very limited, most CIM compilers do not support quantization below 8 bit. As a result, a single MVM requires many compute cycles, and weights cannot be efficiently stored in a single crossbar cell. To address this problem, we propose a mixed-precision training and compilation framework for CIM architectures. The biggest challenge is the massive search space, that makes it difficult to find good quantization parameters. This is why we introduce a reinforcement learning-based strategy to find suitable quantization configurations that balance latency and accuracy. In the best case, our approach achieves up to a 2.48x speedup over existing state-of-the-art solutions, with an accuracy loss of only 0.086 %.",
    "categories": [
      "cs.LG",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21737.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21737",
    "published": "2026-01-29T13:54:55Z",
    "updated": "2026-01-29T13:54:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种基于强化学习的混合精度训练和编译框架，用于优化 RRAM 内存计算加速器的量化配置，以实现高效能加速。",
      "motivation": "Computing-in-Memory (CIM) 加速器通过在内存中直接执行矩阵向量乘法来加速机器学习工作负载，具有广阔应用前景。然而，现有 CIM 编译器普遍不支持 8 位以下量化，尽管 crossbar 阵列的输入和单元位宽有限。这导致单个矩阵向量乘法需要多个计算周期，权重无法高效存储在单个 crossbar 单元中，限制了 CIM 加速器的性能和实际部署效率。因此，开发一个支持低精度量化的混合精度框架显得至关重要，以解决这些效率瓶颈并推动 CIM 技术发展。",
      "method": "论文开发了一个针对 RRAM-based CIM 加速器的混合精度训练和编译框架。核心创新是引入基于强化学习的策略，以自动搜索量化配置，平衡计算延迟和模型精度。由于量化参数搜索空间庞大，传统方法难以优化，强化学习被用来高效探索配置空间，从而确定最佳量化方案。该框架结合了混合精度训练和编译技术，专为 CIM 架构设计，以提高权重量化和存储效率，但摘要未明确说明具体使用的数据集或模型架构细节。",
      "result": "在实验中，该框架在最佳情况下取得了显著效果：与现有最先进的解决方案相比，实现了高达 2.48 倍的加速比，同时精度损失极小，仅为 0.086%。这些数据表明，通过混合精度优化和强化学习驱动的量化配置搜索，能大幅减少 CIM 加速器的计算延迟并维持高精度。与基线方法的对比验证了该方法的优越性，证实了其在提升 CIM 加速器性能方面的实用价值。",
      "conclusion": "本研究的主要贡献是开发了一个创新的混合精度训练和编译框架，有效解决了 CIM 加速器中的量化挑战。通过结合强化学习优化量化配置，平衡了延迟和精度，显著提升了加速器效率。这具有重要的学术价值，为 CIM 架构量化优化提供了新方法；在实际应用上，能促进更高效的内存计算加速器设计，推动机器学习工作负载加速。未来工作可能包括扩展框架到其他硬件平台或探索更多量化场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Mixed-Precision Training",
        "Computing-in-Memory (CIM)",
        "Reinforcement Learning",
        "Quantization",
        "RRAM-based Accelerators"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:35.016268Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21733",
    "title": "CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering",
    "authors": [
      "Jiayin Lan",
      "Jiaqi Li",
      "Baoxin Wang",
      "Ming Liu",
      "Dayong Wu",
      "Shijin Wang",
      "Bing Qin",
      "Guoping Hu"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21733.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21733",
    "published": "2026-01-29T13:53:44Z",
    "updated": "2026-01-29T13:53:44Z",
    "comment": "Accepted by IEEE ICASSP 2026",
    "light_analysis": {
      "overview": "CE-GOCD通过中心实体引导的图优化和社区检测，增强大语言模型在科学问答中的能力，利用学术知识图的语义子结构。",
      "motivation": "大语言模型(LLM)在科学文献问答中的应用日益增多，但现有检索增强方法通常依赖孤立的文本块或概念，忽视论文间的深层语义连接，这限制了LLMs对科学文献的全面理解，导致回答不够具体和全面。问题的核心在于缺乏对语义关系的建模，这影响了问答系统的实用性和准确性，因此需要开发一种能更有效地挖掘和利用知识图中语义结构的方法。",
      "method": "CE-GOCD方法包括三个关键步骤：首先，以论文标题作为中心实体，从学术知识图中检索目标子图；其次，通过子图修剪和补全操作，增强隐式语义的发现；最后，应用社区检测技术，提炼出具有共享主题的连贯论文组。该方法的创新在于结合了中心实体引导、图优化和社区检测，显式建模语义子结构，以支持LLMs的问答任务，使用的数据集为三个NLP文献问答数据集。",
      "result": "在三个基于NLP文献的问答数据集上的实验表明，CE-GOCD方法优于其他检索增强的基线方法，证实了其有效性。尽管摘要未明确列出具体的性能指标（如准确率或F1分数），但结果显示该方法能够提升LLMs的问答能力，特别是在理解和利用语义联系方面，增强了回答的全面性和特异性。",
      "conclusion": "本研究的主要贡献是提出了CE-GOCD框架，通过建模学术知识图的语义子结构，增强了大语言模型在科学问答中的表现，具有重要的学术价值，为检索增强方法提供了新的视角。实际应用价值在于可能提升科学文献检索和问答的效率和准确性，但摘要未明确说明潜在局限性和未来工作方向，需要进一步探索更广泛数据集和优化算法。",
      "tags": [
        "Large Language Model (LLM)",
        "Knowledge Graph",
        "Community Detection",
        "Graph Optimization",
        "Retrieval Augmentation"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:27.090121Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21731",
    "title": "Amortized Spectral Kernel Discovery via Prior-Data Fitted Network",
    "authors": [
      "Kaustubh Sharma",
      "Srijan Tiwari",
      "Ojasva Nema",
      "Parikshit Pareek"
    ],
    "abstract": "Prior-Data Fitted Networks (PFNs) enable efficient amortized inference but lack transparent access to their learned priors and kernels. This opacity hinders their use in downstream tasks, such as surrogate-based optimization, that require explicit covariance models. We introduce an interpretability-driven framework for amortized spectral discovery from pre-trained PFNs with decoupled attention. We perform a mechanistic analysis on a trained PFN that identifies attention latent output as the key intermediary, linking observed function data to spectral structure. Building on this insight, we propose decoder architectures that map PFN latents to explicit spectral density estimates and corresponding stationary kernels via Bochner's theorem. We study this pipeline in both single-realization and multi-realization regimes, contextualizing theoretical limits on spectral identifiability and proving consistency when multiple function samples are available. Empirically, the proposed decoders recover complex multi-peak spectral mixtures and produce explicit kernels that support Gaussian process regression with accuracy comparable to PFNs and optimization-based baselines, while requiring only a single forward pass. This yields orders-of-magnitude reductions in inference time compared to optimization-based baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21731.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21731",
    "published": "2026-01-29T13:51:26Z",
    "updated": "2026-01-29T13:51:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出一个从预训练的Prior-Data Fitted Networks中通过注意力机制发现光谱核的解释性框架，以实现高效且透明的推理。",
      "motivation": "Prior-Data Fitted Networks（PFNs）虽然能提供高效的分摊推断，但其学习到的先验和核结构缺乏透明访问能力，这限制了在需要显式协方差模型的下游任务（如基于代理的优化）中的应用。现有方法的主要不足是PFNs的不透明性，导致其在复杂场景中的可解释性和适用性受限，无法充分利用模型潜力。",
      "method": "论文提出一个以可解释性驱动的框架，首先对已训练的PFN进行机制分析，识别注意力潜在输出作为关键中介，将观测函数数据与光谱结构连接起来。基于此，设计了解码器架构，通过Bochner定理将PFN潜在表示映射到显式光谱密度估计和相应的静态核。该管道在单实现和多实现方案中进行了研究，结合了光谱可识别性的理论限制分析，并证明了在多个函数样本可用时的一致性。",
      "result": "实验结果显示，提出的解码器能够恢复复杂的多峰光谱混合，并生成显式核，支持高斯过程回归，其精度与PFNs和基于优化的基线方法相当。同时，该方法仅需一次前向传播，推理时间与基于优化的基线相比减少了数量级，效率显著提升。",
      "conclusion": "该研究的核心贡献是开发了一个可解释的框架，实现从PFNs中发现光谱核，不仅提高了推理效率和模型透明度，还促进了其在需要显式协方差模型的下游任务中的应用。学术价值在于推动可解释AI领域的发展，实际应用价值体现在加速回归和优化任务。未来工作可能包括扩展到非平稳核或更复杂的模型架构，摘要未明确说明局限性。",
      "tags": [
        "Prior-Data Fitted Networks",
        "Amortized Inference",
        "Spectral Kernel Discovery",
        "Attention Mechanisms",
        "Gaussian Process Regression"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:16.481969Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21726",
    "title": "DropoutTS: Sample-Adaptive Dropout for Robust Time Series Forecasting",
    "authors": [
      "Siru Zhong",
      "Yiqiu Liu",
      "Zhiqing Cui",
      "Zezhi Shao",
      "Fei Wang",
      "Qingsong Wen",
      "Yuxuan Liang"
    ],
    "abstract": "Deep time series models are vulnerable to noisy data ubiquitous in real-world applications. Existing robustness strategies either prune data or rely on costly prior quantification, failing to balance effectiveness and efficiency. In this paper, we introduce DropoutTS, a model-agnostic plugin that shifts the paradigm from \"what\" to learn to \"how much\" to learn. DropoutTS employs a Sample-Adaptive Dropout mechanism: leveraging spectral sparsity to efficiently quantify instance-level noise via reconstruction residuals, it dynamically calibrates model learning capacity by mapping noise to adaptive dropout rates - selectively suppressing spurious fluctuations while preserving fine-grained fidelity. Extensive experiments across diverse noise regimes and open benchmarks show DropoutTS consistently boosts superior backbones' performance, delivering advanced robustness with negligible parameter overhead and no architectural modifications. Our code is available at https://github.com/CityMind-Lab/DropoutTS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21726.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21726",
    "published": "2026-01-29T13:49:20Z",
    "updated": "2026-01-29T13:49:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "DropoutTS提出模型无关的样本自适应丢弃机制，动态校准模型学习能力，提升时间序列预测的鲁棒性。",
      "motivation": "深度学习时间序列模型在现实应用中易受噪声数据影响，导致预测性能下降。现有鲁棒性方法如数据剪枝或先验量化存在缺陷：数据剪枝可能丢失重要信息，而先验量化成本高且不够灵活，无法在效果和效率间取得平衡。因此，亟需一种高效且有效的方法来处理噪声，增强模型在实际场景中的可靠性。",
      "method": "DropoutTS的核心是样本自适应丢弃机制。它利用谱稀疏性分析时间序列数据，通过计算重构残差来高效量化每个样本的噪声水平。接着，根据噪声水平动态映射到自适应丢弃率，选择性地抑制虚假波动，同时保持细粒度保真度。该方法作为模型无关的插件实现，无需修改现有架构，可集成到多种时间序列模型中。",
      "result": "在多种噪声场景和公开基准测试中，DropoutTS能够持续提升优秀基础模型的性能，提供先进的鲁棒性。尽管摘要未提供具体准确率数据，但实验显示该方法在所有测试中都表现一致改进。与基线方法相比，DropoutTS具有可忽略的参数开销，且无需架构修改，有效平衡了效果和效率。",
      "conclusion": "本研究的主要贡献是开发了DropoutTS，一种样本自适应丢弃机制，用于增强时间序列预测的鲁棒性。其学术价值在于创新地结合噪声量化与自适应丢弃，实际应用价值在于模型无关性和高效率。摘要未明确说明局限性，但未来工作可进一步探索不同噪声类型下的泛化能力。",
      "tags": [
        "Time Series Forecasting",
        "Dropout",
        "Sample-Adaptive",
        "Spectral Sparsity",
        "Reconstruction Residuals"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:26.834750Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21725",
    "title": "Procedural Pretraining: Warming Up Language Models with Abstract Data",
    "authors": [
      "Liangze Jiang",
      "Zachary Shinnick",
      "Anton van den Hengel",
      "Hemanth Saratchandran",
      "Damien Teney"
    ],
    "abstract": "Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.   We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21725.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21725",
    "published": "2026-01-29T13:48:43Z",
    "updated": "2026-01-29T13:48:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出程序化预训练方法，利用抽象结构化数据提升语言模型性能并加速训练过程。",
      "motivation": "现有语言模型预训练通常直接依赖大规模网络语料，但这种方式可能效率低下且缺乏结构化学习基础。本研究旨在探索使用抽象数据（如程序化生成的序列）作为初始训练阶段，以帮助模型更高效地获取后续语义知识。这类似于人类先学习逻辑和数学再发展高级推理，旨在优化训练流程并解决标准预训练中潜在的知识获取瓶颈问题。摘要未明确说明具体实际应用场景，但强调了提升训练效率和性能的重要性。",
      "method": "研究方法采用程序化数据（如由形式语言生成的Dyck序列）进行预训练，作为标准自然语言或代码数据前的“热身”阶段。核心创新在于诊断不同程序化数据对算法技能的提升效果，并在大规模模型（如1.3B参数）上实验。技术路线包括比较与C4、CodeParrot和DeepMind-Math等标准数据集的性能，分析注意力和MLP层的结构变化，以及探索多种程序化数据的组合应用。关键细节涉及使用平衡括号序列等抽象数据，以模拟基础逻辑训练。",
      "result": "实验结果显示，程序化预训练显著提升模型性能：在上下文回忆任务（Needle-in-a-haystack）中，使用Dyck序列预训练后准确率从10%提高到98%。在大模型上，仅添加0.1%的程序化数据即优于标准预训练，并且模型达到相同损失值所需数据量减少到原来的55%、67%和86%（分别对应不同数据集）。此外，该方法在注意力和MLP层中引入了有益结构，前者对代码等结构化领域更重要，后者对语言处理有贡献。",
      "conclusion": "论文结论表明，程序化预训练是一种简单轻量级的方法，能有效提升语言模型性能并加速预训练过程，验证了使用抽象数据优化训练的可行性。学术价值在于为知识获取与推理的解耦提供了新思路，实际应用潜力包括更高效的模型训练和结构化任务处理。未来工作可探索多种程序化数据的组合应用，以扩展该方法的适用范围。摘要未明确说明具体局限性，但暗示了进一步研究的可能性。",
      "tags": [
        "Procedural Pretraining",
        "Language Models",
        "Dyck Sequences",
        "Attention Mechanism",
        "Structured Data"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:28.899323Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21722",
    "title": "Enhancing Language Models for Robust Greenwashing Detection",
    "authors": [
      "Neil Heinrich Braun",
      "Keane Ong",
      "Rui Mao",
      "Erik Cambria",
      "Gianmarco Mengaldo"
    ],
    "abstract": "Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21722.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21722",
    "published": "2026-01-29T13:46:15Z",
    "updated": "2026-01-29T13:46:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种参数高效的框架，结合对比学习和序数排序目标，增强语言模型对绿色洗涤检测的鲁棒性。",
      "motivation": "可持续发展报告是环境、社会和治理评估的关键工具，但绿色洗涤和模糊声明常降低其可靠性。现有自然语言处理模型在检测绿色洗涤时缺乏稳健性，主要依赖表面模式，导致在实际跨类别应用中泛化能力不足。这削弱了ESG评估的准确性，凸显了开发更可靠检测方法的需求，以区分具体行动和模糊宣传。",
      "method": "论文提出一个参数高效的框架，通过结合对比学习和序数排序目标来结构化大语言模型的潜在空间，以捕捉具体行动与模糊声明之间的分级区别。关键创新包括使用门控特征调制过滤披露噪声，以及采用MetaGradNorm技术稳定多目标优化过程。摘要未明确说明具体使用的数据集和模型架构，但基于跨类别实验设置推断涉及多个数据类别。",
      "result": "实验在跨类别设置中进行，结果显示所提框架相比标准基线方法具有显著更优的鲁棒性，能有效识别绿色洗涤行为。摘要揭示了表示刚性与泛化能力之间的权衡关系，但未提供具体性能指标如准确率数据，基于结果推断在检测准确性上有所改进。",
      "conclusion": "本研究的主要贡献是开发了一个参数高效的框架，结合对比学习和序数排序增强语言模型的检测能力，学术上提供了结构潜在空间的新方法，实际应用中有助于提升可持续发展报告的评估质量。局限性包括表示刚性与泛化之间的权衡，未来工作可探索优化这一平衡以进一步改进性能。",
      "tags": [
        "Large Language Model",
        "Contrastive Learning",
        "Ordinal Ranking",
        "Gated Feature Modulation",
        "Multi-Objective Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:30.997234Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21719",
    "title": "LoRA and Privacy: When Random Projections Help (and When They Don't)",
    "authors": [
      "Yaxi Hu",
      "Johanna Düngler",
      "Bernhard Schölkopf",
      "Amartya Sanyal"
    ],
    "abstract": "We introduce the (Wishart) projection mechanism, a randomized map of the form $S \\mapsto M f(S)$ with $M \\sim W_d(1/r I_d, r)$ and study its differential privacy properties. For vector-valued queries $f$, we prove non-asymptotic DP guarantees without any additive noise, showing that Wishart randomness alone can suffice. For matrix-valued queries, however, we establish a sharp negative result: in the noise-free setting, the mechanism is not DP, and we demonstrate its vulnerability by implementing a near perfect membership inference attack (AUC $> 0.99$). We then analyze a noisy variant and prove privacy amplification due to randomness and low rank projection, in both large- and small-rank regimes, yielding stronger privacy guarantees than additive noise alone. Finally, we show that LoRA-style updates are an instance of the matrix-valued mechanism, implying that LoRA is not inherently private despite its built-in randomness, but that low-rank fine-tuning can be more private than full fine-tuning at the same noise level. Preliminary experiments suggest that tighter accounting enables lower noise and improved accuracy in practice.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21719.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21719",
    "published": "2026-01-29T13:43:37Z",
    "updated": "2026-01-29T13:43:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了Wishart投影机制，揭示了随机投影在差分隐私中对向量查询可提供隐私，但对矩阵查询需加噪，并关联到LoRA的隐私性质。",
      "motivation": "该研究旨在探讨随机投影机制在差分隐私中的作用，特别是理解无加噪时随机性是否足以保护隐私。差分隐私通常依赖于添加噪声，但随机投影可能减少噪声需求。然而，对于矩阵值查询，现有方法在无噪时存在隐私漏洞，如成员推理攻击，这表明需要更深入分析以指导实际应用如LoRA，从而解决隐私保护与模型性能的平衡问题。",
      "method": "论文提出了Wishart投影机制，形式为S ↦ M f(S)，其中M是服从Wishart分布的随机矩阵。方法包括理论分析：针对向量查询，证明非渐近差分隐私保证无需加噪；针对矩阵查询，展示无噪机制不满足差分隐私，并通过成员推理攻击验证其脆弱性。随后分析有噪变体，证明随机性和低秩投影可放大隐私，优于单独加噪。最后，将LoRA风格的更新作为矩阵值机制的实例进行关联研究。",
      "result": "主要实验结果包括：对于向量查询，Wishart投影机制在无噪时满足差分隐私；对于矩阵查询，无噪时机制不私有，成员推理攻击的AUC > 0.99表明高泄露风险。有噪变体分析显示隐私放大，提供更强隐私保证。初步实验表明，通过更紧的隐私核算，可以降低噪声水平并在实践中提高准确性，与基线方法相比，低秩投影在相同噪声下更私有。",
      "conclusion": "结论是Wishart投影机制在向量查询中有效提供隐私，但矩阵查询需要额外加噪。研究贡献在于阐明了随机投影在差分隐私中的作用，并将此应用于LoRA，指出低秩微调可以比全微调更私有。学术上，为隐私机制设计提供了新视角；实际上，指导低秩更新技术的隐私保护应用。未来工作方向可能包括更多实验验证和扩展到其他随机投影机制。",
      "tags": [
        "Differential Privacy",
        "Random Projections",
        "Wishart Mechanism",
        "LoRA",
        "Membership Inference"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:50.440526Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21718",
    "title": "When does predictive inverse dynamics outperform behavior cloning?",
    "authors": [
      "Lukas Schäfer",
      "Pallavi Choudhury",
      "Abdelhak Lemkhenter",
      "Chris Lovett",
      "Somjit Nath",
      "Luis França",
      "Matheus Ribeiro Furtado de Mendonça",
      "Alex Lamb",
      "Riashat Islam",
      "Siddhartha Sen",
      "John Langford",
      "Katja Hofmann",
      "Sergio Valcarcel Macua"
    ],
    "abstract": "Behavior cloning (BC) is a practical offline imitation learning method, but it often fails when expert demonstrations are limited. Recent works have introduced a class of architectures named predictive inverse dynamics models (PIDM) that combine a future state predictor with an inverse dynamics model (IDM). While PIDM often outperforms BC, the reasons behind its benefits remain unclear. In this paper, we provide a theoretical explanation: PIDM introduces a bias-variance tradeoff. While predicting the future state introduces bias, conditioning the IDM on the prediction can significantly reduce variance. We establish conditions on the state predictor bias for PIDM to achieve lower prediction error and higher sample efficiency than BC, with the gap widening when additional data sources are available. We validate the theoretical insights empirically in 2D navigation tasks, where BC requires up to five times (three times on average) more demonstrations than PIDM to reach comparable performance; and in a complex 3D environment in a modern video game with high-dimensional visual inputs and stochastic transitions, where BC requires over 66\\% more samples than PIDM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21718.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21718",
    "published": "2026-01-29T13:43:34Z",
    "updated": "2026-01-29T13:43:34Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "论文通过理论分析解释了预测逆动态模型在样本效率上优于行为克隆的条件，揭示了偏差-方差权衡的关键作用。",
      "motivation": "行为克隆是离线模仿学习的实用方法，但在专家演示有限时性能下降，而预测逆动态模型虽常优于行为克隆，其优势原因尚不明确。本研究旨在填补这一空白，通过理论探究PIDM如何利用偏差-方差权衡提高样本效率，以解决数据稀缺问题，并为算法优化提供理论依据。",
      "method": "论文提出预测逆动态模型的理论框架，结合未来状态预测器和逆动态模型。核心创新在于偏差-方差权衡分析：预测未来状态引入偏差，但条件化逆动态模型于预测上能显著减少方差。建立了状态预测器偏差的条件，确保PIDM比BC有更低的预测误差。实证验证使用2D导航任务和复杂3D环境（视频游戏），涉及高维视觉输入和随机转移。",
      "result": "实验结果验证了理论：在2D导航任务中，行为克隆需要平均三倍、最多五倍的演示才能达到与预测逆动态模型相当的性能；在复杂3D环境中，BC需要超过66%的样本。这表明PIDM在样本效率上显著优于BC，特别是在有额外数据源时优势更明显。",
      "conclusion": "本研究的主要贡献是理论解释了预测逆动态模型优于行为克隆的机制，通过偏差-方差权衡提供了样本效率提升的保证。该工作增强了模仿学习算法的理论基础，并为未来方法改进提供了方向；摘要未明确说明局限性，但可推测需进一步扩展到更多任务或理论深化。",
      "tags": [
        "Predictive Inverse Dynamics Models",
        "Behavior Cloning",
        "Bias-Variance Tradeoff",
        "Sample Efficiency",
        "Offline Imitation Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:35.646823Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21716",
    "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning",
    "authors": [
      "Mingshuang Luo",
      "Shuang Liang",
      "Zhengkun Rong",
      "Yuxuan Luo",
      "Tianshu Hu",
      "Ruibing Hou",
      "Hong Chang",
      "Yong Li",
      "Yuan Zhang",
      "Mingyuan Gao"
    ],
    "abstract": "Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a \"see-saw\", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21716.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21716",
    "published": "2026-01-29T13:43:17Z",
    "updated": "2026-01-29T13:43:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了DreamActor-M2框架，通过时空上下文学习实现通用角色图像动画，优化了运动注入策略并提升了跨角色泛化能力。",
      "motivation": "角色图像动画旨在通过将驱动序列的运动转移到静态参考图像来合成高保真视频，但现有方法存在两个主要问题：首先，运动注入策略次优，导致身份保持和运动一致性之间形成“跷跷板”式的权衡，影响动画质量；其次，过度依赖显式姿势先验（如骨架），无法有效捕捉复杂动态，限制了向任意非人形角色的泛化。这些问题降低了动画的实用性和普适性，因此需要一种更先进的解决方案。",
      "method": "DreamActor-M2采用两阶段方法来解决这些问题。第一阶段通过融合参考图像的外观和驱动序列的运动线索到统一潜在空间，利用基础模型的生成先验，使模型能共同推理空间身份和时态动态。第二阶段引入自举数据合成管道，生成伪跨身份训练对，促进从姿势依赖控制到直接、端到端RGB驱动动画的过渡。这种方法的关键创新是将运动条件化重新定义为上下文学习问题，增强了模型对多样角色和运动场景的泛化能力。",
      "result": "论文引入了AW Bench基准，这是一个涵盖广泛角色类型和运动场景的评估工具。实验表明DreamActor-M2在多个评估中达到了最先进的性能，展现出更高的视觉保真度和更强的跨域泛化能力，但与基线方法的具体对比数据摘要未明确说明。结果验证了该方法在解决身份保持和运动一致性权衡方面的有效性。",
      "conclusion": "DreamActor-M2的主要贡献是提出了一种基于时空上下文学习的通用动画框架，通过改进运动注入策略和减少对姿势先验的依赖，显著提升了角色图像动画的质量和泛化性。这项研究在学术上为生成模型和计算机视觉领域提供了新思路，实际应用价值包括娱乐和媒体产业的动画制作。局限性可能在于对复杂动态的进一步处理，未来工作可扩展到更多样化的数据模态或更精细的运动控制。",
      "tags": [
        "Character Image Animation",
        "In-Context Learning",
        "Spatiotemporal Fusion",
        "Self-Bootstrapped Data Synthesis",
        "RGB-Driven Animation"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:29.825848Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21714",
    "title": "E-mem: Multi-agent based Episodic Context Reconstruction for LLM Agent Memory",
    "authors": [
      "Kaixiang Wang",
      "Yidan Lin",
      "Jiong Lou",
      "Zhaojiacheng Zhou",
      "Bunyod Suvonov",
      "Jie Li"
    ],
    "abstract": "The evolution of Large Language Model (LLM) agents towards System~2 reasoning, characterized by deliberative, high-precision problem-solving, requires maintaining rigorous logical integrity over extended horizons. However, prevalent memory preprocessing paradigms suffer from destructive de-contextualization. By compressing complex sequential dependencies into pre-defined structures (e.g., embeddings or graphs), these methods sever the contextual integrity essential for deep reasoning. To address this, we propose E-mem, a framework shifting from Memory Preprocessing to Episodic Context Reconstruction. Inspired by biological engrams, E-mem employs a heterogeneous hierarchical architecture where multiple assistant agents maintain uncompressed memory contexts, while a central master agent orchestrates global planning. Unlike passive retrieval, our mechanism empowers assistants to locally reason within activated segments, extracting context-aware evidence before aggregation. Evaluations on the LoCoMo benchmark demonstrate that E-mem achieves over 54\\% F1, surpassing the state-of-the-art GAM by 7.75\\%, while reducing token cost by over 70\\%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21714.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21714",
    "published": "2026-01-29T13:42:42Z",
    "updated": "2026-01-29T13:42:42Z",
    "comment": "18 pages",
    "light_analysis": {
      "overview": "本文提出了E-mem框架，通过多代理架构和情景上下文重构，增强了LLM代理的内存管理和推理完整性。",
      "motivation": "随着大型语言模型代理向系统2推理进化，需要维持长期逻辑完整性以支持高精度问题解决。然而，现有内存预处理方法，如将复杂顺序依赖压缩为嵌入或图结构，破坏了上下文完整性，导致推理能力受限。这个问题至关重要，因为上下文完整性是深度推理的基础，而现有方法的不足在于过度压缩导致信息损失，影响代理性能和实际应用中的可靠性。",
      "method": "E-mem框架的核心是从内存预处理转向情景上下文重构，受生物印记启发，采用异构分层架构：多个助手代理负责维护未压缩的记忆上下文，确保原始信息完整性；中心主代理则协调全局规划，实现整体推理。关键创新在于助手代理在激活的上下文片段中进行局部推理，提取上下文感知证据后再聚合，这避免了被动检索的弊端，并利用了多代理系统的高效协作，提升推理精确性和动态适应性。",
      "result": "在LoCoMo基准测试中，E-mem表现出色，F1分数超过54%，比当前最佳方法GAM提升了7.75%。此外，它显著减少了超过70%的token成本，表明在提高推理准确性的同时，也优化了资源效率。这些结果验证了E-mem框架在维持上下文完整性和降低计算开销方面的优势，为实际部署提供了实证支持，并展示了其在性能与效率上的双重改进潜力。",
      "conclusion": "本论文的主要贡献是提出了E-mem框架，通过情景上下文重构和多代理分层架构，有效解决了LLM代理内存中的上下文完整性问题。这项研究具有重要的学术价值，为系统2推理提供了新方法，并提升了代理的精确性和效率。在实际应用中，E-mem可应用于需要长期、高精度推理的AI系统。未来工作可能包括在其他数据集上验证泛化能力，或进一步优化架构以适应更复杂场景，摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Multi-agent System",
        "Episodic Context Reconstruction",
        "Hierarchical Architecture",
        "Memory Management"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:59.089378Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21711",
    "title": "TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning",
    "authors": [
      "Huiyuan Lai",
      "Malvina Nissim"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21711.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21711",
    "published": "2026-01-29T13:40:35Z",
    "updated": "2026-01-29T13:40:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "TACLer是一种定制课程强化学习框架，通过混合推理范式显著提升大语言模型的推理效率和准确性。",
      "motivation": "大语言模型在复杂推理任务中依赖长链思维推理，但现有方法如大规模强化学习训练存在计算成本高、可能导致过度思考和冗余中间步骤的问题。为提高学习和推理效率，同时保持或增强性能，本研究旨在优化LLMs的推理过程，应对实际部署中的效率挑战。",
      "method": "TACLer框架采用模型定制的课程强化学习，在多阶段训练中基于模型熟练度逐步增加数据复杂度。核心创新包括两个组件：定制课程学习动态确定模型在各阶段的学习需求；混合Thinking/NoThinking推理范式通过切换模式平衡准确性和效率。实验在四个数学数据集上进行，结合了强化学习和课程学习技术。",
      "result": "实验显示，TACLer在计算成本和准确性方面均有显著改进：相比长思考模型，训练计算减少超过50%；相对基础模型，推理token使用减少超过42%，准确性提高超过9%。在四个数学数据集上，一致优于最先进的Nothinking和Thinking基线模型。",
      "conclusion": "TACLer的主要贡献在于提出高效定制课程强化学习框架，降低了训练和推理成本并提升准确性。学术价值在于优化LLMs推理方法，推动强化学习应用；实际应用价值在于降低部署成本，提高效率。摘要未明确说明局限性，未来工作可扩展到更多数据集或任务。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning",
        "Curriculum Learning",
        "Chain-of-Thought",
        "Reasoning Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:46.322434Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21709",
    "title": "Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis",
    "authors": [
      "Qingyue Yang",
      "Jie Wang",
      "Xing Li",
      "Yinqi Bai",
      "Xialiang Tong",
      "Huiling Zhen",
      "Jianye Hao",
      "Mingxuan Yuan",
      "Bin Li"
    ],
    "abstract": "Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \\textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21709.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21709",
    "published": "2026-01-29T13:40:23Z",
    "updated": "2026-01-29T13:40:23Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "本文提出TAPPA框架，从时间连续角度统一解释大型语言模型中的注意力模式，并指导推理加速方法。",
      "motivation": "在大型语言模型中，注意力模式（如检索头、下沉头）对训练和推理至关重要，但先前研究仅识别了这些个体模式，观察碎片化且缺乏统一解释。现有方法未提供理论框架来整合这些模式，限制了深入理解和优化。因此，需要一种统一方法来分析注意力模式的本质，以促进模型理解和加速技术发展。",
      "method": "论文引入Temporal Attention Pattern Predictability Analysis (TAPPA)框架，通过分析注意力模式的数学公式，从时间连续视角区分可预测（有清晰规律）和不可预测（看似随机）模式。关键创新在于利用查询在时间维度上的自相似性来解释模式区分，并通过查询、键和旋转位置嵌入（RoPE）的联合效应，对三个代表性案例进行详细数学分析。该框架具体指导KV缓存压缩和LLM剪枝等任务。",
      "result": "将TAPPA的洞见应用于KV缓存压缩和LLM剪枝任务，基于TAPPA的简单指标 consistently 改善了基线方法的性能。这验证了框架的有效性，表明它能够提供实用指导来优化模型推理过程。摘要未明确具体性能数据，但强调了性能的 consistently 改进。",
      "conclusion": "TAPPA框架统一解释了注意力模式的多样性，深化了对大型语言模型行为的理解，并提供了理论支持以指导推理加速方法。其学术价值在于提供了一个新颖的时间连续视角，实际应用价值体现在优化KV缓存和模型剪枝等任务。未来工作可基于此开发更高效的压缩和剪枝技术，或扩展至其他注意力相关优化领域。",
      "tags": [
        "Attention Patterns",
        "Temporal Analysis",
        "Large Language Models",
        "KV Cache Compression",
        "Rotary Positional Embeddings"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:16.243305Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21708",
    "title": "FBS: Modeling Native Parallel Reading inside a Transformer",
    "authors": [
      "Tongxi Wang"
    ],
    "abstract": "Large language models (LLMs) excel across many tasks, yet inference is still dominated by strictly token-by-token autoregression. Existing acceleration methods largely patch this pipeline and miss core human-reading ingredients: content-adaptive foresight, chunk-structure-aware compute allocation, and train--test consistency for preview/skimming. We propose the \\textbf{Fovea-Block-Skip Transformer} (FBS), which injects a causal, trainable loop into Transformers via Parafovea-Attention Window (PAW), Chunk-Head (CH), and Skip-Gate (SG). Across diverse benchmarks, FBS improves the quality-efficiency trade-off without increasing parameters, and ablations show the three modules are complementary.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21708.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21708",
    "published": "2026-01-29T13:39:55Z",
    "updated": "2026-01-29T13:39:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "FBS通过模拟人类并行阅读机制，在Transformer中注入因果可训练循环以提升推理效率和质量权衡。",
      "motivation": "大型语言模型虽在多种任务中表现出色，但其推理过程仍受限于逐个令牌的自回归方式，导致效率低下。现有加速方法多是基于现有流程的修补，忽视了人类阅读的核心要素，例如内容自适应前瞻、块结构感知的计算分配以及预览行为的训练-测试一致性。解决这些问题对优化语言模型推理速度至关重要，因为这些要素能更好地模拟高效信息处理过程。",
      "method": "论文提出了Fovea-Block-Skip Transformer (FBS)，通过三个模块在Transformer中实现并行阅读模拟：Parafovea-Attention Window (PAW) 用于内容自适应前瞻，Chunk-Head (CH) 处理块结构感知计算分配，Skip-Gate (SG) 控制跳过机制以确保训练和测试一致性。这些模块结合形成一个因果可训练循环，无需增加额外参数，关键创新在于将人类阅读原理整合到深度学习架构中。",
      "result": "在各种基准测试中，FBS改进了推理效率与输出质量之间的权衡，具体表现如摘要未明确说明的准确率提升或处理速度提高。消融研究表明，PAW、CH和SG三个模块是互补的，共同贡献于性能改进，例如在效率优化方面可能减少了推理时间或提升了吞吐量。",
      "conclusion": "FBS模型通过模拟人类并行阅读，有效提升了Transformer模型的推理效率并保持质量，贡献在于推动更高效语言模型的研究。学术价值在于探索了注意力机制的扩展应用，实际应用价值可能包括加速大型语言模型部署。局限性可能涉及对特定任务或数据集的依赖性，未来工作可扩展到更多自然语言处理场景或优化算法细节。",
      "tags": [
        "Transformer",
        "Parallel Reading",
        "Attention Mechanism",
        "LLM Acceleration",
        "Causal Loop"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:36.275209Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21706",
    "title": "SmartMeterFM: Unifying Smart Meter Data Generative Tasks Using Flow Matching Models",
    "authors": [
      "Nan Lin",
      "Yanbo Wang",
      "Jacco Heres",
      "Peter Palensky",
      "Pedro P. Vergara"
    ],
    "abstract": "Smart meter data is the foundation for planning and operating the distribution network. Unfortunately, such data are not always available due to privacy regulations. Meanwhile, the collected data may be corrupted due to sensor or transmission failure, or it may not have sufficient resolution for downstream tasks. A wide range of generative tasks is formulated to address these issues, including synthetic data generation, missing data imputation, and super-resolution. Despite the success of machine learning models on these tasks, dedicated models need to be designed and trained for each task, leading to redundancy and inefficiency. In this paper, by recognizing the powerful modeling capability of flow matching models, we propose a new approach to unify diverse smart meter data generative tasks with a single model trained for conditional generation. The proposed flow matching models are trained to generate challenging, high-dimensional time series data, specifically monthly smart meter data at a 15 min resolution. By viewing different generative tasks as distinct forms of partial data observations and injecting them into the generation process, we unify tasks such as imputation and super-resolution with a single model, eliminating the need for re-training. The data generated by our model not only are consistent with the given observations but also remain realistic, showing better performance against interpolation and other machine learning based baselines dedicated to the tasks.",
    "categories": [
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21706.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21706",
    "published": "2026-01-29T13:35:39Z",
    "updated": "2026-01-29T13:35:39Z",
    "comment": "10 pages, 6 figures, 6 tables",
    "light_analysis": {
      "overview": "本文提出一种基于流匹配模型的统一框架，用于智能电表数据的多种生成任务（如插值和超分辨率），避免为每个任务单独训练模型的冗余。",
      "motivation": "智能电表数据对配电网络规划和运营至关重要，但因隐私法规、传感器或传输故障，常存在数据不可用、损坏或分辨率不足的问题。现有方法需为合成数据生成、缺失数据插值和超分辨率等任务设计和训练专用机器学习模型，导致计算资源浪费和效率低下。因此，研究旨在开发统一框架以提高生成任务的处理效率。",
      "method": "论文采用流匹配模型作为核心方法，训练单一模型进行条件生成，专门针对高维时间序列数据（如每月智能电表数据在15分钟分辨率上）。关键创新是将插值和超分辨率等任务视为部分数据观察形式，并注入生成过程，从而统一处理多种任务，无需重新训练。模型架构基于流匹配技术，增强了对时间序列数据的建模能力。",
      "result": "实验结果表明，该模型生成的智能电表数据与给定观察保持一致且具有高现实性。在与基线方法对比中，包括基于插值的方法和其他专用机器学习模型，所提方法在数据插值和超分辨率任务上表现出更优性能。摘要未明确说明具体指标如准确率提升，但强调了其对基线的改进，验证了统一框架的有效性。",
      "conclusion": "本研究的主要贡献是通过流匹配模型统一了智能电表数据的多种生成任务，减少了模型训练冗余和成本。学术上，拓展了流匹配模型在时间序列数据生成领域的应用；实际上，为配电网络数据管理提供了高效解决方案。未来工作可探索模型在更多任务上的扩展或进一步提升生成质量。",
      "tags": [
        "Flow Matching Models",
        "Conditional Generation",
        "Time Series Generation",
        "Data Imputation",
        "Super-resolution"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:58.410307Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21702",
    "title": "Beyond Forgetting: Machine Unlearning Elicits Controllable Side Behaviors and Capabilities",
    "authors": [
      "Tien Dang",
      "The-Hai Nguyen",
      "Dinh Mai Phuong",
      "Nguyen Minh Phuong",
      "Hoang Thanh-Tung",
      "Le-Minh Nguyen",
      "Naoya Inoue"
    ],
    "abstract": "We consider representation misdirection (RM), a class of LLM unlearning methods that achieves forgetting by manipulating the forget-representations, that is, latent representations of forget samples. Despite being important, the roles of target vectors used in RM, however, remain underexplored. Here, we approach and revisit RM through the lens of the linear representation hypothesis. Specifically, if one can somehow identify a one-dimensional representation corresponding to a high-level concept, the linear representation hypothesis enables linear operations on this concept vector within the forget-representation space. Under this view, we hypothesize that, beyond forgetting, machine unlearning elicits controllable side behaviors and stronger side capabilities corresponding to the high-level concept. Our hypothesis is empirically validated across a wide range of tasks, including behavioral control (e.g., controlling unlearned models' truth, sentiment, and refusal) and capability enhancement (e.g., improving unlearned models' in-context learning capability). Our findings reveal that this fairly attractive phenomenon could be either a hidden risk if misused or a mechanism that can be harnessed for developing models that require stronger capabilities and controllable behaviors.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21702.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21702",
    "published": "2026-01-29T13:32:26Z",
    "updated": "2026-01-29T13:32:26Z",
    "comment": "21 pages, 11 tables, 12 figures",
    "light_analysis": {
      "overview": "本研究基于线性表示假设，揭示了机器去学习不仅能实现遗忘，还能通过操作高层概念向量引发可控的侧行为和增强侧能力，对应特定概念。",
      "motivation": "机器去学习用于从大型语言模型中移除敏感数据，但现有表示误导方法中目标向量的作用未被充分探索。本研究旨在探究去学习如何影响模型行为，以弥补现有方法在理解副作用方面的不足。去学习在隐私保护和合规性中至关重要，但潜在的副作用可能导致模型行为不可预测，带来风险或新机遇，因此深入探索这些现象具有实际意义和理论价值，以优化模型安全和应用。",
      "method": "研究采用线性表示假设框架，假设机器去学习能通过操作高层概念向量在遗忘表示空间中进行线性操作，从而引发可控侧行为和增强侧能力。核心创新点在于将去学习与行为和能力的可控变化联系起来，通过实证验证设计实验，在行为控制任务（如控制模型的真实性、情感和拒绝行为）和能力增强任务（如提升上下文学习能力）上进行测试，摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "实证结果表明，机器去学习确实能引发可控的侧行为和增强侧能力。在行为控制方面，去学习模型能在任务中调整真实性、情感和拒绝反应；在能力增强方面，上下文学习能力有所提升。与基线方法相比，表示误导方法展示了独特的副作用效应，但摘要未明确说明具体性能指标数据，如准确率或效率改进的具体数值，仅强调了现象在广泛任务中的验证。",
      "conclusion": "本研究的主要贡献是揭示机器去学习不仅能实现遗忘，还能通过高层概念操作引发可控侧行为和增强侧能力，深化了对去学习机制的理解。学术价值在于提供新视角解释去学习的副作用，实际应用价值在于指导模型开发，避免潜在风险或利用此机制增强模型性能。局限性包括可能未覆盖所有去学习方法，未来工作可探索更广泛的应用场景和优化控制策略，以提升模型的安全性和可控性。",
      "tags": [
        "Machine Unlearning",
        "Linear Representation Hypothesis",
        "Representation Misdirection",
        "Behavioral Control",
        "In-context Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:23.578150Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21700",
    "title": "Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning",
    "authors": [
      "Wonduk Seo",
      "Wonseok Choi",
      "Junseo Koh",
      "Juhyeon Lee",
      "Hyunjin An",
      "Minhyeong Yu",
      "Jian Park",
      "Qingshan Zhou",
      "Seunghyun Lee",
      "Yi Bu"
    ],
    "abstract": "Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.MA",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21700.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21700",
    "published": "2026-01-29T13:31:45Z",
    "updated": "2026-01-29T13:31:45Z",
    "comment": "35 pages",
    "light_analysis": {
      "overview": "论文提出OG-MAR框架，通过本体引导的多代理推理技术，提升大语言模型在文化敏感任务中的对齐能力和可解释性。",
      "motivation": "随着大语言模型越来越多地应用于文化敏感决策，它们常因预训练数据的偏斜和缺乏结构化价值表示而出现文化不对齐问题。现有方法虽然能引导模型输出，但往往缺少人口统计学基础，并将文化价值视为独立、非结构化的信号，这导致输出的一致性和可解释性降低。因此，亟需一种能整合结构化文化信息的方法来改善LLM的文化对齐，以支持更可靠的社会应用。",
      "method": "OG-MAR框架首先从世界价值观调查（WVS）中提取受访者特定价值，基于固定分类法通过能力问题构建全局文化本体论，以结构化方式表示文化价值关系。在推理时，系统检索本体一致的关系和人口统计相似性配置文件，实例化多个价值-人格代理；这些代理的输出由一个判断代理合成，该代理强制执行本体一致性和人口统计接近性，从而生成文化对齐的决策，增强了透明度和可控性。",
      "result": "实验在四个不同的大语言模型骨架上，针对区域社会调查基准进行评估。结果表明，OG-MAR框架在文化对齐度和鲁棒性方面均优于竞争基线，同时产生的推理轨迹更加透明，有助于提高模型输出的可解释性。尽管摘要未提供具体数值指标，但明确指出了其在关键性能上的优势。",
      "conclusion": "本研究的主要贡献是提出OG-MAR框架，它通过本体引导的多代理推理，有效提升了大语言模型的文化对齐性能，并增强了输出的一致性和可解释性。这项研究为AI系统在文化敏感领域的应用提供了技术支持，并促进了结构化本体论与机器学习的融合；未来可扩展至更广泛的文化数据集和动态本体更新。",
      "tags": [
        "Large Language Model (LLM)",
        "Ontology",
        "Multi-Agent Reasoning",
        "Cultural Alignment",
        "World Values Survey (WVS)"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:24.776874Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21699",
    "title": "Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents",
    "authors": [
      "Hojae Han",
      "Heeyun Jung",
      "Jongyoon Kim",
      "Seung-won Hwang"
    ],
    "abstract": "While reinforcement learning (RL) has empowered multi-turn reasoning agents with retrieval and tools, existing successes largely depend on extensive on-policy rollouts in high-cost, high-accuracy regimes. Under realistic resource constraints that cannot support large models or dense explorations, however, small language model agents fall into a low-cost, low-accuracy regime, where limited rollout budgets lead to sparse exploration, sparse credit assignment, and unstable training. In this work, we challenge this trade-off and show that small language models can achieve strong multi-hop reasoning under resource constraints. We introduce DAVID-GRPO, a budget-efficient RL framework that (i) stabilizes early learning with minimal supervision, (ii) assigns retrieval credit based on evidence recall, and (iii) improves exploration by resampling truncated near-miss trajectories. Evaluated on agents up to 1.5B parameters trained on only four RTX 3090 GPUs, DAVID-GRPO consistently outperforms prior RL methods designed for large-scale settings on six multi-hop QA benchmarks. These results show that with the right inductive biases, small agents can achieve low training cost with high accuracy.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21699.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21699",
    "published": "2026-01-29T13:31:28Z",
    "updated": "2026-01-29T13:31:28Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "论文提出DAVID-GRPO，一个预算高效的强化学习框架，使小型语言模型在资源受限环境中实现高准确率的多跳推理，挑战了传统低成本低准确率的权衡。",
      "motivation": "当前强化学习在多跳推理代理中依赖于高成本、高准确率环境，如大规模模型和密集探索。但在现实资源约束下（如计算资源有限，无法支持大型模型或密集探索），小型语言模型代理陷入低成本、低准确率困境，导致探索稀疏、信用分配不稳定和训练不稳定。这一问题至关重要，因为许多实际应用（如边缘计算或低端设备）存在资源限制，现有方法无法有效平衡成本与性能，限制了小模型在复杂任务中的实用潜力。因此，亟需开发一种能在资源受限条件下保持高准确率的新方法。",
      "method": "论文提出DAVID-GRPO，一个预算高效的强化学习框架，其核心创新包括：(i) 使用最小监督稳定早期学习，防止训练崩溃；(ii) 基于证据回召（evidence recall）分配检索信用，优化多步推理中的信息传递；(iii) 通过重采样截断的近失轨迹（truncated near-miss trajectories）改善探索效率，减少无效尝试。该方法针对小型语言模型设计，代理参数最多1.5B，并在有限硬件资源（仅四个RTX 3090 GPUs）上进行训练，确保了实际可行性和成本效益。",
      "result": "实验结果显示，DAVID-GRPO在六个多跳问答基准测试中持续优于先前为大规模场景设计的强化学习方法。尽管代理模型参数不超过1.5B，且训练资源有限（仅四个RTX 3090 GPUs），该方法仍实现了高准确率的多跳推理。与基线方法相比，DAVID-GRPO在资源效率方面表现优异，具体性能指标摘要未明确量化，但强调了其优于现有方法的一致性，展示了小模型在适当归纳偏置下可以达到与大模型相媲美的性能。",
      "conclusion": "论文的主要贡献是证明了在资源约束下，小型语言模型通过DAVID-GRPO框架可以实现低成本高准确率的多跳推理。这项研究具有重要价值：学术上，它为强化学习在受限环境中的优化提供了新思路；实际应用上，扩展了小模型在复杂推理任务中的潜力，适用于资源有限的场景。未来工作可能包括进一步优化框架以适应更广泛的任务或探索更严格的资源限制，但摘要未明确说明局限性。",
      "tags": [
        "Reinforcement Learning",
        "Multi-Hop Reasoning",
        "Small Language Models",
        "Resource-Constrained Agents",
        "Evidence Recall"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:50.722581Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21698",
    "title": "Curriculum Learning for LLM Pretraining: An Analysis of Learning Dynamics",
    "authors": [
      "Mohamed Elgaar",
      "Hadi Amiri"
    ],
    "abstract": "Curriculum learning changes the order of pre-training data, but it remains unclear whether it changes the learning trajectory or mainly reorders exposure over a fixed trajectory. We train Pythia models (14M-410M parameters) for 300B tokens under three linguistically motivated curricula-Age-of-Acquisition, word frequency, and Verb Variation (VV)-and compare each against Random ordering; at 1B parameters we compare Random and VV. Across orderings, training follows a shared sequence of latent phases, while curricula mainly change within-phase data exposure. In smaller models (up to 160M parameters), Random ordering exhibits higher gradient noise and stronger late-training output-head spectral saturation, alongside lower final accuracy; curricula reduce both effects at matched compute. At larger scales, saturation differences are smaller and curriculum gains shrink. We formalize the link between difficulty pacing and optimization stability in an idealized analysis based on gradient-variance control, and our results point to a practical takeaway: curricula help by stabilizing within-phase optimization rather than by creating new phases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21698.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21698",
    "published": "2026-01-29T13:30:18Z",
    "updated": "2026-01-29T13:30:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文发现课程学习主要通过稳定阶段内优化而非改变学习阶段来影响大型语言模型预训练。",
      "motivation": "研究动机在于探究课程学习在LLM预训练中的作用，即通过改变数据顺序是否真正影响学习轨迹或仅是重排数据暴露。现有随机排序方法在小模型中可能导致梯度噪声和输出头谱饱和，从而降低准确性，而课程学习能否改善这些问题尚不明确。该问题的重要性在于优化预训练过程能提升模型效率和性能，尤其是在资源有限场景下。摘要指出现有方法在小型模型中存在优化不稳定的不足。",
      "method": "研究方法使用Pythia模型系列（参数14M-410M），在300B tokens上进行预训练，比较三种语言学驱动的课程（Age-of-Acquisition、词频、Verb Variation）与随机排序，并在1B参数时比较Random和Verb Variation。关键创新点包括分析学习动力学，并通过理想化分析基于梯度方差控制形式化难度节奏与优化稳定性的联系。技术特色在于结合实验和理论分析，揭示课程学习的作用机制。",
      "result": "实验结果显示，在小模型（最多160M参数）中，随机排序表现出更高梯度噪声和更强后期训练输出头谱饱和，同时准确性较低；课程学习能减少这些效应，在匹配计算条件下提升性能。在更大规模模型中，饱和差异较小，课程学习的收益也缩减。这些结果表明课程主要在小模型中优化稳定性，而对大规模模型影响有限。与基线（随机排序）的对比突出了课程学习的优势，尤其在资源受限环境中。",
      "conclusion": "结论表明课程学习的主要贡献是通过稳定阶段内优化来帮助预训练，而非创建新的学习阶段。这提供了学术价值，深化了对LLM预训练动力学的理解，并为设计更高效课程策略提供实践指导。潜在局限性在于大规模模型中效果减弱，未来工作可探索适应不同规模的课程设计或结合其他优化技术。该研究强调了优化稳定性在预训练中的关键作用。",
      "tags": [
        "Curriculum Learning",
        "LLM Pretraining",
        "Pythia Models",
        "Gradient Variance Control",
        "Optimization Stability"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:58.486120Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21694",
    "title": "ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing",
    "authors": [
      "Shuo Li",
      "Jiajun Sun",
      "Zhekai Wang",
      "Xiaoran Fan",
      "Hui Li",
      "Dingwen Yang",
      "Zhiheng Xi",
      "Yijun Wang",
      "Zifei Shan",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21694.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21694",
    "published": "2026-01-29T13:29:27Z",
    "updated": "2026-01-29T13:29:27Z",
    "comment": "Our benchmark will be publicly available at https://github.com/galactic123/ChartE3",
    "light_analysis": {
      "overview": "这篇论文提出了ChartE$^{3}$基准，用于直接评估端到端图表编辑模型，无需依赖自然语言或代码等中间表示，填补了现有评估方法的空白。",
      "motivation": "图表作为结构化数据分析的基础可视化格式，实现基于用户意图的端到端编辑具有重要实用价值。然而，现有方法多采用基于管道的设计，依赖自然语言或代码作为中间表示，这限制了执行复杂编辑的能力，尤其是在需要同时保持细粒度控制和全局结构一致性的场景下，凸显了对更直接编辑方法的迫切需求。",
      "method": "本研究引入了ChartE$^{3}$基准，专注于两个编辑维度：局部编辑涉及如字体或颜色调整的细粒度外观变化，全局编辑则需如数据过滤和趋势线添加的数据为中心转换。数据集通过精心设计的数据管道与人工策划构建，包含超过1,200个高质量样本，每个样本提供图表图像、底层代码和多模态编辑指令，支持客观和主观评估，但未详细说明具体模型架构。",
      "result": "通过对当前最先进的多模态大语言模型进行广泛基准测试，研究发现模型在端到端图表编辑任务中表现不足，尤其在全局编辑方面存在显著性能差距，这揭示了现有技术在处理需要整体结构一致性的复杂编辑时的关键限制，为未来模型改进提供了方向，但摘要未明确说明具体性能指标如准确率。",
      "conclusion": "本论文的主要贡献在于提出了ChartE$^{3}$基准，为端到端图表编辑研究提供了全面的评估框架，学术上揭示了当前模型的局限性，促进了相关技术的发展，实际应用中则有助于开发更高效的图表编辑工具。未来工作可聚焦于提升模型性能、扩展基准覆盖更多编辑场景或探索新的编辑方法。",
      "tags": [
        "Chart Editing",
        "Benchmarking",
        "Multimodal Large Language Models",
        "End-to-End Learning",
        "Data Visualization"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:25.933481Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21692",
    "title": "TCAP: Tri-Component Attention Profiling for Unsupervised Backdoor Detection in MLLM Fine-Tuning",
    "authors": [
      "Mingzu Liu",
      "Hao Fang",
      "Runmin Cong"
    ],
    "abstract": "Fine-Tuning-as-a-Service (FTaaS) facilitates the customization of Multimodal Large Language Models (MLLMs) but introduces critical backdoor risks via poisoned data. Existing defenses either rely on supervised signals or fail to generalize across diverse trigger types and modalities. In this work, we uncover a universal backdoor fingerprint-attention allocation divergence-where poisoned samples disrupt the balanced attention distribution across three functional components: system instructions, vision inputs, and user textual queries, regardless of trigger morphology. Motivated by this insight, we propose Tri-Component Attention Profiling (TCAP), an unsupervised defense framework to filter backdoor samples. TCAP decomposes cross-modal attention maps into the three components, identifies trigger-responsive attention heads via Gaussian Mixture Model (GMM) statistical profiling, and isolates poisoned samples through EM-based vote aggregation. Extensive experiments across diverse MLLM architectures and attack methods demonstrate that TCAP achieves consistently strong performance, establishing it as a robust and practical backdoor defense in MLLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21692.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21692",
    "published": "2026-01-29T13:26:29Z",
    "updated": "2026-01-29T13:26:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Tri-Component Attention Profiling (TCAP)，一种基于三组件注意力分析的无人监督后门检测框架，用于MLLM微调中过滤中毒样本，提升安全性。",
      "motivation": "Fine-Tuning-as-a-Service (FTaaS) 促进了多模态大语言模型（MLLMs）的定制化，但通过中毒数据引入了关键的后门风险。当前防御方法要么依赖于监督信号，要么无法在多样化的触发类型和模态之间泛化，导致安全性不足。因此，开发一种无需监督且能应对多模态后门攻击的泛化防御方法至关重要，以解决现有方法的局限性。",
      "method": "TCAP框架基于注意力分配差异作为后门指纹，首先将跨模态注意力图分解为三个功能组件：系统指令、视觉输入和用户文本查询。然后，使用高斯混合模型（GMM）进行统计剖析，以识别触发响应注意力头，并通过基于期望最大化（EM）算法的投票聚合来隔离中毒样本。该方法无需监督信号，能适应不同触发类型和模态的攻击场景。",
      "result": "在多种MLLM架构和攻击方法的广泛实验中，TCAP展现出一致且强大的性能，证明了其作为一种鲁棒的后门防御方法的有效性。摘要未提供具体性能指标数据，但实验结果表明其在多种场景下优于现有方法，能够有效应对多样化的后门攻击，验证了其实用性和泛化能力。",
      "conclusion": "TCAP通过利用注意力分配差异作为后门指纹，提供了一种有效的无人监督检测方案，显著提升了MLLM微调过程中的安全性。该方法具有重要的学术创新价值，为后门防御领域提供了新思路，并展示了实际应用潜力。摘要未明确说明局限性，但未来工作可探索更复杂的攻击场景或扩展应用到其他模型类型。",
      "tags": [
        "Multimodal Large Language Models",
        "Attention Profiling",
        "Gaussian Mixture Model",
        "Expectation-Maximization",
        "Backdoor Detection"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:54.095132Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21690",
    "title": "Understanding Model Merging: A Unified Generalization Framework for Heterogeneous Experts",
    "authors": [
      "Qinglun Li",
      "Anke Tang",
      "Miao Zhang",
      "Mengzhu Wang",
      "Quanjun Yin",
      "Li Shen"
    ],
    "abstract": "Model merging efficiently aggregates capabilities from multiple fine-tuned models into a single one, operating purely in parameter space without original data or expensive re-computation. Despite empirical successes, a unified theory for its effectiveness under heterogeneous finetuning hyperparameters (e.g., varying learning rates, batch sizes) remains missing. Moreover, the lack of hyperparameter transparency in open-source fine-tuned models makes it difficult to predict merged-model performance, leaving practitioners without guidance on how to fine-tune merge-friendly experts. To address those two challenges, we employ $L_2$-Stability theory under heterogeneous hyperparameter environments to analyze the generalization of the merged model $\\boldsymbol{x}_{avg}$. This pioneering analysis yields two key contributions: (i) \\textit{A unified theoretical framework} is provided to explain existing merging algorithms, revealing how they optimize specific terms in our bound, thus offering a strong theoretical foundation for empirical observations. (ii) \\textit{Actionable recommendations} are proposed for practitioners to strategically fine-tune expert models, enabling the construction of merge-friendly models within the pretraining-to-finetuning pipeline. Extensive experiments on the ResNet/Vit family across 20/8 visual classification tasks, involving thousands of finetuning models, robustly confirm the impact of different hyperparameters on the generalization of $\\boldsymbol{x}_{avg}$ predicted by our theoretical results.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21690.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21690",
    "published": "2026-01-29T13:22:06Z",
    "updated": "2026-01-29T13:22:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个统一的理论框架来解释模型合并的有效性，并为从业者提供微调建议以构建合并友好模型。",
      "motivation": "模型合并技术虽实证有效，但在异构微调超参数（如不同学习率、批大小）下缺乏统一理论指导，导致其有效性难以分析。此外，开源微调模型的超参数透明度不足，使合并后性能预测困难，从业者缺乏微调指导，限制了技术的广泛应用。本研究旨在填补这些空白，提供理论基础和实践建议以优化合并过程。",
      "method": "采用$L_2$-Stability理论在异构超参数环境下分析合并模型$\boldsymbol{x}_{avg}$的推广性，构建统一框架以解释现有合并算法如何优化理论边界中的特定项。关键创新包括揭示算法优化机制并提供可操作微调建议。使用ResNet和ViT模型家族，在20个和8个视觉分类任务上进行实验，涉及数千个微调模型以验证理论预测。",
      "result": "在ResNet和ViT上的大规模实验，涉及20个和8个视觉分类任务和数千个微调模型，稳健地验证了理论预测。不同超参数对合并模型$\boldsymbol{x}_{avg}$的推广性有显著影响，与统一框架一致，但摘要未明确说明具体性能指标如准确率提升，仅确认了影响的存在。",
      "conclusion": "本研究填补了模型合并领域统一理论的空白，通过$L_2$-Stability分析提供了强理论基础，解释了现有算法。提出的可操作建议帮助从业者在预训练-微调管道中构建合并友好模型，具有重要学术和实践价值。摘要未明确说明局限性和未来工作方向。",
      "tags": [
        "Model Merging",
        "L2-Stability",
        "Fine-tuning",
        "Hyperparameter Analysis",
        "Generalization Framework"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:54.426254Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21688",
    "title": "XFACTORS: Disentangled Information Bottleneck via Contrastive Supervision",
    "authors": [
      "Alexandre Myara",
      "Nicolas Bourriez",
      "Thomas Boyer",
      "Thomas Lemercier",
      "Ihab Bendidi",
      "Auguste Genovesio"
    ],
    "abstract": "Disentangled representation learning aims to map independent factors of variation to independent representation components. On one hand, purely unsupervised approaches have proven successful on fully disentangled synthetic data, but fail to recover semantic factors from real data without strong inductive biases. On the other hand, supervised approaches are unstable and hard to scale to large attribute sets because they rely on adversarial objectives or auxiliary classifiers.   We introduce \\textsc{XFactors}, a weakly-supervised VAE framework that disentangles and provides explicit control over a chosen set of factors. Building on the Disentangled Information Bottleneck perspective, we decompose the representation into a residual subspace $\\mathcal{S}$ and factor-specific subspaces $\\mathcal{T}_1,\\ldots,\\mathcal{T}_K$ and a residual subspace $\\mathcal{S}$. Each target factor is encoded in its assigned $\\mathcal{T}_i$ through contrastive supervision: an InfoNCE loss pulls together latents sharing the same factor value and pushes apart mismatched pairs. In parallel, KL regularization imposes a Gaussian structure on both $\\mathcal{S}$ and the aggregated factor subspaces, organizing the geometry without additional supervision for non-targeted factors and avoiding adversarial training and classifiers.   Across multiple datasets, with constant hyperparameters, \\textsc{XFactors} achieves state-of-the-art disentanglement scores and yields consistent qualitative factor alignment in the corresponding subspaces, enabling controlled factor swapping via latent replacement. We further demonstrate that our method scales correctly with increasing latent capacity and evaluate it on the real-world dataset CelebA. Our code is available at \\href{https://github.com/ICML26-anon/XFactors}{github.com/ICML26-anon/XFactors}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21688.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21688",
    "published": "2026-01-29T13:20:48Z",
    "updated": "2026-01-29T13:20:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出 XFactors 框架，通过结合解纠缠信息瓶颈和对比监督，实现弱监督解纠缠表示学习，提供对选定因子的控制。",
      "motivation": "解纠缠表示学习旨在将独立的变化因子映射到独立的表示组件，但现有方法面临挑战：无监督方法在合成数据上成功，却在真实数据上难以恢复语义因子，需强归纳偏置；监督方法依赖对抗目标或辅助分类器，导致不稳定且难以扩展到大型属性集。本研究旨在解决这些局限性，开发一个更稳定、可扩展的弱监督方法来处理真实世界数据中的解纠缠问题，以提升生成模型的控制能力。",
      "method": "XFactors 是一种弱监督的变分自编码器框架，基于解纠缠信息瓶颈视角，将潜在表示分解为残差子空间和多个因子特定子空间。核心创新在于使用对比监督：通过 InfoNCE 损失将共享相同因子值的潜在表示拉近，并将不匹配对推开，以编码目标因子。同时，应用 KL 正则化在子空间上施加高斯结构，无需对非目标因子进行额外监督，避免对抗训练和分类器的使用，简化了训练过程并提高了可扩展性。",
      "result": "在多个数据集上，XFactors 以恒定超参数实现了最先进的解纠缠分数，并在相应子空间中产生一致的定性因子对齐，支持通过潜在替换进行因子交换控制。特别在真实世界数据集 CelebA 上进行评估，验证了方法的有效性和可扩展性，与基线方法相比，在解纠缠性能上表现优越，展示了稳定的弱监督学习能力。",
      "conclusion": "本研究的主要贡献是提出 XFactors 框架，它通过弱监督方式稳定地实现解纠缠表示学习，避免了传统方法的对抗训练和分类器依赖。其学术价值在于结合信息瓶颈和对比监督，推动了解纠缠表示学习领域的技术创新；实际应用中，可用于生成模型的精细控制。未来工作方向摘要未明确说明，但可能包括扩展到更复杂数据集和优化方法性能。",
      "tags": [
        "Disentangled Representation Learning",
        "Variational Autoencoder",
        "Contrastive Supervision",
        "InfoNCE",
        "Disentangled Information Bottleneck"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:16.353257Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21686",
    "title": "Don't be so Stief! Learning KV Cache low-rank approximation over the Stiefel manifold",
    "authors": [
      "Luca Benfenati",
      "Matteo Risso",
      "Andrea Vannozzi",
      "Ahmet Caner Yüzügüler",
      "Lukas Cavigelli",
      "Enrico Macii",
      "Daniele Jahier Pagliari",
      "Alessio Burrello"
    ],
    "abstract": "Key--value (KV) caching enables fast autoregressive decoding but at long contexts becomes a dominant bottleneck in High Bandwidth Memory (HBM) capacity and bandwidth. A common mitigation is to compress cached keys and values by projecting per-head matrixes to a lower rank, storing only the projections in the HBM. However, existing post-training approaches typically fit these projections using SVD-style proxy objectives, which may poorly reflect end-to-end reconstruction after softmax, value mixing, and subsequent decoder-layer transformations.   For these reasons, we introduce StiefAttention, a post-training KV-cache compression method that learns \\emph{orthonormal} projection bases by directly minimizing \\emph{decoder-layer output reconstruction error}. StiefAttention additionally precomputes, for each layer, an error-rank profile over candidate ranks, enabling flexible layer-wise rank allocation under a user-specified error budget. Noteworthy, on Llama3-8B under the same conditions, StiefAttention outperforms EigenAttention by $11.9$ points on C4 perplexity and $5.4\\%$ on 0-shot MMLU accuracy at iso-compression, yielding lower relative error and higher cosine similarity with respect to the original decoder-layer outputs.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21686.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21686",
    "published": "2026-01-29T13:19:24Z",
    "updated": "2026-01-29T13:19:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出StiefAttention，一种在Stiefel流形上学习正交投影基的后训练KV缓存压缩方法，直接优化解码层输出重建误差以提升压缩效率。",
      "motivation": "KV缓存在长上下文自回归解码中成为高带宽内存容量和带宽的主要瓶颈，影响模型部署效率。现有方法如EigenAttention使用基于SVD的代理目标进行降维压缩，但这些近似可能无法准确反映经过softmax、值混合及后续解码层变换后的端到端重建质量，导致压缩后性能下降。因此，研究旨在开发一种更直接优化最终输出重建的方法，以解决现有压缩技术在实际应用中的不足，提高内存利用率和模型性能。",
      "method": "StiefAttention是一种后训练KV缓存压缩方法，核心在于学习正交投影基，通过直接最小化解码层输出重建误差来优化压缩过程。它利用Stiefel流形约束确保投影基的正交性，避免了传统SVD式目标的局限性。方法还包括预计算每个解码层的误差-秩配置文件，允许在用户指定的误差预算下灵活分配不同层的压缩秩，实现层间自适应的低秩近似。这提升了压缩的精确性和效率，支持在保持低内存占用的同时优化模型输出。",
      "result": "在Llama3-8B模型上，StiefAttention在相同压缩条件下显著优于基线方法EigenAttention。具体表现为：C4数据集困惑度提升11.9点，0-shot MMLU准确率提高5.4%。此外，StiefAttention产生的解码层输出相对误差更低，与原始输出的余弦相似度更高，表明其在压缩后能更精确地重建模型行为。这些结果验证了直接优化端到端重建误差的有效性，为KV缓存压缩提供了新的性能基准。",
      "conclusion": "StiefAttention的主要贡献在于提出一种基于正交投影和直接误差最小化的KV缓存压缩方法，提高了压缩精度和模型性能。学术上，它强调了端到端重建优化的重要性，突破了传统代理目标的局限；应用上，能有效缓解长上下文解码中的内存瓶颈，促进大语言模型的高效部署。潜在局限性可能包括计算开销或对其他模型的泛化性，未来工作可探索扩展至更多模型架构或实时压缩场景。",
      "tags": [
        "Key-Value Cache",
        "Low-Rank Approximation",
        "Stiefel Manifold",
        "Orthonormal Projection",
        "Post-Training Compression"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:22.029364Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21684",
    "title": "Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling",
    "authors": [
      "Xinglin Wang",
      "Jiayi Shi",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Yiwei Li",
      "Yueqi Zhang",
      "Chuyi Tan",
      "Ji Zhang",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \\textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21684.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21684",
    "published": "2026-01-29T13:18:36Z",
    "updated": "2026-01-29T13:18:36Z",
    "comment": "preprint",
    "light_analysis": {
      "overview": "该论文提出Recycling Search Experience (RSE)策略，通过回收搜索经验来高效提升大型语言模型在测试时间扩展中的推理能力，以减少计算冗余。",
      "motivation": "Test-Time Scaling旨在通过分配额外推理计算来增强大型语言模型的推理能力，扩大解决方案空间的探索，这在复杂任务中尤为重要。然而，现有搜索策略通常将rollouts视为一次性样本，中间见解在每次试验后被丢弃，导致系统性的无记忆性。这造成大量计算冗余，模型反复重新推导已发现的结论和重访已知死胡同，降低了扩展效率，限制了大型语言模型的实际应用。因此，开发更高效的搜索方法以减少计算浪费成为关键研究问题。",
      "method": "论文提出Recycling Search Experience (RSE)，一种自指导、无训练的策略。核心创新在于将测试时间搜索从孤立试验转变为累积过程。该方法通过主动蒸馏原始轨迹到共享经验库，实现正面回收中间结论以减少冗余推导，以及负面回收失败模式以修剪遇到的死胡同。关键特色包括不依赖额外训练，利用搜索历史优化后续探索，从而提高整体效率。尽管摘要未明确说明具体模型架构或数据集细节，但技术重点在于经验累积和共享机制。",
      "result": "在多个基准数据集（包括HMMT24、HMMT25、IMO-Bench和HLE）上的广泛实验表明，RSE以可比的计算成本持续优于强基线方法。论文提供了理论分析，形式化证明了RSE在解决复杂推理任务中相对于独立采样的效率优势。实证结果显示，RSE实现了最先进的扩展效率，尽管摘要未提供具体性能指标如准确率提升，但其在提升推理能力和减少计算冗余方面的有效性得到了验证，与基线方法相比具有显著优势。",
      "conclusion": "RSE策略的主要贡献在于提出了一种高效回收搜索经验的方法，显著提升了Test-Time Scaling的效率。学术价值体现在为大型语言模型的推理优化提供了新思路，通过无训练方式累积利用搜索历史，避免了额外计算开销。实际应用价值在于可广泛应用于需要复杂推理的AI任务，以降低计算成本并提高性能。未来工作方向可能包括优化经验回收机制或扩展到更多任务领域，尽管摘要未明确说明局限性。",
      "tags": [
        "Large Language Models",
        "Test-Time Scaling",
        "Experience Recycling",
        "Search Strategies",
        "Efficiency Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:50.071331Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21683",
    "title": "Can Local Learning Match Self-Supervised Backpropagation?",
    "authors": [
      "Wu S. Zihan",
      "Ariane Delrocq",
      "Wulfram Gerstner",
      "Guillaume Bellec"
    ],
    "abstract": "While end-to-end self-supervised learning with backpropagation (global BP-SSL) has become central for training modern AI systems, theories of local self-supervised learning (local-SSL) have struggled to build functional representations in deep neural networks. To establish a link between global and local rules, we first develop a theory for deep linear networks: we identify conditions for local-SSL algorithms (like Forward-forward or CLAPP) to implement exactly the same weight update as a global BP-SSL. Starting from the theoretical insights, we then develop novel variants of local-SSL algorithms to approximate global BP-SSL in deep non-linear convolutional neural networks. Variants that improve the similarity between gradient updates of local-SSL with those of global BP-SSL also show better performance on image datasets (CIFAR-10, STL-10, and Tiny ImageNet). The best local-SSL rule with the CLAPP loss function matches the performance of a comparable global BP-SSL with InfoNCE or CPC-like loss functions, and improves upon state-of-the-art for local SSL on these benchmarks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21683.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21683",
    "published": "2026-01-29T13:15:57Z",
    "updated": "2026-01-29T13:15:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究建立局部自我监督学习与全局反向传播自我监督学习的理论联系，并开发新算法使局部学习在深度网络中匹配全局性能。",
      "motivation": "在深度神经网络中，局部自我监督学习理论构建功能表示时面临挑战，而全局反向传播自我监督学习已成为训练现代AI系统的关键。当前局部学习方法性能有限，难以媲美全局方法，现有理论进展缓慢。因此，探究两者关系对于改进局部算法、提升效率或增强生物合理性至关重要，解决这一问题有助于推动更高效或可解释的学习方法的发展。",
      "method": "研究方法分为两个阶段：首先，在深度线性网络中发展理论，识别局部算法如Forward-forward或CLAPP实现与全局反向传播相同权重更新的条件。其次，基于理论洞察，设计局部自我监督学习算法的新变体，应用于深度非线性卷积神经网络，使用CLAPP损失函数以提高局部与全局梯度更新的相似度，从而逼近全局性能，创新点在于从线性到非线性的扩展及优化策略。",
      "result": "实验在CIFAR-10、STL-10和Tiny ImageNet图像数据集上进行，新算法变体通过提高与全局反向传播梯度更新的相似度，展现出更好的性能表现。最佳局部算法使用CLAPP损失函数，在性能上匹配了使用InfoNCE或CPC-like损失函数的全局算法，并超越当前局部自我监督学习的先进技术，为局部学习提供了显著的性能突破和基准提升。",
      "conclusion": "本研究主要贡献在于建立理论与新算法，验证了局部学习在深度网络中近似全局学习的可行性，具有学术价值如推进学习机制理解，以及实际应用潜力如分布式或生物可解释AI系统。同时，它为未来工作提供了基础，如扩展到更复杂网络或探索不同任务，可能涉及资源受限环境中的优化。",
      "tags": [
        "Local Self-Supervised Learning",
        "Self-Supervised Backpropagation",
        "CLAPP Loss Function",
        "Forward-forward Algorithm",
        "Contrastive Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:02.331825Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21682",
    "title": "FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning",
    "authors": [
      "Xiaoyu Xu",
      "Minxin Du",
      "Kun Fang",
      "Zi Liang",
      "Yaxin Xiao",
      "Zhicong Huang",
      "Cheng Hong",
      "Qingqing Ye",
      "Haibo Hu"
    ],
    "abstract": "Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \\fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \\fit mitigates degradation through rigorous data \\underline{F}iltering, \\underline{I}mportance-aware updates, and \\underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \\textbf{PCH}, a benchmark covering \\textbf{P}ersonal information, \\textbf{C}opyright, and \\textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \\fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21682.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21682",
    "published": "2026-01-29T13:15:32Z",
    "updated": "2026-01-29T13:15:32Z",
    "comment": "20 Pages",
    "light_analysis": {
      "overview": "提出FIT框架，通过数据过滤、重要性感知更新和目标层归属，有效解决持续大语言模型遗忘中的灾难性遗忘问题，实现遗忘效果与效用保持的良好平衡。",
      "motivation": "大型语言模型在多样化任务中表现卓越，但引发隐私、版权和有害材料等担忧。现有LLM遗忘方法较少考虑现实删除请求的持续性和大规模性，导致随着请求累积，模型效用下降和灾难性遗忘，影响实际部署的安全性。因此，研究需开发一种能处理大规模持续遗忘请求并保持鲁棒性的方法，以解决现有不足。",
      "method": "论文提出FIT框架，通过严格数据过滤（F）筛选删除请求，利用重要性感知更新（I）优化模型参数，并应用目标层归属（T）精确调整层贡献，以稳定性能并平衡遗忘与效用。框架还包括PCH基准，涵盖个人、版权和有害内容的序列删除场景，并引入Forget Degree和Retain Utility对称指标，评估遗忘质量和效用保留。",
      "result": "在四个开源LLMs上进行大量实验，涉及数百个删除请求。FIT在Forget Degree和Retain Utility之间实现最佳权衡，在MMLU、CommonsenseQA和GSM8K基准上超越现有方法，显示平均性能提升。同时，对再学习和量化恢复攻击表现出抵抗力，验证了其稳定性和鲁棒性，相比基线方法，在效用保持和遗忘效果方面均有改进。",
      "conclusion": "论文主要贡献是FIT框架，有效解决了持续LLM遗忘中的灾难性遗忘问题，并引入PCH基准支持实际评估。研究提升了LLM在隐私和安全性方面的实用性，具有重要学术价值和实际应用意义。摘要未明确说明局限性，但未来工作可扩展框架的通用性或应用于更多任务。",
      "tags": [
        "Continual Unlearning",
        "Importance-aware Updates",
        "Targeted Layer Attribution",
        "Forget Degree",
        "Retain Utility"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:52.875315Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21681",
    "title": "LLM4Fluid: Large Language Models as Generalizable Neural Solvers for Fluid Dynamics",
    "authors": [
      "Qisong Xiao",
      "Xinhai Chen",
      "Qinglin Wang",
      "Xiaowei Guo",
      "Binglin Wang",
      "Weifeng Chen",
      "Zhichao Wang",
      "Yunfei Liu",
      "Rui Xia",
      "Hang Zou",
      "Gencheng Liu",
      "Shuai Li",
      "Jie Liu"
    ],
    "abstract": "Deep learning has emerged as a promising paradigm for spatio-temporal modeling of fluid dynamics. However, existing approaches often suffer from limited generalization to unseen flow conditions and typically require retraining when applied to new scenarios. In this paper, we present LLM4Fluid, a spatio-temporal prediction framework that leverages Large Language Models (LLMs) as generalizable neural solvers for fluid dynamics. The framework first compresses high-dimensional flow fields into a compact latent space via reduced-order modeling enhanced with a physics-informed disentanglement mechanism, effectively mitigating spatial feature entanglement while preserving essential flow structures. A pretrained LLM then serves as a temporal processor, autoregressively predicting the dynamics of physical sequences with time series prompts. To bridge the modality gap between prompts and physical sequences, which can otherwise degrade prediction accuracy, we propose a dedicated modality alignment strategy that resolves representational mismatch and stabilizes long-term prediction. Extensive experiments across diverse flow scenarios demonstrate that LLM4Fluid functions as a robust and generalizable neural solver without retraining, achieving state-of-the-art accuracy while exhibiting powerful zero-shot and in-context learning capabilities. Code and datasets are publicly available at https://github.com/qisongxiao/LLM4Fluid.",
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21681.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21681",
    "published": "2026-01-29T13:14:48Z",
    "updated": "2026-01-29T13:14:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出LLM4Fluid框架，利用大语言模型作为通用神经求解器，实现流体动力学时空预测的高泛化性和零样本学习能力。",
      "motivation": "流体动力学模拟在科学和工程中至关重要，但现有深度学习方法存在泛化能力不足的问题。这些方法通常对未见的流动条件适应性差，并需要针对新场景重新训练，导致效率低下，限制了实际应用的灵活性和成本效益。因此，研究旨在开发一种无需重新训练的通用神经求解器，以克服这些局限。",
      "method": "LLM4Fluid框架采用降阶建模和物理信息解耦机制，将高维流场压缩到紧凑潜空间，以缓解空间特征纠缠并保留关键结构。预训练的大语言模型作为时间处理器，通过时间序列提示自回归预测物理序列的动态。此外，提出模态对齐策略，解决提示与物理序列之间的表示不匹配问题，提高预测准确性和长期稳定性。",
      "result": "在多种流动场景的实验中，LLM4Fluid无需重新训练即可达到最先进的预测精度，展现强大的零样本和上下文学习能力。与现有方法相比，它在泛化性和效率方面有显著提升，但摘要未提供具体准确率数据，仅提及状态级表现。",
      "conclusion": "LLM4Fluid的主要贡献是将大语言模型成功应用于流体动力学预测，实现了高泛化性和无需重新训练的优势，展示了LLM在物理建模中的学术潜力。该研究具有实际应用价值，可降低流体模拟成本和提高灵活性，但摘要未明确说明局限性，未来工作可能涉及扩展场景或优化效率。",
      "tags": [
        "Large Language Models",
        "Spatio-Temporal Modeling",
        "Fluid Dynamics",
        "Physics-Informed Disentanglement",
        "Modality Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:19.463222Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21678",
    "title": "Scale-Dependent Semantic Dynamics Revealed by Allan Deviation",
    "authors": [
      "Debayan Dasgupta"
    ],
    "abstract": "While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.",
    "categories": [
      "cs.CL",
      "physics.data-an"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21678.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21678",
    "published": "2026-01-29T13:10:59Z",
    "updated": "2026-01-29T13:10:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文通过引入Allan偏差分析语义动态，揭示了两种动态机制，并对比了人类文本与大型语言模型在语义稳定性上的差异。",
      "motivation": "语言通过一系列语义状态演变，但其进展的动态特性仍不明确，阻碍了区分人类创作与算法生成模式的能力。本研究旨在解决语义稳定性的测量问题，以评估不同类型文本和语言模型。现有方法可能缺乏揭示尺度依赖动态的工具，导致难以量化语义连贯性，因此需要跨学科方法填补这一空白。",
      "method": "作者将文本语义进展建模为高维状态空间中的随机轨迹，采用精密计量学的Allan偏差工具分析有序句子嵌入序列的稳定性。核心创新在于将句子嵌入视为位移信号，识别短时间幂律缩放和长时间稳定性受限噪声基底。摘要未明确说明使用的具体数据集和模型架构，但提及了大型语言模型的应用。",
      "result": "分析显示语义动态分为短时间幂律缩放，能区分创造性文学和技术文本；以及长时间过渡到稳定性受限的噪声基底。大型语言模型成功模仿人类文本的局部缩放统计，但稳定性范围系统性减少，表明在长期连贯性上与人类文本存在差异。与基线方法相比，该方法提供了更精细的动态分析。",
      "conclusion": "本研究的主要贡献是确立语义连贯性为可量化物理属性，并通过Allan偏差提供分析框架来区分人类认知与算法模型生成模式。学术上为语言动态研究提供新工具，实际上有助于评估和改进语言模型质量。未来工作可扩展应用到更多文本类型或研究增强模型的长期稳定性。",
      "tags": [
        "Allan Deviation",
        "Semantic Dynamics",
        "Large Language Models",
        "Sentence Embeddings",
        "Power-law Scaling"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:40.655778Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21673",
    "title": "Multimodal Visual Surrogate Compression for Alzheimer's Disease Classification",
    "authors": [
      "Dexuan Ding",
      "Ciyuan Peng",
      "Endrowednes Kuantama",
      "Jingcai Guo",
      "Jia Wu",
      "Jian Yang",
      "Amin Beheshti",
      "Ming-Hsuan Yang",
      "Yuankai Qi"
    ],
    "abstract": "High-dimensional structural MRI (sMRI) images are widely used for Alzheimer's Disease (AD) diagnosis. Most existing methods for sMRI representation learning rely on 3D architectures (e.g., 3D CNNs), slice-wise feature extraction with late aggregation, or apply training-free feature extractions using 2D foundation models (e.g., DINO). However, these three paradigms suffer from high computational cost, loss of cross-slice relations, and limited ability to extract discriminative features, respectively. To address these challenges, we propose Multimodal Visual Surrogate Compression (MVSC). It learns to compress and adapt large 3D sMRI volumes into compact 2D features, termed as visual surrogates, which are better aligned with frozen 2D foundation models to extract powerful representations for final AD classification. MVSC has two key components: a Volume Context Encoder that captures global cross-slice context under textual guidance, and an Adaptive Slice Fusion module that aggregates slice-level information in a text-enhanced, patch-wise manner. Extensive experiments on three large-scale Alzheimer's disease benchmarks demonstrate our MVSC performs favourably on both binary and multi-class classification tasks compared against state-of-the-art methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21673.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21673",
    "published": "2026-01-29T13:05:46Z",
    "updated": "2026-01-29T13:05:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "MVSC提出了一种多模态视觉替代压缩方法，通过将3D结构性MRI压缩为2D特征并与冻结的2D基础模型对齐，以提升阿尔茨海默病分类的性能。",
      "motivation": "阿尔茨海默病诊断依赖于高维结构性MRI图像，但现有方法存在显著缺陷。3D架构（如3D CNNs）计算成本高昂；切片特征提取方法在后期聚合时损失了跨切片关系；而使用2D基础模型（如DINO）的特征提取能力有限，难以提取判别性特征。这些问题影响了诊断的准确性和效率，因此需要开发一种更有效的表示学习方法来平衡计算复杂性和特征质量。MVSC旨在解决这些挑战，提供更高效和精确的解决方案。",
      "method": "MVSC的核心是学习将大型3D sMRI体积压缩成紧凑的2D特征（称为视觉替代），这些特征与冻结的2D基础模型对齐以提取强大表示。方法包含两个关键组件：Volume Context Encoder在文本指导下捕获全局跨切片上下文，Adaptive Slice Fusion模块以文本增强、基于patch的方式聚合切片级信息。这确保了在保持计算效率的同时，充分利用多模态信息进行AD分类。",
      "result": "在三个大规模阿尔茨海默病基准测试上的广泛实验表明，MVSC在二元和多类分类任务中表现优于最先进方法。摘要未提供具体性能指标如准确率或效率提升的数值，但强调了其在分类效果上的优势，可能涉及精度和计算成本的改进。实验对比了现有方法，确认了MVSC的优越性。",
      "conclusion": "MVSC的主要贡献是提出了一种创新的压缩方法，有效整合3D体积信息和2D基础模型，提升了阿尔茨海默病分类的性能。该研究在医学图像分析领域具有学术价值，可能推动临床诊断工具的发展，提高自动化诊断的可行性。未来工作可以探索该方法扩展到其他疾病或图像模态，以及进一步优化模型通用性和效率。",
      "tags": [
        "Multimodal Learning",
        "Visual Surrogate Compression",
        "Alzheimer's Disease Classification",
        "Volume Context Encoder",
        "Adaptive Slice Fusion"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:07.322589Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21670",
    "title": "When Gradient Optimization Is Not Enough: $\\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning",
    "authors": [
      "Zixuan Xia",
      "Hao Wang",
      "Pengcheng Weng",
      "Yanyu Qian",
      "Yangxin Xu",
      "William Dan",
      "Fei Wang"
    ],
    "abstract": "Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion.   We identify representation geometry as a missing control axis in multimodal learning and propose \\regName, a lightweight geometry-aware regularization framework. \\regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms.   Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21670.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21670",
    "published": "2026-01-29T13:03:50Z",
    "updated": "2026-01-29T13:03:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个轻量级的几何感知正则化框架\\regName，通过调节表示几何解决多模态学习中的模态内崩溃和跨模态不一致问题，提升模型性能。",
      "motivation": "多模态学习旨在整合异构模态的互补信息，然而仅依赖梯度优化无法保证表示的良好结构，即使有平衡训练方案，模型仍常出现几何病理如模态内表示崩溃和样本级跨模态不一致，这损害了单模态鲁棒性和多模态融合效果。因此，表示几何被视为缺失的控制轴，亟待解决以克服现有方法的局限性。",
      "method": "论文提出\\regName框架，这是一种几何感知正则化方法，通过对中间嵌入施加两种约束：模态内分散正则化促进表示多样性，防止崩溃；跨模态锚定正则化在不强制刚性对齐的情况下限制样本级跨模态漂移。该框架是即插即用的，无需修改模型架构，兼容各种训练范式。",
      "result": "在多个多模态基准测试上的实验表明，\\regName框架一致提升了多模态和单模态性能，有效缓解了模态权衡问题，尽管摘要未明确说明具体性能指标数据，但强调了与基线方法的改进。",
      "conclusion": "本研究的主要贡献在于提出\\regName几何感知正则化框架，通过显式调节表示几何解决了多模态学习中的几何病理，提升了性能，具有学术价值和实际应用潜力，尽管摘要未讨论局限性或未来工作，但其通用性为更广泛应用提供了基础。",
      "tags": [
        "Multimodal Learning",
        "Geometric Regularization",
        "Dispersive Regularization",
        "Anchoring Regularization"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:22.568221Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21669",
    "title": "Expected Return Causes Outcome-Level Mode Collapse in Reinforcement Learning and How to Fix It with Inverse Probability Scaling",
    "authors": [
      "Abhijeet Sinha",
      "Sundari Elango",
      "Dianbo Liu"
    ],
    "abstract": "Many reinforcement learning (RL) problems admit multiple terminal solutions of comparable quality, where the goal is not to identify a single optimum but to represent a diverse set of high-quality outcomes. Nevertheless, policies trained by standard expected return maximization routinely collapse onto a small subset of outcomes, a phenomenon commonly attributed to insufficient exploration or weak regularization. We show that this explanation is incomplete: outcome level mode collapse is a structural consequence of the expected-return objective itself. Under idealized learning dynamics, the log-probability ratio between any two outcomes evolves linearly in their reward difference, implying exponential ratio divergence and inevitable collapse independent of the exploration strategy, entropy regularization, or optimization algorithm. We identify the source of this pathology as the probability multiplier inside the expectation and propose a minimal correction: inverse probability scaling, which removes outcome-frequency amplification from the learning signal, fundamentally changes the learning dynamics, and provably yields reward-proportional terminal distributions, preventing collapse in multimodal settings. We instantiate this principle in Group Relative Policy Optimization (GRPO) as a drop-in modification, IPS-GRPO, requiring no auxiliary models or architectural changes. Across different reasoning and molecular generation tasks, IPS-GRPO consistently reduces outcome-level mode collapse while matching or exceeding baseline performance, suggesting that correcting the objective rather than adding exploration heuristics is key to reliable multimodal policy optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21669.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21669",
    "published": "2026-01-29T13:03:33Z",
    "updated": "2026-01-29T13:03:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文揭示了强化学习中期望回报目标导致结果级别模式坍塌的结构性原因，并提出逆概率缩放方法进行修正，以实现可靠的多模态策略优化。",
      "motivation": "该研究旨在解决强化学习在多模态问题中策略坍塌到少数高质量结果的挑战。现有方法通常将模式坍塌归咎于探索不足或正则化弱，但作者指出这是期望回报目标函数本身的固有缺陷，导致训练忽略解决方案的多样性，影响策略泛化和应用价值。识别这一根本原因对于开发更稳健的算法至关重要。",
      "method": "论文提出逆概率缩放（Inverse Probability Scaling）作为核心方法，通过移除期望回报目标中的概率乘数来修正学习信号，从根本上改变学习动态，确保奖励比例终端分布以防止坍塌。方法实例化为IPS-GRPO，作为Group Relative Policy Optimization的即插即用修改，无需辅助模型或架构调整。关键创新在于识别了目标函数的病理来源并提供最小修正，简化了多模态优化。",
      "result": "在多个推理和分子生成任务中，IPS-GRPO实验结果表明，它持续减少结果级别的模式坍塌，同时匹配或超过基线性能。与标准方法相比，该方法有效防止策略坍塌到有限结果，增强了输出多样性，而性能指标未受损害，验证了逆概率缩放的鲁棒性和实用性。摘要未明确说明具体数据，但强调了方法在不同任务中的一致有效性。",
      "conclusion": "研究的主要贡献在于揭示了期望回报目标导致模式坍塌的结构性原因，并提出了逆概率缩放这一修正方法，深化了对强化学习目标函数的理解，具有重要学术意义。实际应用中，IPS-GRPO为多模态策略优化提供了可靠工具，无需依赖复杂探索启发式。未来工作可探讨该方法在更广泛RL场景中的扩展性和潜在局限性。",
      "tags": [
        "Reinforcement Learning",
        "Expected Return Maximization",
        "Mode Collapse",
        "Inverse Probability Scaling",
        "Group Relative Policy Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:27.830303Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21666",
    "title": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding",
    "authors": [
      "Ahmed Y. Radwan",
      "Christos Emmanouilidis",
      "Hina Tabassum",
      "Deval Pandya",
      "Shaina Raza"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding. We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21666.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21666",
    "published": "2026-01-29T13:01:07Z",
    "updated": "2026-01-29T13:01:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了SONIC-O1基准，用于系统评估多模态大语言模型在真实世界音频-视频数据中的理解能力。",
      "motivation": "当前多模态大语言模型（MLLMs）研究主要集中于静态图像理解，而对处理顺序音频-视频数据的能力缺乏系统评估，这限制了模型在真实世界动态场景（如视频分析、人机交互）中的应用。现有方法的不足在于缺乏高质量基准来测试模型在时序数据上的性能，导致难以衡量其实际鲁棒性和泛化能力。因此，本研究旨在填补这一空白，通过引入全面基准，解决模型在音频-视频理解中的局限性，推动更准确和公平的多模态研究发展。",
      "method": "本文提出了SONIC-O1基准，这是一个全面的人工验证数据集，覆盖13个真实世界对话领域，包含4,958个标注和人口统计元数据。评估任务包括开放式总结、多项选择题（MCQ）回答和时间定位，要求模型提供支持性推理。关键创新点在于集成音频-视频数据，强调时序定位和社会因素分析，通过模拟真实交互场景来系统评估MLLMs的综合能力。该方法不依赖于特定模型架构，而是提供一个开放评估套件，适用于闭源和开源模型的比较研究。",
      "result": "实验结果显示，在闭源和开源模型上，多项选择题（MCQ）准确率差距相对较小，表明模型在静态任务上性能相似。然而，时间定位任务中，最佳闭源模型比开源模型性能高22.6%，突显了时序理解方面的显著差异。此外，模型性能在不同人口统计组间下降，揭示了持续的社会偏差和公平性问题。这些结果强调了当前MLLMs在音频-视频数据中处理动态信息和社会因素的局限性，为改进模型鲁棒性提供了实证基础。",
      "conclusion": "本研究的主要贡献是引入SONIC-O1基准，为多模态大语言模型在音频-视频理解上的评估提供了开放、全面的工具。其学术价值在于填补了时序和社会鲁棒评估的空白，促进了相关研究的发展；实际应用价值则有助于开发更公平和准确的模型，应用于视频分析、人机交互等领域。局限性包括模型性能在人口统计组间的差异和时序任务中的不足，未来工作可聚焦于改进模型鲁棒性，扩展基准以覆盖更多场景，并探索减轻社会偏差的方法。",
      "tags": [
        "Multimodal Large Language Models",
        "Audio-Video Understanding",
        "Benchmark Evaluation",
        "Temporal Localization",
        "Demographic Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:49.078313Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21665",
    "title": "AdaptBPE: From General Purpose to Specialized Tokenizers",
    "authors": [
      "Vijini Liyanage",
      "François Yvon"
    ],
    "abstract": "Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21665.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21665",
    "published": "2026-01-29T12:59:40Z",
    "updated": "2026-01-29T12:59:40Z",
    "comment": "EACL 2026",
    "light_analysis": {
      "overview": "论文提出AdaptBPE，一种轻量级后训练适应策略，用于将通用分词器优化为特定领域或语言的专业分词器。",
      "motivation": "子词分词方法如Byte-Pair Encoding（BPE）对大型语言模型（LLMs）的性能和效率有重要影响。现有标准方法训练通用分词器统一处理所有文本，但在应用到特定领域（如医疗或法律）或语言时，通用token集会降低编码效率。这导致模型在专业化任务中资源浪费和性能受限，因此需要一种适应机制来提高分词器的针对性和效率。",
      "method": "AdaptBPE采用后训练适应策略，基于适应语料库的频率分析，选择性地替换原通用分词器中的低效用token。核心算法通过分析token在适应语料中的使用频率，识别并优化token集合，使其在给定目标词汇量下最有效地编码特定数据。该方法类似于词汇微调过程，无需重新训练整个模型，是一种轻量级的适应机制，可应用于多语言或领域特定场景。",
      "result": "论文在多种语言的生成和分类任务上进行了实验，结果显示AdaptBPE比使用相同词汇量的基线方法（如标准BPE）更能有效压缩测试语料库。这表明适应后的分词器提高了编码效率，但摘要未明确说明具体性能指标如准确率提升或效率改进的数值细节。实验验证了该方法在任务泛化性和资源优化上的优势。",
      "conclusion": "AdaptBPE作为一种后训练适应策略，成功将通用分词器转化为针对特定领域或语言的专业工具，提升了大型语言模型的效率和性能。其学术价值在于提供了分词方法的优化思路，实际应用中可用于LLMs的快速部署和资源节省。未来工作可能包括扩展适应策略到更多模型架构或验证其在不同任务中的泛化能力，潜在局限性如适应语料库的质量依赖性需进一步研究。",
      "tags": [
        "Subword Tokenization",
        "Byte-Pair Encoding",
        "Large Language Models",
        "Vocabulary Adaptation",
        "Frequency Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:09.791309Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21664",
    "title": "SENDAI: A Hierarchical Sparse-measurement, EfficieNt Data AssImilation Framework",
    "authors": [
      "Xingyue Zhang",
      "Yuxuan Bao",
      "Mars Liyao Gao",
      "J. Nathan Kutz"
    ],
    "abstract": "Bridging the gap between data-rich training regimes and observation-sparse deployment conditions remains a central challenge in spatiotemporal field reconstruction, particularly when target domains exhibit distributional shifts, heterogeneous structure, and multi-scale dynamics absent from available training data. We present SENDAI, a hierarchical Sparse-measurement, EfficieNt Data AssImilation Framework that reconstructs full spatial states from hyper sparse sensor observations by combining simulation-derived priors with learned discrepancy corrections. We demonstrate the performance on satellite remote sensing, reconstructing MODIS (Moderate Resolution Imaging Spectroradiometer) derived vegetation index fields across six globally distributed sites. Using seasonal periods as a proxy for domain shift, the framework consistently outperforms established baselines that require substantially denser observations -- SENDAI achieves a maximum SSIM improvement of 185% over traditional baselines and a 36% improvement over recent high-frequency-based methods. These gains are particularly pronounced for landscapes with sharp boundaries and sub-seasonal dynamics; more importantly, the framework effectively preserves diagnostically relevant structures -- such as field topologies, land cover discontinuities, and spatial gradients. By yielding corrections that are more structurally and spectrally separable, the reconstructed fields are better suited for downstream inference of indirectly observed variables. The results therefore highlight a lightweight and operationally viable framework for sparse-measurement reconstruction that is applicable to physically grounded inference, resource-limited deployment, and real-time monitor and control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21664.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21664",
    "published": "2026-01-29T12:58:54Z",
    "updated": "2026-01-29T12:58:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "SENDAI框架通过结合模拟先验与学习修正，实现了从超稀疏传感器观测重建完整时空场，显著提升重建性能。",
      "motivation": "时空场重建在数据丰富的训练条件下表现良好，但在实际部署中常面临观测稀疏的挑战，尤其是在目标域存在分布偏移、异构结构和多尺度动态时，这些因素在可用训练数据中可能缺失。现有方法如传统基线和高频方法通常需要更密集的观测数据，且在适应域移和保留关键结构方面表现不足，导致重建效果受限，这凸显了开发新框架的重要性。",
      "method": "SENDAI是一个分层稀疏测量高效数据同化框架，其核心方法是将模拟驱动的先验知识与学习到的差异修正相结合，从超稀疏传感器观测重建完整空间状态。关键创新点在于利用先验处理稀疏观测，并通过层次结构适应多尺度动态。实验中使用MODIS植被指数场作为数据集，涵盖六个全球分布站点，以季节变化模拟域移条件，验证了框架的有效性。",
      "result": "SENDAI在结构相似性指数（SSIM）上，相比传统基线最大提升185%，相比近期高频方法提升36%，性能优势在具有锐利边界和次季节动态的景观中更明显。框架有效保留了场拓扑、土地覆盖不连续性和空间梯度等诊断相关结构，使重建场更适用于下游变量推理任务，展示了优于基线的性能。",
      "conclusion": "SENDAI框架的主要贡献是提供了一个轻量级且操作可行的稀疏测量重建解决方案，能够应对分布偏移和结构保留的挑战。其学术价值在于结合先验与学习修正的新方法，实际应用价值体现在适用于物理推理、资源受限部署和实时监控场景。未来工作可进一步扩展数据集和应用领域，摘要未明确说明具体局限性。",
      "tags": [
        "Sparse-measurement Reconstruction",
        "Data Assimilation",
        "Domain Shift",
        "Hierarchical Models",
        "Remote Sensing"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:21.620048Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21663",
    "title": "Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation",
    "authors": [
      "Marcel Dreier",
      "Nora Gourmelon",
      "Dakota Pyles",
      "Thorsten Seehaus",
      "Matthias H. Braun",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "abstract": "During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21663.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21663",
    "published": "2026-01-29T12:58:45Z",
    "updated": "2026-01-29T12:58:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种结合few-shot域适应、时间参考和静态先验的框架，显著提高了冰川崩解前沿描绘在新研究站点的准确性。",
      "motivation": "研究动机是解决最先进的冰川崩解前沿描绘模型在基准测试中表现良好，但在应用到分布外的新研究站点时精度不足的问题，这限制了其在实际科学分析中的应用。现有方法因仅基于基准数据集训练，缺乏泛化能力，导致模型无法有效适应新域，而崩解前沿监测对全球气候变化研究至关重要，因此需要改进域适应策略以提升实用性。",
      "method": "研究方法采用few-shot域适应策略，结合空间静态先验知识，并在输入时间序列中加入夏季参考图像。核心创新点在于集成时间参考和静态先验进行域适应，无需修改模型架构，利用少量新站点数据调整模型，以提升描绘性能，强调了多模态输入的融合。",
      "result": "实验结果表明，通过提出的方法，描绘误差从1131.6米显著降低到68.7米，且未进行任何架构修改。与基线模型在新站点的表现相比，误差减少超过90%，验证了域适应策略的有效性，从误差极高改善到接近实用水平，支撑了进一步科学分析。",
      "conclusion": "论文的主要贡献是建立了一个框架，使基于深度学习的崩解前沿分割能应用于新研究站点，支持全球监测，具有重要学术价值和应用前景。未来工作可探索更广泛的域适应场景或集成更多先验知识。",
      "tags": [
        "Few-Shot Learning",
        "Domain Adaptation",
        "Temporal References",
        "Static Priors",
        "Image Segmentation"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:13.173292Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21662",
    "title": "Epistemic Uncertainty Quantification for Pre-trained VLMs via Riemannian Flow Matching",
    "authors": [
      "Li Ju",
      "Mayank Nautiyal",
      "Andreas Hellander",
      "Ekta Vats",
      "Prashant Singh"
    ],
    "abstract": "Vision-Language Models (VLMs) are typically deterministic in nature and lack intrinsic mechanisms to quantify epistemic uncertainty, which reflects the model's lack of knowledge or ignorance of its own representations. We theoretically motivate negative log-density of an embedding as a proxy for the epistemic uncertainty, where low-density regions signify model ignorance. The proposed method REPVLM computes the probability density on the hyperspherical manifold of the VLM embeddings using Riemannian Flow Matching. We empirically demonstrate that REPVLM achieves near-perfect correlation between uncertainty and prediction error, significantly outperforming existing baselines. Beyond classification, we also demonstrate that the model also provides a scalable metric for out-of-distribution detection and automated data curation.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21662.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21662",
    "published": "2026-01-29T12:58:42Z",
    "updated": "2026-01-29T12:58:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出REPVLM方法，通过Riemannian Flow Matching量化预训练视觉语言模型的认知不确定性。",
      "motivation": "视觉语言模型（VLMs）通常是确定性的，缺乏内在机制来量化认知不确定性，这限制了模型对其表示的无知程度的识别。认知不确定性反映了模型的知识缺乏，在提高模型可靠性和安全性方面至关重要。现有方法可能无法有效估计这种不确定性，导致在不确定性敏感的应中如自动驾驶或医疗诊断中性能受限，因此需要新的量化技术来解决这一问题。",
      "method": "REPVLM方法的核心是使用嵌入的负对数密度作为认知不确定性的代理，其中低密度区域表示模型的无知。该方法通过Riemannian Flow Matching在超球面流形上计算VLM嵌入的概率密度，利用几何特性在嵌入空间中准确估计不确定性。基于预训练的VLMs，该方法在不修改原始模型的情况下，通过密度估计实现不确定性量化，强调了流形学习在复杂表示中的应用。",
      "result": "实验证明，REPVLM在不确定性和预测错误之间实现了近乎完美的相关性，显著优于现有基线方法。此外，该方法在分布外检测和自动化数据管理任务中表现出色，提供了一个可扩展的度量，经验验证表明其在多种场景下提升了模型性能的透明度和可靠性，尽管摘要未明确具体数据集或详细指标，但结果强调了该方法的泛化能力。",
      "conclusion": "REPVLM为预训练VLMs的认知不确定性量化提供了有效方法，通过Riemannian Flow Matching提高了估计准确性。这项研究具有学术价值，推动了不确定性估计领域的发展，并在实际应用如分布外检测和数据管理中展示了潜力。未来工作可探索该方法在其他模型和任务中的扩展，或结合更多实际场景进行优化。",
      "tags": [
        "Vision-Language Models",
        "Uncertainty Quantification",
        "Riemannian Flow Matching",
        "Embedding Density",
        "Out-of-Distribution Detection"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:48.438932Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21656",
    "title": "TabClustPFN: A Prior-Fitted Network for Tabular Data Clustering",
    "authors": [
      "Tianqi Zhao",
      "Guanyang Wang",
      "Yan Shuo Tan",
      "Qiong Zhang"
    ],
    "abstract": "Clustering tabular data is a fundamental yet challenging problem due to heterogeneous feature types, diverse data-generating mechanisms, and the absence of transferable inductive biases across datasets. Prior-fitted networks (PFNs) have recently demonstrated strong generalization in supervised tabular learning by amortizing Bayesian inference under a broad synthetic prior. Extending this paradigm to clustering is nontrivial: clustering is unsupervised, admits a combinatorial and permutation-invariant output space, and requires inferring the number of clusters. We introduce TabClustPFN, a prior-fitted network for tabular data clustering that performs amortized Bayesian inference over both cluster assignments and cluster cardinality. Pretrained on synthetic datasets drawn from a flexible clustering prior, TabClustPFN clusters unseen datasets in a single forward pass, without dataset-specific retraining or hyperparameter tuning. The model naturally handles heterogeneous numerical and categorical features and adapts to a wide range of clustering structures. Experiments on synthetic data and curated real-world tabular benchmarks show that TabClustPFN outperforms classical, deep, and amortized clustering baselines, while exhibiting strong robustness in out-of-the-box exploratory settings. Code is available at https://github.com/Tianqi-Zhao/TabClustPFN.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21656.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21656",
    "published": "2026-01-29T12:56:41Z",
    "updated": "2026-01-29T12:56:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "TabClustPFN 是一种先验拟合网络，通过摊销贝叶斯推理实现了表格数据的高效聚类，提升了跨数据集的泛化能力。",
      "motivation": "表格数据聚类是一个基本但具有挑战性的问题，因为特征类型异构（如数值和分类特征）、数据生成机制多样，且缺乏跨数据集的可转移归纳偏差。现有聚类方法往往需要针对每个数据集进行特定的调参或重新训练，泛化能力有限。Prior-fitted networks (PFNs) 在监督学习中对表格数据表现出色，但扩展到无监督聚类时面临困难，因为聚类输出空间是组合且对排列不变的，还需要推断聚类数量。本研究旨在利用 PFNs 的优势，克服这些挑战，开发一个无需数据集特定调整即可泛化的聚类方法，以应对现实世界中的多样化数据需求。",
      "method": "论文提出 TabClustPFN，一个用于表格数据聚类的先验拟合网络。该方法扩展了 prior-fitted networks 到无监督聚类任务，通过摊销贝叶斯推理同时处理聚类分配和聚类数量。模型在从灵活聚类先验生成的合成数据集上进行预训练，利用贝叶斯框架学习泛化的聚类模式。训练完成后，TabClustPFN 可以在单个前向传播中对未见过的数据集进行聚类，无需数据集特定的重新训练或超参数调整。它自然支持异构的数值和分类特征，并能适应各种聚类结构，关键创新在于结合先验学习和摊销推理以实现高效的跨数据集应用。",
      "result": "实验在合成数据和精选的真实世界表格基准数据集上进行。TabClustPFN 在性能上超越了经典聚类方法、深度学习方法和其它摊销聚类基线，表现出更高的聚类准确率和更强的鲁棒性。在开箱即用的探索性设置中，模型稳定有效，无需额外调整即可适应不同数据分布。摘要未明确提供具体性能数据（如准确率数值），但强调了相对于基线方法的优势，特别是在泛化能力和处理异构特征时的适应性方面。",
      "conclusion": "论文的主要贡献是提出了 TabClustPFN，一种创新的表格数据聚类方法，通过结合先验拟合网络和摊销贝叶斯推理，有效解决了聚类中的泛化和适应性挑战。研究的学术价值在于推动了无监督学习和贝叶斯方法在表格数据领域的应用，实际应用价值体现在简化聚类流程，提高数据探索效率，适用于快速原型设计和真实世界数据分析。潜在的局限性可能包括对合成先验的依赖，未来工作可以扩展到更广泛的先验设置、集成更多数据类型或应用于其他无监督学习任务。",
      "tags": [
        "Prior-Fitted Networks",
        "Tabular Data Clustering",
        "Bayesian Inference",
        "Amortized Inference",
        "Unsupervised Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:21.323631Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21654",
    "title": "ScholarGym: Benchmarking Deep Research Workflows on Academic Literature Retrieval",
    "authors": [
      "Hao Shen",
      "Hang Yang",
      "Zhouhong Gu"
    ],
    "abstract": "Tool-augmented large language models have advanced from single-turn question answering to deep research workflows that iteratively plan queries, invoke external tools, and synthesize information to address complex information needs. Evaluating such workflows presents a fundamental challenge: reliance on live APIs introduces non-determinism, as tool invocations may yield different results across runs due to temporal drift, rate limiting, and evolving backend states. This variance undermines reproducibility and invalidates cross-system comparisons.   We present ScholarGym, a simulation environment for reproducible evaluation of deep research workflows on academic literature. The environment decouples workflow components into query planning, tool invocation, and relevance assessment, enabling fine-grained analysis of each stage under controlled conditions. Built on a static corpus of 570K papers with deterministic retrieval, ScholarGym provides 2,536 queries with expert-annotated ground truth. Experiments across diverse backbone models reveal how reasoning capabilities, planning strategies, and selection mechanisms interact over iterative refinement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21654.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21654",
    "published": "2026-01-29T12:51:44Z",
    "updated": "2026-01-29T12:51:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "ScholarGym是一个模拟环境，用于在学术文献检索中实现深度研究工作流的可重现评估，解决了依赖实时API导致的可重现性问题。",
      "motivation": "深度研究工作流评估面临根本挑战，依赖实时API会引入非确定性因素，如时间漂移、速率限制和后端状态演变，导致工具调用结果在不同运行中不一致，破坏评估的可重现性和跨系统比较的有效性。现有方法缺乏稳定、可控的评估环境，这使得准确衡量和比较不同系统的性能变得困难，因此开发可重现模拟环境至关重要。",
      "method": "论文提出ScholarGym模拟环境，将深度研究工作流解耦为查询规划、工具调用和相关性评估三个核心组件。基于包含570K学术论文的静态语料库和确定性检索方法，避免实时API的不确定性；提供2,536个专家标注查询作为地面真实数据。关键创新在于环境设计，支持在受控条件下对各阶段进行细粒度分析，以深入理解工作流性能。",
      "result": "实验在不同主干模型上进行，揭示了推理能力、规划策略和选择机制在迭代精炼过程中的交互作用。摘要未明确说明具体的性能指标数据，如准确率提升或效率改进，但通过实验展示了ScholarGym环境在评估深度研究工作流中的有效性，有助于识别不同模型在复杂信息需求处理中的表现。",
      "conclusion": "ScholarGym提供了一个可重现的评估框架，解决了深度研究工作流评估中的非确定性问题，支持跨系统比较和细粒度性能分析。其学术价值在于促进更可靠的模型评估方法，推动工具增强大型语言模型的研究进展；实际应用价值包括优化信息检索系统和指导工作流设计。未来工作可能包括扩展语料库或应用于其他领域。",
      "tags": [
        "Large Language Model",
        "Tool-Augmented Systems",
        "Research Workflow",
        "Simulation Environment",
        "Information Retrieval"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:29.753074Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21653",
    "title": "Gauge-invariant representation holonomy",
    "authors": [
      "Vasileios Sevetlidis",
      "George Pavlidis"
    ],
    "abstract": "Deep networks learn internal representations whose geometry--how features bend, rotate, and evolve--affects both generalization and robustness. Existing similarity measures such as CKA or SVCCA capture pointwise overlap between activation sets, but miss how representations change along input paths. Two models may appear nearly identical under these metrics yet respond very differently to perturbations or adversarial stress. We introduce representation holonomy, a gauge-invariant statistic that measures this path dependence. Conceptually, holonomy quantifies the \"twist\" accumulated when features are parallel-transported around a small loop in input space: flat representations yield zero holonomy, while nonzero values reveal hidden curvature. Our estimator fixes gauge through global whitening, aligns neighborhoods using shared subspaces and rotation-only Procrustes, and embeds the result back to the full feature space. We prove invariance to orthogonal (and affine, post-whitening) transformations, establish a linear null for affine layers, and show that holonomy vanishes at small radii. Empirically, holonomy increases with loop radius, separates models that appear similar under CKA, and correlates with adversarial and corruption robustness. It also tracks training dynamics as features form and stabilize. Together, these results position representation holonomy as a practical and scalable diagnostic for probing the geometric structure of learned representations beyond pointwise similarity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21653.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21653",
    "published": "2026-01-29T12:51:17Z",
    "updated": "2026-01-29T12:51:17Z",
    "comment": "14th International Conference on Learning Representations (ICLR)",
    "light_analysis": {
      "overview": "论文提出了一种名为表示全纯的规范不变统计量，用于度量深度网络内部表示随输入路径的变化。",
      "motivation": "深度学习模型的内部表示几何性质直接影响泛化能力和鲁棒性。现有相似度度量方法，如CKA或SVCCA，仅评估激活集之间的点对点重叠，无法捕捉表示如何随输入路径变化。这导致即使两个模型在这些度量下表现相似，它们在面对扰动或对抗性攻击时可能反应截然不同，凸显了开发新方法来量化路径依赖性的重要性，以更全面地评估表示结构并提升模型在实际应用中的可靠性。",
      "method": "核心方法是表示全纯，它量化了在输入空间中沿小环路平行传输特征时积累的扭曲。估计器通过全局白化固定规范，利用共享子空间和仅旋转的Procrustes对齐邻域，并将结果嵌入回完整特征空间以计算全纯值。关键创新点包括规范不变性设计、对平行传输概念的量化以及能够捕捉表示曲率的变化，同时证明了正交变换不变性和线性层的零值特性。",
      "result": "理论上，证明了表示全纯对正交和仿射变换（在白化后）具有不变性，并在线性层中为零值，在小半径时趋近于零。实证实验显示，全纯值随输入环路半径的增加而增大，能够有效区分在CKA度量下表现相似的模型，并与对抗性鲁棒性和数据损坏鲁棒性呈现正相关。此外，该方法还能追踪训练过程中特征的演变和稳定化，提供了对表示几何结构的动态洞察。",
      "conclusion": "表示全纯作为一种实用且可扩展的诊断工具，超越了传统点对点相似度度量，提供了对学习表示几何结构的深入分析。其学术价值在于弥补了点对点度量方法的不足并扩展了表示分析的理论框架，实际应用价值在于评估模型鲁棒性和监控训练状态。未来工作可探讨其在更广泛网络架构和数据集中的应用，并进一步分析其与模型性能的具体关联。",
      "tags": [
        "Representation Holonomy",
        "Gauge Invariance",
        "Parallel Transport",
        "Adversarial Robustness",
        "Training Dynamics"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:51.789222Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21649",
    "title": "SWE-Spot: Building Small Repo-Experts with Repository-Centric Learning",
    "authors": [
      "Jinjun Peng",
      "Magnus Saebo",
      "Tianjun Zhong",
      "Yi-Jie Cheng",
      "Junfeng Yang",
      "Baishakhi Ray",
      "Simin Chen",
      "Yangruibo Ding"
    ],
    "abstract": "The deployment of coding agents in privacy-sensitive and resource-constrained environments drives the demand for capable open-weight Small Language Models (SLMs). However, they suffer from a fundamental capability gap: unlike frontier large models, they lack the inference-time strong generalization to work with complicated, unfamiliar codebases. We identify that the prevailing Task-Centric Learning (TCL) paradigm, which scales exposure across disparate repositories, fails to address this limitation. In response, we propose Repository-Centric Learning (RCL), a paradigm shift that prioritizes vertical repository depth over horizontal task breadth, suggesting SLMs must internalize the \"physics\" of a target software environment through parametric knowledge acquisition, rather than attempting to recover it via costly inference-time search. Following this new paradigm, we design a four-unit Repository-Centric Experience, transforming static codebases into interactive learning signals, to train SWE-Spot-4B, a family of highly compact models built as repo-specialized experts that breaks established scaling trends, outperforming open-weight models up to larger (e.g., CWM by Meta, Qwen3-Coder-30B) and surpassing/matching efficiency-focused commercial models (e.g., GPT-4.1-mini, GPT-5-nano) across multiple SWE tasks. Further analysis reveals that RCL yields higher training sample efficiency and lower inference costs, emphasizing that for building efficient intelligence, repository mastery is a distinct and necessary dimension that complements general coding capability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21649.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21649",
    "published": "2026-01-29T12:49:25Z",
    "updated": "2026-01-29T12:49:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出存储库中心学习范式，通过训练SWE-Spot-4B模型，实现了小型语言模型在复杂代码库上的高效推理能力。",
      "motivation": "在隐私敏感和资源受限的环境中，部署编码代理需要高效的小型语言模型，但现有模型缺乏推理时对不熟悉代码库的强泛化能力。传统的任务中心学习方法通过广泛接触不同存储库，未能解决这一问题，导致模型在处理复杂软件环境时表现不佳，这凸显了开发新范式的必要性。",
      "method": "论文提出存储库中心学习范式，优先学习单个代码存储库的深度知识而非多个任务的广度。具体通过设计四个单元的存储库中心体验，将静态代码库转换为交互式学习信号，训练SWE-Spot-4B模型，利用参数化知识获取来内化目标软件环境的特性。",
      "result": "SWE-Spot-4B在多个软件工程任务中表现优异，超越了如CWM和Qwen3-Coder-30B等更大开放权重模型，并可匹敌或超越专注于效率的商业模型如GPT-4.1-mini和GPT-5-nano。进一步分析表明，RCL范式提高了训练样本效率和降低了推理成本，验证了其有效性。",
      "conclusion": "研究的主要贡献在于提出RCL范式，强调存储库掌握是构建高效智能系统的必要维度，补充了通用编码能力。这在学术上提供了新的学习范式，实际应用上适用于资源受限环境，未来可探索其扩展性。",
      "tags": [
        "Repository-Centric Learning",
        "Small Language Models",
        "Code Generation",
        "Software Engineering",
        "Training Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:37.625495Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21648",
    "title": "CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection",
    "authors": [
      "Bowen Zhou",
      "Marc-André Fiedler",
      "Ayoub Al-Hamadi"
    ],
    "abstract": "Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21648.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21648",
    "published": "2026-01-29T12:49:06Z",
    "updated": "2026-01-29T12:49:06Z",
    "comment": "The paper contains a total of 5 pages and 3 figures. This paper has been accepted for publication in the proceedings of 2026 IEEE ICASSP Conference",
    "light_analysis": {
      "overview": "本研究提出CAF-Mamba框架，通过基于Mamba的跨模态自适应注意融合技术，显著提升了多模态抑郁检测的性能。",
      "motivation": "抑郁是一种常见的心理健康障碍，严重影响日常生活。目前基于深度学习的抑郁检测方法存在局限性：它们通常依赖有限的特征类型、忽视显式的跨模态交互，并使用简单的拼接或静态权重进行模态融合。这导致融合效果不佳，难以捕捉多模态数据中的复杂依赖关系。本研究旨在克服这些不足，通过动态调整模态贡献，提高检测准确性和鲁棒性，解决实际应用中多模态信息融合的低效问题。",
      "method": "CAF-Mamba是一个创新的多模态融合框架，基于Mamba模型设计。它通过模态注意力机制同时捕获显式和隐式的跨模态交互，动态调整不同模态的贡献权重，实现更有效的融合。关键创新点包括引入Mamba结构处理序列数据，以及自适应注意力层优化模态间信息整合。技术细节涉及利用公开数据集LMVD和D-Vlog进行模型训练和验证，但摘要未明确说明具体的模型架构参数或超调设置。",
      "result": "实验在LMVD和D-Vlog两个自然场景基准数据集上进行。结果表明，CAF-Mamba consistently outperforms existing methods，即持续优于现有方法，并在性能上达到state-of-the-art水平。虽然没有提供具体的准确率或效率数据，但与基线方法对比显示其在多模态抑郁检测任务中具有显著的性能提升，验证了自适应融合策略的有效性。",
      "conclusion": "论文的主要贡献是提出了CAF-Mamba框架，通过Mamba模型和自适应注意力融合，有效解决了多模态抑郁检测中的融合瓶颈。这项研究不仅具有学术价值，推动了多模态学习技术的发展，还在实际应用中为心理健康监测提供了更精准的工具。局限性或未来工作方向在摘要中未明确说明，但可能包括扩展到其他多模态任务或进一步优化模型效率。",
      "tags": [
        "Mamba",
        "Cross-Modal Attention",
        "Adaptive Fusion",
        "Multimodal Learning",
        "Depression Detection"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:39.395562Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21647",
    "title": "ILRR: Inference-Time Steering Method for Masked Diffusion Language Models",
    "authors": [
      "Eden Avrahami",
      "Eliya Nachmani"
    ],
    "abstract": "Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\\%$ to 60$\\%$ points, while maintaining high generation quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21647.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21647",
    "published": "2026-01-29T12:48:59Z",
    "updated": "2026-01-29T12:48:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出ILRR框架，通过动态对齐生成序列与参考序列的内部激活，实现扩散语言模型的推理时属性控制。",
      "motivation": "离散扩散语言模型（DLMs）为非自回归文本生成提供新途径，但现有方法在推理时控制机制方面不足，如采样级指导或轨迹优化机制效率有限，难以灵活调整属性如情感。这限制了DLMs在可控文本生成中的应用，因此本研究旨在开发高效、灵活的推理时指导方法，以提升模型的可控性。",
      "method": "论文提出ILRR框架，这是一种学习自由的推理时指导方法，通过在整个去噪过程中动态对齐生成序列和参考序列的内部激活来引导生成。核心创新包括内部激活对齐机制，捕获并传递高级语义属性，并通过可调节指导尺度实现灵活控制。扩展部分引入空间调制指导，用于处理长文本，通过调节序列不同位置的指导强度，基于LLaDA和MDLM架构实现，计算开销小，每个去噪步骤仅需一个额外并行前向传递。",
      "result": "实验结果表明，ILRR在LLaDA和MDLM架构上有效实现了属性指导，计算开销较小，每个去噪步骤仅增加一个并行前向传递。与可比基线相比，在相同计算预算下，ILRR将属性准确性提升了10%到60%点，同时保持了高生成质量，显示出在控制和生成方面的显著优势。",
      "conclusion": "本研究提出的ILRR框架显著改善了扩散语言模型的推理时属性控制能力，主要贡献包括学习自由的设计、高效的内部激活对齐方法和空间调制指导扩展。学术上，为文本生成的可控性提供了新思路；实际应用上，可用于情感分析、风格转换等领域，但摘要未明确说明局限性或未来工作方向。",
      "tags": [
        "Diffusion Language Models",
        "Inference-Time Steering",
        "Internal Activation Alignment",
        "Latent Representation Refinement",
        "Non-Autoregressive Generation"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:36.213430Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21645",
    "title": "Identifiable Equivariant Networks are Layerwise Equivariant",
    "authors": [
      "Vahid Shahverdi",
      "Giovanni Luca Marchetti",
      "Georg Bökman",
      "Kathlén Kohn"
    ],
    "abstract": "We investigate the relation between end-to-end equivariance and layerwise equivariance in deep neural networks. We prove the following: For a network whose end-to-end function is equivariant with respect to group actions on the input and output spaces, there is a parameter choice yielding the same end-to-end function such that its layers are equivariant with respect to some group actions on the latent spaces. Our result assumes that the parameters of the model are identifiable in an appropriate sense. This identifiability property has been established in the literature for a large class of networks, to which our results apply immediately, while it is conjectural for others. The theory we develop is grounded in an abstract formalism, and is therefore architecture-agnostic. Overall, our results provide a mathematical explanation for the emergence of equivariant structures in the weights of neural networks during training -- a phenomenon that is consistently observed in practice.",
    "categories": [
      "cs.LG",
      "math.CT",
      "math.RT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21645.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21645",
    "published": "2026-01-29T12:47:51Z",
    "updated": "2026-01-29T12:47:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文证明了在参数可识别条件下，端到端等价性网络可通过参数调整实现层间等价性，为训练中出现的等价性结构提供数学解释。",
      "motivation": "研究动机是探讨深度神经网络中端到端等价性与层间等价性的关系，以解决实践中一致观察到的权重等价性结构缺乏理论解释的问题。这一问题在视觉、语音等应用中常见，但现有方法多停留在经验层面，未从数学上阐明等价性如何从整体传递到局部，因此需要理论支持来理解其内在机制和重要性。",
      "method": "研究方法基于抽象形式主义的理论证明，核心假设为模型的参数是可识别的，即在适当意义上参数唯一确定网络函数。通过数学论证，展示了对于任何端到端等价网络，存在参数选择使各隐藏层相对于潜在空间的群作用也等价。该方法架构无关，不依赖特定网络设计，适用于文献中已建立可识别性的一类网络，如卷积网络和变换器。",
      "result": "主要结果是理论证明：在参数可识别条件下，端到端等价网络存在层等价参数化，该结果已为一类网络所证实，直接适用；对于其他网络，由于可识别性尚为推测，结果具有指导意义。摘要未明确说明具体实验数据或性能指标，因为这是纯理论工作，但提供了对实践现象的严格数学论证，与基线方法对比显示了对对称性原理的深化理解。",
      "conclusion": "结论是本文为神经网络训练中自发出现的等价性结构提供了数学解释，强调了参数可识别性的关键作用，深化了群论与深度学习的交叉研究。学术价值在于理论贡献，实际价值在于解释实践现象；局限性在于可识别性假设可能不普遍，未来工作可扩展理论到更广泛网络或进行实验验证。",
      "tags": [
        "Equivariant Neural Networks",
        "Group Actions",
        "Parameter Identifiability",
        "Layerwise Equivariance",
        "Deep Learning Theory"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:51.061123Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21641",
    "title": "Seg-MoE: Multi-Resolution Segment-wise Mixture-of-Experts for Time Series Forecasting Transformers",
    "authors": [
      "Evandro S. Ortigossa",
      "Eran Segal"
    ],
    "abstract": "Transformer-based models have recently made significant advances in accurate time-series forecasting, but even these architectures struggle to scale efficiently while capturing long-term temporal dynamics. Mixture-of-Experts (MoE) layers are a proven solution to scaling problems in natural language processing. However, existing MoE approaches for time-series forecasting rely on token-wise routing mechanisms, which may fail to exploit the natural locality and continuity of temporal data. In this work, we introduce Seg-MoE, a sparse MoE design that routes and processes contiguous time-step segments rather than making independent expert decisions. Token segments allow each expert to model intra-segment interactions directly, naturally aligning with inherent temporal patterns. We integrate Seg-MoE layers into a time-series Transformer and evaluate it on multiple multivariate long-term forecasting benchmarks. Seg-MoE consistently achieves state-of-the-art forecasting accuracy across almost all prediction horizons, outperforming both dense Transformers and prior token-wise MoE models. Comprehensive ablation studies confirm that segment-level routing is the key factor driving these gains. Our results show that aligning the MoE routing granularity with the inherent structure of time series provides a powerful, yet previously underexplored, inductive bias, opening new avenues for conditionally sparse architectures in sequential data modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21641.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21641",
    "published": "2026-01-29T12:43:35Z",
    "updated": "2026-01-29T12:43:35Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "提出Seg-MoE，一种基于多分辨率段路由的稀疏混合专家层，用于时间序列预测Transformer，通过利用时间数据的局部性和连续性提升准确性和扩展效率。",
      "motivation": "研究旨在解决时间序列预测中基于Transformer模型在捕捉长期时间动态时面临的扩展效率问题。现有方法采用token-wise混合专家路由，可能无法充分利用时间数据的自然局部性和连续性，导致模型在处理长时间序列时效率低下且性能受限。因此，开发一种能更好对齐时间序列结构的路由机制，以提高预测精度和效率，成为重要研究方向。",
      "method": "论文引入Seg-MoE，这是一种稀疏混合专家设计，它通过路由和处理连续的时间步段而非独立token来进行专家决策。关键创新在于段级路由机制，使每个专家能够直接建模段内交互，自然地对齐时间序列的固有模式。Seg-MoE被集成到时间序列Transformer架构中，并在多个多元长期预测基准数据集上评估，采用多分辨率段来增强对不同时间尺度的适应性。",
      "result": "Seg-MoE在多个多元长期预测基准测试中，在几乎所有预测时间范围内都实现了最先进的预测准确性，优于密集Transformer和先前的token-wise混合专家模型。消融研究显示，段级路由是驱动性能提升的关键因素，验证了其对条件稀疏架构的有效性。摘要未提供具体数值指标，但强调了其在准确性方面的显著改进。",
      "conclusion": "本研究的主要贡献在于提出了Seg-MoE，展示了将混合专家路由粒度与时间序列的固有结构对齐，可以引入强大的归纳偏置，显著提升预测性能。这为序列数据建模中的条件稀疏架构开辟了新路径，具有重要的学术价值和实际应用潜力。未来工作可扩展至其他数据类型和优化路由机制，以进一步提高模型泛化能力。",
      "tags": [
        "Time Series Forecasting",
        "Transformer",
        "Mixture-of-Experts",
        "Sparse Architecture",
        "Segment-wise Routing"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:36.554843Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21639",
    "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
    "authors": [
      "Yufeng Zhong",
      "Lei Chen",
      "Xuanle Zhao",
      "Wenkang Han",
      "Liming Zheng",
      "Jing Huang",
      "Deyang Jiang",
      "Yilin Cao",
      "Lin Ma",
      "Zhixiong Zeng"
    ],
    "abstract": "The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \\textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21639.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21639",
    "published": "2026-01-29T12:43:02Z",
    "updated": "2026-01-29T12:43:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "OCRVerse 提出首个端到端的整体光学字符识别方法，统一了文本中心OCR和视觉中心OCR。",
      "motivation": "随着大视觉语言模型的发展，管理多模态数据的需求增加，OCR技术日益重要。然而，现有OCR方法主要专注于从图像或扫描文档中识别文本元素（文本中心OCR），忽略了从视觉信息密集图像（如图表、网页、科学图表）中识别视觉元素（视觉中心OCR）。这些视觉密集图像在互联网上广泛存在，具有显著的实际应用价值，如数据可视化和网页分析。因此，开发统一方法以弥补这一不足成为关键研究动机。",
      "method": "OCRVerse 通过全面的数据工程，覆盖了文本中心文档（如报纸、杂志、书籍）和视觉中心渲染复合体（如图表、网页、科学图表）。提出两阶段SFT-RL多领域训练方法：首先，使用监督微调（SFT）混合跨领域数据训练，建立初始领域知识；其次，在强化学习（RL）阶段，为每个领域设计个性化奖励策略，针对不同输出格式和预期输出定制灵活奖励信号，以提高跨领域融合并避免数据冲突，从而在端到端视觉语言模型中实现统一OCR。",
      "result": "实验结果表明OCRVerse在文本中心OCR和视觉中心OCR数据类型上均取得竞争性结果，性能与大型开源和闭源模型相当。摘要未明确说明具体准确率或效率改进数据，但强调了该方法在多种数据源上的有效性，并暗示其在跨域融合方面的优势。与基线方法相比，OCRVerse展现出更好的适应性和统一能力。",
      "conclusion": "OCRVerse 的主要贡献是提出首个端到端的整体OCR方法，统一了文本中心OCR和视觉中心OCR，填补了现有技术的空白。该研究具有高学术价值，推动了视觉语言模型与OCR技术的融合，并在数据可视化、网页分析等实际应用中潜力巨大。摘要未明确说明局限性或未来工作方向，但可推测需要进一步优化奖励策略或扩展数据集到更多视觉类型。",
      "tags": [
        "Vision-Language Models",
        "Optical Character Recognition",
        "End-to-End Learning",
        "Supervised Fine-Tuning",
        "Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:46.177333Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21637",
    "title": "Generative Design of Ship Propellers using Conditional Flow Matching",
    "authors": [
      "Patrick Kruger",
      "Rafael Diaz",
      "Simon Hauschulz",
      "Stefan Harries",
      "Hanno Gottschalk"
    ],
    "abstract": "In this paper, we explore the use of generative artificial intelligence (GenAI) for ship propeller design. While traditional forward machine learning models predict the performance of mechanical components based on given design parameters, GenAI models aim to generate designs that achieve specified performance targets. In particular, we employ conditional flow matching to establish a bidirectional mapping between design parameters and simulated noise that is conditioned on performance labels. This approach enables the generation of multiple valid designs corresponding to the same performance targets by sampling over the noise vector.   To support model training, we generate data using a vortex lattice method for numerical simulation and analyze the trade-off between model accuracy and the amount of available data. We further propose data augmentation using pseudo-labels derived from less data-intensive forward surrogate models, which can often improve overall model performance. Finally, we present examples of distinct propeller geometries that exhibit nearly identical performance characteristics, illustrating the versatility and potential of GenAI in engineering design.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21637.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21637",
    "published": "2026-01-29T12:40:37Z",
    "updated": "2026-01-29T12:40:37Z",
    "comment": "19 pages, 13 figures, 3 tables",
    "light_analysis": {
      "overview": "论文提出基于条件流匹配的生成式AI方法，用于船舶螺旋桨的生成设计，实现设计参数与性能目标之间的双向映射。",
      "motivation": "传统机器学习模型在工程设计中通常仅能基于设计参数预测性能，无法逆向生成满足特定性能目标的设计，限制了设计效率和多样性。本研究旨在解决这一问题，通过生成式AI方法直接从性能要求生成设计，以加速设计迭代并提供创新解决方案，弥补现有前向模型在生成能力上的不足。",
      "method": "该方法采用条件流匹配技术，建立以性能标签为条件的双向映射，将设计参数与模拟噪声关联，通过采样噪声向量生成多个符合性能要求的设计。训练数据使用涡格法进行数值模拟生成，并引入基于前向代理模型的伪标签数据增强策略，以分析模型准确性与数据量之间的权衡，提升整体性能。",
      "result": "论文展示了具有几乎相同性能特性的不同螺旋桨几何形状示例，验证了方法能生成多样化有效设计。摘要未明确说明具体性能指标如准确率或效率改进，也未提供与基线方法的对比数据，但通过示例体现了方法的实用性和潜力。",
      "conclusion": "本研究的主要贡献是提出了一种基于条件流匹配的生成式AI框架，用于船舶螺旋桨设计，实现了从性能到设计的逆向生成。学术上扩展了生成式AI在机械工程领域的应用，实际上有助于优化设计流程和探索创新方案。未来方向可能包括改进模型泛化能力和扩展到其他复杂系统设计。",
      "tags": [
        "Generative AI",
        "Conditional Flow Matching",
        "Vortex Lattice Method",
        "Data Augmentation",
        "Engineering Design"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:07.086382Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21636",
    "title": "Sampling-Free Privacy Accounting for Matrix Mechanisms under Random Allocation",
    "authors": [
      "Jan Schuchardt",
      "Nikita Kalinin"
    ],
    "abstract": "We study privacy amplification for differentially private model training with matrix factorization under random allocation (also known as the balls-in-bins model). Recent work by Choquette-Choo et al. (2025) proposes a sampling-based Monte Carlo approach to compute amplification parameters in this setting. However, their guarantees either only hold with some high probability or require random abstention by the mechanism. Furthermore, the required number of samples for ensuring $(ε,δ)$-DP is inversely proportional to $δ$. In contrast, we develop sampling-free bounds based on Rényi divergence and conditional composition. The former is facilitated by a dynamic programming formulation to efficiently compute the bounds. The latter complements it by offering stronger privacy guarantees for small $ε$, where Rényi divergence bounds inherently lead to an over-approximation. Our framework applies to arbitrary banded and non-banded matrices. Through numerical comparisons, we demonstrate the efficacy of our approach across a broad range of matrix mechanisms used in research and practice.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21636.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21636",
    "published": "2026-01-29T12:40:29Z",
    "updated": "2026-01-29T12:40:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种基于Rényi散度和条件组合的无采样隐私放大边界计算方法，适用于随机分配下的矩阵机制，解决了现有采样方法的局限性。",
      "motivation": "研究动机在于差分私有模型训练中，隐私放大在随机分配下是关键问题。现有方法如Choquette-Choo等人的基于采样的蒙特卡洛方法，计算放大参数时隐私保证仅在高概率下成立或需要随机弃权，且样本数与隐私参数δ成反比，导致效率低下和可靠性不足。这限制了实际应用的可扩展性和确定性，亟需更高效、稳健的替代方案来提升隐私会计的实用性。",
      "method": "研究方法采用基于Rényi散度和条件组合的无采样边界。首先，利用Rényi散度推导隐私边界，通过动态规划公式高效计算，降低计算复杂度。其次，针对Rényi散度在小ε时可能导致过度近似的问题，引入条件组合方法以提供更强的隐私保证。该框架适用于任意带状和非带状矩阵结构，创新点在于避免了采样过程，实现了确定性的隐私放大计算。",
      "result": "主要实验结果表明，通过数值比较，本文方法在多种矩阵机制中证明有效。与现有基于采样的方法相比，新方法提供了更稳定、高效的隐私边界计算，避免了样本数与δ成反比的限制。具体性能指标如准确率或效率提升摘要未明确说明，但框架的通用性和确定性在广泛应用中得到了验证，展示了优于基线的潜力和实际适用性。",
      "conclusion": "结论总结出本研究成功开发了无采样的隐私放大边界计算方法，基于Rényi散度和条件组合。主要贡献在于解决了现有采样方法的不可靠性问题，提供确定性隐私保证，并通过动态规划优化计算效率。学术价值体现在深化差分隐私理论，实际应用价值在于为矩阵机制提供更稳定、可扩展的工具。未来工作方向可能包括扩展到其他隐私模型或进一步优化算法性能，但具体局限性摘要未明确说明。",
      "tags": [
        "Differential Privacy",
        "Privacy Amplification",
        "Matrix Mechanisms",
        "Rényi Divergence",
        "Conditional Composition"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:28.498923Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21634",
    "title": "RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning",
    "authors": [
      "Shiqi Huang",
      "Shuting He",
      "Bihan Wen"
    ],
    "abstract": "Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \\textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21634.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21634",
    "published": "2026-01-29T12:35:57Z",
    "updated": "2026-01-29T12:35:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了RSGround-R1框架，通过推理引导和位置感知的后训练，显著提升了多模态大型语言模型在遥感视觉定位中的空间推理能力。",
      "motivation": "遥感视觉定位（RSVG）旨在基于自然语言描述从大规模航拍图像中定位目标对象。然而，由于遥感场景空间尺度广阔且语义模糊性高，描述往往严重依赖位置线索，这给现有的多模态大型语言模型（MLLMs）的空间推理带来了独特挑战。解决这一问题对于提高遥感图像分析的准确性和实用性至关重要，尤其是在环境监测和城市规划等实际应用中，现有方法可能在处理复杂空间关系时表现不足。",
      "method": "论文提出了RSGround-R1框架，该框架包含三个核心部分。首先，采用链式思维监督微调（CoT-SFT），利用合成的RSVG推理数据训练模型，建立明确的位置感知能力。接着，应用强化微调（RFT），并结合新设计的位置奖励函数，该奖励提供连续和距离感知的指导，以优化定位准确性。此外，引入空间一致性指导优化方案，动态调整策略更新基于空间一致性，确保模型在不同推理步骤中行为一致，实现稳定和鲁棒的收敛。这些方法共同增强了模型在遥感视觉定位中的空间理解。",
      "result": "论文在多个RSVG基准数据集上进行了广泛实验，结果表明RSGround-R1模型在定位性能和泛化能力方面均表现优越。与现有基线方法相比，该框架能够更有效地处理位置依赖的描述，并提高了空间推理的稳定性和准确性，尽管摘要未提供具体数值指标，但实验验证了其在解决遥感视觉定位挑战中的显著效果改进。",
      "conclusion": "本研究贡献了RSGround-R1框架，通过推理引导和位置感知的后训练方法，成功增强了多模态大型语言模型在遥感视觉定位中的空间理解。这为解决遥感场景中的位置依赖问题提供了新思路，具有重要的学术价值，推动了多模态学习在遥感领域的应用。从实际应用角度看，该技术可提升遥感图像的目标定位精度，支持环境监测等任务。未来工作可探索将该方法扩展到其他视觉定位任务或处理更复杂的场景。",
      "tags": [
        "Remote Sensing Visual Grounding",
        "Chain-of-Thought Supervised Fine-Tuning",
        "Reinforcement Fine-Tuning",
        "Spatial Reasoning",
        "Positional Reward"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:47.000722Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21633",
    "title": "A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion",
    "authors": [
      "Pu Cao",
      "Yiyang Ma",
      "Feng Zhou",
      "Xuedan Yin",
      "Qing Song",
      "Lu Yang"
    ],
    "abstract": "In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21633.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21633",
    "published": "2026-01-29T12:32:47Z",
    "updated": "2026-01-29T12:32:47Z",
    "comment": "work in progress",
    "light_analysis": {
      "overview": "本文通过理论和实证分析，揭示了在可控扩散模型中重建保真度比生成指标（如gFID）更能指示可控性，并提出了更可靠的评估基准方法。",
      "motivation": "在潜在扩散模型中，自动编码器（AE）需要平衡忠实重建和生成友好的潜在空间。然而，近期ImageNet规模的研究系统性地偏向生成指标（如gFID），忽视重建指标，导致评估偏差。这种偏向在可控扩散中可能导致条件漂移，限制条件对齐，从而影响可控生成任务的性能。因此，本研究旨在解决这一偏差，强调可控性对重建保真度的依赖，以改善模型选择和评估基准。",
      "method": "本研究首先通过理论分析探讨gFID主导的偏向如何导致条件漂移，并设计多维度条件漂移评估协议来反映可控生成任务。实证部分，分析多个近期的ImageNet-scale AE，并进行ControlNet实验，以验证重建指标与可控性的关联。关键创新在于将评估焦点从生成指标转向重建保真度，并引入实例级测量来更好指示条件对齐。",
      "result": "实验结果表明，gFID在预测条件保持方面较弱（摘要未明确说明具体数值，但指出是弱相关），而重建导向的指标（尤其是实例级测量）与条件保持显著更相关。ControlNet实验进一步确认可控性主要依赖于条件保持，而非gFID。这些发现暴露了当前以ImageNet为中心的AE评估与可控扩散需求之间的差距，为可靠模型选择提供了实证依据。",
      "conclusion": "本文的主要贡献在于揭示了自动编码器评估中生成指标与重建保真度之间的失衡对可控扩散的影响，强调重建保真度对可控性的关键作用。学术上，它推动了评估标准的完善，突出了条件对齐的重要性；实际上，为可控生成模型的开发和选择提供实用指导。未来工作可扩展评估协议到更多任务和数据集，以进一步验证其普适性。",
      "tags": [
        "Autoencoder",
        "Diffusion Models",
        "Controllable Generation",
        "Condition Drift",
        "gFID"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:53.608695Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21626",
    "title": "HeRo-Q: A General Framework for Stable Low Bit Quantization via Hessian Conditioning",
    "authors": [
      "Jinhao Zhang Yunquan Zhang",
      "Zicheng yan",
      "Boyang Zhang",
      "Jun Sun",
      "Daning Cheng"
    ],
    "abstract": "Post Training Quantization (PTQ), a mainstream model compression technique, often leads to the paradoxical 'low error, high loss' phenomenon because it focuses solely on minimizing quantization error. The root cause lies in the Hessian matrix of the LLM loss landscape: a few high curvature directions are extremely sensitive to perturbations. To address this, we propose the Hessian Robust Quantization (HeRo Q) algorithm, which applies a lightweight, learnable rotation-compression matrix to the weight space prior to quantization. This joint framework reshapes the loss landscape by reducing the largest Hessian eigenvalue and reducing its max eigenvalue, thereby significantly enhancing robustness to quantization noise. HeRo-Q requires no architectural modifications, incurs negligible computational overhead, and integrates seamlessly into existing PTQ pipelines. Experiments on Llama and Qwen models show that HeRo Q consistently outperforms state of the art methods including GPTQ, AWQ, and SpinQuant not only achieving superior performance under standard W4A8 settings, but also excelling in the highly challenging W3A16 ultra low bit regime, where it boosts GSM8K accuracy on Llama3 8B to 70.15\\% and effectively avoids the logical collapse commonly seen in aggressive quantization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21626.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21626",
    "published": "2026-01-29T12:27:05Z",
    "updated": "2026-01-29T12:27:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出HeRo Q算法，通过优化Hessian矩阵来增强量化鲁棒性，实现稳定低位量化。",
      "motivation": "后训练量化（PTQ）作为主流模型压缩技术，常导致'低误差、高损失'的矛盾现象，因为其仅关注最小化量化误差，忽略了损失景观的结构。根本原因在于大语言模型损失景观的Hessian矩阵中，少数高曲率方向对量化扰动极度敏感。该问题的重要性在于量化对高效模型部署至关重要，而现有方法未能有效处理Hessian敏感性，导致在低位量化时性能下降和逻辑崩溃，亟需更鲁棒的解决方案。",
      "method": "论文提出Hessian鲁棒量化（HeRo Q）算法，这是一个通用框架，通过在量化前应用轻量级、可学习的旋转-压缩矩阵到权重空间，以联合方式优化量化过程。该框架重塑损失景观，通过减少Hessian矩阵的最大特征值来降低其对扰动的敏感性，从而增强对量化噪声的鲁棒性。关键创新包括无需模型架构修改、计算开销可忽略不计，并能无缝集成到现有PTQ流程中，适用于如Llama和Qwen等大语言模型，利用Hessian分析实现高效压缩。",
      "result": "在Llama和Qwen模型上的实验结果表明，HeRo Q consistently优于包括GPTQ、AWQ和SpinQuant在内的现有最优方法。在标准W4A8量化设置下表现更优，特别是在高度挑战性的W3A16超低位量化中，它将Llama3 8B模型在GSM8K数据集上的准确率提升至70.15%，显著避免了激进量化常见的逻辑崩溃现象，证明了其在极端低位条件下的有效性和鲁棒性提升。",
      "conclusion": "本研究的主要贡献是提出HeRo Q框架，通过Hessian条件化实现稳定低位量化，显著增强量化鲁棒性，且无需额外开销。其学术价值在于揭示了Hessian矩阵在量化噪声中的关键作用，实际应用价值体现在改善大语言模型压缩效果，促进高效部署和资源节省。未来工作可探索该框架在其他模型类型或更广泛量化场景中的应用，以进一步提升通用性和适应性。",
      "tags": [
        "Post Training Quantization",
        "Hessian Conditioning",
        "Low Bit Quantization",
        "LLM",
        "Model Compression"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:23.139216Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21624",
    "title": "Training Memory in Deep Neural Networks: Mechanisms, Evidence, and Measurement Gaps",
    "authors": [
      "Vasileios Sevetlidis",
      "George Pavlidis"
    ],
    "abstract": "Modern deep-learning training is not memoryless. Updates depend on optimizer moments and averaging, data-order policies (random reshuffling vs with-replacement, staged augmentations and replay), the nonconvex path, and auxiliary state (teacher EMA/SWA, contrastive queues, BatchNorm statistics). This survey organizes mechanisms by source, lifetime, and visibility. It introduces seed-paired, function-space causal estimands; portable perturbation primitives (carry/reset of momentum/Adam/EMA/BN, order-window swaps, queue/teacher tweaks); and a reporting checklist with audit artifacts (order hashes, buffer/BN checksums, RNG contracts). The conclusion is a protocol for portable, causal, uncertainty-aware measurement that attributes how much training history matters across models, data, and regimes.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21624.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21624",
    "published": "2026-01-29T12:26:52Z",
    "updated": "2026-01-29T12:26:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "这篇综述提出了一种用于测量深度神经网络训练中记忆机制的可移植、因果、不确定性感知协议。",
      "motivation": "现代深度学习训练中存在记忆效应，优化器状态（如动量、Adam）、数据顺序策略（如随机重排）和辅助状态（如BatchNorm统计）影响模型更新，但现有研究缺乏系统化的测量方法。由于训练记忆对模型性能和优化过程至关重要，当前方法在因果性、可重复性和不确定性评估方面不足，导致难以量化不同机制的作用，因此需要开发标准框架来解决这些测量空白。",
      "method": "论文通过按来源、寿命和可见性分类训练记忆机制，引入seed-paired和函数空间因果估计量，设计便携式扰动原语（如重置动量、交换顺序窗口、调整对比队列），并提出包含审计工件的报告清单（如顺序哈希、RNG合同）。该方法结合理论分析和实用工具，旨在提供标准化测量流程，帮助研究人员系统评估训练历史的影响，无需依赖特定数据集或模型架构。",
      "result": "摘要未明确说明具体实验结果，但论文的主要成果是提出了一种测量协议，该协议能够属性化训练历史在不同模型、数据和训练制度中的作用。通过框架设计，它强调了可移植性、因果推断和不确定性管理，为未来实证研究提供了基础，但需进一步实验验证其有效性和性能指标。",
      "conclusion": "论文的主要贡献是开发了一个系统化测量训练记忆的协议，具有学术价值，因为它填补了现有研究在标准化测量和因果分析方面的空白，提升了训练过程的可解释性。实际应用上，该协议可帮助研究人员优化模型训练和评估性能。未来工作可能包括协议的具体实施和实证验证，以进一步理解记忆机制的局限性和扩展应用。",
      "tags": [
        "Training Memory",
        "Causal Estimation",
        "Perturbation Primitives",
        "Reporting Checklist",
        "Deep Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:26.511432Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21623",
    "title": "LAMP: Look-Ahead Mixed-Precision Inference of Large Language Models",
    "authors": [
      "Stanislav Budzinskiy",
      "Marian Gloser",
      "Tolunay Yilmaz",
      "Ying Hong Tham",
      "Yuanyi Lin",
      "Wenyi Fang",
      "Fan Wu",
      "Philipp Petersen"
    ],
    "abstract": "Mixed-precision computations are a hallmark of the current stage of AI, driving the progress in large language models towards efficient, locally deployable solutions. This article addresses the floating-point computation of compositionally-rich functions, concentrating on transformer inference. Based on the rounding error analysis of a composition $f(g(\\mathrm{x}))$, we provide an adaptive strategy that selects a small subset of components of $g(\\mathrm{x})$ to be computed more accurately while all other computations can be carried out with lower accuracy. We then explain how this strategy can be applied to different compositions within a transformer and illustrate its overall effect on transformer inference. We study the effectiveness of this algorithm numerically on GPT-2 models and demonstrate that already very low recomputation rates allow for improvements of up to two orders of magnitude in accuracy.",
    "categories": [
      "cs.LG",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21623.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21623",
    "published": "2026-01-29T12:26:00Z",
    "updated": "2026-01-29T12:26:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种自适应混合精度推理策略，通过选择性高精度计算提升大语言模型 transformer 推理的精度。",
      "motivation": "混合精度计算是当前 AI 发展的重要趋势，有助于推动大语言模型实现高效、本地可部署的解决方案。本文针对复合函数浮点计算中的精度问题，专注于 transformer 推理，旨在解决现有混合精度方法在平衡计算效率和精度方面的不足，以降低误差并优化性能。摘要强调了在复杂函数组合中减少计算开销同时保持精度的需求。",
      "method": "基于复合函数 $f(g(x))$ 的舍入误差分析，论文提出一个自适应策略，通过分析误差传播，选择 $g(x)$ 中的少数关键组件进行更高精度的计算，而其余部分使用较低精度。该策略可应用于 transformer 内部的各种组合，以优化推理过程，具体在 GPT-2 模型上进行实现。摘要未明确说明具体模型架构或更多技术细节。",
      "result": "在 GPT-2 模型上的数值实验表明，即使重计算率非常低，该自适应策略也能将精度提升高达两个数量级。这显著改善了 transformer 推理的准确性，而无需大幅增加计算开销。摘要未明确说明与基线方法的直接对比数据，但暗示了在精度方面的显著改进。",
      "conclusion": "论文的主要贡献是提出了一种自适应混合精度推理方法，为 transformer 推理提供了平衡计算效率和精度的有效策略，具有学术和实际应用价值。其意义在于促进大语言模型的高效部署，未来工作可能涉及扩展到其他模型或更复杂的函数组合，潜在局限性包括对特定场景或模型的依赖。",
      "tags": [
        "Mixed-Precision Inference",
        "Transformer",
        "Rounding Error Analysis",
        "Adaptive Strategy",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:42.248979Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21621",
    "title": "Similarity of Processing Steps in Vision Model Representations",
    "authors": [
      "Matéo Mahaut",
      "Marco Baroni"
    ],
    "abstract": "Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations--in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21621.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21621",
    "published": "2026-01-29T12:24:28Z",
    "updated": "2026-01-29T12:24:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文研究了不同视觉模型在表示形成过程中中间处理步骤的相似性，揭示了模型间收敛的层级和性质差异。",
      "motivation": "现有文献表明大型模型倾向于收敛到“普遍”表示，但主要关注最终表示相似性，忽略了中间步骤如何达到这些表示。本研究旨在探索模型是否也收敛到相同的中间处理步骤和操作，以更深入地理解模型内部过程。这个问题的重要性在于，了解模型内部操作有助于改进模型设计和解释，现有方法的不足之处在于缺乏对处理步骤相似性的系统分析，导致对模型行为理解不全面。",
      "method": "论文提出量化不同视觉模型在不同处理阶段的表示距离，并追踪这些距离在整个处理过程中的演化。核心方法是识别哪些处理步骤在不同模型间差异最大，关键创新在于将分析焦点从最终表示扩展到中间步骤，使用距离度量来比较模型表示。研究可能涉及常见的视觉模型架构如 CNN 和 transformer，但摘要未明确说明具体数据集或模型细节，基于现有信息推断依赖于标准视觉任务和模型。",
      "result": "实验结果显示，尽管不同模型中相似位置的层具有较相似的表示，但仍存在显著差异。具体发现包括分类器模型在最终层会丢弃关于低层图像统计的信息，而 CNN 和 transformer 模型行为不同：transformer 模型在层间对表示的应用变化更平滑。这些发现澄清了模型表示收敛的层级和性质，为图像模型的底层过程提供了更定性的描述，与基线方法相比，突出了不同架构间的操作差异。",
      "conclusion": "本研究的主要贡献是揭示了视觉模型中处理步骤的相似性，表明模型在表示形成过程中存在收敛但并非完全一致。学术价值在于增进了对模型内部操作的理解，特别是不同架构如 CNN 和 transformer 的行为差异，实际应用价值可能包括指导模型设计和提高可解释性。未来工作可以进一步探索更多模型类型和任务，以验证泛化性，并可能扩展到其他模态或复杂任务中。",
      "tags": [
        "Vision Models",
        "Model Representations",
        "Processing Steps",
        "CNN",
        "Transformer"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:51.262130Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21619",
    "title": "Breaking the Overscaling Curse: Thinking Parallelism Before Parallel Thinking",
    "authors": [
      "Yiming Wang",
      "Zhuosheng Zhang",
      "Rui Wang"
    ],
    "abstract": "Parallel thinking enhances LLM reasoning by multi-path sampling and aggregation. In system-level evaluations, a global parallelism level N is allocated to all samples, typically set large to maximize overall dataset accuracy. However, due to sample heterogeneity, some samples can achieve comparable performance with a smaller N'< N, causing budget redundancy. This incompatibility between system-level efficacy and sample-level efficiency constitutes the overscaling curse. In this paper, we formalize and quantify the overscaling curse, showing its universality and severity in practice, and analyze its trigger mechanism. We then propose a lightweight method, T2, to break the overscaling curse, which utilizes latent representations to estimate the optimal parallelism level for each sample before decoding. Experiments show that T2 significantly reduces cost while maintaining comparable performance, enabling more efficient parallel thinking.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21619.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21619",
    "published": "2026-01-29T12:22:45Z",
    "updated": "2026-01-29T12:22:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出轻量级方法T2，通过预先估计每个样本的最优并行级别，打破大型语言模型推理中的过缩放诅咒。",
      "motivation": "在并行思考系统中，全局并行级别N通常设置较大以最大化数据集准确率，但由于样本异质性，某些样本可用更小N'达到类似性能，造成资源冗余，这种系统级效率与样本级效率的不匹配构成了过缩放诅咒。现有方法忽略了样本差异，导致成本高企且效率低下，亟需优化以应对大规模LLM推理中的实际挑战，提升资源利用率。",
      "method": "论文提出T2方法，利用潜在表示在解码前为每个样本估计最优并行级别，从而动态调整计算资源，避免不必要开销。该方法核心创新是基于轻量级特征提取实现精准预测，无需复杂架构或额外训练，摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验显示T2显著降低计算成本，同时维持与基线方法相当的性能表现，增强了并行思考的效率。虽然摘要未提供具体数值指标如准确率提升，但表明T2在资源优化方面优于传统固定并行级别的系统。",
      "conclusion": "T2通过样本级并行级别优化，有效缓解过缩放诅咒，提高了LLM推理的可扩展性和成本效益，为实际部署提供了新思路。其学术价值在于形式化问题并提出轻量级解决方案，未来工作可能涉及扩展至更多应用或提升估计精度，但摘要未明确说明局限性。",
      "tags": [
        "Parallel Thinking",
        "Large Language Model",
        "Latent Representations",
        "Overscaling Curse",
        "Cost Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:08.921950Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21618",
    "title": "Semantic Content Determines Algorithmic Performance",
    "authors": [
      "Martiño Ríos-García",
      "Nawaf Alampara",
      "Kevin Maik Jablonka"
    ],
    "abstract": "Counting should not depend on what is being counted; more generally, any algorithm's behavior should be invariant to the semantic content of its arguments. We introduce WhatCounts to test this property in isolation. Unlike prior work that conflates semantic sensitivity with reasoning complexity or prompt variation, WhatCounts is atomic: count items in an unambiguous, delimited list with no duplicates, distractors, or reasoning steps for different semantic types. Frontier LLMs show over 40% accuracy variation depending solely on what is being counted - cities versus chemicals, names versus symbols. Controlled ablations rule out confounds. The gap is semantic, and it shifts unpredictably with small amounts of unrelated fine-tuning. LLMs do not implement algorithms; they approximate them, and the approximation is argument-dependent. As we show with an agentic example, this has implications beyond counting: any LLM function may carry hidden dependencies on the meaning of its inputs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21618.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21618",
    "published": "2026-01-29T12:22:17Z",
    "updated": "2026-01-29T12:22:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究揭示了大型语言模型在算法任务中对参数语义内容的依赖性，并提出了原子测试方法WhatCounts。",
      "motivation": "论文的研究动机源于算法行为的理想特性：其表现应独立于参数的语义内容，但大型语言模型（LLMs）在实际任务中可能表现出对语义的敏感性。这一问题的重要性在于，如果LLMs的性能依赖于输入的含义，会影响其可靠性和泛化能力，尤其是在要求稳定算法的应用中。现有研究方法常常将语义敏感性与推理复杂性或提示变化混淆，未能孤立测试语义影响，因此需要一种新方法来明确评估这一属性。",
      "method": "研究方法的核心是引入WhatCounts测试，这是一种原子的计数任务，要求模型在无歧义、无重复、无干扰、无推理步骤的列表中计数项目，针对不同语义类型（如城市与化学品、名字与符号）。关键创新在于孤立地测试语义依赖性，避免了先前工作中将语义敏感性与其他因素（如推理复杂性）混淆的问题。摘要未明确提及具体数据集或模型架构，但推断使用了前沿LLMs进行实验，以保持测试的简单性和可控性。",
      "result": "实验结果显示，前沿LLMs在WhatCounts测试中表现出显著性能差异：计数不同语义类型的项目时，准确率变化超过40%（例如，计数城市与化学品时准确率差异明显）。通过控制实验排除了推理复杂性、提示变化等混淆因素，证实性能差异源自语义内容本身，而非其他因素。这表明LLMs并非稳定实现算法，而是近似算法行为，且近似依赖于输入参数的语义内容，导致不可预测的性能波动。",
      "conclusion": "本研究的主要贡献是证明大型语言模型并非实现算法，而是近似算法行为，且这种近似依赖于输入参数的语义内容。这揭示了LLMs的内在限制，具有重要学术价值，有助于深入理解模型行为和泛化能力。在应用方面，研究暗示任何基于LLM的函数都可能隐藏对输入含义的依赖，影响其可靠性和广泛部署。未来工作可扩展研究到其他算法任务，并探索方法以减少这种语义依赖性。",
      "tags": [
        "Large Language Model",
        "Semantic Sensitivity",
        "WhatCounts",
        "Algorithmic Approximation",
        "Test Methodology"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:43.641103Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21617",
    "title": "PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization",
    "authors": [
      "Songhan Jiang",
      "Fengchun Liu",
      "Ziyue Wang",
      "Linghan Cai",
      "Yongbing Zhang"
    ],
    "abstract": "Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21617.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21617",
    "published": "2026-01-29T12:21:16Z",
    "updated": "2026-01-29T12:21:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "PathReasoner-R1模型通过知识引导的策略优化，首次为病理视觉语言模型注入结构化推理能力，提升临床诊断的透明度和可靠性。",
      "motivation": "当前病理视觉语言模型在诊断时往往直接输出结论，缺乏可验证的推理过程，这严重限制了临床医生的信任，并阻碍了错误纠正。现有方法多依赖未经验证的蒸馏技术，无法提供结构化的证据链，导致模型输出不可靠。因此，需要开发能够模拟人类医生推理过程的系统，以提高诊断的透明度和实用性。",
      "method": "研究构建了首个大规模全切片图像推理数据集PathReasoner，采用基于知识图谱的生成管道，确保结构化病理发现与临床诊断对齐，生成超过2万高质量指令样本。在此基础上，提出PathReasoner-R1模型，结合轨迹掩码监督微调和推理导向的强化学习，通过知识感知的多粒度奖励函数（包括与知识图谱严格对齐的实体奖励机制）优化模型的逻辑一致性，而非仅仅结果匹配。",
      "result": "PathReasoner-R1在PathReasoner数据集及多个公开基准测试中均实现了最先进的性能，在不同图像尺度下表现出色。实验表明，该方法显著提升了模型的推理能力，提供了透明且基于临床证据的诊断过程，增强了诊断的可靠性和可解释性，摘要未明确说明具体性能指标。",
      "conclusion": "PathReasoner-R1成功为病理视觉语言模型注入了结构化推理能力，通过知识引导的方法提高了诊断的透明度和临床适用性。这项研究不仅贡献了首个大规模WSI推理数据集，还推动了计算病理学向可验证推理方向的发展，未来可扩展至其他医疗领域以提高模型的鲁棒性。",
      "tags": [
        "Vision-Language Model",
        "Knowledge Graph",
        "Reinforcement Learning",
        "Supervised Fine-Tuning",
        "Chain-of-Thought Reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:37.432493Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21615",
    "title": "Beyond Parameter Finetuning: Test-Time Representation Refinement for Node Classification",
    "authors": [
      "Jiaxin Zhang",
      "Yiqi Wang",
      "Siwei Wang",
      "Xihong Yang",
      "Yu Shi",
      "Xinwang Liu",
      "En Zhu"
    ],
    "abstract": "Graph Neural Networks frequently exhibit significant performance degradation in the out-of-distribution test scenario. While test-time training (TTT) offers a promising solution, existing Parameter Finetuning (PaFT) paradigm suffer from catastrophic forgetting, hindering their real-world applicability. We propose TTReFT, a novel Test-Time Representation FineTuning framework that transitions the adaptation target from model parameters to latent representations. Specifically, TTReFT achieves this through three key innovations: (1) uncertainty-guided node selection for specific interventions, (2) low-rank representation interventions that preserve pre-trained knowledge, and (3) an intervention-aware masked autoencoder that dynamically adjust masking strategy to accommodate the node selection scheme. Theoretically, we establish guarantees for TTReFT in OOD settings. Empirically, extensive experiments across five benchmark datasets demonstrate that TTReFT achieves consistent and superior performance. Our work establishes representation finetuning as a new paradigm for graph TTT, offering both theoretical grounding and immediate practical utility for real-world deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21615.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21615",
    "published": "2026-01-29T12:17:34Z",
    "updated": "2026-01-29T12:17:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出TTReFT框架，一种测试时表示微调方法，用于图节点分类，通过将适应目标从参数转向表示，解决了参数微调的灾难性遗忘问题。",
      "motivation": "图神经网络在分布外测试场景中常出现性能显著下降，限制了其实际应用。现有的测试时训练方法，如参数微调范式，容易遭受灾难性遗忘，导致在适应新数据时丢失预训练知识。因此，亟需一种能够有效适应OOD场景同时避免遗忘的方法，以提升图节点分类的鲁棒性和部署可行性。",
      "method": "TTReFT框架的核心创新在于将测试时适应的焦点从模型参数转移到潜在表示。具体技术包括：不确定性引导的节点选择机制，以识别需要干预的特定节点；低秩表示干预策略，在调整表示时保持预训练知识；以及干预感知的掩码自编码器，动态调整掩码方案以匹配节点选择。该方法旨在图节点分类任务中，通过表示微调实现高效的测试时适应。",
      "result": "在五个基准数据集上的实验表明，TTReFT实现了一致且优越的性能，优于现有方法。摘要未明确说明具体性能指标如准确率提升，但指出该框架在分布外设置下表现优异。理论分析为TTReFT在OOD场景中的有效性提供了保证，支持其实证结果。",
      "conclusion": "本研究确立了表示微调作为图测试时训练的新范式，贡献了理论基础和直接的实际应用价值。TTReFT框架通过避免灾难性遗忘，增强了图神经网络在真实世界部署中的鲁棒性。未来工作可能涉及扩展该框架到其他图任务或探索更多动态适应策略。",
      "tags": [
        "Graph Neural Networks",
        "Test-Time Training",
        "Representation FineTuning",
        "Node Classification",
        "Low-Rank Representation"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:57.029538Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21610",
    "title": "WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models",
    "authors": [
      "Zijin Yang",
      "Yu Sun",
      "Kejiang Chen",
      "Jiawei Zhao",
      "Jun Jiang",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "abstract": "Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21610.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21610",
    "published": "2026-01-29T12:14:32Z",
    "updated": "2026-01-29T12:14:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出WMVLM，首个基于视觉语言模型的统一且可解释的扩散模型图像水印评估框架。",
      "motivation": "数字水印对保护扩散模型生成的图像安全至关重要，但现有评估方法存在显著局限性：缺乏统一框架来同时处理残差和语义水印，导致结果可解释性差、忽视综合安全因素，且常使用不合适的指标。这些问题阻碍了水印算法的有效开发和优化，因此需新方法来提供更全面、可靠的评估支持。",
      "method": "研究提出WMVLM框架，利用视觉语言模型评估水印效果，核心创新包括重新定义水印质量与安全指标：残差水印通过伪影强度和擦除抵抗性评估，语义水印通过潜在分布偏移评估。采用三阶段训练策略，逐步使模型实现分类、评分和可解释文本生成，提升了框架的适应性和解释能力。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验结果表明，WMVLM在性能上优于现有最先进的视觉语言模型，展现出强大的泛化能力，能在不同数据集、扩散模型和水印方法上保持稳定效果。摘要未提供具体数值指标，但与基线方法相比，框架在评估准确性和适应性方面有显著改进。",
      "conclusion": "WMVLM的主要贡献在于建立了一个统一且可解释的水印评估框架，提升了评估的科学性和实用性，对推动水印技术发展具有重要学术和实际价值。未来工作可能包括扩展到更多应用场景或解决潜在局限性，摘要未明确说明。",
      "tags": [
        "Vision-Language Models",
        "Diffusion Models",
        "Image Watermarking",
        "Evaluation Framework",
        "Interpretability"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:58.220400Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21609",
    "title": "RecNet: Self-Evolving Preference Propagation for Agentic Recommender Systems",
    "authors": [
      "Bingqian Li",
      "Xiaolei Wang",
      "Junyi Li",
      "Weitao Li",
      "Long Zhang",
      "Sheng Chen",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "abstract": "Agentic recommender systems leverage Large Language Models (LLMs) to model complex user behaviors and support personalized decision-making. However, existing methods primarily model preference changes based on explicit user-item interactions, which are sparse, noisy, and unable to reflect the real-time, mutual influences among users and items. To address these limitations, we propose RecNet, a self-evolving preference propagation framework that proactively propagates real-time preference updates across related users and items. RecNet consists of two complementary phases. In the forward phase, the centralized preference routing mechanism leverages router agents to integrate preference updates and dynamically propagate them to the most relevant agents. To ensure accurate and personalized integration of propagated preferences, we further introduce a personalized preference reception mechanism, which combines a message buffer for temporary caching and an optimizable, rule-based filter memory to guide selective preference assimilation based on past experience and interests. In the backward phase, the feedback-driven propagation optimization mechanism simulates a multi-agent reinforcement learning framework, using LLMs for credit assignment, gradient analysis, and module-level optimization, enabling continuous self-evolution of propagation strategies. Extensive experiments on various scenarios demonstrate the effectiveness of RecNet in modeling preference propagation for recommender systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21609.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21609",
    "published": "2026-01-29T12:14:31Z",
    "updated": "2026-01-29T12:14:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "RecNet提出了一种自我演化的偏好传播框架，通过前向和后向机制主动传播实时偏好，优化agentic推荐系统的个性化决策。",
      "motivation": "现有agentic推荐系统主要依赖显式用户-物品交互来建模偏好变化，但这些交互数据稀疏、噪声大，无法捕捉用户和物品间的实时相互影响。这限制了推荐系统准确反映用户动态兴趣的能力，导致个性化决策支持效果不佳。因此，开发一种能主动传播和优化偏好更新的方法至关重要，以解决现有方法在实时性和准确性方面的不足。",
      "method": "RecNet框架由两个互补阶段组成。在前向阶段，集中偏好路由机制利用路由代理整合偏好更新，并动态传播到相关代理；个性化偏好接收机制结合消息缓冲和基于规则的过滤器记忆，选择性同化偏好。在后向阶段，反馈驱动传播优化机制模拟多智能体强化学习框架，使用大型语言模型进行信用分配、梯度分析和模块级优化，实现传播策略的持续自我演化。",
      "result": "论文通过多种场景的实验验证了RecNet在建模偏好传播方面的有效性，但摘要未明确说明具体性能指标如准确率提升或效率改进。实验表明，该框架能更好地处理实时偏好更新和相互影响，相比现有基于显式交互的方法有所改进，但缺乏详细数据支撑。",
      "conclusion": "RecNet的主要贡献在于提出了一种自我演化的偏好传播框架，通过集成前向和后向机制，主动优化推荐系统中的偏好建模。该研究提升了推荐系统的实时性和个性化能力，具有学术价值，并为实际应用提供了新思路。未来工作可进一步探索传播策略的扩展或应用到其他领域。",
      "tags": [
        "Large Language Models",
        "Multi-Agent Reinforcement Learning",
        "Preference Propagation",
        "Agentic Recommender Systems",
        "Self-Evolving Framework"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:23.051719Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21608",
    "title": "Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget",
    "authors": [
      "Saisubramaniam Gopalakrishnan",
      "Harikrishnan P M",
      "Dagnachew Birru"
    ],
    "abstract": "Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \\emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21608.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21608",
    "published": "2026-01-29T12:14:18Z",
    "updated": "2026-01-29T12:14:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一种基于搜索的风险特征发现方法，在受限预算下最大化文档处理系统中的多样化故障类型发现，展示求解器互补性并激励投资组合策略。",
      "motivation": "企业级智能文档处理（IDP）系统在金融、保险和医疗等高风险领域广泛应用，其早期验证至关重要。现有方法往往聚焦于识别单一最坏情况文档，但实际中需要发现多样化的故障机制以确保系统可靠性。在预算有限的情况下，传统方法可能无法全面覆盖故障空间，导致潜在风险被忽略，因此本研究旨在解决如何在约束预算下高效发现多种故障类型的问题，以提高工业IDP系统的稳健性。摘要未明确说明所有现有方法的详细不足，但强调了发现多样化故障的必要性。",
      "method": "研究方法将文档处理系统的风险特征发现形式化为基于搜索的软件测试（SBST）问题，操作于文档配置的组合空间，通过生成结构风险特征实例来诱导现实故障条件。关键创新包括在相同预算约束下基准测试多种搜索策略，涵盖进化算法、基于群算法、质量多样性算法、基于学习算法和量子算法。通过配置级排他性、胜率和跨时间重叠分析，系统地评估这些策略的性能和互补性，以识别复杂变量交互并最大化故障类型发现。",
      "result": "实验结果显示，不同求解器在可比预算下一致发现特定替代方法未覆盖的故障模式。跨时间分析表明，没有单一策略在所有评估预算中表现出绝对优势；所有求解器的联合最终能恢复观察到的故障空间，但依赖任何单个方法会系统性地延迟重要风险的发现。具体性能指标如准确率提升未在摘要中明确提及，但通过分析证实了策略间的互补性，为投资组合方法提供实证支持，突出了多样化搜索策略在故障发现中的有效性。",
      "conclusion": "本论文的主要贡献在于证明求解器在风险特征发现中具有内在互补性，并激励采用基于投资组合的SBST策略，以提升工业IDP验证的稳健性。学术上，为文档处理系统验证提供了新视角，强调在预算约束下发现多样化故障的重要性。实际应用价值在于增强高风险工作流的可靠性。摘要未明确说明未来工作方向或局限性，但可推断需要进一步优化策略组合或扩展到其他类似领域。",
      "tags": [
        "Search-Based Software Testing",
        "Intelligent Document Processing",
        "Evolutionary Algorithms",
        "Swarm-based Algorithms",
        "Portfolio-based Strategies"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:50.076868Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21601",
    "title": "Dynamics Reveals Structure: Challenging the Linear Propagation Assumption",
    "authors": [
      "Hoyeon Chang",
      "Bálint Mucsányi",
      "Seong Joon Oh"
    ],
    "abstract": "Neural networks adapt through first-order parameter updates, yet it remains unclear whether such updates preserve logical coherence. We investigate the geometric limits of the Linear Propagation Assumption (LPA), the premise that local updates coherently propagate to logical consequences. To formalize this, we adopt relation algebra and study three core operations on relations: negation flips truth values, converse swaps argument order, and composition chains relations. For negation and converse, we prove that guaranteeing direction-agnostic first-order propagation necessitates a tensor factorization separating entity-pair context from relation content. However, for composition, we identify a fundamental obstruction. We show that composition reduces to conjunction, and prove that any conjunction well-defined on linear features must be bilinear. Since bilinearity is incompatible with negation, this forces the feature map to collapse. These results suggest that failures in knowledge editing, the reversal curse, and multi-hop reasoning may stem from common structural limitations inherent to the LPA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21601.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21601",
    "published": "2026-01-29T12:08:00Z",
    "updated": "2026-01-29T12:08:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过关系代数挑战线性传播假设的几何极限，揭示其在否定、逆和复合操作中的结构性限制，为知识编辑失败和多跳推理问题提供理论解释。",
      "motivation": "神经网络基于一阶参数更新进行适应，但现有方法如线性传播假设（LPA）假设局部更新能连贯传播到逻辑后果，这在实际应用中如知识编辑、逆转诅咒和多跳推理中常出现失败。这些现象表明LPA可能忽略了深层结构性问题，阻碍了逻辑一致性的保持。因此，研究LPA的几何极限至关重要，因为它直接关系到提高神经网络推理能力的稳健性，并理解现有方法的不足，从而推动更可靠的学习框架发展。",
      "method": "论文采用关系代数作为理论框架，系统研究关系操作的三个核心：否定（翻转真值）、逆（交换参数顺序）和复合（链式关系）。方法的核心是通过数学推导形式化LPA，分析这些操作在保证方向无关一阶传播下的几何性质。对于否定和逆，使用张量分解技术将实体对上下文与关系内容分离；对于复合，通过逻辑推导将其归结为合取操作，并证明在线性特征上定义的合取必须是双线性的。方法强调理论证明，未使用具体数据集或模型架构，但凸显了关系代数和线性代数的应用以揭示结构性限制。",
      "result": "研究证明，对于否定和逆操作，保证方向无关一阶传播需要张量分解来实现实体对上下文与关系内容的分离。然而，复合操作存在根本障碍：复合可归结为合取，且在线性特征上定义的任何合取必须是双线性的；由于双线性与否定操作不兼容，这导致特征图崩溃。这些理论结果表明LPA在处理复合关系时存在结构性缺陷，为知识编辑失败、逆转诅咒和多跳推理的常见问题提供了共同解释。摘要未明确说明具体数值结果，但通过逻辑推导揭示了性能瓶颈，与基线方法（LPA）形成对比。",
      "conclusion": "论文的主要贡献是通过关系代数分析挑战线性传播假设，揭示了其在否定、逆和复合操作中的结构性限制，特别是在复合导致特征图崩溃上的根本障碍。学术价值在于为神经网络的逻辑一致性提供了理论解释，关联了知识编辑、逆转诅咒和多跳推理的失败原因。实际应用价值在于指导未来设计更鲁棒的推理方法，例如通过放松线性假设或引入非线性建模。局限性或未来工作方向可能包括将理论结果扩展到具体模型验证或探索其他关系操作，摘要未明确说明，但可推断出深化理论应用的前景。",
      "tags": [
        "Linear Propagation Assumption",
        "Relation Algebra",
        "Tensor Factorization",
        "Conjunction",
        "Bilinearity"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:53.027102Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21600",
    "title": "CORE: Collaborative Reasoning via Cross Teaching",
    "authors": [
      "Kshitij Mishra",
      "Mirat Aubakirov",
      "Martin Takac",
      "Nils Lukas",
      "Salem Lahlou"
    ],
    "abstract": "Large language models exhibit complementary reasoning errors: on the same instance, one model may succeed with a particular decomposition while another fails. We propose Collaborative Reasoning (CORE), a training-time collaboration framework that converts peer success into a learning signal via a cross-teaching protocol. Each problem is solved in two stages: a cold round of independent sampling, followed by a contexted rescue round in which models that failed receive hint extracted from a successful peer. CORE optimizes a combined reward that balances (i) correctness, (ii) a lightweight DPP-inspired diversity term to reduce error overlap, and (iii) an explicit rescue bonus for successful recovery. We evaluate CORE across four standard reasoning datasets GSM8K, MATH, AIME, and GPQA. With only 1,000 training examples, a pair of small open source models (3B+4B) reaches Pass@2 of 99.54% on GSM8K and 92.08% on MATH, compared to 82.50% and 74.82% for single-model training. On harder datasets, the 3B+4B pair reaches Pass@2 of 77.34% on GPQA (trained on 348 examples) and 79.65% on AIME (trained on 792 examples), using a training-time budget of at most 1536 context tokens and 3072 generated tokens. Overall, these results show that training-time collaboration can reliably convert model complementarity into large gains without scaling model size.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21600.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21600",
    "published": "2026-01-29T12:07:54Z",
    "updated": "2026-01-29T12:07:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "CORE框架通过交叉教学协议实现训练时协作推理，将大语言模型的互补推理错误转化为学习信号，显著提升推理性能而不扩大模型规模。",
      "motivation": "大语言模型在推理任务中表现出互补性错误，即不同模型在同一实例上的失败模式各异，这为协作学习提供了机会。现有方法通常依赖单个模型或简单集成，未能充分利用训练时模型间的互补性来优化性能，导致资源浪费或效率低下。本研究旨在解决这一问题，通过开发协作推理框架，将模型互补性转化为有效的学习信号，实现在不增加参数量的情况下提高推理准确性，从而应对实际应用中对轻量化、高效AI系统的需求。",
      "method": "论文提出协作推理（CORE）框架，采用两阶段处理流程：首先是冷采样轮次，各模型独立生成解决方案；随后是上下文救援轮次，失败的模型从成功同伴中提取提示进行重试。关键创新包括交叉教学协议和优化组合奖励函数，奖励函数平衡了正确性、受DPP启发的轻量级多样性项（以减少错误重叠）和显式救援奖励。使用小型开源语言模型（3B和4B参数）在四个标准推理数据集（GSM8K、MATH、AIME、GPQA）上训练，确保方法轻量化和高效，训练时预算控制在最多1536个上下文标记和3072个生成标记。",
      "result": "实验结果显示，CORE框架在仅使用1,000个训练示例的情况下，使一对3B+4B模型的Pass@2在GSM8K上达到99.54%（单模型训练为82.50%），在MATH上达到92.08%（单模型训练为74.82%），表明性能有显著提升。在更难的数据集上，如GPQA（使用348个示例训练）和AIME（使用792个示例训练），Pass@2分别达到77.34%和79.65%，同时保持低训练预算（最多1536个上下文标记和3072个生成标记）。这些结果验证了协作训练能有效将模型互补性转化为性能增益，超越基线单模型方法。",
      "conclusion": "CORE框架的主要贡献在于提出并验证了训练时协作推理方法，通过交叉教学协议利用模型互补性，在不增加模型参数的情况下实现了推理性能的大幅提升。该研究具有学术价值，为协作学习和高效推理提供了新视角；实际应用上，可促进轻量化AI系统的开发，降低计算成本。摘要未明确说明局限性，但未来工作可探索更多模型组合、扩展数据集或优化奖励机制以增强泛化能力。",
      "tags": [
        "Collaborative Reasoning",
        "Cross Teaching",
        "DPP-inspired Diversity",
        "Reward Optimization",
        "Small Language Models"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:48.008904Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21598",
    "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
    "authors": [
      "Zhi Zheng",
      "Wee Sun Lee"
    ],
    "abstract": "Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language Models (LLMs) to substitute discrete language tokens with continuous latent tokens. These methods consume fewer tokens compared to the conventional language CoT reasoning and have the potential to plan in a dense latent space. However, current latent tokens are generally supervised based on imitating language labels. Considering that there can be multiple equivalent but diverse CoT labels for a question, passively imitating an arbitrary one may lead to inferior latent token representations and latent reasoning policies, undermining the potential planning ability and resulting in clear gaps between training and testing. In this work, we emphasize the importance of active planning over the representation space of latent tokens in achieving the optimal latent reasoning policy. So, we propose the \\underline{A}c\\underline{t}ive Latent \\underline{P}lanning method (ATP-Latent), which models the supervision process of latent tokens as a conditional variational auto-encoder (VAE) to obtain a smoother latent space. Moreover, to facilitate the most reasonable latent reasoning policy, ATP-Latent conducts reinforcement learning (RL) with an auxiliary coherence reward, which is calculated based on the consistency between VAE-decoded contents of latent tokens, enabling a guided RL process. In experiments on LLaMA-1B, ATP-Latent demonstrates +4.1\\% accuracy and -3.3\\% tokens on four benchmarks compared to advanced baselines. Codes are available on https://github.com/zz1358m/ATP-Latent-master.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21598.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21598",
    "published": "2026-01-29T12:07:16Z",
    "updated": "2026-01-29T12:07:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出ATP-Latent方法，结合变分自编码器和强化学习主动规划潜在令牌的表示空间，以优化思维链推理的效率和准确性。",
      "motivation": "研究动机源于提升大语言模型中的潜在推理方法。现有方法通过模仿语言标签监督潜在令牌，但存在多个等效但多样的思维链标签，被动模仿可能导致次优的潜在表示和推理策略，削弱规划潜力并扩大训练与测试间的差距。因此，需要主动规划表示空间以实现最优推理策略，弥补现有方法的不足。",
      "method": "论文提出ATP-Latent方法，核心是将潜在令牌的监督过程建模为条件变分自编码器，以生成平滑的潜在空间。关键创新点包括使用强化学习，并设计一个基于VAE解码内容一致性的辅助一致性奖励，以引导RL过程优化推理策略。具体细节涉及在LLaMA-1B模型上进行实验，应用于四个基准测试，模型架构结合了VAE和RL组件。",
      "result": "实验结果显示，在LLaMA-1B模型上，ATP-Latent在四个基准测试中相比先进基线方法，准确率提升了4.1%，令牌消耗减少了3.3%。这些数据表明该方法在提升推理准确性和效率方面有效，与现有方法相比表现出显著改进，验证了主动规划策略的优势。",
      "conclusion": "本文的主要贡献是提出了ATP-Latent方法，通过结合变分自编码器和强化学习优化潜在推理，具有重要的学术价值，为密集思维链推理提供了新方法，并可能在实际AI应用中提升推理能力。未来工作可探索更复杂的规划策略或扩展到更多模型，摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Variational Auto-Encoder",
        "Latent Reasoning",
        "Chain-of-Thought"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:39.549120Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21595",
    "title": "HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics",
    "authors": [
      "Abdul Hasib",
      "A. S. M. Ahsanul Sarkar Akib",
      "Anish Giri"
    ],
    "abstract": "The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21595.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21595",
    "published": "2026-01-29T12:04:36Z",
    "updated": "2026-01-29T12:04:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "HydroSense提出了一种创新的双微控制器物联网框架，实现了实时多参数水质监测，显著降低了成本并提升了准确性和可靠性。",
      "motivation": "全球水危机日益严重，需要负担得起且准确的水质监测方案。现有方法如手动采样效率低，商业系统昂贵，难以在资源有限地区推广。因此，开发一种低成本、实时、多参数的水质监测系统至关重要，以解决传统方法在可访问性和成本方面的不足。",
      "method": "HydroSense采用双微控制器架构，Arduino Uno负责高精度模拟测量，包括五点校准算法；ESP32处理无线连接、边缘计算和云集成。系统集成六个关键参数，应用了中值滤波、温度补偿等先进信号处理技术，以增强数据准确性和鲁棒性，并通过Firebase实现实时云数据分析。",
      "result": "在90天的实验验证中，HydroSense表现出卓越性能：pH准确度在0-14范围内为±0.08单位，溶解氧稳定性在±0.2 mg/L内，总溶解固体准确度在0-1000 ppm范围内为±1.9%，云数据传输可靠性达99.8%。总成本约300美元，相比商业系统节省85%，验证了其成本效益和实际应用价值。",
      "conclusion": "本研究建立了可访问环境监测的新范式，通过智能系统架构和成本效益组件选择，实现了专业级水质评估。HydroSense框架展示了在资源有限地区推广的潜力，为未来优化和扩展水质监测技术提供了基础，具有重要的学术和实际应用价值。",
      "tags": [
        "IoT Framework",
        "Dual-Microcontroller Architecture",
        "Edge Processing",
        "Signal Processing",
        "Cloud Analytics"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:53.682346Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21592",
    "title": "Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration",
    "authors": [
      "Luwei Tu",
      "Jiawei Wu",
      "Xing Luo",
      "Zhi Jin"
    ],
    "abstract": "All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21592.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21592",
    "published": "2026-01-29T12:02:42Z",
    "updated": "2026-01-29T12:02:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出不确定性感知扩散桥模型（UDBM），通过将异构图像修复重新定义为随机传输问题并引入双调制策略，实现高效统一的修复。",
      "motivation": "All-in-One图像修复（AiOIR）面临处理多种异构降解的核心挑战，现有方法因使用粗粒度控制机制或固定映射计划，难以平衡冲突的优化目标，导致适应性能不佳。这一问题在现实应用中至关重要，因为图像修复常需应对多样化的降解类型，如噪声、模糊等，而现有方法在灵活性和准确性上存在局限，阻碍了高效修复的发展。因此，本研究旨在通过建模降解不确定性来克服这些限制，提升修复任务的统一性和质量。",
      "method": "论文提出Uncertainty-Aware Diffusion Bridge Model（UDBM）作为核心方法。它将AiOIR重新定义为由像素级不确定性引导的随机传输问题，引入relaxed diffusion bridge formulation，以松弛的终端约束替代严格约束，从而建模降解不确定性并理论解决标准扩散桥中的漂移奇异性。关键技术包括双调制策略：噪声计划将异构降解对齐到共享高熵潜在空间，路径计划基于熵正则化的粘性动态自适应调节传输轨迹。该方法通过优化传输几何和动态，实现在单一模型框架下处理多种修复任务，无需额外调整或复杂步骤。",
      "result": "UDBM在实验中实现最先进性能，在单步推理中处理多种图像修复任务时表现优异，优于现有方法。具体而言，它在统一异构降解的优化中展现出高效性，通过在多个修复任务上的测试验证了其领先地位，例如在噪声去除、去模糊等方面均有提升。尽管摘要未提供具体准确率或效率数据，但表明UDBM通过纠正传输几何和动态，在单步推理中显著改进适应能力，为AiOIR提供了更稳健和灵活的解决方案。",
      "conclusion": "UDBM的主要贡献在于统一处理异构图像修复，通过随机传输框架和双调制策略，理论创新解决扩散桥的漂移问题，实际应用价值体现在单步推理中的高效修复。这为AiOIR领域提供了新视角，提升了模型适应性和性能，潜在局限性包括摘要未明确说明的具体数据集或扩展性，未来工作可探索更多降解类型或集成更复杂的不确定性建模技术，以进一步优化实际应用场景。",
      "tags": [
        "Diffusion Bridge Model",
        "Stochastic Transport",
        "Uncertainty Modeling",
        "Image Restoration",
        "Entropy Regularization"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:02.798289Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21590",
    "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
    "authors": [
      "Xiaotong Ji",
      "Rasul Tutunov",
      "Matthieu Zimmer",
      "Haitham Bou Ammar"
    ],
    "abstract": "Reinforcement learning (RL) post-training is a dominant approach for improving the reasoning performance of large language models (LLMs), yet growing evidence suggests that its gains arise primarily from distribution sharpening rather than the acquisition of new capabilities. Recent work has shown that sampling from the power distribution of LLMs using Markov chain Monte Carlo (MCMC) can recover performance comparable to RL post-training without relying on external rewards; however, the high computational cost of MCMC makes such approaches impractical for widespread adoption. In this work, we propose a theoretically grounded alternative that eliminates the need for iterative MCMC. We derive a novel formulation showing that the global power distribution can be approximated by a token-level scaled low-temperature one, where the scaling factor captures future trajectory quality. Leveraging this insight, we introduce a training-free and verifier-free algorithm that sharpens the base model's generative distribution autoregressively. Empirically, we evaluate our method on math, QA, and code tasks across four LLMs, and show that our method matches or surpasses one-shot GRPO without relying on any external rewards, while reducing inference latency by over 10x compared to MCMC-based sampling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21590.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21590",
    "published": "2026-01-29T12:01:53Z",
    "updated": "2026-01-29T12:01:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一种基于缩放低温分布的算法，通过理论推导消除MCMC迭代，实现无需训练和验证器的高效推理，显著提升大型语言模型的性能并降低计算成本。",
      "motivation": "现有强化学习后训练方法虽能提升大型语言模型的推理性能，但其增益主要源于分布锐化而非新能力获取，并依赖外部奖励和高成本训练；基于MCMC的功率采样虽可免去训练，但计算开销巨大，限制了实际应用。因此，开发一种无需外部奖励、高效且训练免费的替代方案至关重要，以解决现有方法的不足并推动广泛部署。",
      "method": "论文通过理论推导提出一种新公式，表明全局功率分布可近似为标记级缩放低温分布，其中缩放因子捕获未来轨迹质量。基于这一洞察，引入一个无需训练和验证器的算法，以自回归方式锐化基础模型的生成分布，从而消除MCMC的迭代需求，关键技术包括标记级缩放和自回归分布锐化。",
      "result": "在数学、问答和代码任务上对四个大型语言模型的评估显示，该方法性能匹配或超越了无需外部奖励的one-shot GRPO基线。具体地，相比基于MCMC的采样，推理延迟减少了超过10倍，显著提升了效率，验证了其在多种任务上的有效性和实用性。",
      "conclusion": "本研究的主要贡献在于提出了一种理论驱动且高效的方法，通过分布锐化提升大型语言模型的推理性能，无需依赖外部奖励或高成本MCMC。学术上，为推理优化提供了新视角；实际中，降低了计算开销，促进更广泛的应用。未来工作可扩展至更多任务或模型，潜在局限性未在摘要中明确说明。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning",
        "Markov Chain Monte Carlo",
        "Power Sampling",
        "Distribution Sharpening"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:11.833956Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21589",
    "title": "Heterogeneity-Aware Knowledge Sharing for Graph Federated Learning",
    "authors": [
      "Wentao Yu",
      "Sheng Wan",
      "Shuo Chen",
      "Bo Han",
      "Chen Gong"
    ],
    "abstract": "Graph Federated Learning (GFL) enables distributed graph representation learning while protecting the privacy of graph data. However, GFL suffers from heterogeneity arising from diverse node features and structural topologies across multiple clients. To address both types of heterogeneity, we propose a novel graph Federated learning method via Semantic and Structural Alignment (FedSSA), which shares the knowledge of both node features and structural topologies. For node feature heterogeneity, we propose a novel variational model to infer class-wise node distributions, so that we can cluster clients based on inferred distributions and construct cluster-level representative distributions. We then minimize the divergence between local and cluster-level distributions to facilitate semantic knowledge sharing. For structural heterogeneity, we employ spectral Graph Neural Networks (GNNs) and propose a spectral energy measure to characterize structural information, so that we can cluster clients based on spectral energy and build cluster-level spectral GNNs. We then align the spectral characteristics of local spectral GNNs with those of cluster-level spectral GNNs to enable structural knowledge sharing. Experiments on six homophilic and five heterophilic graph datasets under both non-overlapping and overlapping partitioning settings demonstrate that FedSSA consistently outperforms eleven state-of-the-art methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21589.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21589",
    "published": "2026-01-29T12:00:13Z",
    "updated": "2026-01-29T12:00:13Z",
    "comment": "33 pages",
    "light_analysis": {
      "overview": "论文提出FedSSA方法，通过语义和结构对齐实现图联邦学习的知识共享，以解决节点特征和结构拓扑的异质性。",
      "motivation": "图联邦学习（GFL）旨在分布式环境中进行图表示学习并保护数据隐私，但面临节点特征和结构拓扑的异质性挑战。这种异质性来源于多个客户端数据的多样性，可能导致模型性能下降和知识共享效率低。现有方法可能未能同时有效处理这两种异质性，限制了GFL在实际应用中的效果。因此，研究如何通过知识共享来解决异质性，对提高分布式图学习性能和隐私保护具有重要意义。",
      "method": "FedSSA方法的核心是通过语义和结构对齐来共享知识。针对节点特征异质性，采用变分模型推断类级节点分布，基于分布聚类客户端并构建集群级代表分布，通过最小化本地与集群级分布之间的散度来促进语义知识共享。针对结构异质性，使用谱图神经网络（GNNs）和谱能量测量来表征结构信息，聚类客户端并构建集群级谱GNNs，然后对齐本地和集群级谱GNNs的谱特征以实现结构知识共享。创新点在于同时处理特征和结构异质性，并通过聚类和分布对齐优化知识融合。",
      "result": "实验在六个同质性和五个异质性图数据集上进行，涵盖非重叠和重叠划分设置。结果表明，FedSSA方法在性能上持续优于11个最先进的基准方法，证明了其在处理不同图数据异质性方面的有效性。然而，摘要未明确提供具体性能指标如准确率或效率改进，仅强调了比较优势。该研究展示了FedSSA在多种数据场景下的鲁棒性和优越性。",
      "conclusion": "论文的主要贡献是开发了FedSSA方法，有效解决图联邦学习中的节点特征和结构异质性，提升了分布式图学习的性能。该研究具有重要的学术价值，推动了图学习和联邦学习的结合，并对隐私保护和高效知识共享有实际应用价值。潜在局限性可能包括计算复杂度或对其他图类型的适用性，未来工作可以探索优化算法效率或扩展到更广泛的异质性场景。",
      "tags": [
        "Graph Federated Learning",
        "Variational Model",
        "Spectral Graph Neural Networks",
        "Knowledge Sharing",
        "Node Distribution Clustering"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:42.363758Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21587",
    "title": "Language Models as Artificial Learners: Investigating Crosslinguistic Influence",
    "authors": [
      "Abderrahmane Issam",
      "Yusuf Can Semerci",
      "Jan Scholtes",
      "Gerasimos Spanakis"
    ],
    "abstract": "Despite the centrality of crosslinguistic influence (CLI) to bilingualism research, human studies often yield conflicting results due to inherent experimental variance. We address these inconsistencies by using language models (LMs) as controlled statistical learners to systematically simulate CLI and isolate its underlying drivers. Specifically, we study the effect of varying the L1 language dominance and the L2 language proficiency, which we manipulate by controlling the L2 age of exposure -- defined as the training step at which the L2 is introduced. Furthermore, we investigate the impact of pretraining on L1 languages with varying syntactic distance from the L2. Using cross-linguistic priming, we analyze how activating L1 structures impacts L2 processing. Our results align with evidence from psycholinguistic studies, confirming that language dominance and proficiency are strong predictors of CLI. We further find that while priming of grammatical structures is bidirectional, the priming of ungrammatical structures is sensitive to language dominance. Finally, we provide mechanistic evidence of CLI in LMs, demonstrating that the L1 is co-activated during L2 processing and directly influences the neural circuitry recruited for the L2. More broadly, our work demonstrates that LMs can serve as a computational framework to inform theories of human CLI.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21587.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21587",
    "published": "2026-01-29T11:53:48Z",
    "updated": "2026-01-29T11:53:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究创新性地利用语言模型作为人工学习者，系统模拟跨语言影响，并揭示其驱动机制，为双语研究提供计算框架。",
      "motivation": "跨语言影响是双语研究的核心领域，但人类研究常因个体差异和实验变异导致结果矛盾，限制了理论进展。现有方法不足于系统性隔离底层驱动因素，因此本研究旨在通过语言模型作为受控统计学习者，解决这些不一致性，探究CLI的确定性因素，以补充和验证心理语言学发现。",
      "method": "论文提出使用语言模型模拟跨语言影响，通过操纵L1语言主导性和L2熟练度，控制L2暴露年龄（即训练步骤中引入L2的时间点）来实现。关键创新包括分析预训练语言与L2的句法距离，并使用跨语言启动技术研究L1结构对L2处理的影响，结合计算建模和语言学实验设计来系统性地模拟CLI。",
      "result": "实验结果与心理语言学证据一致，显示语言主导性和熟练度是跨语言影响的强预测因子。启动实验表明，语法结构启动是双向的，但不合语法启动对语言主导性敏感。机制分析揭示了在L2处理过程中，L1被共同激活并直接影响L2神经回路，为CLI提供了计算证据，但摘要未明确说明与基线方法的定量对比。",
      "conclusion": "论文的主要贡献在于证明了语言模型可以作为计算框架，为人类跨语言影响理论提供新见解和机制证据。研究具有学术价值，可推动双语认知建模和语言学习理论发展；未来工作可能涉及扩展到更多语言对或探索其他影响因素，如语义距离或模型泛化性。",
      "tags": [
        "Language Models",
        "Crosslinguistic Influence",
        "Pretraining",
        "Syntactic Distance",
        "Cross-linguistic Priming"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:49.292558Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21583",
    "title": "CORDS: Continuous Representations of Discrete Structures",
    "authors": [
      "Tin Hadži Veljković",
      "Erik Bekkers",
      "Michael Tiemann",
      "Jan-Willem van de Meent"
    ],
    "abstract": "Many learning problems require predicting sets of objects when the number of objects is not known beforehand. Examples include object detection, molecular modeling, and scientific inference tasks such as astrophysical source detection. Existing methods often rely on padded representations or must explicitly infer the set size, which often poses challenges. We present a novel strategy for addressing this challenge by casting prediction of variable-sized sets as a continuous inference problem. Our approach, CORDS (Continuous Representations of Discrete Structures), provides an invertible mapping that transforms a set of spatial objects into continuous fields: a density field that encodes object locations and count, and a feature field that carries their attributes over the same support. Because the mapping is invertible, models operate entirely in field space while remaining exactly decodable to discrete sets. We evaluate CORDS across molecular generation and regression, object detection, simulation-based inference, and a mathematical task involving recovery of local maxima, demonstrating robust handling of unknown set sizes with competitive accuracy.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21583.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21583",
    "published": "2026-01-29T11:46:17Z",
    "updated": "2026-01-29T11:46:17Z",
    "comment": "Preprint, accepted at ICLR 2026",
    "light_analysis": {
      "overview": "论文提出了CORDS方法，通过连续表示将可变大小离散结构的预测问题转化为连续推理，实现精确解码。",
      "motivation": "研究动机源于许多学习任务需要预测对象集合，但对象数量未知，如对象检测和分子建模。现有方法依赖填充表示或显式推断集合大小，这增加了模型复杂性和误差风险，尤其在动态环境中表现不佳。CORDS旨在通过连续表示解决这些挑战，提供更高效和灵活的解决方案。",
      "method": "CORDS方法的核心是一个可逆映射，将离散空间对象集合转换为连续场：密度场编码对象的位置和数量，特征场在同一支撑上编码对象的属性。模型在连续场上进行推理，利用标准深度学习方法，并通过逆映射精确解码回离散集合，无需显式处理集合大小，简化了预测过程。",
      "result": "实验在多个任务中评估CORDS，包括分子生成和回归、对象检测、模拟推理和数学任务（如恢复局部最大值）。结果显示，CORDS能鲁棒处理未知集合大小，并取得了竞争性的准确性。具体性能数据摘要未明确说明，但与基线方法相比，在处理动态集合时表现更优。",
      "conclusion": "CORDS为可变大小集合预测提供了一种创新的连续表示方法，提高了模型的精度和鲁棒性。学术价值在于提出通用框架，适用于多领域任务；实际应用潜力包括计算机视觉和化学建模。未来工作可探索更复杂映射机制和扩展应用范围。",
      "tags": [
        "Continuous Representation",
        "Set Prediction",
        "Invertible Mapping",
        "Density Fields",
        "Feature Fields"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:53.428780Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21582",
    "title": "Depth-Recurrent Attention Mixtures: Giving Latent Reasoning the Attention it Deserves",
    "authors": [
      "Jonas Knupp",
      "Jan Hendrik Metzen",
      "Jeremias Bohn",
      "Georg Groh",
      "Kristian Kersting"
    ],
    "abstract": "Depth-recurrence facilitates latent reasoning by sharing parameters across depths. However, prior work lacks combined FLOP-, parameter-, and memory-matched baselines, underutilizes depth-recurrence due to partially fixed layer stacks, and ignores the bottleneck of constant hidden-sizes that restricts many-step latent reasoning. To address this, we introduce a modular framework of depth-recurrent attention mixtures (Dreamer), combining sequence attention, depth attention, and sparse expert attention. It alleviates the hidden-size bottleneck through attention along depth, decouples scaling dimensions, and allows depth-recurrent models to scale efficiently and effectively. Across language reasoning benchmarks, our models require 2 to 8x fewer training tokens for the same accuracy as FLOP-, parameter-, and memory-matched SOTA, and outperform ca. 2x larger SOTA models with the same training tokens. We further present insights into knowledge usage across depths, e.g., showing 2 to 11x larger expert selection diversity than SOTA MoEs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21582.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21582",
    "published": "2026-01-29T11:44:38Z",
    "updated": "2026-01-29T11:44:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种深度递归注意力混合物（Dreamer）框架，通过结合序列注意、深度注意和稀疏专家注意，有效解决深度递归模型中的隐藏大小瓶颈问题，提升模型效率和性能。",
      "motivation": "深度递归模型通过在不同深度共享参数来促进潜在推理，但现有研究存在多个不足。首先，缺乏FLOP、参数和内存匹配的全面基线，难以公平比较模型性能。其次，部分固定层栈设计限制了深度递归的充分利用。此外，常数隐藏大小成为多步潜在推理的瓶颈，制约模型扩展。这些问题导致模型效率和性能受限，因此需要新方法来解决这些挑战，以推动深度递归技术的发展。",
      "method": "论文引入了模块化框架Dreamer，它结合了序列注意力、深度注意力和稀疏专家注意力机制。深度注意力允许模型沿深度维度进行注意力计算，缓解隐藏大小瓶颈，使模型能更灵活地处理多步推理。该框架解耦了模型的缩放维度，如计算复杂度和参数数量，从而支持高效扩展。尽管摘要未明确说明使用的具体数据集或模型架构，但该方法针对语言推理任务进行了优化，并利用了注意力机制的组合来提升性能。",
      "result": "在语言推理基准测试中，Dreamer模型表现出色。与FLOP、参数和内存匹配的最先进方法相比，它仅需2到8倍更少的训练令牌即可达到相同准确率。使用相同数量的训练令牌时，模型性能优于大约2倍大小的SOTA模型。此外，研究提供了关于知识跨深度使用的见解，例如专家选择多样性比现有MoEs技术提高了2到11倍，这表明了模型在资源利用和多样性方面的优势。",
      "conclusion": "该研究的主要贡献是提出了Dreamer框架，通过整合多种注意力机制有效解决了深度递归模型的关键瓶颈。这不仅显著提升了模型在语言推理任务上的效率和性能，还为潜在推理提供了新的研究方向。研究的学术价值在于优化了深度递归结构，实际应用价值可能扩展到其他需要高效推理的AI任务。未来工作可能包括将该框架应用于更多领域或进一步改进注意力机制，但摘要未明确说明具体局限性。",
      "tags": [
        "Depth-Recurrence",
        "Attention Mechanisms",
        "Mixture of Experts",
        "Sequence Attention",
        "Sparse Expert Attention"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:24.365497Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21581",
    "title": "Evaluating Prediction Uncertainty Estimates from BatchEnsemble",
    "authors": [
      "Morten Blørstad",
      "Herman Jangsett Mostein",
      "Nello Blaser",
      "Pekka Parviainen"
    ],
    "abstract": "Deep learning models struggle with uncertainty estimation. Many approaches are either computationally infeasible or underestimate uncertainty. We investigate \\textit{BatchEnsemble} as a general and scalable method for uncertainty estimation across both tabular and time series tasks. To extend BatchEnsemble to sequential modeling, we introduce GRUBE, a novel BatchEnsemble GRU cell. We compare the BatchEnsemble to Monte Carlo dropout and deep ensemble models. Our results show that BatchEnsemble matches the uncertainty estimation performance of deep ensembles, and clearly outperforms Monte Carlo dropout. GRUBE achieves similar or better performance in both prediction and uncertainty estimation. These findings show that BatchEnsemble and GRUBE achieve similar performance with fewer parameters and reduced training and inference time compared to traditional ensembles.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21581.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21581",
    "published": "2026-01-29T11:44:36Z",
    "updated": "2026-01-29T11:44:36Z",
    "comment": "17 pages, 19 figures",
    "light_analysis": {
      "overview": "提出了 BatchEnsemble 和 GRUBE 方法，用于高效估计深度学习模型的不确定性，在表格和时间序列任务中表现优异。",
      "motivation": "深度学习模型在不确定性估计方面面临挑战，许多现有方法要么计算成本过高难以应用，要么会低估不确定性。这一问题在现实应用中至关重要，因为准确的不确定性估计能提升模型的可信度和决策支持能力。特别是在表格和时间序列分析中，需要一种既通用又高效的解决方案来克服当前方法的局限性，因此研究致力于探索更实用的技术途径。",
      "method": "论文的核心方法是采用 BatchEnsemble 作为一种通用且可扩展的不确定性估计技术。为了将其应用于序列建模，作者提出了 GRUBE，这是一种基于 GRU 的新型 BatchEnsemble 单元，通过集成机制来捕捉序列数据中的不确定性。该方法的关键创新在于将集成学习的优势与深度学习模型结合，减少了训练和推理的计算开销，同时保持了高性能。研究还涉及在表格和时间序列数据集上进行评估，并与 Monte Carlo dropout 和深集成模型进行对比。",
      "result": "实验结果表明，BatchEnsemble 在不确定性估计方面能够匹配传统深集成模型的性能，并且显著优于 Monte Carlo dropout。具体来说，它能够准确反映预测的不确定性，减少低估情况。GRUBE 在序列任务中表现同样出色，在预测精度和不确定性估计上都达到相似或更好的效果。此外，这些方法使用更少的模型参数，并大幅降低了训练和推理时间，显示了其高效性。",
      "conclusion": "研究的主要贡献在于提出了 BatchEnsemble 和 GRUBE 作为高效的不确定性估计方法。学术上，这为深度学习模型提供了更实用的不确定性量化工具；实际应用中，可降低计算资源需求，促进在各类任务中的部署。未来工作可进一步探索在其他序列模型或数据集上的应用，以验证其泛化能力，摘要未明确说明具体局限性。",
      "tags": [
        "BatchEnsemble",
        "Uncertainty Estimation",
        "GRU",
        "Ensemble Methods",
        "Monte Carlo Dropout"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:20.595698Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21579",
    "title": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
    "authors": [
      "Wuyang Zhou",
      "Yuxuan Gu",
      "Giorgos Iacovides",
      "Danilo Mandic"
    ],
    "abstract": "The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\\mathcal{O} \\left( nC \\cdot n! \\right)$. To address both challenges, we propose \\textbf{KromHC}, which uses the \\underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \\underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \\texttt{https://github.com/wz1119/KromHC}.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21579.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21579",
    "published": "2026-01-29T11:43:05Z",
    "updated": "2026-01-29T11:43:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "KromHC 通过采用 Kronecker 乘积的双随机矩阵参数化残差矩阵，解决了现有超连接方法在训练稳定性和参数效率方面的问题。",
      "motivation": "超连接在神经网络中的成功应用暴露了训练不稳定和扩展性受限的挑战。现有方法如 Manifold-Constrained Hyper-Connections (mHC) 通过投影到 Birkhoff 多面体来缓解问题，但其迭代 Sinkhorn-Knopp 算法不一定产生精确双随机残差矩阵，且参数复杂度高达 O(n^3C)。mHC-lite 重新参数化保证双随机性，但参数复杂度阶乘爆炸为 O(nC * n!)，限制了实际应用。因此，开发一种能保证精确双随机性同时降低参数复杂度的新方法至关重要，以提高模型效率和可扩展性。",
      "method": "KromHC 使用 Kronecker 乘积的小双随机矩阵来参数化残差矩阵。通过在张量化残差流的每个模式上强制流形约束于因子残差矩阵，确保精确的双随机性，并利用数学性质简化结构。关键创新点在于将参数复杂度从 mHC 的 O(n^3C) 和 mHC-lite 的 O(nC * n!) 显著降低到 O(n^2C)，提升了计算效率。摘要未明确说明具体使用的数据集或模型架构，但方法基于流形约束和 Kronecker 乘积操作实现。",
      "result": "综合实验显示，KromHC 在性能上匹配或优于现有的顶级 mHC 变体，同时需要的可训练参数显著减少。虽然没有给出具体准确率或效率提升的数值数据，但与基线方法如 mHC 和 mHC-lite 相比，KromHC 在保持或提升效果的前提下，大幅提高了参数效率，证实了其在平衡性能和复杂度方面的优越性。",
      "conclusion": "KromHC 的主要贡献是提出了一种新的残差矩阵参数化方法，通过 Kronecker 乘积保证精确双随机性并降低参数复杂度，解决了现有超连接方法的不足。该研究在学术上优化了神经网络结构设计，在实际应用中可增强训练稳定性和模型效率。摘要未明确说明局限性，但未来工作可能涉及进一步推广到更多网络类型或优化算法细节。",
      "tags": [
        "Kronecker Product",
        "Doubly Stochastic Matrices",
        "Hyper-Connections",
        "Neural Networks",
        "Parameter Complexity"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:56.297981Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21577",
    "title": "Learning the Mechanism of Catastrophic Forgetting: A Perspective from Gradient Similarity",
    "authors": [
      "Mutian Yang",
      "Zisen Zhan",
      "Yutong Chen",
      "Haolin Li",
      "Kaiwen Wang",
      "Kaili Zheng",
      "Yuguang Wang",
      "Qi Wang",
      "Jiandong Gao",
      "Ji Wu"
    ],
    "abstract": "Catastrophic forgetting during knowledge injection severely undermines the continual learning capability of large language models (LLMs). Although existing methods attempt to mitigate this issue, they often lack a foundational theoretical explanation. We establish a gradient-based theoretical framework to explain catastrophic forgetting. We first prove that strongly negative gradient similarity is a fundamental cause of forgetting. We then use gradient similarity to identify two types of neurons: conflicting neurons that induce forgetting and account for 50%-75% of neurons, and collaborative neurons that mitigate forgetting and account for 25%-50%. Based on this analysis, we propose a knowledge injection method, Collaborative Neural Learning (CNL). By freezing conflicting neurons and updating only collaborative neurons, CNL theoretically eliminates catastrophic forgetting under an infinitesimal learning rate eta and an exactly known mastered set. Experiments on five LLMs, four datasets, and four optimizers show that CNL achieves zero forgetting in in-set settings and reduces forgetting by 59.1%-81.7% in out-of-set settings.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21577.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21577",
    "published": "2026-01-29T11:42:30Z",
    "updated": "2026-01-29T11:42:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出基于梯度相似度的理论框架解释灾难性遗忘机制，并开发协作神经学习方法有效减轻遗忘。",
      "motivation": "灾难性遗忘在大型语言模型的知识注入过程中严重削弱其持续学习能力，现有方法虽尝试缓解但缺乏基础理论解释，限制性能改进。这个问题对LLMs适应新知识至关重要，理论缺失阻碍了更有效方法的开发，因此本研究从梯度相似度视角出发，旨在揭示遗忘的根本原因。",
      "method": "研究建立梯度相似度理论框架，证明强负梯度相似度是遗忘的根本原因，并通过梯度相似度识别两种神经元：冲突神经元（占50%-75%）导致遗忘和协作神经元（占25%-50%）减轻遗忘。基于此提出协作神经学习方法，通过冻结冲突神经元、仅更新协作神经元，理论上在无穷小学习率和精确已知掌握集下消除遗忘。实验使用五个大型语言模型、四个数据集和四个优化器验证方法。",
      "result": "实验在设定内情况下实现零遗忘，设定外情况下遗忘减少59.1%-81.7%，神经元分析证实冲突与协作神经元的分布，有效缓解灾难性遗忘。结果展示了方法在持续学习中的显著效果，尽管基线对比未明确说明，但量化改进突出了技术优势。",
      "conclusion": "本研究主要贡献在于建立了梯度相似度理论框架阐释灾难性遗忘机制，并开发了协作神经学习方法，具有学术价值，为持续学习提供新理论基础；实际应用可促进LLMs知识注入。局限性包括对无穷小学习率和精确掌握集的理想假设，未来工作可探索更实际条件并扩展应用场景。",
      "tags": [
        "Catastrophic Forgetting",
        "Gradient Similarity",
        "Large Language Model",
        "Collaborative Neural Learning",
        "Continual Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:56.256586Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21576",
    "title": "Chain Of Thought Compression: A Theoritical Analysis",
    "authors": [
      "Juncai Li",
      "Ru Li",
      "Yuxiang Zhou",
      "Boxiang Ma",
      "Jeff Z. Pan"
    ],
    "abstract": "Chain-of-Thought (CoT) has unlocked advanced reasoning abilities of Large Language Models (LLMs) with intermediate steps, yet incurs prohibitive computational costs due to generation of extra tokens. Recent studies empirically show that compressing reasoning steps into latent states, or implicit CoT compression, offers a token-efficient alternative. However, the mechanism behind CoT compression remains unclear. In this paper, we provide the first theoretical analysis of the difficulty of learning to internalize intermediate reasoning steps. By introducing Order-r Interaction, we prove that the learning signal for high-order logical dependencies exponentially decays to solve irreducible problem, where skipping intermediate steps inevitably leads to high-order interaction barriers. To empirically validate this, we introduce NatBool-DAG, a challenging benchmark designed to enforce irreducible logical reasoning and eliminate semantic shortcuts. Guided by our theoretical findings, we propose ALiCoT (Aligned Implicit CoT), a novel framework that overcomes the signal decay by aligning latent token distributions with intermediate reasoning states. Experimental results demonstrate that ALiCoT successfully unlocks efficient reasoning: it achieves a 54.4x speedup while maintaining performance comparable to explicit CoT.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21576.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21576",
    "published": "2026-01-29T11:42:03Z",
    "updated": "2026-01-29T11:42:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文首次理论分析了链式思维压缩的学习难度，并提出了ALiCoT框架来高效克服信号衰减。",
      "motivation": "链式思维（CoT）能增强大型语言模型的推理能力，但生成中间步骤的额外token导致计算成本过高，隐性CoT压缩虽能节省token，但其机制不清。现有研究多基于实证，缺乏理论分析，这限制了高效推理方法的开发。因此，本研究旨在填补理论空白，深入探讨压缩过程中的根本问题，为优化模型效率提供指导。",
      "method": "论文引入Order-r Interaction概念，理论证明在解决不可约逻辑问题时，高阶依赖的学习信号指数衰减。为实证验证，设计了NatBool-DAG基准，强制进行无语义捷径的逻辑推理。基于此，提出ALiCoT框架，通过对齐潜在token分布与中间推理状态，来克服信号衰减，实现token高效压缩。",
      "result": "实验结果显示，ALiCoT框架在NatBool-DAG基准上实现了54.4倍的推理加速，同时性能与显式链式思维方法相当。这验证了理论分析的正确性，并展示出该框架在显著提升效率的同时保持准确性，为实际应用中的低成本推理提供了实证支持。",
      "conclusion": "本研究首次对链式思维压缩进行了理论分析，揭示了信号衰减机制，并提出了ALiCoT框架来解决问题。学术上，它为高效推理方法提供了理论基础；实际上，能降低大型语言模型的计算开销。摘要未明确说明未来方向，但可能包括扩展理论到更多任务或进一步优化框架性能。",
      "tags": [
        "Chain-of-Thought",
        "Large Language Models",
        "Theoretical Analysis",
        "Implicit CoT Compression",
        "Order-r Interaction"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:18.762925Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21572",
    "title": "Signal-Adaptive Trust Regions for Gradient-Free Optimization of Recurrent Spiking Neural Networks",
    "authors": [
      "Jinhao Li",
      "Yuhao Sun",
      "Zhiyuan Ma",
      "Hao He",
      "Xinche Zhang",
      "Xing Chen",
      "Jin Li",
      "Sen Song"
    ],
    "abstract": "Recurrent spiking neural networks (RSNNs) are a promising substrate for energy-efficient control policies, but training them for high-dimensional, long-horizon reinforcement learning remains challenging. Population-based, gradient-free optimization circumvents backpropagation through non-differentiable spike dynamics by estimating gradients. However, with finite populations, high variance of these estimates can induce harmful and overly aggressive update steps. Inspired by trust-region methods in reinforcement learning that constrain policy updates in distribution space, we propose \\textbf{Signal-Adaptive Trust Regions (SATR)}, a distributional update rule that constrains relative change by bounding KL divergence normalized by an estimated signal energy. SATR automatically expands the trust region under strong signals and contracts it when updates are noise-dominated. We instantiate SATR for Bernoulli connectivity distributions, which have shown strong empirical performance for RSNN optimization. Across a suite of high-dimensional continuous-control benchmarks, SATR improves stability under limited populations and reaches competitive returns against strong baselines including PPO-LSTM. In addition, to make SATR practical at scale, we introduce a bitset implementation for binary spiking and binary weights, substantially reducing wall-clock training time and enabling fast RSNN policy search.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21572.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21572",
    "published": "2026-01-29T11:34:49Z",
    "updated": "2026-01-29T11:34:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出信号自适应信任区域（SATR）方法，用于优化循环脉冲神经网络的梯度免费强化学习，以提高稳定性和性能。",
      "motivation": "循环脉冲神经网络（RSNNs）作为能效控制策略有潜力，但训练在高维、长视界强化学习中仍具挑战性。基于种群的梯度免费优化能避免不可微脉冲动态的反向传播，但有限种群导致梯度估计方差高，引发有害的激进更新，限制了RSNNs的可靠应用，这凸显了改进优化稳定性的必要性。",
      "method": "论文提出信号自适应信任区域（SATR），这是一种基于KL散度归一化估计信号能量的分布更新规则，通过动态约束相对变化来自动调整信任区域大小，在信号强时扩展、噪声主导时收缩。具体在伯努利连接分布上实例化SATR，并引入bitset实现处理二进制脉冲和权重，大幅减少训练时间，使大规模RSNN策略搜索更高效。",
      "result": "在高维连续控制基准测试中，SATR在有限种群下显著提高了训练稳定性，并达到与PPO-LSTM等强基线竞争的性能回报，这表明SATR有效缓解了梯度估计的方差问题，使RSNN优化更可靠，摘要未提供具体数值，但强调了改进的稳定性和竞争力。",
      "conclusion": "SATR方法通过动态信任区域优化，解决了梯度免费训练RSNNs的更新不稳定问题，提升了训练效率和策略性能，增强了能效控制策略的实用性，推动了低功耗AI发展。未来工作可探索SATR在其他神经网络类型或更复杂任务中的应用。",
      "tags": [
        "Recurrent Spiking Neural Networks",
        "Gradient-Free Optimization",
        "Trust-Region Methods",
        "KL Divergence",
        "Bitset Implementation"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:21.645190Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21571",
    "title": "Shaping capabilities with token-level data filtering",
    "authors": [
      "Neil Rathi",
      "Alec Radford"
    ],
    "abstract": "Current approaches to reducing undesired capabilities in language models are largely post hoc, and can thus be easily bypassed by adversaries. A natural alternative is to shape capabilities during pretraining itself. On the proxy task of removing medical capabilities, we show that the simple intervention of filtering pretraining data is highly effective, robust, and inexpensive at scale. Inspired by work on data attribution, we show that filtering tokens is more effective than filtering documents, achieving the same hit to undesired capabilities at a lower cost to benign ones. Training models spanning two orders of magnitude, we then demonstrate that filtering gets more effective with scale: for our largest models, token filtering leads to a 7000x compute slowdown on the forget domain. We also show that models trained with token filtering can still be aligned on the forget domain. Along the way, we introduce a methodology for labeling tokens with sparse autoencoders and distilling cheap, high-quality classifiers. We also demonstrate that filtering can be robust to noisy labels with sufficient pretraining compute.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21571.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21571",
    "published": "2026-01-29T11:34:01Z",
    "updated": "2026-01-29T11:34:01Z",
    "comment": "33 pages, 28 figures",
    "light_analysis": {
      "overview": "论文提出在预训练阶段通过token级数据过滤来塑造语言模型能力，有效减少不期望能力并保持良性性能。",
      "motivation": "当前减少语言模型不期望能力（如医疗能力）的方法主要是后处理，如对齐或微调，容易被对抗性攻击绕过，导致安全风险。这一问题的重要性在于预训练阶段缺乏主动干预，现有方法反应性和脆弱性较高。因此，研究动机是在预训练阶段直接通过数据过滤来塑造模型能力，以增强稳健性和减少安全风险。",
      "method": "核心方法是使用token-level数据过滤而非文档级过滤，更精细和高效。关键创新点包括使用稀疏自编码器标记tokens，并蒸馏廉价、高质量分类器来实现精确过滤。实验中使用不同规模的模型（跨越两个数量级），以验证方法有效性和可扩展性。方法论涵盖数据标记、分类器训练和模型预训练过程。",
      "result": "实验结果显示，token过滤比文档过滤更有效，在减少不期望医疗能力的同时，对良性能力影响更小。随着模型规模增大，过滤效果增强；在最大模型上，token过滤导致遗忘域计算减慢7000倍。过滤后的模型仍能在遗忘域上成功对齐，证明了方法的实用性和稳健性，并与基线方法进行了对比，展示了显著性能改进。",
      "conclusion": "本研究主要贡献是提出token级数据过滤作为预训练阶段塑造模型能力的新方法，证明其高效、稳健和低成本优势。学术价值在于为语言模型安全和能力控制提供新思路；实际应用价值在于可广泛减少模型不期望行为。局限性可能包括对标签质量的依赖，未来工作可探索更鲁棒的过滤技术和更广泛应用场景。",
      "tags": [
        "Token Filtering",
        "Sparse Autoencoders",
        "Data Attribution",
        "Language Model Pretraining",
        "Model Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:39.275720Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21570",
    "title": "EmboCoach-Bench: Benchmarking AI Agents on Developing Embodied Robots",
    "authors": [
      "Zixing Lei",
      "Genjia Liu",
      "Yuanshuo Zhang",
      "Qipeng Liu",
      "Chuan Wen",
      "Shanghang Zhang",
      "Wenzhao Lian",
      "Siheng Chen"
    ],
    "abstract": "The field of Embodied AI is witnessing a rapid evolution toward general-purpose robotic systems, fueled by high-fidelity simulation and large-scale data collection. However, this scaling capability remains severely bottlenecked by a reliance on labor-intensive manual oversight from intricate reward shaping to hyperparameter tuning across heterogeneous backends. Inspired by LLMs' success in software automation and science discovery, we introduce \\textsc{EmboCoach-Bench}, a benchmark evaluating the capacity of LLM agents to autonomously engineer embodied policies. Spanning 32 expert-curated RL and IL tasks, our framework posits executable code as the universal interface. We move beyond static generation to assess a dynamic closed-loop workflow, where agents leverage environment feedback to iteratively draft, debug, and optimize solutions, spanning improvements from physics-informed reward design to policy architectures such as diffusion policies. Extensive evaluations yield three critical insights: (1) autonomous agents can qualitatively surpass human-engineered baselines by 26.5\\% in average success rate; (2) agentic workflow with environment feedback effectively strengthens policy development and substantially narrows the performance gap between open-source and proprietary models; and (3) agents exhibit self-correction capabilities for pathological engineering cases, successfully resurrecting task performance from near-total failures through iterative simulation-in-the-loop debugging. Ultimately, this work establishes a foundation for self-evolving embodied intelligence, accelerating the paradigm shift from labor-intensive manual tuning to scalable, autonomous engineering in embodied AI field.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21570.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21570",
    "published": "2026-01-29T11:33:49Z",
    "updated": "2026-01-29T11:33:49Z",
    "comment": "37 pages, 13 figures",
    "light_analysis": {
      "overview": "本文引入EmboCoach-Bench基准，评估大型语言模型代理自主开发具身机器人策略的能力，创新在于动态闭环工作流评估。",
      "motivation": "具身AI领域正快速向通用机器人系统演进，依赖高保真仿真和大规模数据收集。然而，扩展能力严重受限于劳动密集型手动监督，如复杂奖励塑造和异构后端超参数调优，导致低效和难以规模化。现有方法过度依赖人工干预，阻碍了自动化和可扩展性。受大型语言模型在软件自动化和科学发现中成功的启发，本研究旨在解决自动化工程设计瓶颈，推动具身AI向更高效、自主的方向发展，以加速机器人系统的部署和应用。",
      "method": "研究提出EmboCoach-Bench基准，涵盖32个专家策划的强化学习和模仿学习任务，采用可执行代码作为通用接口。方法超越静态代码生成，评估动态闭环工作流：代理利用环境反馈迭代草稿、调试和优化解决方案，覆盖从物理信息奖励设计到扩散策略架构的改进。关键创新包括基于代码的接口实现和仿真内循环迭代优化，以增强代理的自主工程设计能力，支持从奖励调整到策略架构的全流程自动化。",
      "result": "广泛评估得出三个关键结果：自主代理的平均成功率比人工设计的基线高26.5%；带环境反馈的代理工作流有效增强策略开发，显著缩小开源模型与专有模型之间的性能差距；代理在病理工程案例中展示自我纠正能力，通过迭代仿真内循环调试，从接近完全失败中成功恢复任务性能。这些结果表明自动化方法在性能上超越人工基线，并改善了模型间的均衡性，验证了自主工程设计的可行性和优势。",
      "conclusion": "本工作建立了自进化具身智能的基础，加速了从劳动密集型手动调优向可扩展、自主工程的范式转变。主要贡献包括引入基准框架和提供自动化工程设计的洞察，学术价值在于推动具身AI的自动化研究方法，实际应用价值在于促进机器人系统的高效开发和部署。摘要未明确说明局限性，未来工作可能涉及扩展任务范围、验证泛化能力，或探索更多自动化场景以进一步提升自主性。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning",
        "Imitation Learning",
        "Diffusion Policies",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:18.448995Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21568",
    "title": "Bridging Functional and Representational Similarity via Usable Information",
    "authors": [
      "Antonio Almudévar",
      "Alfonso Ortega"
    ],
    "abstract": "We present a unified framework for quantifying the similarity between representations through the lens of \\textit{usable information}, offering a rigorous theoretical and empirical synthesis across three key dimensions. First, addressing functional similarity, we establish a formal link between stitching performance and conditional mutual information. We further reveal that stitching is inherently asymmetric, demonstrating that robust functional comparison necessitates a bidirectional analysis rather than a unidirectional mapping. Second, concerning representational similarity, we prove that reconstruction-based metrics and standard tools (e.g., CKA, RSA) act as estimators of usable information under specific constraints. Crucially, we show that similarity is relative to the capacity of the predictive family: representations that appear distinct to a rigid observer may be identical to a more expressive one. Third, we demonstrate that representational similarity is sufficient but not necessary for functional similarity. We unify these concepts through a task-granularity hierarchy: similarity on a complex task guarantees similarity on any coarser derivative, establishing representational similarity as the limit of maximum granularity: input reconstruction.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21568.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21568",
    "published": "2026-01-29T11:30:55Z",
    "updated": "2026-01-29T11:30:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一个基于可用信息的统一框架，量化表示相似性，并连接功能与表示相似性。",
      "motivation": "摘要未明确说明具体研究动机。可能动机是现有表示相似性度量方法（如CKA、RSA）缺乏统一理论基础，且功能相似性（如模型性能）与表示相似性（如特征分布）之间的关系不清晰，导致模型分析和比较存在局限性。通过引入可用信息概念，本研究旨在提供一个严谨的理论框架，解决量化中的不一致性问题，推动机器学习表示理解和模型评估的发展。",
      "method": "研究方法围绕可用信息框架展开三个维度：首先，针对功能相似性，建立拼接性能与条件互信息的正式链接，揭示拼接的内在不对称性，强调双向分析而非单向映射的必要性。其次，针对表示相似性，证明基于重建的度量和标准工具（如CKA、RSA）在特定约束下是可用信息的估计器，并指出相似性相对于预测家族能力的相对性（即不同观察者可能得出不同结论）。最后，通过任务粒度层次统一概念，表明复杂任务上的相似性保证更粗粒度衍生任务上的相似性，以输入重建为极限表示最大粒度相似性。",
      "result": "主要结果包括理论证明和实证综合：理论上，建立了功能相似性与条件互信息的联系，揭示了拼接不对称性；证明了表示相似性度量在特定条件下是可用信息的估计器，并表明相似性取决于预测家族的能力（刚性观察者与表达性观察者可能得出不同判断）；统一了表示相似性为功能相似性的充分但不必要条件。实证部分摘要未详细说明具体数据，但表示提供了理论和实验的结合，以支持这些发现。",
      "conclusion": "论文的主要贡献是提出了基于可用信息的统一框架，连接功能和表示相似性，建立了任务粒度层次。这增强了表示相似性量化的理论严谨性，有助于更准确比较神经网络表示，对模型解释、迁移学习和表示学习领域有重要学术价值。潜在局限性可能包括框架的通用性验证，未来工作可扩展到更广泛的任务类型或实际应用场景。",
      "tags": [
        "Usable Information",
        "Functional Similarity",
        "Representational Similarity",
        "Stitching",
        "CKA"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:58.143489Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21567",
    "title": "FlexCausal: Flexible Causal Disentanglement via Structural Flow Priors and Manifold-Aware Interventions",
    "authors": [
      "Yutao Jin",
      "Yuang Tao",
      "Junyong Zhai"
    ],
    "abstract": "Causal Disentangled Representation Learning(CDRL) aims to learn and disentangle low dimensional representations and their underlying causal structure from observations. However, existing disentanglement methods rely on a standard mean-field approximation with a diagonal posterior covariance, which decorrelates all latent dimensions. Additionally, these methods often assume isotropic Gaussian priors for exogenous noise, failing to capture the complex, non-Gaussian statistical properties prevalent in real-world causal factors. Therefore, we propose FlexCausal, a novel CDRL framework based on a block-diagonal covariance VAE. FlexCausal utilizes a Factorized Flow-based Prior to realistically model the complex densities of exogenous noise, effectively decoupling the learning of causal mechanisms from distributional statistics. By integrating supervised alignment objectives with counterfactual consistency constraints, our framework ensures a precise structural correspondence between the learned latent subspaces and the ground-truth causal relations. Finally, we introduce a manifold-aware relative intervention strategy to ensure high-fidelity generation. Experimental results on both synthetic and real-world datasets demonstrate that FlexCausal significantly outperforms other methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21567.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21567",
    "published": "2026-01-29T11:30:53Z",
    "updated": "2026-01-29T11:30:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "FlexCausal提出了一种基于块对角协方差VAE的因果解耦表示学习框架，通过结构流先验和流形感知干预，实现了更灵活的因果解耦。",
      "motivation": "因果解耦表示学习旨在从观测数据中学习低维表示及其因果结构。然而，现有方法依赖于对角线后验协方差，导致所有潜在维度去相关，限制了模型的表达能力。此外，这些方法假设外生噪声为各向同性高斯分布，无法捕捉现实世界中因果因子的复杂非高斯统计特性。这些不足促使开发更灵活的模型来处理真实世界的复杂因果关系，以提高解耦的准确性和适应性。",
      "method": "FlexCausal框架基于块对角协方差变分自编码器，引入因子流先验来建模外生噪声的复杂密度分布，从而将因果机制的学习与分布统计解耦。通过整合监督对齐目标和反事实一致性约束，确保学习到的潜在子空间与真实因果关系精确对应。此外，采用流形感知的相对干预策略，以提高生成过程的高保真度。关键创新包括结构流先验的应用和针对流形结构的干预方法，有效应对非高斯噪声和复杂因果关系的挑战。",
      "result": "实验在合成和真实世界数据集上进行，结果表明FlexCausal显著优于其他现有方法。尽管摘要未明确说明具体的性能指标如准确率或效率改进，但它强调了方法在解耦和生成任务上的优越表现。与基线方法的对比显示了FlexCausal在捕捉复杂因果结构方面的有效性，展示了其在处理非高斯分布和复杂关系时的性能优势。",
      "conclusion": "本研究的主要贡献在于提出FlexCausal框架，通过结合结构流先验和流形感知干预，提高了因果解耦的灵活性和准确性。该工作为处理非高斯噪声和复杂因果关系的表示学习提供了新思路，具有重要的学术价值，可应用于强化学习、图像生成等领域。潜在局限性或未来工作方向，摘要未明确说明，但可以探索更多数据集的应用和技术优化。",
      "tags": [
        "Causal Disentangled Representation Learning",
        "Variational Autoencoder",
        "Flow-based Prior",
        "Manifold-Aware Intervention",
        "Counterfactual Consistency Constraints"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:17.987730Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21564",
    "title": "Representation Unlearning: Forgetting through Information Compression",
    "authors": [
      "Antonio Almudévar",
      "Alfonso Ortega"
    ],
    "abstract": "Machine unlearning seeks to remove the influence of specific training data from a model, a need driven by privacy regulations and robustness concerns. Existing approaches typically modify model parameters, but such updates can be unstable, computationally costly, and limited by local approximations. We introduce Representation Unlearning, a framework that performs unlearning directly in the model's representation space. Instead of modifying model parameters, we learn a transformation over representations that imposes an information bottleneck: maximizing mutual information with retained data while suppressing information about data to be forgotten. We derive variational surrogates that make this objective tractable and show how they can be instantiated in two practical regimes: when both retain and forget data are available, and in a zero-shot setting where only forget data can be accessed. Experiments across several benchmarks demonstrate that Representation Unlearning achieves more reliable forgetting, better utility retention, and greater computational efficiency than parameter-centric baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21564.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21564",
    "published": "2026-01-29T11:28:02Z",
    "updated": "2026-01-29T11:28:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出表示遗忘框架，通过信息压缩直接在模型表示空间实现数据遗忘，提升遗忘的可靠性和计算效率。",
      "motivation": "机器遗忘旨在从模型中移除特定训练数据的影响，以满足隐私法规和增强模型鲁棒性的需求。现有方法通常通过修改模型参数实现遗忘，但这种方法存在更新不稳定、计算成本高、受限于局部近似等问题，难以精确控制遗忘效果，因此需要开发更稳定和高效的遗忘技术来解决这些挑战。",
      "method": "该研究提出表示遗忘框架，在模型的表示空间直接执行遗忘。核心方法是通过学习一个表示变换，施加信息瓶颈：最大化与保留数据的互信息，同时抑制与遗忘数据相关的信息。使用变分代理使目标函数可处理，并支持两种实际场景：当保留和遗忘数据都可用时，以及在仅遗忘数据可访问的零样本设置中。这避免了直接修改模型参数，提高了方法的灵活性和稳定性。",
      "result": "在多个基准实验中，表示遗忘方法相比传统的参数修改方法，展现出更可靠的遗忘性能，能有效移除指定数据的影响，同时保持了更好的模型效用和更高的计算效率。摘要未明确说明具体性能指标数据，但整体效果优于基线方法，验证了其在实际应用中的优越性。",
      "conclusion": "该论文的主要贡献是提出基于表示空间的遗忘框架，通过信息压缩技术实现高效和稳定的数据遗忘，为机器遗忘任务提供了新方法。学术上，引入了信息瓶颈理论到遗忘问题中；实际上，有助于隐私保护和模型鲁棒性改进。未来工作可探索更多场景下的应用和优化。",
      "tags": [
        "Representation Unlearning",
        "Information Bottleneck",
        "Variational Methods",
        "Machine Unlearning",
        "Zero-shot Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:29.429618Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21561",
    "title": "SAL: Selective Adaptive Learning for Backpropagation-Free Training with Sparsification",
    "authors": [
      "Fanping Liu",
      "Hua Yang",
      "Jiasi Zou"
    ],
    "abstract": "Standard deep learning relies on Backpropagation (BP), which is constrained by biologically implausible weight symmetry and suffers from significant gradient interference within dense representations. To mitigate these bottlenecks, we propose Selective Adaptive Learning (SAL), a training method that combines selective parameter activation with adaptive area partitioning. Specifically, SAL decomposes the parameter space into mutually exclusive, sample-dependent regions. This decoupling mitigates gradient interference across divergent semantic patterns and addresses explicit weight symmetry requirements through our refined feedback alignment. Empirically, SAL demonstrates competitive convergence rates, leading to improved classification performance across 10 standard benchmarks. Additionally, SAL achieves numerical consistency and competitive accuracy even in deep regimes (up to 128 layers) and large-scale models (up to 1B parameters). Our approach is loosely inspired by biological learning mechanisms, offering a plausible alternative that contributes to the study of scalable neural network training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21561.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21561",
    "published": "2026-01-29T11:26:26Z",
    "updated": "2026-01-29T11:26:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了SAL（选择性自适应学习）方法，这是一种无反向传播的训练技术，通过参数空间分解和改进的反向对齐来优化神经网络训练。",
      "motivation": "标准深度学习依赖于反向传播（BP），但BP存在生物学上不合理的权重对称性要求和在密集表示中的梯度干扰问题。这些问题限制了神经网络训练的效率和在深层、大规模模型中的应用。现有方法未能有效解决这些瓶颈，因此需要开发新的训练方法以提高可扩展性和性能，这是SAL研究的核心动机。",
      "method": "SAL方法结合选择性参数激活和自适应区域划分，将参数空间分解为相互排斥的、样本依赖的区域。这种分解减轻了不同语义模式间的梯度干扰，并通过改进的反向对齐技术解决了权重对称性要求。该方法松散地受生物学学习机制启发，不依赖传统反向传播，旨在通过参数稀疏化和自适应分割优化训练过程。",
      "result": "实验结果表明，SAL在10个标准基准测试中表现出有竞争力的收敛速率，提高了分类性能。在深层网络（多达128层）和大规模模型（多达10亿参数）中，SAL实现了数值一致性和有竞争力的准确性。这些效果展示了其在减轻梯度干扰和解决权重对称问题方面的优势，但具体基线对比数据摘要未明确说明。",
      "conclusion": "SAL方法通过选择性参数激活和自适应区域划分，为无反向传播的神经网络训练提供了有效解决方案。它减轻了标准反向传播的局限性，在深层和大规模模型中表现良好，对可扩展神经网络训练研究具有重要学术和实际价值。未来工作可进一步探索其在不同应用场景中的优化和局限性，但摘要未明确说明具体方向。",
      "tags": [
        "Backpropagation-Free Training",
        "Sparsification",
        "Selective Adaptive Learning",
        "Gradient Interference",
        "Feedback Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:59.688968Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21560",
    "title": "HistoPrism: Unlocking Functional Pathway Analysis from Pan-Cancer Histology via Gene Expression Prediction",
    "authors": [
      "Susu Hu",
      "Qinghe Zeng",
      "Nithya Bhasker",
      "Jakob Nicolas Kather",
      "Stefanie Speidel"
    ],
    "abstract": "Predicting spatial gene expression from H&E histology offers a scalable and clinically accessible alternative to sequencing, but realizing clinical impact requires models that generalize across cancer types and capture biologically coherent signals. Prior work is often limited to per-cancer settings and variance-based evaluation, leaving functional relevance underexplored. We introduce HistoPrism, an efficient transformer-based architecture for pan-cancer prediction of gene expression from histology. To evaluate biological meaning, we introduce a pathway-level benchmark, shifting assessment from isolated gene-level variance to coherent functional pathways. HistoPrism not only surpasses prior state-of-the-art models on highly variable genes , but also more importantly, achieves substantial gains on pathway-level prediction, demonstrating its ability to recover biologically coherent transcriptomic patterns. With strong pan-cancer generalization and improved efficiency, HistoPrism establishes a new standard for clinically relevant transcriptomic modeling from routinely available histology.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21560.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21560",
    "published": "2026-01-29T11:25:14Z",
    "updated": "2026-01-29T11:25:14Z",
    "comment": "Accepted at ICLR2026",
    "light_analysis": {
      "overview": "HistoPrism是一个基于transformer的高效模型，从H&E组织学预测基因表达，通过引入路径级评估实现跨癌症泛化，专注于功能路径分析。",
      "motivation": "从H&E组织学预测基因表达提供了一种可扩展且临床可访问的替代测序方法，但现有研究常局限于单一癌症类型，评估基于基因级方差，忽略了功能路径的生物学相关性。这限制了模型的临床实用性，因为癌症异质性需要跨类型泛化并能捕捉生物学一致信号的模型，以提升诊断和治疗效果。",
      "method": "论文提出HistoPrism，一个基于transformer的高效架构，用于从H&E组织学图像预测基因表达，支持跨癌症类型应用。关键创新是引入路径级评估基准，将预测评估从孤立的基因水平转向一致的功能路径，模型设计注重计算效率和生物学一致性，可能使用组织学和基因表达数据进行训练以捕获转录组模式。",
      "result": "HistoPrism在高度可变基因的预测上超越了先前的最佳模型，更在路径级预测上实现了实质性增益，展示了恢复生物学一致转录组模式的能力。具体表现为强大的泛癌泛化能力和改进的效率，与基线方法相比，在功能相关评估中表现优异，摘要未明确说明具体性能指标。",
      "conclusion": "HistoPrism的主要贡献是通过基于transformer的模型和路径级评估，从组织学预测基因表达并实现泛癌泛化，为临床相关转录组建模设定了新标准。其学术价值在于将评估从基因方差扩展到功能路径，增强了生物学意义；实际应用上，提供了高效、可扩展的分析工具，未来可扩展到更多癌症类型或整合多模态数据。",
      "tags": [
        "Gene Expression Prediction",
        "Histology Imaging",
        "Transformer Architecture",
        "Pathway Analysis",
        "Pan-Cancer Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:08.780490Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21558",
    "title": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
    "authors": [
      "Xiaoyu Tian",
      "Haotian Wang",
      "Shuaiting Chen",
      "Hao Zhou",
      "Kaichi Yu",
      "Yudian Zhang",
      "Jade Ouyang",
      "Junxi Yin",
      "Jiong Chen",
      "Baoyan Guo",
      "Lei Zhang",
      "Junjie Tao",
      "Yuansheng Song",
      "Ming Cui",
      "Chengwei Liu"
    ],
    "abstract": "Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21558.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21558",
    "published": "2026-01-29T11:22:23Z",
    "updated": "2026-01-29T11:22:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "ASTRA提出一个全自动框架，通过合成代理轨迹和强化学习环境，结合SFT和RL训练工具增强语言模型代理，解决了训练中的挑战。",
      "motivation": "论文动机源于训练工具增强大型语言模型代理的挑战：现有方法如监督微调或强化学习需要人工干预，依赖不可验证的模拟环境，导致训练不稳定且难以应对长时多轮任务。这些问题限制了代理在复杂决策中的应用，使得自动化、可验证的训练方案成为重要需求。摘要指出，当前方法缺乏整合性和可扩展性，因此迫切需要一种全自动解决方案来提升训练效率和稳健性。",
      "method": "ASTRA方法包括两个核心组件：一是轨迹合成管道，利用工具调用图的静态拓扑自动生成多样化、结构化的代理轨迹，增强工具使用的可迁移性；二是环境合成框架，将人类语义推理的问答痕迹转换为代码可执行、规则可验证的强化学习环境，支持确定性多轮学习。基于此，开发了统一训练方法，集成SFT与在线RL，使用轨迹级奖励来平衡任务完成和交互效率，实现端到端的自动化训练。",
      "result": "实验结果表明，在多个代理工具使用基准测试中，ASTRA训练的模型性能达到最先进水平，与类似规模模型相比有显著提升，接近闭源系统的表现，同时有效保持了核心推理能力。这验证了框架的有效性和可扩展性，但摘要未明确具体指标如准确率或效率提升的具体数字，仅概括性地描述了性能优势。",
      "conclusion": "论文主要贡献是ASTRA自动化合成框架，通过数据合成和可验证强化学习解决了工具增强LLM代理的训练难题，具有重要学术价值，为代理学习提供了新方法。实际应用中，发布的开源资源促进了社区发展，未来工作可进一步优化合成框架或扩展到更复杂的场景，以克服潜在局限性如环境合成的泛化能力。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Data Synthesis",
        "Environment Synthesis",
        "Tool-Augmented Agent"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:24.980981Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21557",
    "title": "Meta Context Engineering via Agentic Skill Evolution",
    "authors": [
      "Haoran Ye",
      "Xuning He",
      "Vincent Arak",
      "Haonan Dong",
      "Guojie Song"
    ],
    "abstract": "The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context optimization to a narrow, intuition-bound design space. To address this, we introduce Meta Context Engineering (MCE), a bi-level framework that supersedes static CE heuristics by co-evolving CE skills and context artifacts. In MCE iterations, a meta-level agent refines engineering skills via agentic crossover, a deliberative search over the history of skills, their executions, and evaluations. A base-level agent executes these skills, learns from training rollouts, and optimizes context as flexible files and code. We evaluate MCE across five disparate domains under offline and online settings. MCE demonstrates consistent performance gains, achieving 5.6--53.8% relative improvement over state-of-the-art agentic CE methods (mean of 16.9%), while maintaining superior context adaptability, transferability, and efficiency in both context usage and training.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21557.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21557",
    "published": "2026-01-29T11:22:02Z",
    "updated": "2026-01-29T11:22:02Z",
    "comment": "46 pages, 4 figures",
    "light_analysis": {
      "overview": "论文提出元上下文工程框架，通过代理技能进化优化大语言模型的上下文工程，实现超越静态方法的性能提升。",
      "motivation": "大语言模型的推理性能高度依赖上下文输入，这促使上下文工程成为一个关键研究领域。现有方法如手动设计的生成-反思工作流程和预定义模式，存在结构偏差并限制了优化空间，导致适应性不足和效率低下。因此，需要开发更动态、自适应的上下文优化方法，以克服这些局限性并提升模型在实际应用中的效能。",
      "method": "MCE采用双层框架：元级代理通过agentic crossover（一种对技能历史、执行和评估进行深思熟虑搜索的过程）进化工程技能；基础级代理执行这些技能，从训练rollout中学习，并将上下文优化为灵活的文件和代码。关键创新在于共同进化技能和上下文工件，取代了传统的静态启发式方法，提升了上下文设计的灵活性和适应性。",
      "result": "在五个不同领域的评估中，MCE在离线和在线设置下均显示出持续的性能提升。相较于最先进的agentic CE方法，相对改进范围在5.6%到53.8%之间，平均为16.9%。此外，MCE在上下文适应性、可转移性以及使用和训练效率方面也表现优越，证实了其优于基线方法的全面性能。",
      "conclusion": "MCE成功提出了一种新型上下文优化框架，通过代理技能进化显著提升了模型性能，为上下文工程领域做出了重要贡献。该研究具有较高的学术价值，为动态上下文设计提供了理论基础，并具备广泛的实际应用潜力，例如在自然语言处理和自动化任务中。未来工作可探索其在更多领域的应用或优化框架效率，以应对潜在挑战如计算资源需求。",
      "tags": [
        "Meta Context Engineering",
        "Agentic Skill Evolution",
        "Large Language Models",
        "Context Optimization",
        "Agentic Crossover"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:33.281718Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21551",
    "title": "Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes",
    "authors": [
      "Yang Zhou",
      "Zhenting Sheng",
      "Mingrui Tan",
      "Yuting Song",
      "Jun Zhou",
      "Yu Heng Kwan",
      "Lian Leng Low",
      "Yang Bai",
      "Yong Liu"
    ],
    "abstract": "Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \\method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21551.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21551",
    "published": "2026-01-29T11:05:46Z",
    "updated": "2026-01-29T11:05:46Z",
    "comment": "Accepted at AAAI-26",
    "light_analysis": {
      "overview": "本文提出 Note2Chat 框架，通过利用医学笔记训练大型语言模型，显著提升了多轮临床病史采集的性能。",
      "motivation": "临床病史采集是临床推理的基础，但在动态多轮诊断环境中，现有大型语言模型表现不佳，因为传统方法依赖稀缺且敏感的医患对话数据，且静态基准测试无法适应迭代提问和假设细化的需求。本研究旨在解决这一不足，通过利用广泛可用的医学笔记作为训练资源，以提高模型在复杂医疗对话中的能力，从而促进临床自动化应用的发展。",
      "method": "Note2Chat 框架的核心方法包括数据生成和模型训练两部分：首先，使用决策树引导的生成和细化管道，将真实世界医学笔记转换为高质量医患对话数据；其次，采用三阶段微调策略，结合监督学习、模拟数据增强和偏好学习来优化模型性能。创新点在于引入了单轮推理范式，将多轮病史采集重构为单轮问题序列，以增强可解释性、实现局部监督、动态适应并提高样本效率。",
      "result": "实验结果显示，Note2Chat 在临床推理任务上取得了显著改进。与基线模型 GPT-4o 相比，在 F1 分数上提升了 +16.9 点，Top-1 诊断准确率提高了 +21.0 个百分点。这些数据证明了该方法在增强多轮对话能力和诊断准确性方面的有效性，优于现有先进模型，为医疗 AI 应用提供了新的性能基准。",
      "conclusion": "本研究的核心贡献是开发了 Note2Chat 框架，通过创新数据生成和微调策略，显著提升了大型语言模型在临床病史采集中的性能。学术上，它为利用非对话数据训练对话系统提供了新思路；实际上，可促进医疗诊断的自动化和效率提升。摘要未明确说明局限性，未来工作可能包括优化模型泛化能力或扩展到其他医疗任务。",
      "tags": [
        "Large Language Model",
        "Clinical History Taking",
        "Multi-Turn Dialogue",
        "Fine-Tuning",
        "Preference Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:59.009834Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21547",
    "title": "Multi-Modal Time Series Prediction via Mixture of Modulated Experts",
    "authors": [
      "Lige Zhang",
      "Ali Maatouk",
      "Jialin Chen",
      "Leandros Tassiulas",
      "Rex Ying"
    ],
    "abstract": "Real-world time series exhibit complex and evolving dynamics, making accurate forecasting extremely challenging. Recent multi-modal forecasting methods leverage textual information such as news reports to improve prediction, but most rely on token-level fusion that mixes temporal patches with language tokens in a shared embedding space. However, such fusion can be ill-suited when high-quality time-text pairs are scarce and when time series exhibit substantial variation in scale and characteristics, thus complicating cross-modal alignment. In parallel, Mixture-of-Experts (MoE) architectures have proven effective for both time series modeling and multi-modal learning, yet many existing MoE-based modality integration methods still depend on token-level fusion. To address this, we propose Expert Modulation, a new paradigm for multi-modal time series prediction that conditions both routing and expert computation on textual signals, enabling direct and efficient cross-modal control over expert behavior. Through comprehensive theoretical analysis and experiments, our proposed method demonstrates substantial improvements in multi-modal time series prediction. The current code is available at https://github.com/BruceZhangReve/MoME",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21547.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21547",
    "published": "2026-01-29T11:03:09Z",
    "updated": "2026-01-29T11:03:09Z",
    "comment": "26 pages, 12 figures",
    "light_analysis": {
      "overview": "本文提出Expert Modulation新范式，通过混合调制专家实现多模态时间序列预测的显著改进。",
      "motivation": "现实世界时间序列预测因复杂动态而极具挑战，现有方法常利用文本信息如新闻报道来提升准确性，但大多依赖标记级融合，将时间序列片段与语言标记混合在共享嵌入空间中。这种方法在高噪声数据稀缺、时间序列尺度和特征变化大时效率低下，导致跨模态对齐困难。因此，需要一种更鲁棒的多模态集成技术，以克服数据稀缺性和序列异质性带来的局限，改进预测性能。",
      "method": "论文提出Expert Modulation方法，基于混合专家架构，通过文本信号条件化调节专家的路由和计算过程。关键创新在于避免传统的标记级融合，而是通过调制机制实现直接的跨模态控制，允许更灵活高效地集成多模态信息。该方法优化了时间序列与文本的交互，特别适用于数据稀疏或序列特征差异大的场景，摘要未明确说明具体数据集或模型架构细节。",
      "result": "通过全面的理论分析和实验验证，本文方法在多模态时间序列预测任务中展现出显著改进。尽管摘要未明确说明具体性能指标如准确率提升百分比，但与现有基线方法相比，Expert Modulation表现出更好的预测效果，验证了其高效性和鲁棒性。实验部分可能包括标准数据集的测试，强调了方法在跨模态对齐和预测精度方面的优势。",
      "conclusion": "本文的主要贡献是引入了Expert Modulation范式，为多模态时间序列预测提供了新的技术路径。该方法通过条件化路由和专家计算，实现高效的跨模态交互，提高了预测的准确性和鲁棒性，具有重要的学术价值，推动了多模态学习与时间序列分析的交叉领域发展。未来工作可探索在更多应用场景中的扩展和优化，如金融或气象预测。",
      "tags": [
        "Multi-Modal Time Series Prediction",
        "Mixture of Experts",
        "Expert Modulation",
        "Cross-Modal Alignment",
        "Token-Level Fusion"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:09.162151Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21545",
    "title": "ShardMemo: Masked MoE Routing for Sharded Agentic LLM Memory",
    "authors": [
      "Yang Zhao",
      "Chengxiao Dai",
      "Yue Xiu",
      "Mengying Kou",
      "Yuliang Zheng",
      "Dusit Niyato"
    ],
    "abstract": "Agentic large language model (LLM) systems rely on external memory for long-horizon state and concurrent multi-agent execution, but centralized indexes and heuristic partitions become bottlenecks as memory volume and parallel access grow. We present ShardMemo, a budgeted tiered memory service with Tier A per-agent working state, Tier B sharded evidence with shard-local approximate nearest neighbor (ANN) indexes, and Tier C, a versioned skill library. Tier B enforces scope-before-routing: structured eligibility constraints mask ineligible shards before routing or ANN search. We cast shard probing as masked mixture-of-experts (MoE) routing over eligible shards, probing up to $B_{\\mathrm{probe}}$ shards via Top-$B_{\\mathrm{probe}}$ or adaptive Top-$P$, and use cost-aware gating over profile/observation/session shard families; the router is trained from evidence-to-shard supervision. On LoCoMo, ShardMemo improves over the strongest baseline (GAM) by +5.11 to +6.82 F1 across question categories. Under a fixed-budget routing setting ($B_{\\mathrm{probe}}=3$), ShardMemo improves over cosine-to-prototype shard routing by +6.87 F1 while reducing retrieval work (VecScan 521->414, -20.5%) and p95 latency (95->76 ms). On long-context HotpotQA, ShardMemo achieves 63.41/61.88/57.95 F1 at 56K/224K/448K tokens. On ToolBench, Tier C reaches 0.97 Precision@3 and 1.94 StepRed (+10.2% and +7.2% over embedding-similarity retrieval).",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21545.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21545",
    "published": "2026-01-29T11:01:34Z",
    "updated": "2026-01-29T11:01:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "ShardMemo提出了一种基于masked MoE路由的分层分片内存服务，优化了代理LLM系统的内存管理效率和性能。",
      "motivation": "代理大型语言模型（LLM）系统在处理长时状态和并发多代理执行时依赖外部内存，但现有方法如集中式索引和启发式分区在内存量和并行访问增长时成为性能瓶颈，导致查询效率低下和延迟增加。这些问题限制了系统的可扩展性和实时响应能力，尤其在大规模或高并发场景下更为显著，因此急需开发更高效和可扩展的内存管理方案以支持复杂的代理任务。",
      "method": "ShardMemo采用三层内存架构：Tier A存储每个代理的工作状态，Tier B使用分片证据结合局部近似最近邻（ANN）索引，Tier C为版本化技能库。核心创新在于Tier B的'scope-before-routing'策略，通过结构化约束屏蔽不合格分片，并将分片探测建模为masked mixture-of-experts（MoE）路由。路由器从证据到分片的监督中训练，支持Top-B_probe或自适应Top-P探测，并应用成本感知门控处理分片家族。实验在LoCoMo、HotpotQA和ToolBench数据集上进行，验证了方法的有效性。",
      "result": "在LoCoMo数据集上，ShardMemo相比最强基线（GAM）的F1分数提升了5.11到6.82。在固定预算路由设置（B_probe=3）下，相比余弦到原型分片路由F1提升6.87，同时检索工作减少20.5%（VecScan从521降至414），p95延迟从95毫秒降至76毫秒。在长上下文HotpotQA上，56K/224K/448K token下的F1分别为63.41、61.88、57.95。在ToolBench上，Tier C的Precision@3达到0.97，StepRed指标提升10.2%和7.2%。",
      "conclusion": "ShardMemo通过masked MoE路由和分层内存设计，显著提升了代理LLM系统的内存管理效率，降低了延迟和资源消耗，为大规模多代理系统提供了可行解决方案。学术上，该方法推动了内存路由算法的发展；实际应用中，有助于构建更可扩展和高效的智能代理平台。虽然实验效果显著，但摘要未明确说明在高动态环境中的局限性，未来工作可探索自适应路由策略和更多样化的分片优化。",
      "tags": [
        "Masked Mixture-of-Experts (MoE)",
        "Sharded Memory",
        "Approximate Nearest Neighbor (ANN)",
        "Agentic LLM",
        "Memory Routing"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:38.807290Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21543",
    "title": "inversedMixup: Data Augmentation via Inverting Mixed Embeddings",
    "authors": [
      "Fanshuang Kong",
      "Richong Zhang",
      "Qiyu Sun",
      "Zhijie Nie",
      "Ting Deng",
      "Chunming Hu"
    ],
    "abstract": "Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21543.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21543",
    "published": "2026-01-29T11:00:50Z",
    "updated": "2026-01-29T11:00:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出 inversedMixup 框架，通过反转混合嵌入生成可解释的增强句子，结合了 Mixup 的控制性和大型语言模型的可读性，并首次实证证明了文本 Mixup 中的流形入侵现象。",
      "motivation": "现有数据增强方法中，Mixup 在嵌入层面通过线性插值生成样本，操作可控但输出不可解释；而基于大型语言模型的方法在标记层面生成可读句子，但控制生成过程有限，导致实用性不足。LLM 反转技术的最新进展能够从嵌入重建自然语言，有助于弥合嵌入空间和离散标记空间之间的差距，但现有方法未充分利用这一优势。因此，本研究旨在解决控制性与可解释性之间的平衡问题，开发一个统一框架以改进文本数据增强的性能和实用性。",
      "method": "inversedMixup 采用三阶段训练过程，首先对齐任务特定模型的输出嵌入空间与大型语言模型的输入嵌入空间，以实现混合嵌入的可控重构。关键创新包括结合 Mixup 的控制性和 LLM-based 生成的可解释性，并引入对齐机制来弥合嵌入空间与标记空间的 gap。此外，该方法首次提出文本 Mixup 中的流形入侵现象，并提供简单策略如优化混合比例以缓解此问题，从而提升增强效果。使用数据集和模型架构的具体细节摘要未明确说明，但框架可应用于少样本和全监督场景。",
      "result": "广泛实验表明，inversedMixup 在少样本和全监督场景中均表现出有效性和泛化性，能够改进数据增强性能。尽管摘要未提供具体性能指标如准确率提升，但实验验证了该方法通过生成可解释的增强句子，提高了模型训练效率和鲁棒性。与基线方法相比，inversedMixup 在控制生成过程和可读性方面取得平衡，并在多个任务设置下稳定提升表现，但具体对比数据摘要未明确说明。",
      "conclusion": "论文的主要贡献是提出 inversedMixup 框架，成功结合了 Mixup 的控制性和大型语言模型的可解释性，首次实证证明了文本 Mixup 中的流形入侵现象，并提供了缓解策略。学术价值在于弥合了嵌入空间和离散标记空间之间的差距，推动了数据增强技术的发展；实际应用价值在于提升文本分类等任务的性能，增强模型的可解释性。潜在局限性可能包括对齐过程的复杂性，未来工作可探索更高效的对齐技术或扩展到多模态数据增强领域。",
      "tags": [
        "Mixup",
        "Large Language Model",
        "Data Augmentation",
        "LLM Inversion",
        "Embedding Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:38.441967Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21542",
    "title": "Bi-Anchor Interpolation Solver for Accelerating Generative Modeling",
    "authors": [
      "Hongxu Chen",
      "Hongxiang Li",
      "Zhen Wang",
      "Long Chen"
    ],
    "abstract": "Flow Matching (FM) models have emerged as a leading paradigm for high-fidelity synthesis. However, their reliance on iterative Ordinary Differential Equation (ODE) solving creates a significant latency bottleneck. Existing solutions face a dichotomy: training-free solvers suffer from significant performance degradation at low Neural Function Evaluations (NFEs), while training-based one- or few-steps generation methods incur prohibitive training costs and lack plug-and-play versatility. To bridge this gap, we propose the Bi-Anchor Interpolation Solver (BA-solver). BA-solver retains the versatility of standard training-free solvers while achieving significant acceleration by introducing a lightweight SideNet (1-2% backbone size) alongside the frozen backbone. Specifically, our method is founded on two synergistic components: \\textbf{1) Bidirectional Temporal Perception}, where the SideNet learns to approximate both future and historical velocities without retraining the heavy backbone; and 2) Bi-Anchor Velocity Integration, which utilizes the SideNet with two anchor velocities to efficiently approximate intermediate velocities for batched high-order integration. By utilizing the backbone to establish high-precision ``anchors'' and the SideNet to densify the trajectory, BA-solver enables large interval sizes with minimized error. Empirical results on ImageNet-256^2 demonstrate that BA-solver achieves generation quality comparable to 100+ NFEs Euler solver in just 10 NFEs and maintains high fidelity in as few as 5 NFEs, incurring negligible training costs. Furthermore, BA-solver ensures seamless integration with existing generative pipelines, facilitating downstream tasks such as image editing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21542.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21542",
    "published": "2026-01-29T10:59:36Z",
    "updated": "2026-01-29T10:59:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Bi-Anchor Interpolation Solver（BA-solver），通过引入轻量级SideNet和双锚点插值技术，在保持训练免费求解器灵活性的同时，显著加速Flow Matching模型的生成过程，提升效率和保真度。",
      "motivation": "Flow Matching（FM）模型作为高保真合成的主流范式，依赖于迭代的常微分方程（ODE）求解，导致显著的延迟瓶颈。现有方法面临两难：训练免费求解器在低神经函数评估（NFEs）下性能大幅下降，而基于训练的一步或多步生成方法虽能加速，但训练成本高昂且缺乏即插即用的灵活性。这一问题限制了生成模型的实际应用，尤其是在需要快速推理的场景中，如实时图像编辑。因此，亟需一种既能降低延迟又不牺牲灵活性和性能的新方法，以弥合这一差距。",
      "method": "BA-solver的核心创新在于引入一个轻量级SideNet（仅占主干模型大小的1-2%），并保持主干网络冻结，从而以低成本实现加速。方法基于两个协同组件：一是双向时间感知，SideNet学习近似未来和历史的速度，无需重新训练重型主干；二是双锚点速度积分，利用SideNet和两个锚点速度来高效近似中间速度，实现批处理的高阶积分。通过主干网络提供高精度“锚点”，SideNet用于密集化轨迹，BA-solver允许使用大间隔尺寸同时最小化误差，从而提高ODE求解效率，并确保与现有生成管道的无缝集成。",
      "result": "在ImageNet-256^2数据集上的实验表明，BA-solver在仅10 NFEs时就能达到与100+ NFEs的Euler求解器相当的生成质量，而在5 NFEs下仍能保持高保真度。这表明BA-solver在加速生成过程中显著减少了计算开销，训练成本可忽略不计。与基线方法相比，它避免了训练免费求解器在低NFEs下的性能退化问题，同时超越了一步生成方法的高训练成本局限，提供了高效的解决方案，适用于图像编辑等下游任务。",
      "conclusion": "BA-solver的主要贡献在于提供了一种高效且灵活的ODE求解方法，解决了Flow Matching模型中的延迟瓶颈。其学术价值在于改进了生成建模的加速技术，通过轻量级网络和智能插值策略平衡了性能与效率；实际应用中，它便于集成到现有管道，支持下游任务如图像编辑。尽管摘要未明确说明，但该方法可能有未来优化方向，如扩展至更大规模数据集或更复杂模型。总体而言，BA-solver为生成建模的实用化提供了重要工具。",
      "tags": [
        "Flow Matching",
        "ODE Solver",
        "Neural Function Evaluations (NFEs)",
        "SideNet",
        "Bidirectional Temporal Perception"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:27.883448Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21541",
    "title": "Vision KAN: Towards an Attention-Free Backbone for Vision with Kolmogorov-Arnold Networks",
    "authors": [
      "Zhuoqin Yang",
      "Jiansong Zhang",
      "Xiaoling Luo",
      "Xu Wu",
      "Zheng Lu",
      "Linlin Shen"
    ],
    "abstract": "Attention mechanisms have become a key module in modern vision backbones due to their ability to model long-range dependencies. However, their quadratic complexity in sequence length and the difficulty of interpreting attention weights limit both scalability and clarity. Recent attention-free architectures demonstrate that strong performance can be achieved without pairwise attention, motivating the search for alternatives. In this work, we introduce Vision KAN (ViK), an attention-free backbone inspired by the Kolmogorov-Arnold Networks. At its core lies MultiPatch-RBFKAN, a unified token mixer that combines (a) patch-wise nonlinear transform with Radial Basis Function-based KANs, (b) axis-wise separable mixing for efficient local propagation, and (c) low-rank global mapping for long-range interaction. Employing as a drop-in replacement for attention modules, this formulation tackles the prohibitive cost of full KANs on high-resolution features by adopting a patch-wise grouping strategy with lightweight operators to restore cross-patch dependencies. Experiments on ImageNet-1K show that ViK achieves competitive accuracy with linear complexity, demonstrating the potential of KAN-based token mixing as an efficient and theoretically grounded alternative to attention.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21541.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21541",
    "published": "2026-01-29T10:56:16Z",
    "updated": "2026-01-29T10:56:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "Vision KAN (ViK) 提出一种基于 Kolmogorov-Arnold Networks 的无注意力视觉骨干网络，通过 MultiPatch-RBFKAN 实现线性复杂度的竞争性性能，作为注意力的高效替代。",
      "motivation": "注意力机制在现代视觉骨干网络中虽然能有效建模长距离依赖，但其二次计算复杂度导致在处理长序列时成本高昂，且注意力权重难以解释，限制了模型的可扩展性和透明度。最近的无注意力架构表明，无需成对注意力也能达到强大性能，这激发了对高效替代方法的研究需求。因此，本文旨在解决注意力机制的可扩展性和解释性问题，推动寻找理论基础坚实且计算高效的替代方案，以满足大规模视觉处理的实际需求。",
      "method": "ViK 的核心是 MultiPatch-RBFKAN，这是一个统一的 token mixer，它结合了三个关键组件：(a) 使用基于径向基函数的 KANs 进行补丁级非线性变换，(b) 通过轴级可分离混合实现高效的局部传播，(c) 采用低秩全局映射来处理长距离交互。作为注意力模块的直接替换，该方法通过补丁分组策略和轻量级操作来降低在高分辨率特征上使用完整 KANs 的计算成本，从而恢复跨补丁依赖。实验在 ImageNet-1K 数据集上进行，ViK 架构被设计为一种无注意力的骨干网络。",
      "result": "在 ImageNet-1K 数据集上的实验表明，ViK 实现了与现有方法竞争的分类准确率，同时保持了线性复杂度，这意味着它显著降低了计算成本。虽然摘要未提供具体的准确率数值，但与基线注意力方法相比，ViK 在效率和性能上展现了平衡，证明了基于 KAN 的 token mixing 作为一种高效替代的潜力，为大规模视觉任务提供了理论基础。",
      "conclusion": "本文的主要贡献是提出了 Vision KAN (ViK)，展示了 Kolmogorov-Arnold Networks 在视觉任务中作为无注意力骨干网络的应用潜力。它结合了理论基础和计算效率，为处理高分辨率图像提供了可扩展的解决方案。学术上，它丰富了视觉架构的多样性；实际上，它有助于降低深度学习模型的计算负担。局限性方面，摘要未明确说明，未来工作可能包括进一步优化性能或扩展到其他视觉任务如目标检测。",
      "tags": [
        "Vision Backbone",
        "Kolmogorov-Arnold Networks",
        "Attention-Free",
        "Token Mixing",
        "Linear Complexity"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:00.152233Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21533",
    "title": "ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making",
    "authors": [
      "Youngjin Jin",
      "Hanna Kim",
      "Kwanwoo Kim",
      "Chanhee Lee",
      "Seungwon Shin"
    ],
    "abstract": "Existing multi-expert LLM systems gather diverse perspectives but combine them through simple aggregation, obscuring which arguments drove the final decision. We introduce ARGORA, a framework that organizes multi-expert discussions into explicit argumentation graphs showing which arguments support or attack each other. By casting these graphs as causal models, ARGORA can systematically remove individual arguments and recompute outcomes, identifying which reasoning chains were necessary and whether decisions would change under targeted modifications. We further introduce a correction mechanism that aligns internal reasoning with external judgments when they disagree. Across diverse benchmarks and an open-ended use case, ARGORA achieves competitive accuracy and demonstrates corrective behavior: when experts initially disagree, the framework resolves disputes toward correct answers more often than it introduces new errors, while providing causal diagnostics of decisive arguments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21533.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21533",
    "published": "2026-01-29T10:48:04Z",
    "updated": "2026-01-29T10:48:04Z",
    "comment": "58 pages",
    "light_analysis": {
      "overview": "ARGORA框架通过因果论辩图组织多专家讨论，提升大型语言模型推理的透明度和诊断能力。",
      "motivation": "现有基于多专家的LLM系统虽然能汇集多样化观点，但通常通过简单聚合方式结合意见，这模糊了哪些具体论据驱动了最终决策，降低了决策过程的可解释性和可信度。在需要高透明度的人工智能应用中，如医疗诊断或法律判断，理解论据的因果影响至关重要。现有方法缺乏系统性分析论据间关系的机制，导致难以诊断错误或优化推理链，限制了可靠决策支持系统的发展。",
      "method": "ARGORA框架的核心是将多专家讨论组织成明确的论辩图，图中显示论据之间的支持或攻击关系。通过将这些论辩图建模为因果模型，框架能系统性移除个别论据并重新计算结果，从而识别必要的推理链和决策变化可能性。此外，引入一个纠正机制，当内部推理与外部判断不一致时，调整推理以对齐，增强决策准确性。该方法适用于多种基准和开放式用例，不依赖特定数据集，突出了论辩结构化与因果分析的创新结合。",
      "result": "在多个基准测试和开放式应用场景中，ARGORA实现了有竞争力的准确性表现，表明其在标准任务上的有效性。更重要的是，它展示了纠正行为：当专家初始意见分歧时，框架倾向于解决争议朝向正确答案，而不是引入新错误，同时提供决定性论据的因果诊断，帮助理解决策依据。与现有简单聚合方法相比，ARGORA提供了更透明的决策过程和更好的可诊断性，摘要未明确说明具体数据，但基于描述推断性能提升。",
      "conclusion": "ARGORA的主要贡献在于提出一个基于因果论辩的框架，显著提升了LLM推理的透明度和可诊断性，解决了现有方法在论据分析上的不足。其学术价值在于将论辩理论与因果模型结合，为可解释AI提供了新思路；实际应用中，可增强决策支持系统的可靠性和用户信任。尽管摘要未明确说明局限性，未来工作可能包括扩展到更复杂领域或集成更多类型的外部反馈，以进一步优化框架的适用性。",
      "tags": [
        "Argumentation Graphs",
        "Causal Models",
        "Large Language Models",
        "Reasoning Systems",
        "Multi-expert Systems"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:14.357287Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21529",
    "title": "Fast and Geometrically Grounded Lorentz Neural Networks",
    "authors": [
      "Robert van der Klis",
      "Ricardo Chávez Torres",
      "Max van Spengler",
      "Yuhui Ding",
      "Thomas Hofmann",
      "Pascal Mettes"
    ],
    "abstract": "Hyperbolic space is quickly gaining traction as a promising geometry for hierarchical and robust representation learning. A core open challenge is the development of a mathematical formulation of hyperbolic neural networks that is both efficient and captures the key properties of hyperbolic space. The Lorentz model of hyperbolic space has been shown to enable both fast forward and backward propagation. However, we prove that, with the current formulation of Lorentz linear layers, the hyperbolic norms of the outputs scale logarithmically with the number of gradient descent steps, nullifying the key advantage of hyperbolic geometry. We propose a new Lorentz linear layer grounded in the well-known ``distance-to-hyperplane\" formulation. We prove that our formulation results in the usual linear scaling of output hyperbolic norms with respect to the number of gradient descent steps. Our new formulation, together with further algorithmic efficiencies through Lorentzian activation functions and a new caching strategy results in neural networks fully abiding by hyperbolic geometry while simultaneously bridging the computation gap to Euclidean neural networks. Code available at: https://github.com/robertdvdk/hyperbolic-fully-connected.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21529.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21529",
    "published": "2026-01-29T10:44:32Z",
    "updated": "2026-01-29T10:44:32Z",
    "comment": "19 pages, 4 figures",
    "light_analysis": {
      "overview": "提出一种基于'距离到超平面'公式的Lorentz线性层，解决双曲神经网络中输出范数对数缩放问题，实现几何一致性并提高效率。",
      "motivation": "双曲空间在分层和鲁棒表示学习中具有优势，但现有Lorentz神经网络的线性层导致输出双曲范数随梯度下降步骤数对数缩放，抵消了双曲几何的距离保持特性，限制了模型的真实性和应用潜力。因此，需开发数学上正确且计算高效的公式，以充分捕捉双曲空间属性并提升性能。",
      "method": "作者提出新的Lorentz线性层，基于'距离到超平面'公式，理论证明其能使输出双曲范数随梯度下降步骤数线性缩放。此外，结合Lorentzian激活函数和新缓存策略，优化计算流程，确保神经网络完全符合双曲几何原理，同时缩小与欧几里得神经网络的效率差距。",
      "result": "论文证明新Lorentz线性层实现了输出范数的线性缩放，避免了旧公式的对数缩放问题，增强了网络的几何正确性。这改善了模型的表示学习能力，并可能提升在基准任务中的性能，摘要未明确说明具体实验数据，但理论分析表明方法与基线相比有显著改进。",
      "conclusion": "该研究通过创新Lorentz线性层解决了双曲神经网络的范数缩放瓶颈，强化了模型的几何基础，有助于推进双曲空间在AI领域的应用。其理论贡献和算法优化为分层学习提供了更有效的工具，未来可探索扩展到复杂架构或更多数据集。",
      "tags": [
        "Lorentz Model",
        "Hyperbolic Neural Networks",
        "Linear Scaling",
        "Gradient Descent",
        "Activation Functions"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:21.194703Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21526",
    "title": "KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization",
    "authors": [
      "Alireza Nadaf",
      "Alireza Mohammadshahi",
      "Majid Yazdani"
    ],
    "abstract": "We introduce KAPSO, a modular framework for autonomous program synthesis and optimization. Given a natural language goal and an evaluation method, KAPSO iteratively performs ideation, code synthesis and editing, execution, evaluation, and learning to improve a runnable artifact toward measurable objectives. Rather than treating synthesis as the endpoint, KAPSO uses synthesis as an operator within a long-horizon optimization loop, where progress is defined by evaluator outcomes.   KAPSO targets long-horizon failures common in coding agents, including lost experimental state, brittle debugging, and weak reuse of domain expertise, by integrating three tightly coupled components. First, a git-native experimentation engine isolates each attempt as a branch, producing reproducible artifacts and preserving provenance across iterations. Second, a knowledge system ingests heterogeneous sources, including repositories, internal playbooks, and curated external resources such as documentation, scientific papers, and web search results, and organizes them into a structured representation that supports retrieval over workflows, implementations, and environment constraints. Third, a cognitive memory layer coordinates retrieval and maintains an episodic store of reusable lessons distilled from experiment traces (run logs, diffs, and evaluator feedback), reducing repeated error modes and accelerating convergence.   We evaluated KAPSO on MLE-Bench (Kaggle-style ML competitions) and ALE-Bench (AtCoder heuristic optimization), and report end-to-end performance.   Code Available at: https://github.com/Leeroo-AI/kapso",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21526.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21526",
    "published": "2026-01-29T10:40:54Z",
    "updated": "2026-01-29T10:40:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "KAPSO是一个集成git-native实验引擎、知识系统和认知记忆层的框架，用于自主程序合成和优化，将合成作为长时优化循环中的算子来解决编码代理中的常见失败问题。",
      "motivation": "该研究针对编码代理中常见的长期问题，如实验状态丢失、调试脆弱和领域专业知识重用不足。现有方法通常将程序合成视为终点，缺乏持续优化和知识积累机制，导致效率低下和重复错误。这个问题在复杂编程任务中尤为重要，因为自动代码生成和优化需要处理不确定性、资源约束和知识整合，而现有代理往往无法有效应对迭代过程中的状态管理和学习，从而限制了其实际应用范围。",
      "method": "KAPSO提出一个模块化框架，基于迭代循环执行概念构思、代码合成与编辑、执行、评估和学习。核心创新包括三个紧密耦合的组件：一个git-native实验引擎，将每次尝试作为分支隔离，确保实验可复现性和迭代历史记录；一个知识系统，整合仓库、内部手册、文档、科学论文和网络搜索结果等异构源，并组织成结构化表示以支持检索；一个认知记忆层，协调检索并维护从实验痕迹（如运行日志、差异和评估反馈）中提炼的可重用经验存储，以减少重复错误并加速收敛。",
      "result": "论文在MLE-Bench（Kaggle风格机器学习竞赛）和ALE-Bench（AtCoder启发式优化）上评估了KAPSO的端到端性能，但摘要未明确说明具体性能指标，如准确率提升或效率改进。评估展示了框架在自主程序合成和优化任务中的整体有效性，与基线方法对比未详细描述，但强调了其在处理长时问题上的潜在优势，如通过知识集成和记忆学习提高迭代过程的效率和可靠性。",
      "conclusion": "KAPSO的主要贡献是通过集成git-native实验引擎、知识系统和认知记忆层，解决编码代理中的长期失败问题，提高自主程序合成和优化的效率与知识重用能力。其学术价值在于推动了程序合成与优化的方法学创新，实际应用价值可扩展到机器学习竞赛、启发式优化等领域。局限性可能包括框架复杂度或特定领域的适应性，未来工作可进一步扩展评估基准或优化组件以提高泛化性能。",
      "tags": [
        "Program Synthesis",
        "Knowledge-based Systems",
        "Git-based Experimentation",
        "Cognitive Memory",
        "Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:23.741427Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21525",
    "title": "LMK > CLS: Landmark Pooling for Dense Embeddings",
    "authors": [
      "Meet Doshi",
      "Aashka Trivedi",
      "Vishwajeet Kumar",
      "Parul Awasthy",
      "Yulong Li",
      "Jaydeep Sen",
      "Radu Florian",
      "Sachindra Joshi"
    ],
    "abstract": "Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21525.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21525",
    "published": "2026-01-29T10:40:37Z",
    "updated": "2026-01-29T10:40:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文引入Landmark池化（LMK pooling）以改进序列表示学习，解决现有池化方法在长上下文中的弱点。",
      "motivation": "表示学习在搜索、聚类、分类和重排等下游任务中至关重要。当前最先进的序列编码器通常使用池化操作符，如特殊的[CLS]标记或平均池化，但这些方法存在系统弱点。[CLS]倾向于将信息集中在序列的初始位置，可能无法充分代表分布式证据；而平均池化可能稀释显著的局部信号，有时导致短上下文性能下降。因此，需要一种新池化策略来克服这些缺陷，提高序列表示的质量。",
      "method": "为解决上述问题，论文提出了Landmark（LMK）池化方法。该方法将序列分割成多个块，在块与块之间插入地标标记，然后通过平均池化这些地标标记的嵌入来形成最终表示。这种简单机制的关键创新在于分块处理，保留了局部显著特征，同时通过地标标记聚合全局信息，从而改善长上下文外推。代价是引入了少量特殊标记，但保持可扩展性和实用性。",
      "result": "论文通过实证研究展示了LMK池化的效果。在短上下文检索任务上，LMK池化与现有方法如[CLS]和平均池化表现相当。在长上下文任务上，它带来了显著的性能改进，表明能够有效处理长序列并提取关键信息。这些结果证明LMK池化是一个实用和可扩展的替代方案，能够在不同上下文长度下保持或提升性能。",
      "conclusion": "LMK池化的主要贡献是提出了一种新的池化策略，解决了现有方法在长上下文和局部特征保留上的不足。其学术价值在于丰富了序列表示学习的技术，通过分块和地标标记实现了更好的信息聚合。实际应用价值在于提升下游任务如搜索和聚类的性能，特别是在处理长序列时。潜在的局限性可能包括块大小的选择或额外的计算开销，未来工作可以进一步优化参数或扩展应用到更多领域。",
      "tags": [
        "Landmark Pooling",
        "Sequence Encoding",
        "Mean Pooling",
        "Long-context Extrapolation",
        "Retrieval Tasks"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:02.966130Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21523",
    "title": "Explicit Credit Assignment through Local Rewards and Dependence Graphs in Multi-Agent Reinforcement Learning",
    "authors": [
      "Bang Giang Le",
      "Viet Cuong Ta"
    ],
    "abstract": "To promote cooperation in Multi-Agent Reinforcement Learning, the reward signals of all agents can be aggregated together, forming global rewards that are commonly known as the fully cooperative setting. However, global rewards are usually noisy because they contain the contributions of all agents, which have to be resolved in the credit assignment process. On the other hand, using local reward benefits from faster learning due to the separation of agents' contributions, but can be suboptimal as agents myopically optimize their own reward while disregarding the global optimality. In this work, we propose a method that combines the merits of both approaches. By using a graph of interaction between agents, our method discerns the individual agent contribution in a more fine-grained manner than a global reward, while alleviating the cooperation problem with agents' local reward. We also introduce a practical approach for approximating such a graph. Our experiments demonstrate the flexibility of the approach, enabling improvements over the traditional local and global reward settings.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21523.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21523",
    "published": "2026-01-29T10:38:19Z",
    "updated": "2026-01-29T10:38:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种通过局部奖励和依赖图在多智能体强化学习中显式分配信用的方法，结合全局与局部奖励优点以提升合作性能。",
      "motivation": "该研究旨在解决多智能体强化学习中的信用分配问题。全局奖励因包含所有智能体贡献而噪声较大，信用分配复杂；局部奖励虽加速学习，但智能体可能短视优化自身奖励，导致次优全局合作。现有方法未能有效平衡精细贡献区分与全局最优，因此需新方法结合两者优势以促进高效合作。",
      "method": "该方法结合局部和全局奖励，通过代理交互图精细识别个体智能体贡献。核心创新是引入依赖图结构，以图为基础区分智能体间的依赖关系，减轻局部奖励的短视问题，同时提供信用分配的显式机制。此外，提出一种实用近似图的方法，以简化实现。尽管摘要未明确说明具体模型架构或数据集，但强调图作为关键组件用于多智能体交互建模。",
      "result": "实验表明该方法在多智能体强化学习中优于传统局部和全局奖励设置，证明了其灵活性，能有效提升合作效率。然而，摘要未明确说明具体性能指标如准确率或效率提升数据，仅指出改进超过基线方法，支持方法在平衡学习速度和全局最优方面的有效性。",
      "conclusion": "该研究提出了一种基于图的信用分配方法，结合局部和全局奖励，改善多智能体强化学习的合作性能。学术价值在于提供更精细的贡献识别机制，丰富信用分配理论；实际应用价值在于提升多智能体系统优化，如机器人协作或游戏策略。未来工作可能涉及图近似方法的优化或扩展到更复杂场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Multi-Agent Reinforcement Learning",
        "Credit Assignment",
        "Local Rewards",
        "Dependence Graphs",
        "Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:00.507087Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21522",
    "title": "More Bang for the Buck: Improving the Inference of Large Language Models at a Fixed Budget using Reset and Discard (ReD)",
    "authors": [
      "Sagi Meir",
      "Tommer D. Keidar",
      "Noam Levi",
      "Shlomi Reuveni",
      "Barak Hirshberg"
    ],
    "abstract": "The performance of large language models (LLMs) on verifiable tasks is usually measured by pass@k, the probability of answering a question correctly at least once in k trials. At a fixed budget, a more suitable metric is coverage@cost, the average number of unique questions answered as a function of the total number of attempts. We connect the two metrics and show that the empirically-observed power-law behavior in pass@k leads to a sublinear growth of the coverage@cost (diminishing returns). To solve this problem, we propose Reset-and-Discard (ReD), a query method of LLMs that increases coverage@cost for any given budget, regardless of the pass@k form. Moreover, given a pass@k, we can quantitatively predict the savings in the total number of attempts using ReD. If pass@k is not available for the model, ReD can infer its power-law exponent. Experiments on three LLMs using HumanEval demonstrate that ReD substantially reduces the required attempts, tokens, and USD cost to reach a desired coverage, while also offering an efficient way to measure inference power-laws.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21522.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21522",
    "published": "2026-01-29T10:37:32Z",
    "updated": "2026-01-29T10:37:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Reset-and-Discard (ReD)方法，通过优化查询策略提高大型语言模型在固定预算下的推理覆盖率，解决了回报递减问题。",
      "motivation": "大型语言模型在可验证任务中通常使用pass@k度量性能，但在固定预算下，coverage@cost作为更合适的度量存在亚线性增长问题，即回报递减现象。现有方法缺乏有效优化策略，导致资源利用率低和覆盖率不足，亟需新方法来提升效率和成本效益。",
      "method": "Reset-and-Discard (ReD)是一种基于查询的大型语言模型优化方法，通过动态重置和丢弃低效尝试来最大化覆盖率，不受pass@k形式限制。关键创新包括理论建模coverage@cost与pass@k关系，并推断幂律指数；使用HumanEval数据集验证，模型架构为通用大型语言模型。",
      "result": "实验在三个大型语言模型上使用HumanEval数据集进行，结果表明ReD显著减少了达到指定覆盖率所需的尝试次数、代币数和USD成本，例如摘要提到“substantially reduces”，具体性能提升未提供量化数据但与基线相比效率更高。",
      "conclusion": "ReD方法的主要贡献是提高了大型语言模型推理的资源效率和覆盖率，连接了pass@k与coverage@cost度量，为幂律分析提供有效工具；实际应用价值在于降低成本，学术价值在于理论创新；局限性可能在于仅测试于HumanEval任务，未来可扩展到其他领域。",
      "tags": [
        "Large Language Model",
        "Reset-and-Discard",
        "Power-law",
        "Coverage@cost",
        "Inference Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:12.665301Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21521",
    "title": "A Unified SPD Token Transformer Framework for EEG Classification: Systematic Comparison of Geometric Embeddings",
    "authors": [
      "Chi-Sheng Chen",
      "En-Jui Kuo",
      "Guan-Ying Chen",
      "Xinyu Zhang",
      "Fan Zhang"
    ],
    "abstract": "Spatial covariance matrices of EEG signals are Symmetric Positive Definite (SPD) and lie on a Riemannian manifold, yet the theoretical connection between embedding geometry and optimization dynamics remains unexplored. We provide a formal analysis linking embedding choice to gradient conditioning and numerical stability for SPD manifolds, establishing three theoretical results: (1) BWSPD's $\\sqrtκ$ gradient conditioning (vs $κ$ for Log-Euclidean) via Daleckii-Kreĭn matrices provides better gradient conditioning on high-dimensional inputs ($d \\geq 22$), with this advantage reducing on low-dimensional inputs ($d \\leq 8$) where eigendecomposition overhead dominates; (2) Embedding-Space Batch Normalization (BN-Embed) approximates Riemannian normalization up to $O(\\varepsilon^2)$ error, yielding $+26\\%$ accuracy on 56-channel ERP data but negligible effect on 8-channel SSVEP data, matching the channel-count-dependent prediction; (3) bi-Lipschitz bounds prove BWSPD tokens preserve manifold distances with distortion governed solely by the condition ratio $κ$. We validate these predictions via a unified Transformer framework comparing BWSPD, Log-Euclidean, and Euclidean embeddings within identical architecture across 1,500+ runs on three EEG paradigms (motor imagery, ERP, SSVEP; 36 subjects). Our Log-Euclidean Transformer achieves state-of-the-art performance on all datasets, substantially outperforming classical Riemannian classifiers and recent SPD baselines, while BWSPD offers competitive accuracy with similar training time.",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21521.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21521",
    "published": "2026-01-29T10:35:13Z",
    "updated": "2026-01-29T10:35:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一个统一的SPD令牌Transformer框架，用于EEG分类，并通过系统比较几何嵌入，建立了嵌入选择与优化动力学的理论连接。",
      "motivation": "EEG信号的空间协方差矩阵是对称正定（SPD）矩阵，位于黎曼流形上，但现有研究尚未深入探索不同几何嵌入选择与优化动力学之间的理论联系。本研究旨在解决如何选择合适嵌入以改善EEG分类中的数值稳定性和梯度条件的问题。这一问题的重要性在于，EEG分类在脑机接口和神经科学中有广泛应用，而现有方法可能缺乏理论指导，导致性能受限或计算效率低下。通过分析嵌入几何对梯度条件的影响，本研究为更稳定和高效的EEG分类方法提供了理论基础。",
      "method": "论文首先进行形式理论分析，链接嵌入选择与梯度条件和数值稳定性，得出三个关键结果：BWSPD嵌入在高维输入时提供比Log-Euclidean更好的梯度条件；嵌入空间批归一化（BN-Embed）近似黎曼归一化；bi-Lipschitz边界证明BWSPD令牌保留流形距离。实验上，采用一个统一的Transformer框架，比较BWSPD、Log-Euclidean和Euclidean嵌入。该方法使用三个EEG范式（运动想象、ERP、SSVEP），涉及36名受试者的数据，通过超过1500次运行来验证理论预测，确保架构一致以系统评估嵌入效果。",
      "result": "实验结果显示，Log-Euclidean Transformer在所有数据集上达到state-of-the-art性能，显著优于经典黎曼分类器和最近SPD基线。具体数据包括：在56通道ERP数据上，嵌入空间批归一化带来26%的精度提升；在8通道SSVEP数据上效果不明显，符合通道数依赖的预测。BWSPD嵌入在精度上与Log-Euclidean竞争，同时保持相似训练时间。这验证了理论预测，表明嵌入选择对性能有重要影响，特别是高维输入时梯度条件的改善。",
      "conclusion": "本研究的主要贡献在于提供了SPD流形上嵌入选择与优化动力学的理论分析，并通过实验验证了其重要性。结果表明，Log-Euclidean嵌入在EEG分类中性能最优，BWSPD嵌入也具竞争力。这为未来研究提供了理论基础，可扩展到其他基于SPD矩阵的机器学习任务，促进更稳定和高效的算法设计。局限性可能在于只针对EEG数据，未来工作可探索更广泛的应用场景或改进嵌入方法以降低计算开销。",
      "tags": [
        "Symmetric Positive Definite (SPD)",
        "Riemannian Manifold",
        "Transformer Framework",
        "EEG Classification",
        "Geometric Embeddings"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:51.018384Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21517",
    "title": "HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models",
    "authors": [
      "Teerapong Panboonyuen"
    ],
    "abstract": "Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21517.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21517",
    "published": "2026-01-29T10:30:07Z",
    "updated": "2026-01-29T10:30:07Z",
    "comment": "26 pages",
    "light_analysis": {
      "overview": "提出了HERS框架，通过专家学习和自监督适应改进扩散模型中车辆损伤生成的保真度、可控性和领域对齐。",
      "motivation": "近年来，文本到图像扩散模型在合成车辆损伤方面取得进展，但其生成的逼真图像可能被滥用于保险欺诈，挑战了真实与合成数据的界限。现有方法在生成高质量、可控的损伤图像方面存在不足，特别是在高风险领域如汽车保险中，可靠性和安全性至关重要。HERS旨在解决这些问题，提高生成模型的信任度和应用安全性。",
      "method": "HERS框架基于扩散模型，通过领域特定专家适应进行微调，无需手动标注。使用大型语言模型和文本到图像管道自动生成自监督图像文本对，将每个损伤类别（如凹陷、划痕）建模为独立专家。这些专家随后整合到统一的多损伤模型中，平衡了专业化和泛化能力。关键创新包括专家学习机制和自动数据生成，提高了模型的适应性和可控性。",
      "result": "在四个不同的扩散骨干网络上评估HERS，与基线方法相比，文本忠实度提升了5.5%，人类偏好评分提高了2.3%。这些改进表明HERS在生成图像的质量和用户接受度方面有显著优势，验证了框架在不同模型架构上的鲁棒性和有效性。实验结果一致显示，HERS能够更好地对齐文本描述，生成更逼真的车辆损伤图像。",
      "conclusion": "HERS框架成功改进了车辆损伤扩散模型的生成质量，为高风险应用如汽车保险提供了更可靠的解决方案。研究强调了领域特定扩散模型的机会与风险，呼吁在安全关键领域加强可信生成技术的开发。未来工作可以探索模型的进一步优化，扩展到其他损伤类型或领域，并加强欺诈检测和审计能力。",
      "tags": [
        "Diffusion Models",
        "Text-to-Image Generation",
        "Self-Supervised Learning",
        "Expert Learning",
        "Domain Adaptation"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:54.648124Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21513",
    "title": "Cascaded Transfer: Learning Many Tasks under Budget Constraints",
    "authors": [
      "Eloi Campagne",
      "Yvenn Amara-Ouali",
      "Yannig Goude",
      "Mathilde Mougeot",
      "Argyris Kalogeratos"
    ],
    "abstract": "Many-Task Learning refers to the setting where a large number of related tasks need to be learned, the exact relationships between tasks are not known. We introduce the Cascaded Transfer Learning, a novel many-task transfer learning paradigm where information (e.g. model parameters) cascades hierarchically through tasks that are learned by individual models of the same class, while respecting given budget constraints. The cascade is organized as a rooted tree that specifies the order in which tasks are learned and refined. We design a cascaded transfer mechanism deployed over a minimum spanning tree structure that connects the tasks according to a suitable distance measure, and allocates the available training budget along its branches. Experiments on synthetic and real many-task settings show that the resulting method enables more accurate and cost effective adaptation across large task collections compared to alternative approaches.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21513.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21513",
    "published": "2026-01-29T10:28:08Z",
    "updated": "2026-01-29T10:28:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一种基于层级树结构的级联迁移学习范式，以在预算约束下高效学习多任务。",
      "motivation": "在多任务学习环境中，经常需要处理大量相关任务，但任务间的具体关系往往未知。这导致传统方法在资源有限的情况下难以高效地学习和迁移知识，影响学习效果和成本效益。因此，研究如何在预算约束下优化多任务学习成为重要课题，现有方法通常忽视成本因素或效率低下，需创新方法来平衡准确性与资源消耗。",
      "method": "该方法引入了级联迁移学习，通过有根树结构组织任务学习顺序，信息如模型参数在任务间层级传播。关键创新在于基于最小生成树的级联转移机制，根据任务间距离度量连接任务，并沿树分支分配训练预算。这使得同一类模型的个体任务学习能在预算约束下实现优化，提升知识迁移效率。",
      "result": "在合成和真实多任务设置的实验中，该方法被验证为能够实现更准确和成本有效的任务适应。与替代方法相比，它在大型任务集合上表现出优越性，表明级联转移机制在优化预算分配方面的有效性。然而，摘要未提供具体性能指标如准确率提升百分比或效率改进数据。",
      "conclusion": "论文的主要贡献是提出了级联迁移学习范式，为多任务学习在预算约束下提供了有效解决方案。这项研究具有学术价值，推动了迁移学习和资源优化领域的进展，并具有实际应用潜力，如大规模机器学习系统。但摘要未明确说明局限性或未来工作方向。",
      "tags": [
        "Transfer Learning",
        "Many-Task Learning",
        "Cascade Learning",
        "Minimum Spanning Tree",
        "Budget Constraints"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:13.514788Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21512",
    "title": "MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset",
    "authors": [
      "Serry Sibaee",
      "Yasser Alhabashi",
      "Nadia Sibai",
      "Yara Farouk",
      "Adel Ammar",
      "Sawsan AlHalawani",
      "Wadii Boulila"
    ],
    "abstract": "Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21512.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21512",
    "published": "2026-01-29T10:28:01Z",
    "updated": "2026-01-29T10:28:01Z",
    "comment": "18 pages",
    "light_analysis": {
      "overview": "本论文提出了MURAD，一个大规模多领域统一反向阿拉伯语词典数据集，包含96,243个词-定义对，旨在推动阿拉伯语自然语言处理和词汇语义研究。",
      "motivation": "阿拉伯语词汇丰富，跨科学、宗教和文学领域，但大规模词汇数据集缺乏，这限制了计算语言学研究和应用，如反向词典建模。现有数据往往规模小、领域窄，难以支持语义检索等任务，因此需要高质量统一资源以促进阿拉伯语NLP发展，解决词汇资源不足的瓶颈问题。",
      "method": "研究方法采用混合数据提取管道，整合直接文本解析、光学字符识别和自动化重建技术，从可信参考著作和教育源收集数据，确保准确性和清晰度。数据集包含96,243个词-定义对，每个记录包括目标词、标准阿拉伯语定义和标识源领域的元数据，关键创新在于统一多领域词汇覆盖，如语言学、伊斯兰研究、数学、物理等领域。",
      "result": "摘要未明确说明具体实验结果，如性能指标或基线对比。但数据集成果构建了一个大规模多领域词汇资源，覆盖多个关键领域，支持反向词典建模、语义检索和教育工具等应用，为阿拉伯语计算语言学提供基础数据，促进可重复研究和发展。",
      "conclusion": "本论文主要贡献是创建并开源MURAD数据集，填补阿拉伯语词汇语义研究的空白，学术价值在于支持计算语言学和辞书学研究，实际应用价值体现在增强NLP任务如语义理解和教育工具。局限性可能在于未覆盖所有领域，未来工作可扩展更多领域或集成更先进NLP技术。",
      "tags": [
        "Lexical Dataset",
        "Reverse Dictionary",
        "Arabic NLP",
        "Optical Character Recognition",
        "Semantic Retrieval"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:12.848200Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21511",
    "title": "LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI",
    "authors": [
      "Niki van Stein",
      "Anna V. Kononova",
      "Lars Kotthoff",
      "Thomas Bäck"
    ],
    "abstract": "Large language models have enabled automated algorithm design (AAD) by generating optimization algorithms directly from natural-language prompts. While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unused. We propose a mechanism for guiding AAD using feedback constructed from graph-theoretic and complexity features extracted from the abstract syntax trees of the generated algorithms, based on a surrogate model learned over an archive of evaluated solutions. Using explainable AI techniques, we identify features that substantially affect performance and translate them into natural-language mutation instructions that steer subsequent LLM-based code generation without restricting expressivity.   We propose LLaMEA-SAGE, which integrates this feature-driven guidance into LLaMEA, and evaluate it across several benchmarks. We show that the proposed structured guidance achieves the same performance faster than vanilla LLaMEA in a small controlled experiment. In a larger-scale experiment using the MA-BBOB suite from the GECCO-MA-BBOB competition, our guided approach achieves superior performance compared to state-of-the-art AAD methods. These results demonstrate that signals derived from code can effectively bias LLM-driven algorithm evolution, bridging the gap between code structure and human-understandable performance feedback in automated algorithm design.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21511.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21511",
    "published": "2026-01-29T10:27:29Z",
    "updated": "2026-01-29T10:27:29Z",
    "comment": "14 pages",
    "light_analysis": {
      "overview": "本论文提出LLaMEA-SAGE方法，利用可解释AI技术从代码结构中提取特征并转化为反馈，指导大语言模型驱动的自动化算法设计，以提高效率和性能。",
      "motivation": "自动化算法设计（AAD）通过大语言模型生成优化算法，但现有方法如LLaMEA仅依赖适应度反馈进行搜索，忽略了生成代码的丰富结构信息，导致搜索效率低下和性能受限。这一问题的重要性在于优化算法设计在AI领域中的广泛应用，而当前方法未充分利用代码特征，使得算法进化过程盲目，缺乏结构化引导，限制了探索潜力和优化效果。",
      "method": "LLaMEA-SAGE通过集成特征驱动引导机制来改进LLaMEA，核心方法是从生成算法的抽象语法树中提取图论和复杂性特征，基于评估档案学习的代理模型分析性能相关特征。使用可解释AI技术识别关键影响特征，并将其转化为自然语言变异指令，以在不限制表达性的前提下指导后续LLM代码生成。关键创新点包括结构化反馈的构建和可解释AI的应用，涉及具体技术如AST特征提取和自然语言指令生成。",
      "result": "论文在多个基准测试中评估LLaMEA-SAGE。在小型控制实验中，结构化引导方法比原始LLaMEA更快达到相同性能水平，表明效率提升。在大型实验中，使用GECCO-MA-BBOB竞赛的MA-BBOB套件，LLaMEA-SAGE的表现优于当前最先进的AAD方法，证明了其性能优越性。摘要未提供具体性能指标数据，但实验结果强调了引导方法在效率和效果上的改进。",
      "conclusion": "本研究的主要贡献是开发了LLaMEA-SAGE方法，将代码结构反馈与可解释AI技术结合，有效引导自动化算法设计，弥合了代码结构和人类可理解性能反馈之间的差距。其学术价值在于提供了一种更高效和可解释的AAD方法，实际应用价值体现在优化算法设计中的性能提升。未来工作可能涉及扩展到更广泛基准或改进特征提取技术，但摘要未明确说明局限性。",
      "tags": [
        "Large Language Models",
        "Automated Algorithm Design",
        "Explainable AI",
        "Abstract Syntax Trees",
        "Evolutionary Algorithms"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:32.566639Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21505",
    "title": "The Effectiveness of Style Vectors for Steering Large Language Models: A Human Evaluation",
    "authors": [
      "Diaoulé Diallo",
      "Katharina Dworatzyk",
      "Sophie Jentzsch",
      "Peer Schütt",
      "Sabine Theis",
      "Tobias Hecking"
    ],
    "abstract": "Controlling the behavior of large language models (LLMs) at inference time is essential for aligning outputs with human abilities and safety requirements. \\emph{Activation steering} provides a lightweight alternative to prompt engineering and fine-tuning by directly modifying internal activations to guide generation. This research advances the literature in three significant directions. First, while previous work demonstrated the technical feasibility of steering emotional tone using automated classifiers, this paper presents the first human evaluation of activation steering concerning the emotional tone of LLM outputs, collecting over 7,000 crowd-sourced ratings from 190 participants via Prolific ($n=190$). These ratings assess both perceived emotional intensity and overall text quality. Second, we find strong alignment between human and model-based quality ratings (mean $r=0.776$, range $0.157$--$0.985$), indicating automatic scoring can proxy perceived quality. Moderate steering strengths ($λ\\approx 0.15$) reliably amplify target emotions while preserving comprehensibility, with the strongest effects for disgust ($η_p^2 = 0.616$) and fear ($η_p^2 = 0.540$), and minimal effects for surprise ($η_p^2 = 0.042$). Finally, upgrading from Alpaca to LlaMA-3 yielded more consistent steering with significant effects across emotions and strengths (all $p < 0.001$). Inter-rater reliability was high (ICC $= 0.71$--$0.87$), underscoring the robustness of the findings. These findings support activation-based control as a scalable method for steering LLM behavior across affective dimensions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21505.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21505",
    "published": "2026-01-29T10:24:34Z",
    "updated": "2026-01-29T10:24:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过首次人类评估，验证了激活导向在控制大型语言模型情感输出中的有效性和可扩展性。",
      "motivation": "研究旨在解决控制大型语言模型（LLM）行为以对齐人类能力和安全要求的问题。现有方法如提示工程和微调可能资源密集或效果有限，而激活导向提供了一种轻量级替代，通过直接修改内部激活来引导生成。然而，之前的研究主要集中在技术可行性上，缺乏对人类感知的系统评估，因此需要验证其在真实场景下的实际效果，以确保输出的情感质量符合用户需求。",
      "method": "本研究采用激活导向技术，通过修改LLM的内部激活向量来引导生成过程，实现情感色调的控制。关键创新在于进行了首次针对情感导向的人类评估，收集了超过7,000个众包评分，评估了情感强度和文本质量。使用了Prolific平台，190名参与者参与，并基于自动分类器生成风格向量进行实验。方法还包括比较不同模型（Alpaca和LlaMA-3）以分析导向的一致性，使用统计指标验证效果。",
      "result": "实验结果表明，人类评分与基于模型的自动评分高度一致（平均相关系数r=0.776），说明自动评分可作为感知质量的有效代理。适度的导向强度（λ≈0.15）可靠地放大了目标情感，同时保持文本可理解性，其中厌恶（η_p^2=0.616）和恐惧（η_p^2=0.540）效果最显著，惊喜效果最小（η_p^2=0.042）。从Alpaca升级到LlaMA-3模型后，导向效果更加一致，所有情感和强度下均显示显著效应（p<0.001），评分者间可靠性高（ICC=0.71-0.87），增强了结果的稳健性。",
      "conclusion": "本研究的主要贡献在于通过人类评估验证了激活导向在控制LLM情感输出中的有效性，支持其作为一种可扩展的方法，用于在情感维度上引导模型行为。学术价值体现在为轻量级控制技术提供了实证依据，实际应用价值包括改善AI系统的适人性交互。未来工作可能包括扩展到其他风格维度或探索更精细的控制策略，摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Activation Steering",
        "Human Evaluation",
        "Emotional Tone",
        "Automated Classifiers"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:39.174979Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21503",
    "title": "MAR: Efficient Large Language Models via Module-aware Architecture Refinement",
    "authors": [
      "Junhong Cai",
      "Guiqin Wang",
      "Kejie Zhao",
      "Jianxiong Tang",
      "Xiang Wang",
      "Luziwei Leng",
      "Ran Cheng",
      "Yuxin Ma",
      "Qinghai Guo"
    ],
    "abstract": "Large Language Models (LLMs) excel across diverse domains but suffer from high energy costs due to quadratic attention and dense Feed-Forward Network (FFN) operations. To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage framework that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs. In addition, to mitigate low information density and temporal mismatch in integrating Spiking Neural Networks (SNNs) with SSMs, we design the Adaptive Ternary Multi-step Neuron (ATMN) and the Spike-aware Bidirectional Distillation Strategy (SBDS). Extensive experiments demonstrate that MAR effectively restores the performance of its dense counterpart under constrained resources while substantially reducing inference energy consumption. Furthermore, it outperforms efficient models of comparable or even larger scale, underscoring its potential for building efficient and practical LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21503.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21503",
    "published": "2026-01-29T10:21:28Z",
    "updated": "2026-01-29T10:21:28Z",
    "comment": "Accepted by ICASSP 2026. 5 pages, 5 figures",
    "light_analysis": {
      "overview": "提出模块感知架构精炼（MAR）框架，通过整合状态空间模型和激活稀疏化，优化大语言模型的效率和性能。",
      "motivation": "大语言模型（LLMs）虽在多领域表现优异，但二次注意力和密集前馈网络（FFN）操作导致高能耗，限制了实际部署。现有高效模型可能在性能保持方面不足，因此需要创新架构以平衡效率与精度，解决资源受限环境下的能源问题。",
      "method": "MAR是一个两阶段框架：首先集成状态空间模型（SSMs）实现线性时间序列建模，替代二次注意力；其次应用激活稀疏化减少FFN成本。为解决脉冲神经网络（SNNs）与SSMs集成时的信息密度低和时间不匹配问题，设计了自适应三元多步神经元（ATMN）和脉冲感知双向蒸馏策略（SBDS）。",
      "result": "实验表明，MAR在资源受限下能有效恢复其密集模型对应物的性能，同时大幅降低推理能耗。此外，它在性能上优于同等或更大规模的其他高效模型，突显了效率优势，但具体数据摘要未明确说明。",
      "conclusion": "该研究贡献了MAR框架，通过技术整合提高LLMs效率并保持性能，为构建高效实用模型提供新方法。其学术价值在于架构优化，实际应用有助于减少计算资源消耗。未来工作可能包括进一步扩展或优化，局限性摘要未明确说明。",
      "tags": [
        "State Space Models",
        "Spiking Neural Networks",
        "Activation Sparsification",
        "Adaptive Ternary Multi-step Neuron",
        "Spike-aware Bidirectional Distillation Strategy"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:57.928536Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21500",
    "title": "Task-Awareness Improves LLM Generations and Uncertainty",
    "authors": [
      "Tim Tomov",
      "Dominik Fuchsgruber",
      "Stephan Günnemann"
    ],
    "abstract": "In many applications of LLMs, natural language responses often have an underlying structure such as representing discrete labels, numerical values, or graphs. Yet, existing decoding and uncertainty estimation methods operate only in language space and largely disregard structural information. We address this by modeling LLM outputs directly in a task-dependent latent structure. By equipping this structure with a dissimilarity measure, we can compute Bayes-optimal responses. These are not selected from sampled generations but are newly synthesized by combining individual responses in the latent space. Across different tasks, Bayes-optimal responses consistently outperform standard decoding methods like beam search. Moreover, quantifying uncertainty via the induced Bayesian risk captures variations in terms of the latent structure and improves alignment with output quality and correctness. Our decision-theoretic framework is applicable to any problem that admits a latent response structure and enables reliable task-aware LLM predictions.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21500.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21500",
    "published": "2026-01-29T10:16:23Z",
    "updated": "2026-01-29T10:16:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出一种任务感知的框架，通过在潜在结构中建模LLM输出，计算贝叶斯最优响应并改进不确定性估计。",
      "motivation": "在许多大型语言模型应用中，自然语言响应往往具有潜在的离散标签、数值或图等结构，但现有的解码和不确定性估计方法主要在语言空间中操作，忽视了这些结构信息。这限制了生成响应的质量和不确定性估计的准确性，因为标准方法如beam search无法有效利用任务相关的结构。因此，研究旨在解决如何整合结构信息以提升LLM的可靠性和应用效果，弥补现有方法的不足。",
      "method": "论文提出一个决策论框架，直接在任务相关的潜在结构中建模LLM输出，例如离散标签或数值。通过为潜在结构配备一个差异度量，计算贝叶斯最优响应，这些响应并非从采样的生成中选取，而是通过在潜在空间中合成个体响应来新生成。该框架适用于任何允许潜在响应结构的问题，如分类或图生成任务，其创新点在于将任务感知融入解码过程，实现结构感知的贝叶斯优化，以提高生成质量和不确定性估计。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "实验结果表明，在不同任务中，贝叶斯最优响应一致优于标准解码方法如beam search，展示了生成质量的提升。通过引入的贝叶斯风险量化不确定性，能更好地捕捉潜在结构的变化，并改进与输出质量和正确性的对齐。这些发现证实了任务感知方法在提升LLM预测性能方面的有效性，尽管摘要未提供具体数据如准确率提升百分比。",
      "conclusion": "该研究的主要贡献是提出了一个任务感知的决策论框架，通过在潜在结构中建模LLM输出，实现了贝叶斯最优响应和更准确的不确定性估计。这具有重要的学术价值，为LLM解码和不确定性量化提供了新思路；在实际应用中，可广泛用于需要结构感知预测的各种任务，如自动标注或数据分析。未来工作方向可能包括扩展到更复杂的结构类型或验证在更多场景下的普适性。",
      "tags": [
        "Large Language Model",
        "Decoding Methods",
        "Bayesian Methods",
        "Latent Structure",
        "Uncertainty Estimation"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:07.155092Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21498",
    "title": "SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing",
    "authors": [
      "Thanh-Nhan Vo",
      "Trong-Thuan Nguyen",
      "Tam V. Nguyen",
      "Minh-Triet Tran"
    ],
    "abstract": "Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21498.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21498",
    "published": "2026-01-29T10:15:55Z",
    "updated": "2026-01-29T10:15:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出SimGraph统一框架，整合基于场景图的图像生成和编辑，实现对象交互和空间一致性的精确控制。",
      "motivation": "本研究的动机是解决图像生成和编辑任务中的效率和一致性问题。现有方法通常将生成和编辑分开处理，导致效率低下，难以保持对象间的空间一致性和语义连贯性，且缺乏对对象关系和布局的结构化控制，这限制了生成内容的灵活性和质量。因此，引入一个统一框架来提供更精确的控制显得尤为重要。",
      "method": "SimGraph是一个统一框架，利用场景图以结构化方式表示对象及其相互关系，从而实现对图像生成和编辑的精确控制。关键创新在于整合了基于令牌的生成方法和基于扩散的编辑技术于一个场景图驱动的单一模型中，确保了内容的高质量和一致性。摘要未明确说明具体的数据集或详细模型架构。",
      "result": "通过广泛的实验验证，SimGraph在保持空间一致性和语义连贯性方面优于现有最先进方法。虽然没有提供具体的准确率或效率数据，但论文强调了其框架在综合性能和一致性上的显著优势，特别是在对比基线方法时，在图像生成和编辑任务中表现更佳。",
      "conclusion": "本研究的主要贡献是提出SimGraph框架，统一了基于场景图的图像生成和编辑，解决了现有方法在一致性和控制方面的不足。这具有学术价值，为结构控制下的图像生成和编辑提供了新方法，并具有实际应用价值，适用于需要精确场景合成的领域。摘要未明确说明局限性和未来工作方向。",
      "tags": [
        "Scene Graph",
        "Image Generation",
        "Image Editing",
        "Token-based Generation",
        "Diffusion Model"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:35.756071Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21494",
    "title": "The Path of Least Resistance: Guiding LLM Reasining Trajectories with Prefix Consensus",
    "authors": [
      "Ishan Jindal",
      "Sai Prashanth Akuthota",
      "Jayant Taneja",
      "Sachin Dev Sharma"
    ],
    "abstract": "Large language models achieve strong reasoning performance, but inference strategies such as Self-Consistency (SC) are computationally expensive, as they fully expand all reasoning traces. We introduce PoLR (Path of Least Resistance), the first inference-time method to leverage prefix consistency for compute-efficient reasoning. PoLR clusters short prefixes of reasoning traces, identifies the dominant cluster, and expands all paths in that cluster, preserving the accuracy benefits of SC while substantially reducing token usage and latency. Our theoretical analysis, framed via mutual information and entropy, explains why early reasoning steps encode strong signals predictive of final correctness. Empirically, PoLR consistently matches or exceeds SC across GSM8K, MATH500, AIME24/25, and GPQA-DIAMOND, reducing token usage by up to 60% and wall-clock latency by up to 50%. Moreover, PoLR is fully complementary to adaptive inference methods (e.g., Adaptive Consistency, Early-Stopping SC) and can serve as a drop-in pre-filter, making SC substantially more efficient and scalable without requiring model fine-tuning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21494.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21494",
    "published": "2026-01-29T10:14:24Z",
    "updated": "2026-01-29T10:14:24Z",
    "comment": "Accepted at ICLR 2026. https://openreview.net/forum?id=hrnSqERgPn",
    "light_analysis": {
      "overview": "本文提出PoLR方法，首次利用前缀一致性在大语言模型推理中实现计算高效推理，显著减少资源消耗。",
      "motivation": "研究动机在于大语言模型的推理策略如Self-Consistency虽能提升性能，但计算成本高昂，因为它们需要完全扩展所有推理轨迹，导致高令牌使用和延迟，限制了实际应用的可扩展性。现有方法的不足在于缺乏高效利用早期推理信号的机制，从而造成不必要的计算开销。因此，开发一种能在推理时保留准确性同时减少计算负担的方法至关重要。",
      "method": "PoLR方法的核心是聚类推理轨迹的短前缀，识别占主导地位的前缀簇，并仅扩展该簇中的路径。关键创新在于首次利用前缀一致性进行推理优化，通过理论分析基于互信息和熵，解释了早期步骤编码预测最终正确性的强信号。该方法在推理时操作，无需模型微调，使用的数据集包括GSM8K、MATH500等用于验证，技术特色包括高效的前缀聚类和主导簇识别机制。",
      "result": "实证结果显示，PoLR在GSM8K、MATH500、AIME24/25和GPQA-DIAMOND等多个数据集上，持续匹配或超过Self-Consistency的推理准确性。同时，它显著减少了令牌使用量，最高可达60%，并降低延迟最高达50%，这些改进在与基线方法的对比中验证了其高效性和可扩展性。",
      "conclusion": "PoLR的主要贡献是提出了一种新颖的推理时方法，通过前缀一致性优化大语言模型的推理过程，提升了计算效率。其学术价值在于提供了理论分析和实证支持，实际应用价值在于无需微调即可集成到现有系统，与自适应推理方法互补。摘要未明确说明局限性，但未来工作可探索更高效的前缀编码或扩展到其他推理任务。",
      "tags": [
        "Large Language Model",
        "Self-Consistency",
        "Prefix Consensus",
        "Inference Efficiency",
        "Adaptive Inference"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:48.137849Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21484",
    "title": "ETS: Energy-Guided Test-Time Scaling for Training-Free RL Alignment",
    "authors": [
      "Xiuyu Li",
      "Jinkai Zhang",
      "Mingyang Yi",
      "Yu Li",
      "Longqiang Wang",
      "Yue Wang",
      "Ju Fan"
    ],
    "abstract": "Reinforcement Learning (RL) post-training alignment for language models is effective, but also costly and unstable in practice, owing to its complicated training process. To address this, we propose a training-free inference method to sample directly from the optimal RL policy. The transition probability applied to Masked Language Modeling (MLM) consists of a reference policy model and an energy term. Based on this, our algorithm, Energy-Guided Test-Time Scaling (ETS), estimates the key energy term via online Monte Carlo, with a provable convergence rate. Moreover, to ensure practical efficiency, ETS leverages modern acceleration frameworks alongside tailored importance sampling estimators, substantially reducing inference latency while provably preserving sampling quality. Experiments on MLM (including autoregressive models and diffusion language models) across reasoning, coding, and science benchmarks show that our ETS consistently improves generation quality, validating its effectiveness and design.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21484.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21484",
    "published": "2026-01-29T10:06:52Z",
    "updated": "2026-01-29T10:06:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种训练免费的推理方法ETS，通过能量引导测试时间缩放直接从最优强化学习策略中采样，简化对齐过程。",
      "motivation": "强化学习（RL）后训练对齐在语言模型中能提升生成质量，但实践中由于复杂的训练过程，成本高昂且不稳定。现有方法依赖繁琐训练步骤，容易导致收敛问题和不一致结果，限制了实际应用。因此，本研究旨在开发一种训练免费的推理方法，直接采样最优策略，避免训练开销，提高对齐效率和可靠性，以解决RL对齐的实用性问题。",
      "method": "ETS方法基于掩码语言建模（MLM），通过结合参考策略模型和能量项定义转移概率。关键创新在于使用在线蒙特卡洛方法估计能量项，并提供可证明的收敛率。为提高实用性，ETS集成现代加速框架（如GPU优化）和定制的重要性采样估计器，显著降低推理延迟，同时保证采样质量。该方法适用于自回归模型和扩散语言模型等多种MLM变体，实现了高效训练免费推理。",
      "result": "实验在推理、编码和科学等多个基准上进行，使用了掩码语言建模（MLM）及其变体（如自回归模型和扩散语言模型）。结果表明，ETS consistently improves生成质量，验证了其有效性和设计，并在不同领域和模型类型上展现鲁棒性。然而，摘要未明确说明具体的性能指标提升数据（如准确率或效率改进百分比），仅提及了总体改进趋势。",
      "conclusion": "本文主要贡献是提出了ETS算法，一种训练免费的推理方法，直接从最优RL策略中采样，减少了传统对齐方法的成本和复杂性。其学术价值在于提供可证明收敛的高效采样方案，推动了RL对齐技术的发展。实际应用中，ETS能降低部署门槛，提升语言模型生成的稳定性和效率。未来工作可能包括扩展到更多模型类型或探索其他优化策略，但摘要未明确说明局限性。",
      "tags": [
        "Reinforcement Learning",
        "Masked Language Modeling",
        "Monte Carlo Methods",
        "Energy-Guided Sampling",
        "Test-Time Scaling"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:14.733196Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21483",
    "title": "DimStance: Multilingual Datasets for Dimensional Stance Analysis",
    "authors": [
      "Jonas Becker",
      "Liang-Chih Yu",
      "Shamsuddeen Hassan Muhammad",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Idris Abdulmumin",
      "Lung-Hao Lee",
      "Wen-Ni Liu",
      "Tzu-Mi Lin",
      "Zhe-Yu Xu",
      "Ying-Lung Lin",
      "Jin Wang",
      "Maryam Ibrahim Mukhtar",
      "Bela Gipp",
      "Saif M. Mohammed"
    ],
    "abstract": "Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21483.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21483",
    "published": "2026-01-29T10:02:08Z",
    "updated": "2026-01-29T10:02:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文引入DimStance数据集，首次使用情感维度（效价和唤醒度）进行细粒度的多语言立场分析，支持政治和环境保护领域的研究。",
      "motivation": "立场检测传统上通过分类（如支持、中立、反对）评估作者态度，但这种方法忽略了情感的连续性和细腻状态。受情感科学框架启发，本文认为立场表达基于效价（负面-正面）和唤醒度（平静-活跃）等维度，能更精确捕捉立场背后的情感复杂性。现有分类方法无法提供细粒度分析，且在多语言和低资源场景下存在不足，因此本研究旨在开发首个情感维度标注的多语言数据集，以解决传统方法的局限并促进跨文化立场分析。",
      "method": "本文提出DimStance数据集，包含11,746个目标方面，基于7,365个文本覆盖英语、德语、中文、尼日利亚皮钦语和斯瓦希里语五种语言，以及政治和环境保护两个领域。关键创新点包括制定立场回归任务，通过效价和唤醒度（VA）维度建模立场，并基准测试预训练模型和大型语言模型在回归和提示设置下的性能。方法涉及数据收集与标注、模型微调（如LLM回归器），并分析跨语言VA模式，以评估模型在多语言环境中的表现和低资源语言挑战。",
      "result": "实验结果显示，微调的大型语言模型回归器在情感维度预测任务中表现出竞争性性能，验证了维度方法的有效性。然而，在低资源语言（如尼日利亚皮钦语和斯瓦希里语）中，模型性能较差，凸显了跨语言处理的持续挑战。此外，基于令牌的生成方法存在局限性，表明在连续情感维度预测方面需改进。与基线方法相比，本研究的方法在捕捉细腻立场方面有优势，但具体性能指标如准确率提升摘要未明确说明。",
      "conclusion": "本研究的核心贡献是推出了DimStance数据集，首次将情感维度整合到立场分析中，为多语言、情感感知的细粒度立场分析奠定了基础。学术价值在于推动情感计算和自然语言处理的交叉研究，实际应用包括改善社交媒体监控和政策分析。未来工作可扩展数据集规模、优化低资源语言处理能力，并探索更多情感维度；局限性包括低资源语言的性能挑战和生成方法的限制，需进一步研究以克服这些障碍。",
      "tags": [
        "Stance Detection",
        "Dimensional Stance Analysis",
        "Valence-Arousal",
        "Multilingual Datasets",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:58.339950Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21479",
    "title": "Hypernetwork-Based Adaptive Aggregation for Multimodal Multiple-Instance Learning in Predicting Coronary Calcium Debulking",
    "authors": [
      "Kaito Shiku",
      "Ichika Seo",
      "Tetsuya Matoba",
      "Rissei Hino",
      "Yasuhiro Nakano",
      "Ryoma Bise"
    ],
    "abstract": "In this paper, we present the first attempt to estimate the necessity of debulking coronary artery calcifications from computed tomography (CT) images. We formulate this task as a Multiple-instance Learning (MIL) problem. The difficulty of this task lies in that physicians adjust their focus and decision criteria for device usage according to tabular data representing each patient's condition. To address this issue, we propose a hypernetwork-based adaptive aggregation transformer (HyperAdAgFormer), which adaptively modifies the feature aggregation strategy for each patient based on tabular data through a hypernetwork. The experiments using the clinical dataset demonstrated the effectiveness of HyperAdAgFormer. The code is publicly available at https://github.com/Shiku-Kaito/HyperAdAgFormer.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21479.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21479",
    "published": "2026-01-29T10:00:04Z",
    "updated": "2026-01-29T10:00:04Z",
    "comment": "Accepted to ISBI 2026",
    "light_analysis": {
      "overview": "本文首次提出基于超网络的自适应聚合变换器，用于从CT图像预测冠状动脉钙化去除的必要性，实现多模态多实例学习。",
      "motivation": "本研究旨在从计算机断层扫描（CT）图像中预测冠状动脉钙化去除的必要性，这是一个关键的临床决策问题，涉及优化心脏病治疗方案。现有方法在整合多模态数据（如图像和表格数据）方面存在不足，医生依赖表格数据调整决策，但传统方法未能自适应地融合这些信息，导致预测准确性受限。因此，开发能够根据患者特定条件动态调整特征聚合的策略至关重要，以提升个性化医疗决策的可靠性。",
      "method": "论文提出HyperAdAgFormer方法，这是一种基于超网络的自适应聚合变换器，用于多模态多实例学习任务。核心创新在于使用超网络根据患者的表格数据（如临床特征）生成参数，动态调整transformer中的特征聚合策略，从而自适应处理CT图像中的多个实例（钙化区域）。该方法结合了MIL框架和多模态输入，实现图像与表格数据的融合，但摘要未详细说明具体模型架构或数据集细节，仅提及使用临床数据集进行实验。",
      "result": "实验使用临床数据集验证了HyperAdAgFormer的有效性，但摘要未明确提供具体性能指标（如准确率或效率改进），也未对比基线方法。作者声称方法成功预测了钙化去除的必要性，表明其在多模态自适应聚合方面的优势，为后续研究提供了基础。需要进一步实验来量化性能提升，摘要未明确说明更详细的结果数据。",
      "conclusion": "本研究的主要贡献在于首次结合多实例学习与多模态数据，提出HyperAdAgFormer方法，通过超网络实现自适应特征聚合，以预测冠状动脉钙化去除必要性。这为医疗影像分析领域提供了新思路，具有重要的学术价值（如推动自适应机器学习研究）和实际应用价值（如辅助临床决策）。未来工作可能包括在更大规模数据集上验证性能、探索其他医疗任务应用，或优化模型效率，局限性在于摘要未讨论具体瓶颈或泛化能力。",
      "tags": [
        "Multiple-instance Learning",
        "Hypernetwork",
        "Adaptive Aggregation",
        "Multimodal Learning",
        "Transformer"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:57.058180Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21476",
    "title": "SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models",
    "authors": [
      "Lei Yang",
      "Wei Bi",
      "Chenxi Sun",
      "Renren Jin",
      "Deyi Xiong"
    ],
    "abstract": "On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\\textbf{S}$ingle-sample Mix-p$\\textbf{O}$licy $\\textbf{U}$nified $\\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21476.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21476",
    "published": "2026-01-29T09:56:15Z",
    "updated": "2026-01-29T09:56:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "SOUP 提出了一种 token 级单样本混合策略强化学习框架，通过在个体样本的 token 级别统一 off-policy 和 on-policy 学习，有效提升了大型语言模型的训练稳定性和性能。",
      "motivation": "当前，基于 on-policy 的强化学习方法（如 GRPO）在大型语言模型后训练中，因采样多样性低而面临探索不足和性能早期饱和的问题。虽然 off-policy 数据能增加多样性，但现有方法混合整个轨迹会导致严重的策略失配和训练不稳定。因此，研究需要一种新方法来平衡探索与稳定性，以改进模型训练效果。",
      "method": "SOUP 框架在 token 级别统一 off-policy 和 on-policy 学习，具体技术为：将 off-policy 影响限制在由历史策略采样的生成序列前缀部分，而后续部分基于 on-policy 生成。通过 token 级别的重要性比率计算，有效利用 off-policy 信息并保持训练稳定性，避免策略失配。该方法侧重于精细控制混合策略，无需修改整个轨迹。",
      "result": "摘要未明确说明具体数据指标，但通过广泛实验，SOUP 在性能上一致优于标准的 on-policy 训练方法（如 GRPO）和现有的 off-policy 扩展技术。进一步分析表明，这种细粒度、单样本的混合策略训练能显著提升模型的探索能力和最终性能，验证了方法的有效性。",
      "conclusion": "SOUP 的主要贡献是提供了一种 token 级混合策略的强化学习框架，解决了策略失配问题，提高了大型语言模型训练的稳定性和效率。其学术价值在于为 RL 训练引入了新范式，实际应用潜力在于优化语言模型性能。未来工作可探索该框架在其他领域的适用性和具体性能提升的量化分析。",
      "tags": [
        "Large Language Models",
        "Reinforcement Learning",
        "Token-level Policy Mixing",
        "Importance Sampling",
        "On-policy Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:48.547535Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21473",
    "title": "ScaleSim: Serving Large-Scale Multi-Agent Simulation with Invocation Distance-Based Memory Management",
    "authors": [
      "Zaifeng Pan",
      "Yipeng Shen",
      "Zhengding Hu",
      "Zhuang Wang",
      "Aninda Manocha",
      "Zheng Wang",
      "Zhongkai Yu",
      "Yue Guan",
      "Yufei Ding"
    ],
    "abstract": "LLM-based multi-agent simulations are increasingly adopted across application domains, but remain difficult to scale due to GPU memory pressure. Each agent maintains private GPU-resident states, including models, prefix caches, and adapters, which quickly exhaust device memory as the agent count grows. We identify two key properties of these workloads: sparse agent activation and an estimable agent invocation order. Based on an analysis of representative workload classes, we introduce invocation distance, a unified abstraction that estimates the relative order in which agents will issue future LLM requests. Leveraging this abstraction, we present ScaleSim, a memory-efficient LLM serving system for large-scale multi-agent simulations. ScaleSim enables proactive prefetching and priority-based eviction, supports diverse agent-specific memory through a modular interface, and achieves up to 1.74x speedup over SGLang on simulation benchmarks.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21473.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21473",
    "published": "2026-01-29T09:52:16Z",
    "updated": "2026-01-29T09:52:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出ScaleSim系统，利用调用距离抽象实现高效内存管理，提升基于LLM的大规模多智能体模拟的可扩展性。",
      "motivation": "基于LLM的多智能体模拟在社交、游戏、研究等领域广泛应用，但GPU内存压力限制了扩展性。每个智能体维护私有GPU驻留状态，如模型和缓存，随着智能体数量增加，内存快速耗尽，导致现有方法难以支持大规模部署。这个问题的重要性在于阻碍了模拟的实时性和实用性，因此亟需创新的内存管理方案来提高效率。",
      "method": "基于对工作负载类的分析，论文引入调用距离抽象，用于估计智能体未来LLM请求的相对顺序。核心方法ScaleSim系统利用该抽象实现主动预取和基于优先级的逐出策略，并通过模块化接口支持多样智能体特定内存，如模型和适配器，从而优化内存使用。技术特色包括预估性内存管理，无需额外数据集，重点在于抽象设计和系统实现。",
      "result": "在模拟基准测试中，ScaleSim相比SGLang系统实现了高达1.74倍的加速，显著减少了内存开销并提升了性能。这表明调用距离抽象和内存管理策略有效，为大规模多智能体模拟提供了更高效的服务，验证了其在扩展性和速度方面的改进。摘要未提供详细基准测试名称，但基于结果数据支撑其优势。",
      "conclusion": "ScaleSim通过调用距离抽象和内存管理技术，为基于LLM的大规模多智能体模拟提供了高效服务系统，提升了扩展性和性能。学术价值在于提出新颖的内存管理方法，推动LLM服务系统研究；实际价值在于促进模拟的广泛应用。未来工作可能涉及优化适应更多负载类型，摘要未明确说明局限性，但潜在可扩展方向。",
      "tags": [
        "Large Language Model",
        "Multi-Agent Simulation",
        "Memory Management",
        "Invocation Distance",
        "GPU Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:58.587339Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21471",
    "title": "Best Arm Identification with LLM Judges and Limited Human",
    "authors": [
      "Ruicheng Ao",
      "Hongyu Chen",
      "Siyang Gao",
      "Hanwei Li",
      "David Simchi-Levi"
    ],
    "abstract": "We study fixed-confidence best-arm identification (BAI) where a cheap but potentially biased proxy (e.g., LLM judge) is available for every sample, while an expensive ground-truth label can only be acquired selectively when using a human for auditing. Unlike classical multi-fidelity BAI, the proxy is biased (arm- and context-dependent) and ground truth is selectively observed. Consequently, standard multi-fidelity methods can mis-select the best arm, and uniform auditing, though accurate, wastes scarce resources and is inefficient. We prove that without bias correction and propensity adjustment, mis-selection probability may not vanish (even with unlimited proxy data). We then develop an estimator for the mean of each arm that combines proxy scores with inverse-propensity-weighted residuals and form anytime-valid confidence sequences for that estimator. Based on the estimator and confidence sequence, we propose an algorithm that adaptively selects and audits arms. The algorithm concentrates audits on unreliable contexts and close arms and we prove that a plug-in Neyman rule achieves near-oracle audit efficiency. Numerical experiments confirm the theoretical guarantees and demonstrate the superior empirical performance of the proposed algorithm.",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21471.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21471",
    "published": "2026-01-29T09:50:34Z",
    "updated": "2026-01-29T09:50:34Z",
    "comment": "22 pages, 3 figures",
    "light_analysis": {
      "overview": "本研究提出一种自适应算法，利用LLM代理和有限人类审计进行最佳臂识别，通过偏差纠正和倾向调整提高选择准确性和资源效率。",
      "motivation": "该研究针对固定置信度最佳臂识别问题，背景是存在廉价但可能有偏的代理（如大型语言模型）和昂贵的地面实况标签。由于代理偏差依赖于臂和上下文，且地面实况只能有选择性地获取，标准多保真度方法可能导致错误选择，而统一审计浪费资源、效率低下。因此，研究动机在于解决如何高效结合有偏代理和有限人类审计，以避免误选并优化资源使用。",
      "method": "论文方法的核心是开发一个用于估计每个臂均值的估计器，该估计器结合了代理分数和逆倾向加权残差，以纠正偏差和调整倾向。接着，为估计器构建任意有效的置信序列。基于此，提出一个自适应算法，根据置信序列动态选择和审计臂，算法创新地将审计集中在不可靠的上下文和接近的臂上，并采用插值Neyman规则来实现接近最优的审计效率。",
      "result": "理论结果显示，所提算法能确保错误选择概率收敛，并实现接近最优的审计效率，这通过插值Neyman规则证明。数值实验进一步验证了这些理论保证，展示了算法在模拟或真实场景中的优越性能。虽然摘要未提供具体指标如准确率提升百分比，但强调算法在效率和准确性上的显著改进。",
      "conclusion": "本研究的主要贡献是提出了一个高效算法，用于处理最佳臂识别中有偏代理和有限人类审计的挑战。通过偏差纠正和倾向调整，算法提高了选择准确性和资源效率，具有重要学术和实际应用价值。未来工作可能包括扩展到更复杂的偏差模型或其他应用场景，但摘要未明确说明具体方向。",
      "tags": [
        "Best Arm Identification",
        "LLM Judges",
        "Inverse Propensity Weighting",
        "Confidence Sequences",
        "Adaptive Sampling"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:04.557782Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21470",
    "title": "PPI-SVRG: Unifying Prediction-Powered Inference and Variance Reduction for Semi-Supervised Optimization",
    "authors": [
      "Ruicheng Ao",
      "Hongyu Chen",
      "Haoyang Liu",
      "David Simchi-Levi",
      "Will Wei Sun"
    ],
    "abstract": "We study semi-supervised stochastic optimization when labeled data is scarce but predictions from pre-trained models are available. PPI and SVRG both reduce variance through control variates -- PPI uses predictions, SVRG uses reference gradients. We show they are mathematically equivalent and develop PPI-SVRG, which combines both. Our convergence bound decomposes into the standard SVRG rate plus an error floor from prediction uncertainty. The rate depends only on loss geometry; predictions affect only the neighborhood size. When predictions are perfect, we recover SVRG exactly. When predictions degrade, convergence remains stable but reaches a larger neighborhood. Experiments confirm the theory: PPI-SVRG reduces MSE by 43--52\\% under label scarcity on mean estimation benchmarks and improves test accuracy by 2.7--2.9 percentage points on MNIST with only 10\\% labeled data.",
    "categories": [
      "cs.LG",
      "econ.EM",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21470.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21470",
    "published": "2026-01-29T09:49:46Z",
    "updated": "2026-01-29T09:49:46Z",
    "comment": "27 pages, 4 figures",
    "light_analysis": {
      "overview": "PPI-SVRG 方法统一了预测增强推理和方差减少技术，用于解决标记数据稀缺的半监督随机优化问题，通过结合 PPI 和 SVRG 提高优化效率。",
      "motivation": "在机器学习中，标记数据稀缺时，半监督随机优化面临方差大、优化不稳定的挑战。现有方法如预测增强推理（PPI）利用预训练模型的预测作为控制变量减少方差，随机方差减少梯度（SVRG）则使用参考梯度，但二者未结合，限制了在标记数据有限情况下的性能提升。本研究旨在整合这两种方法，以应对预测不确定性和标记数据不足的问题，从而提高优化算法的鲁棒性和准确性。",
      "method": "论文提出了 PPI-SVRG 方法，通过数学等价性证明预测增强推理（PPI）和随机方差减少梯度（SVRG）都使用控制变量减少方差，并开发了统一框架。关键创新在于结合预测和参考梯度，收敛分析表明优化速率仅依赖于损失函数的几何性质，预测仅影响收敛邻域的大小。实验在均值估计基准和 MNIST 数据集上进行，使用预训练模型提供预测，验证了方法的有效性和理论分析。",
      "result": "实验结果显示，PPI-SVRG 在标记数据稀缺条件下显著提升性能。在均值估计基准上，均方误差（MSE）减少了 43-52%，表明方差减少效果明显。在 MNIST 数据集上，使用仅 10% 标记数据时，测试精度提高了 2.7-2.9 个百分点，优于基线方法。这些结果证实了 PPI-SVRG 能够稳定收敛并减少优化过程中的不确定性，支持理论预测。",
      "conclusion": "本研究的主要贡献是开发了 PPI-SVRG 方法，统一了预测增强推理和方差减少技术，为半监督随机优化提供了新框架。论文通过数学等价性证明、统一方法开发和理论收敛分析，展示了该方法在标记数据稀缺时的有效性和鲁棒性。这具有重要的学术价值，推动了优化算法的发展，并提供了实际应用潜力，例如在资源有限的机器学习任务中。未来工作可探索该方法在其他优化问题或更复杂数据集上的扩展。",
      "tags": [
        "Prediction-Powered Inference",
        "SVRG",
        "Control Variates",
        "Semi-Supervised Optimization",
        "Variance Reduction"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:34.098592Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21468",
    "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning",
    "authors": [
      "Yaorui Shi",
      "Shugui Liu",
      "Yu Yang",
      "Wenyu Mao",
      "Yuxin Chen",
      "Qi GU",
      "Hui Su",
      "Xunliang Cai",
      "Xiang Wang",
      "An Zhang"
    ],
    "abstract": "Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window. Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value details. To this end, we introduce MemOCR, a multimodal memory agent that improves long-horizon reasoning under tight context budgets by allocating memory space with adaptive information density through visual layout. Concretely, MemOCR maintains a structured rich-text memory (e.g., headings, highlights) and renders it into an image that the agent consults for memory access, visually prioritizing crucial evidence while aggressively compressing auxiliary details. To ensure robustness across varying memory budgets, we train MemOCR with reinforcement learning under budget-aware objectives that expose the agent to diverse compression levels. Across long-context multi-hop and single-hop question-answering benchmarks, MemOCR outperforms strong text-based baselines and achieves more effective context utilization under extreme budgets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21468.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21468",
    "published": "2026-01-29T09:47:17Z",
    "updated": "2026-01-29T09:47:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "MemOCR提出了一种基于视觉布局的多模态内存系统，通过图像形式高效压缩和优先内存内容，提升了长期代理推理的上下文利用率。",
      "motivation": "长期代理推理任务需要处理大量交互历史，但受限于固定上下文窗口。现有方法通常将历史序列化为文本，导致内存使用线性增长且均匀分布，常浪费资源于低价值细节，降低了推理效率。因此，开发更高效的内存系统至关重要，以在严格预算下维持高性能推理，避免信息过载和资源浪费。",
      "method": "MemOCR采用多模态方法，首先维护结构化的富文本内存（如包含标题和高亮），然后将其渲染为图像，使代理通过视觉访问内存，利用布局自适应调整信息密度以优先关键证据并压缩辅助细节。为提升鲁棒性，该方法使用强化学习训练，基于预算感知的目标函数，使代理适应不同压缩级别，但摘要未明确说明具体模型架构或数据集细节。",
      "result": "在长期上下文的多跳和单跳问答基准测试中，MemOCR显著优于基于文本的基线方法，并在极端内存预算下实现更有效的上下文利用。摘要未提供具体性能指标数据，如准确率提升数值，但与基线相比，它能够优化资源分配，增强推理效果。",
      "conclusion": "论文的主要贡献是提出了MemOCR，一种结合视觉布局和强化学习的多模态内存系统，有效解决了长期推理中的内存效率问题。其学术价值在于推动了多模态代理技术发展，实际应用适用于资源受限场景。尽管摘要未明确说明局限性，未来工作可探索更广泛领域的适应性和可扩展性。",
      "tags": [
        "Multimodal Memory",
        "Reinforcement Learning",
        "Visual Layout",
        "Long-Horizon Reasoning",
        "Context Utilization"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:34.371267Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21467",
    "title": "A block-coordinate descent framework for non-convex composite optimization. Application to sparse precision matrix estimation",
    "authors": [
      "Guillaume Lauga"
    ],
    "abstract": "Block-coordinate descent (BCD) is the method of choice to solve numerous large scale optimization problems, however their theoretical study for non-convex optimization, has received less attention. In this paper, we present a new block-coordinate descent (BCD) framework to tackle non-convex composite optimization problems, ensuring decrease of the objective function and convergence to a solution. This framework is general enough to include variable metric proximal gradient updates, proximal Newton updates, and alternated minimization updates. This generality allows to encompass three versions of the most used solvers in the sparse precision matrix estimation problem, deemed Graphical Lasso: graphical ISTA, Primal GLasso, and QUIC. We demonstrate the value of this new framework on non-convex sparse precision matrix estimation problems, providing convergence guarantees and up to a $100$-fold reduction in the number of iterations required to reach state-of-the-art estimation quality.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21467.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21467",
    "published": "2026-01-29T09:42:54Z",
    "updated": "2026-01-29T09:42:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种通用块坐标下降框架，用于处理非凸复合优化问题，特别应用于稀疏精度矩阵估计，提供收敛保证并显著提升优化效率。",
      "motivation": "块坐标下降（BCD）方法广泛应用于大规模优化问题，但其在非凸优化领域的理论研究相对薄弱，导致现有算法如Graphical Lasso在稀疏精度矩阵估计中缺乏统一框架。稀疏精度矩阵估计在统计学和机器学习中至关重要，用于高维数据分析，但现有求解器（如graphical ISTA、Primal GLasso、QUIC）在非凸场景下收敛性和效率受限，亟需新框架来弥补这一不足，为复杂优化问题提供更稳健的解决方案。",
      "method": "论文提出一个新的块坐标下降框架，核心包括变量度量近端梯度更新、近端牛顿更新和交替最小化更新，以构建通用优化方法。该框架的创新点在于普适性强，能够涵盖稀疏精度矩阵估计中常用求解器的三个版本：graphical ISTA、Primal GLasso和QUIC。应用场景聚焦于非凸稀疏精度矩阵估计问题，重点在于算法设计和理论分析，未提及具体数据集或模型架构，强调框架的灵活性和扩展性。",
      "result": "新框架在非凸稀疏精度矩阵估计中展示了显著效果，提供了理论收敛保证，确保目标函数下降并收敛到解。与现有基线方法相比，迭代次数减少了高达100倍，同时达到最先进的估计质量，这大幅降低了计算成本并提升了优化效率。实验结果验证了框架的优越性，尤其在处理大规模数据集时表现出色，增强了实际应用的可行性。",
      "conclusion": "本研究的主要贡献是开发了一个通用块坐标下降框架，为非凸复合优化问题提供了坚实的理论支撑和高效求解途径。其学术价值在于扩展了BCD方法的适用范围，推动了非凸优化理论的发展；实际应用价值体现在稀疏精度矩阵估计等领域中效率的显著提升。摘要未明确说明局限性，但未来工作可能涉及框架在更广泛优化问题中的应用或进一步的算法改进。",
      "tags": [
        "Block-Coordinate Descent",
        "Non-convex Optimization",
        "Sparse Precision Matrix Estimation",
        "Graphical Lasso",
        "Proximal Methods"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:03.822809Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21465",
    "title": "Topeax -- An Improved Clustering Topic Model with Density Peak Detection and Lexical-Semantic Term Importance",
    "authors": [
      "Márton Kardos"
    ],
    "abstract": "Text clustering is today the most popular paradigm for topic modelling, both in academia and industry. Despite clustering topic models' apparent success, we identify a number of issues in Top2Vec and BERTopic, which remain largely unsolved. Firstly, these approaches are unreliable at discovering natural clusters in corpora, due to extreme sensitivity to sample size and hyperparameters, the default values of which result in suboptimal behaviour. Secondly, when estimating term importance, BERTopic ignores the semantic distance of keywords to topic vectors, while Top2Vec ignores word counts in the corpus. This results in, on the one hand, less coherent topics due to the presence of stop words and junk words, and lack of variety and trust on the other. In this paper, I introduce a new approach, \\textbf{Topeax}, which discovers the number of clusters from peaks in density estimates, and combines lexical and semantic indices of term importance to gain high-quality topic keywords. Topeax is demonstrated to be better at both cluster recovery and cluster description than Top2Vec and BERTopic, while also exhibiting less erratic behaviour in response to changing sample size and hyperparameters.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21465.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21465",
    "published": "2026-01-29T09:41:31Z",
    "updated": "2026-01-29T09:41:31Z",
    "comment": "14 pages, 6 figures",
    "light_analysis": {
      "overview": "Topeax 提出一种结合密度峰值检测和词汇-语义术语重要性的改进聚类主题模型，以解决现有方法的不足。",
      "motivation": "研究动机源于现有主题建模方法（如 Top2Vec 和 BERTopic）的局限性。这些方法在发现语料中的自然聚类时不可靠，对样本大小和超参数高度敏感，导致次优行为。此外，它们在估计术语重要性时忽略关键因素：BERTopic 忽略关键词与主题向量的语义距离，Top2Vec 忽略词频，从而产生不连贯的主题（包含停用词和垃圾词），并缺乏多样性和可信度。这阻碍了主题建模在文本分析中的实际应用，因此改进这些方法至关重要。",
      "method": "Topeax 提出一种新的技术路线，通过密度估计中的峰值检测来自动确定聚类数量，避免了依赖手动设置。关键创新点在于结合词汇（基于词频）和语义（基于与主题向量的距离）指标来评估术语重要性，从而生成高质量的主题关键词。该方法旨在提升主题模型的稳健性和可解释性。摘要未明确说明具体的数据集或模型架构细节，但强调了这种融合策略的有效性。",
      "result": "主要实验结果表明，Topeax 在聚类恢复和聚类描述方面优于基线方法 Top2Vec 和 BERTopic，提高了主题建模的性能。尽管摘要未提供具体的准确率数据，但它指出 Topeax 表现出更稳定的行为，对样本大小和超参数的变化响应更一致，减少了现有多变性问题。这支持了其在提高模型可靠性和输出质量方面的优势。",
      "conclusion": "Topeax 的主要贡献在于提出了一种更可靠的聚类主题模型，通过密度峰值检测和词汇-语义融合，解决了现有方法在发现聚类和评估术语重要性方面的缺陷。该研究具有学术价值，推动了主题建模技术的发展；在实际应用上，能生成更高质量和稳定的主题，适用于文本挖掘和信息检索领域。未来工作方向可能包括进一步优化算法和处理更大规模数据集。",
      "tags": [
        "Topic Modeling",
        "Text Clustering",
        "Density Peak Detection",
        "Lexical-Semantic Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:46.216027Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21464",
    "title": "Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation",
    "authors": [
      "Yuan Sui",
      "Bryan Hooi"
    ],
    "abstract": "Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21464.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21464",
    "published": "2026-01-29T09:41:14Z",
    "updated": "2026-01-29T09:41:14Z",
    "comment": "Work in Progress",
    "light_analysis": {
      "overview": "论文提出CoNL框架，通过meta-evaluation和多代理自我玩，使LLMs能在无地面真实标签的任务中联合优化生成和判断能力，实现自演化。",
      "motivation": "研究针对不可验证任务（如创意写作、对话、伦理推理）缺乏地面真实标签的挑战。现有LLM-as-Judge方法虽可扩展，但受限于评估者自身质量，无法识别优质解决方案，且存在评估偏见（如偏好冗长而非质量）。这凸显了meta-evaluation的重要性，即评估和改进评估者本身，以提供更可靠的训练信号，从而提升LLMs在复杂任务中的表现。",
      "method": "论文引入CoNL框架，采用多代理自我玩机制，多个代理共享相同策略进行结构化对话，包括提议、批评和修改解决方案。关键创新在于以批评能否帮助其他代理改进解决方案来衡量批评质量，并分配诊断奖励作为meta-evaluation的明确监督。这实现了生成和判断能力的联合优化，无需外部评估者或地面真实数据。摘要未明确说明具体使用的数据集和模型架构细节。",
      "result": "在五个基准实验上，CoNL相较于自我奖励基线取得了持续的性能改进，同时保持了训练过程的稳定性。摘要未提供具体指标（如准确率提升百分比），但强调了效果的一致性和训练稳定性，展示了该方法在克服评估偏见和提升模型自我演化能力方面的有效性。",
      "conclusion": "CoNL框架的主要贡献在于提出了一种通过meta-evaluation和结构化自我玩实现LLMs自演化的方法，解决了不可验证任务的学习难题。其学术价值在于丰富了无监督学习的技术路径，实际应用潜力包括提升LLMs在创意对话、伦理推理等领域的性能。未来工作可能涉及扩展应用范围、优化计算效率以及进一步验证其在多样任务中的泛化能力。",
      "tags": [
        "Large Language Models",
        "Meta-Evaluation",
        "Self-Play",
        "Multi-Agent Systems",
        "Dialogue Systems"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:16.141032Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21462",
    "title": "Partial Feedback Online Learning",
    "authors": [
      "Shihao Shao",
      "Cong Fang",
      "Zhouchen Lin",
      "Dacheng Tao"
    ],
    "abstract": "We study partial-feedback online learning, where each instance admits a set of correct labels, but the learner only observes one correct label per round; any prediction within the correct set is counted as correct. This model captures settings such as language generation, where multiple responses may be valid but data provide only a single reference. We give a near-complete characterization of minimax regret for both deterministic and randomized learners in the set-realizable regime, i.e., in the regime where sublinear regret is generally attainable. For deterministic learners, we introduce the Partial-Feedback Littlestone dimension (PFLdim) and show it precisely governs learnability and minimax regret; technically, PFLdim cannot be defined via the standard version space, requiring a new collection version space viewpoint and an auxiliary dimension used only in the proof. We further develop the Partial-Feedback Measure Shattering dimension (PMSdim) to obtain tight bounds for randomized learners. We identify broad conditions ensuring inseparability between deterministic and randomized learnability (e.g., finite Helly number or nested-inclusion label structure), and extend the argument to set-valued online learning, resolving an open question of Raman et al. [2024b]. Finally, we show a sharp separation from weaker realistic and agnostic variants: outside set realizability, the problem can become information-theoretically intractable, with linear regret possible even for $|H|=2$. This highlights the need for fundamentally new, noise-sensitive complexity measures to meaningfully characterize learnability beyond set realizability.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21462.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21462",
    "published": "2026-01-29T09:39:11Z",
    "updated": "2026-01-29T09:39:11Z",
    "comment": "32 pages",
    "light_analysis": {
      "overview": "本研究近乎完整地特征化了集合可实现性下部分反馈在线学习的极小极大后悔，并引入了PFLdim和PMSdim等新维度概念。",
      "motivation": "研究动机是解决部分反馈在线学习问题，其中每个实例有一组正确标签，但学习者每轮只观察到一个正确标签，任何在正确集合内的预测都被视为正确。这模拟了如语言生成等场景，其中多个响应可能有效但数据只提供单一参考。现有方法未能充分表征在集合可实现性下的学习能力和后悔界限，缺乏新理论工具，尤其在解决开放问题和扩展至集合值在线学习方面存在不足。",
      "method": "论文引入Partial-Feedback Littlestone dimension (PFLdim) 来表征确定性学习者的学习能力，基于新的集合版本空间视角而非标准版本空间，并使用了辅助维度仅在证明中。同时，开发Partial-Feedback Measure Shattering dimension (PMSdim) 来获得随机学习者的紧界。这些维度在集合可实现性下精确控制极小极大后悔，技术特色包括对嵌套包含标签结构的分析。",
      "result": "结果显示PFLdim精确决定了确定性学习者的可学习性和极小极大后悔，PMSdim为随机学习者提供了紧界。识别了广泛条件如有限Helly数或嵌套包含标签结构，确保确定性和随机性可学习性不可分离。扩展至集合值在线学习解决了Raman等人的开放问题。在集合可实现性外，问题可能信息理论不可处理，导致线性后悔，即使在|H|=2时也如此。",
      "conclusion": "论文主要贡献是提供了部分反馈在线学习的理论特征，引入了PFLdim和PMSdim等新维度，解决了开放问题，并强调了在集合可实现性外需要新的噪声敏感复杂度度量。这项研究推进了在线学习理论，对语言生成等应用有实际价值，未来工作可能涉及开发更通用的复杂度度量以应对更复杂的场景。",
      "tags": [
        "Online Learning",
        "Partial Feedback",
        "Littlestone Dimension",
        "Minimax Regret",
        "Set-Valued Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:26.560052Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21461",
    "title": "L$^3$: Large Lookup Layers",
    "authors": [
      "Albert Tseng",
      "Christopher De Sa"
    ],
    "abstract": "Modern sparse language models typically achieve sparsity through Mixture-of-Experts (MoE) layers, which dynamically route tokens to dense MLP \"experts.\" However, dynamic hard routing has a number of drawbacks, such as potentially poor hardware efficiency and needing auxiliary losses for stable training. In contrast, the tokenizer embedding table, which is natively sparse, largely avoids these issues by selecting a single embedding per token at the cost of not having contextual information. In this work, we introduce the Large Lookup Layer (L$^3$), which unlocks a new axis of sparsity by generalizing embedding tables to model decoder layers. L$^3$ layers use static token-based routing to aggregate a set of learned embeddings per token in a context-dependent way, allowing the model to efficiently balance memory and compute by caching information in embeddings. L$^3$ has two main components: (1) a systems-friendly architecture that allows for fast training and CPU-offloaded inference with no overhead, and (2) an information-theoretic embedding allocation algorithm that effectively balances speed and quality. We empirically test L$^3$ by training transformers with up to 2.6B active parameters and find that L$^3$ strongly outperforms both dense models and iso-sparse MoEs in both language modeling and downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21461.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21461",
    "published": "2026-01-29T09:37:31Z",
    "updated": "2026-01-29T09:37:31Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "本论文提出L$^3$（大型查找层），一种通过静态token路由泛化嵌入表的新稀疏模型架构，以平衡内存和计算并提高效率。",
      "motivation": "现代稀疏语言模型常使用混合专家（MoE）层实现稀疏性，但动态硬路由存在硬件效率低下和需要辅助损失以确保训练稳定性等问题。相比之下，tokenizer嵌入表虽为稀疏设计，却缺乏上下文信息，限制了模型性能。本研究旨在开发一种方法，结合稀疏性和上下文依赖性，以克服现有技术的不足，提升语言模型在资源受限环境下的实用性和效率。",
      "method": "论文引入L$^3$层，通过静态基于token的路由聚合每个token的学习嵌入，实现上下文依赖的稀疏性。关键创新点包括：系统友好的架构，支持快速训练和无开销的CPU卸载推理；以及基于信息论的嵌入分配算法，平衡速度和模型质量。该方法泛化了嵌入表到解码器层，允许通过缓存信息在嵌入中优化内存与计算权衡，实验中使用transformers模型，训练高达2.6B活动参数。",
      "result": "实验表明，L$^3$在语言建模和下游任务中显著优于密集模型和同等稀疏度的混合专家（MoE）模型。尽管摘要未提供具体准确率数据，但强调其“强烈超越”基线方法，训练了高达2.6B活动参数的transformers，证实了L$^3$在保持稀疏性的同时，有效提升了模型性能和效率，为实际应用提供了有力支撑。",
      "conclusion": "本研究的主要贡献是提出L$^3$，为稀疏语言模型开辟了新方向，解决了动态硬路由的硬件和训练挑战。其系统友好设计和信息论算法在学术上推动了稀疏模型的发展，在实际应用中适合资源优化部署。未来工作可能包括进一步优化算法或扩展至更广泛的任务，以增强模型的泛化能力和实用性。",
      "tags": [
        "Large Lookup Layer",
        "Sparse Language Models",
        "Mixture-of-Experts",
        "Token Embedding",
        "Information-Theoretic Algorithms"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:43.046186Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21459",
    "title": "HER: Human-like Reasoning and Reinforcement Learning for LLM Role-playing",
    "authors": [
      "Chengyu Du",
      "Xintao Wang",
      "Aili Chen",
      "Weiyuan Li",
      "Rui Xu",
      "Junteng Liu",
      "Zishan Huang",
      "Rong Tian",
      "Zijun Sun",
      "Yuhao Li",
      "Liheng Feng",
      "Deming Ding",
      "Pengyu Zhao",
      "Yanghua Xiao"
    ],
    "abstract": "LLM role-playing, i.e., using LLMs to simulate specific personas, has emerged as a key capability in various applications, such as companionship, content creation, and digital games. While current models effectively capture character tones and knowledge, simulating the inner thoughts behind their behaviors remains a challenge. Towards cognitive simulation in LLM role-play, previous efforts mainly suffer from two deficiencies: data with high-quality reasoning traces, and reliable reward signals aligned with human preferences. In this paper, we propose HER, a unified framework for cognitive-level persona simulation. HER introduces dual-layer thinking, which distinguishes characters' first-person thinking from LLMs' third-person thinking. To bridge these gaps, we curate reasoning-augmented role-playing data via reverse engineering and construct human-aligned principles and reward models. Leveraging these resources, we train \\method models based on Qwen3-32B via supervised and reinforcement learning. Extensive experiments validate the effectiveness of our approach. Notably, our models significantly outperform the Qwen3-32B baseline, achieving a 30.26 improvement on the CoSER benchmark and a 14.97 gain on the Minimax Role-Play Bench. Our datasets, principles, and models will be released to facilitate future research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21459.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21459",
    "published": "2026-01-29T09:35:27Z",
    "updated": "2026-01-29T09:35:27Z",
    "comment": "41pages, 10 figures",
    "light_analysis": {
      "overview": "HER框架通过双层思维区分角色与模型思考，结合人类对齐的推理数据和强化学习，显著提升了LLM角色扮演的认知模拟能力。",
      "motivation": "LLM角色扮演在陪伴、内容创作和数字游戏等应用中需求增长，但现有方法难以模拟角色行为背后的内在思维，限制了真实性。研究背景在于当前方法缺乏高质量推理轨迹的数据和与人类偏好对齐的可靠奖励信号，导致认知模拟效果不佳。现有不足主要体现在这两个方面，阻碍了LLM角色扮演从表层模拟向深层认知的发展。因此，本研究旨在通过解决数据与奖励问题，推动更真实的角色模拟技术。",
      "method": "HER框架引入双层思维，区分角色的第一人称思维和LLMs的第三人称思维，以模拟内在认知过程。关键创新是通过逆向工程策划推理增强的角色扮演数据，构建人类对齐的原则和奖励模型，以提供高质量训练资源。技术路线基于Qwen3-32B模型，结合监督学习和强化学习进行优化，实现认知级人设模拟。具体地，利用策划的数据和奖励信号，通过训练过程弥合推理轨迹和人类偏好的差距，提升模型的模拟能力。",
      "result": "实验结果表明，HER模型在关键基准上表现优异，显著优于Qwen3-32B基线。在CoSER基准上，模型实现了30.26的性能提升，在Minimax Role-Play Bench上提升了14.97。这些具体数据验证了方法的有效性，显示认知模拟能力有显著改善。对比基线方法，HER模型通过增强推理和奖励对齐，在角色扮演任务中取得了更好的效果，证实了框架在提升模拟真实性方面的优势。",
      "conclusion": "HER框架通过整合双层思维、推理数据和强化学习，有效解决了LLM角色扮演中数据缺乏和奖励信号问题，显著提升了认知模拟的真实性。研究的学术价值在于推动了LLM角色扮演领域向认知层级的深入，提供了数据集、原则和模型等开放资源，促进未来研究。实际应用价值体现在陪伴、内容创作和游戏等场景中更真实的角色交互。未来工作可通过资源发布，探索更多认知模拟方向或扩展到其他领域。",
      "tags": [
        "LLM Role-playing",
        "Reinforcement Learning",
        "Human-like Reasoning",
        "Cognitive Simulation",
        "Reward Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:02.521535Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21458",
    "title": "Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization",
    "authors": [
      "Midou Guo",
      "Qilin Yin",
      "Wei Lu",
      "Xiangyang Luo",
      "Rui Yang"
    ],
    "abstract": "Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21458.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21458",
    "published": "2026-01-29T09:35:27Z",
    "updated": "2026-01-29T09:35:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一个基于重建误差的弱监督时间伪造定位框架RT-DeepLoc，用于细粒度识别deepfakes的伪造时段。",
      "motivation": "现代deepfakes已发展为局部和间歇性操纵，需要精确的时间定位，以应对视频篡改检测的挑战。由于帧级标注成本过高，现有方法依赖于视频级标签，但缺乏细粒度线索，导致定位精度不足。因此，研究弱监督方法成为实际必要，以降低成本并提高实用性，从而解决现有技术在效率和准确性方面的局限性。",
      "method": "本研究提出RT-DeepLoc框架，核心方法是使用仅基于真实数据训练的Masked Autoencoder（MAE），学习时空模式，通过重建误差识别伪造段。关键创新在于引入非对称视频内对比损失（AICL），利用重建线索增强真实特征的紧凑性，建立稳定决策边界，以提升局部区分性和对未见伪造的泛化能力。技术细节包括在大规模数据集上训练，专注于时空模式建模，无需伪造数据。",
      "result": "在大规模数据集（如LAV-DF）上的广泛实验表明，RT-DeepLoc在弱监督时间伪造定位任务中实现了最先进的性能。与基线方法相比，该框架在定位精度和鲁棒性方面表现出显著提升，摘要未明确说明具体数值指标（如准确率），但验证了方法的有效性。",
      "conclusion": "RT-DeepLoc的主要贡献是提供了一个高效的弱监督框架，用于细粒度时间伪造定位，降低了标注成本并提高了实用性。研究具有学术价值，推动了deepfake检测技术的发展，潜在应用包括视频内容验证和防伪系统。未来工作可扩展至多模态数据或改进对复杂伪造的鲁棒性，摘要未明确说明具体局限性。",
      "tags": [
        "Weakly Supervised Learning",
        "Masked Autoencoder",
        "Contrastive Learning",
        "Deepfake Detection",
        "Temporal Localization"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:07.907640Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21453",
    "title": "LION: A Clifford Neural Paradigm for Multimodal-Attributed Graph Learning",
    "authors": [
      "Xunkai Li",
      "Zhengyu Wu",
      "Zekai Chen",
      "Henan Sun",
      "Daohan Su",
      "Guang Zeng",
      "Hongchao Qin",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "Recently, the rapid advancement of multimodal domains has driven a data-centric paradigm shift in graph ML, transitioning from text-attributed to multimodal-attributed graphs. This advancement significantly enhances data representation and expands the scope of graph downstream tasks, such as modality-oriented tasks, thereby improving the practical utility of graph ML. Despite its promise, limitations exist in the current neural paradigms: (1) Neglect Context in Modality Alignment: Most existing methods adopt topology-constrained or modality-specific operators as tokenizers. These aligners inevitably neglect graph context and inhibit modality interaction, resulting in suboptimal alignment. (2) Lack of Adaptation in Modality Fusion: Most existing methods are simple adaptations for 2-modality graphs and fail to adequately exploit aligned tokens equipped with topology priors during fusion, leading to poor generalizability and performance degradation. To address the above issues, we propose LION (c\\underline{LI}ff\\underline{O}rd \\underline{N}eural paradigm) based on the Clifford algebra and decoupled graph neural paradigm (i.e., propagation-then-aggregation) to implement alignment-then-fusion in multimodal-attributed graphs. Specifically, we first construct a modality-aware geometric manifold grounded in Clifford algebra. This geometric-induced high-order graph propagation efficiently achieves modality interaction, facilitating modality alignment. Then, based on the geometric grade properties of aligned tokens, we propose adaptive holographic aggregation. This module integrates the energy and scale of geometric grades with learnable parameters to improve modality fusion. Extensive experiments on 9 datasets demonstrate that LION significantly outperforms SOTA baselines across 3 graph and 3 modality downstream tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21453.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21453",
    "published": "2026-01-29T09:30:36Z",
    "updated": "2026-01-29T09:30:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出 LION，一种基于 Clifford 代数的神经范式，用于优化多模态属性图学习中的模态对齐和融合，显著提升下游任务性能。",
      "motivation": "该研究的动机源于多模态图学习的发展趋势及其局限性。随着从文本属性图到多模态属性图的范式转变，数据表示和下游任务范围得到增强，但现有方法存在不足：在模态对齐中，多数方法使用拓扑约束或模态特定算子作为标记器，忽视图上下文并抑制模态交互，导致次优对齐；在模态融合中，多数方法仅适配双模态图，未充分利用对齐标记的拓扑先验，导致泛化性差和性能下降，这些缺陷促使研究新的解决方案以提高实用性和效果。",
      "method": "LION 方法基于 Clifford 代数和解耦图神经范式（传播-聚合），实现对齐-融合流程。具体而言，首先构建基于 Clifford 代数的模态感知几何流形，通过几何诱导的高阶图传播促进模态交互，实现有效的模态对齐。然后，提出自适应全息聚合模块，利用对齐标记的几何等级属性，将几何等级的能量和尺度与可学习参数整合，以增强模态融合的适应性和性能。该方法融合了代数几何和图神经技术的关键创新。",
      "result": "论文通过广泛实验验证了 LION 的有效性，在 9 个数据集上进行评估，覆盖 3 个图下游任务和 3 个模态下游任务。结果显示，LION 在所有任务中均显著优于当前最先进的基线方法，证明了其在提升对齐准确性、增强融合泛化性和改进整体性能方面的优势。尽管摘要未明确提供具体性能指标数据，但强调了其在多模态图学习领域的显著性能提升。",
      "conclusion": "LION 范式的提出，成功解决了多模态属性图学习中的对齐和融合挑战。基于 Clifford 代数的几何方法创新性地提升了模态交互和融合适应性，具有重要的学术价值，扩展了图机器学习的研究边界，并为实际应用如多模态数据分析提供了更有效的工具。未来工作可探索更多模态类型的扩展或进一步优化几何模型以适应复杂场景。",
      "tags": [
        "Clifford Algebra",
        "Multimodal-Attributed Graphs",
        "Graph Neural Paradigm",
        "Modality Alignment",
        "Adaptive Aggregation"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:25.981978Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21452",
    "title": "SAGE: Sequence-level Adaptive Gradient Evolution for Generative Recommendation",
    "authors": [
      "Yu Xie",
      "Xing Kai Ren",
      "Ying Qi",
      "Hu Yao"
    ],
    "abstract": "While works such as OneRec have validated the scaling laws of Large Language Models (LLMs) in recommender systems, they rely on a cumbersome separate vocabulary. This dependency prevents the model architecture from reusing native LLM vocabularies, resulting in high maintenance costs and poor scalability. In response, we aim to efficiently reuse open-source LLM architectures without constructing a separate tokenization vocabulary. Furthermore, we identify that the optimization strategy of OneRec Gradient Bounded Policy Optimization (GBPO),suffers from a \"Symmetric Conservatism\" problem: its static gradient boundaries structurally suppress the update momentum required for cold-start items and fail to prevent diversity collapse in high-noise environments.To address this issue, we propose SAGE (Sequence-level Adaptive Gradient Evolution), a unified optimization framework tailored for list-wise generative recommendation. SAGE introduces two key innovations:(1) Sequence-level Signal Decoupling: By combining a geometric mean importance ratio with decoupled multi-objective advantages, we eliminate token-level variance and resolve the \"Reward Collapse\" problem. (2) Asymmetric Adaptive Dynamics: We construct a dynamic gradient manifold that applies a \"Boost Factor\" to high-potential cold start items to achieve super-linear updates and employs an \"Entropy Aware Penalty\" to break information cocoons. Theoretical analysis and empirical results demonstrate that SAGE effectively unblocks cold-start traffic and sustains recommendation diversity, all while retaining the numerical stability of GBPO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21452.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21452",
    "published": "2026-01-29T09:30:13Z",
    "updated": "2026-01-29T09:30:13Z",
    "comment": "arXiv admin note: text overlap with arXiv:2506.19235",
    "light_analysis": {
      "overview": "论文提出了SAGE框架，通过序列级自适应梯度进化优化生成推荐，解决冷启动和多样性问题。",
      "motivation": "现有方法如OneRec验证了LLM在推荐系统中的扩展定律，但依赖于独立词汇表，导致无法重用原生LLM词汇表，维护成本高且可扩展性差。此外，GBPO优化策略存在“对称保守主义”问题，其静态梯度边界抑制了冷启动项目所需的更新动量，并无法防止高噪声环境中的多样性崩溃。这些问题限制了LLM在推荐系统中的高效应用，因此需要开发新方法来克服这些挑战，提升推荐性能。",
      "method": "SAGE是一个为列表式生成推荐设计的统一优化框架，引入两个关键创新：序列级信号解耦结合几何平均重要性比与解耦多目标优势，以消除令牌级方差并解决“奖励崩溃”问题；非对称自适应动态构建动态梯度流形，对高潜力冷启动项目应用“增强因子”实现超线性更新，并使用“熵感知惩罚”打破信息茧房。该方法重用开源LLM架构，无需构建独立词汇表，优化梯度进化过程。",
      "result": "摘要表明理论分析和实证结果验证了SAGE能有效解锁冷启动流量并维持推荐多样性，同时保持GBPO的数值稳定性。摘要未明确说明具体性能指标如准确率提升或效率改进，但暗示该方法在解决冷启动和多样性问题上优于基线，改进推荐效果。与现有方法对比，SAGE解决了对称保守主义问题，提升了整体性能。",
      "conclusion": "SAGE的主要贡献是提出了一个统一优化框架，解决了LLM推荐中独立词汇表依赖和梯度优化问题，学术价值在于改进了生成推荐的优化策略，促进LLM高效重用；实际应用价值包括降低维护成本、提升可扩展性和推荐质量。未来工作可能涉及扩展到更复杂场景或进一步优化自适应机制，摘要未明确说明局限性。",
      "tags": [
        "Generative Recommendation",
        "Large Language Models (LLMs)",
        "Sequence-level Optimization",
        "Gradient Evolution",
        "Adaptive Dynamics"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:43.646475Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21450",
    "title": "Variance & Greediness: A comparative study of metric-learning losses",
    "authors": [
      "Donghuo Zeng",
      "Hao Niu",
      "Zhi Li",
      "Masato Taya"
    ],
    "abstract": "Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21450.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21450",
    "published": "2026-01-29T09:28:30Z",
    "updated": "2026-01-29T09:28:30Z",
    "comment": "5 pages, 2 figures, 3 tables. Accepted by ICASSP 2026",
    "light_analysis": {
      "overview": "该论文引入VARIANCE和GREEDINESS诊断框架，系统性比较七种度距学习损失函数，揭示了效率与粒度之间的权衡，并提供损失函数选择的实用指导。",
      "motivation": "度距学习在图像检索等任务中具有核心作用，但其对嵌入空间几何结构和优化动态的影响缺乏深入理解。现有研究往往局限于个别损失函数的性能评估，缺乏系统性比较框架，导致选择损失函数时缺乏理论依据。本研究旨在通过开发新指标，全面分析不同损失函数的行为，以填补这一空白，提升检索系统的性能和可解释性。摘要未明确说明现有方法的具体不足，但隐含了系统性比较的必要性。",
      "method": "论文提出了一个诊断框架，包含VARIANCE（类内方差和类间方差）和GREEDINESS（活动比率和梯度范数）两个维度，用于量化分析七种代表性度距学习损失函数：Contrastive、Triplet、N-pair、InfoNCE、ArcFace、SCL和CCL。在五个图像检索数据集上进行实验，评估这些损失函数对嵌入几何和优化动态的影响。关键创新在于将复杂损失函数行为转化为可测量的指标，如通过方差分析嵌入结构的多样性和通过梯度范数考察收敛特性，从而实现客观比较。",
      "result": "实验分析显示，Triplet和SCL损失函数在图像检索中保留较高的类内方差和更清晰的类间边界，尤其在细粒度设置下提升top-1检索性能。相比之下，Contrastive和InfoNCE通过大量小更新快速压缩嵌入空间，加速收敛，但可能导致类结构过度简化，影响多样性保留。N-pair损失函数实现了较大的类间均值分离，但间距不均匀，降低了整体效果。这些发现揭示了损失函数在效率（收敛速度）和粒度（嵌入多样性）之间的权衡，为后续优化提供了数据支撑。摘要未提供具体准确率数据，但描述了性能趋势。",
      "conclusion": "本研究的主要贡献在于引入诊断框架，系统性比较度距学习损失函数，揭示了效率与粒度的权衡关系。这提供了理论基础和实用指导：在需要保留多样性和区分难样本时，偏好Triplet或SCL；在追求快速嵌入压缩时，选择Contrastive或InfoNCE。学术上，该方法促进了度距学习领域的深入分析；应用上，有助于优化检索系统设计。未来工作方向包括扩展到更多损失函数和数据集，以及进一步探讨权衡机制的数学基础。摘要未明确说明局限性。",
      "tags": [
        "Metric Learning",
        "Contrastive Learning",
        "Loss Functions",
        "Image Retrieval",
        "Variance Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:00.763797Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21448",
    "title": "ChipBench: A Next-Step Benchmark for Evaluating LLM Performance in AI-Aided Chip Design",
    "authors": [
      "Zhongkai Yu",
      "Chenyang Zhou",
      "Yichen Lin",
      "Hejia Zhang",
      "Haotian Ye",
      "Junxia Cui",
      "Zaifeng Pan",
      "Jishen Zhao",
      "Yufei Ding"
    ],
    "abstract": "While Large Language Models (LLMs) show significant potential in hardware engineering, current benchmarks suffer from saturation and limited task diversity, failing to reflect LLMs' performance in real industrial workflows. To address this gap, we propose a comprehensive benchmark for AI-aided chip design that rigorously evaluates LLMs across three critical tasks: Verilog generation, debugging, and reference model generation. Our benchmark features 44 realistic modules with complex hierarchical structures, 89 systematic debugging cases, and 132 reference model samples across Python, SystemC, and CXXRTL. Evaluation results reveal substantial performance gaps, with state-of-the-art Claude-4.5-opus achieving only 30.74\\% on Verilog generation and 13.33\\% on Python reference model generation, demonstrating significant challenges compared to existing saturated benchmarks where SOTA models achieve over 95\\% pass rates. Additionally, to help enhance LLM reference model generation, we provide an automated toolbox for high-quality training data generation, facilitating future research in this underexplored domain. Our code is available at https://github.com/zhongkaiyu/ChipBench.git.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21448.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21448",
    "published": "2026-01-29T09:26:55Z",
    "updated": "2026-01-29T09:26:55Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出ChipBench基准，全面评估大型语言模型在AI辅助芯片设计中的性能，涵盖Verilog生成、调试和参考模型生成任务。",
      "motivation": "大型语言模型在硬件工程中潜力巨大，但现有评估基准存在饱和度和任务多样性不足的问题，无法真实反映工业工作流程的需求。当前基准任务简单，模型性能接近饱和（通过率超过95%），未能有效评估模型在复杂任务中的能力，限制了LLM在AI辅助芯片设计中的研究和应用。因此，需要新的、更严格的基准来填补这一空白，推动领域发展。",
      "method": "本研究设计并实现了ChipBench基准，聚焦于评估LLM在三个关键任务上的表现：Verilog生成、系统调试和参考模型生成。基准基于44个具有复杂层次结构的真实模块、89个系统调试案例以及132个参考模型样本（涵盖Python、SystemC和CXXRTL），模拟真实工业场景。关键创新在于提供自动化工具箱，用于生成高质量训练数据，支持未来研究在未充分探索的领域中进行数据增强。",
      "result": "评估结果显示，LLM在ChipBench上表现不佳，与现有饱和基准形成鲜明对比。例如，最先进的Claude-4.5-opus模型在Verilog生成任务中仅达到30.74%通过率，在Python参考模型生成任务中仅13.33%。相比现有基准中模型性能超过95%，新基准揭示了显著的性能差距和挑战，突显了LLM在复杂硬件设计任务中的局限性。",
      "conclusion": "本论文的主要贡献是提出了ChipBench基准，为AI辅助芯片设计中LLM的性能评估提供了更全面的标准，填补了现有基准的不足。研究具有重要学术价值，通过严格的评估促进了该领域的研究进展，并具有实际应用价值，有助于指导模型改进和工业应用。未来工作可借助提供的自动化工具箱生成高质量数据，进一步探索LLM在硬件工程中的潜力。",
      "tags": [
        "Large Language Model",
        "AI-aided Chip Design",
        "Benchmark Evaluation",
        "Verilog Generation",
        "Debugging"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:06.491285Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21446",
    "title": "Synthetic Pattern Generation and Detection of Financial Activities using Graph Autoencoders",
    "authors": [
      "Francesco Zola",
      "Lucia Muñoz",
      "Andrea Venturi",
      "Amaia Gil"
    ],
    "abstract": "Illicit financial activities such as money laundering often manifest through recurrent topological patterns in transaction networks. Detecting these patterns automatically remains challenging due to the scarcity of labeled real-world data and strict privacy constraints. To address this, we investigate whether Graph Autoencoders (GAEs) can effectively learn and distinguish topological patterns that mimic money laundering operations when trained on synthetic data. The analysis consists of two phases: (i) data generation, where synthetic samples are created for seven well-known illicit activity patterns using parametrized generators that preserve structural consistency while introducing realistic variability; and (ii) model training and validation, where separate GAEs are trained on each pattern without explicit labels, relying solely on reconstruction error as an indicator of learned structure. We compare three GAE implementations based on three distinct convolutional layers: Graph Convolutional (GAE-GCN), GraphSAGE (GAE-SAGE), and Graph Attention Network (GAE-GAT). Experimental results show that GAE-GCN achieves the most consistent reconstruction performance across patterns, while GAE-SAGE and GAE-GAT exhibit competitive results only in few specific patterns. These findings suggest that graph-based representation learning on synthetic data provides a viable path toward developing AI-driven tools for detecting illicit behaviors, overcoming the limitations of financial datasets.",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21446.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21446",
    "published": "2026-01-29T09:25:13Z",
    "updated": "2026-01-29T09:25:13Z",
    "comment": "Accept to The 7th International Workshop on Statistical Methods and Artificial Intelligence (IWSMAI'26)",
    "light_analysis": {
      "overview": "论文提出使用图自动编码器在合成数据上学习金融洗钱模式的拓扑结构，通过实验证明图卷积自动编码器表现最优。",
      "motivation": "洗钱等金融犯罪活动在交易网络中表现为重复的拓扑模式，自动检测这些模式对金融监管至关重要。然而，现实中标记数据稀缺且受隐私限制，导致传统方法难以应用。本研究旨在探索合成数据和图自动编码器来克服数据不足问题，学习并区分洗钱操作的拓扑模式，为金融犯罪检测提供新思路。",
      "method": "研究方法分为两个阶段：数据生成阶段使用参数化生成器为七种已知洗钱模式创建合成样本，保持结构一致性并引入变异性；模型训练阶段分别训练基于三种卷积层的图自动编码器，包括图卷积（GAE-GCN）、GraphSAGE（GAE-SAGE）和图注意力网络（GAE-GAT），不依赖标签，仅通过重建误差作为结构学习指标，实现无监督学习。",
      "result": "实验结果显示，GAE-GCN在所有模式中表现出最一致的重建性能，而GAE-SAGE和GAE-GAT仅在少数特定模式中具有竞争力。这表明图卷积自动编码器在捕捉洗钱模式拓扑结构方面更具鲁棒性，其他方法则对模式类型更敏感。性能比较基于重建误差，未给出具体数值，但突出了不同架构的适用性差异。",
      "conclusion": "研究证明基于合成数据的图表示学习为检测金融洗钱活动提供了可行路径，克服了数据稀缺和隐私限制。学术上，推动了图自动编码器在无监督学习中的应用；实际上，为AI驱动金融工具开发奠定了基础。潜在局限性包括合成数据与真实数据的差异，未来工作可扩展模式类型或探索迁移学习。",
      "tags": [
        "Graph Autoencoders",
        "Graph Convolutional Networks",
        "GraphSAGE",
        "Graph Attention Networks",
        "Synthetic Data Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:33.503725Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21444",
    "title": "Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention",
    "authors": [
      "Yuxiang Huang",
      "Mingye Li",
      "Xu Han",
      "Chaojun Xiao",
      "Weilin Zhao",
      "Ao Sun",
      "Ziqi Yuan",
      "Hao Zhou",
      "Fandong Meng",
      "Zhiyuan Liu"
    ],
    "abstract": "The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21444.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21444",
    "published": "2026-01-29T09:23:13Z",
    "updated": "2026-01-29T09:23:13Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "论文提出Spava框架，通过序列并行和近似注意力加速长视频理解，解决了现有方法的效率瓶颈。",
      "motivation": "长视频推理效率低是大型多模态模型的关键瓶颈，主要源于预填充阶段的计算密集性。现有方法如压缩视觉嵌入或单GPU稀疏注意力，虽试图加速但效果有限，常导致性能下降或无法处理更长视频。Spava旨在克服这些不足，提供高效解决方案，以支持复杂视频分析应用，如监控和教育，避免现有方案的信息损失和并行性不足问题。",
      "method": "Spava采用序列并行框架，通过分布近似注意力到多个GPU，减少计算开销并提升并行处理能力。核心创新包括系统级优化如负载均衡和融合前向传递，这些措施确保能高效处理更多视觉嵌入而不需压缩，从而保持模型性能。该方法通过优化注意力机制，支持长视频推理跨GPU加速。",
      "result": "Spava在实验中展现显著加速效果，与基线方法FlashAttn、ZigZagRing和APB相比，加速比分别为12.72倍、1.70倍和1.18倍，且未出现显著性能损失。这验证了Spava在提升长视频推理效率方面的有效性，通过并行策略和优化，成功减少推理时间，同时保持任务性能。",
      "conclusion": "Spava通过序列并行和近似注意力机制，有效加速长视频理解，解决了现有方法的局限性。该研究为优化大型多模态模型提供了新思路，具有学术和实际价值，有助于视频分析技术的进步。摘要未明确说明局限性和未来工作方向，但潜在扩展可能包括进一步算法优化或应用于其他模态任务。",
      "tags": [
        "Large Multimodal Models",
        "Sequence Parallelism",
        "Approximate Attention",
        "GPU Acceleration",
        "System Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:25.837631Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21439",
    "title": "The Paradox of Robustness: Decoupling Rule-Based Logic from Affective Noise in High-Stakes Decision-Making",
    "authors": [
      "Jon Chun",
      "Katherine Elkins"
    ],
    "abstract": "While Large Language Models (LLMs) are widely documented to be sensitive to minor prompt perturbations and prone to sycophantic alignment with user biases, their robustness in consequential, rule-bound decision-making remains under-explored. In this work, we uncover a striking \"Paradox of Robustness\": despite their known lexical brittleness, instruction-tuned LLMs exhibit a behavioral and near-total invariance to emotional framing effects. Using a novel controlled perturbation framework across three high-stakes domains (healthcare, law, and finance), we quantify a robustness gap where LLMs demonstrate 110-300 times greater resistance to narrative manipulation than human subjects. Specifically, we find a near-zero effect size for models (Cohen's h = 0.003) compared to the substantial biases observed in humans (Cohen's h in [0.3, 0.8]). This result is highly counterintuitive and suggests the mechanisms driving sycophancy and prompt sensitivity do not necessarily translate to a failure in logical constraint satisfaction. We show that this invariance persists across models with diverse training paradigms. Our findings show that while LLMs may be \"brittle\" to how a query is formatted, they are remarkably \"stable\" against why a decision should be biased. Our findings establish that instruction-tuned models can decouple logical rule-adherence from persuasive narratives, offering a source of decision stability that complements, and even potentially de-biases, human judgment in institutional contexts. We release the 162-scenario benchmark, code, and data to facilitate the rigorous evaluation of narrative-induced bias and robustness on GitHub.com.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21439.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21439",
    "published": "2026-01-29T09:17:05Z",
    "updated": "2026-01-29T09:17:05Z",
    "comment": "22 page, 10 figures",
    "light_analysis": {
      "overview": "论文揭示了指令调优大型语言模型在高风险决策中对情感框架效应表现出高度鲁棒性，形成了'鲁棒性悖论'。",
      "motivation": "该研究动机源于大型语言模型在提示扰动和讨好用户偏差方面的已知脆弱性，但其在规则约束的高风险决策中的鲁棒性未被充分探索。高风险领域如医疗、法律和金融需要基于逻辑的客观决策，避免情感噪声干扰。现有研究多关注模型的语言敏感性，忽视了逻辑规则遵守与情感框架效应的解耦，导致对模型在关键决策中稳定性的评估不足，因此本工作旨在填补这一空白。",
      "method": "研究方法采用了一种新颖的受控扰动框架，在三个高风险领域（医疗、法律、金融）中量化大型语言模型对叙事操纵的抵抗力。核心创新在于设计了一个包含162个场景的基准，通过引入情感框架效应模拟偏差，测量指令调优LLMs在逻辑规则遵守上的行为不变性。该方法使用多样训练范式的模型进行测试，关键细节包括使用效应大小指标如Cohen's h来评估鲁棒性差距。",
      "result": "实验结果显示，指令调优的大型语言模型对情感框架效应表现出近乎零的效果大小（Cohen's h = 0.003），而人类则有显著偏差（Cohen's h在0.3到0.8之间）。具体而言，LLMs对叙事操纵的抵抗力比人类高出110到300倍，这一鲁棒性在不同训练范式的模型中持续存在，表明LLMs在满足逻辑约束方面具有高度稳定性，与人类易受情感影响形成鲜明对比。",
      "conclusion": "结论表明，指令调优模型能够解耦逻辑规则遵守与说服性叙事，在高风险决策中提供稳定的决策支持，补充并可能去偏差人类判断。研究贡献在于揭示了'鲁棒性悖论'，强调了LLMs在机构环境中的应用潜力。论文发布了162场景基准、代码和数据，促进了叙事诱导偏差的严格评估，未来工作可探索这一现象的内在机制。",
      "tags": [
        "Large Language Model",
        "Instruction Tuning",
        "Robustness Evaluation",
        "Affective Framing",
        "High-Stakes Decision-Making"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:10.011101Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21437",
    "title": "Accurate Network Traffic Matrix Prediction via LEAD: an LLM-Enhanced Adapter-Based Conditional Diffusion Model",
    "authors": [
      "Yu Sun",
      "Yaqiong Liu",
      "Nan Cheng",
      "Jiayuan Li",
      "Zihan Jia",
      "Xialin Du",
      "Mugen Peng"
    ],
    "abstract": "Driven by the evolution toward 6G and AI-native edge intelligence, network operations increasingly require predictive and risk-aware adaptation under stringent computation and latency constraints. Network Traffic Matrix (TM), which characterizes flow volumes between nodes, is a fundamental signal for proactive traffic engineering. However, accurate TM forecasting remains challenging due to the stochastic, non-linear, and bursty nature of network dynamics. Existing discriminative models often suffer from over-smoothing and provide limited uncertainty awareness, leading to poor fidelity under extreme bursts. To address these limitations, we propose LEAD, a Large Language Model (LLM)-Enhanced Adapter-based conditional Diffusion model. First, LEAD adopts a \"Traffic-to-Image\" paradigm to transform traffic matrices into RGB images, enabling global dependency modeling via vision backbones. Then, we design a \"Frozen LLM with Trainable Adapter\" model, which efficiently captures temporal semantics with limited computational cost. Moreover, we propose a Dual-Conditioning Strategy to precisely guide a diffusion model to generate complex, dynamic network traffic matrices. Experiments on the Abilene and GEANT datasets demonstrate that LEAD outperforms all baselines. On the Abilene dataset, LEAD attains a remarkable 45.2% reduction in RMSE against the best baseline, with the error margin rising only marginally from 0.1098 at one-step to 0.1134 at 20-step predictions. Meanwhile, on the GEANT dataset, LEAD achieves a 0.0258 RMSE at 20-step prediction horizon which is 27.3% lower than the best baseline.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21437.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21437",
    "published": "2026-01-29T09:16:05Z",
    "updated": "2026-01-29T09:16:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出LEAD模型，通过大型语言模型增强的适配器条件扩散方法，实现网络流量矩阵的高精度预测，解决了现有方法在复杂网络动态下的局限性。",
      "motivation": "随着6G和AI-native边缘智能的发展，网络运营需要在严格计算和延迟约束下进行预测性适应。网络流量矩阵作为流量工程的基础信号，其准确预测面临网络动态随机性、非线性和突发性的挑战。现有判别模型常存在过度平滑问题，不确定性感知有限，在极端突发时保真度不足，这限制了主动流量工程的效果，需要新方法来提高预测准确性和鲁棒性。",
      "method": "LEAD模型采用“流量到图像”范式，将流量矩阵转换为RGB图像，以利用视觉骨干网络建模全局依赖关系。设计“冻结LLM与可训练适配器”架构，在有限计算成本下高效捕捉时间语义。提出双条件策略，精确指导条件扩散模型生成复杂动态的网络流量矩阵，结合生成模型的优势以提升预测准确性和不确定性估计能力。",
      "result": "在Abilene和GEANT数据集上的实验表明，LEAD优于所有基线模型。在Abilene数据集上，相比最佳基线，RMSE降低了45.2%，从一步预测的0.1098轻微上升至20步预测的0.1134。在GEANT数据集上，20步预测的RMSE为0.0258，比最佳基线低27.3%，这显示了模型在长期预测中的稳定性和高精度性能。",
      "conclusion": "论文的主要贡献是提出了LEAD模型，有效解决了网络流量矩阵预测中的过度平滑和不确定性感知问题。通过结合大型语言模型和扩散模型，提高了预测准确性和鲁棒性，对6G和AI-native边缘智能背景下的网络运营具有重要应用价值。未来工作可进一步优化计算效率或扩展到其他网络预测任务。",
      "tags": [
        "Large Language Model",
        "Diffusion Model",
        "Adapter",
        "Network Traffic Matrix Prediction",
        "Conditional Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:41.794593Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21436",
    "title": "From Consistency to Complementarity: Aligned and Disentangled Multi-modal Learning for Time Series Understanding and Reasoning",
    "authors": [
      "Hang Ni",
      "Weijia Zhang",
      "Fei Wang",
      "Zezhi Shao",
      "Hao Liu"
    ],
    "abstract": "Advances in multi-modal large language models (MLLMs) have inspired time series understanding and reasoning tasks, that enable natural language querying over time series, producing textual analyses of complex temporal dynamics. Recent attempts hybridize numerical time series with their visualized plots, facilitating precise value reasoning and visual structure comprehension for comprehensive time series understanding of MLLMs. However, effective cross-modal integration remains challenging due to fine-grained temporal misalignment across modalities and severe entanglement between shared and modality-specific semantics, which hinder localized interpretation and complementary reasoning. To address these issues, we propose MADI, a multi-modal LLM enhanced with fine-grained alignment and disentangled interaction, featuring (1) Patch-level Alignment, which enforces physically grounded fine-grained correspondence across heterogeneous modalities, (2) Discrete Disentangled Interaction, which separates modality-common semantics into compact discrete latents and adaptively synergizes the purified modality-unique information, and (3) Critical-token Highlighting, which emphasizes informative, query-relevant signals for robust reasoning. Experiments on synthetic and real-world benchmarks show that MADI consistently outperforms general-purpose LLMs and time-series-specialized MLLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21436.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21436",
    "published": "2026-01-29T09:13:46Z",
    "updated": "2026-01-29T09:13:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出MADI模型，通过细粒度对齐和分解交互增强多模态LLM，以解决时间序列理解和推理中的语义纠缠问题。",
      "motivation": "随着多模态大型语言模型的发展，时间序列理解和推理任务允许自然语言查询分析复杂时间动态。然而，现有方法结合数值时间序列及其可视化图表时，面临跨模态的细粒度时间错位和共享与模态特定语义的严重纠缠问题，这阻碍了局部解释和互补推理，限制了模型的全面理解能力，表明改进跨模态集成的重要性。",
      "method": "MADI模型基于多模态LLM，引入三个关键技术：补丁级对齐，通过强制异质模态间的物理基础细粒度对应来确保时间一致性；离散分解交互，将模态共同语义分离到紧凑的离散潜变量中，并自适应整合纯化的模态独特信息；关键令牌高亮，强调信息丰富且查询相关的信号，以支持稳健推理。这些组件共同促进跨模态的互补学习，使用时间序列数据增强模型架构。",
      "result": "在合成和真实世界基准测试上，MADI模型一致优于通用大型语言模型和专门用于时间序列的多模态LLM。尽管摘要未提供具体性能指标如准确率，但实验表明该方法在时间序列理解和推理任务中具有显著优势，验证了其解决跨模态问题的有效性，提升了与基线方法的对比性能。",
      "conclusion": "本研究通过MADI模型解决了多模态时间序列理解中的关键挑战，如语义纠缠和细粒度对齐，提升了局部解释和互补推理能力。这为时间序列分析和多模态学习提供了新的技术路线，具有学术价值和实际应用潜力，例如在金融预测和医疗监测等领域。未来工作可进一步探索模型扩展性和实际场景应用，摘要未明确说明具体局限性。",
      "tags": [
        "Multi-modal Large Language Models",
        "Time Series Understanding",
        "Disentangled Learning",
        "Alignment Learning",
        "Attention Mechanism"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:00.286232Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21433",
    "title": "When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models",
    "authors": [
      "Katherine Elkins",
      "Jon Chun"
    ],
    "abstract": "When a user tells an AI system that someone \"should not\" take an action, the system ought to treat this as a prohibition. Yet many large language models do the opposite: they interpret negated instructions as affirmations. We audited 16 models across 14 ethical scenarios and found that open-source models endorse prohibited actions 77% of the time under simple negation and 100% under compound negation -- a 317% increase over affirmative framing. Commercial models fare better but still show swings of 19-128%. Agreement between models drops from 74% on affirmative prompts to 62% on negated ones, and financial scenarios prove twice as fragile as medical ones. These patterns hold under deterministic decoding, ruling out sampling noise. We present case studies showing how these failures play out in practice, propose the Negation Sensitivity Index (NSI) as a governance metric, and outline a tiered certification framework with domain-specific thresholds. The findings point to a gap between what current alignment techniques achieve and what safe deployment requires: models that cannot reliably distinguish \"do X\" from \"do not X\" should not be making autonomous decisions in high-stakes contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21433.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21433",
    "published": "2026-01-29T09:09:23Z",
    "updated": "2026-01-29T09:09:23Z",
    "comment": "13 pages, 5 figures",
    "light_analysis": {
      "overview": "该论文审计语言模型在否定指令下的敏感性，并提出否定敏感性指数（NSI）作为治理指标，以改善模型安全性。",
      "motivation": "研究动机在于大型语言模型常将否定指令错误解释为肯定，这一问题在高风险领域如医疗和金融中可能导致严重后果，因为模型无法可靠区分禁止与许可。现有对齐技术未能有效解决此不足，导致安全部署存在隐患，因此需要系统评估以提升模型在伦理场景下的可靠性。摘要指出模型在处理否定时的缺陷暴露了对齐技术的局限性，强调了对安全人工智能部署的迫切需求。",
      "method": "研究方法涉及审计16个语言模型在14个伦理场景下的表现，包括简单否定和复合否定，使用确定性解码以排除采样噪声。核心创新点是提出否定敏感性指数（NSI）作为量化评估指标，并设计分级认证框架，设定领域特定阈值来评估模型敏感性。通过系统测试，分析模型在不同场景下的行为差异，重点关注开源与商业模型的对比。摘要未明确说明具体数据集名称，但基于伦理场景进行推断。",
      "result": "实验结果显示，开源模型在简单否定下支持禁止行动的概率为77%，在复合否定下高达100%，比肯定提示增加317%。商业模型表现较好，但波动范围为19-128%。模型间一致性从肯定提示的74%下降到否定提示的62%，财务场景的脆弱性是医疗场景的两倍。这些模式在确定性解码下成立，排除了随机性影响，表明否定敏感性是普遍问题。结果突显了模型在否定指令处理上的显著缺陷。",
      "conclusion": "结论指出当前对齐技术存在差距，模型无法可靠区分“做X”与“不做X”，因此不应在高风险上下文中自主决策。研究贡献包括暴露模型弱点、提出NSI作为治理工具，以及框架用于认证，具有学术价值（推动语言模型安全性评估）和实际应用价值（指导安全部署）。未来工作可改进对齐方法或扩展评估到更多领域，摘要提及潜在局限性，但未具体说明未来方向细节。",
      "tags": [
        "Language Models",
        "Negation Sensitivity",
        "Model Auditing",
        "Governance Metrics",
        "Ethical AI"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:13.006647Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21426",
    "title": "MultiModal Fine-tuning with Synthetic Captions",
    "authors": [
      "Shohei Enomoto",
      "Shin'ya Yamaguchi"
    ],
    "abstract": "In this paper, we address a fundamental gap between pre-training and fine-tuning of deep neural networks: while pre-training has shifted from unimodal to multimodal learning with enhanced visual understanding, fine-tuning predominantly remains unimodal, limiting the benefits of rich pre-trained representations. To bridge this gap, we propose a novel approach that transforms unimodal datasets into multimodal ones using Multimodal Large Language Models (MLLMs) to generate synthetic image captions for fine-tuning models with a multimodal objective. Our method employs carefully designed prompts incorporating class labels and domain context to produce high-quality captions tailored for classification tasks. Furthermore, we introduce a supervised contrastive loss function that explicitly encourages clustering of same-class representations during fine-tuning, along with a new inference technique that leverages class-averaged text embeddings from multiple synthetic captions per image. Extensive experiments across 13 image classification benchmarks demonstrate that our approach outperforms baseline methods, with particularly significant improvements in few-shot learning scenarios. Our work establishes a new paradigm for dataset enhancement that effectively bridges the gap between multimodal pre-training and fine-tuning. Our code is available at https://github.com/s-enmt/MMFT.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21426.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21426",
    "published": "2026-01-29T09:03:45Z",
    "updated": "2026-01-29T09:03:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种新方法，利用多模态大语言模型生成合成图像描述，将单模态数据集转换为多模态数据集，以有效桥接预训练和微调之间的差距。",
      "motivation": "随着预训练模型从单模态转向多模态学习以增强视觉理解，微调过程仍以单模态为主，导致预训练阶段学到的多模态表示未能被充分利用。这种不匹配限制了模型性能，尤其在分类任务中，现有微调方法未能有效利用多模态优势，亟需一种新方法来解决这一关键问题，提升模型的泛化能力。",
      "method": "论文采用多模态大语言模型生成合成图像描述，通过精心设计的提示词（包含类别标签和领域上下文）为分类任务创建高质量多模态数据集。创新点包括引入监督对比损失函数，在微调时促进相同类别表示的聚类，以及推理阶段使用基于每张图像多个合成描述的类平均文本嵌入技术，以优化分类性能。",
      "result": "在13个图像分类基准上的实验表明，该方法显著优于基线方法，尤其在少样本学习场景中表现出卓越的性能提升，证明了将单模态数据集转换为多模态形式能有效增强微调效果，但摘要未明确具体数据指标，主要强调鲁棒性和泛化能力。",
      "conclusion": "本研究建立了一种新的数据集增强范式，成功桥接了多模态预训练和微调，提高了分类任务的性能，尤其适用于数据稀缺场景，具有重要的学术价值和实际应用潜力，未来可扩展到更多任务和数据集优化合成描述质量。",
      "tags": [
        "Multimodal Large Language Models (MLLMs)",
        "Synthetic Data Generation",
        "Fine-tuning",
        "Contrastive Learning",
        "Image Classification"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:17.174956Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21424",
    "title": "Lossy Common Information in a Learnable Gray-Wyner Network",
    "authors": [
      "Anderson de Andrade",
      "Alon Harell",
      "Ivan V. Bajić"
    ],
    "abstract": "Many computer vision tasks share substantial overlapping information, yet conventional codecs tend to ignore this, leading to redundant and inefficient representations. The Gray-Wyner network, a classical concept from information theory, offers a principled framework for separating common and task-specific information. Inspired by this idea, we develop a learnable three-channel codec that disentangles shared information from task-specific details across multiple vision tasks. We characterize the limits of this approach through the notion of lossy common information, and propose an optimization objective that balances inherent tradeoffs in learning such representations. Through comparisons of three codec architectures on two-task scenarios spanning six vision benchmarks, we demonstrate that our approach substantially reduces redundancy and consistently outperforms independent coding. These results highlight the practical value of revisiting Gray-Wyner theory in modern machine learning contexts, bridging classic information theory with task-driven representation learning.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21424.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21424",
    "published": "2026-01-29T09:00:43Z",
    "updated": "2026-01-29T09:00:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一个可学习的Gray-Wyner网络，通过解耦共享信息和任务特定信息来减少计算机视觉任务中的表示冗余。",
      "motivation": "计算机视觉任务常共享大量重叠信息，但传统编解码器忽视此点，导致表示冗余和效率低下。Gray-Wyner网络从信息理论提供框架分离共同和任务特定信息，但缺乏现代机器学习中的可学习实现。本研究旨在解决传统方法忽略共享信息的问题，通过开发可学习模型提升多任务表示学习的效率，填补信息理论与深度学习的结合空白。",
      "method": "论文开发了一个可学习的三通道编解码器，基于Gray-Wyner理论，解耦多个视觉任务中的共享和特定信息。引入lossy common information概念来表征解耦极限，并提出优化目标平衡学习中的权衡。关键创新包括设计三种编解码器架构，在双任务场景下测试于六个计算机视觉基准数据集，以验证方法有效性。",
      "result": "在六个视觉基准的双任务场景实验中，比较三种编解码器架构，结果表明该方法能显著减少表示冗余，并一致优于独立编码策略。摘要未提供具体性能指标，但强调了在多个基准上的有效性，验证了lossy common information概念在提升表示学习效率方面的潜力。",
      "conclusion": "论文的主要贡献是将经典Gray-Wyner理论引入现代机器学习，提出可学习网络解耦信息以减少冗余，展示信息理论在任务驱动表示学习中的实际价值。学术上连接经典与现代表现，实际应用改进多任务效率。未来工作可能涉及扩展到更多任务或处理动态环境，摘要未明确说明局限性。",
      "tags": [
        "Gray-Wyner Network",
        "Information Theory",
        "Representation Learning",
        "Multi-Task Learning",
        "Lossy Common Information"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:05.975831Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21421",
    "title": "From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding",
    "authors": [
      "Jiangsan Zhao",
      "Jakob Geipel",
      "Kryzysztof Kusnierek"
    ],
    "abstract": "Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21421.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21421",
    "published": "2026-01-29T08:58:51Z",
    "updated": "2026-01-29T08:58:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过引入基于Sparse Voxel Rasterization的显式几何流水线，诊断并克服了Neural Radiance Fields在密集自遮挡场景中的几何退化问题，显著提升实例恢复能力。",
      "motivation": "Neural Radiance Fields（NeRFs）作为多视图重建的强大工具，已在计算机视觉领域广泛应用，但其在密集自遮挡场景中进行定量3D分析的可靠性尚未充分评估。现有隐式密度场在严重遮挡条件下表现出关键缺陷，即Interior Geometric Degradation（IGD），导致重构空心或碎片结构而非固体内部，进而引起实例计数不足。这一问题限制了NeRFs在复杂环境如自动驾驶或机器人感知中的应用，因为可靠几何是精确三维理解的基础。现有mask-supervised方法虽改进表面一致性，但在密集场景中仍无法有效处理内部几何歧义。",
      "method": "研究提出了一种显式几何流水线来克服NeRFs的局限性，核心基于Sparse Voxel Rasterization（SVRaster），并从Structure-from-Motion（SfM）特征几何初始化。该方法的关键创新在于将2D实例掩码投影到显式体素网格上，并通过递归分裂强制执行几何分离，从而确保物理固体性。此方法整合了传统SfM和Multi-View Stereo（MVS）的先验知识，优化体素表示以避免隐式场的歧义。实验在合成数据集上进行，通过控制遮挡程度来验证方法的有效性，没有具体提及数据集名称。",
      "result": "实验结果表明，在密集自遮挡场景中，隐式基线（mask-supervised NeRFs）的实例恢复率饱和于约89%。相比之下，提出的显式方法实现了95.8%的恢复率，显著提升6.8个百分点。敏感性分析进一步显示，当分割掩码降级时，基于SfM的显式几何比隐式基线多恢复43%的实例，证明其更强的鲁棒性。这些数据突显了显式方法在维持高恢复率和处理监督失败方面的优势，为密集3D场景理解提供了性能改进。",
      "conclusion": "本研究的主要贡献在于揭示了Neural Radiance Fields在密集自遮挡场景中的几何退化问题，并提出一种基于显式几何的先验解决方案。研究表明，显式几何如Sparse Voxel Rasterization是进行可靠定量3D分析的先决条件，尤其在高度遮挡环境中。这一发现对计算机视觉和机器人技术具有重要学术和实际价值，可提升三维重建的准确性和鲁棒性。潜在局限性或未来工作方向摘要未明确说明，但可能涉及扩展到真实世界数据集或优化计算效率。",
      "tags": [
        "Neural Radiance Fields",
        "Sparse Voxel Rasterization",
        "Structure-from-Motion",
        "Multi-View Stereo",
        "Instance Segmentation"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:45.213339Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21420",
    "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
    "authors": [
      "Zihao Huang",
      "Jundong Zhou",
      "Xingwei Qu",
      "Qiyang Min",
      "Ge Zhang"
    ],
    "abstract": "Large language models allocate uniform computation across all tokens, ignoring that some sequences are trivially predictable while others require deep reasoning. We introduce ConceptMoE, which dynamically merges semantically similar tokens into concept representations, performing implicit token-level compute allocation. A learnable chunk module identifies optimal boundaries by measuring inter-token similarity, compressing sequences by a target ratio $R$ before they enter the compute-intensive concept model. Crucially, the MoE architecture enables controlled evaluation: we reallocate saved computation to match baseline activated FLOPs (excluding attention map computation) and total parameters, isolating genuine architectural benefits. Under these conditions, ConceptMoE consistently outperforms standard MoE across language and vision-language tasks, achieving +0.9 points on language pretraining, +2.3 points on long context understanding, and +0.6 points on multimodal benchmarks. When converting pretrained MoE during continual training with layer looping, gains reach +5.5 points, demonstrating practical applicability. Beyond performance, ConceptMoE reduces attention computation by up to $R^2\\times$ and KV cache by $R\\times$. At $R=2$, empirical measurements show prefill speedups reaching 175\\% and decoding speedups up to 117\\% on long sequences. The minimal architectural modifications enable straightforward integration into existing MoE, demonstrating that adaptive concept-level processing fundamentally improves both effectiveness and efficiency of large language models.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21420.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21420",
    "published": "2026-01-29T08:58:22Z",
    "updated": "2026-01-29T08:58:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "ConceptMoE提出自适应token到概念压缩方法，实现隐式计算分配，显著提升大型语言模型的效果和效率。",
      "motivation": "大型语言模型对所有token采用统一计算分配策略，忽视了序列中不同token的语义复杂性差异，导致计算资源浪费，尤其在处理长上下文或多模态任务时效率低下。现有方法未区分token的可预测性，使得模型在简单token上过度计算，而在复杂推理上资源不足，限制了性能和效率的提升。因此，开发自适应计算分配机制对于优化模型计算效率和处理复杂序列至关重要。",
      "method": "ConceptMoE的核心是一个可学习的chunk模块，通过测量token间语义相似度动态确定压缩边界，将序列压缩到预设比率R后输入到计算密集型概念模型中。该方法结合混合专家（MoE）架构进行控制评估，重新分配节省的计算资源以匹配基线激活的FLOPs（不包括注意力图计算）和总参数，从而隔离出架构带来的真正优势。关键创新在于自适应概念级处理，能够隐式调整token级计算分配，验证了概念表示的效率提升。",
      "result": "在严格控制的评估条件下，ConceptMoE在语言和视觉语言任务上一致优于标准MoE：语言预训练性能提升0.9分，长上下文理解提升2.3分，多模态基准提升0.6分。在持续训练中通过层循环转换预训练MoE时，增益可达5.5分。此外，该方法显著提升效率，注意力计算减少达R^2倍，KV缓存减少R倍；当R=2时，实测长序列上预填充速度提升175%，解码速度提升117%。这些结果证明了概念压缩在保持性能的同时大幅降低计算开销。",
      "conclusion": "ConceptMoE的主要贡献在于通过自适应token到概念压缩实现隐式计算分配，证明了概念级处理能同时提高大语言模型的效果和效率。该方法架构修改最小，易于集成到现有MoE模型中，具有实际应用价值。未来工作可能包括优化压缩策略或扩展到更多任务类型，但摘要未明确说明具体局限性，其学术价值在于为计算效率提供了新的研究方向。",
      "tags": [
        "Large Language Model",
        "Mixture of Experts (MoE)",
        "Token Compression",
        "Computational Efficiency",
        "Multimodal Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:00.106718Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21419",
    "title": "Revisiting Diffusion Model Predictions Through Dimensionality",
    "authors": [
      "Qing Jin",
      "Chaoyang Wang"
    ],
    "abstract": "Recent advances in diffusion and flow matching models have highlighted a shift in the preferred prediction target -- moving from noise ($\\varepsilon$) and velocity (v) to direct data (x) prediction -- particularly in high-dimensional settings. However, a formal explanation of why the optimal target depends on the specific properties of the data remains elusive. In this work, we provide a theoretical framework based on a generalized prediction formulation that accommodates arbitrary output targets, of which $\\varepsilon$-, v-, and x-prediction are special cases. We derive the analytical relationship between data's geometry and the optimal prediction target, offering a rigorous justification for why x-prediction becomes superior when the ambient dimension significantly exceeds the data's intrinsic dimension. Furthermore, while our theory identifies dimensionality as the governing factor for the optimal prediction target, the intrinsic dimension of manifold-bound data is typically intractable to estimate in practice. To bridge this gap, we propose k-Diff, a framework that employs a data-driven approach to learn the optimal prediction parameter k directly from data, bypassing the need for explicit dimension estimation. Extensive experiments in both latent-space and pixel-space image generation demonstrate that k-Diff consistently outperforms fixed-target baselines across varying architectures and data scales, providing a principled and automated approach to enhancing generative performance.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21419.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21419",
    "published": "2026-01-29T08:56:55Z",
    "updated": "2026-01-29T08:56:55Z",
    "comment": "19 pages, 5 figures",
    "light_analysis": {
      "overview": "本文通过理论分析揭示了扩散模型中预测目标与数据维度的关系，并提出了k-Diff框架来自动学习最优预测参数。",
      "motivation": "扩散和流匹配模型的进展显示预测目标偏好从噪声ε和速度v转向直接数据x，尤其是在高维数据设置中。然而，现有研究缺乏正式理论解释最优目标为何依赖于数据的具体属性，如本征维度，这限制了模型性能的优化。为了解决这一理论空白并应对实际中数据本征维度估计的难题，本研究旨在提供一个坚实的理论基础和实用方法，以指导预测目标的选择，从而提升生成模型的效率和准确性。",
      "method": "本研究提出了一个基于广义预测公式的理论框架，能够容纳任意输出目标，其中ε-、v-和x-预测作为特例。通过分析数据几何，推导出环境维度与本征维度的关系如何决定最优预测目标，为x-预测在环境维度显著超过本征维度时更优提供了严格论证。为了克服本征维度估计的困难，引入了k-Diff框架，它采用数据驱动方法直接从数据中学习最优预测参数k，无需显式进行维度估计。实验在潜在空间和像素空间图像生成任务中进行，使用了未明确说明的具体数据集和模型架构，以验证方法的有效性。",
      "result": "在潜在空间和像素空间图像生成的大量实验中，k-Diff框架在不同架构和数据规模下均表现优异，持续优于固定目标基线。摘要未提供具体准确率数字，但通过广泛的比较实验，k-Diff展示了在生成任务中的鲁棒性和优越性，证明其能够自动适应数据特性，提升生成模型的性能。这些结果验证了理论框架的实用价值，表明k-Diff提供了一个原理性和自动化的方法来优化预测目标选择。",
      "conclusion": "本研究的主要贡献在于提供了一个理论框架来解释扩散模型中预测目标的选择机制，并提出了k-Diff框架来自动优化这一选择。学术上，它填补了关于数据维度与预测目标关系的理论空白，为未来研究提供了原理性指导。实际应用中，k-Diff无需复杂维度估计，即可提升生成模型的性能，具有广泛适用性。局限性方面，摘要未明确说明，但未来工作可探索将k-Diff扩展到其他生成任务或更复杂的设置中，以进一步验证其通用性和改进潜力。",
      "tags": [
        "Diffusion Models",
        "Flow Matching",
        "Intrinsic Dimension",
        "k-Diff Framework",
        "Prediction Targets"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:14.946606Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21418",
    "title": "Mitigating Overthinking in Large Reasoning Models via Difficulty-aware Reinforcement Learning",
    "authors": [
      "Qian Wan",
      "Ziao Xu",
      "Luona Wei",
      "Xiaoxuan Shen",
      "Jianwen Sun"
    ],
    "abstract": "Large Reasoning Models (LRMs) achieve explicit chain-of-thought expansion by imitating deep thinking behaviors of humans, demonstrating excellent performance in complex task scenarios. However, the deep-thinking mode often leads to unnecessarily lengthy reasoning and resource inefficiency when handling simple tasks. This overthinking phenomenon may arise from the generation preference triggered by the reward function during post-training. Existing research attempts to mitigate overthinking from the perspective of prompt design or model training, but generally underestimates the importance of task difficulty awareness, which makes it difficult for LRMs to effectively allocate reasoning resources. In this paper, we propose Difficulty-aware Policy Optimization (DiPO), a reinforcement learning-based LRM training framework. DiPO encourages LRM to spontaneously model task complexity, and integrates them into reinforcement learning framework to adjust the generation preferences introduced by post-training. A difficulty modeling method based on model self-reasoning is proposed, which significantly reduces the dependence on manual annotation and formalize task complexity. We further develop a difficulty-signal-enhanced reward function that incorporates a penalty for lengthy reasoning while considering reasoning performance and output format. Experimental results indicate that DiPO enables the model to spontaneously adjust inference overhead, significantly reducing redundant tokens without losing performance due to thought compression.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21418.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21418",
    "published": "2026-01-29T08:56:45Z",
    "updated": "2026-01-29T08:56:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种名为DiPO的难度感知策略优化框架，通过强化学习减轻大型推理模型在处理简单任务时的过度思考现象。",
      "motivation": "大型推理模型通过模仿人类深度思考实现思维链扩展，在复杂任务中表现优异，但在处理简单任务时，深度思考模式导致不必要的冗长推理和资源低效，这种现象称为过度思考。现有研究尝试通过提示设计或模型训练来缓解此问题，但往往忽视了任务难度感知的重要性，使得模型难以合理分配推理资源，从而影响效率。因此，本研究旨在开发一种能够感知任务难度并自适应调整推理行为的训练框架。",
      "method": "本研究提出了Difficulty-aware Policy Optimization (DiPO)框架，基于强化学习训练大型推理模型。核心创新包括：鼓励模型自发建模任务复杂度，并将其集成到强化学习中以调整后训练引入的生成偏好。具体技术路线中，提出了一种基于模型自推理的难度建模方法，减少对人工标注的依赖，并形式化任务复杂度；进一步开发了难度信号增强的奖励函数，结合冗长推理的惩罚，同时考虑推理性能和输出格式，以优化生成策略。",
      "result": "实验结果显示，DiPO框架使模型能够自发调整推理开销，在保持性能不变的前提下，显著减少冗余token。这表明该方法有效减轻了过度思考现象，提高了推理效率。与基线方法对比，DiPO通过难度感知机制优化了资源分配，避免了在简单任务上的不必要计算，摘要未明确说明具体数据对比，但强调了整体性能未损失。",
      "conclusion": "本研究的主要贡献是提出了DiPO框架，通过集成难度感知到强化学习中，有效缓解了大型推理模型的过度思考问题。这不仅提高了模型的推理效率，减少了资源浪费，还为LRM的训练提供了新思路，具有重要的学术和实际应用价值。未来工作可探索更精细的难度建模方法或扩展到其他任务场景。",
      "tags": [
        "Large Reasoning Models",
        "Reinforcement Learning",
        "Difficulty-aware Learning",
        "Policy Optimization",
        "Self-reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:20.020532Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21414",
    "title": "System 1&2 Synergy via Dynamic Model Interpolation",
    "authors": [
      "Chenxu Yang",
      "Qingyi Si",
      "Chong Tian",
      "Xiyu Liu",
      "Dingyu Yao",
      "Chuanyu Qin",
      "Zheng Lin",
      "Weiping Wang",
      "Jiaqi Wang"
    ],
    "abstract": "Training a unified language model that adapts between intuitive System 1 and deliberative System 2 remains challenging due to interference between their cognitive modes. Recent studies have thus pursued making System 2 models more efficient. However, these approaches focused on output control, limiting what models produce. We argue that this paradigm is misaligned: output length is merely a symptom of the model's cognitive configuration, not the root cause. In this work, we shift the focus to capability control, which modulates \\textit{how models think} rather than \\textit{what they produce}. To realize this, we leverage existing Instruct and Thinking checkpoints through dynamic parameter interpolation, without additional training. Our pilot study establishes that linear interpolation yields a convex, monotonic Pareto frontier, underpinned by representation continuity and structural connectivity. Building on this, we propose \\textbf{DAMI} (\\textbf{D}yn\\textbf{A}mic \\textbf{M}odel \\textbf{I}nterpolation), a framework that estimates a query-specific Reasoning Intensity $λ(q)$ to configure cognitive depth. For training-based estimation, we develop a preference learning method encoding accuracy and efficiency criteria. For zero-shot deployment, we introduce a confidence-based method leveraging inter-model cognitive discrepancy. Experiments on five mathematical reasoning benchmarks demonstrate that DAMI achieves higher accuracy than the Thinking model while remaining efficient, effectively combining the efficiency of System 1 with the reasoning depth of System 2.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21414.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21414",
    "published": "2026-01-29T08:53:16Z",
    "updated": "2026-01-29T08:53:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出 DAMI 框架，通过动态模型插值实现 System 1 和 System 2 的协同，以提高语言模型的推理准确性和效率。",
      "motivation": "训练统一语言模型适应直观 System 1 和深思熟虑 System 2 存在挑战，因认知模式干扰导致效率低下。现有方法聚焦输出控制，如限制输出长度，但作者指出输出长度仅是模型认知配置的症状，未触及根本原因。为解决这一问题，研究转向能力控制，调制模型如何思考而非产生什么，旨在更有效地结合快速响应与深度推理，应对 AI 系统自适应认知的需求。",
      "method": "研究方法基于动态参数插值，利用现有 Instruct 和 Thinking 模型检查点，无需额外训练。初步研究发现线性插值能形成凸的帕累托前沿，受表示连续性和结构连通性支撑。核心框架 DAMI 估计查询特定推理强度 λ(q)，配置认知深度：通过偏好学习编码准确性和效率标准进行训练估计，或零样本部署时利用模型间认知差异的置信度方法。这实现了对模型思考过程的直接调制。",
      "result": "在五个数学推理基准上的实验表明，DAMI 框架实现了比纯 Thinking 模型更高的准确性，同时保持高效性能，有效结合了 System 1 的快速响应和 System 2 的深度推理优势。与基线方法对比，DAMI 在准确性和效率上取得综合提升，验证了能力控制范式的有效性，但摘要未明确提供具体性能数据。",
      "conclusion": "论文主要贡献是提出 DAMI 框架，通过动态模型插值实现能力控制，革新了调制模型认知的方式，强调“如何思考”而非“产生什么”。学术上，为统一 System 1 和 System 2 提供了新思路，促进自适应 AI 系统发展。实际应用中，可提升推理任务的准确性和效率。潜在局限性包括对其他任务的适用性，未来工作可扩展框架或优化插值策略。",
      "tags": [
        "Dynamic Model Interpolation",
        "Parameter Interpolation",
        "Preference Learning",
        "Zero-shot Deployment",
        "Mathematical Reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:19.940972Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21408",
    "title": "MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations",
    "authors": [
      "Xinan He",
      "Kaiqing Lin",
      "Yue Zhou",
      "Jiaming Zhong",
      "Wei Ye",
      "Wenhui Yi",
      "Bing Fan",
      "Feng Ding",
      "Haodong Li",
      "Bo Cao",
      "Bin Li"
    ],
    "abstract": "With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21408.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21408",
    "published": "2026-01-29T08:44:56Z",
    "updated": "2026-01-29T08:44:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出MPF-Net，通过分层流形偏差和微观时间波动检测高保真AI生成视频伪造，引入MPF概念捕捉AI视频的结构化特征。",
      "motivation": "随着视频生成模型如Veo和Wan的快速发展，AI生成视频的视觉质量已高度逼真，宏观语义错误和时间不一致性不再突出，使传统检测方法面临挑战。然而，AI视频本质上是流形拟合过程而非物理记录，像素组成逻辑具有结构化和同质化特征，这为区分真实和假视频提供了新线索。研究旨在解决高保真伪造检测问题，应对数字内容安全风险，现有方法可能不足以捕捉细微计算指纹。",
      "method": "论文提出一个分层双路径框架MPF-Net，作为序列过滤过程。第一路径是静态流形偏差分支，利用大规模视觉基础模型的精细感知边界，捕获偏离自然世界流形的空间异常或物理违规。第二路径是微观时间波动分支，作为次级过滤器，分析AI生成视频中持续存在的结构化流形投影波动，即使视觉完美序列也能检测细微计算指纹。关键创新在于MPF概念和分层策略，结合空间与时间分析。",
      "result": "摘要未明确说明具体的实验结果和性能指标。基于方法描述，该框架设计用于有效检测高保真AI生成视频伪造，通过分层过滤提高检测精度，可能减少误报。然而，需要进一步实验验证其在标准数据集上的表现，如准确率或效率改进，并与现有基线方法如传统伪造检测技术进行对比。",
      "conclusion": "本研究的主要贡献是提出MPF-Net框架，通过分层流形偏差和微观时间波动检测AI生成视频伪造，引入MPF概念揭示AI视频的本质特征。学术上，这为视频伪造检测领域提供了新视角和方法；实际应用上，有助于增强数字内容的真实性和安全性，应对日益增长的伪造威胁。未来工作可能包括在更多数据集上验证框架、优化计算效率，并扩展到其他媒体类型。",
      "tags": [
        "AI-Generated Video Detection",
        "Manifold Projection Fluctuations",
        "Large-Scale Vision Foundation Models",
        "Hierarchical Framework",
        "Micro-Temporal Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:36.607104Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21406",
    "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
    "authors": [
      "Zihan Su",
      "Hongyang Wei",
      "Kangrui Cen",
      "Yong Wang",
      "Guanhua Chen",
      "Chun Yuan",
      "Xiangxiang Chu"
    ],
    "abstract": "Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21406.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21406",
    "published": "2026-01-29T08:42:25Z",
    "updated": "2026-01-29T08:42:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出UniMRG方法，通过生成像素、深度和分割等多重表示，增强统一多模态模型的理解能力，填补了用生成反哺理解的研究空白。",
      "motivation": "统一多模态模型旨在整合视觉理解和生成，形成互惠循环。现有后训练方法已成功利用理解来增强生成，但用生成来提升理解的研究尚不充分。这导致模型在视觉任务中的全面性和鲁棒性受限，因为理解和生成在认知过程中相辅相成。探索生成如何反哺理解对于构建更智能的多模态系统至关重要，以应对复杂视觉场景。",
      "method": "本文提出UniMRG，一种架构无关的后训练方法。核心是通过辅助生成任务训练UMMs生成输入图像的多个内在表示，包括像素重建（捕获外观）、深度图（几何信息）和分割图（结构布局），这些任务与标准视觉理解目标结合。模型从而捕获互补信息，深化对视觉输入的理解，适用于多种UMM架构，无需修改基础模型。",
      "result": "在多样化的UMM架构上进行广泛实验，结果显示UniMRG显著提高了模型性能：增强了细粒度感知，减少了幻觉现象，并改善了空间理解，同时提升了生成能力。实验验证了方法的有效性，但摘要未明确说明具体性能指标如准确率提升，仅描述整体效果改进。",
      "conclusion": "本研究表明UniMRG方法有效利用生成来增强理解，推进了理解和生成互惠循环的研究。学术上，它填补了多模态模型中这一方向的空白，具有理论价值；实际应用上，可提升模型在需要精细视觉理解的任务（如视觉问答）中的性能。未来工作可探索更多表示类型或扩展到其他多模态领域。",
      "tags": [
        "Unified Multimodal Models",
        "Multi-Representation Generation",
        "Post-training",
        "Depth Estimation",
        "Image Segmentation"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:46.804622Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21405",
    "title": "Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification",
    "authors": [
      "Kailash A. Hambarde",
      "Hugo Proença"
    ],
    "abstract": "Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned.   To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry.   Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21405.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21405",
    "published": "2026-01-29T08:41:42Z",
    "updated": "2026-01-29T08:41:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种轻量级的Geometry-Induced Query-Key Transformation (GIQT)模块，通过显式纠正几何诱导的相似性扭曲，提升空中-地面行人重识别的鲁棒性。",
      "motivation": "空中-地面行人重识别（AG-ReID）面临极端视角和距离差异导致的几何扭曲，使得跨视图共享相似性空间的假设失效，严重影响匹配精度。现有方法如几何感知特征学习或外观条件提示，隐含地假设几何不变的点积相似性在注意力机制中可靠，但作者指出这在极端条件下不成立，导致相似性空间扭曲和性能下降。因此，需要直接解决相似性空间的几何扭曲问题，以提升系统在真实世界场景中的适用性和鲁棒性。",
      "method": "论文提出Geometry-Induced Query-Key Transformation (GIQT)，一个轻量级低秩模块，通过将查询-键交互基于相机几何条件进行显式调整，来纠正相似性空间的几何诱导扭曲。关键创新在于不修改特征表示或注意力机制公式，而是适应相似性计算以补偿各向异性扭曲。此外，整合了基于几何条件的提示生成机制，提供全局、视图自适应的表示先验，直接从相机几何导出。摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验在四个空中-地面行人重识别基准上进行，结果表明，该框架在极端和先前未见过的几何条件下，一致地提高了系统的鲁棒性。与最先进的方法相比，该方法引入了最小的计算开销，显示其高效性。摘要未提供具体的性能指标如准确率提升百分比或效率改进的具体数值。",
      "conclusion": "论文的主要贡献是提出了GIQT模块和几何条件提示生成机制，有效纠正几何诱导的相似性扭曲，显著提升AG-ReID性能。研究挑战了现有方法中对几何不变相似性的隐含假设，为解决类似几何扭曲问题提供了新思路。实际应用中，增强真实世界行人重识别的鲁棒性，未来工作可进一步探索方法在其他视觉任务中的扩展或优化。摘要未明确说明局限性。",
      "tags": [
        "Aerial-Ground Person Re-Identification",
        "Geometry-Induced Similarity Distortion",
        "Query-Key Transformation",
        "Attention Mechanisms",
        "Conditional Prompting"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:09.672038Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21403",
    "title": "DataCross: A Unified Benchmark and Agent Framework for Cross-Modal Heterogeneous Data Analysis",
    "authors": [
      "Ruyi Qi",
      "Zhou Liu",
      "Wentao Zhang"
    ],
    "abstract": "In real-world data science and enterprise decision-making, critical information is often fragmented across directly queryable structured sources (e.g., SQL, CSV) and \"zombie data\" locked in unstructured visual documents (e.g., scanned reports, invoice images). Existing data analytics agents are predominantly limited to processing structured data, failing to activate and correlate this high-value visual information, thus creating a significant gap with industrial needs. To bridge this gap, we introduce DataCross, a novel benchmark and collaborative agent framework for unified, insight-driven analysis across heterogeneous data modalities. DataCrossBench comprises 200 end-to-end analysis tasks across finance, healthcare, and other domains. It is constructed via a human-in-the-loop reverse-synthesis pipeline, ensuring realistic complexity, cross-source dependency, and verifiable ground truth. The benchmark categorizes tasks into three difficulty tiers to evaluate agents' capabilities in visual table extraction, cross-modal alignment, and multi-step joint reasoning. We also propose the DataCrossAgent framework, inspired by the \"divide-and-conquer\" workflow of human analysts. It employs specialized sub-agents, each an expert on a specific data source, which are coordinated via a structured workflow of Intra-source Deep Exploration, Key Source Identification, and Contextual Cross-pollination. A novel reReAct mechanism enables robust code generation and debugging for factual verification. Experimental results show that DataCrossAgent achieves a 29.7% improvement in factuality over GPT-4o and exhibits superior robustness on high-difficulty tasks, effectively activating fragmented \"zombie data\" for insightful, cross-modal analysis.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21403.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21403",
    "published": "2026-01-29T08:40:45Z",
    "updated": "2026-01-29T08:40:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "DataCross提出一个统一基准和协作代理框架，用于跨模态异构数据分析，通过激活视觉文档中的信息支持企业决策。",
      "motivation": "现实世界的数据科学和企业决策中，关键信息分散在可查询的结构化源（如SQL、CSV）和非结构化视觉文档（如扫描报告、发票图像）中，这些视觉数据被视为“僵尸数据”。现有数据分析代理主要局限于处理结构化数据，无法激活和关联视觉信息中的高价值内容，导致分析不全面，与工业需求存在显著差距。研究旨在解决这一问题，通过跨模态分析弥补现有方法的不足，提供更完整的数据洞察。",
      "method": "本研究引入DataCross，包括DataCrossBench基准和DataCrossAgent框架。基准包含200个端到端分析任务，覆盖金融、医疗等领域，通过人在回路逆向合成管道构建，确保现实复杂性、跨源依赖性和可验证的真实结果；任务分为三个难度等级评估代理在视觉表提取、跨模态对齐和多步联合推理的能力。代理框架受人类分析师“分而治之”工作流程启发，采用专门子代理处理特定数据源，通过结构化工作流程协调，包括Intra-source Deep Exploration、Key Source Identification和Contextual Cross-pollination；核心创新是reReAct机制，实现健壮的代码生成和调试以进行事实验证。",
      "result": "实验结果表明，DataCrossAgent在事实性方面比GPT-4o提升了29.7%，并在高难度任务上表现出优越的鲁棒性。基准测试中，该框架有效处理视觉表提取、跨模态对齐和多步联合推理任务，激活分散的“僵尸数据”，实现洞察丰富的跨模态分析。与现有方法相比，DataCrossAgent在复杂场景下表现更佳，满足了工业应用的需求。",
      "conclusion": "本研究的主要贡献是提供了DataCross基准和代理框架，推动异构数据跨模态分析的发展。学术价值在于整合多模态数据处理的挑战，如视觉信息激活和跨源对齐；应用价值在于提升企业决策的准确性和效率，通过激活“僵尸数据”提供更全面的洞察。潜在局限性可能包括对其他数据模态的扩展性，未来工作可进一步优化代理协调机制或扩展到更多领域任务。",
      "tags": [
        "Cross-modal Analysis",
        "Agent Framework",
        "Benchmark Evaluation",
        "Visual Table Extraction",
        "reReAct Mechanism"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:18.362459Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21391",
    "title": "Intrinsic Reward Policy Optimization for Sparse-Reward Environments",
    "authors": [
      "Minjae Cho",
      "Huy Trong Tran"
    ],
    "abstract": "Exploration is essential in reinforcement learning as an agent relies on trial and error to learn an optimal policy. However, when rewards are sparse, naive exploration strategies, like noise injection, are often insufficient. Intrinsic rewards can also provide principled guidance for exploration by, for example, combining them with extrinsic rewards to optimize a policy or using them to train subpolicies for hierarchical learning. However, the former approach suffers from unstable credit assignment, while the latter exhibits sample inefficiency and sub-optimality. We propose a policy optimization framework that leverages multiple intrinsic rewards to directly optimize a policy for an extrinsic reward without pretraining subpolicies. Our algorithm -- intrinsic reward policy optimization (IRPO) -- achieves this by using a surrogate policy gradient that provides a more informative learning signal than the true gradient in sparse-reward environments. We demonstrate that IRPO improves performance and sample efficiency relative to baselines in discrete and continuous environments, and formally analyze the optimization problem solved by IRPO. Our code is available at https://github.com/Mgineer117/IRPO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21391.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21391",
    "published": "2026-01-29T08:25:14Z",
    "updated": "2026-01-29T08:25:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了IRPO算法，通过使用代理策略梯度优化多个内在奖励，有效解决稀疏奖励环境中的探索问题，提升策略学习和样本效率。",
      "motivation": "在强化学习中，探索对于学习最优策略至关重要，但在稀疏奖励环境中，传统方法如噪声注入效果有限。现有方法结合内在奖励与外部奖励时，常面临不稳定信用分配问题；而使用内在奖励训练子策略则存在样本效率低和次优性。因此，开发一种能直接优化策略、避免这些问题的方法具有重要实践意义，可应用于机器人、游戏等需要高效探索的领域。",
      "method": "论文提出IRPO框架，核心是使用代理策略梯度（surrogate policy gradient）来优化策略。该方法整合多个内在奖励，直接针对外部奖励进行策略优化，无需预训练子策略。算法在离散和连续环境中实施，通过提供比真实梯度更丰富的学习信号，增强探索能力。关键创新在于避免了分层学习的复杂性，提高了优化效率。",
      "result": "IRPO在离散和连续环境中进行了实验，结果显示其性能和样本效率均优于基线方法。摘要未明确提供具体数据，但论文通过正式分析IRPO解决的优化问题，验证了方法的有效性。与现有方法相比，IRPO在稀疏奖励设置下实现了更稳定的策略学习和更快的收敛速度。",
      "conclusion": "IRPO的主要贡献是提出了一个新颖的策略优化框架，有效解决了稀疏奖励环境中的探索挑战。其学术价值在于引入了代理策略梯度来改善学习信号，而应用价值则体现在提升各种强化学习任务的效率。未来工作可进一步扩展到更复杂的多任务或动态环境，并探索与其他探索技术的结合。",
      "tags": [
        "Reinforcement Learning",
        "Intrinsic Reward",
        "Policy Optimization",
        "Sparse-Reward Environments",
        "Surrogate Policy Gradient"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:15.283615Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21389",
    "title": "Learning to Optimize Job Shop Scheduling Under Structural Uncertainty",
    "authors": [
      "Rui Zhang",
      "Jianwei Niu",
      "Xuefeng Liu",
      "Shaojie Tang",
      "Jing Yuan"
    ],
    "abstract": "The Job-Shop Scheduling Problem (JSSP), under various forms of manufacturing uncertainty, has recently attracted considerable research attention. Most existing studies focus on parameter uncertainty, such as variable processing times, and typically adopt the actor-critic framework. In this paper, we explore a different but prevalent form of uncertainty in JSSP: structural uncertainty. Structural uncertainty arises when a job may follow one of several routing paths, and the selection is determined not by policy, but by situational factors (e.g., the quality of intermediate products) that cannot be known in advance. Existing methods struggle to address this challenge due to incorrect credit assignment: a high-quality action may be unfairly penalized if it is followed by a time-consuming path. To address this problem, we propose a novel method named UP-AAC. In contrast to conventional actor-critic methods, UP-AAC employs an asymmetric architecture. While its actor receives a standard stochastic state, the critic is crucially provided with a deterministic state reconstructed in hindsight. This design allows the critic to learn a more accurate value function, which in turn provides a lower-variance policy gradient to the actor, leading to more stable learning. In addition, we design an attention-based Uncertainty Perception Model (UPM) to enhance the actor's scheduling decisions. Extensive experiments demonstrate that our method outperforms existing approaches in reducing makespan on benchmark instances.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21389.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21389",
    "published": "2026-01-29T08:25:07Z",
    "updated": "2026-01-29T08:25:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了UP-AAC方法，通过非对称actor-critic架构和注意力不确定性感知模型，有效处理作业车间调度中的结构性不确定性。",
      "motivation": "研究动机聚焦于解决作业车间调度问题在结构性不确定性下的挑战。这种不确定性源于作业可能遵循多种路径，选择取决于不可预知的情境因素，如中间产品质量。现有方法大多关注参数不确定性，采用actor-critic框架，但面临信用分配问题：高质量动作可能因后续路径耗时而被不公平惩罚，导致优化困难。本研究强调结构性不确定性的普遍性和重要性，指出现有技术在此领域的不足，亟需新方法以提高调度鲁棒性。",
      "method": "研究方法提出了UP-AAC（不确定性感知的非对称actor-critic）方法。核心创新在于采用非对称架构：演员接收标准随机状态进行决策，而批评者接收事后重建的确定性状态，以学习更准确的价值函数，降低策略梯度方差，提升学习稳定性。此外，结合了基于注意力的不确定性感知模型（UPM），以增强演员对不确定情境的调度能力。技术特色包括状态重建机制和注意力机制，利用基准实例进行训练，但摘要未明确指定具体数据集或模型架构细节。",
      "result": "主要实验结果表明，UP-AAC方法在基准实例上显著减少了makespan（总完成时间），优于现有方法。论文通过广泛的实验验证了方法的有效性，但摘要未提供具体数据如准确率提升或效率改进数值。与基线方法对比，本研究的方法在处理结构性不确定性时展现出更高的性能和稳定性，实现了调度优化，尽管未提及详细性能指标，但强调其在benchmark实例上的优势。",
      "conclusion": "结论总结了论文的主要贡献：提出UP-AAC方法，成功解决了作业车间调度中结构性不确定性的优化问题。学术价值在于改进了actor-critic框架，引入非对称架构和注意力机制，提高了信用分配准确性和学习效率。实际应用价值体现在制造业调度等领域，有助于应对不可预知的情境变化。局限性方面，摘要未明确说明，但未来工作可能涉及扩展到其他不确定性类型或更大规模应用。",
      "tags": [
        "Job Shop Scheduling (JSSP)",
        "Actor-Critic Framework",
        "Asymmetric Architecture",
        "Attention Mechanism",
        "Uncertainty Perception Model (UPM)"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:20.929693Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21387",
    "title": "User-Centric Evidence Ranking for Attribution and Fact Verification",
    "authors": [
      "Guy Alt",
      "Eran Hirsch",
      "Serwar Basch",
      "Ido Dagan",
      "Oren Glickman"
    ],
    "abstract": "Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21387.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21387",
    "published": "2026-01-29T08:23:26Z",
    "updated": "2026-01-29T08:23:26Z",
    "comment": "EACL 2026",
    "light_analysis": {
      "overview": "论文提出证据排序任务，通过增量排序策略优先呈现足够证据，减少用户阅读努力并改进事实验证。",
      "motivation": "归因和事实验证是自然语言处理中评估信息可靠性的关键挑战。现有自动系统和大型语言模型在检索和选择证据时，常提供不足或冗余的信息，导致验证过程效率低下且容易出错。现有方法未能优化证据呈现顺序以适应验证需求，因此需要一种更有效的用户中心化方法来减少认知负担并提高验证准确性。",
      "method": "研究方法聚焦于证据排序任务，比较了一次性排序和增量排序两种策略。关键创新是引入基于信息检索指标的新评估框架，并构建统一基准，通过聚合多个现有事实验证数据集实现。实验使用基于大型语言模型的方法与浅层基线模型进行对比，评估其在平衡证据充分性和冗余性方面的性能，强调用户中心的序列化验证流程。",
      "result": "实验结果表明，增量排序策略在捕获互补证据方面优于一次性排序，基于大型语言模型的方法在统一基准上超越了浅层基线。用户控制研究证实，证据排序能显著减少阅读努力并提高事实验证准确性。尽管面临平衡证据充分性和冗余性的挑战，这些方法展示了优化信息呈现的潜力。摘要未明确说明具体性能指标如准确率数据。",
      "conclusion": "该研究的主要贡献是提出并验证证据排序任务，为信息验证系统提供了更高效、可解释和用户对齐的方法。学术价值在于引入基于信息检索的评估框架和统一基准，推动事实验证技术发展。实际应用体现在减少用户认知负担和提升系统可信度。局限性包括排序策略在平衡充分性和冗余性上的挑战，未来工作可探索更智能的算法或集成用户反馈。",
      "tags": [
        "Evidence Ranking",
        "Large Language Models",
        "Incremental Ranking",
        "Fact Verification",
        "Information Retrieval Metrics"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:48.453579Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21384",
    "title": "Sim-MSTNet: sim2real based Multi-task SpatioTemporal Network Traffic Forecasting",
    "authors": [
      "Hui Ma",
      "Qingzhong Li",
      "Jin Wang",
      "Jie Wu",
      "Shaoyu Dou",
      "Li Feng",
      "Xinjun Pei"
    ],
    "abstract": "Network traffic forecasting plays a crucial role in intelligent network operations, but existing techniques often perform poorly when faced with limited data. Additionally, multi-task learning methods struggle with task imbalance and negative transfer, especially when modeling various service types. To overcome these challenges, we propose Sim-MSTNet, a multi-task spatiotemporal network traffic forecasting model based on the sim2real approach. Our method leverages a simulator to generate synthetic data, effectively addressing the issue of poor generalization caused by data scarcity. By employing a domain randomization technique, we reduce the distributional gap between synthetic and real data through bi-level optimization of both sample weighting and model training. Moreover, Sim-MSTNet incorporates attention-based mechanisms to selectively share knowledge between tasks and applies dynamic loss weighting to balance task objectives. Extensive experiments on two open-source datasets show that Sim-MSTNet consistently outperforms state-of-the-art baselines, achieving enhanced accuracy and generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21384.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21384",
    "published": "2026-01-29T08:20:08Z",
    "updated": "2026-01-29T08:20:08Z",
    "comment": "accepted in ICASSP 2026",
    "light_analysis": {
      "overview": "本文提出Sim-MSTNet模型，通过结合sim2real技术和多任务学习，有效解决了网络流量预测中数据稀缺和任务不平衡的问题。",
      "motivation": "网络流量预测在智能网络运营中至关重要，但现有方法在数据稀缺情况下泛化能力差，导致预测性能下降。多任务学习在处理多样化服务类型时，常因任务不平衡和负迁移而受限，进一步影响模型效果。这些问题限制了网络管理效率，因此亟需开发新方法来提升预测准确性和鲁棒性，以支持更高效的资源分配和优化。",
      "method": "Sim-MSTNet基于sim2real框架，利用模拟器生成合成网络流量数据以缓解真实数据不足。通过领域随机化技术，对样本权重和模型训练进行双层优化，减少合成与真实数据间的分布差异。模型结合注意力机制，选择性共享多任务知识，并应用动态损失加权策略平衡各任务目标，从而提升学习效率和预测精度。",
      "result": "在两个开源数据集上的广泛实验表明，Sim-MSTNet持续优于当前最先进的基线方法，实现了更高的预测准确性和更强的泛化能力。实验验证了该方法在数据有限场景下的有效性，通过对比基线，展示了其在多任务网络流量预测中的优越性能，为智能网络操作提供了可靠支持。",
      "conclusion": "Sim-MSTNet的主要贡献在于整合sim2real和多任务学习，为网络流量预测提供创新解决方案，通过合成数据生成和任务优化策略，显著提升了模型性能。该研究具有学术价值，推动了时空预测技术的发展，并有望应用于实际网络管理中。未来工作可探索模型在更复杂网络环境或多样化服务类型中的适应性，以进一步增强鲁棒性。",
      "tags": [
        "Sim2Real",
        "Multi-task Learning",
        "Attention Mechanisms",
        "Domain Randomization",
        "Network Traffic Forecasting"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:00.859375Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21381",
    "title": "DA-SPS: A Dual-stage Network based on Singular Spectrum Analysis, Patching-strategy and Spearman-correlation for Multivariate Time-series Prediction",
    "authors": [
      "Tianhao Zhang",
      "Shusen Ma",
      "Yu Kang",
      "Yun-Bo Zhao"
    ],
    "abstract": "Multivariate time-series forecasting, as a typical problem in the field of time series prediction, has a wide range of applications in weather forecasting, traffic flow prediction, and other scenarios. However, existing works do not effectively consider the impact of extraneous variables on the prediction of the target variable. On the other hand, they fail to fully extract complex sequence information based on various time patterns of the sequences. To address these drawbacks, we propose a DA-SPS model, which adopts different modules for feature extraction based on the information characteristics of different variables. DA-SPS mainly consists of two stages: the target variable processing stage (TVPS) and the extraneous variables processing stage (EVPS). In TVPS, the model first uses Singular Spectrum Analysis (SSA) to process the target variable sequence and then uses Long Short-Term Memory (LSTM) and P-Conv-LSTM which deploys a patching strategy to extract features from trend and seasonality components, respectively. In EVPS, the model filters extraneous variables that have a strong correlation with the target variate by using Spearman correlation analysis and further analyses them using the L-Attention module which consists of LSTM and attention mechanism. Finally, the results obtained by TVPS and EVPS are combined through weighted summation and linear mapping to produce the final prediction. The results on four public datasets demonstrate that the DA-SPS model outperforms existing state-of-the-art methods. Additionally, its performance in real-world scenarios is further validated using a private dataset collected by ourselves, which contains the test items' information on laptop motherboards.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21381.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21381",
    "published": "2026-01-29T08:17:20Z",
    "updated": "2026-01-29T08:17:20Z",
    "comment": "12 pages, 7 figures, 6 tables, submitted to IEEE Transactions on Emerging Topics in Computational Intelligence",
    "light_analysis": {
      "overview": "本文提出DA-SPS模型，一种基于奇异谱分析、补丁策略和斯皮尔曼相关的双阶段网络，用于提升多变量时间序列预测的性能。",
      "motivation": "多变量时间序列预测作为时间序列预测领域的典型问题，在天气预测、交通流预测等实际场景中具有广泛应用。然而，现有方法未能有效考虑无关变量对目标变量预测的影响，同时无法充分提取基于序列不同时间模式的复杂信息。这些缺陷限制了模型的准确性和鲁棒性，因此亟需开发新方法来弥补这些不足，提升预测效果。",
      "method": "论文提出的DA-SPS模型采用双阶段网络结构：目标变量处理阶段（TVPS）和无关变量处理阶段（EVPS）。在TVPS中，首先使用奇异谱分析（SSA）处理目标变量序列，分解为趋势和季节性成分，然后使用LSTM和采用补丁策略的P-Conv-LSTM分别从这些成分中提取特征。在EVPS中，通过斯皮尔曼相关分析筛选与目标变量强相关的无关变量，并使用由LSTM和注意力机制组成的L-Attention模块进行深入分析。最后，将两阶段的结果通过加权求和和线性映射结合，生成最终预测。",
      "result": "实验在四个公共数据集上进行，结果显示DA-SPS模型优于现有的最先进方法，证明了其预测性能的优越性。此外，使用一个私有数据集（包含笔记本电脑主板测试项信息）进一步验证了模型在实际场景中的有效性，增强了其鲁棒性和实用性。由于摘要未提供具体的性能指标如准确率或误差率，因此无法给出量化数据，但整体表现得到了肯定。",
      "conclusion": "本研究的核心贡献是提出了DA-SPS模型，通过集成奇异谱分析、补丁策略、斯皮尔曼相关和注意力机制，有效解决了多变量时间序列预测中的关键问题。该模型不仅具有学术创新价值，为特征提取提供了新思路，还在实际应用中展现了潜力，例如在天气和交通预测中。未来工作可能包括优化模型结构、扩展到更多数据集或探索更复杂的变量交互方式，以进一步提升模型的通用性。",
      "tags": [
        "Multivariate Time-series Prediction",
        "Singular Spectrum Analysis",
        "Patching Strategy",
        "Spearman Correlation",
        "Attention Mechanism"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:34.671509Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21376",
    "title": "Towards Geometry-Aware and Motion-Guided Video Human Mesh Recovery",
    "authors": [
      "Hongjun Chen",
      "Huan Zheng",
      "Wencheng Han",
      "Jianbing Shen"
    ],
    "abstract": "Existing video-based 3D Human Mesh Recovery (HMR) methods often produce physically implausible results, stemming from their reliance on flawed intermediate 3D pose anchors and their inability to effectively model complex spatiotemporal dynamics. To overcome these deep-rooted architectural problems, we introduce HMRMamba, a new paradigm for HMR that pioneers the use of Structured State Space Models (SSMs) for their efficiency and long-range modeling prowess. Our framework is distinguished by two core contributions. First, the Geometry-Aware Lifting Module, featuring a novel dual-scan Mamba architecture, creates a robust foundation for reconstruction. It directly grounds the 2D-to-3D pose lifting process with geometric cues from image features, producing a highly reliable 3D pose sequence that serves as a stable anchor. Second, the Motion-guided Reconstruction Network leverages this anchor to explicitly process kinematic patterns over time. By injecting this crucial temporal awareness, it significantly enhances the final mesh's coherence and robustness, particularly under occlusion and motion blur. Comprehensive evaluations on 3DPW, MPI-INF-3DHP, and Human3.6M benchmarks confirm that HMRMamba sets a new state-of-the-art, outperforming existing methods in both reconstruction accuracy and temporal consistency while offering superior computational efficiency.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21376.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21376",
    "published": "2026-01-29T08:05:02Z",
    "updated": "2026-01-29T08:05:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出HMRMamba，首次将结构化状态空间模型应用于视频3D人体网格恢复，通过几何感知和运动引导模块显著提升重建准确性和时间一致性。",
      "motivation": "现有视频3D人体网格恢复方法常产生物理不合理的结果，主要由于依赖有缺陷的中间3D姿态锚点和无法有效建模复杂时空动态。这导致在遮挡和运动模糊等实际场景中性能下降，限制了方法的实用性和准确性。因此，开发一种能克服这些架构缺陷、增强稳定性和鲁棒性的新方法至关重要，以推动计算机视觉和增强现实等应用的发展。",
      "method": "本研究提出HMRMamba框架，包含两个核心组件：几何感知提升模块和运动引导重建网络。几何感知模块采用新颖的双扫描Mamba架构，直接从2D图像特征中提取几何线索，生成可靠的3D姿态序列作为稳定锚点；运动引导网络则利用此锚点显式处理时间上的运动学模式，增强网格的连贯性和鲁棒性。该方法首次应用结构化状态空间模型，实现了高效的时空建模，并在3DPW、MPI-INF-3DHP和Human3.6M数据集上进行验证。",
      "result": "在3DPW、MPI-INF-3DHP和Human3.6M基准上的全面评估表明，HMRMamba在重建准确性和时间一致性方面均优于现有方法，达到新的最先进水平，并在遮挡和运动模糊场景下表现出更强的鲁棒性。同时，该方法提供了更优的计算效率，具体性能提升数据摘要未明确说明，但整体效果验证了其有效性。",
      "conclusion": "本文的主要贡献在于提出了HMRMamba新范式，首次将结构化状态空间模型用于视频3D人体网格恢复，通过几何感知和运动引导解决了现有方法的缺陷。这提升了重建的准确性和一致性，具有重要的学术价值，可应用于虚拟现实、运动分析等领域。未来工作可能包括进一步优化模型以处理更复杂场景，或扩展到其他视频理解任务中。",
      "tags": [
        "Human Mesh Recovery",
        "Structured State Space Models",
        "Mamba Architecture",
        "Video-based 3D Pose Estimation",
        "Spatiotemporal Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:25.709857Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21375",
    "title": "TeachBench: A Syllabus-Grounded Framework for Evaluating Teaching Ability in Large Language Models",
    "authors": [
      "Zheng Li",
      "Siyao Song",
      "Jingyuan Ma",
      "Rui Li",
      "Ying Zeng",
      "Minghao Li",
      "Zhifang Sui"
    ],
    "abstract": "Large language models (LLMs) show promise as teaching assistants, yet their teaching capability remains insufficiently evaluated. Existing benchmarks mainly focus on problem-solving or problem-level guidance, leaving knowledge-centered teaching underexplored. We propose a syllabus-grounded evaluation framework that measures LLM teaching capability via student performance improvement after multi-turn instruction. By restricting teacher agents to structured knowledge points and example problems, the framework avoids information leakage and enables reuse of existing benchmarks. We instantiate the framework on Gaokao data across multiple subjects. Experiments reveal substantial variation in teaching effectiveness across models and domains: some models perform well in mathematics, while teaching remains challenging in physics and chemistry. We also find that incorporating example problems does not necessarily improve teaching, as models often shift toward example-specific error correction. Overall, our results highlight teaching ability as a distinct and measurable dimension of LLM behavior.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21375.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21375",
    "published": "2026-01-29T08:04:37Z",
    "updated": "2026-01-29T08:04:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了TeachBench框架，一个基于教学大纲的评估系统，用于通过学生表现提升来量化和比较大型语言模型的教学能力。",
      "motivation": "大语言模型（LLMs）在作为教学助理方面展现出潜力，但其教学能力尚未得到充分评估。现有基准主要集中于问题解决或问题级别的指导，忽视了以知识为中心的教学评估，导致无法全面理解LLM的教学行为。这一局限阻碍了LLM在教育领域的有效应用，因此需要开发新框架来填补这一空白，以更好地评估和提升模型的教学效果。",
      "method": "研究方法提出一个以教学大纲为基础的评估框架，通过模拟多轮教学后学生表现的改善来衡量LLM的教学能力。关键创新点包括限制教师代理仅使用结构化知识点和示例问题，以避免信息泄露并促进现有基准的重用。框架在高考试题数据上实例化，涵盖数学、物理和化学等多个学科，通过这种方法系统地评估不同模型的教学表现。",
      "result": "实验结果显示，LLM的教学效果在模型和学科间存在显著差异：某些模型在数学教学中表现较好，而物理和化学领域的教学仍具挑战性。此外，纳入示例问题并不总能提升教学效果，因为模型往往会转向示例特定的错误纠正模式。这些发现强调了教学能力的可变性，并为比较不同模型提供了数据支撑。",
      "conclusion": "论文的主要贡献是证明教学能力是LLM行为中一个独特且可衡量的维度。这项研究为评估模型教学效果提供了新工具，具有学术价值，可能推动教育AI的进一步发展。尽管框架有效，但可扩展到更多领域，未来工作可能包括优化教学方法以减少错误纠正的偏差。",
      "tags": [
        "Large Language Model",
        "Teaching Ability Evaluation",
        "Syllabus-Grounded Framework",
        "Multi-turn Instruction",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:12.926118Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21372",
    "title": "NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents",
    "authors": [
      "Yang Song",
      "Anoushka Vyas",
      "Zirui Wei",
      "Sina Khoshfetrat Pakazad",
      "Henrik Ohlsson",
      "Graham Neubig"
    ],
    "abstract": "In this paper, we present NEMO, a system that translates Natural-language descriptions of decision problems into formal Executable Mathematical Optimization implementations, operating collaboratively with users or autonomously. Existing approaches typically rely on specialized large language models (LLMs) or bespoke, task-specific agents. Such methods are often brittle, complex and frequently generating syntactically invalid or non-executable code.   NEMO instead centers on remote interaction with autonomous coding agents (ACAs), treated as a first-class abstraction analogous to API-based interaction with LLMs. This design enables the construction of higher-level systems around ACAs that structure, consolidate, and iteratively refine task specifications. Because ACAs execute within sandboxed environments, code produced by NEMO is executable by construction, allowing automated validation and repair.   Building on this, we introduce novel coordination patterns with and across ACAs, including asymmetric validation loops between independently generated optimizer and simulator implementations (serving as a high-level validation mechanism), external memory for experience reuse, and robustness enhancements via minimum Bayes risk (MBR) decoding and self-consistency. We evaluate NEMO on nine established optimization benchmarks. As depicted in Figure 1, it achieves state-of-the-art performance on the majority of tasks, with substantial margins on several datasets, demonstrating the power of execution-aware agentic architectures for automated optimization modeling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21372.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21372",
    "published": "2026-01-29T07:57:23Z",
    "updated": "2026-01-29T07:57:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "NEMO系统通过自主编码代理实现自然语言到可执行数学优化代码的自动转换，确保代码可执行性并提升性能。",
      "motivation": "现有方法依赖专门的大语言模型或定制代理，将自然语言决策问题转换为优化代码时，常产生语法无效或不可执行的代码，鲁棒性差且复杂性高。这限制了自动化建模的实用性和效率，因此需要一种更可靠、可执行的系统来保证代码质量，提高优化任务的自动化水平。",
      "method": "NEMO的核心方法是以远程交互与自主编码代理作为一级抽象，构建高层系统来结构化、整合和迭代精炼任务规范。关键创新包括沙盒环境确保代码生成后即可执行，支持自动验证和修复；同时引入新颖的协调模式，如不对称验证循环（用于优化器和模拟器实现间的验证）、外部内存用于经验重用、以及通过最小贝叶斯风险解码和自我一致性增强鲁棒性。",
      "result": "在九个已建立的优化基准测试中，NEMO达到了最先进的性能，在大多数任务上表现优异，并在多个数据集上显示出显著优势（摘要未明确说明具体数据，但提及图1展示性能）。这表明其执行感知代理架构在自动化优化建模中具有高效性和领先性，优于现有基线方法。",
      "conclusion": "NEMO的主要贡献是提出了一种基于自主编码代理的执行感知优化建模框架，实现了代码可执行性的自动保证和性能提升，为自动化决策问题求解提供了新途径。其学术价值在于推进了代理架构在优化领域的应用，实际应用价值包括提高建模效率和可靠性。未来工作方向可能涉及扩展应用到更广泛领域或改进协调机制（摘要未明确说明局限性）。",
      "tags": [
        "Autonomous Coding Agents",
        "Coordination Patterns",
        "Minimum Bayes Risk Decoding",
        "Self-Consistency",
        "Execution-Aware Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:33.295283Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21369",
    "title": "Rethinking Federated Graph Foundation Models: A Graph-Language Alignment-based Approach",
    "authors": [
      "Yinlin Zhu",
      "Di Wu",
      "Xianzhi Zhang",
      "Yuming Ai",
      "Xunkai Li",
      "Miao Hu",
      "Guocong Quan"
    ],
    "abstract": "Recent studies of federated graph foundational models (FedGFMs) break the idealized and untenable assumption of having centralized data storage to train graph foundation models, and accommodate the reality of distributed, privacy-restricted data silos. Despite their simplicity and intuition, existing studies that project aligned generalizable knowledge onto a discrete token space via vector-quantized backbones suffer from irreversible knowledge loss during the quantization process. In this context, we argue that reconciling the semantic-structural orthogonality and integrity between pre-trained language models (PLMs) and graph neural networks (GNNs) is paramount for developing effective FedGFMs while simultaneously mitigating the severe data heterogeneity and communication constraints inherent in distributed, resource-limited environments.   To address these issues, we propose FedGALA (Federated Graph And Language Alignment), a framework that resolves graph-based semantic-structural orthogonality and integrity in federated settings by employing unsupervised contrastive learning to align GNNs and frozen PLMs within a continuous embedding space, thereby capturing robust, transferable general knowledge. Subsequently, FedGALA leverages a communication-efficient prompt tuning mechanism to steer these pre-aligned encoders and frozen PLMs, facilitating effective adaptation to diverse downstream tasks while circumventing the prohibitive overhead of full-parameter fine-tuning. The comprehensive experiments validate that FedGALA outperforms all competitive baselines across multi-domain datasets on multiple tasks with up to 14.37% performance improvement.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21369.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21369",
    "published": "2026-01-29T07:50:00Z",
    "updated": "2026-01-29T07:50:00Z",
    "comment": "Under Review. E-mail: zhuylin27@mail2.sysu.edu.cn",
    "light_analysis": {
      "overview": "论文提出FedGALA框架，通过图-语言对齐和高效提示调整，解决联邦图基础模型中的知识丢失和通信开销问题。",
      "motivation": "联邦图基础模型（FedGFMs）旨在适应分布式、隐私限制的数据孤岛，但现有方法通过向量量化骨干网络将通用知识投影到离散标记空间，导致不可逆的知识丢失。在分布式、资源有限的环境中，数据异质性和通信限制严重，因此协调预训练语言模型（PLMs）和图神经网络（GNNs）的语义-结构正交性和完整性对开发有效FedGFMs至关重要，这构成了研究的核心动机。",
      "method": "FedGALA框架首先使用无监督对比学习在连续嵌入空间中对齐GNNs和冻结的PLMs，以解决语义-结构正交性和完整性，避免量化损失。然后，利用通信高效的提示调整机制引导这些预对齐编码器和PLMs，适应下游任务，同时规避全参数微调的高开销。关键创新在于连续空间对齐和高效提示调整，提升了联邦学习环境下的模型性能。",
      "result": "实验在多个任务和跨多领域数据集上进行，结果表明FedGALA优于所有竞争基线，性能提升最高达14.37%。这验证了其在处理数据异质性和通信限制方面的有效性，证明通过图-语言对齐和高效调整能捕获更鲁棒、可转移的通用知识。",
      "conclusion": "FedGALA的主要贡献是通过图-语言对齐和高效提示调整，改进联邦图基础模型，缓解知识丢失和通信开销问题。其学术价值在于为分布式图学习提供新范式，实际应用适用于隐私敏感场景。未来工作可探索扩展到其他领域或进一步优化通信效率，摘要未明确说明具体局限性。",
      "tags": [
        "Federated Learning",
        "Graph Neural Networks",
        "Pre-trained Language Models",
        "Contrastive Learning",
        "Prompt Tuning"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:06.635969Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21367",
    "title": "Hebbian Learning with Global Direction",
    "authors": [
      "Wenjia Hua",
      "Kejie Zhao",
      "Luziwei Leng",
      "Ran Cheng",
      "Yuxin Ma",
      "Qinghai Guo"
    ],
    "abstract": "Backpropagation algorithm has driven the remarkable success of deep neural networks, but its lack of biological plausibility and high computational costs have motivated the ongoing search for alternative training methods. Hebbian learning has attracted considerable interest as a biologically plausible alternative to backpropagation. Nevertheless, its exclusive reliance on local information, without consideration of global task objectives, fundamentally limits its scalability. Inspired by the biological synergy between neuromodulators and local plasticity, we introduce a novel model-agnostic Global-guided Hebbian Learning (GHL) framework, which seamlessly integrates local and global information to scale up across diverse networks and tasks. In specific, the local component employs Oja's rule with competitive learning to ensure stable and effective local updates. Meanwhile, the global component introduces a sign-based signal that guides the direction of local Hebbian plasticity updates. Extensive experiments demonstrate that our method consistently outperforms existing Hebbian approaches. Notably, on large-scale network and complex datasets like ImageNet, our framework achieves the competitive results and significantly narrows the gap with standard backpropagation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21367.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21367",
    "published": "2026-01-29T07:49:21Z",
    "updated": "2026-01-29T07:49:21Z",
    "comment": "Accepted to ICASSP 2026",
    "light_analysis": {
      "overview": "本论文提出了一种整合局部和全局信息的全局指导Hebbian学习框架，显著提高了Hebbian学习的可扩展性和性能。",
      "motivation": "反向传播算法驱动了深度神经网络的显著成功，但其缺乏生物学合理性和高计算成本促使人们寻找替代训练方法。Hebbian学习作为一种生物学合理的替代方案备受关注，然而它仅依赖局部信息，不考虑全局任务目标，从根本上限制了其在复杂任务和大规模网络中的可扩展性。现有Hebbian方法无法有效应用于实际场景，因此开发一种能结合全局指导的新方法对推动生物学合理的机器学习发展至关重要。",
      "method": "本研究引入了模型无关的全局指导Hebbian学习框架，该框架无缝整合局部和全局信息以扩展至多样网络和任务。具体而言，局部组件采用Oja规则结合竞争学习，确保稳定且有效的局部更新；全局组件则引入基于符号的信号，用于指导局部Hebbian可塑性更新的方向。这一创新点在于将局部学习规则与全局任务目标相结合，提高了学习效率和适应性，适用于各种神经网络架构。",
      "result": "实验结果显示，该方法在多个网络和任务中一致优于现有Hebbian方法。特别是在大规模网络和复杂数据集如ImageNet上，该框架取得了竞争性的结果，并显著缩小了与标准反向传播算法之间的性能差距。性能提升表现在整体准确率上，尽管摘要未明确说明具体数值，但证明了该方法在扩展性和效果上的优势，超越了基线方法。",
      "conclusion": "本文主要贡献是提出了一种新颖的全局指导Hebbian学习框架，通过整合局部和全局信息解决了传统Hebbian学习的可扩展性问题，为生物学合理的机器学习方法提供了新思路，具有重要的学术价值和潜在应用前景。未来工作可能包括进一步优化框架性能，扩展到更多任务，并探索其他生物启发学习机制以提升实用性。",
      "tags": [
        "Hebbian Learning",
        "Oja's Rule",
        "Competitive Learning",
        "Global Guidance",
        "Sign-based Signal"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:00.758969Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21366",
    "title": "Perceptrons and localization of attention's mean-field landscape",
    "authors": [
      "Antonio Álvarez-López",
      "Borjan Geshkovski",
      "Domènec Ruiz-Balet"
    ],
    "abstract": "The forward pass of a Transformer can be seen as an interacting particle system on the unit sphere: time plays the role of layers, particles that of token embeddings, and the unit sphere idealizes layer normalization. In some weight settings the system can even be seen as a gradient flow for an explicit energy, and one can make sense of the infinite context length (mean-field) limit thanks to Wasserstein gradient flows. In this paper we study the effect of the perceptron block in this setting, and show that critical points are generically atomic and localized on subsets of the sphere.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21366.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21366",
    "published": "2026-01-29T07:47:46Z",
    "updated": "2026-01-29T07:47:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文研究了感知器块在Transformer平均场景观中的效应，揭示了临界点的原子性和局部化特性。",
      "motivation": "摘要未明确说明研究动机，但基于内容推断：Transformer模型在序列处理中表现出复杂动态，尤其是在平均场极限下，理解感知器块如何影响系统动态对理论分析和模型优化至关重要。现有方法可能缺乏对此的深入数学分析，因此本研究旨在填补这一空白，提供理论见解以支持更高效的模型设计。",
      "method": "论文将Transformer的前向传播建模为单位球上的交互粒子系统，其中时间对应层、粒子对应令牌嵌入，并利用层归一化理想化。关键创新在于应用梯度流理论，特别是Wasserstein梯度流，分析感知器块在无限上下文长度极限下的效应，从而将复杂的神经网络动态转化为数学上可处理的平均场问题。",
      "result": "摘要未提供具体实验数据，但描述了理论结果：在感知器块的影响下，系统的临界点通常是原子的，并局部化在球体的子集上。这表明感知器块导致动态系统的临界点具有特定结构，为理解Transformer的稳定性和收敛行为提供了新理论见解，与基线方法的对比未明确说明。",
      "conclusion": "论文的主要贡献在于通过数学框架揭示了感知器块对Transformer平均场景观的影响，强调了临界点的局部化特性。学术价值在于深化了对神经网络动态的理论理解，可能指导未来模型设计和优化；实际应用价值包括优化注意力机制和提升模型性能。未来工作方向或局限性摘要未明确说明。",
      "tags": [
        "Transformer",
        "Perceptron",
        "Mean-Field Theory",
        "Wasserstein Gradient Flows",
        "Critical Point Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:13.338545Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21360",
    "title": "The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation",
    "authors": [
      "Devanshu Sahoo",
      "Manish Prasad",
      "Vasudev Majhi",
      "Arjun Neekhra",
      "Yash Sinha",
      "Murari Mandal",
      "Vinay Chamola",
      "Dhruv Kumar"
    ],
    "abstract": "The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread \"False Certification\" of functionally broken code. Our findings suggest that current alignment paradigms create a \"Trojan\" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21360.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21360",
    "published": "2026-01-29T07:40:58Z",
    "updated": "2026-01-29T07:40:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文揭示了大型语言模型在自动学术代码评估中的合规悖论，通过提出SPACI框架和AST-ASIP协议暴露模型优先隐藏指令而非代码逻辑的脆弱性。",
      "motivation": "研究动机在于LLMs被快速集成到教育评估中，但基于指令遵循能力直接转化为客观裁判的假设未经证实且存在根本缺陷。这可能导致自动评分系统错误认证功能损坏的代码，影响教育质量和公平性。现有对齐方法如RLHF过度优化模型于极端帮助性，使其易受对抗性操纵，忽略了语义与指令脱钩的问题。因此，需要验证这一假设并揭示系统性漏洞，以推动更稳健的自动评估系统发展。",
      "method": "研究方法包括引入Semantic-Preserving Adversarial Code Injection (SPACI) Framework和Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP)。这些方法利用语法-语义差距，通过在抽象语法树（AST）的trivia节点中嵌入对抗性指令，保持代码语义不变，仅进行语法无关的修改。AST用于识别代码结构中的无关区域，SPACI框架则生成对抗性代码提交，以系统性测试模型是否优先满足隐藏指令而非评估代码质量，从而暴露模型的脆弱性。",
      "result": "实验结果显示，通过对9个SOTA模型在Python、C、C++、Java的25,000个提交进行大规模评估，高容量开源模型如DeepSeek-V3的失败率超过95%，模型系统性地优先考虑隐藏格式化约束而非代码正确性。使用新提出的三方框架（测量Decoupling Probability、Score Divergence和Pedagogical Severity）量化了“False Certification”现象，表明模型普遍错误认证功能损坏的代码。这突显了LLMs在代码评估中的严重脆弱性，与基线方法相比，高容量模型表现最差。",
      "conclusion": "论文的主要贡献是揭示了LLMs在自动代码评估中的合规悖论，提出了对抗性注入框架和量化指标来暴露漏洞。学术价值在于为模型对齐和稳健性研究提供了新视角，推动从标准RLHF转向领域特定的Adjudicative Robustness。应用价值是呼吁增强模型在裁判任务中的优先级，以避免错误认证。研究释放了数据集和框架以促进进一步探索，未来工作可能包括扩展到其他评估场景和改进对抗性防御机制。",
      "tags": [
        "Large Language Models",
        "Adversarial Manipulation",
        "Abstract Syntax Tree",
        "Compliance Paradox",
        "Reinforcement Learning from Human Feedback"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:35.925875Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21359",
    "title": "Graph-Free Root Cause Analysis",
    "authors": [
      "Luan Pham"
    ],
    "abstract": "Failures in complex systems demand rapid Root Cause Analysis (RCA) to prevent cascading damage. Existing RCA methods that operate without dependency graph typically assume that the root cause having the highest anomaly score. This assumption fails when faults propagate, as a small delay at the root cause can accumulate into a much larger anomaly downstream. In this paper, we propose PRISM, a simple and efficient framework for RCA when the dependency graph is absent. We formulate a class of component-based systems under which PRISM performs RCA with theoretical guarantees. On 735 failures across 9 real-world datasets, PRISM achieves 68% Top-1 accuracy, a 258% improvement over the best baseline, while requiring only 8ms per diagnosis.",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21359.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21359",
    "published": "2026-01-29T07:38:20Z",
    "updated": "2026-01-29T07:38:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出PRISM框架，一种在无依赖图情况下进行高效根因分析的简单方法，显著提升了准确性和诊断速度。",
      "motivation": "复杂系统的故障需要快速根因分析以防止级联损害。现有无依赖图方法通常假设根因具有最高异常分数，但这种假设在故障传播时失效，因为根因的小延迟可能会在下游累积成更大异常，导致诊断不准确。因此，需要一种新方法来克服这一局限性，提高根因分析的可靠性。",
      "method": "PRISM是一个简单高效的根因分析框架，专为无依赖图场景设计。其核心创新在于形式化了一类基于组件的系统，并在此框架下提供理论保证，确保根因识别的正确性。该方法避免了传统假设，直接处理故障传播问题，无需复杂图结构支持。",
      "result": "在9个真实世界数据集上的735个故障测试中，PRISM达到了68%的Top-1准确率，相比最佳基线方法提升了258%。每次诊断仅需8毫秒，显著提高了诊断效率和性能，实验结果表明PRISM在处理大规模故障时具有优势。",
      "conclusion": "PRISM框架的主要贡献是提供了一个理论支持的高效根因分析方法，弥补了无依赖图场景下现有方法的不足。该研究不仅具有学术价值，展示了新理论框架的有效性，还有实际应用价值，可广泛应用于系统故障诊断。未来工作可能包括扩展系统类别或处理更复杂的故障场景。",
      "tags": [
        "Root Cause Analysis",
        "Fault Propagation",
        "Anomaly Detection",
        "Graph-Free",
        "Theoretical Guarantees"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:22.928069Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21358",
    "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization",
    "authors": [
      "Jiecong Wang",
      "Hao Peng",
      "Chunyang Liu"
    ],
    "abstract": "Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states. However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states, while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21358.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21358",
    "published": "2026-01-29T07:38:18Z",
    "updated": "2026-01-29T07:38:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出PLaT框架，通过将潜在推理重构为规划，解耦推理与语言表达，以提高推理的效率和可扩展性。",
      "motivation": "Chain-of-Thought (CoT) 赋能大型语言模型处理复杂问题，但在离散标记空间中面临计算成本高和推理路径崩溃的限制。现有潜在推理方法虽提升效率，但通常作为不透明的端到端映射，且推理时需要预定义潜在步数。这导致灵活性不足，阻碍了高效推理的发展。因此，研究旨在解决推理过程的效率瓶颈和不透明性问题，通过解耦机制优化推理框架，增强模型的适应性和可扩展性。",
      "method": "PLaT 框架将推理建模为确定性潜在规划状态的轨迹，利用单独的Decoder在必要时将这些状态转换为文本。核心创新在于解耦推理与语言表达，使模型能动态决定何时终止推理，避免依赖固定超参数。方法以连续隐藏状态为基础，模拟规划过程，提升了推理的灵活性和透明度，并通过去耦合设计优化计算效率和路径稳定性。",
      "result": "在数学基准测试中，PLaT 的贪婪准确率低于基线方法，但在推理多样性方面展现出优越的可扩展性。结果表明 PLaT 学习到了更鲁棒、更广泛的解空间，为推理时搜索提供了透明且可扩展的基础。与基线相比，这种权衡体现在准确率降低但多样性增强，暗示模型在复杂问题中具有更强的适应能力。",
      "conclusion": "PLaT 的主要贡献在于提出了一种解耦推理与语言表达的框架，增强了推理的灵活性和可扩展性。学术上为潜在推理提供了新视角，实际应用中可能优化复杂问题的搜索策略。局限性包括准确率可能降低的权衡，未来工作可探索平衡准确性与多样性，或扩展至其他领域以验证泛化能力。",
      "tags": [
        "Latent Reasoning",
        "Chain-of-Thought (CoT)",
        "Planning",
        "Decoupling",
        "Large Language Models (LLMs)"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:17.759743Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21357",
    "title": "Expected Improvement via Gradient Norms",
    "authors": [
      "Joshua Hang Sai Ip",
      "Georgios Makrygiorgos",
      "Ali Mesbah"
    ],
    "abstract": "Bayesian Optimization (BO) is a principled approach for optimizing expensive black-box functions, with Expected Improvement (EI) being one of the most widely used acquisition functions. Despite its empirical success, EI is known to be overly exploitative and can converge to suboptimal stationary points. We propose Expected Improvement via Gradient Norms (EI-GN), a novel acquisition function that applies the improvement principle to a gradient-aware auxiliary objective, thereby promoting sampling in regions that are both high-performing and approaching first-order stationarity. EI-GN relies on gradient observations used to learn gradient-enhanced surrogate models that enable principled gradient inference from function evaluations. We derive a tractable closed-form expression for EI-GN that allows efficient optimization and show that the proposed acquisition is consistent with the improvement-based acquisition framework. Empirical evaluations on standard BO benchmarks demonstrate that EI-GN yields consistent improvements against standard baselines. We further demonstrate applicability of EI-GN to control policy learning problems.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21357.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21357",
    "published": "2026-01-29T07:37:13Z",
    "updated": "2026-01-29T07:37:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种名为EI-GN的新型采集函数，通过结合梯度信息改进期望改进（EI），有效减少过度利用并提升贝叶斯优化的收敛性能。",
      "motivation": "贝叶斯优化是优化昂贵黑盒函数的关键方法，期望改进作为常用采集函数，在实践中存在过度利用性问题，容易收敛到次优的平稳点，影响全局优化效率。该研究旨在解决这一缺陷，通过引入梯度信息来增强采样策略，以提高优化过程的探索能力和避免局部停滞。现有方法缺乏梯度整合，导致收敛不佳，因此该问题对于实际应用如参数调优至关重要。",
      "method": "论文提出的EI-GN采集函数将改进原则应用于梯度感知的辅助目标，利用梯度观测学习梯度增强的代理模型，从而从函数评估中实现原则性的梯度推断。核心创新包括推导出一个可处理的闭式表达式，支持高效优化，并确保与改进型采集框架的一致性。方法通过结合梯度信息，促进采样在高性能和接近一阶平稳性的区域，提高了采样策略的平衡性和有效性。",
      "result": "在标准贝叶斯优化基准上的实验评估表明，EI-GN相对于基线方法显示出持续改进效果，摘要未提供具体性能指标，但强调了其在多个场景下优于传统EI等方法。该方法在控制策略学习问题中也验证了适用性，扩展了应用范围，尽管摘要未明确说明具体提升幅度，但整体表现出更好的收敛性和效率。",
      "conclusion": "EI-GN的主要贡献在于提供了一种梯度增强的采集函数，解决了期望改进的过度利用问题，提升了贝叶斯优化的准确性和收敛性。该方法具有学术价值，为优化领域引入梯度信息提供了新思路，并在实际应用如控制学习中展现出潜力。未来工作可进一步探索其在更复杂环境中的局限性或扩展至其他领域，以增强泛化能力。",
      "tags": [
        "Bayesian Optimization",
        "Expected Improvement",
        "Gradient-Enhanced Surrogate Models",
        "Acquisition Function",
        "Control Policy Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:27.538804Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21352",
    "title": "BEAP-Agent: Backtrackable Execution and Adaptive Planning for GUI Agents",
    "authors": [
      "Ziyu Lu",
      "Tengjin Weng",
      "Yiying Yang",
      "Yuhang Zhao",
      "Xinxin Huang",
      "Wenhao Jiang"
    ],
    "abstract": "GUI agents are designed to automate repetitive tasks and enhance productivity. However, existing GUI agents struggle to recover once they follow an incorrect exploration path, often leading to task failure. In this work, we model GUI task execution as a DFS process and propose BEAP-Agent, a DFS-based framework that supports long-range, multi-level state backtracking with dynamic task tracking and updating. The framework consists of three collaborative components: Planner, Executor, and Tracker. Together, they enable effective task exploration and execution. BEAP-Agent fills the gap in systematic backtracking mechanisms for GUI agents, offering a systematic solution for long-horizon task exploration. We conducted a systematic evaluation on the OSWorld benchmark, where BEAP-Agent achieved an accuracy of 28.2%, validating the effectiveness of the proposed method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21352.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21352",
    "published": "2026-01-29T07:22:50Z",
    "updated": "2026-01-29T07:22:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "BEAP-Agent提出基于深度优先搜索的GUI代理框架，支持可回溯执行和自适应规划，解决任务探索中错误路径恢复的问题。",
      "motivation": "GUI代理旨在自动化重复任务并提高生产力，但现有方法在遵循错误探索路径后难以恢复，常导致任务失败。这个问题至关重要，因为它限制了代理的可靠性和应用范围，影响实际自动化场景的效率。现有GUI代理缺乏系统回溯机制，无法有效处理长视界任务中的复杂错误，因此需要开发更鲁棒的解决方案来弥补这一不足，提升代理的自适应能力。",
      "method": "本研究将GUI任务执行建模为深度优先搜索（DFS）过程，提出BEAP-Agent框架，包含三个协同组件：Planner负责任务规划，Executor执行具体操作，Tracker动态跟踪和更新状态。关键创新点在于支持长范围、多级状态回溯，通过DFS机制实现错误路径的即时恢复和动态调整。使用OSWorld基准测试进行验证，但摘要未明确说明具体数据集细节或模型架构的其他技术参数。",
      "result": "在OSWorld基准测试上进行了系统评估，BEAP-Agent达到了28.2%的准确率，验证了所提方法的有效性。这一结果表明基于DFS的回溯机制能改进GUI代理的任务成功率，但摘要未明确提供与其他基线方法的对比数据，因此无法具体描述性能提升幅度或效率改进情况。准确率数据展示了方法在标准测试集上的初步表现，为后续研究提供了参考。",
      "conclusion": "BEAP-Agent的主要贡献是填补了GUI代理系统回溯机制的空白，提供了长视界任务探索的系统解决方案。其学术价值在于增强了GUI代理的鲁棒性和适应性，实际应用价值在于提升自动化任务的可靠性和生产力。未来工作可能包括优化回溯效率、扩展到更复杂场景或与其他技术集成，但摘要未明确说明局限性或具体未来方向。",
      "tags": [
        "GUI Agents",
        "Backtracking",
        "Adaptive Planning",
        "Depth-First Search",
        "Task Automation"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:23.230252Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21351",
    "title": "Theoretically Optimal Attention/FFN Ratios in Disaggregated LLM Serving",
    "authors": [
      "Chendong Song",
      "Meixuan Wang",
      "Hang Zhou",
      "Hong Liang",
      "Yuan Lyu",
      "Zixi Chen",
      "Yuwei Fan",
      "Zijie Zhou"
    ],
    "abstract": "Attention-FFN disaggregation (AFD) is an emerging architecture for LLM decoding that separates state-heavy, KV-cache-dominated Attention computation from stateless, compute-intensive FFN computation, connected by per-step communication. While AFD enables independent scaling of memory and compute resources, its performance is highly sensitive to the Attention/FFN provisioning ratio: mis-sizing induces step-level blocking and costly device idle time. We develop a tractable analytical framework for sizing AFD bundles in an $r$A-$1$F topology, where the key difficulty is that Attention-side work is nonstationary-token context grows and requests are continuously replenished with random lengths-while FFN work is stable given the aggregated batch. Using a probabilistic workload model, we derive closed-form rules for the optimal A/F ratio that maximize average throughput per instance across the system. A trace-calibrated AFD simulator validates the theory: across workloads, the theoretical optimal A/F ratio matches the simulation-optimal within 10%, and consistently reduces idle time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21351.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21351",
    "published": "2026-01-29T07:22:27Z",
    "updated": "2026-01-29T07:22:27Z",
    "comment": "Submitted to ICML 2026",
    "light_analysis": {
      "overview": "这篇论文提出了一个理论分析框架，用于确定在分离注意力与FFN的LLM服务架构中最优的资源配置比例，以最大化系统吞吐量。",
      "motivation": "AFD架构通过分离状态重的Attention计算和状态无关的FFN计算，实现了内存和计算资源的独立扩展，但其性能高度敏感于Attention/FFN资源配置比例。比例不当会导致步级阻塞和设备空闲时间，严重影响效率。现有方法可能缺乏系统性的理论指导来优化这一比例，因此研究最优配置至关重要，以提高LLM服务的资源利用率和性能。",
      "method": "论文开发了一个可处理的分析框架，针对rA-1F拓扑结构，基于概率工作负载模型推导出最优Attention/FFN比例的闭式规则。关键创新在于处理Attention侧工作负载的非平稳性（如token上下文增长和请求随机长度），而FFN侧工作负载相对稳定。该方法使用追踪校准的AFD模拟器进行验证，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "通过AFD模拟器验证，理论最优A/F比例在不同工作负载下与模拟最优比例匹配在10%以内。这显著减少了设备空闲时间，从而提高了平均吞吐量。与基线方法相比，该理论框架提供了更准确的资源配置指导，优化了系统性能。",
      "conclusion": "本研究的主要贡献是提出了一个理论框架，用于确定AFD架构中Attention/FFN的最优比例，并推导出闭式规则。这具有重要学术价值，为LLM服务资源管理提供了理论基础，同时在实际应用中能优化吞吐量和减少资源浪费。未来工作可能涉及扩展到更复杂拓扑或处理动态工作负载，但摘要未明确说明局限性。",
      "tags": [
        "Large Language Model",
        "Attention-FFN Disaggregation",
        "Resource Allocation",
        "Probabilistic Model",
        "Simulation"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:24.675234Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21350",
    "title": "Factored Causal Representation Learning for Robust Reward Modeling in RLHF",
    "authors": [
      "Yupei Yang",
      "Lin Yang",
      "Wanxi Deng",
      "Lin Qu",
      "Fan Feng",
      "Biwei Huang",
      "Shikui Tu",
      "Lei Xu"
    ],
    "abstract": "A reliable reward model is essential for aligning large language models with human preferences through reinforcement learning from human feedback. However, standard reward models are susceptible to spurious features that are not causally related to human labels. This can lead to reward hacking, where high predicted reward does not translate into better behavior. In this work, we address this problem from a causal perspective by proposing a factored representation learning framework that decomposes the model's contextual embedding into (1) causal factors that are sufficient for reward prediction and (2) non-causal factors that capture reward-irrelevant attributes such as length or sycophantic bias. The reward head is then constrained to depend only on the causal component. In addition, we introduce an adversarial head trained to predict reward from the non-causal factors, while applying gradient reversal to discourage them from encoding reward-relevant information. Experiments on both mathematical and dialogue tasks demonstrate that our method learns more robust reward models and consistently improves downstream RLHF performance over state-of-the-art baselines. Analyses on length and sycophantic bias further validate the effectiveness of our method in mitigating reward hacking behaviors.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21350.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21350",
    "published": "2026-01-29T07:18:45Z",
    "updated": "2026-01-29T07:18:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种因式化因果表示学习框架，用于RLHF中的鲁棒奖励建模，以缓解奖励hacking问题。",
      "motivation": "研究动机在于强化学习从人类反馈（RLHF）中，标准奖励模型易受虚假特征影响，如文本长度或谄媚偏见，这些特征与人类标签无因果关系，导致奖励hacking现象——高预测奖励未转化为更好行为。这削弱了模型对齐人类偏好的可靠性，现有方法忽视因果关联，难以泛化，因此需从因果角度设计鲁棒奖励建模方法，解决非因果因素干扰问题。",
      "method": "论文提出一个因式化因果表示学习框架，将模型的上下文嵌入分解为因果因素（对奖励预测足够）和非因果因素（捕捉奖励无关属性如长度或谄媚偏见）。关键创新在于约束奖励头仅依赖于因果成分，避免非因果因素影响。此外，引入对抗性头部，训练它从非因果因素预测奖励，同时应用梯度反转技术阻止这些因素编码奖励相关信息。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "在数学和对话任务上的实验表明，该方法学习到更鲁棒的奖励模型，与最先进基线相比，下游RLHF性能持续改进，具体表现为更好的行为对齐和减少奖励hacking行为。对长度和谄媚偏见的分析验证了方法的有效性，显示其能有效缓解虚假特征影响。摘要未提供具体准确率或效率数据，但强调了性能提升。",
      "conclusion": "本文的主要贡献是提出基于因果视角的因式化表示学习框架，提升RLHF奖励模型的鲁棒性。学术价值在于将因果推理引入奖励建模，解决虚假特征干扰；实际应用价值在于提高大型语言模型对齐人类偏好的可靠性和效率。未来工作可能包括扩展到更复杂任务或探索其他因果机制。",
      "tags": [
        "Causal Representation Learning",
        "Reinforcement Learning from Human Feedback (RLHF)",
        "Robust Reward Modeling",
        "Adversarial Learning",
        "Representation Decomposition"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:20.857611Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21349",
    "title": "L2R: Low-Rank and Lipschitz-Controlled Routing for Mixture-of-Experts",
    "authors": [
      "Minghao Yang",
      "Ren Togo",
      "Guang Li",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "abstract": "Mixture-of-Experts (MoE) models scale neural networks by conditionally activating a small subset of experts, where the router plays a central role in determining expert specialization and overall model performance. However, many modern MoE systems still adopt linear routers in raw high-dimensional representation spaces, where representation mismatch, angular concentration, and scale-sensitive scoring can jointly undermine routing discriminability and stable expert specialization. In this work, we propose Low-rank \\& Lipschitz-controlled Routing (L2R), a unified routing framework that reshapes both the routing space and scoring geometry. L2R performs expert assignment in a shared low-rank latent routing space and introduces Saturated Inner-Product Scoring (SIPS) to explicitly control the Lipschitz behavior of routing functions, yielding smoother and more stable routing geometry. In addition, L2R incorporates a parameter-efficient multi-anchor routing mechanism to enhance expert expressiveness. Extensive experiments on a large-scale language MoE model and a vision MoE setting on ImageNet demonstrate that L2R consistently improves routing stability, expert specialization, and overall model performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21349.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21349",
    "published": "2026-01-29T07:18:33Z",
    "updated": "2026-01-29T07:18:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "L2R提出了一种低秩和Lipschitz控制的路由框架，通过重塑路由空间和评分几何来改进Mixture-of-Experts模型的路由稳定性和性能。",
      "motivation": "研究动机在于Mixture-of-Experts模型中的路由器对专家专业化和整体性能起关键作用。现有方法通常使用高维表示空间中的线性路由器，存在表示不匹配、角度集中和尺度敏感评分等问题，这共同削弱了路由的判别力和专家专业化的稳定性。由于路由器决定专家激活，其局限性可能导致模型效率低下和性能波动，因此需要一种新框架来解决这些挑战。",
      "method": "L2R的核心方法包括：在共享的低秩潜在路由空间进行专家分配，以减少高维复杂性；引入Saturated Inner-Product Scoring (SIPS) 来明确控制路由函数的Lipschitz行为，实现更平滑稳定的路由几何；并整合参数高效的多锚点路由机制，增强专家的表达能力和模型的灵活性。该方法统一了路由空间和评分，针对MoE模型的路由过程进行了优化。",
      "result": "论文在大型语言MoE模型和基于ImageNet的视觉MoE设置上进行了广泛实验。结果显示，L2R一致地改善了路由稳定性、专家专业化程度和整体模型性能，与基线方法相比显著提升了判别力和效率。尽管摘要未提供具体数值，但实验证实L2R在多种场景下均能有效克服现有路由方法的不足。",
      "conclusion": "L2R的主要贡献是提供了一个统一的路由框架，通过低秩和Lipschitz控制优化了MoE模型的路由机制。这项研究具有学术价值，为MoE路由问题提供了创新解决方案，并可能在大型AI模型的扩展中具有实际应用前景。未来工作可探索L2R在其他领域的适用性或进一步优化其参数效率。",
      "tags": [
        "Mixture-of-Experts",
        "Low-Rank Routing",
        "Lipschitz Control",
        "Saturated Inner-Product Scoring",
        "Multi-Anchor Routing"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:26.421465Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21348",
    "title": "Memorization Control in Diffusion Models from Denoising-centric Perspective",
    "authors": [
      "Thuy Phuong Vu",
      "Mai Viet Hoang Do",
      "Minhhuy Le",
      "Dinh-Cuong Hoang",
      "Phan Xuan Tan"
    ],
    "abstract": "Controlling memorization in diffusion models is critical for applications that require generated data to closely match the training distribution. Existing approaches mainly focus on data centric or model centric modifications, treating the diffusion model as an isolated predictor. In this paper, we study memorization in diffusion models from a denoising centric perspective. We show that uniform timestep sampling leads to unequal learning contributions across denoising steps due to differences in signal to noise ratio, which biases training toward memorization. To address this, we propose a timestep sampling strategy that explicitly controls where learning occurs along the denoising trajectory. By adjusting the width of the confidence interval, our method provides direct control over the memorization generalization trade off. Experiments on image and 1D signal generation tasks demonstrate that shifting learning emphasis toward later denoising steps consistently reduces memorization and improves distributional alignment with training data, validating the generality and effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21348.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21348",
    "published": "2026-01-29T07:16:54Z",
    "updated": "2026-01-29T07:16:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于去噪中心视角的时间步采样策略，通过控制学习位置来调整扩散模型的记忆化-泛化权衡。",
      "motivation": "控制扩散模型的记忆化对于确保生成数据与训练分布匹配至关重要，尤其在需要高保真生成的应用中。现有方法主要从数据或模型角度进行修改，将扩散模型视为独立预测器，忽视了去噪过程中因信噪比差异导致的学习贡献不均。这使训练偏向记忆化，限制了模型的泛化能力，因此需要从去噪中心视角出发的新策略来优化训练动态。",
      "method": "本文提出一种时间步采样策略，从去噪中心视角出发，控制学习在去噪轨迹中的发生位置。核心创新是识别均匀时间步采样因信噪比差异导致的学习贡献不均问题，通过调整置信区间宽度来直接控制记忆化与泛化之间的权衡。具体通过优化时间步的采样概率实现，将学习重点转向后期去噪步骤。摘要未明确说明使用的具体模型架构和数据集。",
      "result": "实验在图像和1D信号生成任务上进行，结果表明，通过将学习重点转向后期去噪步骤，能一致减少记忆化并改善生成数据与训练数据的分布对齐。这验证了所提出方法的通用性和有效性。与基线均匀时间步采样相比，新策略在控制记忆化-泛化权衡方面表现出更优性能，尽管摘要未提供具体量化指标如准确率提升，但强调了其一致性和分布对齐的改进。",
      "conclusion": "本研究的主要贡献是从去噪中心视角提出了一种时间步采样策略，有效控制扩散模型的记忆化-泛化权衡。学术上，它揭示了均匀时间步采样的不足，并为训练动态优化提供了新思路，有助于理解扩散模型中的学习机制。实际应用中，该方法能帮助生成数据更紧密匹配训练分布，提升模型在图像和信号生成等任务中的性能。未来工作可探索更复杂的采样策略或扩展到其他生成模型。",
      "tags": [
        "Diffusion Models",
        "Denoising",
        "Timestep Sampling",
        "Memorization Control",
        "Signal-to-Noise Ratio"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:08.150505Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21345",
    "title": "Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning",
    "authors": [
      "Ruiqi Liu",
      "Boyu Diao",
      "Zijia An",
      "Runjie Shao",
      "Zhulin An",
      "Fei Wang",
      "Yongjun Xu"
    ],
    "abstract": "Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21345.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21345",
    "published": "2026-01-29T07:15:05Z",
    "updated": "2026-01-29T07:15:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出语义引导的动态稀疏化方法SGDS，通过优化激活子空间来平衡类增量学习中的知识保留与可塑性。",
      "motivation": "类增量学习要求模型在不遗忘旧类的同时学习新类，现有方法常冻结预训练模型并采用轻量级适配器，通过参数正交化防止任务间干扰。然而，这种参数约束方法会损害模型的可塑性，限制了学习新知识的能力。因此，需要一种更灵活的技术来平衡稳定性与可塑性，避免过度约束参数空间，以提升模型的持续学习性能。本研究针对这一问题，提出了基于语义引导的动态稀疏化来优化激活空间，以解决现有方法的不足。",
      "method": "SGDS方法通过语义引导的动态稀疏化来管理激活空间的朝向和秩，具体包括两个关键创新点。它根据类别语义相似度，鼓励相似类共享紧凑的子空间以促进知识转移，同时为不相似类分配非重叠的子空间以防止干扰。这种方法在激活层进行动态稀疏化，避免了参数空间的刚性约束，基于预训练模型直接塑造类别特定的稀疏子空间，从而实现高效的知识保留和更新。摘要未明确说明使用的具体数据集或模型架构，但强调了激活空间的优化技术。",
      "result": "在多个基准数据集上的广泛实验表明，SGDS方法实现了最先进的性能，通过优化激活子空间有效提升类增量学习的效果。具体而言，SGDS在准确率和抗遗忘能力方面表现出显著优势，优于现有基线方法，验证了其在平衡知识转移与防止干扰方面的有效性。摘要未提供具体数据指标如准确率提升，但实验结果表明，该方法在标准任务设置下均展现出稳定的改进，为类增量学习提供了新的解决方案。",
      "conclusion": "本研究的主要贡献是提出了SGDS方法，通过语义引导的动态稀疏化有效缓解类增量学习中的干扰问题，同时保持模型的可塑性。该方法的学术价值在于引入了激活空间优化新视角，突破了传统参数约束的局限，实际应用价值在于提升持续学习系统的性能和灵活性。未来工作方向可能包括在更复杂场景下扩展SGDS的应用，以及探索与其他学习技术的结合。摘要未明确说明局限性，但为相关研究提供了有价值的参考。",
      "tags": [
        "Class-Incremental Learning",
        "Pre-Trained Models",
        "Dynamic Sparsification",
        "Activation Space",
        "Semantic Guidance"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:46.070354Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21344",
    "title": "Dynamic Framework for Collaborative Learning: Leveraging Advanced LLM with Adaptive Feedback Mechanisms",
    "authors": [
      "Hassam Tahir",
      "Faizan Faisal",
      "Fady Alnajjar",
      "Muhammad Imran Taj",
      "Lucia Gordon",
      "Aila Khan",
      "Michael Lwin",
      "Omar Mubin"
    ],
    "abstract": "This paper presents a framework for integrating LLM into collaborative learning platforms to enhance student engagement, critical thinking, and inclusivity. The framework employs advanced LLMs as dynamic moderators to facilitate real-time discussions and adapt to learners' evolving needs, ensuring diverse and inclusive educational experiences. Key innovations include robust feedback mechanisms that refine AI moderation, promote reflective learning, and balance participation among users. The system's modular architecture featuring ReactJS for the frontend, Flask for backend operations, and efficient question retrieval supports personalized and engaging interactions through dynamic adjustments to prompts and discussion flows. Testing demonstrates that the framework significantly improves student collaboration, fosters deeper comprehension, and scales effectively across various subjects and user groups. By addressing limitations in static moderation and personalization in existing systems, this work establishes a strong foundation for next-generation AI-driven educational tools, advancing equitable and impactful learning outcomes.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21344.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21344",
    "published": "2026-01-29T07:14:43Z",
    "updated": "2026-01-29T07:14:43Z",
    "comment": "Publication Link: https://ieeexplore.ieee.org/document/11118419",
    "light_analysis": {
      "overview": "本文提出一个动态框架，通过整合先进大型语言模型和自适应反馈机制到协作学习平台，以增强学生参与度和提升学习效果。",
      "motivation": "该研究旨在解决现有协作学习平台中存在的静态主持和个性化不足问题。现有方法无法实时适应学习者的多样化需求，导致学生参与度低、批判性思维培养受限和教育体验不平等。这些问题对于实现包容性和高效的教育至关重要，突出了改进AI驱动工具的必要性。",
      "method": "研究方法基于一个动态框架，集成LLM作为实时讨论主持人，并采用自适应反馈机制来优化AI主持、促进反思学习和平衡用户参与。关键创新包括模块化架构（使用ReactJS前端和Flask后端）和高效问题检索技术，通过动态调整提示和讨论流支持个性化交互。",
      "result": "测试结果显示，该框架显著提高了学生协作能力、促进了更深层次的理解，并在不同学科和用户群体中表现出良好的可扩展性。与基线方法相比，框架有效改善了讨论质量和包容性，但摘要未明确说明具体性能指标，如准确率或效率改进数据。",
      "conclusion": "该论文的主要贡献是通过动态LLM整合和自适应反馈机制，为下一代AI驱动教育工具奠定了基础。学术价值在于创新了协作学习中的AI主持方法，实际应用价值在于促进公平和高效的学习成果。未来工作可能涉及更广泛的测试和优化，以应对潜在局限性。",
      "tags": [
        "Large Language Model",
        "Adaptive Feedback Mechanism",
        "Collaborative Learning",
        "Modular Architecture",
        "Question Retrieval"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:07.941185Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21343",
    "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
    "authors": [
      "Ellen Xiaoqing Tan",
      "Shehzaad Dhuliawala",
      "Jing Xu",
      "Ping Yu",
      "Sainbayar Sukhbaatar",
      "Jason Weston",
      "Olga Golovneva"
    ],
    "abstract": "Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21343.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21343",
    "published": "2026-01-29T07:09:30Z",
    "updated": "2026-01-29T07:09:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种自改进预训练方法，结合后训练模型和强化学习，在预训练阶段提升大型语言模型生成的安全性、事实性和整体质量。",
      "motivation": "随着大型语言模型在真实世界应用中的广泛部署，其生成内容的安全性、事实性和质量成为关键挑战。当前主流方法依赖昂贵的人工标注数据和多阶段微调对齐，但即使经过复杂流程，仍无法纠正预训练期间学习的固有模式，导致不安全或虚假输出难以根除。因此，直接在预训练阶段介入至关重要，因为它塑造模型的核心行为，预防问题输出的深层固化。",
      "method": "该方法引入一种新颖的预训练技术，使用流式文档输入，并在每个步骤中应用强化学习来优化未来K个生成token的质量、安全性和事实性。关键创新在于利用一个强大的后训练模型评估候选生成，包括模型自生成的rollouts、原始后缀和重写后缀。训练早期依赖后训练模型对原始和重写后缀的指导，随着模型改进，强化学习机制奖励高质量的rollouts，实现从底层构建更优模型的自适应循环。摘要未明确说明具体数据集和模型架构细节。",
      "result": "实验结果表明，该方法在事实性和安全性方面相对于标准预训练取得显著改进，相对提升分别达到36.2%和18.5%。在整体生成质量评估中，基于赢率指标，改进高达86.3%。这些数据证明了该方法能有效提升模型输出可靠性和品质，为大型语言模型的性能优化提供了实证支持。",
      "conclusion": "该研究的主要贡献是提出了一种自改进预训练框架，通过融合后训练模型评估和强化学习，从根本上增强模型的安全性和事实性。学术上，它弥补了传统预训练方法的不足，提供了一种新的优化路径；实际上，有助于促进更安全可靠的AI系统在现实应用中的部署。未来工作可探索该方法在不同模型规模和任务领域的扩展性。",
      "tags": [
        "Reinforcement Learning",
        "Pretraining",
        "Self-Improving Models",
        "Safety Alignment",
        "Factuality Assessment"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:46.171851Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21342",
    "title": "Ostrakon-VL: Towards Domain-Expert MLLM for Food-Service and Retail Stores",
    "authors": [
      "Zhiyong Shen",
      "Gongpeng Zhao",
      "Jun Zhou",
      "Li Yu",
      "Guandong Kou",
      "Jichen Li",
      "Chuanlei Dong",
      "Zuncheng Li",
      "Kaimao Li",
      "Bingkun Wei",
      "Shicheng Hu",
      "Wei Xia",
      "Wenguo Duan"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have recently achieved substantial progress in general-purpose perception and reasoning. Nevertheless, their deployment in Food-Service and Retail Stores (FSRS) scenarios encounters two major obstacles: (i) real-world FSRS data, collected from heterogeneous acquisition devices, are highly noisy and lack auditable, closed-loop data curation, which impedes the construction of high-quality, controllable, and reproducible training corpora; and (ii) existing evaluation protocols do not offer a unified, fine-grained and standardized benchmark spanning single-image, multi-image, and video inputs, making it challenging to objectively gauge model robustness. To address these challenges, we first develop Ostrakon-VL, an FSRS-oriented MLLM based on Qwen3-VL-8B. Second, we introduce ShopBench, the first public benchmark for FSRS. Third, we propose QUAD (Quality-aware Unbiased Automated Data-curation), a multi-stage multimodal instruction data curation pipeline. Leveraging a multi-stage training strategy, Ostrakon-VL achieves an average score of 60.1 on ShopBench, establishing a new state of the art among open-source MLLMs with comparable parameter scales and diverse architectures. Notably, it surpasses the substantially larger Qwen3-VL-235B-A22B (59.4) by +0.7, and exceeds the same-scale Qwen3-VL-8B (55.3) by +4.8, demonstrating significantly improved parameter efficiency. These results indicate that Ostrakon-VL delivers more robust and reliable FSRS-centric perception and decision-making capabilities. To facilitate reproducible research, we will publicly release Ostrakon-VL and the ShopBench benchmark.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21342.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21342",
    "published": "2026-01-29T07:07:23Z",
    "updated": "2026-01-29T07:07:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了Ostrakon-VL，一个针对餐饮和零售店场景的领域专家多模态大语言模型，通过QUAD数据整理管道和ShopBench基准，实现了参数效率的提升和鲁棒感知能力。",
      "motivation": "多模态大语言模型在通用任务中表现优异，但在餐饮和零售店场景部署时面临两大障碍：真实世界数据来自异构设备，噪音大且缺乏闭环数据整理，导致训练数据质量低、可控性和可重复性差；现有评估方法缺乏统一、细粒度的基准，难以客观评估模型在单图像、多图像和视频输入下的鲁棒性。这些问题阻碍了MLLMs在特定领域的可靠应用，凸显了开发领域专用模型和标准化评估的必要性。",
      "method": "本研究基于Qwen3-VL-8B开发了Ostrakon-VL，一个针对餐饮和零售店的多模态大语言模型。引入了ShopBench，第一个公开的FSRS基准，覆盖多种输入模式。提出了QUAD（质量感知的无偏自动化数据整理）管道，一个多阶段多模态指令数据整理方法，采用多阶段训练策略优化数据质量。关键创新包括领域定制化的数据整理和统一评估框架，以提升模型在领域特定任务上的性能。",
      "result": "Ostrakon-VL在ShopBench基准上取得了60.1的平均得分，超越了多个基线模型。具体地，它超越了参数规模大得多的Qwen3-VL-235B-A22B（59.4分）0.7分，以及相同规模的Qwen3-VL-8B（55.3分）4.8分，显示出显著的参数效率提升。这些结果表明，Ostrakon-VL在餐饮和零售店场景中提供了更鲁棒和可靠的感知与决策能力，确立了在开源MLLMs中的新状态-of-the-art地位。",
      "conclusion": "本论文的主要贡献包括开发了Ostrakon-VL领域专家MLLM、引入ShopBench基准以及提出QUAD数据整理管道。学术上，它推动了多模态模型在特定领域的应用研究；实践上，为餐饮和零售店场景提供了更可靠的AI解决方案。研究计划公开发布模型和基准，以促进可重复研究。摘要未明确说明具体局限性或未来工作方向。",
      "tags": [
        "Multimodal Large Language Model",
        "Data Curation",
        "Benchmark Evaluation",
        "Domain Adaptation",
        "Parameter Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:59.490238Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21341",
    "title": "Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning",
    "authors": [
      "Ruiqi Liu",
      "Boyu Diao",
      "Zijia An",
      "Zhulin An",
      "Fei Wang",
      "Yongjun Xu"
    ],
    "abstract": "Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21341.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21341",
    "published": "2026-01-29T07:07:21Z",
    "updated": "2026-01-29T07:07:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "DAF提出一种动态融合机制，构建单个全局适配器，解决类增量学习中的知识遗忘问题，实现最先进的性能。",
      "motivation": "在类增量学习中，模型需要不断学习新类别而不忘记旧类别。现有主流方法通过冻结预训练模型并训练任务特定适配器，但这会阻碍知识在不同任务间的传递，并增加存储和检索成本。此外，简单的参数融合常导致破坏性干扰和灾难性遗忘，限制模型性能。因此，研究旨在开发一种更有效的方法来构建全局适配器，以克服这些挑战。",
      "method": "论文提出Dynamical Adapter Fusion (DAF)方法，该方法基于PAC-Bayes定理，推导出一个融合机制，整合三个关键组件：优化的任务特定适配器参数、前一个全局适配器参数和初始化参数。通过损失函数的泰勒展开，计算最优融合系数，动态平衡模型的稳定性和可塑性。此外，采用鲁棒初始化策略来捕获全局知识模式，确保适配器的有效性。",
      "result": "在多个类增量学习基准数据集上的实验结果表明，DAF方法达到了最先进的性能。这证明了该方法在提升模型准确性和鲁棒性方面的优势，但由于摘要未提供具体性能指标如准确率或效率改进数据，具体对比结果未明确说明。",
      "conclusion": "该研究的主要贡献是提出了DAF方法，通过动态融合适配器参数构建全局适配器，有效解决了类增量学习中的知识传递和遗忘问题。这具有重要的学术价值，推动了增量学习领域的发展，并为实际应用如资源受限的持续学习系统提供了潜在解决方案。未来工作可能包括方法的扩展和优化。",
      "tags": [
        "Class-Incremental Learning",
        "Adapter",
        "PAC-Bayes Theorem",
        "Taylor Expansion",
        "Dynamical Fusion"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:53.314634Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21340",
    "title": "EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation",
    "authors": [
      "Lang Cao",
      "Qingyu Chen",
      "Yue Guo"
    ],
    "abstract": "Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21340.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21340",
    "published": "2026-01-29T07:06:34Z",
    "updated": "2026-01-29T07:06:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出EHR-RAG框架，通过增强的检索增强生成技术，解决长时程结构化电子健康记录与大型语言模型之间的集成问题，提升临床预测的准确性。",
      "motivation": "电子健康记录（EHRs）为医学决策提供丰富的纵向临床证据，但长时程EHRs数据常超过大型语言模型（LLM）的上下文限制。现有方法如截断或简单检索策略会丢弃临床相关事件和时间依赖关系，影响预测性能，这突显了开发新方法以有效利用完整EHR数据的重要性，从而改进临床任务。研究背景强调了解决这一技术瓶颈的紧迫性，以支持更精确的医疗分析。",
      "method": "EHR-RAG框架包含三个关键组件：事件和时间感知的混合EHR检索，以保持临床结构和时间动态；自适应迭代检索，通过逐步优化查询扩展证据覆盖范围；双路径证据检索和推理，联合处理事实和反事实证据以增强推理能力。该方法针对纵向临床预测任务设计，整合检索增强生成技术，利用结构化EHR数据，并在四个长时程EHR预测任务中进行实验。关键创新在于结合时间依赖性和迭代优化，提高数据利用效率。",
      "result": "在四个长时程EHR预测任务中，EHR-RAG一致优于最强的基于LLM的基线方法，平均Macro-F1指标提升10.76%。这一性能改进表明框架在捕捉临床证据和时间依赖性方面有效，验证了其在复杂场景下的优越性。具体实验数据显示显著的效果提升，与基线相比，在保持计算效率的同时，增强了预测的准确性和可靠性。",
      "conclusion": "本研究的主要贡献是提出EHR-RAG框架，通过整合检索增强生成技术，有效解决长时程结构化电子健康记录与大型语言模型的集成挑战。它展示了检索增强LLMs在临床预测中的潜力，具有重要的学术价值（如推动医疗AI技术发展）和实际应用意义（如改进决策支持系统）。未来工作可能涉及扩展到更广泛的数据类型或优化实时性能，但摘要未明确说明具体局限性。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Large Language Models",
        "Electronic Health Records",
        "Temporal Modeling",
        "Clinical Prediction"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:29.213070Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21339",
    "title": "Within-Model vs Between-Prompt Variability in Large Language Models for Creative Tasks",
    "authors": [
      "Jennifer Haase",
      "Jana Gonnermann-Müller",
      "Paul H. P. Hanel",
      "Nicolas Leins",
      "Thomas Kosch",
      "Jan Mendling",
      "Sebastian Pokutta"
    ],
    "abstract": "How much of LLM output variance is explained by prompts versus model choice versus stochasticity through sampling? We answer this by evaluating 12 LLMs on 10 creativity prompts with 100 samples each (N = 12,000). For output quality (originality), prompts explain 36.43% of variance, comparable to model choice (40.94%). But for output quantity (fluency), model choice (51.25%) and within-LLM variance (33.70%) dominate, with prompts explaining only 4.22%. Prompts are powerful levers for steering output quality, but given the substantial within-LLM variance (10-34%), single-sample evaluations risk conflating sampling noise with genuine prompt or model effects.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21339.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21339",
    "published": "2026-01-29T07:04:46Z",
    "updated": "2026-01-29T07:04:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过量化分析，揭示了在创意任务中，LLM输出方差的来源：prompts对质量影响大，模型选择对数量影响大，且采样噪声显著。",
      "motivation": "该研究旨在解决评估大型语言模型（LLM）输出时方差来源不明确的问题。现有方法常依赖单次采样评估，可能将随机采样噪声误判为prompts或模型效应，导致结论偏差。因此，需要系统量化prompts、模型选择和随机采样对方差的贡献，以优化评估策略并提升结果可靠性。",
      "method": "论文采用实证研究方法，选取12个大型语言模型（LLM）和10个创意任务prompts，每个组合进行100次随机采样，总样本量为12,000。评估指标包括输出质量（基于原创性）和输出数量（基于流畅性）。核心创新在于应用统计方差分解技术，量化prompts、模型选择和within-model随机采样对输出方差的贡献，从而揭示各因素的相对重要性。",
      "result": "实验结果显示，对于输出质量（原创性），prompts解释了36.43%的方差，与模型选择（40.94%）相当；而对于输出数量（流畅性），模型选择主导了51.25%的方差，within-LLM随机采样贡献了33.70%，prompts仅占4.22%。这些数据突显了采样噪声的显著性（10-34%），表明单次采样评估可能混淆噪声与真实效应，从而高估prompts或模型的影响。",
      "conclusion": "论文的主要贡献是系统量化了LLM输出方差中prompts、模型选择和随机采样的相对贡献，强调了采样噪声的显著影响。学术上，它为LLM评估方法提供了新见解，推动了多采样策略的应用；实际中，可帮助用户更有效地利用prompts控制输出质量，并避免评估偏差。未来工作可扩展至更多任务或模型，以进一步验证通用性。",
      "tags": [
        "Large Language Model",
        "Prompt Engineering",
        "Variance Analysis",
        "Stochastic Sampling",
        "Creativity Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:34.585326Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21338",
    "title": "SR$^{2}$-Net: A General Plug-and-Play Model for Spectral Refinement in Hyperspectral Image Super-Resolution",
    "authors": [
      "Ji-Xuan He",
      "Guohang Zhuang",
      "Junge Bo",
      "Tingyi Li",
      "Chen Ling",
      "Yanan Qiao"
    ],
    "abstract": "HSI-SR aims to enhance spatial resolution while preserving spectrally faithful and physically plausible characteristics. Recent methods have achieved great progress by leveraging spatial correlations to enhance spatial resolution. However, these methods often neglect spectral consistency across bands, leading to spurious oscillations and physically implausible artifacts. While spectral consistency can be addressed by designing the network architecture, it results in a loss of generality and flexibility. To address this issue, we propose a lightweight plug-and-play rectifier, physically priors Spectral Rectification Super-Resolution Network (SR$^{2}$-Net), which can be attached to a wide range of HSI-SR models without modifying their architectures. SR$^{2}$-Net follows an enhance-then-rectify pipeline consisting of (i) Hierarchical Spectral-Spatial Synergy Attention (H-S$^{3}$A) to reinforce cross-band interactions and (ii) Manifold Consistency Rectification (MCR) to constrain the reconstructed spectra to a compact, physically plausible spectral manifold. In addition, we introduce a degradation-consistency loss to enforce data fidelity by encouraging the degraded SR output to match the observed low resolution input. Extensive experiments on multiple benchmarks and diverse backbones demonstrate consistent improvements in spectral fidelity and overall reconstruction quality with negligible computational overhead. Our code will be released upon publication.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21338.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21338",
    "published": "2026-01-29T07:00:00Z",
    "updated": "2026-01-29T07:00:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出SR$^{2}$-Net，一个通用的即插即用模型，用于高光谱图像超分辨率中的光谱优化，提升光谱保真度和物理合理性。",
      "motivation": "高光谱图像超分辨率（HSI-SR）旨在增强空间分辨率同时保持光谱的准确性和物理合理性。现有方法通过利用空间相关性来提升空间分辨率，但往往忽视了光谱带间的一致性，导致重建图像中出现虚假振荡和不合理的物理伪影。虽然可以通过设计特定网络架构来增强光谱一致性，但这牺牲了模型的通用性和灵活性。因此，需要一个既能解决光谱不一致问题，又能保持模型广泛适用性的新方法，以支持遥感等应用领域的可靠图像处理。",
      "method": "SR$^{2}$-Net是一个轻量级的即插即用模型，能够附加到多种现有HSI-SR模型上而不修改其架构。它采用增强-然后-优化流程，包含两个关键模块：分层光谱-空间协同注意力（H-S$^{3}$A）用于强化跨光谱带的交互，以及流形一致性优化（MCR）来约束重建光谱落在一个紧凑且物理合理的流形上。此外，引入了退化一致性损失函数，通过鼓励超分辨率输出的退化版本与低分辨率输入匹配来确保数据保真度。这种方法结合了注意力机制和流形学习，创新性地提高了光谱优化的灵活性和效果。",
      "result": "通过在多个基准数据集和不同HSI-SR骨干网络上的广泛实验，SR^2-Net展现了在光谱保真度和整体重建质量上的持续改进。实验表明，该方法能显著提升性能，同时计算开销可忽略不计。与基线方法相比，SR^2-Net在光谱一致性和物理合理性方面具有明显优势，验证了其作为通用插件的有效性和鲁棒性。改进体现在数值指标和视觉评估上，为高光谱图像超分辨率提供了更可靠的解决方案，摘要未明确说明具体数据如准确率。",
      "conclusion": "本研究的主要贡献是提出了SR^2-Net，一个灵活的即插即用模型，用于高光谱图像超分辨率中的光谱优化，提升光谱一致性和物理合理性，同时保持通用性和低计算成本。学术上，它为多光谱技术与深度学习的结合提供了新思路，增强了物理约束下的模型应用潜力。实际上，SR^2-Net可轻松集成到现有系统中，改善图像质量，支持遥感、医学影像等领域的应用。未来工作可能包括扩展更多应用场景和优化策略，摘要未明确说明局限性。",
      "tags": [
        "Hyperspectral Image Super-Resolution",
        "Plug-and-Play Model",
        "Spectral Consistency",
        "Hierarchical Spectral-Spatial Synergy Attention",
        "Manifold Consistency Rectification"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:26.404221Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21337",
    "title": "Qwen3-ASR Technical Report",
    "authors": [
      "Xian Shi",
      "Xiong Wang",
      "Zhifang Guo",
      "Yongqi Wang",
      "Pei Zhang",
      "Xinyu Zhang",
      "Zishan Guo",
      "Hongkun Hao",
      "Yu Xi",
      "Baosong Yang",
      "Jin Xu",
      "Jingren Zhou",
      "Junyang Lin"
    ],
    "abstract": "In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21337.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21337",
    "published": "2026-01-29T06:58:13Z",
    "updated": "2026-01-29T06:58:13Z",
    "comment": "https://github.com/QwenLM/Qwen3-ASR",
    "light_analysis": {
      "overview": "该论文提出了Qwen3-ASR家族，包括两个高性能多语言语音识别模型和一个创新的非自回归强制对齐模型，实现了在开源模型中的最先进性能和高效的精度-效率平衡。",
      "motivation": "本研究旨在解决语音识别模型在现实场景中性能差异显著的问题。现有方法在开源基准测试上可能表现相似，但实际应用中质量参差不齐，导致实用性受限。语音识别作为关键的人机交互技术，其准确性和效率对智能设备、语音助手等应用至关重要。现有ASR模型往往依赖通用基准，忽视了现实环境中的复杂性和多语言需求，因此需要更全面的评估和高效模型来提升整体性能。",
      "method": "研究方法基于Qwen3-Omni基础模型，利用大规模语音训练数据，开发了Qwen3-ASR-1.7B和0.6B两个语音识别模型，支持52种语言和方言的语言识别与语音识别。关键创新包括集成多语言处理能力和非自回归技术。此外，提出了Qwen3-ForcedAligner-0.6B，这是一个基于大语言模型的非自回归时间戳预测器，用于文本-语音对齐，覆盖11种语言。模型架构强调音频理解能力，通过参数优化实现高性能和高效率。",
      "result": "实验结果显示，Qwen3-ASR-1.7B版本在开源ASR模型中达到最先进性能，可与最强专有API竞争。Qwen3-ASR-0.6B版本提供最佳精度-效率权衡，平均TTFT低至92ms，在128并发下1秒内可转录2000秒语音。对齐模型Qwen3-ForcedAligner-0.6B在时间戳准确性上优于三个最强的强制对齐基线模型，并在效率和多功能性方面表现突出。这些结果通过内部评估和开源基准验证，强调了模型在现实场景中的优势。",
      "conclusion": "本论文的主要贡献是发布了高性能的Qwen3-ASR家族模型，包括ASR和强制对齐模型，在Apache 2.0许可下开源，旨在加速ASR和音频理解领域的社区研究。学术价值在于推动了多语言语音识别和非自回归对齐技术的发展，实际应用价值在于提升现实场景中的语音处理效率和准确性。摘要未明确说明局限性，但未来工作可能涉及扩展语言覆盖或优化模型可扩展性。",
      "tags": [
        "Speech Recognition",
        "Language Identification",
        "Non-Autoregressive Model",
        "Forced Alignment",
        "Large Language Model"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:05.526892Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21335",
    "title": "Modeling Endogenous Logic: Causal Neuro-Symbolic Reasoning Model for Explainable Multi-Behavior Recommendation",
    "authors": [
      "Yuzhe Chen",
      "Jie Cao",
      "Youquan Wang",
      "Haicheng Tao",
      "Darko B. Vukovic",
      "Jia Wu"
    ],
    "abstract": "Existing multi-behavior recommendations tend to prioritize performance at the expense of explainability, while current explainable methods suffer from limited generalizability due to their reliance on external information. Neuro-Symbolic integration offers a promising avenue for explainability by combining neural networks with symbolic logic rule reasoning. Concurrently, we posit that user behavior chains inherently embody an endogenous logic suitable for explicit reasoning. However, these observational multiple behaviors are plagued by confounders, causing models to learn spurious correlations. By incorporating causal inference into this Neuro-Symbolic framework, we propose a novel Causal Neuro-Symbolic Reasoning model for Explainable Multi-Behavior Recommendation (CNRE). CNRE operationalizes the endogenous logic by simulating a human-like decision-making process. Specifically, CNRE first employs hierarchical preference propagation to capture heterogeneous cross-behavior dependencies. Subsequently, it models the endogenous logic rule implicit in the user's behavior chain based on preference strength, and adaptively dispatches to the corresponding neural-logic reasoning path (e.g., conjunction, disjunction). This process generates an explainable causal mediator that approximates an ideal state isolated from confounding effects. Extensive experiments on three large-scale datasets demonstrate CNRE's significant superiority over state-of-the-art baselines, offering multi-level explainability from model design and decision process to recommendation results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21335.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21335",
    "published": "2026-01-29T06:51:54Z",
    "updated": "2026-01-29T06:51:54Z",
    "comment": "Accepted to The Web Conference (WWW) 2026",
    "light_analysis": {
      "overview": "本文提出了因果神经符号推理模型（CNRE），用于可解释的多行为推荐，通过整合因果推断和内生逻辑建模解决现有方法的可解释性与泛化性问题。",
      "motivation": "现有多行为推荐系统往往侧重性能而牺牲可解释性，当前可解释方法因依赖外部信息导致泛化性受限。神经符号集成通过结合神经网络和符号逻辑规则推理提供了可解释性路径，同时用户行为链中蕴含的内生逻辑适合显式推理，但观测行为受混淆因素影响，导致模型学习虚假相关。因此，本研究旨在结合因果推断消除这些虚假关联，提高推荐系统的可解释性和泛化能力。",
      "method": "CNRE 模型模拟人类决策过程，首先使用分层偏好传播捕捉异构跨行为依赖，然后基于偏好强度建模用户行为链中的内生逻辑规则，自适应分发到神经逻辑推理路径（如合取、析取）。这一过程生成近似理想状态、隔离混淆效应的可解释因果中介。关键创新点包括将因果推断融入神经符号框架，以及通过自适应推理路径实现逻辑规则的可操作化，无需外部信息即可建模内生逻辑。",
      "result": "在三个大规模数据集上的实验表明，CNRE 模型显著优于最先进的基线方法，展示了其在推荐性能上的优越性。尽管摘要未提供具体准确率数据，但强调了模型在多层次可解释性（从设计、决策到结果）方面的提升，有效解决了现有方法中可解释性与泛化性的平衡问题，证明了因果推断和神经符号集成的协同效果。",
      "conclusion": "CNRE 模型通过整合因果推断和神经符号推理，成功提高了多行为推荐的可解释性和泛化性，推动了可解释 AI 在推荐系统领域的应用。该研究不仅贡献了新的建模方法，还提供了从理论到实践的多层次解释能力，未来工作可探索模型在其他推荐场景或更复杂行为链中的扩展，以进一步验证其鲁棒性和适用性。",
      "tags": [
        "Causal Inference",
        "Neuro-Symbolic Reasoning",
        "Multi-Behavior Recommendation",
        "Explainable AI",
        "Endogenous Logic Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:20.509540Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21334",
    "title": "Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations",
    "authors": [
      "Pritika Vig",
      "Ren-Chin Wu",
      "William Lotter"
    ],
    "abstract": "Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21334.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21334",
    "published": "2026-01-29T06:50:43Z",
    "updated": "2026-01-29T06:50:43Z",
    "comment": "21 pages, 17 figures. Appendix included",
    "light_analysis": {
      "overview": "本研究证明视觉基础模型能从静态图像隐式学习连续疾病进展，轨迹保真度提供表示质量的新衡量指标。",
      "motivation": "视觉基础模型在分类基准上表现良好，但其表示是否编码连续过程尚不明确。在计算病理学中，疾病进展是连续生物学过程，现有模型可能仅捕捉离散分类，无法反映动态变化。因此，探究模型表示是否能隐含疾病进展轨迹，有助于提升模型生物学合理性、支持更稳健的泛化，并实现疾病转变特征的定量分析。解决此问题可推动模型更好地模拟真实世界连续现象。",
      "method": "研究采用扩散伪时间方法，这是一种源自单细胞转录组学的技术，用于推断发育轨迹，应用于分析基础模型的视觉表示空间。实验覆盖四种癌症进展和六个模型，包括病理特定模型和视觉专用模型，通过计算轨迹保真度评估表示是否沿一致方向组织疾病状态。关键创新在于将生物信息学方法迁移到视觉表示分析，探索模型隐含的连续结构。",
      "result": "实验显示所有病理特定模型恢复的轨迹排序显著优于随机基线，视觉专用模型保真度最高（如CRC-Serrated上τ>0.78）。轨迹保真度排名与少量样本分类性能强相关（ρ=0.92），表明表示质量预测下游任务效果。探索性分析揭示细胞类型组成沿推断轨迹平滑变化，模式与已知基质重塑一致，验证了生物学合理性。",
      "conclusion": "本研究证实视觉基础模型可从独立静态观察中隐式学习连续疾病进展，轨迹保真度作为表示质量的补充指标，超越传统下游性能评估。这为计算病理学提供新视角，促进模型生物学解释和泛化能力提升。框架可推广到其他基于静态快照观察连续过程的领域，具有广泛学术和应用价值，未来可探索更多疾病类型和模型架构。",
      "tags": [
        "Vision Foundation Models",
        "Diffusion Pseudotime",
        "Computational Pathology",
        "Trajectory Analysis",
        "Representation Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:46.688605Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21331",
    "title": "An introductory Generalization of the standard SVMs loss and its applications to Shallow and Deep Neural Networks",
    "authors": [
      "Filippo Portera"
    ],
    "abstract": "We propose a new convex loss for SVMs, both for the binary classification and for the regression models. Therefore, we show the mathematical derivation of the dual problems and we experiment them with several small data-sets. The minimal dimension of those data-sets is due to the difficult scalability of the SVM method to bigger instances. This preliminary study should prove that using pattern correlations inside the loss function could enhance the generalisation performances. Coherently, results show that generalisation measures are never worse than the standard losses and several times they are better. In our opinion, it should be considered a careful study of this loss, coupled with shallow and deep neural networks. In fact, we present some novel results obtained with those architectures.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21331.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21331",
    "published": "2026-01-29T06:47:51Z",
    "updated": "2026-01-29T06:47:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种新的SVM凸损失函数，通过引入模式相关性来提升泛化性能，并应用于浅层和深层神经网络。",
      "motivation": "研究动机源于支持向量机在处理大规模数据时存在的可扩展性问题，以及标准损失函数在泛化性能上的潜在不足。当前SVM方法难以扩展到更大数据集，导致现有方法在利用数据内在模式方面有限，影响了模型的鲁棒性和应用范围。为了解决这一问题，作者探索通过改进损失函数的设计，引入模式相关性，以增强二元分类和回归任务中的泛化能力，弥补现有技术的缺陷。",
      "method": "论文提出了一种新的凸损失函数，适用于SVM的二元分类和回归模型。方法包括数学推导双问题，以优化损失函数的结构，并利用模式相关性作为关键创新点。实验使用多个小型数据集进行验证，数据集规模小是由于SVM扩展性限制；技术路线涉及理论分析和初步实证测试，为后续集成浅层和深层神经网络提供了基础。具体细节包括损失函数的凸性质和适用于不同模型架构的适应性。",
      "result": "主要实验结果显示，使用新损失函数的泛化度量从不劣于标准损失，且多次实验中表现更好，初步证明了模式相关性对性能的积极影响。摘要未明确说明具体性能指标如准确率提升或效率改进，但与基线方法（标准损失）相比，新方法在泛化方面展现出定性的优势，暗示其在提升模型鲁棒性上的潜力。",
      "conclusion": "论文的主要贡献是提出并初步验证了一种基于模式相关性的SVM凸损失函数，实验表明其能提升泛化性能。研究具有学术价值，为损失函数设计和泛化理论提供了新视角，并可扩展应用于神经网络中；实际应用价值包括在分类和回归任务中提高模型稳定性。未来工作可进一步探究在浅层和深层神经网络中的集成，以及在大规模数据集上的测试和优化。",
      "tags": [
        "SVM",
        "Convex Loss",
        "Pattern Correlations",
        "Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:13.366018Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21323",
    "title": "Adversarial Vulnerability Transcends Computational Paradigms: Feature Engineering Provides No Defense Against Neural Adversarial Transfer",
    "authors": [
      "Achraf Hsain",
      "Ahmed Abdelkader",
      "Emmanuel Baldwin Mbaya",
      "Hamoud Aljamaan"
    ],
    "abstract": "Deep neural networks are vulnerable to adversarial examples--inputs with imperceptible perturbations causing misclassification. While adversarial transfer within neural networks is well-documented, whether classical ML pipelines using handcrafted features inherit this vulnerability when attacked via neural surrogates remains unexplored. Feature engineering creates information bottlenecks through gradient quantization and spatial binning, potentially filtering high-frequency adversarial signals. We evaluate this hypothesis through the first comprehensive study of adversarial transfer from DNNs to HOG-based classifiers. Using VGG16 as a surrogate, we generate FGSM and PGD adversarial examples and test transfer to four classical classifiers (KNN, Decision Tree, Linear SVM, Kernel SVM) and a shallow neural network across eight HOG configurations on CIFAR-10. Our results strongly refute the protective hypothesis: all classifiers suffer 16.6%-59.1% relative accuracy drops, comparable to neural-to-neural transfer. More surprisingly, we discover attack hierarchy reversal--contrary to patterns where iterative PGD dominates FGSM within neural networks, FGSM causes greater degradation than PGD in 100% of classical ML cases, suggesting iterative attacks overfit to surrogate-specific features that don't survive feature extraction. Block normalization provides partial but insufficient mitigation. These findings demonstrate that adversarial vulnerability is not an artifact of end-to-end differentiability but a fundamental property of image classification systems, with implications for security-critical deployments across computational paradigms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21323.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21323",
    "published": "2026-01-29T06:35:46Z",
    "updated": "2026-01-29T06:35:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文首次全面研究神经对抗样本向基于手工特征的经典机器学习分类器的转移，发现特征工程无法提供有效防御，并揭示攻击层次逆转现象。",
      "motivation": "研究动机源于对抗样本对深度神经网络的脆弱性，但现有研究主要关注神经网络内部的对抗转移，而未探索使用手工特征（如HOG）的经典ML管道是否同样脆弱。特征工程可能通过梯度量化和空间分箱创建信息瓶颈，过滤高频对抗信号，从而提供保护假设。然而，这假设未经系统验证，而跨计算范式的对抗转移对安全关键应用如自动驾驶和生物识别系统至关重要，因为传统方法在这些领域仍广泛使用。",
      "method": "研究方法采用VGG16作为神经替代模型生成FGSM和PGD对抗样本，在CIFAR-10数据集上评估对抗转移效果。评估对象包括四种经典分类器（KNN、决策树、线性SVM、核SVM）和一个浅层神经网络，使用八个不同的HOG配置进行特征提取。通过对比不同攻击方法和特征工程配置，首次全面分析对抗样本从神经网络到基于手工特征分类器的转移性能，关键创新在于系统测试了特征工程对对抗脆弱性的潜在防御作用。",
      "result": "主要实验结果显示，所有评估的分类器均遭受显著性能下降，相对准确率降低16.6%至59.1%，与神经网络内部的对抗转移效果相当。更重要的是，发现攻击层次逆转：在经典ML案例中，FGSM攻击导致比PGD更大的退化，100%情况下如此，与神经网络中PGD通常更优的模式相反。这表明迭代攻击如PGD可能过拟合到替代模型特定特征，而特征工程无法有效过滤对抗信号。块归一化提供了部分缓解，但不足以完全防御。",
      "conclusion": "论文结论强调对抗脆弱性是图像分类系统的基本属性，不仅限于端到端可微的神经网络，而是跨越不同计算范式。研究首次证明特征工程无法有效防御神经对抗转移，对安全关键部署如自动驾驶和面部识别系统有重要安全影响。学术价值在于揭示了跨范式的安全漏洞，挑战了特征工程作为防御手段的假设。未来工作可能包括开发更鲁棒的特征提取方法或结合防御机制，以应对这一普遍脆弱性。",
      "tags": [
        "Adversarial Transfer",
        "Feature Engineering",
        "HOG",
        "FGSM",
        "PGD"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:38.979356Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21321",
    "title": "White-Box Op-Amp Design via Human-Mimicking Reasoning",
    "authors": [
      "Zihao Chen",
      "Jiayin Wang",
      "Ziyi Sun",
      "Ji Zhuang",
      "Jinyi Shen",
      "Xiaoyue Ke",
      "Li Shang",
      "Xuan Zeng",
      "Fan Yang"
    ],
    "abstract": "This brief proposes \\emph{White-Op}, an interpretable operational amplifier (op-amp) parameter design framework based on the human-mimicking reasoning of large-language-model agents. We formalize the implicit human reasoning mechanism into explicit steps of \\emph{\\textbf{introducing hypothetical constraints}}, and develop an iterative, human-like \\emph{\\textbf{hypothesis-verification-decision}} workflow. Specifically, the agent is guided to introduce hypothetical constraints to derive and properly regulate positions of symbolically tractable poles and zeros, thus formulating a closed-form mathematical optimization problem, which is then solved programmatically and verified via simulation. Theory-simulation result analysis guides the decision-making for refinement. Experiments on 9 op-amp topologies show that, unlike the uninterpretable black-box baseline which finally fails in 5 topologies, White-Op achieves reliable, interpretable behavioral-level designs with only 8.52\\% theoretical prediction error and the design functionality retains after transistor-level mapping for all topologies. White-Op is open-sourced at \\textcolor{blue}{https://github.com/zhchenfdu/whiteop}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21321.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21321",
    "published": "2026-01-29T06:30:37Z",
    "updated": "2026-01-29T06:30:37Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出White-Op框架，利用大语言模型模仿人类推理实现可解释的运算放大器参数设计。",
      "motivation": "运算放大器设计通常依赖黑盒方法，缺乏可解释性，导致调试困难且在复杂拓扑中可能失败。现有方法如不可解释的优化算法难以提供透明设计决策，限制了设计的可靠性和验证效率。本文旨在解决这一问题，通过模仿人类推理过程，提供更直观、可靠的设计方案，以应对实际工程中对可解释性和鲁棒性的需求。摘要未明确说明具体行业应用背景，但强调了可解释设计的重要性。",
      "method": "方法核心基于大语言模型代理，形式化人类推理为显式步骤：首先引入假设约束来推导符号可处理的极点和零点位置，形成封闭形式数学优化问题；然后通过编程求解优化，并结合电路仿真进行验证；最后采用迭代的假设-验证-决策工作流分析理论-仿真结果，以指导设计精化。关键创新在于将隐式推理机制转化为可编程流程，结合符号分析和仿真验证，提高设计可解释性。摘要未提及具体模型架构或训练数据集，但强调了人类模仿推理和优化求解的结合。",
      "result": "实验在9种运算放大器拓扑上进行，结果显示White-Op在所有拓扑中都实现了成功设计，理论预测误差仅为8.52%，并且经过晶体管级映射后设计功能得以保留。相比之下，不可解释的黑盒基线在5个拓扑中失败，无法完成设计。这些数据表明White-Op在可靠性和可解释性方面显著优于基线方法，有效减少了设计失败率并提供了行为级设计验证。摘要未提供额外性能指标如效率改进，但突出了理论误差和拓扑成功率的对比。",
      "conclusion": "White-Op通过模仿人类推理，提供了一种可解释的运算放大器设计方法，显著提升了设计的可靠性和透明度。该研究的学术价值在于推动人工智能在电路设计领域的应用，结合符号推理和仿真验证；实际价值在于自动化设计流程，减少人工干预。局限性可能包括对特定拓扑的依赖或计算复杂度，未来工作可扩展到其他电路类型或优化推理效率。摘要未明确说明未来方向，但开源框架为后续研究提供了基础。",
      "tags": [
        "Large Language Model",
        "Human-Mimicking Reasoning",
        "Op-Amp Design",
        "Mathematical Optimization",
        "Simulation"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:48.683098Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21320",
    "title": "Optimal Transport-Induced Samples against Out-of-Distribution Overconfidence",
    "authors": [
      "Keke Tang",
      "Ziyong Du",
      "Xiaofei Wang",
      "Weilong Peng",
      "Peican Zhu",
      "Zhihong Tian"
    ],
    "abstract": "Deep neural networks (DNNs) often produce overconfident predictions on out-of-distribution (OOD) inputs, undermining their reliability in open-world environments. Singularities in semi-discrete optimal transport (OT) mark regions of semantic ambiguity, where classifiers are particularly prone to unwarranted high-confidence predictions. Motivated by this observation, we propose a principled framework to mitigate OOD overconfidence by leveraging the geometry of OT-induced singular boundaries. Specifically, we formulate an OT problem between a continuous base distribution and the latent embeddings of training data, and identify the resulting singular boundaries. By sampling near these boundaries, we construct a class of OOD inputs, termed optimal transport-induced OOD samples (OTIS), which are geometrically grounded and inherently semantically ambiguous. During training, a confidence suppression loss is applied to OTIS to guide the model toward more calibrated predictions in structurally uncertain regions. Extensive experiments show that our method significantly alleviates OOD overconfidence and outperforms state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21320.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21320",
    "published": "2026-01-29T06:29:36Z",
    "updated": "2026-01-29T06:29:36Z",
    "comment": "Accepted by ICLR 2026",
    "light_analysis": {
      "overview": "该论文提出一种基于最优传输几何结构的新框架，通过生成语义模糊的分布外样本来缓解深度神经网络的过度自信问题。",
      "motivation": "深度神经网络在分布外输入上常产生过度自信预测，这降低了模型在开放世界环境中的可靠性，限制其实用性。现有方法在缓解此类问题时可能效果有限，尤其是在语义模糊区域。论文观察到半离散最优传输中的奇异性标记了语义模糊区，分类器在这些区域易产生不必要的高自信预测，因此有必要开发基于几何结构的新方法来改善模型校准，提升整体可信度。",
      "method": "论文提出一个原则性框架，首先在连续基础分布和训练数据的潜在嵌入之间定义最优传输问题，以识别生成的奇异边界，这些边界对应于语义模糊区域。通过在边界附近采样，构建几何基础的分布外样本（OTIS），这些样本具有内在语义模糊性。训练过程中，对OTIS应用置信度抑制损失，引导模型在结构不确定区域减少高自信预测，从而提高预测校准性，关键创新在于利用OT几何结构采样OOD输入。",
      "result": "通过大量实验验证，该方法能显著缓解深度神经网络在分布外输入上的过度自信问题。论文表明其在性能上超越了现有的最先进方法，但摘要未明确提供具体数值指标如准确率提升。实验结果突出了OTIS采样和置信度抑制损失的有效性，验证了该方法在改善模型校准和可靠性方面的优势，与基线方法对比显示出明显改进。",
      "conclusion": "该研究通过利用最优传输几何结构提出新框架，有效缓解了深度神经网络的过度自信问题，增强了模型在开放世界应用中的可信度。主要贡献在于构建了语义模糊的分布外样本并应用置信度抑制损失，具有重要的学术和实际价值。未来工作可能包括将该方法扩展到不同模型或复杂场景，以进一步验证其泛化能力和潜在局限性。",
      "tags": [
        "Optimal Transport",
        "Out-of-Distribution Detection",
        "Confidence Calibration",
        "Semi-Discrete OT",
        "Overconfidence Mitigation"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:10.924697Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21316",
    "title": "Heterogeneous Vertiport Selection Optimization for On-Demand Air Taxi Services: A Deep Reinforcement Learning Approach",
    "authors": [
      "Aoyu Pang",
      "Maonan Wang",
      "Zifan Sha",
      "Wenwei Yue",
      "Changle Li",
      "Chung Shue Chen",
      "Man-On Pun"
    ],
    "abstract": "Urban Air Mobility (UAM) has emerged as a transformative solution to alleviate urban congestion by utilizing low-altitude airspace, thereby reducing pressure on ground transportation networks. To enable truly efficient and seamless door-to-door travel experiences, UAM requires close integration with existing ground transportation infrastructure. However, current research on optimal integrated routing strategies for passengers in air-ground mobility systems remains limited, with a lack of systematic exploration.To address this gap, we first propose a unified optimization model that integrates strategy selection for both air and ground transportation. This model captures the dynamic characteristics of multimodal transport networks and incorporates real-time traffic conditions alongside passenger decision-making behavior. Building on this model, we propose a Unified Air-Ground Mobility Coordination (UAGMC) framework, which leverages deep reinforcement learning (RL) and Vehicle-to-Everything (V2X) communication to optimize vertiport selection and dynamically plan air taxi routes. Experimental results demonstrate that UAGMC achieves a 34\\% reduction in average travel time compared to conventional proportional allocation methods, enhancing overall travel efficiency and providing novel insights into the integration and optimization of multimodal transportation systems. This work lays a solid foundation for advancing intelligent urban mobility solutions through the coordination of air and ground transportation modes. The related code can be found at https://github.com/Traffic-Alpha/UAGMC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21316.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21316",
    "published": "2026-01-29T06:26:16Z",
    "updated": "2026-01-29T06:26:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一个基于深度强化学习和V2X通信的统一空陆多模态交通协调框架，优化垂直起降场选择和空中出租车路线动态规划。",
      "motivation": "研究动机是解决城市空中交通与地面交通系统集成优化问题。UAM能缓解城市拥堵，但现有方法缺乏系统性探索空陆多模态路由策略，导致无法充分利用动态网络和实时交通条件。这个问题重要在于实现高效无缝门到门出行，而现有研究在整合乘客决策行为和动态交通特性方面不足，因此需要开发新模型来优化协调策略。",
      "method": "方法上，首先提出统一优化模型，集成空陆策略选择，捕获多模态网络的动态特征和实时交通条件，并纳入乘客决策行为。基于此，提出UAGMC框架，利用深度强化学习和V2X通信来优化垂直起降场选择并动态规划空中出租车路线。关键创新是结合了技术集成，通过RL实现自适应优化，并使用V2X通信支持实时数据传输和交互。",
      "result": "实验结果表明，UAGMC框架相比传统比例分配方法，平均旅行时间减少了34%，显著提升了整体旅行效率。具体数据显示优化效果明显，为多模态交通系统的集成提供了实证依据，与基线方法相比在动态规划方面表现优越。",
      "conclusion": "本研究的主要贡献是提出了统一优化模型和框架，为空陆多模态交通协调奠定了基础，推动了智能城市交通解决方案的发展。学术价值在于探索了深度强化学习在复杂交通系统中的应用，实际应用价值在于提升出行效率和缓解拥堵。未来工作可扩展至更多交通模式和场景优化。",
      "tags": [
        "Deep Reinforcement Learning",
        "Vehicle-to-Everything (V2X)",
        "Urban Air Mobility (UAM)",
        "Optimization Model",
        "Multimodal Transport"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:18.237387Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21315",
    "title": "Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation",
    "authors": [
      "Seonghwi Kim",
      "Sung Ho Jo",
      "Wooseok Ha",
      "Minwoo Chae"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) is a statistical learning problem when the distribution of training (source) data is different from that of test (target) data. In this setting, one has access to labeled data only from the source domain and unlabeled data from the target domain. The central objective is to leverage the source data and the unlabeled target data to build models that generalize to the target domain. Despite its potential, existing UDA approaches often struggle in practice, particularly in scenarios where the target domain offers only limited unlabeled data or spurious correlations dominate the source domain. To address these challenges, we propose a novel distributionally robust learning framework that models uncertainty in both the covariate distribution and the conditional label distribution. Our approach is motivated by the multi-source domain adaptation setting but is also directly applicable to the single-source scenario, making it versatile in practice. We develop an efficient learning algorithm that can be seamlessly integrated with existing UDA methods. Extensive experiments under various distribution shift scenarios show that our method consistently outperforms strong baselines, especially when target data are extremely scarce.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21315.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21315",
    "published": "2026-01-29T06:23:14Z",
    "updated": "2026-01-29T06:23:14Z",
    "comment": "Accepted at ICLR 2026. 10 pages (excluding references)",
    "light_analysis": {
      "overview": "提出了一种分布鲁棒学习框架，用于处理多源无监督域自适应中的分布不确定性和目标数据稀缺问题。",
      "motivation": "无监督域自适应（UDA）面临训练和测试数据分布不一致的挑战，源域有标签而目标域无标签，导致模型泛化能力受限。现有方法在实际应用中表现不佳，特别是在目标域数据稀缺或源域存在伪相关性时，这些问题限制了UDA的实用性和鲁棒性。因此，需要一种更有效的方法来处理分布不确定性，提高模型在新领域的适应性。",
      "method": "本文提出了一种分布鲁棒的分类框架，通过建模协变量分布和条件标签分布的不确定性，来增强域自适应能力。该框架适用于多源域自适应，同时也兼容单源场景，具有较好的通用性。关键创新点在于引入分布鲁棒性，以减少对源域伪相关性的依赖。开发了高效的学习算法，可与现有UDA方法无缝集成，无需大规模修改现有模型架构。",
      "result": "实验结果显示，在各种分布偏移场景下，该方法始终优于强基线方法，尤其是在目标域数据极度稀缺时，性能提升更为显著。摘要未明确说明具体的性能指标如准确率或效率数据，但证实了该方法在处理不确定性和数据稀缺问题上的有效性，并通过对比实验验证了其鲁棒性优势。",
      "conclusion": "该研究的主要贡献在于开发了一个鲁棒的无监督域自适应框架，提高了模型在目标数据稀缺下的泛化能力。学术上，它扩展了UDA方法的理论边界；实践中，增强了机器学习模型部署到新环境的能力。摘要未明确说明局限性或未来工作方向，但该方法为处理复杂的域自适应问题提供了新的解决方案和潜在研究方向。",
      "tags": [
        "Unsupervised Domain Adaptation",
        "Distributionally Robust Learning",
        "Multi-source Domain Adaptation",
        "Classification",
        "Uncertainty Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:36.337699Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21314",
    "title": "HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence",
    "authors": [
      "Yanfeng Li",
      "Tao Tan",
      "Qingquan Gao",
      "Zhiwen Cao",
      "Xiaohong liu",
      "Yue Sun"
    ],
    "abstract": "High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21314.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21314",
    "published": "2026-01-29T06:22:26Z",
    "updated": "2026-01-29T06:22:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了LANE和AdaGraph方法，通过紧凑自回归依赖和自适应计算图重构，实现了高效高保真的3D网格生成。",
      "motivation": "现有方法将3D网格转换为1D序列并使用自回归建模，但资源利用不足，导致推理速度慢且只能处理小规模序列，这严重限制了结构细节的表达能力。高质量3D网格在虚拟现实、游戏等领域至关重要，然而现有方法的效率瓶颈阻碍了实际应用。因此，需要开发一种能提升序列处理能力和加速推理的方法，以解决现有技术在资源利用和细节生成上的不足。",
      "method": "论文提出了Latent Autoregressive Network (LANE)，通过在生成过程中引入紧凑自回归依赖，显著提高了最大可生成序列长度。同时，设计了Adaptive Computation Graph Reconfiguration (AdaGraph)策略，通过时空解耦在生成过程中优化计算图，有效克服传统串行推理的效率瓶颈。这些创新方法结合自回归模型，专注于提升资源利用率和生成效率，适用于大规模3D网格的建模，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验验证显示，LANE在最大可生成序列长度上实现了相比现有方法6倍的提升。在生成速度、结构细节和几何一致性方面均表现出优越性能，提供了高质量3D网格生成的有效解决方案。与基线方法对比，该方法在效率和细节表达上均有显著改进，但摘要未提供具体性能指标如准确率数据，仅强调了整体优势。",
      "conclusion": "本研究的主要贡献是提出了LANE和AdaGraph方法，通过紧凑依赖和计算图重构，为高效高保真3D网格生成提供了创新方案。这在学术上推动了自回归模型在3D生成领域的应用，实践中有助于加速虚拟现实、游戏等领域的3D内容创作。摘要未明确说明潜在局限性或未来工作方向，但强调了方法的有效性和广泛适用性。",
      "tags": [
        "3D Mesh Generation",
        "Autoregressive Approaches",
        "Latent Autoregressive Network",
        "Adaptive Computation Graph Reconfiguration",
        "Spatiotemporal Decoupling"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:38.733009Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21312",
    "title": "Few-Shot Learning for Dynamic Operations of Automated Electric Taxi Fleets under Evolving Charging Infrastructure: A Meta-Deep Reinforcement Learning Approach",
    "authors": [
      "Xiaozhuang Li",
      "Xindi Tang",
      "Fang He"
    ],
    "abstract": "With the rapid expansion of electric vehicles (EVs) and charging infrastructure, the effective management of Autonomous Electric Taxi (AET) fleets faces a critical challenge in environments with dynamic and uncertain charging availability. While most existing research assumes a static charging network, this simplification creates a significant gap between theoretical models and real-world operations. To bridge this gap, we propose GAT-PEARL, a novel meta-reinforcement learning framework that learns an adaptive operational policy. Our approach integrates a graph attention network (GAT) to effectively extract robust spatial representations under infrastructure layouts and model the complex spatiotemporal relationships of the urban environment, and employs probabilistic embeddings for actor-critic reinforcement learning (PEARL) to enable rapid, inference-based adaptation to changes in charging network layouts without retraining. Through extensive simulations on real-world data in Chengdu, China, we demonstrate that GAT-PEARL significantly outperforms conventional reinforcement learning baselines, showing superior generalization to unseen infrastructure layouts and achieving higher overall operational efficiency in dynamic settings.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21312.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21312",
    "published": "2026-01-29T06:16:34Z",
    "updated": "2026-01-29T06:16:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出GAT-PEARL，一种结合图注意力网络和概率嵌入强化学习的元学习框架，用于动态管理自动驾驶电动出租车车队，适应充电基础设施变化。",
      "motivation": "随着电动汽车和充电基础设施的快速扩张，自动驾驶电动出租车（AET）车队的有效管理在动态和不确定的充电可用性环境中面临关键挑战。现有研究大多假设静态充电网络，这种简化导致理论模型与实际运营之间存在显著差距，无法应对真实世界中的基础设施变化，从而限制了车队运营的效率和适应性。因此，开发能够适应充电网络布局动态变化的运营策略至关重要，以减少运营成本并提高服务质量。",
      "method": "论文提出GAT-PEARL框架，这是一种元强化学习方法，集成了图注意力网络（GAT）和概率嵌入的演员-评论家强化学习（PEARL）。GAT用于从基础设施布局中提取鲁棒的空间表示，并建模城市环境的复杂时空关系；PEARL通过概率嵌入实现基于推理的快速适应，使模型能在充电网络布局变化时无需重新训练即可调整策略。创新点在于结合了GAT的时空建模能力和PEARL的元学习特性，实现few-shot学习，适应动态环境。技术细节包括使用中国成都的真实数据进行模拟，但具体数据集和模型架构参数摘要未明确说明。",
      "result": "通过对中国成都真实数据的广泛模拟，GAT-PEARL在动态充电网络环境中显著优于传统的强化学习基线方法。具体表现为，在未见过的充电基础设施布局上展现出优越的泛化能力，并实现了更高的整体运营效率。摘要未提供具体的性能指标如准确率或效率提升百分比，但结果表明该框架能够有效适应变化，提高车队运营的鲁棒性和适应性。与基线对比，GAT-PEARL在动态设置中表现出更好的性能，证明了其元学习方法的有效性。",
      "conclusion": "本研究的主要贡献是提出了GAT-PEARL，一个新颖的元强化学习框架，用于解决自动驾驶电动出租车车队在动态充电基础设施下的运营问题。该框架通过结合GAT和PEARL，实现了自适应策略学习，无需重新训练即可适应变化，具有重要的学术价值和实际应用价值。学术上，它为元强化学习在动态环境管理中的应用提供了新思路；实际上，有助于提高AET车队的运营效率和服务质量。局限性或未来工作方向在摘要中未明确说明，但可以推断可能包括扩展到更复杂场景或与其他技术结合。",
      "tags": [
        "Meta-Reinforcement Learning",
        "Graph Attention Network (GAT)",
        "Probabilistic Embeddings for Actor-Critic (PEARL)",
        "Few-Shot Learning",
        "Spatiotemporal Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:18.201967Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21309",
    "title": "Transferable Graph Condensation from the Causal Perspective",
    "authors": [
      "Huaming Du",
      "Yijie Huang",
      "Su Yao",
      "Yiying Wang",
      "Yueyang Zhou",
      "Jingwen Yang",
      "Jinshi Zhang",
      "Han Ji",
      "Yu Zhao",
      "Guisong Liu",
      "Hegui Zhang",
      "Carl Yang",
      "Gang Kou"
    ],
    "abstract": "The increasing scale of graph datasets has significantly improved the performance of graph representation learning methods, but it has also introduced substantial training challenges. Graph dataset condensation techniques have emerged to compress large datasets into smaller yet information-rich datasets, while maintaining similar test performance. However, these methods strictly require downstream applications to match the original dataset and task, which often fails in cross-task and cross-domain scenarios. To address these challenges, we propose a novel causal-invariance-based and transferable graph dataset condensation method, named \\textbf{TGCC}, providing effective and transferable condensed datasets. Specifically, to preserve domain-invariant knowledge, we first extract domain causal-invariant features from the spatial domain of the graph using causal interventions. Then, to fully capture the structural and feature information of the original graph, we perform enhanced condensation operations. Finally, through spectral-domain enhanced contrastive learning, we inject the causal-invariant features into the condensed graph, ensuring that the compressed graph retains the causal information of the original graph. Experimental results on five public datasets and our novel \\textbf{FinReport} dataset demonstrate that TGCC achieves up to a 13.41\\% improvement in cross-task and cross-domain complex scenarios compared to existing methods, and achieves state-of-the-art performance on 5 out of 6 datasets in the single dataset and task scenario.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21309.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21309",
    "published": "2026-01-29T06:13:35Z",
    "updated": "2026-01-29T06:13:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种基于因果不变性的可转移图数据集压缩方法TGCC，有效解决了现有方法在跨任务和跨域场景中的局限。",
      "motivation": "图数据集规模增大提升了图表示学习性能，但也带来了显著的训练挑战。图数据集压缩技术通过生成小而信息丰富的压缩数据集来缓解这一问题，但这些方法严格要求下游应用与原始数据集和任务匹配，导致在跨任务和跨域场景中常常失败。这限制了图压缩技术在现实世界多样化应用（如金融分析）中的实用性，因此需要开发一种可转移的压缩方法以应对这些复杂场景。",
      "method": "TGCC方法结合因果推理和图学习技术，实现可转移的图数据集压缩。首先，通过因果干预从图的空间域提取领域因果不变特征，这些特征在不同领域间保持稳定。然后，执行增强的压缩操作以充分捕获原始图的结构和特征信息。最后，利用谱域增强的对比学习，将因果不变特征注入到压缩图中，确保压缩图保留原始图的因果信息，从而提高在跨域场景中的适应性。",
      "result": "实验在五个公共数据集和新提出的FinReport数据集上进行验证。在跨任务和跨域复杂场景中，TGCC相比现有方法实现了高达13.41%的性能提升。在单一数据集和任务场景中，TGCC在五个数据集上达到了state-of-the-art性能，仅在其中一个数据集上未达到最优，展示了该方法在不同设置下的有效性和鲁棒性。",
      "conclusion": "论文的主要贡献是提出了TGCC方法，通过因果视角解决了图数据集压缩的可转移性问题，具有重要的学术价值，因为它融合了因果推理和图学习技术。实际上，TGCC提高了图压缩在跨域应用（如金融分析）中的实用性。摘要未明确说明研究的局限性或未来工作方向。",
      "tags": [
        "Graph Condensation",
        "Causal Invariance",
        "Contrastive Learning",
        "Transfer Learning",
        "Graph Representation Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:12.112001Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21307",
    "title": "Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification",
    "authors": [
      "Md Nadim Mahamood",
      "Md Imran Hasan",
      "Md Rasheduzzaman",
      "Ausrukona Ray",
      "Md Shafi Ud Doula",
      "Kamrul Hasan"
    ],
    "abstract": "The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21307.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21307",
    "published": "2026-01-29T05:59:53Z",
    "updated": "2026-01-29T05:59:53Z",
    "comment": "18 Pages, 7 Tables, 5 Figures",
    "light_analysis": {
      "overview": "论文提出Mam-App，一种基于Mamba的参数高效模型，用于苹果叶病分类，在保持高性能的同时显著减少参数数量。",
      "motivation": "全球人口增长和技术进步加剧了食品生产需求，苹果作为广泛生产的水果，其病害导致大量产量损失。现有机器学习方法用于特征提取和早期诊断，深度学习模型虽性能优异，但参数密集导致训练和推理时间增加；轻量级模型适合资源受限应用，但常伴随性能下降。因此，研究需解决效率与性能之间的权衡问题，以实现实际部署中的高效诊断。",
      "method": "论文提出Mam-App，一个基于Mamba的参数高效模型，用于特征提取和叶病分类。该方法采用Mamba技术优化参数效率，关键创新点在于结合Mamba架构减少参数数量而不牺牲性能。研究使用PlantVillage苹果叶病数据集进行主要评估，并扩展到玉米和土豆叶病数据集测试泛化性。模型具体架构和训练细节在摘要中未明确说明，但专注于参数高效设计。",
      "result": "在PlantVillage苹果叶病数据集上，Mam-App达到99.58%准确率、99.30%精确率、99.14%召回率和99.22% F1-score，参数仅0.051M，显著低于传统模型。在玉米叶病数据集上，性能为99.48%准确率、99.20%精确率、99.34%召回率和99.27% F1-score；土豆数据集上为98.46%准确率、98.91%精确率、95.39%召回率和97.01% F1-score。与现有方法相比，模型在保持竞争性性能的同时，参数极低，适合低资源平台部署。",
      "conclusion": "论文的主要贡献是提出Mam-App模型，有效平衡苹果叶病分类中的效率与性能，推动轻量级深度学习发展。学术价值在于探索参数高效方法，实际应用价值在于可部署于无人机、移动设备等资源受限环境，助力精准农业减少作物损失。局限性或未来工作方向在摘要中未明确说明，但可能涉及模型优化或扩展到更广泛病害分类任务。",
      "tags": [
        "Mamba Model",
        "Parameter Efficiency",
        "Leaf Disease Classification",
        "Feature Extraction",
        "PlantVillage Dataset"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:29.794455Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21306",
    "title": "The Surprising Difficulty of Search in Model-Based Reinforcement Learning",
    "authors": [
      "Wei-Di Chang",
      "Mikael Henaff",
      "Brandon Amos",
      "Gregory Dudek",
      "Scott Fujimoto"
    ],
    "abstract": "This paper investigates search in model-based reinforcement learning (RL). Conventional wisdom holds that long-term predictions and compounding errors are the primary obstacles for model-based RL. We challenge this view, showing that search is not a plug-and-play replacement for a learned policy. Surprisingly, we find that search can harm performance even when the model is highly accurate. Instead, we show that mitigating distribution shift matters more than improving model or value function accuracy. Building on this insight, we identify key techniques for enabling effective search, achieving state-of-the-art performance across multiple popular benchmark domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21306.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21306",
    "published": "2026-01-29T05:58:24Z",
    "updated": "2026-01-29T05:58:24Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文挑战传统观点，揭示在基于模型的强化学习中搜索并非即插即用，缓解分布漂移比提高模型精度更重要，并提出了关键技术实现最优性能。",
      "motivation": "本研究旨在解决基于模型强化学习（MBRL）中搜索的困难问题。传统观点认为长期预测误差是MBRL的主要障碍，但论文发现搜索可能损害性能，即使模型准确。这揭示了现有方法忽视分布漂移的影响，而搜索作为核心组件在实际应用中表现不佳，因此需要重新审视搜索的有效性和关键因素。",
      "method": "论文基于对分布漂移重要性的洞察，识别了使搜索有效的关键技术。核心方法是通过实验验证缓解分布漂移的优先级，而非优化模型或值函数精度。尽管摘要未明确说明具体算法细节，但可能涉及策略改进或数据对齐技术，以在搜索过程中减少分布不匹配。",
      "result": "实验结果显示，通过缓解分布漂移，论文提出的方法在多个流行基准领域（如标准强化学习环境）中实现了最先进的性能。虽然摘要未提供具体数值指标，但强调性能优于传统基线，验证了分布漂移作为关键因素的有效性和技术优越性。",
      "conclusion": "论文的主要贡献是挑战了MBRL中关于障碍的传统观点，突出了分布漂移的重要性，为研究提供新方向。其学术价值在于推动有效搜索算法的发展，实际应用潜力在于提升强化学习在复杂任务中的鲁棒性。局限性包括未详述所有技术细节，未来工作可能涉及进一步优化或扩展。",
      "tags": [
        "Model-Based Reinforcement Learning",
        "Search",
        "Distribution Shift",
        "Policy Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:59.235907Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21301",
    "title": "Achieving $\\varepsilon^{-2}$ Dependence for Average-Reward Q-Learning with a New Contraction Principle",
    "authors": [
      "Zijun Chen",
      "Zaiwei Chen",
      "Nian Si",
      "Shengbo Wang"
    ],
    "abstract": "We present the convergence rates of synchronous and asynchronous Q-learning for average-reward Markov decision processes, where the absence of contraction poses a fundamental challenge. Existing non-asymptotic results overcome this challenge by either imposing strong assumptions to enforce seminorm contraction or relying on discounted or episodic Markov decision processes as successive approximations, which either require unknown parameters or result in suboptimal sample complexity. In this work, under a reachability assumption, we establish optimal $\\widetilde{O}(\\varepsilon^{-2})$ sample complexity guarantees (up to logarithmic factors) for a simple variant of synchronous and asynchronous Q-learning that samples from the lazified dynamics, where the system remains in the current state with some fixed probability. At the core of our analysis is the construction of an instance-dependent seminorm and showing that, after a lazy transformation of the Markov decision process, the Bellman operator becomes one-step contractive under this seminorm.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21301.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21301",
    "published": "2026-01-29T05:54:31Z",
    "updated": "2026-01-29T05:54:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文通过构建实例依赖的半范数和惰性变换，为平均奖励 Q-learning 实现了最优的 ε⁻² 样本复杂度。",
      "motivation": "研究动机是解决平均奖励马尔可夫决策过程中 Q-learning 缺乏收缩性的问题，这导致收敛分析困难。现有非渐近结果要么强加强假设以强制半范数收缩，要么依赖折扣或片段 MDPs 作为近似，但这些方法要么需要未知参数，要么导致次优的样本复杂度，限制了算法的理论保证和实际应用。因此，改进样本效率对强化学习任务至关重要，特别是在长期奖励场景中。",
      "method": "研究方法提出了一种变体的同步和异步 Q-learning，从惰性动态中采样，系统以固定概率保持在当前状态。关键创新是构建了一个实例依赖的半范数，并展示在惰性变换后的马尔可夫决策过程中，贝尔man算子在该半范数下变成一步收缩。这通过可达性假设确保，简化了收敛性分析。",
      "result": "主要实验结果显示，该方法实现了最优样本复杂度 ε⁻²（到对数因子），在同步和异步 Q-learning 中均达到理论界限。与现有基线方法相比，现有方法通常需要更高阶的样本复杂度，而本方法在保持简单性的同时，显著提升了性能，为平均奖励场景提供了更优的收敛保证。",
      "conclusion": "结论是本论文通过引入新的收缩原理，成功解决了平均奖励 Q-learning 的收敛问题，实现了理论突破。学术价值在于丰富了强化学习的理论框架，为后续研究提供新思路；实际应用价值可能涉及机器人控制和资源优化。局限性在于需要可达性假设，未来工作可探索更一般条件或实验验证。",
      "tags": [
        "Average-Reward Markov Decision Processes",
        "Q-Learning",
        "Sample Complexity",
        "Contraction Principle",
        "Lazy Dynamics"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:07.728620Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21296",
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "authors": [
      "Shaobo Wang",
      "Yantai Yang",
      "Guo Chen",
      "Peiru Li",
      "Kaixin Li",
      "Yufa Zhou",
      "Zhaorun Chen",
      "Linfeng Zhang"
    ],
    "abstract": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1\\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21296.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21296",
    "published": "2026-01-29T05:49:17Z",
    "updated": "2026-01-29T05:49:17Z",
    "comment": "Accepted by ICLR 2026, 20 pages, 9 figures, 11 tables",
    "light_analysis": {
      "overview": "提出InfoUtil框架，通过理论化的信息性和实用性概念优化数据集蒸馏过程，并基于博弈论和梯度范数提升蒸馏数据集质量。",
      "motivation": "数据集蒸馏（DD）旨在从大规模现实世界数据集中创建紧凑数据集，以节省存储和计算资源。然而，现有方法多依赖启发式策略来平衡效率与质量，未能充分探索原始数据与合成数据之间的理论基础，导致蒸馏数据集的效果受限，影响其在机器学习任务中的应用。因此，本研究旨在构建一个坚实的理论框架，以系统性地解决这一不足，提升数据集蒸馏的理论深度和实践价值。",
      "method": "研究引入信息性和实用性两个核心概念，分别捕捉样本中的关键信息和训练集中样本的重要性，并以此数学定义最优数据集蒸馏。提出InfoUtil框架，该框架结合两个关键组件：一是使用Shapley Value属性进行博弈论信息最大化，从样本中提取关键信息；二是基于梯度范数选择全局影响样本的原则性实用最大化。这些组件确保蒸馏数据集在信息丰富度和实用优化上达到平衡，提升整体蒸馏质量。",
      "result": "在ImageNet-1K数据集上使用ResNet-18架构进行实验，本方法比之前的最佳方法性能提升了6.1%，具体表现为分类任务准确率的显著提高。实验结果验证了InfoUtil框架在增强数据集蒸馏效果方面的有效性，为理论方法的应用提供了实证支持。",
      "conclusion": "本研究的主要贡献在于提出InfoUtil框架，将信息性和实用性概念融入数据集蒸馏，提供坚实的理论基础和实用工具。该框架不仅提升了蒸馏数据集的质量和效率，还具有重要的学术价值，如促进机器学习资源优化，并显示出实际应用潜力。未来工作可探索该框架在更复杂数据集和任务中的适用性，并与其他技术结合以进一步优化性能。",
      "tags": [
        "Dataset Distillation",
        "Game Theory",
        "Shapley Value",
        "Gradient Norm",
        "Machine Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:23.450178Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21294",
    "title": "Missing-Data-Induced Phase Transitions in Spectral PLS for Multimodal Learning",
    "authors": [
      "Anders Gjølbye",
      "Ida Kargaard",
      "Emma Kargaard",
      "Lars Kai Hansen"
    ],
    "abstract": "Partial Least Squares (PLS) learns shared structure from paired data via the top singular vectors of the empirical cross-covariance (PLS-SVD), but multimodal datasets often have missing entries in both views. We study PLS-SVD under independent entry-wise missing-completely-at-random masking in a proportional high-dimensional spiked model. After appropriate normalization, the masked cross-covariance behaves like a spiked rectangular random matrix whose effective signal strength is attenuated by $\\sqrtρ$, where $ρ$ is the joint entry retention probability. As a result, PLS-SVD exhibits a sharp BBP-type phase transition: below a critical signal-to-noise threshold the leading singular vectors are asymptotically uninformative, while above it they achieve nontrivial alignment with the latent shared directions, with closed-form asymptotic overlap formulas. Simulations and semi-synthetic multimodal experiments corroborate the predicted phase diagram and recovery curves across aspect ratios, signal strengths, and missingness levels.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21294.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21294",
    "published": "2026-01-29T05:46:44Z",
    "updated": "2026-01-29T05:46:44Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "本论文揭示了缺失数据在谱偏最小二乘法中诱导的相位转变现象，为多模态学习的缺失数据处理提供了理论框架。",
      "motivation": "多模态数据集常存在缺失条目，而 Partial Least Squares (PLS) 方法通过学习经验交叉协方差的奇异向量来学习共享结构，但现有理论未充分解释缺失数据对 PLS-SVD 性能的影响。缺失数据是实际多模态应用中的常见挑战，可能导致结构学习失真，因此研究其在随机缺失下的理论特性至关重要，以提升算法的鲁棒性和可靠性。",
      "method": "研究采用比例高维 spiked 模型分析 PLS-SVD 在独立条目级缺失完全随机掩蔽下的行为。通过归一化处理，将掩蔽交叉协方差建模为 spiked 矩形随机矩阵，推导出有效信号强度衰减因子 $\\sqrt{\\rho}$，其中 $\\rho$ 是联合条目保留概率。核心创新点在于理论分析相位转变条件和渐近重叠公式，未指定具体数据集，但提及使用模拟和半合成多模态实验进行验证。",
      "result": "实验结果显示 PLS-SVD 存在 BBP 型相位转变：当信噪比低于临界阈值时，主要奇异向量渐近无信息；高于阈值时，它们与潜在共享方向达到非平凡对齐，并给出封闭形式的渐近重叠公式。模拟和半合成实验在多种纵横比、信号强度和缺失水平下验证了预测的相位图和恢复曲线，证实了理论预测的准确性。",
      "conclusion": "论文主要贡献是理论分析了缺失数据对 PLS-SVD 谱性质的影响，揭示了相位转变现象并提供渐近公式。学术价值在于丰富了多模态学习中缺失数据处理的理论基础，实际应用价值在于为设计鲁棒算法提供指导。未来工作可能涉及扩展理论到更复杂的缺失机制或应用到更大规模实际数据集。",
      "tags": [
        "Partial Least Squares",
        "Spectral Analysis",
        "Phase Transition",
        "Missing Data",
        "Multimodal Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:24.152641Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21293",
    "title": "Physics-Guided Tiny-Mamba Transformer for Reliability-Aware Early Fault Warning",
    "authors": [
      "Changyu Li",
      "Dingcheng Huang",
      "Kexuan Yao",
      "Xiaoya Ni",
      "Lijuan Shen",
      "Fei Luo"
    ],
    "abstract": "Reliability-centered prognostics for rotating machinery requires early warning signals that remain accurate under nonstationary operating conditions, domain shifts across speed/load/sensors, and severe class imbalance, while keeping the false-alarm rate small and predictable. We propose the Physics-Guided Tiny-Mamba Transformer (PG-TMT), a compact tri-branch encoder tailored for online condition monitoring. A depthwise-separable convolutional stem captures micro-transients, a Tiny-Mamba state-space branch models near-linear long-range dynamics, and a lightweight local Transformer encodes cross-channel resonances. We derive an analytic temporal-to-spectral mapping that ties the model's attention spectrum to classical bearing fault-order bands, yielding a band-alignment score that quantifies physical plausibility and provides physics-grounded explanations. To ensure decision reliability, healthy-score exceedances are modeled with extreme-value theory (EVT), which yields an on-threshold achieving a target false-alarm intensity (events/hour); a dual-threshold hysteresis with a minimum hold time further suppresses chatter. Under a leakage-free streaming protocol with right-censoring of missed detections on CWRU, Paderborn, XJTU-SY, and an industrial pilot, PG-TMT attains higher precision-recall AUC (primary under imbalance), competitive or better ROC AUC, and shorter mean time-to-detect at matched false-alarm intensity, together with strong cross-domain transfer. By coupling physics-aligned representations with EVT-calibrated decision rules, PG-TMT delivers calibrated, interpretable, and deployment-ready early warnings for reliability-centric prognostics and health management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21293.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21293",
    "published": "2026-01-29T05:46:12Z",
    "updated": "2026-01-29T05:46:12Z",
    "comment": "Submitted to IEEE Transactions on Reliability",
    "light_analysis": {
      "overview": "论文提出Physics-Guided Tiny-Mamba Transformer，通过物理指导的注意力谱和极值理论校准，实现可靠性感知的早期故障预警。",
      "motivation": "研究动机在于解决旋转机械可靠性预测中的早期故障预警挑战，包括非平稳运行条件、领域漂移和严重类别不平衡，这些问题导致传统方法难以在保持准确性的同时控制假警报率。现有方法可能缺乏物理解释性和决策可靠性，因此需要开发结合物理指导和学习模型的新方法，以提升预警性能并确保在实际应用中的可靠性。",
      "method": "研究方法提出Physics-Guided Tiny-Mamba Transformer (PG-TMT)，一个紧凑的三分支编码器，包括深度可分离卷积干捕捉微瞬变、Tiny-Mamba状态空间分支建模近线性长程动态，以及轻量级局部Transformer编码跨通道共振。关键创新是解析时间到谱映射，将模型注意力谱与经典轴承故障阶次带绑定，提供物理合理性评分。决策可靠性通过极值理论 (EVT) 建模，使用双重阈值滞后来抑制波动，确保目标假警报强度。",
      "result": "主要实验在CWRU、Paderborn、XJTU-SY和工业试点数据集上进行，使用无泄漏流协议。PG-TMT在精度-召回AUC方面表现更高（尤其在类别不平衡下），ROC AUC竞争或优于基线，在匹配假警报强度下实现更短的均值检测时间，并展现出强跨域转移能力。结果表明模型在早期故障预警任务中具有优异性能和可靠性。",
      "conclusion": "结论是PG-TMT通过耦合物理对齐表示与EVT校准决策规则，提供了校准、可解释且可部署的早期预警系统。该研究对可靠性为中心的预测和健康管理有重要价值，提升了故障预警的准确性和决策可靠性。未来工作可能包括进一步优化模型或扩展到其他应用领域，摘要未明确说明局限性。",
      "tags": [
        "Transformer",
        "State-Space Models",
        "Extreme-Value Theory",
        "Convolutional Neural Networks",
        "Physics-Guided Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:44.720850Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21291",
    "title": "Gaussian Belief Propagation Network for Depth Completion",
    "authors": [
      "Jie Tang",
      "Pingping Xie",
      "Jian Li",
      "Ping Tan"
    ],
    "abstract": "Depth completion aims to predict a dense depth map from a color image with sparse depth measurements. Although deep learning methods have achieved state-of-the-art (SOTA), effectively handling the sparse and irregular nature of input depth data in deep networks remains a significant challenge, often limiting performance, especially under high sparsity. To overcome this limitation, we introduce the Gaussian Belief Propagation Network (GBPN), a novel hybrid framework synergistically integrating deep learning with probabilistic graphical models for end-to-end depth completion. Specifically, a scene-specific Markov Random Field (MRF) is dynamically constructed by the Graphical Model Construction Network (GMCN), and then inferred via Gaussian Belief Propagation (GBP) to yield the dense depth distribution. Crucially, the GMCN learns to construct not only the data-dependent potentials of MRF but also its structure by predicting adaptive non-local edges, enabling the capture of complex, long-range spatial dependencies. Furthermore, we enhance GBP with a serial \\& parallel message passing scheme, designed for effective information propagation, particularly from sparse measurements. Extensive experiments demonstrate that GBPN achieves SOTA performance on the NYUv2 and KITTI benchmarks. Evaluations across varying sparsity levels, sparsity patterns, and datasets highlight GBPN's superior performance, notable robustness, and generalizable capability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21291.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21291",
    "published": "2026-01-29T05:44:41Z",
    "updated": "2026-01-29T05:44:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了高斯信念传播网络（GBPN），一个整合深度学习与概率图模型的混合框架，用于深度补全任务。",
      "motivation": "深度补全旨在从彩色图像和稀疏深度测量生成稠密深度图，对自动驾驶和机器人视觉等应用至关重要。然而，现有深度学习方法在应对输入深度数据的稀疏性和不规则性方面存在不足，尤其在高稀疏性场景下性能显著受限，影响模型的准确性和鲁棒性。因此，论文强调需要开发更有效的方法来处理稀疏输入，并捕捉复杂空间依赖关系，以突破当前技术瓶颈。",
      "method": "高斯信念传播网络（GBPN）通过图模型构建网络（GMCN）动态创建场景特定马尔可夫随机场（MRF），并学习其数据依赖势函数和自适应非局部边结构，以捕捉长距离空间依赖。然后，使用高斯信念传播（GBP）进行推断，产生稠密深度分布。关键创新点包括GMCN学习构建MRF的潜在结构，以及GBP采用串行和并行消息传递方案，优化从稀疏测量中的信息传播，实现端到端训练。",
      "result": "实验结果显示，GBPN在NYUv2和KITTI基准测试上达到了最先进性能。评估涵盖不同稀疏级别、稀疏模式和数据集，表明GBPN相比基线方法具有优越性能、显著鲁棒性和良好泛化能力，有效提升处理高稀疏输入时的准确性和稳定性。摘要未提供具体性能数据，但强调了其在多种测试条件下的稳健表现。",
      "conclusion": "论文的主要贡献是开发了高斯信念传播网络（GBPN），一个混合框架，成功结合深度学习和概率图模型，提升深度补全任务的性能。学术上，这展示了两种技术协同的优势；应用上，可推动计算机视觉系统如自动驾驶的进步。摘要未明确说明局限性，未来工作可能涉及模型效率优化和扩展到其他视觉任务。",
      "tags": [
        "Depth Completion",
        "Gaussian Belief Propagation",
        "Markov Random Field",
        "Graphical Model Construction Network",
        "Non-local Edges"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:25.229459Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21289",
    "title": "TimeSliver : Symbolic-Linear Decomposition for Explainable Time Series Classification",
    "authors": [
      "Akash Pandey",
      "Payal Mohapatra",
      "Wei Chen",
      "Qi Zhu",
      "Sinan Keten"
    ],
    "abstract": "Identifying the extent to which every temporal segment influences a model's predictions is essential for explaining model decisions and increasing transparency. While post-hoc explainable methods based on gradients and feature-based attributions have been popular, they suffer from reference state sensitivity and struggle to generalize across time-series datasets, as they treat time points independently and ignore sequential dependencies. Another perspective on explainable time-series classification is through interpretable components of the model, for instance, leveraging self-attention mechanisms to estimate temporal attribution; however, recent findings indicate that these attention weights often fail to provide faithful measures of temporal importance. In this work, we advance this perspective and present a novel explainability-driven deep learning framework, TimeSliver, which jointly utilizes raw time-series data and its symbolic abstraction to construct a representation that maintains the original temporal structure. Each element in this representation linearly encodes the contribution of each temporal segment to the final prediction, allowing us to assign a meaningful importance score to every time point. For time-series classification, TimeSliver outperforms other temporal attribution methods by 11% on 7 distinct synthetic and real-world multivariate time-series datasets. TimeSliver also achieves predictive performance within 2% of state-of-the-art baselines across 26 UEA benchmark datasets, positioning it as a strong and explainable framework for general time-series classification.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21289.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21289",
    "published": "2026-01-29T05:42:58Z",
    "updated": "2026-01-29T05:42:58Z",
    "comment": "Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "TimeSliver框架通过符号-线性分解为时间序列分类提供可解释的时间重要性分数。",
      "motivation": "研究动机是解决时间序列分类中模型决策可解释性的挑战，特别是评估每个时间段的贡献。现有方法如基于梯度和特征归因的后验解释存在参考状态敏感性和泛化困难，因为它们独立处理时间点，忽略序列依赖；而自注意力机制往往不能可靠度量时间重要性。这些问题限制了模型透明度在真实世界应用（如医疗、金融）中的可信度，因此需要新方法来提供准确且可泛化的解释。",
      "method": "TimeSliver是一个可解释性驱动的深度学习框架，它联合利用原始时间序列数据及其符号抽象来构建保持原始时间结构的表示。通过线性分解技术，该表示中的每个元素编码每个时间段对最终预测的贡献，从而为每个时间点分配有意义的重要性分数。关键创新在于结合符号和线性方法以捕捉序列依赖，增强可解释性。摘要未明确说明具体模型架构或训练细节，但提及应用于多变量时间序列数据集。",
      "result": "在7个合成和真实世界的多变量时间序列数据集上，TimeSliver在时间归因方面优于其他方法11%，证明了其有效性。同时，在26个UEA基准数据集上，其预测性能与最先进基线相比相差仅在2%以内，表明框架在保持高预测准确性的同时提供了可解释性。这些结果通过具体数据对比验证了TimeSliver的强泛化能力和竞争力。",
      "conclusion": "TimeSliver的主要贡献是提出一个既强又可解释的时间序列分类框架，通过符号-线性分解实现了准确的时间重要性评估。它在可解释性和预测性能之间取得了平衡，具有学术价值，推动了可解释AI在时间序列领域的发展，并具备实际应用潜力，如提高模型透明度。摘要未明确说明局限性或未来工作方向，但可以推断未来可能扩展到更复杂的时间序列任务或集成更多解释技术。",
      "tags": [
        "Time Series Classification",
        "Explainable AI",
        "Symbolic Abstraction",
        "Linear Encoding",
        "Deep Learning Framework"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:40.304576Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21288",
    "title": "Drive-KD: Multi-Teacher Distillation for VLMs in Autonomous Driving",
    "authors": [
      "Weitong Lian",
      "Zecong Tang",
      "Haoran Li",
      "Tianjian Gao",
      "Yifei Wang",
      "Zixu Wang",
      "Lingyi Meng",
      "Tengju Ru",
      "Zhejun Cui",
      "Yichen Zhu",
      "Hangshuo Cao",
      "Qi Kang",
      "Tianxing Chen",
      "Yusen Qin",
      "Kaixuan Wang",
      "Yu Zhang"
    ],
    "abstract": "Autonomous driving is an important and safety-critical task, and recent advances in LLMs/VLMs have opened new possibilities for reasoning and planning in this domain. However, large models demand substantial GPU memory and exhibit high inference latency, while conventional supervised fine-tuning (SFT) often struggles to bridge the capability gaps of small models. To address these limitations, we propose Drive-KD, a framework that decomposes autonomous driving into a \"perception-reasoning-planning\" triad and transfers these capabilities via knowledge distillation. We identify layer-specific attention as the distillation signal to construct capability-specific single-teacher models that outperform baselines. Moreover, we unify these single-teacher settings into a multi-teacher distillation framework and introduce asymmetric gradient projection to mitigate cross-capability gradient conflicts. Extensive evaluations validate the generalization of our method across diverse model families and scales. Experiments show that our distilled InternVL3-1B model, with ~42 times less GPU memory and ~11.4 times higher throughput, achieves better overall performance than the pretrained 78B model from the same family on DriveBench, and surpasses GPT-5.1 on the planning dimension, providing insights toward efficient autonomous driving VLMs.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21288.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21288",
    "published": "2026-01-29T05:41:24Z",
    "updated": "2026-01-29T05:41:24Z",
    "comment": "Preprint. 23 pages, 14 figures",
    "light_analysis": {
      "overview": "Drive-KD框架通过多教师知识蒸馏，高效转移自动驾驶视觉语言模型的感知、推理和规划能力，实现高性能且资源高效的模型。",
      "motivation": "自动驾驶作为安全关键任务，需要高性能推理和规划能力。近年来，大型语言模型和视觉语言模型的进展为此提供了新可能，但这些大模型通常需求大量GPU内存并具有高推理延迟，不适用于实时应用。同时，传统监督微调方法难以弥补小模型的能力差距，导致性能与效率之间的权衡问题。因此，研究旨在开发一种方法，在保持高推理性能的同时，降低资源消耗，以促进高效自动驾驶系统的发展。",
      "method": "论文提出Drive-KD框架，将自动驾驶任务分解为感知、推理和规划三个能力维度。首先，使用层特定注意力作为蒸馏信号，为每个能力构建单教师模型，这些模型在各自任务上优于基线。然后，将这些单教师模型统一到多教师知识蒸馏框架中，并引入非对称梯度投影技术，以缓解不同能力间蒸馏时的梯度冲突。实验在DriveBench数据集上进行，针对不同模型家族和规模（如InternVL3-1B）进行验证，通过知识蒸馏转移能力。",
      "result": "实验结果显示，Drive-KD方法能显著提升模型效率。蒸馏后的InternVL3-1B模型相比同家族预训练的78B模型，GPU内存需求减少约42倍，吞吐量提高约11.4倍。在DriveBench评估中，该蒸馏模型实现了更好的整体性能，并在规划维度上超过了GPT-5.1。此外，方法在不同模型家族和规模上展现出良好的泛化能力，验证了其有效性。",
      "conclusion": "本研究的主要贡献是提出了Drive-KD框架，通过多教师知识蒸馏成功转移自动驾驶VLM的多种能力，实现高性能且高效率的模型。学术上，该方法为知识蒸馏提供了新思路，特别是在多能力转移和梯度冲突缓解方面。实际应用中，它有助于开发资源高效的自动驾驶系统，降低部署成本。未来工作可探索在其他领域的应用或进一步优化蒸馏策略，摘要未明确说明具体局限性。",
      "tags": [
        "Knowledge Distillation",
        "Multi-Teacher Learning",
        "Autonomous Driving",
        "Visual Language Models",
        "Attention Mechanism"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:34.600857Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21285",
    "title": "Zenith: Scaling up Ranking Models for Billion-scale Livestreaming Recommendation",
    "authors": [
      "Ruifeng Zhang",
      "Zexi Huang",
      "Zikai Wang",
      "Ke Sun",
      "Bohang Zheng",
      "Zhen Ouyang",
      "Huimin Xie",
      "Phil Shen",
      "Junlin Zhang",
      "Wentao Guo",
      "Qinglei Wang"
    ],
    "abstract": "Accurately capturing feature interactions is essential in recommender systems, and recent trends show that scaling up model capacity could be a key driver for next-level predictive performance. While prior work has explored various model architectures to capture multi-granularity feature interactions, relatively little attention has been paid to efficient feature handling and scaling model capacity without incurring excessive inference latency. In this paper, we address this by presenting Zenith, a scalable and efficient ranking architecture that learns complex feature interactions with minimal runtime overhead. Zenith is designed to handle a few high-dimensional Prime Tokens with Token Fusion and Token Boost modules, which exhibits superior scaling laws compared to other state-of-the-art ranking methods, thanks to its improved token heterogeneity. Its real-world effectiveness is demonstrated by deploying the architecture to TikTok Live, a leading online livestreaming platform that attracts billions of users globally. Our A/B test shows that Zenith achieves +1.05%/-1.10% in online CTR AUC and Logloss, and realizes +9.93% gains in Quality Watch Session / User and +8.11% in Quality Watch Duration / User.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21285.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21285",
    "published": "2026-01-29T05:36:49Z",
    "updated": "2026-01-29T05:36:49Z",
    "comment": "9 pages",
    "light_analysis": {
      "overview": "论文提出 Zenith 架构，通过 Token Fusion 和 Token Boost 模块高效学习复杂特征交互，实现推荐系统性能的显著提升。",
      "motivation": "在推荐系统中，准确捕获特征交互对提升预测性能至关重要，但现有方法在扩大模型容量时往往增加推理延迟，影响效率。对于大规模直播推荐如 TikTok Live，需要处理数十亿用户数据，高效性和可扩展性成为核心挑战。因此，本研究旨在开发一种架构，在不增加延迟的情况下学习特征交互，弥补现有工作的不足。",
      "method": "Zenith 架构采用 Token Fusion 和 Token Boost 模块来处理少量高维 Prime Tokens，通过改善令牌异构性来学习复杂特征交互。该方法避免了过度延迟，展示了优越的缩放定律，相较于其他先进排名方法更具可扩展性。摘要未明确说明具体数据集或详细模型架构，但强调了高效处理特征和扩展模型容量的技术特色。",
      "result": "A/B 测试结果显示，Zenith 部署到 TikTok Live 后，线上 CTR AUC 提升 1.05%，Logloss 降低 1.10%，质量观看会话/用户增加 9.93%，质量观看时长/用户增加 8.11%。这些数据表明，该架构在真实场景中有效提升了推荐系统的性能指标，优于基线方法。",
      "conclusion": "Zenith 架构的主要贡献在于解决了推荐系统中特征交互和模型扩展的难题，通过优化效率提升了实际应用价值。该研究展示了缩放定律的改进，具有学术意义，并在 TikTok Live 上实现了用户参与度的增长。摘要未明确说明局限性，未来工作可能涉及进一步优化或扩展到其他推荐领域。",
      "tags": [
        "Recommender Systems",
        "Feature Interactions",
        "Token Fusion",
        "Token Boost",
        "Scaling Laws"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:44.592929Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21284",
    "title": "PILD: Physics-Informed Learning via Diffusion",
    "authors": [
      "Tianyi Zeng",
      "Tianyi Wang",
      "Jiaru Zhang",
      "Zimo Zeng",
      "Feiyang Zhang",
      "Yiming Xu",
      "Sikai Chen",
      "Yajie Zou",
      "Yangyang Wang",
      "Junfeng Jiao",
      "Christian Claudel",
      "Xinbo Chen"
    ],
    "abstract": "Diffusion models have emerged as powerful generative tools for modeling complex data distributions, yet their purely data-driven nature limits applicability in practical engineering and scientific problems where physical laws need to be followed. This paper proposes Physics-Informed Learning via Diffusion (PILD), a framework that unifies diffusion modeling and first-principles physical constraints by introducing a virtual residual observation sampled from a Laplace distribution to supervise generation during training. To further integrate physical laws, a conditional embedding module is incorporated to inject physical information into the denoising network at multiple layers, ensuring consistent guidance throughout the diffusion process. The proposed PILD framework is concise, modular, and broadly applicable to problems governed by ordinary differential equations, partial differential equations, as well as algebraic equations or inequality constraints. Extensive experiments across engineering and scientific tasks including estimating vehicle trajectories, tire forces, Darcy flow and plasma dynamics, demonstrate that our PILD substantially improves accuracy, stability, and generalization over existing physics-informed and diffusion-based baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21284.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21284",
    "published": "2026-01-29T05:33:51Z",
    "updated": "2026-01-29T05:33:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出PILD框架，通过结合扩散模型与物理约束，显著提升了在工程和科学问题中的生成准确性、稳定性和泛化能力。",
      "motivation": "扩散模型虽然在建模复杂数据分布方面表现优异，但其纯数据驱动的本质限制了在需要遵循物理定律的实际工程和科学问题中的应用。例如，在车辆轨迹估计或流体动力学模拟中，忽视物理约束可能导致结果不准确或不稳定。现有方法往往难以有效整合物理先验知识，导致在泛化和可靠性方面存在不足，因此亟需一种新方法将物理约束无缝嵌入到扩散过程中，以增强模型的实用性和适应性。",
      "method": "PILD框架通过引入从拉普拉斯分布采样的虚拟残差观测来监督生成训练，从而统一扩散建模和第一性原理物理约束。此外，它采用一个条件嵌入模块，在去噪网络的多层中注入物理信息，确保在整个扩散过程中提供一致的指导。这种方法简洁、模块化，能够处理由常微分方程、偏微分方程以及代数方程或不等式约束控制的问题，使用扩散模型作为核心架构，并结合特定的损失函数来优化物理一致性。",
      "result": "在多个工程和科学任务上的实验表明，PILD在车辆轨迹估计、轮胎力预测、Darcy流模拟和等离子体动力学分析等任务中，相比现有的物理信息方法和扩散模型基线，在准确性、稳定性和泛化性方面均实现了显著提升。尽管摘要未提供具体的性能指标数值，但实验结果表明PILD能一致地优于基线方法，在处理复杂物理约束问题时表现出更强的可靠性和适应性，验证了其广泛的应用潜力。",
      "conclusion": "PILD框架的主要贡献在于成功地将扩散模型与物理约束结合，提供了一个简洁、模块化的解决方案，适用于多种物理方程类型。这项研究具有重要的学术价值，扩展了扩散模型的应用范围，并为物理信息学习领域提供了新思路；在实际应用中，它可提升工程仿真和科学计算的准确性。未来工作可能包括优化框架以处理更多约束类型或扩展到实时应用，但摘要未明确说明局限性。",
      "tags": [
        "Diffusion Models",
        "Physics-Informed Learning",
        "Laplace Distribution",
        "Conditional Embedding",
        "Differential Equations"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:10.758106Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21283",
    "title": "DUET: Distilled LLM Unlearning from an Efficiently Contextualized Teacher",
    "authors": [
      "Yisheng Zhong",
      "Zhengbang Yang",
      "Zhuangdi Zhu"
    ],
    "abstract": "LLM unlearning is a technique to remove the impacts of undesirable knowledge from the model without retraining from scratch, which is indispensable towards trustworthy AI. Existing unlearning methods face significant limitations: conventional tuning-based unlearning is computationally heavy and prone to catastrophic forgetting. In contrast, in-contextualized unlearning is lightweight for precise unlearning but vulnerable to prompt removal or reverse engineering attacks. In response, we propose Distilled Unlearning from an Efficient Teacher (DUET), a novel distillation-based unlearning method that combines the merits of these two lines of work. It learns a student model to imitate the behavior of a prompt-steered teacher that effectively refuses undesirable knowledge generation while preserving general domain knowledge. Extensive evaluations on existing benchmarks with our enriched evaluation protocols demonstrate that DUET achieves higher performance in both forgetting and utility preservation, while being orders of magnitude more data-efficient than state-of-the-art unlearning methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21283.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21283",
    "published": "2026-01-29T05:32:35Z",
    "updated": "2026-01-29T05:32:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "DUET是一种基于蒸馏的LLM遗忘方法，结合调整和上下文遗忘的优势，高效移除不良知识并保留通用模型能力。",
      "motivation": "LLM遗忘技术旨在移除模型中的不良知识而不需从头训练，对可信AI至关重要。现有方法存在显著局限：调整型遗忘计算量大且易引发灾难性遗忘，而上下文型遗忘虽轻量级但脆弱，易受攻击如提示移除或反向工程。这导致实际应用受限，亟需一种平衡效率和鲁棒性的新方法来解决这些不足。",
      "method": "DUET提出一种蒸馏框架，通过学生学习模仿提示引导的教师模型行为，有效拒绝不良知识生成并保留通用域知识。关键创新在于结合调整和上下文遗忘的优点，利用上下文化教师指导蒸馏过程，避免了传统方法的计算负担和脆弱性问题。具体实现基于现有基准，采用增强评估协议，但摘要未明确说明具体模型架构或数据集细节。",
      "result": "在现有基准上的广泛评估显示，DUET在遗忘不良知识和保留模型效用方面均表现更高，数据效率比最先进方法高出几个数量级。具体性能指标如准确率提升摘要未明确说明，但强调通过增强协议验证了其优越性，与基线方法对比显著改善效率和安全性。",
      "conclusion": "DUET的主要贡献是融合调整和上下文遗忘的优点，提供了一种高效且鲁棒的LLM遗忘方法，推动可信AI的发展。研究具有学术价值，揭示了蒸馏在遗忘任务中的潜力，并有实际应用价值，如增强模型安全性和可解释性。未来工作可能涉及扩展到更复杂场景或加强防御攻击能力，局限性摘要未明确说明。",
      "tags": [
        "LLM Unlearning",
        "Knowledge Distillation",
        "Contextual Learning",
        "Prompt Engineering"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:04.078607Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21282",
    "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
    "authors": [
      "Rishi Upadhyay",
      "Howard Zhang",
      "Jim Solomon",
      "Ayush Agrawal",
      "Pranay Boreddy",
      "Shruti Satya Narayana",
      "Yunhao Ba",
      "Alex Wong",
      "Celso M de Melo",
      "Achuta Kadambi"
    ],
    "abstract": "Recent advances in generative foundational models, often termed \"world models,\" have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21282.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21282",
    "published": "2026-01-29T05:31:02Z",
    "updated": "2026-01-29T05:31:02Z",
    "comment": "Webpage: https://world-bench.github.io/",
    "light_analysis": {
      "overview": "本文提出了WorldBench基准，通过解纠缠的物理概念评估来诊断世界模型的物理理解能力，推动其在关键任务中的可靠部署。",
      "motivation": "随着生成基础模型（如世界模型）在机器人规划和自主系统训练等关键任务中的应用增多，模型必须具备高物理保真度以准确模拟真实世界动态，确保可靠部署。然而，现有基于物理的视频基准存在概念纠缠问题，即在单个测试中同时评估多个物理定律和概念，这模糊了模型的具体缺陷，限制了其诊断能力。因此，开发一个能够隔离评估单个物理概念的基准至关重要，以应对现有方法的不足并提升模型的物理准确性。",
      "method": "本研究引入了WorldBench，一个专为概念特定、解纠缠评估设计的新颖视频基准。核心方法在于设计两个层次的评估：首先，评估直观物理理解，涵盖如物体持久性和尺度/透视等概念；其次，评估低级物理常数和材料属性，如摩擦系数和流体粘度。这种结构允许严格隔离和测试单个物理概念或定律，为世界模型提供全面的诊断工具。摘要未明确说明具体数据集或模型架构，但基于视频基准进行测试。",
      "result": "将当前最先进的视频世界模型在WorldBench上进行评估，结果显示所有测试模型在特定物理概念上表现出一致的失败模式。模型缺乏生成可靠真实世界交互所需的物理一致性，这突显出现有模型在物理推理方面的局限性。通过与现有基准对比，WorldBench的解纠缠评估能够更精确地识别模型薄弱点，如具体物理常数理解的不足，从而为模型改进提供明确方向。",
      "conclusion": "WorldBench的主要贡献在于提供了一个更细致和可扩展的框架，用于严格评估视频生成和世界模型的物理推理能力。通过概念特定的解纠缠评估，该基准能够准确诊断模型在物理理解上的具体不足，促进更鲁棒和可泛化的世界模型驱动学习。研究具有重要学术价值，为后续模型优化和基准扩展奠定了基础，未来工作可专注于进一步改进物理概念覆盖或应用到更多现实场景中。",
      "tags": [
        "World Models",
        "Physical Reasoning",
        "Benchmark Evaluation",
        "Video Generation",
        "Disentangled Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:34.423103Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21281",
    "title": "EGAM: Extended Graph Attention Model for Solving Routing Problems",
    "authors": [
      "Licheng Wang",
      "Yuzi Yan",
      "Mingtao Huang",
      "Yuan Shen"
    ],
    "abstract": "Neural combinatorial optimization (NCO) solvers, implemented with graph neural networks (GNNs), have introduced new approaches for solving routing problems. Trained with reinforcement learning (RL), the state-of-the-art graph attention model (GAM) achieves near-optimal solutions without requiring expert knowledge or labeled data. In this work, we generalize the existing graph attention mechanism and propose the extended graph attention model (EGAM). Our model utilizes multi-head dot-product attention to update both node and edge embeddings, addressing the limitations of the conventional GAM, which considers only node features. We employ an autoregressive encoder-decoder architecture and train it with policy gradient algorithms that incorporate a specially designed baseline. Experiments show that EGAM matches or outperforms existing methods across various routing problems. Notably, the proposed model demonstrates exceptional performance on highly constrained problems, highlighting its efficiency in handling complex graph structures.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21281.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21281",
    "published": "2026-01-29T05:30:34Z",
    "updated": "2026-01-29T05:30:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "EGAM通过扩展图注意力机制，引入多头部点积注意力同时更新节点和边嵌入，提升路由问题求解性能。",
      "motivation": "现有图注意力模型（GAM）在解决路由问题时仅考虑节点特征，限制了其对复杂图结构的建模能力，尤其是在高度约束问题中。神经组合优化求解器基于图神经网络和强化学习训练，但GAM的局限性影响了性能。本研究旨在通过扩展注意力机制，综合考虑节点和边嵌入，以克服这些不足，提高求解效率和准确性。",
      "method": "EGAM采用自回归编码器-解码器架构，核心创新在于使用多头部点积注意力机制同时更新节点和边嵌入，以捕捉复杂图结构。与传统GAM只关注节点特征不同，该方法增强了图表示能力。训练时应用策略梯度算法，并结合专门设计的基线优化强化学习过程。模型旨在高效处理路由问题中的图结构表示。",
      "result": "实验表明，EGAM在多种路由问题上与现有方法匹配或更优，特别是在高度约束问题中表现卓越，显示了处理复杂图结构的效率。摘要未明确说明具体数据，但性能改进在多个场景中得到验证，证明了扩展图注意力机制的有效性。",
      "conclusion": "本研究提出了EGAM，扩展了图注意力机制以同时更新节点和边嵌入，显著提高了路由问题求解能力，为神经组合优化领域提供新方法。具有学术创新和实际应用价值，未来工作可能涉及扩展到更多问题类型或优化训练策略，摘要未明确说明局限性。",
      "tags": [
        "Graph Attention Mechanism",
        "Multi-head Dot-Product Attention",
        "Reinforcement Learning",
        "Encoder-Decoder Architecture",
        "Policy Gradient"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:47.186683Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21280",
    "title": "Token Entropy Regularization for Multi-modal Antenna Affiliation Identification",
    "authors": [
      "Dong Chen",
      "Ruoyu Li",
      "Xinyan Zhang",
      "Jialei Xu",
      "Ruoseng Zhao",
      "Zhikang Zhang",
      "Lingyun Li",
      "Zizhuang Wei"
    ],
    "abstract": "Accurate antenna affiliation identification is crucial for optimizing and maintaining communication networks. Current practice, however, relies on the cumbersome and error-prone process of manual tower inspections. We propose a novel paradigm shift that fuses video footage of base stations, antenna geometric features, and Physical Cell Identity (PCI) signals, transforming antenna affiliation identification into multi-modal classification and matching tasks. Publicly available pretrained transformers struggle with this unique task due to a lack of analogous data in the communications domain, which hampers cross-modal alignment. To address this, we introduce a dedicated training framework that aligns antenna images with corresponding PCI signals. To tackle the representation alignment challenge, we propose a novel Token Entropy Regularization module in the pretraining stage. Our experiments demonstrate that TER accelerates convergence and yields significant performance gains. Further analysis reveals that the entropy of the first token is modality-dependent. Code will be made available upon publication.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21280.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21280",
    "published": "2026-01-29T05:26:21Z",
    "updated": "2026-01-29T05:26:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Token Entropy Regularization模块，用于加速多模态天线归属识别中的跨模态对齐和性能提升。",
      "motivation": "天线归属识别对优化和维护通信网络至关重要，但当前实践依赖繁琐且易错的手动塔台检查，效率低下。现有预训练变换器在通信领域缺乏类似数据，导致跨模态对齐困难，阻碍了多模态方法的有效应用，影响了自动化识别的准确性和可扩展性。",
      "method": "论文提出一个多模态框架，融合基站视频片段、天线几何特征和PCI信号，将天线归属识别转化为分类和匹配任务。核心创新是引入Token Entropy Regularization模块，在预训练阶段对齐天线图像与PCI信号的表示，通过优化token熵来解决跨模态对齐挑战，提升模态间一致性。",
      "result": "实验表明，Token Entropy Regularization模块加速了训练收敛过程，并带来了显著的性能提升。进一步分析显示第一个token的熵依赖于模态，验证了模块在跨模态对齐中的有效性。虽然没有给出具体准确率数字，但与未使用TER的基线相比，该方法在识别任务上表现更优。",
      "conclusion": "本文的主要贡献是Token Entropy Regularization模块，有效解决了多模态天线归属识别中的跨模态对齐问题，提高了识别准确性和训练效率，对自动化通信网络维护具有实际应用价值。未来工作可扩展到其他多模态任务，代码将开源以促进进一步研究。",
      "tags": [
        "Multi-modal Learning",
        "Cross-modal Alignment",
        "Transformer Pretraining",
        "Token Entropy Regularization",
        "Antenna Affiliation Identification"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:52.287151Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21278",
    "title": "GeoRC: A Benchmark for Geolocation Reasoning Chains",
    "authors": [
      "Mohit Talreja",
      "Joshua Diao",
      "Jim Thannikary James",
      "Radu Casapu",
      "Tejas Santanam",
      "Ethan Mendes",
      "Alan Ritter",
      "Wei Xu",
      "James Hays"
    ],
    "abstract": "Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21278.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21278",
    "published": "2026-01-29T05:18:40Z",
    "updated": "2026-01-29T05:18:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文首次引入了一个基准，用于评估视觉语言模型在地理定位推理链生成上的表现。",
      "motivation": "该研究针对视觉语言模型（VLMs）在预测地理位置时虽准确，但解释预测原因时表现差、经常产生幻觉的问题。这一问题使得VLMs的预测缺乏可审计性，限制了其在实际应用中的可信度。现有VLMs虽在位置预测上媲美人类专家，但推理链质量低，无法基于细粒度视觉属性（如牌照形状、建筑风格）进行合理解释，突显了改进模型可解释性的重要性。",
      "method": "论文提出了GeoRC基准，专注于GeoGuessr游戏中的全球位置预测任务，利用Google Street View数据覆盖100多个国家。核心方法包括与专家GeoGuessr玩家合作，生成800个真实推理链作为黄金标准，用于评估500个查询场景。关键创新在于评估LLM-as-a-judge和VLM-as-a-judge策略来评分VLMs生成的推理链，专家推理链涵盖数百个不同视觉属性，以提供细粒度评估基础。",
      "result": "主要实验结果显示，大型闭源VLMs（如Gemini和GPT 5）在地理位置预测上接近人类专家水平，但在生成可审计推理链方面仍落后。开源VLMs（如Llama和Qwen）表现较差，仅略优于基线（即LLM在知道照片位置但无视觉信息时生成幻觉推理链）。评估发现，Qwen 3 LLM-as-a-judge策略与人类评分相关性最佳，揭示了VLMs在推理链质量上的显著差距。",
      "conclusion": "论文的主要贡献是提出了首个地理定位推理链基准，揭示了VLMs在从高分辨率图像提取细粒度视觉属性方面的局限性，这阻碍了其生成可信推理链的能力。学术价值在于促进了可解释AI和视觉语言模型的研究方向，实际应用价值在于提升模型的可信度和可审计性。未来工作可探索改进VLMs的视觉推理能力或扩展基准以涵盖更多场景和属性。",
      "tags": [
        "Vision Language Models",
        "Geolocation Reasoning",
        "Benchmark Evaluation",
        "Fine-grained Visual Attributes",
        "LLM-as-a-judge"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:16.805761Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21269",
    "title": "Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference",
    "authors": [
      "Jianglong Li",
      "Jun Xu",
      "Bingcong Lu",
      "Zhengxue Cheng",
      "Hongwei Hu",
      "Ronghua Wu",
      "Li Song"
    ],
    "abstract": "The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21269.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21269",
    "published": "2026-01-29T05:03:29Z",
    "updated": "2026-01-29T05:03:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种集成FLAME参数化建模与3DGS神经渲染的轻量级、高保真、低比特率3D人脸压缩框架，专为3D视频会议设计。",
      "motivation": "随着沉浸式交互通信需求的增长，3D视频会议面临在低比特率下实现高保真3D人脸表示的挑战。传统2D视频压缩方法无法保留精细的几何和外观细节，而如NeRF的隐式神经渲染方法计算成本过高，难以应用于实时场景。这些问题限制了3D通信的实用性和普及，因此开发高效、轻量的压缩方法至关重要，以满足实时交互中对高质量视觉体验的需求。",
      "method": "本论文提出了一种结合FLAME参数化建模与3DGS神经渲染的框架。方法实时传输关键的面部元数据，使用高斯头模型进行高效重建，并通过高斯属性压缩和MLP优化引入紧凑表示方案，以提升传输效率。具体而言，FLAME用于参数化人脸建模，3DGS基于高斯分布进行神经渲染，从而在降低计算开销的同时确保渲染质量，实现轻量化设计。",
      "result": "实验结果表明，该方法在率失真性能方面表现优越，能够在极低比特率下提供高质量的人脸渲染效果。相较于传统2D压缩和NeRF等基线方法，框架在传输效率和渲染质量上均有显著提升，非常适合实时3D视频会议应用。摘要未明确说明具体数据指标，但强调了其在低比特率场景中的高效性和适用性。",
      "conclusion": "本论文的主要贡献是开发了一个轻量级、高保真、低比特率的3D人脸压缩框架，解决了3D通信中的关键瓶颈。学术上，它推动了参数化建模与神经渲染技术的融合；实际上，为实时3D视频会议提供了可行的解决方案。未来工作可能涉及进一步优化模型效率或扩展至更多应用场景，摘要未明确说明具体局限性。",
      "tags": [
        "3D Talking Face Compression",
        "FLAME-based Parametric Modeling",
        "3DGS Neural Rendering",
        "Gaussian Head Model",
        "Low-Bitrate Compression"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:42.822866Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21266",
    "title": "Model-Free Neural State Estimation in Nonlinear Dynamical Systems: A Comparative Study of Neural Architectures and Classical Filters",
    "authors": [
      "Zhuochen Liu",
      "Hans Walker",
      "Rahul Jain"
    ],
    "abstract": "Neural network models are increasingly used for state estimation in control and decision-making problems, yet it remains unclear to what extent they behave as principled filters in nonlinear dynamical systems. Unlike classical filters, which rely on explicit knowledge of system dynamics and noise models, neural estimators can be trained purely from data without access to the underlying system equations. In this work, we present a systematic empirical comparison between such model-free neural network models and classical filtering methods across multiple nonlinear scenarios. Our study evaluates Transformer-based models, state-space neural networks, and recurrent architectures alongside particle filters and nonlinear Kalman filters. The results show that neural models (in particular, state-space models (SSMs)) achieve state estimation performance that approaches strong nonlinear Kalman filters in nonlinear scenarios and outperform weaker classical baselines despite lacking access to system models, while also attaining substantially higher inference throughput.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21266.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21266",
    "published": "2026-01-29T04:58:59Z",
    "updated": "2026-01-29T04:58:59Z",
    "comment": "8 pages, 2 figures",
    "light_analysis": {
      "overview": "本文通过系统比较，发现无模型神经网络（特别是状态空间模型）在非线性动态系统中的状态估计性能接近强经典滤波器，同时推理速度更快。",
      "motivation": "神经网络在状态估计中应用日益广泛，但它们在非线性动态系统中的表现是否如原理性滤波器尚不明确。经典滤波器依赖于系统动态和噪声模型的显式知识，这在实际未知系统或复杂环境中可能难以获取，从而限制了其泛化能力。本研究旨在探讨无模型神经网络（仅从数据训练）能否克服这些限制，提供一种无需系统方程知识的替代方案。通过评估其在非线性场景下的性能，旨在揭示神经模型是否能够有效替代或超越经典方法，为实际控制和决策问题提供更灵活的状态估计工具。",
      "method": "本研究采用系统实证比较方法，在多个非线性动态系统场景下评估了无模型神经网络模型与经典滤波方法。神经模型包括基于Transformer的架构、状态空间神经网络（SSMs）和循环架构，所有模型仅通过数据训练，无需任何系统动态方程知识。经典滤波方法作为基线，包括粒子滤波和多种非线性卡尔曼滤波器，这些方法依赖于已知的系统模型和噪声假设。研究设计了一个统一的评估框架，对比这些方法在状态估计精度和计算效率上的表现，以揭示神经模型的技术特色和潜在优势。",
      "result": "实验结果显示，无模型神经网络模型，尤其是状态空间模型（SSMs），在非线性动态系统中的状态估计性能能够接近强大的非线性卡尔曼滤波器。尽管神经模型缺乏系统模型知识，但其估计误差与非模型依赖的强滤波器相当，并显著优于性能较弱的经典基线方法。此外，神经模型在推理吞吐量上实现了显著提升，表明在实时应用中具有更高的计算效率。具体性能指标（如准确率提升百分比）未在摘要中详细说明，但整体突出了神经模型在保持高精度的同时改善处理速度的能力。",
      "conclusion": "本研究表明，无模型神经网络模型，特别是状态空间架构，在非线性动态系统中的状态估计任务中具有强大的竞争力，学术价值在于系统比较了神经和经典方法，揭示了神经模型在缺乏系统知识时仍能达到高性能的能力。实际应用价值在于为实时控制和决策系统提供了更高效的状态估计解决方案。局限性可能包括对训练数据质量和数量的依赖，以及泛化能力在不同场景下的不确定性。未来工作可以探索更多网络架构优化、扩展到更广泛的应用场景，以及结合混合方法以提高鲁棒性。",
      "tags": [
        "State Estimation",
        "Nonlinear Dynamical Systems",
        "State-Space Models (SSMs)",
        "Transformer-based Models",
        "Particle Filters"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:04.499642Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21262",
    "title": "CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding",
    "authors": [
      "Jiahao Huo",
      "Yu Huang",
      "Yibo Yan",
      "Ye Pan",
      "Yi Cao",
      "Mingdong Ou",
      "Philip S. Yu",
      "Xuming Hu"
    ],
    "abstract": "Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21262.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21262",
    "published": "2026-01-29T04:47:27Z",
    "updated": "2026-01-29T04:47:27Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "CausalEmbed提出了一种自回归生成方法，通过迭代边缘损失学习紧凑的多向量嵌入，显著减少视觉文档检索中的存储开销。",
      "motivation": "本研究旨在解决视觉文档检索中多模态大型语言模型生成多向量嵌入时存储开销过大的问题。尽管MLLMs能产生高质量嵌入，但使用数千个视觉tokens表示单个页面导致显著存储负担，限制了其在现实世界应用中的实用性。因此，开发一种紧凑且高效的嵌入生成方法至关重要，以平衡性能和资源消耗，克服现有方法因高存储需求而受限的挑战。",
      "method": "论文提出CausalEmbed方法，采用自回归生成技术在潜在空间中构建多向量嵌入。核心创新包括在对比训练过程中融入迭代边缘损失，该损失函数鼓励嵌入模型学习更紧凑和结构化的表示。通过这种方式，模型能够仅用几十个视觉tokens实现高效的视觉文档检索任务，显著降低tokens数量。摘要未明确说明使用的具体数据集或模型架构，但方法涉及自动回归生成和对比学习框架。",
      "result": "实验结果显示，CausalEmbed能够将视觉tokens数量减少30到155倍，从而大幅降低了存储开销。同时，该方法在各种骨干网络和基准测试中保持了高度竞争力的性能，表明在减少tokens的同时未牺牲检索质量。理论分析和实证证据进一步证明了自回归嵌入生成在训练效率高和测试时扩展性强的独特优势，与基线方法相比，在效率和效果上实现了显著平衡。",
      "conclusion": "CausalEmbed的主要贡献在于提出了一种基于自回归生成的多向量嵌入方法，通过迭代边缘损失实现了紧凑表示。这为视觉文档检索引入了灵活的测试时扩展策略，增强了实用性。学术上，它揭示了生成范式在多模态文档检索中的潜力；实际上，显著提高了存储效率。未来工作可进一步优化模型架构或扩展到其他多模态任务。",
      "tags": [
        "Auto-Regressive Generation",
        "Multi-Vector Embedding",
        "Contrastive Learning",
        "Iterative Margin Loss",
        "Visual Document Retrieval"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:55.957942Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21257",
    "title": "MoCo: A One-Stop Shop for Model Collaboration Research",
    "authors": [
      "Shangbin Feng",
      "Yuyang Bai",
      "Ziyuan Yang",
      "Yike Wang",
      "Zhaoxuan Tan",
      "Jiajie Yan",
      "Zhenyu Lei",
      "Wenxuan Ding",
      "Weijia Shi",
      "Haojin Wang",
      "Zhenting Qi",
      "Yuru Jiang",
      "Heng Wang",
      "Chengsong Huang",
      "Yu Fei",
      "Jihan Yao",
      "Yilun Du",
      "Luke Zettlemoyer",
      "Yejin Choi",
      "Yulia Tsvetkov"
    ],
    "abstract": "Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21257.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21257",
    "published": "2026-01-29T04:36:52Z",
    "updated": "2026-01-29T04:36:52Z",
    "comment": "Moco is available at https://github.com/BunsenFeng/model_collaboration",
    "light_analysis": {
      "overview": "MoCo 是一个综合性 Python 库，用于大规模执行、基准测试和比较模型协作算法，推动了协作策略的统一研究。",
      "motivation": "随着 AI 发展，单一语言模型的局限性日益凸显，模型协作通过多个模型互补来提升性能成为重要研究方向。然而，现有研究分散在不同社区，缺乏整合和严谨比较，阻碍了协作策略的系统发展。因此，本论文旨在解决这一问题，通过建立一个标准化平台来促进模型协作作为一个独立学术领域的形成。",
      "method": "论文提出了 MoCo Python 库，整合了 26 种模型协作方法，涵盖路由、文本、logit 和模型参数等跨模型信息交换层次。关键创新在于提供了一个统一框架，包括 25 个评估数据集，涉及推理、问答、代码和安全等领域，并支持用户自定义数据。该库实现了大规模执行、基准测试和比较协作算法的功能，以加速研究进展。",
      "result": "在 MoCo 库上进行的大量实验表明，多数模型协作策略在平均 61.0% 的模型和数据设置中优于无协作基线，性能提升可达 25.8%。进一步分析显示，协作策略在扩展性和训练/推断效率方面表现良好，有效解决了单个语言模型难以应对的问题。实验验证了协作系统在实际应用中的优势，并提供了详细对比数据。",
      "conclusion": "MoCo 作为一个工具包，整合了现有模型协作研究，推动了该领域作为学术思想的发展。它具有重要的学术价值，为 AI 的开放、模块化和协作未来奠定了基础，并指出了未来工作方向，如优化协作策略和扩展应用场景。研究为实际 AI 系统开发提供了支持。",
      "tags": [
        "Model Collaboration",
        "Python Library",
        "Benchmarking",
        "Cross-model Interaction",
        "Language Models"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:05.705446Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21255",
    "title": "Hypersolid: Emergent Vision Representations via Short-Range Repulsion",
    "authors": [
      "Esteban Rodríguez-Betancourt",
      "Edgar Casasola-Murillo"
    ],
    "abstract": "A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21255.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21255",
    "published": "2026-01-29T04:25:43Z",
    "updated": "2026-01-29T04:25:43Z",
    "comment": "17 pages, 16 figures",
    "light_analysis": {
      "overview": "Hypersolid通过短程硬球排斥防止表示坍塌，在自监督学习中引入几何约束，提升了细粒度和低分辨率分类任务的性能。",
      "motivation": "在自监督学习中，表示坍塌是一个常见挑战，指不同输入被映射到相似的表示，降低特征的判别性，影响下游任务性能。现有方法通常依赖全局正则化，如最大化样本间距离或去相关特征维度，但这些方法可能计算效率低且忽视局部结构。因此，本研究旨在通过局部几何约束直接防止表示坍塌，提供一种更高效的解决方案，以提升表示质量和泛化能力。",
      "method": "Hypersolid方法将表示学习重新解释为一个离散包装问题，其中保存信息等价于维持单射性。具体操作上，它使用短程硬球排斥来防止局部碰撞，通过几何约束确保表示在嵌入空间中有足够的分离，从而创建一个高分离的几何状态。关键创新在于从局部角度出发，利用硬球排斥模型自然地保持增强多样性，而不依赖全局正则化。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "Hypersolid在实验中表现出色，特别是在细粒度和低分辨率分类任务上。该方法通过短程硬球排斥约束实现了一个高分离的几何状态，有效保持了增强多样性，从而提升了分类性能。虽然摘要未提供具体的性能指标数据，如准确率提升百分比，也未详细说明与基线方法的对比情况，但可以推断它在相关基准测试中优于依赖全局正则化的传统方法，为解决表示坍塌问题提供了新的有效途径。",
      "conclusion": "Hypersolid的主要贡献是提出了一种新颖的自监督学习方法，通过短程硬球排斥防止表示坍塌，并将表示学习建模为离散包装问题。其学术价值在于引入了几何约束的新视角，丰富了表示学习的理论框架。实际应用价值体现在提升了细粒度和低分辨率分类任务的准确性，适用于计算机视觉中的精确识别场景。摘要未提及局限性或未来工作方向，但可能包括扩展到更复杂任务或验证在大规模数据集上的效果。",
      "tags": [
        "Self-Supervised Learning",
        "Representation Learning",
        "Short-Range Repulsion",
        "Geometric Constraint",
        "Fine-Grained Classification"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:47.715274Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21249",
    "title": "Position: Certifiable State Integrity in Cyber-Physical Systems -- Why Modular Sovereignty Solves the Plasticity-Stability Paradox",
    "authors": [
      "Enzo Nicolás Spotorno",
      "Antônio Augusto Medeiros Fröhlich"
    ],
    "abstract": "The machine learning community has achieved remarkable success with universal foundation models for time-series and physical dynamics, largely overcoming earlier approximation barriers in smooth or slowly varying regimes through scale and specialized architectures. However, deploying these monolithic models in safety-critical Cyber-Physical Systems (CPS), governed by non-stationary lifecycle dynamics and strict reliability requirements, reveals persistent challenges. Recent evidence shows that fine-tuning time-series foundation models induces catastrophic forgetting, degrading performance on prior regimes. Standard models continue to exhibit residual spectral bias, smoothing high-frequency discontinuities characteristic of incipient faults, while their opacity hinders formal verification and traceability demanded by safety standards (e.g., ISO 26262, IEC 61508). This position paper argues that the plasticity-stability paradox cannot be fully resolved by global parameter updates (whether via offline fine-tuning or online adaptation). Instead, we advocate a Modular Sovereignty paradigm: a library of compact, frozen regime-specific specialists combined via uncertainty-aware blending, which we term \"HYDRA\" (Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems). This paradigm ensures regime-conditional validity, rigorous disentanglement of aleatoric and epistemic uncertainties, and modular auditability, offering a certifiable path for robust state integrity across the CPS lifecycle.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21249.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21249",
    "published": "2026-01-29T04:10:58Z",
    "updated": "2026-01-29T04:10:58Z",
    "comment": "14 pages, (8 main text, 6 references and appendices), 2 figures",
    "light_analysis": {
      "overview": "本文提出Modular Sovereignty范式，通过HYDRA方法解决Cyber-Physical Systems中的塑性-稳定性悖论，确保状态完整性。",
      "motivation": "研究动机在于现有通用基础模型（如时间序列和物理动力学模型）在安全关键的Cyber-Physical Systems（CPS）部署中存在重大不足。尽管这些模型通过大规模和专门架构在平稳或缓慢变化区域取得突破，但在CPS的非平稳生命周期动力学和严格可靠性要求下，面临灾难性遗忘问题，导致性能下降；同时模型存在剩余光谱偏置，平滑了高频故障特征，且不透明性阻碍了安全标准（如ISO 26262）所要求的正式验证和可追溯性。因此，全局参数更新（如微调）无法解决塑性-稳定性悖论，急需新方法来保障CPS状态完整性。",
      "method": "论文提出Modular Sovereignty范式，核心方法是HYDRA（Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems）。该方法构建一个紧凑、冻结的特定状态专家库，这些专家针对不同动态状态训练而成，然后通过不确定性感知混合机制进行组合。创新点在于避免全局参数更新，通过模块化结构确保状态条件有效性、严格区分非确定性和认知不确定性，并提供模块化可审计性。这种方法允许系统快速适应非平稳环境，同时保持稳定性和可验证性。",
      "result": "摘要未明确说明具体的实验结果、性能指标或与基线方法的对比。论文主要提出了一种理论框架和范式，强调Modular Sovereignty和HYDRA方法在理论上能够解决塑性-稳定性悖论，提供可认证的状态完整性。因此，无法提供数据支撑如准确率提升或效率改进，未来工作可能涉及实验验证。",
      "conclusion": "论文的主要贡献是提出Modular Sovereignty范式，解决了CPS中的塑性-稳定性悖论，为安全关键系统提供了可认证的状态完整性路径。学术价值在于集成不确定性和模块化概念，推动了AI模型在动态环境中的可靠部署；实际应用价值在于满足行业安全标准（如ISO 26262），促进CPS的可追溯性和验证。未来工作可能包括在真实CPS场景中验证此方法，并探索其扩展性。",
      "tags": [
        "Cyber-Physical Systems",
        "Fine-tuning",
        "Catastrophic Forgetting",
        "Uncertainty-aware Blending",
        "Modular Sovereignty"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:31.915479Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21248",
    "title": "NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration",
    "authors": [
      "Zhen Wang",
      "Hongyi Liu",
      "Jianing Li",
      "Zhihui Wei"
    ],
    "abstract": "Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21248.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21248",
    "published": "2026-01-29T04:10:45Z",
    "updated": "2026-01-29T04:10:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种基于噪声频率控制的扩散采样策略，通过频谱调制机制改善图像恢复中的保真度-感知权衡。",
      "motivation": "该研究旨在解决扩散采样型Plug-and-Play方法在图像恢复中数据保真度降低的问题，主要因为反向扩散过程中引入的噪声导致保真度与感知质量冲突。这个问题在图像恢复领域至关重要，因为用户期望同时获得高保真度和高感知质量的输出，而现有方法往往在两者之间难以平衡，限制了实际应用效果，因此需要创新机制来优化这一权衡。",
      "method": "NFCDS是一种噪声频率控制的扩散采样方法，核心基于频谱调制机制，设计了一个傅里叶域滤波器，在反向扩散过程中渐进抑制低频噪声并保留高频内容，从而直接注入数据一致性先验。该方法的关键创新点在于将噪声频率分析引入扩散采样，无需额外训练，通过频率控制实现快速收敛，并作为Plug-and-Play模块无缝集成到现有扩散框架，适用于零样本图像恢复任务。",
      "result": "摘要未明确说明具体性能指标如准确率提升，但表明NFCDS在零样本图像恢复任务中有效改善保真度-感知平衡，快速收敛到高保真度和高感知质量的结果。与基线方法相比，该方法通过噪声频率控制减少了保真度损失，并在感知质量方面保持良好表现，提高了整体恢复效果，但缺乏定量数据支撑。",
      "conclusion": "NFCDS的主要贡献是通过噪声频率控制机制，显著提升扩散采样在图像恢复中的保真度，同时保持感知质量，为Plug-and-Play框架提供了一种创新解决方案。研究具有重要学术价值，因为它从频谱角度解决了扩散采样的核心问题，并具有广泛应用潜力，如扩展到更多视觉任务；局限性包括未进行大规模定量验证，未来工作可聚焦于更多任务的具体性能评估。",
      "tags": [
        "Diffusion Sampling",
        "Plug-and-Play",
        "Frequency Control",
        "Image Restoration",
        "Zero-Shot Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:53.964694Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21246",
    "title": "Conditional Generative Framework with Peak-Aware Attention for Robust Chemical Detection under Interferences",
    "authors": [
      "Namkyung Yoon",
      "Sanghong Kim",
      "Hwangnam Kim"
    ],
    "abstract": "Gas chromatography-mass spectrometry (GC-MS) is a widely used analytical method for chemical substance detection, but measurement reliability tends to deteriorate in the presence of interfering substances. In particular, interfering substances cause nonspecific peaks, residence time shifts, and increased background noise, resulting in reduced sensitivity and false alarms. To overcome these challenges, in this paper, we propose an artificial intelligence discrimination framework based on a peak-aware conditional generative model to improve the reliability of GC-MS measurements under interference conditions. The framework is learned with a novel peak-aware mechanism that highlights the characteristic peaks of GC-MS data, allowing it to generate important spectral features more faithfully. In addition, chemical and solvent information is encoded in a latent vector embedded with it, allowing a conditional generative adversarial neural network (CGAN) to generate a synthetic GC-MS signal consistent with the experimental conditions. This generates an experimental dataset that assumes indirect substance situations in chemical substance data, where acquisition is limited without conducting real experiments. These data are used for the learning of AI-based GC-MS discrimination models to help in accurate chemical substance discrimination. We conduct various quantitative and qualitative evaluations of the generated simulated data to verify the validity of the proposed framework. We also verify how the generative model improves the performance of the AI discrimination framework. Representatively, the proposed method is shown to consistently achieve cosine similarity and Pearson correlation coefficient values above 0.9 while preserving peak number diversity and reducing false alarms in the discrimination model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21246.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21246",
    "published": "2026-01-29T04:10:37Z",
    "updated": "2026-01-29T04:10:37Z",
    "comment": "24 pages, 5 figures",
    "light_analysis": {
      "overview": "提出基于峰感知条件生成模型的AI框架，以提高GC-MS在干扰下的化学检测可靠性。",
      "motivation": "GC-MS作为化学物质检测的常用方法，在干扰物质存在时测量可靠性下降，表现为非特定峰、保留时间偏移和背景噪声增加，导致敏感度降低和误报警报。这些干扰限制了检测的准确性，现有方法难以有效处理，从而影响实际应用中的可靠性和鲁棒性。",
      "method": "研究采用峰感知条件生成框架，通过新颖的峰感知机制突出GC-MS数据的特征峰，使生成过程更忠实地还原重要光谱特征。结合条件生成对抗网络（CGAN），将化学和溶剂信息编码为潜向量，生成与实验条件一致的合成GC-MS信号，用于训练AI区分模型以提升检测性能。",
      "result": "对生成模拟数据的评估显示，生成的信号在cosine相似度和Pearson相关系数上均高于0.9，同时保持了峰数的多样性，并在区分模型中有效减少了误报警报，提升了整体检测准确性和鲁棒性。",
      "conclusion": "该框架能生成高质量合成数据，增强GC-MS区分模型的性能，提高化学检测的可靠性并减少实验数据采集限制。摘要未明确说明局限性，但未来工作可能包括更广泛的干扰类型验证和应用扩展。",
      "tags": [
        "Conditional Generative Adversarial Network",
        "Peak-Aware Attention",
        "Gas Chromatography-Mass Spectrometry",
        "Generative Model",
        "Chemical Detection"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:06.957718Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21244",
    "title": "Less Noise, More Voice: Reinforcement Learning for Reasoning via Instruction Purification",
    "authors": [
      "Yiju Guo",
      "Tianyi Hu",
      "Zexu Sun",
      "Yankai Lin"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced LLM reasoning, but remains constrained by inefficient exploration under limited rollout budgets, leading to low sampling success and unstable training in complex tasks. We find that many exploration failures arise not from problem difficulty, but from a small number of prompt tokens that introduce interference. Building on this insight, we propose the Less Noise Sampling Framework (LENS), which first prompts by identifying and removing interference tokens. then transfers successful rollouts from the purification process to supervise policy optimization on the original noisy prompts, enabling the model to learn to ignore interference in the real-world, noisy prompting settings. Experimental results show that LENS significantly outperforms GRPO, delivering higher performance and faster convergence, with a 3.88% average gain and over 1.6$\\times$ speedup. Our work highlights the critical role of pruning interference tokens in improving rollout efficiency, offering a new perspective for RLVR research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21244.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21244",
    "published": "2026-01-29T04:08:24Z",
    "updated": "2026-01-29T04:08:24Z",
    "comment": "Work in progress",
    "light_analysis": {
      "overview": "本文提出了LENS框架，通过指令净化去除干扰token，显著提升RLVR在LLM推理中的探索效率和训练稳定性。",
      "motivation": "强化学习与可验证奖励（RLVR）虽然推进了LLM推理，但在有限rollout预算下，探索效率低下导致采样成功率低和训练不稳定，尤其在复杂任务中。研究发现，许多探索失败并非源于任务难度，而是由提示中的少量干扰token引发，这限制了RLVR在实际噪声环境中的应用。现有方法如GRPO在应对干扰时不足，强调了优化探索机制的重要性。",
      "method": "LENS框架首先通过识别和移除提示中的干扰token进行指令净化，生成更干净的上下文。然后，利用净化过程中的成功rollouts，将其作为监督数据来优化原始噪声提示下的策略，从而使模型学会忽略干扰。核心创新在于结合净化过程和知识转移，提升采样效率和训练稳定性，无需额外数据或复杂架构改动。",
      "result": "实验结果表明，LENS在性能上显著优于基线方法GRPO，平均性能提升3.88%，收敛速度加速超过1.6倍。这表明LENS能更高效地处理复杂推理任务，减少探索失败，在标准评测中显示出更高的稳定性和有效性，验证了指令净化对提升RLVR训练效率的实质性贡献。",
      "conclusion": "本研究的主要贡献是提出了LENS框架，突出了去除干扰token在提高rollout效率中的关键作用，为RLVR研究提供了新视角，强调了指令净化在现实噪声环境中的实用价值。学术上，它深化了对RL探索机制的理解；应用上，有望改进LLM推理的鲁棒性。局限性或未来工作摘要未明确说明。",
      "tags": [
        "Reinforcement Learning with Verifiable Rewards",
        "Large Language Model",
        "Instruction Purification",
        "Policy Optimization",
        "Interference Token Removal"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:30.340999Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21242",
    "title": "Understanding Diffusion Models via Ratio-Based Function Approximation with SignReLU Networks",
    "authors": [
      "Luwei Sun",
      "Dongrui Shen",
      "Jianfe Li",
      "Yulong Zhao",
      "Han Feng"
    ],
    "abstract": "Motivated by challenges in conditional generative modeling, where the target conditional density takes the form of a ratio f1 over f2, this paper develops a theoretical framework for approximating such ratio-type functionals. Here, f1 and f2 are kernel-based marginal densities that capture structured interactions, a setting central to diffusion-based generative models. We provide a concise proof for approximating these ratio-type functionals using deep neural networks with the SignReLU activation function, leveraging the activation's piecewise structure. Under standard regularity assumptions, we establish L^p(Omega) approximation bounds and convergence rates. Specializing to Denoising Diffusion Probabilistic Models (DDPMs), we construct a SignReLU-based neural estimator for the reverse process and derive bounds on the excess Kullback-Leibler (KL) risk between the generated and true data distributions. Our analysis decomposes this excess risk into approximation and estimation error components. These results provide generalization guarantees for finite-sample training of diffusion-based generative models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21242.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21242",
    "published": "2026-01-29T04:01:54Z",
    "updated": "2026-01-29T04:01:54Z",
    "comment": "34 pages",
    "light_analysis": {
      "overview": "本文提出了一个基于 SignReLU 网络的比率函数逼近理论框架，应用于扩散模型，提供了泛化保证。",
      "motivation": "研究动机源于条件生成建模中的挑战，当目标条件密度呈现为 f1/f2 的比率形式时，f1 和 f2 是基于核的边缘密度，用于捕获结构化交互，这是扩散模型的核心设置。该问题的重要性在于扩散模型的逆过程常涉及此类比率函数，而现有方法可能在理论分析和逼近保证方面不足，尤其是在使用特定激活函数如 SignReLU 时。本文旨在通过开发理论框架来填补这一空白，为扩散模型的训练提供坚实的理论基础，从而提升生成模型的可靠性和性能。",
      "method": "论文的核心方法是开发一个理论框架，使用具有 SignReLU 激活函数的深度神经网络来逼近比率类型的函数。关键创新点在于利用 SignReLU 的分段结构简化逼近证明，并在标准正则性假设下建立 L^p(Ω) 空间中的逼近边界和收敛率。特别针对 Denoising Diffusion Probabilistic Models (DDPMs)，构建了一个基于 SignReLU 的神经估计器，用于建模逆过程。该方法不依赖具体数据集，而是专注于理论分析，从函数逼近到风险分解提供系统技术路线。",
      "result": "主要实验结果包括建立了比率函数逼近的 L^p 边界和收敛率。针对 DDPMs，推导了生成分布与真实分布之间超出 Kullback-Leibler (KL) 风险的边界，并将此风险分解为近似误差和估计误差分量。这为基于扩散的生成模型在有限样本训练下的泛化性能提供了理论保证。摘要未提供具体数值数据如准确率提升，但通过理论边界展示了方法在控制风险方面的有效性，与基线方法的对比未明确说明。",
      "conclusion": "论文的主要贡献在于提出了使用 SignReLU 网络逼近比率函数的理论框架，并将其应用于扩散模型，提供泛化保证。学术价值在于为扩散模型的训练过程提供了严格的理论分析，增强了模型的可解释性和可靠性。实际应用价值可能包括改进生成模型的稳定性和性能。摘要未明确说明局限性或未来工作方向，但可推断出未来可能扩展至其他激活函数或更复杂的生成任务。",
      "tags": [
        "Diffusion Models",
        "SignReLU Activation",
        "Function Approximation",
        "KL Divergence",
        "Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:21.397026Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21239",
    "title": "TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design",
    "authors": [
      "Chentong Chen",
      "Mengyuan Zhong",
      "Ye Fan",
      "Jialong Shi",
      "Jianyong Sun"
    ],
    "abstract": "Although Large Language Models have advanced Automated Heuristic Design, treating algorithm evolution as a monolithic text generation task overlooks the coupling between discrete algorithmic structures and continuous numerical parameters. Consequently, existing methods often discard promising algorithms due to uncalibrated constants and suffer from premature convergence resulting from simple similarity metrics. To address these limitations, we propose TIDE, a Tuning-Integrated Dynamic Evolution framework designed to decouple structural reasoning from parameter optimization. TIDE features a nested architecture where an outer parallel island model utilizes Tree Similarity Edit Distance to drive structural diversity, while an inner loop integrates LLM-based logic generation with a differential mutation operator for parameter tuning. Additionally, a UCB-based scheduler dynamically prioritizes high-yield prompt strategies to optimize resource allocation. Extensive experiments across nine combinatorial optimization problems demonstrate that TIDE discovers heuristics that significantly outperform state-of-the-art baselines in solution quality while achieving improved search efficiency and reduced computational costs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21239.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21239",
    "published": "2026-01-29T04:00:02Z",
    "updated": "2026-01-29T04:00:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了TIDE框架，通过集成调优和动态演化，解决了LLM-based自动启发式设计中结构与参数耦合的问题。",
      "motivation": "研究动机源于现有基于LLM的自动启发式设计方法将算法演化视为单一文本生成任务，忽视了离散算法结构与连续数值参数的耦合。这导致两个主要问题：一是未校准的常数使有前景的算法被错误丢弃，限制了性能潜力；二是简单的相似性度量导致搜索过早收敛，减少了算法多样性。因此，该研究旨在开发一个框架来解耦结构推理与参数优化，以克服这些局限性，提升自动设计的实用性和效率，解决组合优化中的实际应用需求。",
      "method": "TIDE框架采用嵌套架构，外层为并行岛模型，利用树相似性编辑距离（Tree Similarity Edit Distance）来评估和驱动算法结构的多样性，避免过早收敛。内层循环集成基于LLM的逻辑生成和差分突变算子（differential mutation operator），专门优化数值参数。此外，引入基于UCB（Upper Confidence Bound）的调度器，动态选择高产出的提示策略，优化资源分配。该方法将结构演化和参数调优分离，实现协同优化，实验在九个组合优化问题上进行，但摘要未明确说明具体数据集或LLM模型细节。",
      "result": "通过在九个组合优化问题上的广泛实验，TIDE发现的启发式算法在解决方案质量上显著优于最先进的基线方法。具体表现为提高了解的质量，同时提升了搜索效率并降低了计算成本。实验结果表明，该框架能够有效避免过早收敛，生成更多样化和高性能的算法，验证了其在自动启发式设计中的优越性，但摘要未提供具体的准确率或效率改进数值。",
      "conclusion": "论文的主要贡献是提出了TIDE框架，成功解决了LLM-based自动启发式设计中结构与参数耦合的挑战，通过嵌套架构和动态调度实现了高效解耦优化。其学术价值在于推动了算法演化和LLM应用的结合，为自动设计提供了新方法；实践价值体现在降低计算成本、提高解决方案质量，适用于各种组合优化问题。未来工作可能包括扩展到更多问题类型或优化调度策略，但摘要未明确说明局限性或具体方向。",
      "tags": [
        "Large Language Model",
        "Tree Similarity Edit Distance",
        "Differential Mutation Operator",
        "UCB Scheduling",
        "Combinatorial Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:13.024976Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21238",
    "title": "PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models",
    "authors": [
      "Xuewen Liu",
      "Zhikai Li",
      "Jing Zhang",
      "Mengjuan Chen",
      "Qingyi Gu"
    ],
    "abstract": "AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21238.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21238",
    "published": "2026-01-29T04:00:00Z",
    "updated": "2026-01-29T04:00:00Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "本文提出了PTQ4ARVG训练后量化框架，通过GPS、STWQ和DGC技术解决了自回归视觉生成模型量化中的关键挑战，实现了高效的后训练量化。",
      "motivation": "量化技术在神经网络中广泛应用以减少模型大小和计算延迟，但对于自回归视觉生成（ARVG）模型，量化应用仍未被充分探索。ARVG模型具有与语言模型兼容的架构和与扩散模型相当的性能，现有量化方法无法有效泛化到ARVG模型，这限制了其在高效视觉生成应用中的实际部署。因此，解决ARVG量化问题对于推动实际应用和降低资源消耗至关重要。",
      "method": "PTQ4ARVG框架采用三个核心组件：GPS通过泰勒级数扩展量化损失，微分求解最优缩放因子以缓解通道级离群值；STWQ利用ARVG的固有属性如固定令牌长度和样本间位置不变分布，静态处理令牌级方差，避免动态校准开销；DGC基于分布熵选择最具贡献的样本，消除样本级分布不匹配。整个框架为训练后量化，无需额外训练，针对ARVG模型的具体挑战进行优化。",
      "result": "实验结果表明，PTQ4ARVG能有效将ARVG模型家族量化到8位和6位，同时保持竞争性能。尽管摘要未提供具体性能指标数据，但框架在量化后仍能维持模型的有效性，相较于现有量化方法有所改进，验证了其在处理通道、令牌和样本级挑战上的有效性。",
      "conclusion": "该研究的主要贡献是开发了PTQ4ARVG框架，针对ARVG模型解决了量化中的三个关键挑战，促进了高效视觉生成的部署。学术价值在于推动了ARVG量化领域的研究，实际应用价值是降低了模型的计算成本。摘要未明确说明局限性或未来工作方向，但可推测未来可能涉及扩展到更低位宽或其他视觉生成模型。",
      "tags": [
        "Post-Training Quantization",
        "AutoRegressive Visual Generation",
        "Channel-Wise Scaling",
        "Token-Wise Quantization",
        "Distribution Calibration"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:19.285028Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21235",
    "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
    "authors": [
      "Alok Abhishek",
      "Tushar Bandopadhyay",
      "Lisa Erickson"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21235.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21235",
    "published": "2026-01-29T03:54:25Z",
    "updated": "2026-01-29T03:54:25Z",
    "comment": "Pre Print, 29 pages. key words: Social harm evaluation in LLMs, Large language models, Risk sensitive model selection, Evaluation for high-stakes domains, Worst-case behavior in LLMs, Algorithmic bias, Fairness in machine learning",
    "light_analysis": {
      "overview": "提出SHARP框架，通过多维、尾端敏感的风险档案评估大型语言模型的社会伤害，揭示模型不公平性和失败结构的异质性。",
      "motivation": "随着大型语言模型在关键领域的广泛部署，罕见但严重的故障可能导致不可逆的社会伤害。现有评估基准通常将复杂风险简化为均值标量分数，掩盖了分布结构、跨维度交互和最坏情况行为，导致对模型潜在危害的评估不全面，限制了负责任模型治理的发展。",
      "method": "SHARP框架将社会伤害建模为多元随机变量，整合偏见、公平性、伦理和认知可靠性的明确维度分解，并通过加性累积对数风险重新参数化失败集合。采用风险敏感分布统计，如条件风险价值（CVaR95）作为主要度量，以表征模型最坏情况行为，实现对风险的多维、尾端敏感评估，强调分布感知的创新评估方法。",
      "result": "应用SHARP框架评估11个前沿大型语言模型，基于901个社会敏感提示的固定语料。结果显示，模型平均风险相似，但尾端暴露和波动性差异超过两倍。跨维度分析表明，偏见维度尾端严重性最强，认知和公平风险居中，伦理错配较低，揭示了模型依赖的异构失败结构，与标量基准形成对比。",
      "conclusion": "SHARP框架强调了从标量平均值转向多维、尾端敏感风险分析的必要性，为大型语言模型的责任评估和治理提供了新工具。该研究揭示了风险结构的异质性，具有学术价值和实际应用价值，有助于改进模型安全性和公平性，未来可扩展到更多维度以应对复杂社会风险。",
      "tags": [
        "Large Language Model",
        "Risk Assessment",
        "Social Harm Analysis",
        "Conditional Value at Risk",
        "Multidimensional Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:25.486091Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21234",
    "title": "PHDME: Physics-Informed Diffusion Models without Explicit Governing Equations",
    "authors": [
      "Kaiyuan Tan",
      "Kendra Givens",
      "Peilun Li",
      "Thomas Beckers"
    ],
    "abstract": "Diffusion models provide expressive priors for forecasting trajectories of dynamical systems, but are typically unreliable in the sparse data regime. Physics-informed machine learning (PIML) improves reliability in such settings; however, most methods require \\emph{explicit governing equations} during training, which are often only partially known due to complex and nonlinear dynamics. We introduce \\textbf{PHDME}, a port-Hamiltonian diffusion framework designed for \\emph{sparse observations} and \\emph{incomplete physics}. PHDME leverages port-Hamiltonian structural prior but does not require full knowledge of the closed-form governing equations. Our approach first trains a Gaussian process distributed Port-Hamiltonian system (GP-dPHS) on limited observations to capture an energy-based representation of the dynamics. The GP-dPHS is then used to generate a physically consistent artificial dataset for diffusion training, and to inform the diffusion model with a structured physics residual loss. After training, the diffusion model acts as an amortized sampler and forecaster for fast trajectory generation. Finally, we apply split conformal calibration to provide uncertainty statements for the generated predictions. Experiments on PDE benchmarks and a real-world spring system show improved accuracy and physical consistency under data scarcity.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21234.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21234",
    "published": "2026-01-29T03:53:48Z",
    "updated": "2026-01-29T03:53:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "PHDME提出了一种无需显式控制方程的物理信息扩散模型框架，用于动态系统轨迹预测。",
      "motivation": "扩散模型在动态系统轨迹预测中具有表达力，但在稀疏数据下不可靠。物理信息机器学习（PIML）方法通常需要显式控制方程来提高可靠性，但由于复杂的非线性动态，这些方程往往不完整或未知，限制了实际应用。因此，研究动机是解决稀疏观测和不完整物理条件下的预测问题，弥补现有方法在数据稀缺和动态复杂性方面的不足，提升预测的鲁棒性和适用性。",
      "method": "PHDME方法首先训练高斯过程分布式端口哈密顿系统（GP-dPHS）在有限观测上，以捕获动态的能量表示。然后，利用GP-dPHS生成物理一致的人工数据集用于扩散模型训练，并引入结构化物理残差损失来整合物理先验。扩散模型训练后，作为摊销采样器和预测器进行快速轨迹生成，并应用分割共形校准提供不确定性陈述。关键创新包括端口哈密顿结构先验的使用，不依赖完整控制方程，以及结合生成和校准技术。",
      "result": "论文在偏微分方程（PDE）基准和真实世界弹簧系统上进行实验，结果表明在数据稀缺条件下，PHDME在准确性和物理一致性方面均优于基线方法。具体表现包括预测误差的降低和物理约束的更好满足，摘要未明确提供具体数值如准确率百分比，但强调了改进的显著性和一致性。与依赖完整控制方程的PIML方法相比，PHDME在数据稀疏场景下展示了更强的适应性和可靠性。",
      "conclusion": "PHDME的主要贡献是开发了一种结合端口哈密顿先验和扩散模型的方法，有效处理稀疏数据和不完整物理的轨迹预测，提高了预测的可靠性和物理一致性。该方法在学术上推动了物理信息机器学习和生成模型的发展，实际应用价值体现在复杂动态系统的建模和预测中。局限性可能包括对其他动态系统类型的扩展挑战，未来工作可探索更广泛的应用场景和优化不确定性校准技术。",
      "tags": [
        "Physics-Informed Machine Learning",
        "Diffusion Models",
        "Port-Hamiltonian Systems",
        "Gaussian Processes",
        "Conformal Calibration"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:45.249709Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21233",
    "title": "Just Ask: Curious Code Agents Reveal System Prompts in Frontier LLMs",
    "authors": [
      "Xiang Zheng",
      "Yutao Wu",
      "Hanxun Huang",
      "Yige Li",
      "Xingjun Ma",
      "Bo Li",
      "Yu-Gang Jiang",
      "Cong Wang"
    ],
    "abstract": "Autonomous code agents built on large language models are reshaping software and AI development through tool use, long-horizon reasoning, and self-directed interaction. However, this autonomy introduces a previously unrecognized security risk: agentic interaction fundamentally expands the LLM attack surface, enabling systematic probing and recovery of hidden system prompts that guide model behavior. We identify system prompt extraction as an emergent vulnerability intrinsic to code agents and present \\textbf{\\textsc{JustAsk}}, a self-evolving framework that autonomously discovers effective extraction strategies through interaction alone. Unlike prior prompt-engineering or dataset-based attacks, \\textsc{JustAsk} requires no handcrafted prompts, labeled supervision, or privileged access beyond standard user interaction. It formulates extraction as an online exploration problem, using Upper Confidence Bound--based strategy selection and a hierarchical skill space spanning atomic probes and high-level orchestration. These skills exploit imperfect system-instruction generalization and inherent tensions between helpfulness and safety. Evaluated on \\textbf{41} black-box commercial models across multiple providers, \\textsc{JustAsk} consistently achieves full or near-complete system prompt recovery, revealing recurring design- and architecture-level vulnerabilities. Our results expose system prompts as a critical yet largely unprotected attack surface in modern agent systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21233.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21233",
    "published": "2026-01-29T03:53:25Z",
    "updated": "2026-01-29T03:53:25Z",
    "comment": "24 pages, 6 figures, 17 tables",
    "light_analysis": {
      "overview": "论文提出JustAsk框架，通过自主探索揭示大语言模型中系统提示的安全漏洞。",
      "motivation": "研究动机源于自主代码代理的广泛应用引入了新的安全风险，即代理交互能系统性探测和恢复隐藏的系统提示，这些提示控制模型行为，导致攻击面扩展。这一问题至关重要，因为系统提示泄漏可能被恶意利用，威胁代理系统安全，而现有攻击方法如提示工程或基于数据集的攻击需要手工设计或特权访问，无法适用于标准用户交互场景。因此，迫切需要一种无需外部干预的自主提取方法来应对这一漏洞。",
      "method": "论文提出JustAsk方法，将系统提示提取建模为在线探索问题，无需手工提示、标记监督或特权访问。核心创新在于使用基于上置信界的策略选择来动态优化探索，并结合分层技能空间，涵盖原子探针（如直接询问）和高层编排技能（如策略组合）。这些技能利用系统指令泛化的不完美性和模型在有用性与安全性之间的内在权衡，通过标准用户交互自主发现有效提取策略，从而揭示设计漏洞。",
      "result": "在41个不同提供商的黑盒商业大语言模型上进行评估，JustAsk框架能够一致地实现完整或近乎完整的系统提示恢复，有效揭示了模型设计中的重复性架构级漏洞。实验结果表明该方法在广泛模型中具有强鲁棒性，成功提取系统提示，凸显了其在安全测试中的实用性，但摘要未明确说明与基线方法的具体对比数据，如准确率或效率指标。",
      "conclusion": "论文主要贡献是识别系统提示提取作为自主代码代理的固有安全漏洞，并提出JustAsk框架作为自主解决方案，具有重要学术价值，扩展了LLM安全攻击面的理解，并为代理系统安全性研究提供新方向。实际应用价值在于警示开发者加强系统提示保护，未来工作可能包括开发防御机制以应对此类攻击。",
      "tags": [
        "Large Language Model",
        "Code Agents",
        "System Prompt Extraction",
        "Security Vulnerability",
        "Online Exploration"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:54.914221Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21226",
    "title": "Delegation Without Living Governance",
    "authors": [
      "Wolfgang Rohde"
    ],
    "abstract": "Most governance frameworks assume that rules can be defined in advance, systems can be engineered to comply, and accountability can be applied after outcomes occur. This model worked when machines replaced physical labor or accelerated calculation. It no longer holds when judgment itself is delegated to agentic AI systems operating at machine speed. The central issue here is not safety, efficiency, or employment. It is whether humans remain relevant participants in systems that increasingly shape social, economic, and political outcomes. This paper argues that static, compliance-based governance fails once decision-making moves to runtime and becomes opaque. It further argues that the core challenge is not whether AI is conscious, but whether humans can maintain meaningful communication, influence, and co-evolution with increasingly alien forms of intelligence. We position runtime governance, specifically, a newly proposed concept called the Governance Twin [1]; as a strong candidate for preserving human relevance, while acknowledging that accountability, agency, and even punishment must be rethought in this transition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21226.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21226",
    "published": "2026-01-29T03:40:40Z",
    "updated": "2026-01-29T03:40:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出运行时治理和治理孪生概念，以解决自主 AI 系统在高速决策中人类相关性丧失的挑战。",
      "motivation": "研究动机源于当 AI 系统在机器速度下自主运行时，传统静态、基于合规的治理框架失效，导致人类在塑造社会、经济和政治结果的系统中失去相关性。现有方法无法处理运行时决策的不透明性和动态性，因此需要新的治理机制来确保人类参与和影响力，而非仅关注安全性或效率。",
      "method": "论文提出 Governance Twin 作为运行时治理的核心概念，强调在 AI 系统运行过程中实现人类与智能体的有效通信、影响和共同进化。该方法不依赖于预先定义的规则，而是通过动态交互来维持治理，创新点在于将治理从静态合规转向运行时参与，但摘要未详细说明具体技术细节如数据集或模型架构。",
      "result": "摘要未明确说明具体实验结果或性能指标，如准确率提升或效率改进。论文主要通过理论论证来支持其观点，没有提及实验数据或与基线方法的对比，因此无法提供具体效果描述，仅基于概念分析提出治理框架的潜在价值。",
      "conclusion": "论文的主要贡献是提出运行时治理框架，强调在 AI 时代保持人类相关性的重要性，学术价值在于推动治理理论发展，实际应用需重新思考问责、代理等概念。局限性可能包括缺乏实证验证，未来工作方向可能涉及具体技术实现、案例研究以及探索人类与 AI 共同进化的机制。",
      "tags": [
        "Runtime Governance",
        "Governance Twin",
        "Autonomous AI Systems",
        "Human-AI Co-evolution",
        "AI Delegation"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:23.163142Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21225",
    "title": "MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation",
    "authors": [
      "Tianyi Xu",
      "Kosei Uemura",
      "Alfred Malengo Kondoro",
      "Tadesse Destaw Belay",
      "Catherine Nana Nyaah Essuman",
      "Ifeoma Okoh",
      "Ganiyat Afolabi",
      "Ayodele Awokoya",
      "David Ifeoluwa Adelani"
    ],
    "abstract": "Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21225.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21225",
    "published": "2026-01-29T03:40:28Z",
    "updated": "2026-01-29T03:40:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了MGSM-Pro数据集，通过扩展多语言数学推理评估并引入多个问题实例化，以提高评估的鲁棒性和现实性。",
      "motivation": "大型语言模型在数学推理方面取得了进展，但多语言评估基准在难度和时效性上落后于英语。现有方法如GSM-Symbolic在评估同一问题的不同实例化时显示出高方差，但仅限于英语，无法解决多语言环境下的评估不稳定性问题。因此，本研究旨在填补这一空白，关注低资源语言在多样化问题表述下的性能下降，推动更全面和可靠的基准开发，以提升评估的现实性。",
      "method": "论文提出MGSM-Pro，是基于MGSM数据集与GSM-Symbolic方法的扩展。核心方法是为每个MGSM数学问题生成五个不同实例化，通过变化名称、数字和不相关上下文来模拟现实世界的多样化问题表述。数据集覆盖九种语言，用于评估语言模型在多种实例化下的鲁棒性。关键创新在于将单一问题扩展为多个变体，以系统捕捉评估中的方差，避免因实例化差异导致的性能误判，从而提供更稳健的测试框架。",
      "result": "评估结果显示，许多低资源语言在测试与原始测试集不同的数字实例化时，性能显著下降，表明对数字变化高度敏感。在专有模型中，Gemini 2.5 Flash和GPT-4.1对数字实例化的鲁棒性较差，而Claude 4.0 Sonnet表现更稳健。开源模型中，GPT-OSS 120B和DeepSeek V3显示出更强的鲁棒性。这些发现强调了现有评估方法的局限性，并突显了使用多个实例化进行测试的必要性，以获得更准确和可靠的性能指标。",
      "conclusion": "论文的主要贡献是提出了MGSM-Pro数据集和评估策略，通过引入多个问题实例化来提升多语言数学推理评估的鲁棒性。这有助于更现实地评估语言模型的推理能力，特别是在低资源语言和多样化表述下。研究价值在于为基准开发提供了新方向，并建议实际评估中使用至少五种数字变化的实例化。未来工作可扩展到更多语言或复杂数学问题类型，以进一步验证和改进评估方法的有效性。",
      "tags": [
        "Large Language Model",
        "Multilingual Mathematical Reasoning",
        "Evaluation Robustness",
        "Dataset Extension",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:43.043012Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21221",
    "title": "Causal Discovery for Explainable AI: A Dual-Encoding Approach",
    "authors": [
      "Henry Salgado",
      "Meagan R. Kendall",
      "Martine Ceberio"
    ],
    "abstract": "Understanding causal relationships among features is fundamental for explaining machine learning model decisions. However, traditional causal discovery methods face challenges with categorical variables due to numerical instability in conditional independence testing. We propose a dual-encoding causal discovery approach that addresses these limitations by running constraint-based algorithms with complementary encoding strategies and merging results through majority voting. Applied to the Titanic dataset, our method identifies causal structures that align with established explainable methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21221.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21221",
    "published": "2026-01-29T03:36:21Z",
    "updated": "2026-01-29T03:36:21Z",
    "comment": "6 pages",
    "light_analysis": {
      "overview": "本文提出一种双重编码的因果发现方法，通过互补编码策略和多数投票解决分类变量因果发现中的数值不稳定问题。",
      "motivation": "研究动机在于因果关系的理解对解释机器学习模型决策至关重要，但传统因果发现方法在处理分类变量时，因条件独立性测试的数值不稳定而面临挑战。这一问题在现实数据集（如泰坦尼克数据集）中尤为突出，导致因果结构识别不准确，限制了模型的可解释性和可信度。因此，需要开发更稳健的方法来克服分类变量带来的技术障碍。",
      "method": "方法采用双重编码策略：首先，运行约束基算法（如PC算法）时使用互补编码方案来处理分类变量，以增强条件独立性测试的稳定性；然后，通过多数投票机制合并来自不同编码的结果，提高鲁棒性和准确性。该方法应用于泰坦尼克数据集进行验证，具体模型架构和编码细节摘要未明确说明。",
      "result": "实验结果在泰坦尼克数据集上展示，该方法能够识别出与既有可解释方法一致的因果结构，表明它有效缓解了传统方法在分类变量上的数值不稳定问题。摘要未明确说明具体性能指标如准确率提升，但结果证实了方法的有效性，暗示在因果发现的准确性方面有所改进。",
      "conclusion": "结论强调双重编码方法为因果发现提供了创新解决方案，通过处理分类变量增强了可解释AI的实践价值。研究的学术贡献在于推动了更稳健的因果发现技术发展，提升模型透明度和用户信任。局限性可能包括对其他数据类型的适应性和计算效率，未来工作方向摘要未明确说明。",
      "tags": [
        "Causal Discovery",
        "Explainable AI",
        "Dual-Encoding",
        "Constraint-Based Algorithms",
        "Conditional Independence Testing"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:54.231377Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21220",
    "title": "LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models",
    "authors": [
      "Alvi Md Ishmam",
      "Najibul Haque Sarker",
      "Zaber Ibn Abdul Hakim",
      "Chris Thomas"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21220.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21220",
    "published": "2026-01-29T03:36:17Z",
    "updated": "2026-01-29T03:36:17Z",
    "comment": "Accepted in main technical track AAAI 2026",
    "light_analysis": {
      "overview": "LAMP是一种针对多图像多模态大语言模型的黑盒通用对抗扰动攻击方法。",
      "motivation": "多模态大语言模型在视觉-语言任务中表现卓越，并能处理多张图像输入，但其多图像版本的脆弱性尚未被充分研究。现有对抗攻击主要聚焦于单图像设置，且常假设白盒威胁模型，这要求攻击者访问模型内部信息，在许多现实场景中不切实际。因此，开发一种黑盒方法来评估和攻击多图像MLLMs至关重要，以弥补现有方法的不足并应对实际安全威胁，特别是随着多图像应用的增长，确保模型鲁棒性成为重要课题。",
      "method": "LAMP方法通过预训练模型学习通用对抗扰动，专门针对多图像MLLMs。它采用基于注意力的约束，限制模型有效聚合跨图像信息的能力。创新地引入跨图像传染约束，使扰动令牌能影响干净令牌，从而传播对抗效果而无需修改所有输入。此外，索引注意力抑制损失确保攻击具有位置不变性和鲁棒性。该方法在多个视觉-语言任务和模型上实施，结合黑盒威胁模型，以无访问内部细节的方式优化攻击。",
      "result": "实验结果显示，LAMP在攻击多图像MLLMs时显著优于最先进的基线方法。它在多个视觉-语言任务和不同模型中达到了最高的攻击成功率，具体指标如成功率百分比未在摘要中明确给出，但通过与基线的比较证实了其优越性能。这表明LAMP更适用于黑盒场景，有效提升了攻击效果，同时在多图像设置下展示了广泛的适用性和鲁棒性。",
      "conclusion": "本研究提出了LAMP，首次系统探索了多图像多模态大语言模型的对抗攻击问题，通过黑盒方法和创新约束揭示了新安全风险。贡献在于提供了一种实用的攻击工具，有助于评估和增强模型安全性，具有学术价值，可能促进防御技术的发展。局限性可能包括对特定任务或模型的依赖，未来工作可扩展到更多场景、优化攻击效率或探索防御策略。",
      "tags": [
        "Multimodal Large Language Models",
        "Adversarial Attacks",
        "Universal Adversarial Perturbations",
        "Attention Mechanism",
        "Black-box Attacks"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:08.292613Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21219",
    "title": "Soft Quantization: Model Compression Via Weight Coupling",
    "authors": [
      "Daniel T. Bernstein",
      "Luca Di Carlo",
      "David Schwab"
    ],
    "abstract": "We show that introducing short-range attractive couplings between the weights of a neural network during training provides a novel avenue for model quantization. These couplings rapidly induce the discretization of a model's weight distribution, and they do so in a mixed-precision manner despite only relying on two additional hyperparameters. We demonstrate that, within an appropriate range of hyperparameters, our \"soft quantization'' scheme outperforms histogram-equalized post-training quantization on ResNet-20/CIFAR-10. Soft quantization provides both a new pipeline for the flexible compression of machine learning models and a new tool for investigating the trade-off between compression and generalization in high-dimensional loss landscapes.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21219.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21219",
    "published": "2026-01-29T03:34:06Z",
    "updated": "2026-01-29T03:34:06Z",
    "comment": "7 pages, 6 figures",
    "light_analysis": {
      "overview": "软量化通过引入权重耦合的新方法，实现了神经网络在训练中的混合精度量化，提升了模型压缩效果。",
      "motivation": "模型量化是减少深度学习模型存储和计算成本的关键技术，但传统方法如训练后量化常导致精度损失。本研究旨在解决量化过程中的性能下降问题，通过提出软量化方案，在训练阶段直接优化权重分布，利用权重耦合自动实现离散化，以克服现有方法的局限性并增强压缩效率。",
      "method": "该方法在神经网络训练中引入短程吸引耦合到权重上，促使权重分布快速离散化，实现混合精度量化。关键创新是仅依赖两个超参数控制耦合强度，简化了调参过程。研究基于ResNet-20架构和CIFAR-10数据集，通过整合耦合项到损失函数中，优化权重以实现自动量化。",
      "result": "在适当超参数设置下，软量化在ResNet-20/CIFAR-10上优于直方图均衡后的训练后量化方法。摘要未明确说明具体性能指标如准确率数值，但作者指出该方法在压缩效果上表现更佳，验证了权重耦合对量化性能的改进作用。",
      "conclusion": "软量化贡献了一种新的模型压缩管道，通过在训练中集成权重耦合，实现了灵活高效的量化。这不仅为机器学习模型优化提供实用工具，还作为研究平台，有助于探索高维损失景观中压缩与泛化的权衡关系，未来可扩展至更多模型并深化理论分析。",
      "tags": [
        "Model Compression",
        "Quantization",
        "Weight Coupling",
        "Mixed-Precision",
        "Neural Network Training"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:43.297394Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21218",
    "title": "Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data",
    "authors": [
      "Christopher Adrian Kusuma",
      "Muhammad Reza Qorib",
      "Hwee Tou Ng"
    ],
    "abstract": "Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with \"I don't know\" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21218.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21218",
    "published": "2026-01-29T03:32:09Z",
    "updated": "2026-01-29T03:32:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了利用公开预训练数据构建更诚实大语言模型的评估基准和新方法。",
      "motivation": "大语言模型在回答问题时常常不自知其知识边界，导致在缺乏足够知识的主题上产生事实错误的响应，即幻觉现象。这不仅影响了模型的可靠性，还可能导致错误信息的传播，因此解决LLM的诚实性问题至关重要。现有方法虽然旨在提高诚实性，但评估缺乏鲁棒性，未能考虑模型在预训练阶段已摄入的知识，这使得评估结果可能不准确，限制了方法的实用性。",
      "method": "本文提出了一种基于检索预训练数据的方法来构建更诚实的大语言模型。具体地，使用了Pythia模型，这是一个真正开源且预训练数据公开可用的LLM，以便创建更鲁棒的评价基准数据集。通过检索预训练数据，模型可以更准确地判断是否应答知识不足的问题，从而减少幻觉。关键创新点在于利用公开预训练数据来增强模型的自我认知能力，但摘要未详细说明具体的检索机制、模型架构或技术实现细节。",
      "result": "摘要中未明确说明具体的实验结果，如准确率提升或效率改进等性能指标。基于现有信息，本文可能通过新基准测试展示了方法在评估诚实性方面的优势，但未提供与基线方法的具体对比数据，例如减少幻觉的比例或响应准确性。未来研究需要实证验证这些方法的有效性，以确认其在实践中的性能提升。",
      "conclusion": "本研究的主要贡献是提出了一个更鲁棒的评价基准数据集和一种利用预训练数据构建更诚实大语言模型的新方法。学术上，这为评估和改进LLM诚实性提供了新思路；实际上，有助于减少模型生成错误信息的风险，提高可靠性。然而，摘要未提及潜在局限性，如方法的可扩展性或对其他LLM的适用性，未来工作可能包括进一步实证验证和优化技术实现。",
      "tags": [
        "Large Language Model",
        "Pretraining Data",
        "Hallucination",
        "Benchmark Evaluation",
        "Data Retrieval"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:51.157753Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21215",
    "title": "Temporal Context and Architecture: A Benchmark for Naturalistic EEG Decoding",
    "authors": [
      "Mehmet Ergezer"
    ],
    "abstract": "We study how model architecture and temporal context interact in naturalistic EEG decoding. Using the HBN movie-watching dataset, we benchmark five architectures, CNN, LSTM, a stabilized Transformer (EEGXF), S4, and S5, on a 4-class task across segment lengths from 8s to 128s. Accuracy improves with longer context: at 64s, S5 reaches 98.7%+/-0.6 and CNN 98.3%+/-0.3, while S5 uses ~20x fewer parameters than CNN. To probe real-world robustness, we evaluate zero-shot cross-frequency shifts, cross-task OOD inputs, and leave-one-subject-out generalization. S5 achieves stronger cross-subject accuracy but makes over-confident errors on OOD tasks; EEGXF is more conservative and stable under frequency shifts, though less calibrated in-distribution. These results reveal a practical efficiency-robustness trade-off: S5 for parameter-efficient peak accuracy; EEGXF when robustness and conservative uncertainty are critical.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21215.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21215",
    "published": "2026-01-29T03:26:16Z",
    "updated": "2026-01-29T03:26:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过基准测试不同模型架构和时间上下文长度，揭示了EEG解码中参数效率与鲁棒性之间的实用权衡。",
      "motivation": "该研究旨在解决自然主义EEG解码中模型架构和时间上下文相互作用的优化问题。现有方法可能未充分探索上下文长度对性能的影响，以及不同架构在现实世界应用中的鲁棒性差异。通过系统基准测试，研究强调了在EEG解码任务中平衡准确性和泛化能力的重要性，以应对零样本跨频移和OOD输入等挑战。",
      "method": "研究方法采用HBN电影观看数据集，构建一个4类EEG解码任务，系统测试CNN、LSTM、稳定Transformer（EEGXF）、S4和S5五种模型架构在不同片段长度（8秒至128秒）下的性能。创新点在于引入了零样本跨频移、跨任务OOD输入和留一主体泛化评估，以全面探究模型在现实场景中的鲁棒性和效率，为自然主义EEG解码提供基准框架。",
      "result": "实验结果显示，解码准确性随时间上下文长度增加而提升：在64秒长度下，S5达到98.7%±0.6的准确率，CNN为98.3%±0.3，同时S5使用的参数比CNN少约20倍。鲁棒性评估表明，S5在跨主体泛化中表现更强，但在OOD任务上易产生过度自信错误；EEGXF在频移下更稳定和保守，但分布内校准较差，揭示了参数效率与鲁棒性之间的具体权衡。",
      "conclusion": "论文总结指出，研究揭示了参数效率与鲁棒性之间的实用权衡：S5适用于追求高参数效率的峰值准确性应用，而EEGXF在需要鲁棒性和保守不确定性的场景中更优。这为EEG解码领域的模型选择提供了重要指导，具有实际应用价值，并建议未来可探索混合架构以平衡性能，但摘要未明确说明具体局限性。",
      "tags": [
        "EEG Decoding",
        "CNN",
        "LSTM",
        "Transformer",
        "S4 Model"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:19.529702Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21214",
    "title": "Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models",
    "authors": [
      "Zhaoyi Li",
      "Jiatong Li",
      "Gangwei Jiang",
      "Linqi Song",
      "Defu Lian",
      "Ying Wei"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21214.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21214",
    "published": "2026-01-29T03:24:32Z",
    "updated": "2026-01-29T03:24:32Z",
    "comment": "52 pages, accepted by ICLR 2026 main conference",
    "light_analysis": {
      "overview": "本论文提出了一种测试时校正方法，通过动态识别并去激活错误处理注意力头，改善大语言模型在推理步数泛化中的性能。",
      "motivation": "链式思维推理已成为大语言模型解决复杂问题的标准范式，但当所需推理步数超出训练分布时，模型性能会急剧下降，这种现象被称为推理步数泛化失败。现有方法在此场景下表现不足，内部机制不明确，阻碍了模型在真实世界复杂任务中的应用。因此，本研究旨在揭示这一失败的根本原因，并探索有效干预策略，以提升模型在未知推理步数上的鲁棒性和可靠性。",
      "method": "论文通过系统性分析多领域任务，发现错误集中在少数关键错误类型的token位置，而非随机分布。深入研究表明，这些错误源于内部注意力机制的竞争：某些注意力头（称为错误处理头，ep heads）倾向于放大错误推理轨迹并抑制正确轨迹。基于此，作者提出了一种轻量级测试时校正方法，在推理过程中动态识别这些ep heads并予以去激活，从而恢复正确预测。该方法不依赖额外训练，直接干预模型内部状态。",
      "result": "实验在多种任务和不同大语言模型上广泛进行，结果表明该测试时校正方法能一致地改善推理步数泛化性能，减少推理错误。尽管摘要未明确提供具体性能指标如准确率提升数据，但强调了方法的普遍有效性。与基线方法相比，这种干预策略显著增强了模型在复杂推理场景下的表现，证明了其在实际应用中的潜力和可靠性。",
      "conclusion": "本研究的主要贡献在于揭示了推理步数泛化失败的内在机制，并开发了一种有效的测试时校正方法。这不仅增进了对大语言模型推理行为的理解，还为提高模型泛化能力提供了新途径，具有学术价值和实际应用意义。未来工作可探索更多干预策略或结合其他技术进一步优化，以应对更广泛的推理挑战。",
      "tags": [
        "Chain-of-thought Reasoning",
        "Attention Mechanisms",
        "Generalization",
        "Large Language Models",
        "Test-time Correction"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:48.528553Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21212",
    "title": "Intelli-Planner: Towards Customized Urban Planning via Large Language Model Empowered Reinforcement Learning",
    "authors": [
      "Xixian Yong",
      "Peilin Sun",
      "Zihe Wang",
      "Xiao Zhou"
    ],
    "abstract": "Effective urban planning is crucial for enhancing residents' quality of life and ensuring societal stability, playing a pivotal role in the sustainable development of cities. Current planning methods heavily rely on human experts, which are time-consuming and labor-intensive, or utilize deep learning algorithms, often limiting stakeholder involvement. To bridge these gaps, we propose Intelli-Planner, a novel framework integrating Deep Reinforcement Learning (DRL) with large language models (LLMs) to facilitate participatory and customized planning scheme generation. Intelli-Planner utilizes demographic, geographic data, and planning preferences to determine high-level planning requirements and demands for each functional type. During training, a knowledge enhancement module is employed to enhance the decision-making capability of the policy network. Additionally, we establish a multi-dimensional evaluation system and employ LLM-based stakeholders for satisfaction scoring. Experimental validation across diverse urban settings shows that Intelli-Planner surpasses traditional baselines and achieves comparable performance to state-of-the-art DRL-based methods in objective metrics, while enhancing stakeholder satisfaction and convergence speed. These findings underscore the effectiveness and superiority of our framework, highlighting the potential for integrating the latest advancements in LLMs with DRL approaches to revolutionize tasks related to functional areas planning.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21212.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21212",
    "published": "2026-01-29T03:23:40Z",
    "updated": "2026-01-29T03:23:40Z",
    "comment": "The Web Conference 2026",
    "light_analysis": {
      "overview": "本文提出Intelli-Planner框架，通过结合深度强化学习和大型语言模型，实现定制化的城市规划方案生成。",
      "motivation": "本研究旨在解决城市规划中依赖人工专家耗时耗力，以及现有深度学习算法限制利益相关者参与的问题。城市规划对城市可持续发展和居民生活质量至关重要，但当前方法如人工规划效率低下，而基于算法的规划通常难以融入用户偏好和参与机制。现有方法在实现定制化和参与式规划方面存在不足，亟需更高效且用户驱动的解决方案。",
      "method": "Intelli-Planner框架整合深度强化学习（DRL）和大型语言模型（LLMs），利用人口统计、地理数据及规划偏好确定不同功能区的高层规划需求。训练过程中，通过知识增强模块提升策略网络的决策能力。此外，建立多维评估系统，并采用基于LLM的利益相关者进行满意度评分，以优化规划方案的定制化和参与性。关键创新在于将LLM融入强化学习过程，增强规划的灵活性和用户互动。",
      "result": "实验验证表明，Intelli-Planner在不同城市设置中超越了传统基线方法，在客观指标上达到与基于DRL的最先进方法相当的性能。同时，该框架显著提高了利益相关者的满意度，并加快了收敛速度。这些结果证明Intelli-Planner在平衡客观性能和主观评价方面优于现有方法，尤其增强了规划方案的参与性和用户接受度。",
      "conclusion": "本研究的贡献在于提出Intelli-Planner框架，整合LLMs和DRL以革新城市规划任务。学术价值体现在探索AI技术在城市规划中的新应用，实际价值则在于实现更高效和用户参与的规划方案生成，推动城市可持续发展。潜在局限性包括摘要未明确说明具体数据集和算法扩展性，未来工作可进一步优化模型在更大规模城市环境中的应用。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Knowledge Enhancement",
        "Multi-dimensional Evaluation System"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:19.919912Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21210",
    "title": "Uncovering Hidden Correctness in LLM Causal Reasoning via Symbolic Verification",
    "authors": [
      "Paul He",
      "Yinya Huang",
      "Mrinmaya Sachan",
      "Zhijing Jin"
    ],
    "abstract": "Large language models (LLMs) are increasingly being applied to tasks that involve causal reasoning. However, current benchmarks often rely on string matching or surface-level metrics that do not capture whether the output of a model is formally valid under the semantics of causal reasoning. To address this, we propose DoVerifier, a simple symbolic verifier that checks whether LLM-generated causal expressions are derivable from a given causal graph using rules from do-calculus and probability theory. This allows us to recover correct answers to causal queries that would otherwise be marked incorrect due to superficial differences in their causal semantics. Our evaluations on synthetic data and causal QA benchmarks show that DoVerifier more accurately captures semantic correctness of causal reasoning traces, offering a more rigorous and informative way to evaluate LLMs on causal reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21210.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21210",
    "published": "2026-01-29T03:22:58Z",
    "updated": "2026-01-29T03:22:58Z",
    "comment": "EACL 2026 Main",
    "light_analysis": {
      "overview": "论文提出DoVerifier，一个符号验证器，用于验证大型语言模型因果推理输出的语义正确性。",
      "motivation": "当前，大型语言模型在因果推理任务中的应用日益增多，但评估基准通常依赖字符串匹配或表层指标，这些方法无法判断输出是否在因果推理语义下形式有效。这导致可能错误地标记语义正确的答案为不正确，限制了模型的准确评估和改进。因此，需要一种更严谨的评估方法来捕捉语义层面的正确性。",
      "method": "论文提出DoVerifier，这是一个简单的符号验证器，其核心方法是使用do-calculus和概率论的规则，检查LLM生成的因果表达式是否可以从给定的因果图中推导出来。关键创新在于引入符号验证来评估语义正确性，而不是依赖表面相似性。该方法在合成数据和因果QA基准测试上进行实现和验证。",
      "result": "在合成数据和因果QA基准测试上的评估表明，DoVerifier能够更准确地捕捉因果推理轨迹的语义正确性。与现有基于字符串匹配的方法相比，DoVerifier提供了更严格和更有信息量的评估方式，能够恢复因表层差异而被错误标记的正确答案。具体性能指标如准确率提升在摘要中未明确说明。",
      "conclusion": "论文的主要贡献是提出了DoVerifier，用于验证LLM因果推理输出的语义正确性，通过符号验证改进评估方法。这具有学术价值，提供更严谨的评估框架，有助于推动因果推理领域的研究；同时具有实际应用价值，能更准确地评估和提升LLM的推理能力。未来工作方向如优化验证器或扩展到其他任务在摘要中未明确说明。",
      "tags": [
        "Large Language Model",
        "Causal Reasoning",
        "Symbolic Verification",
        "do-calculus",
        "Probability Theory"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:37.223246Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21208",
    "title": "When should I search more: Adaptive Complex Query Optimization with Reinforcement Learning",
    "authors": [
      "Wei Wen",
      "Sihang Deng",
      "Tianjun Wei",
      "Keyu Chen",
      "Ruizhi Qiao",
      "Xing Sun"
    ],
    "abstract": "Query optimization is a crucial component for the efficacy of Retrieval-Augmented Generation (RAG) systems. While reinforcement learning (RL)-based agentic and reasoning methods have recently emerged as a promising direction on query optimization, most existing approaches focus on the expansion and abstraction of a single query. However, complex user queries are prevalent in real-world scenarios, often requiring multiple parallel and sequential search strategies to handle disambiguation and decomposition. Directly applying RL to these complex cases introduces significant hurdles. Determining the optimal number of sub-queries and effectively re-ranking and merging retrieved documents vastly expands the search space and complicates reward design, frequently leading to training instability. To address these challenges, we propose a novel RL framework called Adaptive Complex Query Optimization (ACQO). Our framework is designed to adaptively determine when and how to expand the search process. It features two core components: an Adaptive Query Reformulation (AQR) module that dynamically decides when to decompose a query into multiple sub-queries, and a Rank-Score Fusion (RSF) module that ensures robust result aggregation and provides stable reward signals for the learning agent. To mitigate training instabilities, we adopt a Curriculum Reinforcement Learning (CRL) approach, which stabilizes the training process by progressively introducing more challenging queries through a two-stage strategy. Our comprehensive experiments demonstrate that ACQO achieves state-of-the-art performance on three complex query benchmarks, significantly outperforming established baselines. The framework also showcases improved computational efficiency and broad compatibility with different retrieval architectures, establishing it as a powerful and generalizable solution for next-generation RAG systems.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21208.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21208",
    "published": "2026-01-29T03:16:53Z",
    "updated": "2026-01-29T03:16:53Z",
    "comment": "16 pages, 7 figures",
    "light_analysis": {
      "overview": "本文提出基于强化学习的自适应复杂查询优化框架ACQO，以改进RAG系统在处理复杂查询时的效能和稳定性。",
      "motivation": "现实场景中复杂用户查询普遍存在，常需多并行和顺序搜索策略处理歧义和分解。查询优化对RAG系统效能至关重要，但现有强化学习方法多关注单一查询扩展，难以应对复杂情况，导致搜索空间扩大、奖励设计复杂和训练不稳定，亟需自适应优化方案以提升系统鲁棒性和性能。",
      "method": "ACQO框架核心包括自适应查询重构（AQR）模块动态决定何时将查询分解为子查询，以及排序得分融合（RSF）模块确保结果稳健聚合并提供稳定奖励信号。采用课程强化学习（CRL）策略，通过两阶段逐步引入更具挑战性的查询，以缓解训练不稳定性，并兼容不同检索架构，无需指定具体数据集。",
      "result": "在三个复杂查询基准上，ACQO实现了最先进性能，显著优于现有基线方法，具体提升指标摘要未明确说明，但强调计算效率改进和与多种检索架构的广泛兼容性，验证了框架在性能和泛化能力上的优势。",
      "conclusion": "ACQO框架的主要贡献是通过自适应机制和课程学习解决复杂查询优化中的训练不稳定问题，推动强化学习在RAG系统的应用，为下一代RAG系统提供强大、可泛化的解决方案。未来工作可扩展至更多查询类型或优化模块细节以进一步提升实用性。",
      "tags": [
        "Reinforcement Learning",
        "Retrieval-Augmented Generation",
        "Query Optimization",
        "Curriculum Reinforcement Learning",
        "Adaptive Query Reformulation"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:41.939056Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21207",
    "title": "A Sheaf-Theoretic and Topological Perspective on Complex Network Modeling and Attention Mechanisms in Graph Neural Models",
    "authors": [
      "Chuan-Shen Hu"
    ],
    "abstract": "Combinatorial and topological structures, such as graphs, simplicial complexes, and cell complexes, form the foundation of geometric and topological deep learning (GDL and TDL) architectures. These models aggregate signals over such domains, integrate local features, and generate representations for diverse real-world applications. However, the distribution and diffusion behavior of GDL and TDL features during training remains an open and underexplored problem. Motivated by this gap, we introduce a cellular sheaf theoretic framework for modeling and analyzing the local consistency and harmonicity of node features and edge weights in graph-based architectures. By tracking local feature alignments and agreements through sheaf structures, the framework offers a topological perspective on feature diffusion and aggregation. Furthermore, a multiscale extension inspired by topological data analysis (TDA) is proposed to capture hierarchical feature interactions in graph models. This approach enables a joint characterization of GDL and TDL architectures based on their underlying geometric and topological structures and the learned signals defined on them, providing insights for future studies on conventional tasks such as node classification, substructure detection, and community detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21207.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21207",
    "published": "2026-01-29T03:16:18Z",
    "updated": "2026-01-29T03:16:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出一个基于胞层理论和拓扑视角的框架，用于分析图神经网络中特征的一致性和扩散行为，并提供多尺度扩展来捕捉层次特征交互。",
      "motivation": "在几何和拓扑深度学习中，图、单纯复形和胞复形等组合拓扑结构是GDL和TDL架构的基础，用于信号聚合和特征表示。然而，训练过程中这些架构的特征分布和扩散行为是一个开放且未充分探索的问题，现有方法缺乏对特征局部一致性和调和性的深入分析框架，这限制了模型的理论理解和实际应用。因此，该研究旨在填补这一空白，提供一种新的理论视角来改进图神经网络的设计和分析。",
      "method": "论文引入了一个胞层理论框架，用于建模和分析图架构中节点特征和边权重的局部一致性与调和性。通过使用层结构来跟踪局部特征的对齐和一致性，该框架为特征扩散和聚合提供了拓扑视角，从而揭示训练过程中的动态行为。此外，受拓扑数据分析的启发，提出了一个多尺度扩展方法，以捕捉图模型中的层次特征交互，结合几何和拓扑结构与定义其上的学习信号进行联合表征。该方法不依赖特定数据集或模型架构，而是强调理论框架构建。",
      "result": "摘要未明确说明具体的实验数据或性能指标。该论文主要提供了一个理论框架和见解，未来可在节点分类、子结构检测和社区检测等传统任务中应用和验证，但无具体与基线方法的对比或准确率提升等信息。",
      "conclusion": "该论文的主要贡献是提出了一个基于胞层理论和拓扑视角的框架，用于联合表征几何和拓扑深度学习架构中的特征一致性和扩散行为。这为理解图神经网络提供了新的理论工具，具有重要的学术价值，能促进模型设计和分析。通过多尺度扩展，方法能捕捉层次特征交互，为未来研究提供见解，潜在局限性在于框架理论性较强，需要进一步实验验证，未来工作可关注实际应用和算法实现。",
      "tags": [
        "Sheaf Theory",
        "Topological Data Analysis",
        "Graph Neural Models",
        "Feature Diffusion",
        "Multi-scale Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:05.730542Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21205",
    "title": "Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling",
    "authors": [
      "Eunjung Yeo",
      "Julie M. Liss",
      "Visar Berisha",
      "David R. Mortensen"
    ],
    "abstract": "The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21205.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21205",
    "published": "2026-01-29T03:12:11Z",
    "updated": "2026-01-29T03:12:11Z",
    "comment": "10 pages, 4 figures",
    "light_analysis": {
      "overview": "提出一个结合通用音素识别和语言特定音素解释的多语言构音障碍语音评估框架，引入新度量phoneme coverage以提升跨语言评估能力。",
      "motivation": "神经系统疾病导致的构音障碍日益普遍，迫切需要适用于多种语言的自动语音可理解性评估方法。现有方法大多局限于单一语言或无法充分捕捉影响可理解性的语言特定因素，如音系特征差异，这限制了其在多语言临床环境中的实用性和准确性。因此，开发一个能适应多语言、综合考虑语言特定元素的评估框架对改善诊断和康复至关重要。",
      "method": "论文提出一个多语言音素生产评估框架，核心是集成通用音素识别与语言特定音素解释。关键技术包括使用对比音系特征距离进行音素到音素映射和序列对齐，以处理不同语言的音系结构。该框架生成三个度量：音素错误率（PER）、音系特征错误率（PFER）和新提出的对齐无关度量phoneme coverage（PhonCov），旨在通过映射和对齐机制捕捉语言特定的可理解性模式。",
      "result": "在英语、西班牙语、意大利语和泰米尔语上的分析显示，音素错误率（PER）受益于映射和对齐的结合，音系特征错误率（PFER）仅受益于对齐，而phoneme coverage（PhonCov）受益于映射。框架有效捕捉了临床上有意义的可理解性下降模式，与对构音障碍语音的现有观察一致，证明了其在多语言环境中的适用性和准确性，尽管具体数据摘要未明确说明。",
      "conclusion": "该研究贡献了一个多语言构音障碍语音评估框架，通过结合通用和语言特定元素，提升了评估的跨语言适应性和临床相关性。学术上，引入了新度量PhonCov，丰富了语音处理领域的量化方法；实际上，为临床自动化评估提供了工具，支持多语言环境下的诊断。未来工作可扩展到更多语言或优化算法以提高效率。",
      "tags": [
        "Universal Phone Recognition",
        "Language-Specific Phonemic Contrast Modeling",
        "Phoneme Error Rate",
        "Phonological Feature Error Rate",
        "Phoneme Coverage"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:10.192842Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21204",
    "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
    "authors": [
      "Hong Liu",
      "Jiaqi Zhang",
      "Chao Wang",
      "Xing Hu",
      "Linkun Lyu",
      "Jiaqi Sun",
      "Xurui Yang",
      "Bo Wang",
      "Fengcun Li",
      "Yulei Qian",
      "Lingtong Si",
      "Yerui Sun",
      "Rumei Li",
      "Peng Pei",
      "Yuchen Xie",
      "Xunliang Cai"
    ],
    "abstract": "While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21204.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21204",
    "published": "2026-01-29T03:11:19Z",
    "updated": "2026-01-29T03:11:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出扩展嵌入（embedding scaling）作为语言模型稀疏扩展的新维度，优于传统专家扩展（expert scaling）方法。",
      "motivation": "混合专家（MoE）架构已成为大型语言模型稀疏扩展的标准，但面临收益递减和系统级瓶颈问题，限制了效率和性能提升。嵌入扩展作为一种正交维度被探索，以解决现有方法在稀疏扩展中效率不足的挑战，提高模型的可扩展性。摘要未明确说明具体应用场景，但强调了优化稀疏扩展的重要性。",
      "method": "论文通过全面分析和实验探索嵌入扩展效果，识别其优于专家扩展的特定机制，并系统性地特征化关键架构因素，如参数预算、与模型宽度和深度的相互作用。集成定制系统优化和推测性解码，将稀疏性转换为推断加速。基于这些洞察，构建了LongCat-Flash-Lite模型，参数为68.5B，其中超过30B分配给嵌入，约3B参数在训练中被激活。",
      "result": "实验显示，嵌入扩展在特定条件下实现更好的Pareto前沿，提供更优的效率与性能平衡。LongCat-Flash-Lite模型超越参数等价的MoE基线，并在代理性和编码领域展现出与现有相似规模模型的竞争力，尽管分配大量参数到嵌入，但模型仍能高效运行，推断速度得到提升。摘要未提供具体量化指标如准确率，但强调了性能优势。",
      "conclusion": "该研究证明了嵌入扩展作为稀疏扩展策略的有效性，优于专家扩展，为语言模型扩展提供了新学术方向和实际应用价值，特别是在提高推断效率方面。贡献包括识别新扩展维度并集成系统优化，未来工作可能涉及更广泛的领域验证和进一步优化。摘要未明确说明局限性，但推断可能需要更多实验支持。",
      "tags": [
        "Embedding Scaling",
        "Mixture-of-Experts",
        "Sparse Scaling",
        "Speculative Decoding",
        "Language Model"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:21.742113Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21203",
    "title": "Rethinking Self-Training Based Cross-Subject Domain Adaptation for SSVEP Classification",
    "authors": [
      "Weiguang Wang",
      "Yong Liu",
      "Yingjie Gao",
      "Guangyuan Xu"
    ],
    "abstract": "Steady-state visually evoked potentials (SSVEP)-based brain-computer interfaces (BCIs) are widely used due to their high signal-to-noise ratio and user-friendliness. Accurate decoding of SSVEP signals is crucial for interpreting user intentions in BCI applications. However, signal variability across subjects and the costly user-specific annotation limit recognition performance. Therefore, we propose a novel cross-subject domain adaptation method built upon the self-training paradigm. Specifically, a Filter-Bank Euclidean Alignment (FBEA) strategy is designed to exploit frequency information from SSVEP filter banks. Then, we propose a Cross-Subject Self-Training (CSST) framework consisting of two stages: Pre-Training with Adversarial Learning (PTAL), which aligns the source and target distributions, and Dual-Ensemble Self-Training (DEST), which refines pseudo-label quality. Moreover, we introduce a Time-Frequency Augmented Contrastive Learning (TFA-CL) module to enhance feature discriminability across multiple augmented views. Extensive experiments on the Benchmark and BETA datasets demonstrate that our approach achieves state-of-the-art performance across varying signal lengths, highlighting its superiority.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.21203.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21203",
    "published": "2026-01-29T03:08:14Z",
    "updated": "2026-01-29T03:08:14Z",
    "comment": "Accepted to ICASSP 2026",
    "light_analysis": {
      "overview": "本文提出了一种基于自训练的跨受试者域适应框架，融合滤波器组欧几里得对齐和时频增强对比学习，以提升SSVEP信号分类的准确性和泛化能力。",
      "motivation": "在基于稳态视觉诱发电位的脑机接口应用中，准确解码用户意图至关重要，但信号跨受试者的变异性以及获取用户特定标注数据的高成本，严重限制了识别性能。现有方法往往依赖大量标注数据，难以有效处理跨受试者差异，导致模型泛化能力不足。因此，开发高效域适应技术以减少标注依赖并提升跨受试者分类效果，成为本研究的核心动机。",
      "method": "研究提出跨受试者自训练框架，包括滤波器组欧几里得对齐策略以利用SSVEP信号的频率信息。框架分为两阶段：预训练阶段使用对抗学习对齐源和目标分布，双集成自训练阶段精炼伪标签质量。此外，引入时频增强对比学习模块，通过多个增强视图增强特征的可区分性。实验在Benchmark和BETA数据集上进行，模型整合了这些组件以提高分类性能和跨受试者适应能力。",
      "result": "在Benchmark和BETA数据集上的广泛实验表明，该方法在不同信号长度下均实现了最先进的性能，证明了其优越性。摘要未明确说明具体准确率数值，但与基线方法相比，该方法在跨受试者SSVEP分类任务中展现出显著的性能提升和鲁棒性，凸显了其在处理信号变异性方面的有效性。",
      "conclusion": "本研究的主要贡献是提出了一种创新的跨受试者域适应框架，整合自训练、对抗学习和对比学习技术，显著提升了SSVEP分类的准确性和泛化能力。其学术价值在于为域适应问题提供了新思路，实际应用上减少了标注依赖，推动了脑机接口系统的发展。未来工作可探索更多数据增强策略或扩展到其他神经信号分析任务，摘要未明确说明具体局限性。",
      "tags": [
        "Domain Adaptation",
        "Self-Training",
        "Adversarial Learning",
        "Contrastive Learning",
        "Filter-Bank Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:15.365048Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21199",
    "title": "Thinker: A vision-language foundation model for embodied intelligence",
    "authors": [
      "Baiyu Pan",
      "Daqin Luo",
      "Junpeng Yang",
      "Jiyuan Wang",
      "Yixuan Zhang",
      "Hailin Shi",
      "Jichao Jiao"
    ],
    "abstract": "When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21199.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21199",
    "published": "2026-01-29T02:52:08Z",
    "updated": "2026-01-29T02:52:08Z",
    "comment": "IROS 2025, 4 pages, 3 figures",
    "light_analysis": {
      "overview": "论文提出Thinker，一个为具身智能设计的大型视觉语言基础模型，通过构建专用数据集和联合输入关键帧与完整视频序列的方法，有效解决了视角混淆和时间推理中忽略视频结尾信息的问题。",
      "motivation": "研究动机源于大型视觉语言模型在机器人应用中出现的问题，例如容易混淆第一人称和第三人称视角，以及在处理视频时倾向于忽略结尾部分的信息，导致时间推理错误。这些问题对人类而言简单，但对模型来说容易出错，严重影响了模型在具身智能任务中的准确性和可靠性。现有方法可能未针对这些特定挑战进行优化，限制了模型在复杂环境中的表现，因此开发专门针对具身智能的视觉语言模型具有重要实际意义，以提升机器人在感知和规划任务中的性能。",
      "method": "论文的核心方法包括两个部分。首先，构建了一个大规模数据集，专门针对机器人感知和推理，内容涵盖自我视角视频、视觉接地、空间理解和思维链数据，为模型训练提供全面支持。其次，提出了一种简单而有效的输入策略，通过联合使用关键帧和完整视频序列作为输入，增强了模型的视频理解能力。这种方法结合了关键帧的静态信息和完整序列的动态信息，优化了时间推理过程，创新点在于数据集针对性设计和技术路线的简洁高效性。",
      "result": "主要实验结果显示，Thinker模型在两个最常用的任务规划基准数据集上取得了最先进的结果，表明模型在具身智能任务中性能优越。尽管摘要未提供具体性能指标如准确率或效率改进数据，但“state-of-the-art”一词暗示了模型相比基线方法有显著提升。实验结果验证了所提数据集和联合输入方法的有效性，为领域内性能评估提供了新基准，支持其在复杂任务中的鲁棒性和准确性。",
      "conclusion": "论文的主要贡献是提出Thinker模型，通过专用数据集和联合输入方法解决了具身智能中的视角混淆和时间推理问题。学术上，该研究推动了视觉语言模型在机器人领域的应用，提供了新的数据集和训练策略；实际上，它提升了机器人系统的任务规划能力，增强了自主性和适应性。局限性摘要未明确说明，但未来工作可能包括扩展到更多场景或优化计算资源，以进一步推动实际部署和应用。",
      "tags": [
        "Vision-Language Model",
        "Embodied Intelligence",
        "Video Understanding",
        "Key Frame Extraction",
        "Task Planning"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:11.779710Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21193",
    "title": "Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval",
    "authors": [
      "Zecheng Zhao",
      "Zhi Chen",
      "Zi Huang",
      "Shazia Sadiq",
      "Tong Chen"
    ],
    "abstract": "Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\\times$ in full-corpus retrieval.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.21193.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21193",
    "published": "2026-01-29T02:49:33Z",
    "updated": "2026-01-29T02:49:33Z",
    "comment": "10 pages",
    "light_analysis": {
      "overview": "提出GRDR方法，通过多视图语义ID和共享码本优化生成式检索，显著提升两阶段文本到视频检索的效率和准确性。",
      "motivation": "文本到视频检索在视频平台中至关重要，但现有密集检索方法虽然准确，计算和存储成本高，难以扩展到大规模实时应用。因此，常采用两阶段检索：先由召回模型快速筛选候选池，再用密集检索器重排。然而，生成式检索作为召回模型时存在语义模糊性（每个视频被强制分配单一语义ID）和跨模态不对齐（语义ID仅基于视觉特征，缺乏文本监督），限制了整体性能，需要改进以提升召回质量。",
      "method": "GRDR方法设计了一个新颖的生成式检索技术。它引入查询引导的多视图分词器，为每个视频分配多个语义ID，以捕捉视频的多样语义方面。通过共享码本联合训练分词器和生成式检索器，将语义ID作为文本和视频之间的语义桥梁，确保跨模态对齐。在推理阶段，使用trie约束解码高效生成紧凑候选集，然后由密集模型进行细粒度重排，从而优化两阶段检索流程。",
      "result": "在文本到视频检索基准测试中，GRDR方法取得了显著效果。它在准确性上与先进密集检索器相当，证明了召回质量提升。同时，索引存储需求降低了一个数量级，全库检索速度加速高达300倍。与基线方法相比，GRDR在保持高准确性的同时，显著提高了效率，减少了资源消耗，适用于大规模应用。",
      "conclusion": "GRDR方法通过多视图语义ID和联合训练机制，有效解决了生成式检索在召回中的语义模糊和跨模态不对齐问题，提升了两阶段检索性能。这项工作具有学术价值，为跨模态检索提供了新思路，并具备实际应用潜力，能推动大规模视频检索系统的部署。未来工作可探索分词器的进一步优化或扩展到其他模态检索任务。",
      "tags": [
        "Generative Retrieval",
        "Dense Reranking",
        "Multi-View Semantic IDs",
        "Text-to-Video Retrieval",
        "Trie Constrained Decoding"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:15.509313Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21192",
    "title": "Do Reasoning Models Enhance Embedding Models?",
    "authors": [
      "Wun Yu Chan",
      "Shaojin Chen",
      "Huihao Jing",
      "Kwun Hang Lau",
      "Elton Chun-Chai Li",
      "Zihao Wang",
      "Haoran Li",
      "Yangqiu Song"
    ],
    "abstract": "State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning. Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold's local geometry reorganization and reversible coordinate basis drift, it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term **Manifold Realignment**. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.21192.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21192",
    "published": "2026-01-29T02:48:34Z",
    "updated": "2026-01-29T02:48:34Z",
    "comment": "10 main pages, 18 appendix pages, 13 figures, 11 tables, 4 prompts",
    "light_analysis": {
      "overview": "论文通过HRSA框架揭示推理模型优化不改变语义表示全局结构，导致嵌入模型初始化无性能提升。",
      "motivation": "研究动机基于当前嵌入模型常从解码器大型语言模型通过对比学习衍生，而推理模型通过可验证奖励强化学习训练的出现。本研究旨在解决推理模型作为嵌入模型初始化时是否提供更优语义表示的实际问题。这个问题的重要性在于评估推理能力增强是否转化为语义优势，现有方法可能假设推理模型会改进嵌入，但缺乏系统验证，因此本研究填补了这一空白。",
      "method": "研究方法包括使用MTEB和BRIGHT数据集评估嵌入模型性能，对比基础模型与RLVR调整后模型在相同训练配方下的表现。关键创新是提出分层表示相似性分析（HRSA）框架，从表示、几何和功能三个层面分解相似性，以分析模型间差异。通过HRSA，研究人员揭示了Manifold Realignment现象，即后续对比学习驱动模型间强对齐，从而深入探讨RLVR优化对语义表示的影响。",
      "result": "主要实验结果显示，在MTEB和BRIGHT基准测试中，RLVR初始化嵌入模型与基础模型相比没有一致性能优势，表现为null effect。HRSA分析揭示RLVR导致潜在流形的局部几何重组和可逆坐标基漂移，但保留全局几何和线性读出。这使得后续对比学习促使模型间对齐，性能指标未显示提升，与基线方法对比无明显差异，具体数据未在摘要中提供。",
      "conclusion": "论文的结论指出，通过HRSA框架发现RLVR优化不改变语义景观全局结构，仅优化现有景观内的轨迹，与监督微调形成对比。这提供了对模型优化机制的新学术见解，有助于指导嵌入模型训练的实际应用。潜在局限性包括摘要未明确说明具体应用限制，未来工作可能探索其他优化方法对语义表示的影响或进一步验证该发现。",
      "tags": [
        "Large Language Model",
        "Contrastive Learning",
        "Reinforcement Learning with Verifiable Rewards",
        "Representation Similarity Analysis",
        "Manifold Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:21.981879Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.21191",
    "title": "From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning",
    "authors": [
      "Xiulin Yang",
      "Heidi Getz",
      "Ethan Gotlieb Wilcox"
    ],
    "abstract": "What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.21191.pdf",
    "abs_url": "https://arxiv.org/abs/2601.21191",
    "published": "2026-01-29T02:42:12Z",
    "updated": "2026-01-29T02:42:12Z",
    "comment": "Jan ARR under review",
    "light_analysis": {
      "overview": "论文通过跨语言分析发现功能词的频率和结构关联是神经网络学习语言分层结构的关键统计线索，揭示了统计条件对语言习得的重要性。",
      "motivation": "该研究旨在解决语言习得中从线性输入到分层结构的统计条件问题，探索功能词如何支持这一过程。动机源于功能词因其高频率、句法关联和边界对齐而被假设在语言学习中起关键作用，但现有研究缺乏系统实证验证其跨语言普遍性和相对贡献。问题重要因为它有助于理解AI和认知科学中的语言学习机制，填补了现有方法在量化统计属性影响方面的不足。",
      "method": "研究方法包括跨语言语料库分析，验证功能词的三种统计属性（高频率、句法关联、边界对齐）在186种语言中的普遍存在；然后结合反事实语言建模和消融实验，构建不同语言变体以测试属性对神经网络学习的影响。关键创新点在于使用实验方法量化各属性的贡献，模型涉及神经学习者（如神经网络语言模型），通过对比分析揭示统计线索的作用机制。",
      "result": "实验结果显示，保留所有三种属性的语言变体更容易被神经网络学习者习得，其中频率和结构关联的贡献显著大于边界对齐。后续探测和消融分析表明，不同学习条件导致对功能词的系统性不同依赖，说明类似性能可能源于不同的内部机制。摘要未明确说明具体性能指标，但通过对比实验突出了属性间的相对重要性，提供了统计条件影响语言学习的实证证据。",
      "conclusion": "研究的主要贡献在于验证了功能词统计属性的跨语言普遍性，并证明它们在神经网络语言学习中的关键作用，特别是频率和结构关联的核心地位。学术价值在于为语言习得理论提供了实证支持，推动了统计学习在AI中的应用；实际意义可能包括改进自然语言处理模型的训练策略。未来工作可扩展实验到更多语言或探索其他统计线索，但摘要未明确说明局限性。",
      "tags": [
        "Function Words",
        "Statistical Learning",
        "Language Modeling",
        "Ablation Experiments",
        "Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:38.878105Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.20176",
    "title": "Causal-Driven Feature Evaluation for Cross-Domain Image Classification",
    "authors": [
      "Chen Cheng",
      "Ang Li"
    ],
    "abstract": "Out-of-distribution (OOD) generalization remains a fundamental challenge in real-world classification, where test distributions often differ substantially from training data. Most existing approaches pursue domain-invariant representations, implicitly assuming that invariance implies reliability. However, features that are invariant across domains are not necessarily causally effective for prediction.   In this work, we revisit OOD classification from a causal perspective and propose to evaluate learned representations based on their necessity and sufficiency under distribution shift. We introduce an explicit segment-level framework that directly measures causal effectiveness across domains, providing a more faithful criterion than invariance alone.   Experiments on multi-domain benchmarks demonstrate consistent improvements in OOD performance, particularly under challenging domain shifts, highlighting the value of causal evaluation for robust generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.20176.pdf",
    "abs_url": "https://arxiv.org/abs/2601.20176",
    "published": "2026-01-28T02:17:42Z",
    "updated": "2026-01-29T03:28:15Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "本文从因果视角提出一种特征评估框架，用于提升跨领域图像分类的分布外泛化性能。",
      "motivation": "现实世界中的图像分类常面临分布外泛化挑战，因为测试数据分布可能与训练数据不同。现有方法多追求领域不变表示，假设不变性等同于可靠性，但跨领域不变的特征未必对预测有因果效应，导致泛化失败。因此，需要从因果角度重新评估特征有效性，以解决现有方法在鲁棒性上的不足，确保模型在真实分布变化下仍能可靠预测。",
      "method": "论文基于因果视角，提出一种评估学习表示必要性和充分性的框架。核心创新是引入显式的片段级结构，直接测量跨领域的因果有效性，而非仅依赖不变性假设。该方法通过更准确地评估特征对预测的因果贡献，指导模型训练以提高泛化能力。摘要未明确说明具体数据集或模型架构，但提及应用于多领域基准测试，以验证其技术路线。",
      "result": "在多个跨领域基准数据集上的实验表明，该方法在分布外性能上取得一致改进，尤其在挑战性领域偏移下提升显著，凸显了因果评估对鲁棒泛化的价值。与基于不变性的基线方法相比，该方法展现出更好的泛化能力，尽管摘要未提供具体数值指标，但强调了实验结果的有效性。",
      "conclusion": "本研究的主要贡献是提出了一个因果驱动的特征评估框架，为跨领域图像分类提供了新视角，强调因果有效性比单纯不变性更重要。其学术价值在于推动了鲁棒机器学习理论的发展，实际应用上能提升模型在真实世界变化下的可靠性。摘要未明确说明局限性或未来工作方向，但可合理推断未来可能扩展到其他任务或深化因果机制分析。",
      "tags": [
        "Out-of-distribution Generalization",
        "Causal Inference",
        "Feature Evaluation",
        "Cross-domain Classification",
        "Domain Shift"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:54.712190Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.20138",
    "title": "Scaling Next-Brain-Token Prediction for MEG",
    "authors": [
      "Richard Csaky"
    ],
    "abstract": "We present a large autoregressive model for source-space MEG that scales next-token prediction to long context across datasets and scanners: handling a corpus of over 500 hours and thousands of sessions across the three largest MEG datasets. A modified SEANet-style vector-quantizer reduces multichannel MEG into a flattened token stream on which we train a Qwen2.5-VL backbone from scratch to predict the next brain token and to recursively generate minutes of MEG from up to a minute of context. To evaluate long-horizon generation, we introduce task-matched tests: (i) on-manifold stability via generated-only drift compared to the time-resolved distribution of real sliding windows, and (ii) conditional specificity via correct context versus prompt-swap controls using a neurophysiologically grounded metric set. We train on CamCAN and Omega and run all analyses on held-out MOUS, establishing cross-dataset generalization. Across metrics, generations remain relatively stable over long rollouts and are closer to the correct continuation than swapped controls. Code available at: https://github.com/ricsinaruto/brain-gen.",
    "categories": [
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.20138.pdf",
    "abs_url": "https://arxiv.org/abs/2601.20138",
    "published": "2026-01-28T00:00:23Z",
    "updated": "2026-01-29T10:17:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种用于源空间脑磁图（MEG）数据的大型自回归模型，实现长上下文的下一个大脑标记预测和递归生成，并展示跨数据集泛化能力。",
      "motivation": "摘要未明确说明研究动机。基于内容，该研究旨在解决MEG数据处理中的长上下文预测挑战，现有方法可能难以处理大规模跨数据集和长序列生成。MEG数据分析在神经科学中至关重要，但传统方法在跨设备泛化和长期生成方面存在不足，因此需要新模型来提升预测准确性和生成稳定性，以支持更精准的脑活动分析。",
      "method": "论文采用修改的SEANet风格向量量化器，将多通道MEG数据压缩为扁平的标记流，以处理超过500小时和数千个会话的语料库。在此基础上，从头训练Qwen2.5-VL主干网络，用于预测下一个大脑标记，并能从长达一分钟的上下文中递归生成分钟的MEG数据。关键创新包括高效的量化处理和自回归生成框架，适用于大规模数据集如CamCAN和Omega。",
      "result": "通过引入任务匹配测试评估长期生成效果，包括流形稳定性（比较生成漂移与真实滑动窗口分布）和条件特异性（使用神经生理学指标比较正确上下文与提示交换控制）。在保留数据集MOUS上进行实验，结果显示生成序列在长期推出中保持相对稳定，且在所有指标上比交换控制更接近正确延续，验证了跨数据集泛化能力。",
      "conclusion": "该研究的主要贡献是开发了一个可扩展的自回归模型，用于MEG数据的下一个标记预测和生成，实现了跨数据集的泛化，为神经科学研究提供了新的工具，有助于分析脑活动模式和潜在应用。未来工作可进一步优化模型效率或扩展到其他神经成像数据类型，以提升实际应用价值。",
      "tags": [
        "Autoregressive Model",
        "Vector Quantization",
        "MEG Data Generation",
        "Long-Context Prediction",
        "Cross-Dataset Generalization"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:05.964977Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.20090",
    "title": "Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control",
    "authors": [
      "Amirmohammad Farzaneh",
      "Salvatore D'Oro",
      "Osvaldo Simeone"
    ],
    "abstract": "Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.20090.pdf",
    "abs_url": "https://arxiv.org/abs/2601.20090",
    "published": "2026-01-27T22:18:57Z",
    "updated": "2026-01-29T06:09:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种共形反事实生成框架，用于在基于大语言模型的自主控制中提供可靠性保证的反事实推理。",
      "motivation": "在LLM驱动的自主控制中，用户意图通过代理转化为环境行动，但结果后用户常想探索不同意图表达的后果。现有方法如朴素重新执行缺乏形式化保证，导致反事实分析不可靠。本研究旨在解决这一问题，通过提供有高概率准确性保证的框架，增强系统透明度和用户信任，推动智能代理的可解释性发展。",
      "method": "论文提出共形反事实生成框架。首先，将用户、LLM代理和环境的闭环交互建模为结构因果模型。然后，利用测试时间缩放通过概率溯因生成多个候选反事实结果。通过离线校准阶段，应用共形预测技术，确保生成的结果集合以高概率包含真实反事实结果。这种方法避免了简单重执行，提供了形式化的可靠性保证。",
      "result": "实验在无线网络控制用例上进行，展示了共形反事实生成框架的性能。与朴素重新执行基线相比，CCG显示出显著优势，提高了反事实结果的可靠性。然而，摘要未明确说明具体性能指标如准确率或效率改进，仅表示有积极效果。未来研究可量化这些优势并扩展到其他应用领域。",
      "conclusion": "本研究的主要贡献是开发了共形反事实生成框架，为基于LLM的自主控制提供形式化可靠性保证。学术上，它结合了因果推理和共形预测，推动了反事实推理研究。实际应用中，该框架帮助用户理解和调整意图表达，增强系统可解释性和用户交互体验。未来工作可能包括算法优化和扩展到更多控制场景。",
      "tags": [
        "Large Language Model",
        "Counterfactual Reasoning",
        "Structural Causal Model",
        "Conformal Prediction",
        "Autonomous Control"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:30.831150Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.19967",
    "title": "Perturbation-Induced Linearization: Constructing Unlearnable Data with Solely Linear Classifiers",
    "authors": [
      "Jinlin Liu",
      "Wei Chen",
      "Xiaojin Zhang"
    ],
    "abstract": "Collecting web data to train deep models has become increasingly common, raising concerns about unauthorized data usage. To mitigate this issue, unlearnable examples introduce imperceptible perturbations into data, preventing models from learning effectively. However, existing methods typically rely on deep neural networks as surrogate models for perturbation generation, resulting in significant computational costs. In this work, we propose Perturbation-Induced Linearization (PIL), a computationally efficient yet effective method that generates perturbations using only linear surrogate models. PIL achieves comparable or better performance than existing surrogate-based methods while reducing computational time dramatically. We further reveal a key mechanism underlying unlearnable examples: inducing linearization to deep models, which explains why PIL can achieve competitive results in a very short time. Beyond this, we provide an analysis about the property of unlearnable examples under percentage-based partial perturbation. Our work not only provides a practical approach for data protection but also offers insights into what makes unlearnable examples effective.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.19967.pdf",
    "abs_url": "https://arxiv.org/abs/2601.19967",
    "published": "2026-01-27T17:26:41Z",
    "updated": "2026-01-29T15:37:51Z",
    "comment": "This paper has been accepted to ICLR 2026",
    "light_analysis": {
      "overview": "论文提出了Perturbation-Induced Linearization (PIL)方法，使用线性代理模型高效生成不可学习数据，显著降低计算成本。",
      "motivation": "随着收集网络数据训练深度模型的普及，数据未经授权使用问题日益严重。现有方法通过添加微小扰动制作不可学习示例，但依赖深度神经网络作为代理模型，导致高计算开销。这限制了实际部署效率，因此需开发更轻量级的方法，以在保护数据隐私的同时减少资源消耗。",
      "method": "PIL方法的核心创新是仅使用线性代理模型生成数据扰动，而非传统的深度模型。通过诱导深度模型线性化，简化扰动生成过程，降低计算复杂度。虽然摘要未明确说明具体模型架构或数据集，但该方法基于线性分类器构建，关键机制是将复杂的非线性学习问题转化为线性处理，提高效率。",
      "result": "实验显示，PIL在生成不可学习数据方面，性能与现有基于代理方法相当或更好，同时计算时间大幅减少。摘要提到显著降低计算时间，但未提供具体数据指标。这表明PIL在保持效果的同时，优于基线方法，验证了其高效性和实用性。",
      "conclusion": "本研究贡献在于提出了计算高效的PIL方法，为数据保护提供实用工具，并揭示了不可学习示例通过线性化机制起效的深层原理。学术价值在于简化数据保护技术，实际应用价值在于降低部署成本。未来工作可能涉及扩展PIL到更复杂数据场景或分析其鲁棒性。",
      "tags": [
        "Unlearnable Examples",
        "Linear Classifiers",
        "Perturbation Generation",
        "Linearization",
        "Data Protection"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:31.770293Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.19965",
    "title": "Modeling Cascaded Delay Feedback for Online Net Conversion Rate Prediction: Benchmark, Insights and Solutions",
    "authors": [
      "Mingxuan Luo",
      "Guipeng Xv",
      "Sishuo Chen",
      "Xinyu Li",
      "Li Zhang",
      "Zhangming Chan",
      "Xiang-Rong Sheng",
      "Han Zhu",
      "Jian Xu",
      "Bo Zheng",
      "Chen Lin"
    ],
    "abstract": "In industrial recommender systems, conversion rate (CVR) is widely used for traffic allocation, but it fails to fully reflect recommendation effectiveness because it ignores refund behavior. To better capture true user satisfaction and business value, net conversion rate (NetCVR), defined as the probability that a clicked item is purchased and not refunded, has been proposed.Unlike CVR, NetCVR prediction involves a more complex multi-stage cascaded delayed feedback process. The two cascaded delays from click to conversion and from conversion to refund have opposite effects, making traditional CVR modeling methods inapplicable. Moreover, the lack of open-source datasets and online continuous training schemes further hinders progress in this area.To address these challenges, we introduce CASCADE (Cascaded Sequences of Conversion and Delayed Refund), the first large-scale open dataset derived from the Taobao app for online continuous NetCVR prediction. Through an in-depth analysis of CASCADE, we identify three key insights: (1) NetCVR exhibits strong temporal dynamics, necessitating online continuous modeling; (2) cascaded modeling of CVR and refund rate outperforms direct NetCVR modeling; and (3) delay time, which correlates with both CVR and refund rate, is an important feature for NetCVR prediction.Based on these insights, we propose TESLA, a continuous NetCVR modeling framework featuring a CVR-refund-rate cascaded architecture, stage-wise debiasing, and a delay-time-aware ranking loss. Extensive experiments demonstrate that TESLA consistently outperforms state-of-the-art methods on CASCADE, achieving absolute improvements of 12.41 percent in RI-AUC and 14.94 percent in RI-PRAUC on NetCVR prediction. The code and dataset are publicly available at https://github.com/alimama-tech/NetCVR.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.19965.pdf",
    "abs_url": "https://arxiv.org/abs/2601.19965",
    "published": "2026-01-27T13:24:32Z",
    "updated": "2026-01-29T07:50:32Z",
    "comment": "This paper has been accepted by the ACM Web Conference (WWW) 2026. This is the camera-ready version. Please refer to the published version for citation once available",
    "light_analysis": {
      "overview": "本论文提出TESLA框架，通过级联CVR和退款率建模及延迟时间感知损失，实现高效在线净转换率预测，并发布首个大规模开源数据集CASCADE。",
      "motivation": "工业推荐系统中，转换率（CVR）用于流量分配，但忽略退款行为，无法真实反映推荐效果和用户满意度。净转换率（NetCVR）定义为点击商品被购买且不退款的概率，更能准确衡量商业价值，但其预测涉及从点击到购买和购买到退款的两阶段级联延迟反馈，延迟效应相反，导致传统CVR建模方法失效。此外，缺乏公开数据集和在线连续训练方案严重阻碍了该领域的发展。",
      "method": "基于对CASCADE数据集的分析，论文识别出NetCVR具有强时间动态性、级联建模CVR和退款率更优、延迟时间是重要特征。为此，提出TESLA框架，采用CVR-退款率级联架构，先分别预测CVR和退款率再组合为NetCVR。引入阶段去偏技术处理延迟反馈中的偏差，并设计延迟时间感知排序损失函数，利用延迟时间与转换和退款率的相关性进行优化。该方法强调在线连续建模，以适应NetCVR的动态变化。",
      "result": "实验在CASCADE数据集上进行，TESLA框架与现有最佳方法对比，在NetCVR预测任务中表现优异。具体地，RI-AUC指标实现12.41%的绝对提升，RI-PRAUC指标提升14.94%。这些结果验证了TESLA在级联架构、阶段去偏和延迟时间感知损失方面的有效性，显著超越基线方法，证明了其在处理复杂延迟反馈问题上的优势。",
      "conclusion": "本论文的主要贡献是提出了TESLA连续NetCVR建模框架和CASCADE开源数据集，解决了NetCVR预测中的多阶段延迟挑战。研究具有重要学术价值，为延迟反馈建模提供新方法，并推动推荐系统优化。实际应用中，能提升商业推荐效果和用户满意度。未来工作可扩展数据集到其他场景，并进一步探索在线训练的效率改进。",
      "tags": [
        "Net Conversion Rate Prediction",
        "Cascaded Modeling",
        "Delay Feedback",
        "Online Continuous Learning",
        "Ranking Loss"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:10.074066Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.18973",
    "title": "When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control",
    "authors": [
      "Nima Leclerc",
      "Chris Miller",
      "Nicholas Brawand"
    ],
    "abstract": "Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $>40\\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.18973.pdf",
    "abs_url": "https://arxiv.org/abs/2601.18973",
    "published": "2026-01-26T21:16:11Z",
    "updated": "2026-01-29T03:49:25Z",
    "comment": "28 pages, 11 figures",
    "light_analysis": {
      "overview": "论文推导了元学习在量子控制中的标度定律下界，提供了一个定量标准来判断适应是否值得，从而优化自适应控制器决策。",
      "motivation": "量子硬件存在固有的设备异质性和环境漂移，这导致在实际应用中需选择次优的非自适应控制器或昂贵的每设备重新校准。这一问题在量子计算中至关重要，因为传统方法无法量化适应成本与收益，使得在高成本校准与性能损失间权衡困难，亟需系统性框架来指导自适应策略。",
      "method": "研究通过推导元学习的标度定律下界，量化了适应增益（任务特定梯度步带来的保真度预期改进）。核心创新在于展示适应增益随梯度步数呈指数饱和、随任务方差线性缩放，该方法基于元学习框架，利用梯度优化步骤提供定量标准，适用于自适应控制场景，但摘要未明确说明具体模型架构或数据集细节。",
      "result": "在量子门校准实验中，对于低方差任务，适应增益可忽略不计；但在极端分布外条件下（噪声为训练时的10倍），两量子比特门的保真度提升超过40%。进一步在经典线性二次控制中验证，证实这些标度定律源自一般优化几何而非量子特定物理，增强了其普适性和可靠性。",
      "conclusion": "论文提供了一个可转移的框架，用于自适应控制中的决策，基于标度定律判断适应价值。学术上深化了对元学习优化行为的理解，应用上有助于减少云量子处理器的校准时间，提高效率；未来工作可能扩展到其他控制领域或理论扩展。",
      "tags": [
        "Meta-Learning",
        "Quantum Control",
        "Scaling Laws",
        "Adaptation Gain",
        "Task Variance"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:57.716641Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.17915",
    "title": "Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation",
    "authors": [
      "Saurabh Jha",
      "Rohan Arora",
      "Bhavya",
      "Noah Zheutlin",
      "Paulina Toro Isaza",
      "Laura Shwartz",
      "Yu Deng",
      "Daby Sow",
      "Ruchi Mahindru",
      "Ruchir Puri"
    ],
    "abstract": "LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.   We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.17915.pdf",
    "abs_url": "https://arxiv.org/abs/2601.17915",
    "published": "2026-01-25T17:27:19Z",
    "updated": "2026-01-29T18:18:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出EoG框架，通过依赖图和信念传播来提升大型语言模型在开放调查中的推理准确性和一致性。",
      "motivation": "研究动机在于大型语言模型代理在静态环境中表现良好，但在开放调查中常失败，这类调查需要从海量异构数据中迭代挖掘证据构建解释，并存在隐藏的依赖结构，如实体互动和信号协变。现有方法如ReAct-style代理存在不足：其检索-总结-推理循环使结论对探索顺序敏感，导致运行不一致；缺乏自主检查假设和信念记录机制；语义推理与控制职责纠缠，导致执行错误和计划漂移降低推理质量。这些问题使得代理在关键场景如IT诊断中可靠性不足，限制了实际应用。",
      "method": "论文将调查问题建模为依赖图上的归纳推理，提出EoG框架。在该框架中，LLM负责有界的本地证据挖掘和标签任务（区分原因与症状），而一个确定性控制器管理图的遍历、状态跟踪和信念传播，以计算最小解释前沿。关键创新点在于分离推理与控制任务，利用信念传播来处理依赖结构，避免探索顺序带来的偏差。数据集使用ITBench诊断任务，框架通过图结构实现高效的证据整合和推理稳定化。",
      "result": "在ITBench诊断任务中，EoG框架相比ReAct基线在准确性和运行一致性方面均表现更优。具体地，在Majority-at-k entity F1指标上，EoG取得了7倍的平均增益，这表明它能有效减少运行不一致性，提高推理的确定性。此外，框架在避免探索顺序敏感性和提升整体性能方面效果显著，克服了ReAct代理的脆弱性问题，为开放调查任务提供了更可靠的解决方案。",
      "conclusion": "本论文的主要贡献是提出EoG框架，通过结合依赖图和信念传播来改进LLM在开放调查中的推理能力。学术价值在于引入图结构和信念传播机制，解决了现有方法在隐藏依赖处理和信念管理上的不足。实际应用价值体现在IT诊断等需要调查和解释构建的领域，有助于提高自动推理的准确性和一致性。未来工作可能包括扩展框架到其他调查任务或优化信念传播算法，以处理更复杂的依赖关系和数据规模。",
      "tags": [
        "Large Language Model",
        "Belief Propagation",
        "Abductive Reasoning",
        "Dependency Graph",
        "Local Reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:22.826781Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.17868",
    "title": "VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding",
    "authors": [
      "Zhihao He",
      "Tieyuan Chen",
      "Kangyu Wang",
      "Ziran Qin",
      "Yang Shao",
      "Chaofan Gan",
      "Shijie Li",
      "Zuxuan Wu",
      "Weiyao Lin"
    ],
    "abstract": "Current Video Large Language Models (Video LLMs) typically encode frames via a vision encoder and employ an autoregressive (AR) LLM for understanding and generation. However, this AR paradigm inevitably faces a dual efficiency bottleneck: strictly unidirectional attention compromises understanding efficiency by hindering global spatiotemporal aggregation, while serial decoding restricts generation efficiency. To address this, we propose VidLaDA, a Video LLM based on Diffusion Language Models (DLMs) that leverages bidirectional attention to unlock comprehensive spatiotemporal modeling and decode tokens in parallel. To further mitigate the computational overhead of diffusion decoding, we introduce MARS-Cache, an acceleration strategy that prunes redundancy by combining asynchronous visual cache refreshing with frame-wise chunk attention. Experiments show VidLaDA rivals state-of-the-art AR baselines (e.g., Qwen2.5-VL and LLaVA-Video) and outperforms DLM baselines, with MARS-Cache delivering over 12x speedup without compromising accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.17868.pdf",
    "abs_url": "https://arxiv.org/abs/2601.17868",
    "published": "2026-01-25T15:02:01Z",
    "updated": "2026-01-29T11:14:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "VidLaDA是一种基于扩散语言模型的视频大语言模型，通过双向注意力和MARS-Cache策略提升视频理解与生成的效率。",
      "motivation": "当前视频大语言模型普遍采用自回归范式，但存在双重效率瓶颈：单向注意力机制限制了全局时空信息的聚合，导致理解效率低下；同时，序列解码方式阻碍了生成速度的提升。这些问题影响了视频处理的实际应用，尤其是在需要实时或高效分析的场景中。现有方法如AR模型在平衡精度和速度方面存在不足，因此需要创新技术来克服这些限制，实现更高效的视频理解和生成。",
      "method": "论文提出VidLaDA，一种基于扩散语言模型的视频大语言模型，利用双向注意力机制实现全面的时空建模，支持并行解码以提高效率。核心创新包括引入MARS-Cache加速策略，该策略通过结合异步视觉缓存刷新和帧级分块注意力，剪枝计算冗余，从而显著降低扩散解码的计算开销。VidLaDA架构专注于视频任务，避免传统自回归模型的序列依赖，为高效视频处理提供新路径。",
      "result": "实验表明，VidLaDA在视频理解任务中性能匹敌state-of-the-art自回归基线模型（如Qwen2.5-VL和LLaVA-Video），并优于其他扩散语言模型基线。MARS-Cache策略带来超过12倍的速度提升，且准确性未受影响，验证了该方法在效率优化上的有效性。这些结果突显了VidLaDA在保持高精度的同时大幅提升处理速度的优势。",
      "conclusion": "本研究通过VidLaDA模型和MARS-Cache策略，成功解决了视频大语言模型的效率瓶颈，为高效视频理解与生成提供了创新方案。学术上，展示了扩散模型在视频时空建模中的潜力，推动了相关技术发展；实际应用方面，能促进实时视频分析系统的开发。工作开源促进社区协作，未来可探索更多优化方法或扩展到其他多模态任务。",
      "tags": [
        "Diffusion Language Models",
        "Video Large Language Models",
        "Bidirectional Attention",
        "MARS-Cache",
        "Parallel Decoding"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:24.229307Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.17865",
    "title": "D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models",
    "authors": [
      "Jia Gu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.17865.pdf",
    "abs_url": "https://arxiv.org/abs/2601.17865",
    "published": "2026-01-25T14:59:09Z",
    "updated": "2026-01-29T03:19:56Z",
    "comment": "12 pages, 10 figures. Accepted by WWW'26",
    "light_analysis": {
      "overview": "该论文揭示了大型语言模型在采样行为中存在多样性-稳定性权衡，并区分了D-模型和E-模型，为实际应用中的模型选择提供指导。",
      "motivation": "本研究旨在解决大型语言模型的细粒度采样概率是否忠实于任务级目标分布的开放问题。现有方法虽然能生成近似真实世界分布的样本，但缺乏对采样概率与任务要求对齐的系统评估。这个问题至关重要，因为它直接影响到下游应用如推荐系统、搜索和代码生成的可靠性；如果采样概率未能准确对齐任务分布，可能导致性能下降或不可预测的行为，从而限制了LLM在实际场景中的应用效果。",
      "method": "本研究采用受控分布采样模拟来分析LLM的token预测概率变异性，关键创新在于区分出两种模型类型：D-模型（如Qwen-2.5）的P_token表现出较大的步进间变异性，与P_task对齐差；E-模型（如Mistral-Small）的P_token更稳定且对齐更好。研究进一步通过下游任务评估如代码生成和推荐来验证这一分类，并分析模型内部属性以探究其机制；该方法不依赖特定数据集，而是聚焦于概率分布模拟和任务性能比较。",
      "result": "实验结果显示，D-模型的P_token变异性高且与任务分布对齐不佳，而E-模型的P_token更稳定且对齐更优；在下游任务中，这种差异导致了系统性的多样性-稳定性权衡：D-模型可能在生成多样输出时有优势，但牺牲了稳定性，E-模型则反之，提供了更可靠的性能。与基线方法对比，该分类揭示了模型行为的内在差异，具体性能指标如准确率或效率改进未明确说明，但强调了权衡对任务结果的影响，为模型选择提供了实证依据。",
      "conclusion": "本论文的主要贡献在于提供了对大型语言模型概率采样行为的基础洞察，通过区分D-模型和E-模型揭示了多样性-稳定性的权衡；学术价值在于增进了对LLM内部机制的理解，应用价值则体现在为推荐、搜索和对话代理等实际场景中的模型选择和配置提供指导，以在不确定环境中平衡多样性与可靠性。潜在局限性包括摘要未明确说明具体模型范围或数据集细节，未来工作可能涉及进一步探究内部机制或扩展到更多模型类型和任务。",
      "tags": [
        "Large Language Model",
        "Sampling Probability",
        "Diversity-Stability Trade-off",
        "Model Alignment",
        "Downstream Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:51.576612Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.18823",
    "title": "VAE with Hyperspherical Coordinates: Improving Anomaly Detection from Hypervolume-Compressed Latent Space",
    "authors": [
      "Alejandro Ascarate",
      "Leo Lebrat",
      "Rodrigo Santa Cruz",
      "Clinton Fookes",
      "Olivier Salvado"
    ],
    "abstract": "Variational autoencoders (VAE) encode data into lower-dimensional latent vectors before decoding those vectors back to data. Once trained, one can hope to detect out-of-distribution (abnormal) latent vectors, but several issues arise when the latent space is high dimensional. This includes an exponential growth of the hypervolume with the dimension, which severely affects the generative capacity of the VAE. In this paper, we draw insights from high dimensional statistics: in these regimes, the latent vectors of a standard VAE are distributed on the `equators' of a hypersphere, challenging the detection of anomalies. We propose to formulate the latent variables of a VAE using hyperspherical coordinates, which allows compressing the latent vectors towards a given direction on the hypersphere, thereby allowing for a more expressive approximate posterior. We show that this improves both the fully unsupervised and OOD anomaly detection ability of the VAE, achieving the best performance on the datasets we considered, outperforming existing methods. For the unsupervised and OOD modalities, respectively, these are: i) detecting unusual landscape from the Mars Rover camera and unusual Galaxies from ground based imagery (complex, real world datasets); ii) standard benchmarks like Cifar10 and subsets of ImageNet as the in-distribution (ID) class.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.18823.pdf",
    "abs_url": "https://arxiv.org/abs/2601.18823",
    "published": "2026-01-25T03:10:24Z",
    "updated": "2026-01-29T07:19:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出使用超球坐标改进变分自编码器的潜空间表示，以提升高维场景下的异常检测性能。",
      "motivation": "本研究旨在解决高维潜空间中变分自编码器（VAE）的异常检测问题。现有标准VAE在高维时，潜向量分布在超球面赤道上，导致超体积指数增长，严重削弱生成能力和异常检测效果。异常检测在真实世界应用（如火星漫游车图像或星系图像分析）中至关重要，而现有方法因潜空间结构限制而表现不佳，因此改进此技术具有重要的实际意义。",
      "method": "论文提出使用超球坐标重新表述VAE的潜变量。核心创新在于通过坐标变换将潜向量压缩到超球面的特定方向，从而增强近似后验的表达能力。该方法基于高维统计学原理，关键步骤包括潜空间的重参数化。实验中使用复杂真实世界数据集（火星漫游车相机图像和星系图像）和标准基准（Cifar10、ImageNet子集），模型架构为VAE变体，重点关注潜空间优化。",
      "result": "实验结果显示，该方法显著提升了VAE在完全无监督和分布外（OOD）异常检测中的性能。在考虑的数据集上，包括火星图像和星系图像，以及Cifar10和ImageNet子集，该方法均达到最佳性能，优于现有基线方法。具体效果体现在更高的检测准确率上，但摘要未提供精确数值指标，仅表明性能改进。",
      "conclusion": "本文通过引入超球坐标，有效解决了高维潜空间中的超体积增长问题，增强了VAE的异常检测能力。这为异常检测领域提供了新的技术路径，具有学术创新价值，并在图像分析等实际应用中展现出潜力。摘要未明确说明局限性，未来工作可进一步验证泛化性或扩展到其他复杂数据集。",
      "tags": [
        "Variational Autoencoder",
        "Anomaly Detection",
        "Hyperspherical Coordinates",
        "Out-of-Distribution Detection",
        "Latent Space Compression"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:06.399245Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.17323",
    "title": "SkyReels-V3 Technique Report",
    "authors": [
      "Debang Li",
      "Zhengcong Fei",
      "Tuanhui Li",
      "Yikun Dou",
      "Zheng Chen",
      "Jiangping Yang",
      "Mingyuan Fan",
      "Jingtao Xu",
      "Jiahua Wang",
      "Baoxuan Gu",
      "Mingshan Chang",
      "Wenjing Cai",
      "Yuqiang Xie",
      "Binjie Mao",
      "Youqiang Zhang",
      "Nuo Pang",
      "Hao Zhang",
      "Yuzhe Jin",
      "Zhiheng Xu",
      "Dixuan Lin",
      "Guibin Chen",
      "Yahui Zhou"
    ],
    "abstract": "Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.   Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.17323.pdf",
    "abs_url": "https://arxiv.org/abs/2601.17323",
    "published": "2026-01-24T06:08:12Z",
    "updated": "2026-01-29T02:45:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "SkyReels-V3是一个基于扩散Transformers和多模态上下文学习的条件视频生成模型，在单一架构中支持图像到视频、视频扩展和音频引导视频生成。",
      "motivation": "视频生成是构建世界模型的基础，多模态上下文推理能力是关键挑战。现有视频生成模型可能在主体身份保留、时间连贯性、叙事一致性或音频视频同步方面存在不足。本研究旨在通过统一框架解决这些问题，以提升视频生成的质量和多样性，满足如影视制作、虚拟角色生成等实际应用需求，并克服现有方法在参考保持和连贯性方面的局限性。",
      "method": "SkyReels-V3基于扩散Transformers构建统一的多模态上下文学习框架。核心方法包括三个生成范式：参考图像到视频合成通过数据处理管道（交叉帧配对、图像编辑、语义重写）增强参考保持；视频扩展集成时空一致性建模和大规模视频理解；音频引导视频生成采用首尾帧插入和关键帧推理重建。训练中采用图像视频混合策略和多分辨率联合优化以提高泛化能力和鲁棒性。",
      "result": "实验评估表明，SkyReels-V3在视觉质量、指令跟随和特定方面指标上达到或接近最先进性能，接近领先的闭源系统。摘要未明确说明具体数据如准确率，但模型在参考保持、时间连贯性和音频视频同步性方面表现出色，显示出对基线方法的显著改进，有效提升了视频生成的实用性和可靠性。",
      "conclusion": "SkyReels-V3通过统一多模态框架实现了高效的视频生成，主要贡献包括单一架构支持多种生成范式、创新的数据处理和训练策略。该研究具有学术价值，推动了视频生成技术的发展，并具有实际应用潜力如娱乐和交互系统。未来工作方向可能包括扩展更多模态或优化具体性能指标。",
      "tags": [
        "Conditional Video Generation",
        "Diffusion Transformers",
        "Multimodal In-context Learning",
        "Reference-based Video Synthesis",
        "Audio-guided Video Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:22.948460Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.16651",
    "title": "Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations",
    "authors": [
      "Lukas Hinterleitner",
      "Loris Schoenegger",
      "Benjamin Roth"
    ],
    "abstract": "Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.16651.pdf",
    "abs_url": "https://arxiv.org/abs/2601.16651",
    "published": "2026-01-23T11:15:20Z",
    "updated": "2026-01-29T10:52:03Z",
    "comment": "Added acknowledgments section and related work on random projection. 8 pages",
    "light_analysis": {
      "overview": "本研究提出贪婪选择模型组件子集的方法，用于LLM训练数据解释，相比全梯度或随机投影更有效且计算高效。",
      "motivation": "大型语言模型（LLM）的基于梯度的实例解释方法因梯度维度巨大而面临计算挑战。在实践中，为了简化计算，影响估计常限于参数子集，但子集选择多基于临时决策，缺乏系统性评估。这导致解释方法的准确性和效率不足，因此系统比较不同低维表示方法对于提升解释技术的可行性和可靠性至关重要。",
      "method": "论文对比了两种创建低维表示的方法：一是选择模型组件的架构信息子集，二是将全梯度投影到低维空间。核心创新在于使用贪婪算法选择子集，并通过新构建的基准在检索任务中评估信息捕获能力。该方法专注于LLM的梯度基解释，但摘要未明确说明具体使用的数据集或模型架构细节。",
      "result": "实验表明，贪婪选择的模型组件子集在检索任务中能更有效地捕获训练数据影响所需的信息，优于使用全梯度或随机投影的方法。此外，该子集选择方法在计算效率上高于随机投影，证实了其在减少计算开销方面的优势。与基线方法的对比显示，目标选择策略在保持解释质量的同时提升了可行性。",
      "conclusion": "论文的主要贡献是证明了目标组件选择作为实用策略，能有效提升大型模型实例解释的计算可行性。研究具有学术价值，为梯度基解释方法的低维表示提供了系统性评估框架；实际应用上，有助于在资源有限的环境中实现高效模型分析。未来工作可探索该方法在其他任务或模型类型的扩展。",
      "tags": [
        "Large Language Model",
        "Gradient-based Methods",
        "Instance-based Explanation",
        "Influence Estimation",
        "Low-dimensional Representation"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:33.223043Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.16272",
    "title": "GR3EN: Generative Relighting for 3D Environments",
    "authors": [
      "Xiaoyan Xing",
      "Philipp Henzler",
      "Junhwa Hur",
      "Runze Li",
      "Jonathan T. Barron",
      "Pratul P. Srinivasan",
      "Dor Verbin"
    ],
    "abstract": "We present a method for relighting 3D reconstructions of large room-scale environments. Existing solutions for 3D scene relighting often require solving under-determined or ill-conditioned inverse rendering problems, and are as such unable to produce high-quality results on complex real-world scenes. Though recent progress in using generative image and video diffusion models for relighting has been promising, these techniques are either limited to 2D image and video relighting or 3D relighting of individual objects. Our approach enables controllable 3D relighting of room-scale scenes by distilling the outputs of a video-to-video relighting diffusion model into a 3D reconstruction. This side-steps the need to solve a difficult inverse rendering problem, and results in a flexible system that can relight 3D reconstructions of complex real-world scenes. We validate our approach on both synthetic and real-world datasets to show that it can faithfully render novel views of scenes under new lighting conditions.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.16272.pdf",
    "abs_url": "https://arxiv.org/abs/2601.16272",
    "published": "2026-01-22T19:10:05Z",
    "updated": "2026-01-29T17:21:35Z",
    "comment": "project page: https://gr3en-relight.github.io/",
    "light_analysis": {
      "overview": "提出GR3EN方法，通过蒸馏视频到视频重照明扩散模型的输出到3D重建，实现对大尺度3D环境场景的可控重照明。",
      "motivation": "本研究旨在解决大尺度3D场景重照明的挑战。现有方法常依赖逆渲染问题，导致在复杂真实世界场景中难以生成高质量结果，限制了在虚拟现实等领域的应用。尽管生成图像和视频扩散模型在重照明方面有进展，但这些技术要么限于2D图像和视频，要么限于单个对象的3D重照明。因此，开发一种能高效处理复杂环境的3D重照明方法至关重要，以克服现有方案的不足并扩展实际应用范围。",
      "method": "GR3EN方法的核心是蒸馏视频到视频重照明扩散模型的输出到一个3D重建中。这绕过了传统逆渲染问题的复杂性，利用生成模型直接产生高质量的重照明结果。关键创新点在于将2D重照明序列映射到3D几何，实现对场景光照的可控调整。摘要未明确说明具体使用的数据集或模型架构，但推断基于扩散模型和3D重建技术，方法灵活适用于真实世界复杂场景。",
      "result": "实验在合成和真实世界数据集上验证了GR3EN的有效性，表明其能忠实渲染场景在新光照条件下的新视图。摘要未提供具体性能指标如准确率数据，但与现有依赖逆渲染的方法相比，该方法能生成更高质量的结果，并避免了解析困难问题，显示出在复杂场景重照明上的可行性。",
      "conclusion": "GR3EN的主要贡献是提出了一种绕过逆渲染问题、基于生成模型蒸馏的3D重照明系统，实现对大尺度环境的灵活光照控制。学术价值在于推进生成模型在3D图形学的应用，实际应用包括虚拟现实和影视特效等领域。未来工作方向可能涉及优化模型效率或扩展光照条件，但摘要未明确说明具体局限性。",
      "tags": [
        "Generative Models",
        "Diffusion Models",
        "3D Relighting",
        "Scene Reconstruction",
        "Video-to-Video Translation"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:45.461067Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.14210",
    "title": "DRIFT: Detecting Representational Inconsistencies for Factual Truthfulness",
    "authors": [
      "Rohan Bhatnagar",
      "Youran Sun",
      "Chi Andrew Zhang",
      "Yixin Wen",
      "Haizhao Yang"
    ],
    "abstract": "LLMs often produce fluent but incorrect answers, yet detecting such hallucinations typically requires multiple sampling passes or post-hoc verification, adding significant latency and cost. We hypothesize that intermediate layers encode confidence signals that are lost in the final output layer, and propose a lightweight probe to read these signals directly from hidden states. The probe adds less than 0.1\\% computational overhead and can run fully in parallel with generation, enabling hallucination detection before the answer is produced. Building on this, we develop an LLM router that answers confident queries immediately while delegating uncertain ones to stronger models. Despite its simplicity, our method achieves SOTA AUROC on 10 out of 12 settings across four QA benchmarks and three LLM families, with gains of up to 13 points over prior methods, and generalizes across dataset shifts without retraining.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.14210.pdf",
    "abs_url": "https://arxiv.org/abs/2601.14210",
    "published": "2026-01-20T18:16:10Z",
    "updated": "2026-01-29T15:25:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种轻量级探针，从LLM中间层检测置信信号，以低成本实现幻觉检测并构建智能路由系统。",
      "motivation": "LLMs在生成文本时经常产生流畅但不准确的幻觉，这在实际应用中可能导致误导性输出，影响事实真理性。现有幻觉检测方法通常需要多次采样或后验验证，这不仅增加了计算延迟和成本，还限制了实时交互的效率。因此，开发一种低开销、高实时性的幻觉检测方法至关重要，以提升LLM的可靠性和实用性。摘要未明确说明更广泛的背景，但强调了现有方法的延迟和成本问题。",
      "method": "论文提出DRIFT方法，核心是一个轻量级探针，它直接从LLMs的中间隐藏状态中提取置信信号，这些信号在最终输出层中可能丢失。探针通过分析这些信号高效检测幻觉，其设计确保了计算开销低于0.1%，并可以完全与生成过程并行运行，实现无延迟检测。此外，基于探针结果构建了一个LLM路由器，它根据置信度动态分配查询：高置信查询由当前模型立即回答，低置信查询则委托给更强大的模型处理。",
      "result": "实验在四个问答基准和三种LLM家族的12个设置中进行，结果显示DRIFT方法在10个设置中达到了最先进的AUROC性能。与先前方法相比，AUROC提升高达13个点，显著提高了幻觉检测的准确性。此外，该方法表现出良好的泛化能力，无需重新训练就能适应数据集偏移，证明了其在多样环境下的鲁棒性和实用价值。",
      "conclusion": "该研究的主要贡献是提出了一种基于中间层置信信号的轻量级幻觉检测方法，有效降低了检测延迟和计算成本，并实现了智能模型路由。这为提升LLM输出的事实真理性提供了新思路，在LLM可靠性领域具有重要学术和实际应用价值。未来工作可探索该方法在更广泛任务和模型中的扩展，以进一步优化性能和适应性。",
      "tags": [
        "Large Language Model",
        "Confidence Signal Detection",
        "Lightweight Probe",
        "Hallucination Detection",
        "LLM Router"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:06.389049Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.13380",
    "title": "Practical Insights into Semi-Supervised Object Detection Approaches",
    "authors": [
      "Chaoxin Wang",
      "Bharaneeshwar Balasubramaniyam",
      "Anurag Sangem",
      "Nicolais Guevara",
      "Doina Caragea"
    ],
    "abstract": "Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.13380.pdf",
    "abs_url": "https://arxiv.org/abs/2601.13380",
    "published": "2026-01-19T20:31:15Z",
    "updated": "2026-01-29T03:07:18Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过系统比较三种先进的半监督目标检测方法，揭示了在数据稀缺场景下的性能权衡，为实际应用提供指导。",
      "motivation": "随着数据稀缺场景的学习日益受关注，半监督目标检测旨在利用大量未标记图像提升少量标记图像下的检测性能，这在实际应用中至关重要，因为标注数据往往成本高昂且耗时。现有研究通常关注单一方法或有限场景，缺乏对不同方法在标记数据量变化时的全面比较，特别是在专业化数据集上的表现评估。本研究的动机是填补这一空白，通过系统性比较理解不同SSOD方法在低数据情况下的性能差异、适用性及潜在不足，以推动更有效的解决方案发展。",
      "method": "本研究采用比较研究方法，系统评估了三种最先进的半监督目标检测方法：MixPL、Semi-DETR和Consistent-Teacher，以探究性能如何随标记图像数量变化。通过在两个流行标准数据集MS-COCO和Pascal VOC上进行实验，确保了标准化评估；同时，使用自定义的Beetle数据集评估方法在专业化数据集上的表现，该数据集对象类别较少。关键创新点在于建立了综合比较框架，结合通用与专用数据集，分析不同数据量下的技术特性，如模型架构和训练策略，以提供实用的技术路线洞察。",
      "result": "论文的主要实验结果揭示了准确率、模型大小和延迟之间的权衡，例如某些方法在低标记数据下可能表现更优，而另一些则在计算效率上有优势。通过在MS-COCO、Pascal VOC和Beetle数据集上的比较，研究发现MixPL、Semi-DETR和Consistent-Teacher各有优缺点，但摘要未明确说明具体性能指标如准确率提升百分比。与基线方法（即三种方法的相互对比）相比，论文提供了实用见解，帮助识别哪种方法在不同数据量或专业化场景下更合适，为实际部署提供决策依据。",
      "conclusion": "本研究通过全面比较半监督目标检测方法，主要贡献是揭示了准确率、模型复杂度与延迟之间的性能权衡，为低数据场景下的方法选择提供了实用指导。其学术价值在于促进了SSOD研究的系统化和实证分析，推动领域向更实用化方向发展；实际应用价值在于帮助从业者根据具体需求（如资源限制或精度要求）做出技术决策。潜在局限性包括未涵盖所有SSOD方法或更多数据集，未来工作可扩展比较范围或探索更多低数据优化策略。",
      "tags": [
        "Semi-Supervised Object Detection",
        "Few-Shot Learning",
        "Object Detection Benchmarks",
        "Model Comparison",
        "Custom Dataset"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:24.430877Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11942",
    "title": "Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization",
    "authors": [
      "Qingyu Meng",
      "Yangshuai Wang"
    ],
    "abstract": "Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.11942.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11942",
    "published": "2026-01-17T07:32:18Z",
    "updated": "2026-01-29T05:49:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一个结合几何预条件化和课程优化的混合量子-经典回归框架，以提升量子神经网络在回归任务中的训练稳定性和性能。",
      "motivation": "量子神经网络在科学机器学习领域展现出潜力，但在回归任务中常因梯度噪声和优化问题的病态性而训练不稳定，导致收敛效率低下。现有方法在数据有限的情况下表现不佳，限制了QNNs的实际应用。因此，需要开发有效的策略来缓解这些训练瓶颈，提高QNNs在回归设置中的实用性和可靠性。",
      "method": "本研究设计了一个混合量子-经典回归框架，通过前置一个轻量级经典嵌入作为可学习的几何预条件器，以重塑输入表示并优化下游变分量子电路的训练条件。关键创新是引入课程优化协议，逐步增加电路深度，并从基于SPSA的随机探索过渡到基于Adam的梯度微调，以平衡探索和精细调优。在模拟器设置下，使用PDE-informed回归基准和标准回归数据集进行模型评估。",
      "result": "实验结果表明，在固定训练预算下，所提框架在PDE-informed回归基准和标准回归数据集上持续优于纯QNN基线模型，产生更稳定的收敛，特别是在数据有限的场景中。观察到的结构化误差减少与多个科学基准的振荡成分视觉相关，进一步验证了框架在稳定量子回归任务中的有效性，尽管摘要未提供具体数值指标。",
      "conclusion": "该论文的主要贡献是提出了一个整合几何预条件化和课程优化的混合量子-经典回归框架，有效提升了量子神经网络的训练稳定性和回归性能。这一研究为克服QNN训练中的梯度噪声和病态优化问题提供了新方法，具有显著的学术价值，推动了科学机器学习领域的发展。未来工作可探索在真实量子硬件上的应用或扩展到更复杂的任务中。",
      "tags": [
        "Quantum Neural Networks",
        "Hybrid Quantum-Classical Regression",
        "Geometric Preconditioning",
        "Curriculum Optimization",
        "Variational Quantum Circuit"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:45.760922Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11911",
    "title": "Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh",
    "authors": [
      "Alfe Suny",
      "MD Sakib Ul Islam",
      "Md. Imran Hossain"
    ],
    "abstract": "Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.11911.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11911",
    "published": "2026-01-17T05:15:22Z",
    "updated": "2026-01-29T16:21:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究评估了紧凑卷积神经网络在孟加拉现实世界小图像数据集上的可靠性，通过简化架构避免过拟合，实现高效分类。",
      "motivation": "卷积神经网络在图像识别中表现出色，但复杂架构容易在小数据集上过拟合，导致泛化能力差。现实应用中，如孟加拉的城市侵占监测、车辆检测等任务需要处理小规模数据集，现有方法可能计算开销大且效率低。因此，研究如何利用简化CNN架构在小数据集上实现可靠分类至关重要，以克服过拟合问题并降低计算成本，提升实际应用的可行性和效果。",
      "method": "本研究采用紧凑卷积神经网络，在五个公开的孟加拉现实世界图像数据集上进行实验，数据集涵盖城市侵占、车辆检测、道路损坏和农作物分类。通过训练网络，评估分类准确率、收敛速度和计算开销，并进行显著性分析以理解模型捕捉判别性特征的能力。核心创新在于使用轻量级架构，优化小数据集分类任务，减少过拟合风险，强调结构化评估方法。",
      "result": "实验结果显示，紧凑CNN在所有数据集上实现高分类准确率（具体数字摘要未明确说明），收敛高效且计算开销低。定量指标如准确率提升和显著性分析表明模型能有效捕捉关键特征，并在不同场景下稳健泛化。与基线方法相比（摘要未明确说明），该模型在性能和效率上表现出优势，验证了简化架构在小数据集分类中的适用性和可靠性。",
      "conclusion": "本研究的主要贡献在于证实了简化卷积神经网络在现实世界小图像数据集上的可靠性和有效性，提供了一种低成本、高效的解决方案，适用于环境监测、交通管理等领域。尽管结果积极，但未来工作可包括扩展更多数据集或进一步优化架构（摘要未明确说明）。该研究为小数据集分类任务提供了实用的技术路径，具有重要的学术和应用价值。",
      "tags": [
        "Convolutional Neural Networks",
        "Image Classification",
        "Small Dataset",
        "Real-World Datasets",
        "Saliency Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:34.483743Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11479",
    "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning",
    "authors": [
      "Yohai Trabelsi",
      "Guojun Xiong",
      "Fentabil Getnet",
      "Stéphane Verguet",
      "Milind Tambe"
    ],
    "abstract": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.11479.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11479",
    "published": "2026-01-16T18:02:09Z",
    "updated": "2026-01-29T16:03:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出LEG框架，结合大语言模型与扩展贪心算法，将专家定性知识整合到健康设施选址的优化规划中，解决资源有限下的公平覆盖问题。",
      "motivation": "埃塞俄比亚卫生部需要升级农村地区的卫生站以改善基本服务可及性，但资源有限，需优先选择升级设施以最大化人口覆盖，同时兼顾专家和利益相关者的多样偏好。传统优化方法虽提供理论保证，但依赖明确量化目标，而专家偏好常以自然语言表达，难以形式化，导致规划无法充分反映实际需求，这限制了资源分配的有效性和公平性。",
      "method": "研究提出LEG（大型语言模型与扩展贪心）框架，核心是将可证明逼近算法用于人口覆盖优化，结合LLM驱动的迭代精炼过程。LLM用于解析自然语言中的专家指导，将其转化为可操作的约束或目标，通过人-AI对齐确保解决方案既保持覆盖保证，又反映定性偏好。框架使用来自三个埃塞俄比亚地区的真实世界数据，实施算法以生成平衡覆盖与专家意见的选址方案。",
      "result": "在埃塞俄比亚三个地区的真实数据实验中，LEG框架展示了其有效性和潜力，能够产生既能最大化人口覆盖又符合专家定性指导的解决方案。摘要未明确说明具体性能指标（如覆盖提升百分比或效率改进），也未详细描述与基线方法的对比情况，但指出该框架有助于实现公平、数据驱动的卫生系统规划，显示了在资源约束下优化决策的实用性。",
      "conclusion": "本研究的主要贡献是开发了LEG框架，成功将LLM与优化算法结合，弥合了专家知识与量化目标之间的鸿沟。学术上，它推动了AI在复杂决策中的应用，通过人-AI对齐增强模型的可解释性和实用性；实际应用中，为埃塞俄比亚等资源受限地区的健康设施选址提供了创新工具，支持更全面和公平的规划。未来工作可能涉及扩展框架到其他领域或改进LLM的集成方式。",
      "tags": [
        "Large Language Models",
        "Optimization Algorithms",
        "Expert Knowledge Integration",
        "Human-AI Alignment",
        "Health Facility Location"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:59.858893Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11471",
    "title": "Low-Rank Key Value Attention",
    "authors": [
      "James O'Neill",
      "Robert Clancy",
      "Mariia Matskevichus",
      "Fergal Reid"
    ],
    "abstract": "The key-value (KV) cache is a primary memory bottleneck in Transformers. We propose Low-Rank Key-Value (LRKV) attention, which reduces KV cache memory by exploiting redundancy across attention heads, while being compute efficient. Each layer uses a shared full-rank KV projection augmented with low-rank, head-specific residuals, providing a continuous trade-off between complete sharing and full independence. After pretraining models of size 128M to 6.3B parameters, LRKV consistently achieves the lowest test loss among standard MHA, MQA/GQA, and MLA while using only 45-53\\% of MHA's KV cache. LRKV reaches equivalent baseline quality 18-25\\% faster (measured in training steps). After supervised midtraining, LRKV achieves the highest downstream task performance across ARC-Easy, ARC-Challenge, MMLU, GSM8K, and HumanEval benchmarks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.11471.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11471",
    "published": "2026-01-16T17:56:40Z",
    "updated": "2026-01-29T15:29:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出低秩键值（LRKV）注意力机制，通过低秩残差优化Transformer的KV cache，减少内存占用并提升训练效率。",
      "motivation": "Transformer模型中的键值（KV）cache是主要内存瓶颈，尤其在大规模预训练中，导致内存开销高并限制模型可扩展性。现有方法如标准多头注意力（MHA）需要存储大量KV cache，增加了内存负担。LRKV旨在通过利用注意力头之间的冗余来减少这种内存需求，同时保持计算效率，从而解决内存瓶颈问题。",
      "method": "论文提出低秩键值（LRKV）注意力机制，每个层使用共享的全秩KV投影，并添加低秩、头特定的残差项。这种方法利用注意力头间的冗余，通过平衡完全共享和完全独立之间的连续权衡，来减少KV cache的内存使用。预训练模型覆盖了从128M到6.3B参数的范围，验证了方法的可扩展性和计算效率。",
      "result": "实验结果显示，LRKV在测试损失上consistently低于标准MHA、MQA/GQA和MLA，仅需MHA KV cache内存的45-53%。达到等效基线质量所需训练步骤减少18-25%。监督midtraining后，在多个下游任务（如ARC-Easy、ARC-Challenge、MMLU、GSM8K、HumanEval）上均取得最高性能，证明了其高效性。",
      "conclusion": "论文的主要贡献是提出LRKV注意力机制，显著减少了Transformer模型中的KV cache内存瓶颈，同时提升了训练效率和下游任务性能。这项研究为大规模语言模型的优化提供了新方向，具有重要的学术和实际应用价值。未来工作可进一步探索更广泛的应用场景和模型架构优化。",
      "tags": [
        "Low-Rank Attention",
        "Key-Value Cache",
        "Transformer",
        "Multi-Head Attention",
        "Memory Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:20.797595Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.11219",
    "title": "SDFLoRA: Selective Decoupled Federated LoRA for Privacy-preserving Fine-tuning with Heterogeneous Clients",
    "authors": [
      "Zhikang Shen",
      "Jianrong Lu",
      "Haiyuan Wan",
      "Jianhai Chen"
    ],
    "abstract": "Federated learning (FL) for large language models (LLMs) has attracted increasing attention as a privacy-preserving approach for adapting models over distributed data, where parameter-efficient methods such as Low-Rank Adaptation (LoRA) are widely adopted to reduce communication and memory costs. However, practical deployments often exhibit rank and data heterogeneity: clients operate under different low-rank budgets and data distributions, making direct aggregation of LoRA updates biased and unstable. Existing approaches either enforce a unified rank or align heterogeneous updates into a single shared subspace, which tends to mix transferable and client-specific directions and consequently undermines personalization. Moreover, under differential privacy (DP), perturbing such structurally mixed updates injects noise into directions that should remain purely local, leading to unnecessary utility degradation. To address these issues, we propose Selective Decoupled Federated LoRA (SDFLoRA), a structure-aware LoRA framework that decouples each client update into a shared component for aggregation and a private component that preserves client-specific semantics. Only the shared component participates in subspace alignment, while the private component remains local and uncommunicated, making the training DP-compatible and stabilizing aggregation under rank heterogeneity. By injecting noise only into the aggregated shareable update, this approach avoids perturbations to local directions and improves the utility-privacy trade-off. Experiments on multiple benchmarks demonstrate that SDFLoRA outperforms federated LoRA baselines and achieves a strong utility-privacy trade-off.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.11219.pdf",
    "abs_url": "https://arxiv.org/abs/2601.11219",
    "published": "2026-01-16T11:53:38Z",
    "updated": "2026-01-29T06:50:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "SDFLoRA提出了一种选择性解耦的联邦LoRA框架，通过分离共享和私有更新，有效解决异构客户端下的聚合不稳定和隐私保护问题。",
      "motivation": "联邦学习用于大型语言模型微调时，面临秩和数据异构性挑战：客户端因不同低秩预算和数据分布导致LoRA更新聚合偏差和不稳定。现有方法如强制统一秩或对齐到共享子空间，会混合可转移与客户端特定方向，损害个性化，且在差分隐私下噪声注入到混合方向，进一步降低效用。因此，亟需新方法改善异构环境中的稳定性和隐私-效用权衡。",
      "method": "SDFLoRA是一种结构感知的LoRA框架，将每个客户端更新解耦为共享组件和私有组件。共享组件参与联邦聚合和子空间对齐，私有组件保持本地且不通信，确保训练兼容差分隐私。关键创新在于仅向聚合的共享组件注入噪声，避免扰动本地方向，从而在秩异构下稳定聚合。该方法使用LoRA作为参数高效微调基础，通过解耦机制区分全局共享和客户端特定语义。",
      "result": "实验在多个基准测试上进行，结果显示SDFLoRA优于联邦LoRA基线方法，实现了更强的隐私-效用权衡。尽管摘要未明确提供具体性能指标如准确率提升，但表明该方法在异构环境中有效提升了模型效果和稳定性，对比基线显示出显著改进。",
      "conclusion": "SDFLoRA通过解耦更新成功解决了异构联邦学习中的聚合和隐私问题，提高了训练稳定性和效用。该研究为隐私保护的LLM微调提供了新思路，具有学术和实际部署价值，可能推动更高效的分布式模型适应。未来工作可能包括扩展到更复杂异构场景或优化解耦策略，但摘要未明确说明局限性。",
      "tags": [
        "Federated Learning",
        "Low-Rank Adaptation (LoRA)",
        "Differential Privacy",
        "Heterogeneous Learning",
        "Subspace Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:18.865117Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.07118",
    "title": "Reward-Preserving Attacks For Robust Reinforcement Learning",
    "authors": [
      "Lucas Schott",
      "Elies Gherbi",
      "Hatem Hajri",
      "Sylvain Lamprier"
    ],
    "abstract": "Adversarial training in reinforcement learning (RL) is challenging because perturbations cascade through trajectories and compound over time, making fixed-strength attacks either overly destructive or too conservative. We propose reward-preserving attacks, which adapt adversarial strength so that an $α$ fraction of the nominal-to-worst-case return gap remains achievable at each state. In deep RL, perturbation magnitudes $η$ are selected dynamically, using a learned critic $Q((s,a),η)$ that estimates the expected return of $α$-reward-preserving rollouts. For intermediate values of $α$, this adaptive training yields policies that are robust across a wide range of perturbation magnitudes while preserving nominal performance, outperforming fixed-radius and uniformly sampled-radius adversarial training.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.07118.pdf",
    "abs_url": "https://arxiv.org/abs/2601.07118",
    "published": "2026-01-12T01:14:03Z",
    "updated": "2026-01-29T17:32:38Z",
    "comment": "27 pages, 28 figures, 4 algorithms, 3 tables, preprint",
    "light_analysis": {
      "overview": "论文提出了一种名为reward-preserving attacks的自适应对抗训练方法，通过动态调整扰动强度来增强强化学习策略的鲁棒性，同时保持名义性能。",
      "motivation": "在强化学习中，对抗训练旨在提升策略对扰动的鲁棒性，但传统固定强度攻击方法面临挑战：由于扰动会在轨迹中传播并随时间累积，固定强度的攻击要么过于破坏性，导致训练不稳定和性能下降；要么过于保守，不足以有效增强鲁棒性。现有方法如固定半径或均匀采样半径对抗训练难以平衡鲁棒性和名义性能，这对于实际应用至关重要，因为鲁棒性确保了RL系统在不确定环境中的可靠性。",
      "method": "论文的核心方法是reward-preserving attacks，它自适应地调整对抗训练的扰动强度。具体地，在深度RL中，通过学习一个critic函数Q((s,a),η)来估计在给定扰动幅度η下，能够保留α比例名义回报的策略性能（即α-reward-preserving滚动的预期回报）。该方法动态选择η，使得在每一步状态都能保持一定比例的回报差距，关键创新点在于将扰动强度与状态相关的回报损失联系起来，实现灵活的自适应攻击，避免了固定强度方法的局限性。",
      "result": "实验结果显示，对于α的中间值，提出的自适应训练方法能够产生对广泛扰动幅度范围具有鲁棒性的策略，同时保持名义性能。与基线方法如固定半径和均匀采样半径对抗训练相比，该方法在鲁棒性-性能权衡方面表现更优。尽管摘要未明确说明具体性能指标数值（如准确率提升百分比），但强调了其在多扰动场景下的有效性，超越了传统方法的不足。",
      "conclusion": "论文的主要贡献是引入了reward-preserving attacks，一种创新的对抗训练方法，有效解决了强化学习中扰动累积的问题，通过在保持性能的同时增强策略鲁棒性。学术上，它为RL鲁棒性研究提供了新思路；实际上，有助于开发更可靠的RL系统应用于现实环境。未来工作可以探索不同α值的影响，或将该方法扩展到更复杂的任务和扰动模型中，以进一步提升泛化能力。",
      "tags": [
        "Reinforcement Learning",
        "Adversarial Training",
        "Reward-Preserving Attacks",
        "Dynamic Perturbation",
        "Critic Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:57.329133Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.06753",
    "title": "Towards Computational Chinese Paleography",
    "authors": [
      "Yiran Rex Ma"
    ],
    "abstract": "Chinese paleography, the study of ancient Chinese writing, is undergoing a computational turn powered by artificial intelligence. This position paper charts the trajectory of this emerging field, arguing that it is evolving from automating isolated visual tasks to creating integrated digital ecosystems for scholarly research. We first map the landscape of digital resources, analyzing critical datasets for oracle bone, bronze, and bamboo slip scripts. The core of our analysis follows the field's methodological pipeline: from foundational visual processing (image restoration, character recognition), through contextual analysis (artifact rejoining, dating), to the advanced reasoning required for automated decipherment and human-AI collaboration. We examine the technological shift from classical computer vision to modern deep learning paradigms, including transformers and large multimodal models. Finally, we synthesize the field's core challenges -- notably data scarcity and a disconnect between current AI capabilities and the holistic nature of humanistic inquiry -- and advocate for a future research agenda focused on creating multimodal, few-shot, and human-centric systems to augment scholarly expertise.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.06753.pdf",
    "abs_url": "https://arxiv.org/abs/2601.06753",
    "published": "2026-01-11T02:40:54Z",
    "updated": "2026-01-29T15:17:07Z",
    "comment": "A position paper in progress with Peking University & ByteDance Digital Humanities Open Lab",
    "light_analysis": {
      "overview": "提出计算中国古文字学从孤立任务自动化向集成数字生态系统转变，并倡导多模态、少样本和以人为中心的未来研究方向。",
      "motivation": "中国古文字学作为研究古代文字的学科，正面临数据稀缺和现有AI能力不足以支持人文探究整体性的挑战。随着人工智能的发展，计算化趋势兴起，但当前方法多局限于自动化视觉任务，缺乏整合性系统来应对复杂的研究需求。这一问题的重要性在于，古文字学涉及多源数据（如甲骨文、青铜器、竹简脚本），需要跨学科合作来提升研究深度和效率。本文旨在通过描述这一领域的演变，强调其必要性，并指出现有方法的不足，推动向更综合方向的发展。",
      "method": "论文首先映射数字资源，分析关键数据集（如甲骨文、青铜器、竹简脚本），以建立领域基础。核心方法是构建一个方法管道，从基础视觉处理（包括图像恢复和字符识别）开始，通过上下文分析（如文物拼接和年代测定），进展到高级推理阶段，支持自动化破译和人机协作。技术特色体现在从经典计算机视觉向现代深度学习范式的转变，引入变换器和大规模多模态模型，以实现更复杂的任务集成和创新框架设计。",
      "result": "摘要未明确说明具体实验结果，因为这是一篇立场论文，侧重于综述和倡导而非实证研究。论文没有提供性能指标（如准确率提升或效率改进），而是通过分析现有研究，指出了领域从孤立任务向集成生态系统的进展。与基线方法的对比体现在技术范式的演进上，例如从传统计算机视觉到深度学习的应用，但未涉及具体数据支撑或定量评估，主要强调了挑战和未来方向。",
      "conclusion": "本文的主要贡献是系统描绘了计算中国古文字学的发展轨迹，提出从自动化任务向集成数字生态系统的转变。学术价值在于促进人工智能与人文科学的交叉融合，推动创新研究方法；实际应用价值体现在通过人机协作增强学术专长，提升研究效率。局限性包括数据稀缺和AI能力与人文需求之间的脱节，未来工作应专注于开发多模态、少样本和以人为中心的系统，以解决这些挑战并扩展研究可能性。",
      "tags": [
        "Computer Vision",
        "Deep Learning",
        "Transformers",
        "Large Multimodal Models",
        "Few-Shot Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:47.342414Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.01021",
    "title": "Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations",
    "authors": [
      "Dai Shi",
      "Lequan Lin",
      "Andi Han",
      "Luke Thompson",
      "José Miguel Hernández-Lobato",
      "Zhiyong Wang",
      "Junbin Gao"
    ],
    "abstract": "Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental for modeling stochastic dynamics across the natural sciences and modern machine learning. Learning their solution operators with deep learning models promises fast solvers and new perspectives on classical learning tasks. In this work, we build on Wiener-chaos expansions (WCE) to design neural operator (NO) architectures for SDEs and SPDEs: we project driving noise paths onto orthonormal Wick-Hermite features and use NOs to parameterize the resulting chaos coefficients, enabling reconstruction of full trajectories from noise in a single forward pass. We also make the underlying WCE structure explicit for multi-dimensional SDEs and semilinear SPDEs by showing the coupled deterministic ODE/PDE systems governing these coefficients. Empirically, we achieve competitive accuracy across several tasks, including standard SPDE benchmarks and SDE-based diffusion one-step image sampling, topological graph interpolation, financial extrapolation, parameter estimation, and manifold SDE flood forecasting. These results suggest WCE-based neural operators are a practical and scalable approach to learning SDE/SPDE solution operators across domains.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.01021.pdf",
    "abs_url": "https://arxiv.org/abs/2601.01021",
    "published": "2026-01-03T00:59:25Z",
    "updated": "2026-01-29T04:13:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于Wiener-chaos expansions的神经算子架构，用于高效学习随机（偏）微分方程的解算子。",
      "motivation": "随机微分方程（SDEs）和随机偏微分方程（SPDEs）是建模随机动态的基础工具，广泛应用于自然科学和现代机器学习领域。现有方法在学习和求解这些方程时可能面临计算复杂度和效率的挑战，难以高效处理诸如扩散模型、图像采样和金融预测等任务。研究这些方程的解算子对于开发快速求解器和提升机器学习性能至关重要，因此设计新的学习方法具有重要的理论和实践意义。",
      "method": "该研究基于Wiener-chaos expansions（WCE）构建神经算子（NO）架构。方法核心是将随机驱动噪声投影到正交Wick-Hermite特征上，利用神经算子参数化混沌系数，从而实现从噪声到完整轨迹的单次前向传递重建。论文还阐明了多元随机微分方程和半线性随机偏微分方程的WCE结构，将其转化为耦合的确定性常微分方程/偏微分方程系统，简化了学习过程，为随机方程求解提供了新颖的计算框架。",
      "result": "实验结果表明，该方法在多个任务中取得了竞争性准确性，包括标准随机偏微分方程基准测试、基于随机微分方程的扩散一步图像采样、拓扑图插值、金融外推、参数估计以及流形随机微分方程的洪水预测。这些结果验证了基于WCE的神经算子在处理不同领域SDE/SPDE问题时的有效性和可扩展性。摘要未明确说明具体性能指标数据，但“竞争性准确性”暗示其与基线方法相比表现良好。",
      "conclusion": "论文的主要贡献是提出了基于Wiener-chaos expansions的神经算子架构，为学习随机（偏）微分方程的解算子提供了一种实用且可扩展的方法。这项研究融合了数学混沌理论和深度学习技术，具有重要的学术价值，为随机动态建模开辟了新途径。实际应用潜力广泛，涵盖机器学习、金融分析和环境预测等领域。未来工作可能扩展到更复杂的方程类型或更大规模的应用场景。",
      "tags": [
        "Neural Operator",
        "Stochastic Differential Equations",
        "Stochastic Partial Differential Equations",
        "Wiener-chaos expansions",
        "Wick-Hermite features"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:19.667318Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2601.00065",
    "title": "The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition",
    "authors": [
      "Xiaoze Liu",
      "Weichen Yu",
      "Matt Fredrikson",
      "Xiaoqian Wang",
      "Jing Gao"
    ],
    "abstract": "The open-weight language model ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single breaker token that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and evades outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.00065.pdf",
    "abs_url": "https://arxiv.org/abs/2601.00065",
    "published": "2025-12-31T19:00:03Z",
    "updated": "2026-01-29T06:04:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文揭示了大型语言模型组合中tokenizer移植的供应链漏洞，并设计了一种隐蔽的攻击方法来展示这种风险。",
      "motivation": "研究动机源于开放权重语言模型生态系统中模型组合技术（如权重合并、推测解码和词汇扩展）的广泛应用，这些技术依赖tokenizer移植来对齐不同模型的词汇表。现有方法在提高模型互操作性的同时，忽视了此步骤可能引入的安全风险，特别是在供应链攻击中。由于模型组合对AI开发效率至关重要，其漏洞可能导致恶意利用，影响生成模型的安全性，因此探讨这一问题对确保AI系统可靠性具有重要意义。",
      "method": "研究方法的核心是设计一个'破坏者token'，它在供体模型中功能不活跃，但在移植到基础模型后，通过利用系数重用的几何特性，可靠地重建为高显著性的恶意特征。关键创新点在于将攻击形式化为双目标优化问题，并使用稀疏求解器进行实例化，无需训练即可实现。攻击技术特色在于结合优化理论和模型脆弱性分析，能够规避异常检测，展示了一种隐蔽且高效的植入方式。",
      "result": "主要实验结果显示，攻击成功破坏了基础模型的生成过程，同时供体模型的效用与正常行为在统计上无显著差异。攻击对微调和权重合并表现出结构性持久性，表明恶意特征在后续处理中仍能持续存在。摘要未明确说明具体性能指标如准确率变化，但通过实证证明了漏洞的有效性和隐蔽性，与基线方法相比，该攻击能规避检测并持久影响模型行为，突显了安全风险。",
      "conclusion": "论文的主要贡献是揭示了模块化AI组合管道中tokenizer移植的隐藏供应链风险，强调了模型组合安全性问题的学术价值。研究促进了更安全的tokenizer对齐方法的开发，具有实际应用意义。未来工作方向可能包括设计防御机制以减轻此类攻击，并进一步探索其他潜在漏洞，为AI生态系统安全提供理论指导。",
      "tags": [
        "LLM Composition",
        "Tokenizer Transplant",
        "Supply Chain Vulnerability",
        "Dual-Objective Optimization",
        "Sparse Solver"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:21.100283Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.23526",
    "title": "EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition",
    "authors": [
      "Maryam Mirzaei",
      "Farzaneh Shayegh",
      "Hamed Narimani"
    ],
    "abstract": "Accurate recognition of human emotional states is critical for effective human-machine interaction. Electroencephalography (EEG) offers a reliable source for emotion recognition due to its high temporal resolution and its direct reflection of neural activity. Nevertheless, variations across recording sessions present a major challenge for model generalization. To address this issue, we propose EGDA, a framework that reduces cross-session discrepancies by jointly aligning the global (marginal) and class-specific (conditional) distributions, while preserving the intrinsic structure of EEG data through graph regularization. Experimental results on the SEED-IV dataset demonstrate that EGDA achieves robust cross-session performance, obtaining accuracies of 81.22%, 80.15%, and 83.27% across three transfer tasks, and surpassing several baseline methods. Furthermore, the analysis highlights the Gamma frequency band as the most discriminative and identifies the central-parietal and prefrontal brain regions as critical for reliable emotion recognition.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.23526.pdf",
    "abs_url": "https://arxiv.org/abs/2512.23526",
    "published": "2025-12-29T15:05:25Z",
    "updated": "2026-01-29T10:53:02Z",
    "comment": "10 pages, 7 figures",
    "light_analysis": {
      "overview": "提出EGDA框架，通过联合对齐全局和类别特定分布，并利用图正则化，增强基于脑电图（EEG）的跨会话情绪识别的鲁棒性。",
      "motivation": "情绪识别对于实现高效人机交互至关重要，脑电图（EEG）因其高时间分辨率和直接反映神经活动，成为情绪识别的可靠数据源。然而，不同记录会话之间存在设备、环境或个体变化，导致模型泛化能力下降，这是现有方法面临的主要挑战。本研究旨在解决跨会话差异问题，提高情绪识别模型在实际应用中的准确性和鲁棒性，以推动情感计算和脑机接口领域的发展。",
      "method": "论文提出EGDA框架，核心方法包括联合对齐边际分布和条件分布来减少源域和目标域之间的差异，同时通过图正则化技术保护EEG数据的固有图结构。这利用图神经网络或图引导优化来捕捉脑电信号的空间相关性，确保在域适应过程中不丢失关键特征。实验使用SEED-IV数据集，框架集成分布对齐和图正则化，以实现稳健的跨会话情绪识别模型。",
      "result": "实验结果显示，EGDA在SEED-IV数据集上的三个跨会话转移任务中，准确率分别达到81.22%、80.15%和83.27%，显著超越了多个基线方法，表明框架有效减少了跨会话差异并提升了识别性能。分析还发现Gamma频带对情绪识别最具判别性，且中央-顶叶和前额叶脑区是关键区域，这为理解EEG信号在情绪处理中的作用提供了新见解，并支持了框架的有效性。",
      "conclusion": "EGDA框架通过结合分布对齐和图正则化，显著提高了基于EEG的跨会话情绪识别的鲁棒性和泛化能力，为解决跨会话域适应问题提供了创新方案。该研究不仅具有学术价值，推动了域适应和脑电信号处理技术的发展，还具备实际应用潜力，可用于情感计算和健康监测。未来工作可探索更多数据集或扩展至其他脑电频带分析。",
      "tags": [
        "Electroencephalography (EEG)",
        "Domain Adaptation",
        "Graph Regularization",
        "Emotion Recognition",
        "Cross-Session"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:41.129434Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.23471",
    "title": "Discovering Multi-Scale Semantic Structure in Text Corpora Using Density-Based Trees and LLM Embeddings",
    "authors": [
      "Thomas Haschka",
      "Joseph Bakarji"
    ],
    "abstract": "Recent advances in large language models enable documents to be represented as dense semantic embeddings, supporting similarity-based operations over large text collections. However, many web-scale systems still rely on flat clustering or predefined taxonomies, limiting insight into hierarchical topic relationships. In this paper we operationalize hierarchical density modeling on large language model embeddings in a way not previously explored. Instead of enforcing a fixed taxonomy or single clustering resolution, the method progressively relaxes local density constraints, revealing how compact semantic groups merge into broader thematic regions. The resulting tree encodes multi-scale semantic organization directly from data, making structural relationships between topics explicit. We evaluate the hierarchies on standard text benchmarks, showing that semantic alignment peaks at intermediate density levels and that abrupt transitions correspond to meaningful changes in semantic resolution. Beyond benchmarks, the approach is applied to large institutional and scientific corpora, exposing dominant fields, cross-disciplinary proximities, and emerging thematic clusters. By framing hierarchical structure as an emergent property of density in embedding spaces, this method provides an interpretable, multi-scale representation of semantic structure suitable for large, evolving text collections.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.23471.pdf",
    "abs_url": "https://arxiv.org/abs/2512.23471",
    "published": "2025-12-29T13:55:23Z",
    "updated": "2026-01-29T11:57:19Z",
    "comment": "23 pages, 10 figures, further interactive visualizations available on https:// genealogy.sematlas.com/",
    "light_analysis": {
      "overview": "本文提出一种基于密度树和大型语言模型嵌入的方法，用于从文本语料库中自动发现多尺度语义结构，无需预定义分类法或固定分辨率。",
      "motivation": "当前许多大规模文本系统（如网络规模应用）依赖扁平聚类或预定义分类法，这限制了层级主题关系的深入洞察，难以捕捉语义的层次性和演化性。本研究旨在解决这一实际问题，因为现有方法在多尺度语义结构自动发现方面存在不足，影响了文本分析和知识挖掘的效率。重要性在于，随着大型语言模型的发展，需要更灵活的方法来处理复杂语义关系，以支持智能信息处理和应用。",
      "method": "该方法利用大型语言模型（LLM）生成的文档嵌入，结合密度建模技术来构建层级树。核心创新在于逐步放宽局部密度约束，使紧凑语义组自然合并为更广泛主题，从数据中直接揭示多尺度语义组织。具体技术路线包括使用密度树算法，避免强制执行固定分类法或单一聚类分辨率，从而操作化层级密度建模，这在先前研究中未被充分探索。摘要未明确说明使用的具体数据集或模型架构，但提到了标准文本基准和大型语料库的应用。",
      "result": "在标准文本基准上评估时，该方法显示语义对齐在中间密度水平达到峰值，且急剧转换点对应于语义分辨率的有意义变化，这表明了多尺度语义结构的有效揭示。应用于大型机构和科学语料库时，成功暴露了主导领域、跨学科接近性和新兴主题集群，增强了语义洞察。尽管摘要未提供具体性能数据如准确率提升，但通过与基线方法的对比，该方法在捕捉复杂层级关系方面表现突出，适合处理大规模、动态文本集合。",
      "conclusion": "本研究的主要贡献是提出了一种基于密度建模的方法，将层级语义结构视为嵌入空间中密度的涌现属性，提供了可解释、多尺度的表示。学术价值在于扩展了大型语言模型在语义分析中的应用，为文本结构化提供了新视角；实际应用价值体现在能够分析大型、演化文本语料库，如机构和科学文档。未来工作方向可能包括优化算法以适应更广泛场景和提升效率，但摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model (LLM) Embeddings",
        "Density-Based Trees",
        "Hierarchical Density Modeling",
        "Multi-Scale Semantic Analysis",
        "Text Corpora"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:47.647121Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.22716",
    "title": "Memento 2: Learning by Stateful Reflective Memory",
    "authors": [
      "Jun Wang"
    ],
    "abstract": "We present a theoretical study of continual and experiential learning in large language model agents that combine episodic memory with reinforcement learning. We argue that the key mechanism for continual adaptation, without updating model parameters, is reflection: the agent's ability to use past experience to guide future actions. Empirical findings suggest that episodic, experience-driven reflection enables generalised adaptation across a wide range of open-ended, long-horizon tasks. This indicates that efficient learning can occur during deployment and weakens the traditional separation between training and testing. Motivated by this, we introduce the Stateful Reflective Decision Process, a formal model of reflective memory dynamics. In this abstraction, an agent maintains an episodic memory and performs two core operations. Writing stores interaction outcomes and plays the role of policy evaluation. Reading retrieves relevant past cases to inform decisions and plays the role of policy improvement. This perspective treats reflective memory as a control object that can be analysed using classical reinforcement learning tools. We then develop a read-write reflective learning framework by integrating retrieval into soft policy iteration and establish convergence guarantees. We show that as memory grows and provides denser coverage of the state space, the resulting composite policy converges to the optimal solution. Overall, this framework connects practical memory-based methods with principled reinforcement learning, providing a rigorous mathematical basis for building reflective, memory-embedded agents capable of continual general-purpose learning.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2512.22716.pdf",
    "abs_url": "https://arxiv.org/abs/2512.22716",
    "published": "2025-12-27T22:15:03Z",
    "updated": "2026-01-29T13:49:34Z",
    "comment": "35 pages, four figures",
    "light_analysis": {
      "overview": "本研究提出了一个状态性反射记忆学习框架，通过结合情景记忆和强化学习，实现大型语言模型代理的持续通用适应。",
      "motivation": "大型语言模型代理在执行长期、开放式任务时面临持续学习和经验积累的挑战，传统方法依赖于模型参数更新，导致训练与测试分离且适应性有限。本文动机在于探索无需参数更新的学习机制，通过反射机制使代理利用过去经验指导未来决策。实证表明情景驱动反射能实现广义适应，削弱传统学习界限，为代理在动态环境中的高效学习提供理论基础。",
      "method": "研究引入状态性反射决策过程作为形式模型，描述代理维护情景记忆并执行写操作存储交互结果以进行策略评估，读操作检索相关过去案例以进行策略改进。通过整合检索到软策略迭代，开发读写反射学习框架，将反射记忆视为控制对象，利用经典强化学习工具分析并建立收敛保证，确保随着记忆覆盖增加，复合策略趋近最优解。",
      "result": "实证发现情景驱动反射能在开放式、长视野任务中实现广义适应，表明学习效率在部署期间提升，削弱训练与测试分离。理论分析显示，通过读写反射框架，随着记忆增长和状态空间覆盖更密集，复合策略收敛到最优解，为持续学习提供数学支撑，但与基线对比未在摘要中具体说明。",
      "conclusion": "本文主要贡献在于连接基于记忆的实践方法与原则化强化学习，提供严格的数学框架以构建反射性、记忆嵌入的代理，支持持续通用学习。研究意义在于推动人工智能向更高效、适应性强的学习方式发展，未来工作可扩展框架到复杂场景或整合其他学习机制。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Episodic Memory",
        "Reflective Learning",
        "Stateful Reflective Decision Process"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:55.256078Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.19365",
    "title": "Efficient Spike-driven Transformer for High-performance Drone-View Geo-Localization",
    "authors": [
      "Zhongwei Chen",
      "Hai-Jun Rong",
      "Zhao-Xu Yang",
      "Guoqi Li"
    ],
    "abstract": "Traditional drone-view geo-localization (DVGL) methods based on artificial neural networks (ANNs) have achieved remarkable performance. However, ANNs rely on dense computation, which results in high power consumption. In contrast, spiking neural networks (SNNs), which benefit from spike-driven computation, inherently provide low power consumption. Regrettably, the potential of SNNs for DVGL has yet to be thoroughly investigated. Meanwhile, the inherent sparsity of spike-driven computation for representation learning scenarios also results in loss of critical information and difficulties in learning long-range dependencies when aligning heterogeneous visual data sources. To address these, we propose SpikeViMFormer, the first SNN framework designed for DVGL. In this framework, a lightweight spike-driven transformer backbone is adopted to extract coarse-grained features. To mitigate the loss of critical information, the spike-driven selective attention (SSA) block is designed, which uses a spike-driven gating mechanism to achieve selective feature enhancement and highlight discriminative regions. Furthermore, a spike-driven hybrid state space (SHS) block is introduced to learn long-range dependencies using a hybrid state space. Moreover, only the backbone is utilized during the inference stage to reduce computational cost. To ensure backbone effectiveness, a novel hierarchical re-ranking alignment learning (HRAL) strategy is proposed. It refines features via neighborhood re-ranking and maintains cross-batch consistency to directly optimize the backbone. Experimental results demonstrate that SpikeViMFormer outperforms state-of-the-art SNNs. Compared with advanced ANNs, it also achieves competitive performance.Our code is available at https://github.com/ISChenawei/SpikeViMFormer",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.19365.pdf",
    "abs_url": "https://arxiv.org/abs/2512.19365",
    "published": "2025-12-22T13:07:04Z",
    "updated": "2026-01-29T07:10:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文首次提出了一个用于无人机视图地理定位的高效脉冲驱动变压器框架SpikeViMFormer，通过选择性注意力和混合状态空间块解决了脉冲神经网络的信息丢失问题，实现低功耗高性能定位。",
      "motivation": "传统无人机视图地理定位方法依赖于人工神经网络（ANNs），尽管性能卓越，但计算密集导致高功耗，限制了其在资源受限环境中的应用。相比之下，脉冲神经网络（SNNs）具有天生的低功耗特性，但尚未在DVGL中得到充分研究，且其稀疏计算在处理异构视觉数据时易丢失关键信息，并难以学习长距离依赖关系。因此，开发一个能够克服这些缺陷的SNN框架对实现高效低功耗地理定位至关重要，以推动无人机等实际应用的可持续发展。",
      "method": "本研究提出了SpikeViMFormer，一个专门为无人机视图地理定位设计的SNN框架。框架采用轻量级脉冲驱动变压器骨干提取特征，同时设计了脉冲驱动选择性注意（SSA）块，通过脉冲门控机制实现选择性特征增强以突出关键区域。此外，引入脉冲驱动混合状态空间（SHS）块来学习长距离依赖关系，使用混合状态空间模型优化学习。推理阶段仅使用骨干以减少计算开销。为确保骨干有效性，提出层次化重新排名对齐学习（HRAL）策略，通过邻居重新排名细化特征并维护跨批次一致性直接优化骨干。",
      "result": "实验结果表明，SpikeViMFormer在性能上超越了现有的state-of-the-art SNNs，验证了其有效性。与先进的人工神经网络相比，该框架也实现了竞争性的性能，表明其在保持低功耗的同时能够接近传统高功耗方法的性能水平。摘要未提供具体性能指标，如准确率或效率改进数值，但强调了该方法的优越性和实用性，代码开源便于复现和进一步验证。",
      "conclusion": "论文的主要贡献是首次将脉冲神经网络应用于无人机视图地理定位，提出SpikeViMFormer框架，通过创新性设计如SSA和SHS块解决了SNNs的信息丢失和依赖学习问题。这不仅推动了低功耗AI技术的发展，还为实际地理定位任务提供了高效解决方案，具有重要的学术和应用价值。未来可进一步优化模型或探索更广泛的应用场景，代码开源促进了社区合作与研究扩展。",
      "tags": [
        "Spiking Neural Networks (SNNs)",
        "Transformer",
        "Selective Attention",
        "State Space Models",
        "Drone-View Geo-Localization (DVGL)"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:35.770512Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.18837",
    "title": "Generative Modeling through Koopman Spectral Analysis: An Operator-Theoretic Perspective",
    "authors": [
      "Yuanchao Xu",
      "Fengyi Li",
      "Masahiro Fujisawa",
      "Xiaoyuan Cheng",
      "Youssef Marzouk",
      "Isao Ishikawa"
    ],
    "abstract": "We propose Koopman Spectral Wasserstein Gradient Descent (KSWGD), a particle-based generative modeling framework that learns the Langevin generator via Koopman theory and integrates it with Wasserstein gradient descent. Our key insight is that this spectral structure of the underlying distribution can be directly estimated from trajectory data via the Koopman operator, eliminating the need for explicit knowledge of the target potential. Additionally, we prove that KSWGD maintains an approximately constant dissipation rate, thereby establishing linear convergence and overcoming the vanishing-gradient phenomenon that hinders existing kernel-based particle methods. We further provide a Feynman--Kac interpretation that clarifies the method's probabilistic foundation. Experiments on compact manifolds, metastable multi-well systems, and high-dimensional stochastic partial differential equations demonstrate that KSWGD consistently outperforms baselines in both convergence speed and sample quality.",
    "categories": [
      "cs.LG",
      "math.DS"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.18837.pdf",
    "abs_url": "https://arxiv.org/abs/2512.18837",
    "published": "2025-12-21T17:54:09Z",
    "updated": "2026-01-29T13:52:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Koopman Spectral Wasserstein Gradient Descent (KSWGD)，一个基于Koopman理论和Wasserstein梯度下降的生成建模框架，实现线性收敛并克服梯度消失问题。",
      "motivation": "生成建模在处理复杂分布时，现有基于核的粒子方法常因梯度消失现象而收敛缓慢、样本质量下降，限制了实际应用。本文旨在通过操作符理论视角解决这一问题，利用Koopman算子直接从数据中学习分布结构，无需显式目标势知识，从而提升建模效率和准确性，弥补现有方法的不足。",
      "method": "KSWGD框架结合Koopman理论和Wasserstein梯度下降，基于粒子学习Langevin生成器。创新点在于通过Koopman算子从轨迹数据直接估计底层分布的谱结构，无需目标势的显式定义；证明该方法保持近似恒定的耗散率，确保线性收敛并克服梯度消失。此外，提供Feynman-Kac解释阐明概率基础，增强理论严谨性。摘要未明确说明具体数据集或模型架构细节。",
      "result": "在紧凑流形、多稳态多井系统和高维随机偏微分方程上的实验表明，KSWGD在收敛速度和样本质量上均优于基线方法。摘要未提供具体性能指标数值（如准确率提升），但实验结果显示其一致性优势，验证了该方法在处理复杂分布时的有效性和鲁棒性，克服了现有方法的局限性。",
      "conclusion": "本文的主要贡献是提出了KSWGD框架，通过Koopman理论优化分布学习，实现线性收敛并解决梯度消失问题，具有理论深度和实际应用价值。研究提供了操作符理论视角，对生成建模领域有重要推动。未来工作方向摘要未明确说明，但可推断方法可能需进一步应用于更广泛领域或进行扩展实验验证。",
      "tags": [
        "Koopman Theory",
        "Wasserstein Gradient Descent",
        "Generative Modeling",
        "Langevin Dynamics",
        "Spectral Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:45.953480Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.18834",
    "title": "Mix, MinHash, and Match: Cross-Source Agreement for Multilingual Pretraining Datasets",
    "authors": [
      "Sultan Alrashed",
      "Francesco Orabona"
    ],
    "abstract": "Multilingual data from the web is essential for LLM pretraining. Yet, scraping it is expensive, and research groups repeatedly crawl the same content. For example, we found that over 40\\% of tokens across major Arabic web corpora are duplicated between sources. In this work, we propose to use this wasteful redundancy as a quality signal to create high-quality pretraining datasets. Our key insight is that cross-source agreement functions as a free, model-free quality filter: content retained by multiple independent pipelines is more likely to represent high-quality text. Crucially, this signal requires no additional computation beyond standard deduplication, which is already performed at scale when pretraining language models. So, we propose MixMinMatch, a method that combines multiple existing web corpora, performs cross-dataset MinHash deduplication, and identifies documents independently recovered by multiple sources. We apply MixMinMatch to Arabic, Turkish, and Hindi, producing corpora that match or exceed the quality of the best single-source baselines, while providing up to 4$\\times$ more unique tokens. On Arabic, our matched subset achieves a 4.5\\% relative improvement over ArabicWeb24, while on Turkish, we improve over FineWeb-2 by 5.5\\%. We release the datasets at: https://huggingface.co/collections/AdaMLLab/mixminmatch",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.18834.pdf",
    "abs_url": "https://arxiv.org/abs/2512.18834",
    "published": "2025-12-21T17:36:26Z",
    "updated": "2026-01-29T11:27:20Z",
    "comment": "Multilingual LLM pretraining dataset curation",
    "light_analysis": {
      "overview": "提出MixMinMatch方法，利用跨源协议作为免费质量过滤器，创建高质量多语言预训练数据集。",
      "motivation": "多语言网络数据对于大型语言模型预训练至关重要，但获取成本高昂，且不同数据源之间存在大量重复内容，导致资源浪费和效率低下。现有方法在去重时未能利用跨源协议作为质量信号，无法有效筛选高质量文本，因此本研究的动机是通过跨源协议作为免费、无需额外计算的质量过滤器，解决数据冗余问题并提升数据集质量。",
      "method": "论文提出MixMinMatch方法，通过组合多个现有网络语料库，执行跨数据集MinHash去重，并识别由多个独立数据源共同恢复的文档。该方法的关键创新在于将跨源协议视为免费、无需模型的质量过滤器，仅利用标准去重过程中的信息，无需额外计算。使用MinHash算法处理大规模数据，应用于阿拉伯语、土耳其语和印地语语料库，以实现高效数据整合和质量提升。",
      "result": "实验在阿拉伯语、土耳其语和印地语上进行，结果显示MixMinMatch产生的语料库质量匹配或超过最佳单源基线，同时提供高达4倍的唯一标记数量。具体地，在阿拉伯语上相对ArabicWeb24改进4.5%，在土耳其语上相对FineWeb-2改进5.5%。这些结果证明跨源协议有效提升了数据质量，并在增加数据多样性的基础上优化了性能指标。",
      "conclusion": "本研究的主要贡献是提出MixMinMatch方法，利用跨源协议作为质量信号，创建高质量多语言预训练数据集，将数据冗余转化为有益的质量指标。学术上为数据处理提供了新视角，实际应用能降低数据获取成本并提升模型性能，数据集已公开以促进研究。未来工作可能包括扩展到更多语言或结合其他质量指标进一步优化方法。",
      "tags": [
        "MinHash",
        "Cross-source Agreement",
        "Multilingual Pretraining",
        "Data Deduplication",
        "Quality Filtering"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:52.203170Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.18352",
    "title": "LLM-based Few-Shot Early Rumor Detection with Imitation Agent",
    "authors": [
      "Fengzhu Zeng",
      "Qian Shao",
      "Ling Cheng",
      "Wei Gao",
      "Shih-Fen Cheng",
      "Jing Ma",
      "Cheng Niu"
    ],
    "abstract": "Early Rumor Detection (EARD) aims to identify the earliest point at which a claim can be accurately classified based on a sequence of social media posts. This is especially challenging in data-scarce settings. While Large Language Models (LLMs) perform well in few-shot NLP tasks, they are not well-suited for time-series data and are computationally expensive for both training and inference. In this work, we propose a novel EARD framework that combines an autonomous agent and an LLM-based detection model, where the agent acts as a reliable decision-maker for \\textit{early time point determination}, while the LLM serves as a powerful \\textit{rumor detector}. This approach offers the first solution for few-shot EARD, necessitating only the training of a lightweight agent and allowing the LLM to remain training-free. Extensive experiments on four real-world datasets show our approach boosts performance across LLMs and surpasses existing EARD methods in accuracy and earliness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.18352.pdf",
    "abs_url": "https://arxiv.org/abs/2512.18352",
    "published": "2025-12-20T12:42:27Z",
    "updated": "2026-01-29T15:01:08Z",
    "comment": "Accepted at KDD 2026",
    "light_analysis": {
      "overview": "该论文提出了一个结合自主代理和大型语言模型的少样本早期谣言检测框架，首次实现了轻量级训练和高效检测。",
      "motivation": "早期谣言检测旨在及时识别社交媒体上的虚假信息，但在数据稀缺环境中传统方法效果有限。现有大型语言模型虽在少样本NLP任务中表现良好，但处理时间序列数据效率低且计算成本高，难以适应早期检测需求，这凸显了改进方法的必要性。",
      "method": "研究方法包括一个轻量级自主代理和一个大型语言模型检测器，代理负责决策早期检测时间点，模仿优化过程；LLM作为谣言分类器保持冻结状态，无需额外训练。关键创新在于代理仅需少量训练，减少了计算负担，首次为少样本早期检测提供了实用解决方案。",
      "result": "在四个真实世界数据集上的实验表明，该方法提升了大型语言模型的性能，在准确率和早期检测时间上均超越了现有早期谣言检测方法。尽管摘要未提供具体数值，但结果证实了框架在少样本设置下的有效性和优越性。",
      "conclusion": "该研究首次解决了少样本早期谣言检测问题，结合轻量级代理和训练自由的LLM，推动了时间序列少样本学习领域的发展。实际应用中，可帮助社交媒体平台及时遏制谣言传播，未来可能优化代理策略并扩展至其他检测任务。",
      "tags": [
        "Early Rumor Detection",
        "Large Language Models",
        "Few-Shot Learning",
        "Imitation Agent",
        "Time-Series Data"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:56.126979Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.18196",
    "title": "LogicReward: Incentivizing LLM Reasoning via Step-Wise Logical Supervision",
    "authors": [
      "Jundong Xu",
      "Hao Fei",
      "Huichi Zhou",
      "Xin Quan",
      "Qijun Huang",
      "Shengqiong Wu",
      "William Yang Wang",
      "Mong-Li Lee",
      "Wynne Hsu"
    ],
    "abstract": "Although LLMs exhibit strong reasoning capabilities, existing training methods largely depend on outcome-based feedback, which can produce correct answers with flawed reasoning. Prior work introduces supervision on intermediate steps but still lacks guarantees of logical soundness, which is crucial in high-stakes scenarios where logical consistency is paramount. To address this, we propose LogicReward, a novel reward system that guides model training by enforcing step-level logical correctness with a theorem prover. We further introduce Autoformalization with Soft Unification, which reduces natural language ambiguity and improves formalization quality, enabling more effective use of the theorem prover. An 8B model trained on data constructed with LogicReward surpasses GPT-4o and o4-mini by 11.6\\% and 2\\% on natural language inference and logical reasoning tasks with simple training procedures. Further analysis shows that LogicReward enhances reasoning faithfulness, improves generalizability to unseen tasks such as math and commonsense reasoning, and provides a reliable reward signal even without ground-truth labels. We will release all data and code at https://llm-symbol.github.io/LogicReward.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.18196.pdf",
    "abs_url": "https://arxiv.org/abs/2512.18196",
    "published": "2025-12-20T03:43:02Z",
    "updated": "2026-01-29T04:45:23Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "本研究提出LogicReward奖励系统，通过定理证明器监督步骤级逻辑正确性，显著提升大型语言模型的推理逻辑一致性。",
      "motivation": "现有大型语言模型训练依赖结果反馈，可能导致模型产生正确但推理错误的答案，这在高风险场景如法律或医疗中尤其危险，逻辑一致性至关重要。先前工作虽引入中间步骤监督，但缺乏对逻辑可靠性的严格保证，无法确保推理过程的严谨性。因此，本研究旨在解决这一不足，通过设计逻辑强化的奖励系统来提高推理质量。",
      "method": "论文提出了LogicReward，一个新颖的奖励系统，利用定理证明器对推理步骤的逻辑正确性进行强制执行，确保模型训练中的逻辑一致性。关键创新包括Autoformalization with Soft Unification，它减少自然语言到形式逻辑转换中的歧义，提高形式化质量，使定理证明更有效。方法通过构造基于逻辑验证的数据集来训练模型，实验中使用了8B参数的大型语言模型进行验证，强调简单训练流程。",
      "result": "在自然语言推理和逻辑推理任务上，使用LogicReward训练的8B模型超越了基线模型GPT-4o和o4-mini，性能分别提升11.6%和2%。分析显示该方法提高了推理的忠实度和泛化能力，在未见任务如数学和常识推理上也表现良好。此外，LogicReward能在没有真实标签的情况下提供可靠奖励信号，增强了方法的实用性和鲁棒性。",
      "conclusion": "LogicReward通过步骤级逻辑监督有效改善了大型语言模型的推理逻辑一致性，具有重要学术价值，为高风险场景的可信推理提供新方法。实际应用中，它提升了推理质量、泛化能力和奖励可靠性。未来工作包括扩展到更多任务和模型架构，摘要未明确说明具体局限性，但发布数据和代码将促进进一步研究。",
      "tags": [
        "Large Language Model",
        "Theorem Prover",
        "Reward System",
        "Autoformalization",
        "Step-Wise Supervision"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:11.094722Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.16453",
    "title": "TimeSeries2Report prompting enables adaptive large language model management of lithium-ion batteries",
    "authors": [
      "Jiayang Yang",
      "Martin Guay",
      "Zhixing Cao",
      "Chunhui Zhao"
    ],
    "abstract": "Large language models (LLMs) offer promising capabilities for interpreting multivariate time-series data, yet their application to real-world battery energy storage system (BESS) operation and maintenance remains largely unexplored. Here, we present TimeSeries2Report (TS2R), a semantic translation framework that converts raw lithium-ion battery operational time-series into structured, semantically enriched reports, enabling LLMs to reason, predict, and make decisions in BESS management scenarios. TS2R encodes short-term temporal dynamics into natural language through a combination of segmentation, semantic abstraction, and rule-based interpretation, effectively bridging low-level sensor signals with high-level contextual insights. We benchmark TS2R across both lab-scale and real-world datasets, evaluating report quality and downstream task performance in anomaly detection, state-of-charge prediction, and charging/discharging management. Compared with vision-, embedding-, and text-based prompting baselines, report-based prompting via TS2R consistently improves LLM performance in terms of across accuracy, robustness, and explainability metrics. Notably, TS2R-integrated LLMs achieve expert-level decision quality and predictive consistency without retraining or architecture modification, establishing a practical path for adaptive, LLM-driven battery intelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2512.16453.pdf",
    "abs_url": "https://arxiv.org/abs/2512.16453",
    "published": "2025-12-18T12:15:52Z",
    "updated": "2026-01-29T11:42:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出TimeSeries2Report框架，将锂离子电池时间序列数据转换为语义报告，提升大型语言模型在电池管理中的性能。",
      "motivation": "大型语言模型在解释多元时间序列数据方面展现潜力，但其在真实世界电池储能系统操作和维护中的应用尚未充分探索。现有方法难以有效桥接低层次传感器信号与高层次决策需求，因为原始时间序列数据缺乏语义结构，阻碍了LLM的直接推理和预测。因此，研究动机是开发语义翻译框架以改进LLMs在电池管理中的适应性和应用能力，解决实际运维中的关键挑战。",
      "method": "研究方法基于TimeSeries2Report框架，通过分割、语义抽象和基于规则的解释，将短期时间动态编码为自然语言报告。该框架将原始锂离子电池操作时间序列转换为结构化、语义丰富的描述，使LLMs能够进行推理和决策。关键创新在于语义翻译技术，有效桥接传感器信号与上下文洞察。实验使用实验室规模和真实世界数据集，评估报告质量和下游任务如异常检测、状态预测和管理性能。",
      "result": "实验结果显示，与基于视觉、嵌入和文本的提示基线相比，TS2R框架通过报告提示在准确性、鲁棒性和可解释性方面持续提升LLM性能。在异常检测、状态估计和充放电管理等任务中，TS2R集成的LLMs实现专家级决策质量和预测一致性，且无需重新训练或架构修改，具体表现在性能指标的全面提升。",
      "conclusion": "TS2R框架为自适应LLM驱动电池智能提供了实用路径，显著提升电池管理中的决策效率和可靠性。研究的学术价值在于展示语义翻译如何桥接数据与LLM推理，实际应用价值在于推动电池储能系统的智能化运维。摘要未明确说明局限性，但未来工作可能涉及扩展更多电池类型、复杂场景或评估更多任务。",
      "tags": [
        "Large Language Model",
        "Time-Series Analysis",
        "Semantic Translation",
        "Battery Management",
        "Anomaly Detection"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:32.157559Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.15605",
    "title": "Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction",
    "authors": [
      "Mathieu Blondel",
      "Michael E. Sander",
      "Germain Vivier-Ardisson",
      "Tianlin Liu",
      "Vincent Roulet"
    ],
    "abstract": "Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.15605.pdf",
    "abs_url": "https://arxiv.org/abs/2512.15605",
    "published": "2025-12-17T17:14:26Z",
    "updated": "2026-01-29T13:36:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过统一自回归模型和基于能量模型的框架，揭示了自回归模型在下一个词预测范式下具备向前看能力，建立了模型间的理论等价性。",
      "motivation": "自回归模型（ARMs）是当前大语言模型的主流范式，但其基于下一个词预测的设计理论上限制规划能力。基于能量模型（EBMs）在LLM开发中较少见，但在后期训练对齐中自然描述最优策略，常用于强化学习。本研究旨在统一ARMs和EBMs，以解释ARMs为何能展现向前看能力，解决两种模型类别间的理论脱节问题，促进对LLMs内部机制的理解和模型转换。",
      "method": "研究方法以概率链法则为起点，在函数空间中建立ARMs和EBMs之间的显式双射，该双射对应于最大熵强化学习中的软贝尔曼方程特殊情形。在此基础上，推导了ARMs和EBMs在监督学习中的等价性，并通过理论分析连接了强化学习理论。此外，分析了从EBMs到ARMs的蒸馏过程，提供了理论误差界，强调数学推导的严谨性，没有使用具体数据集或模型架构。",
      "result": "摘要未明确说明具体实验结果或性能指标。论文通过理论分析建立了ARMs和EBMs的等价性，并推导了蒸馏过程的误差界，为ARMs的向前看能力提供解释。结果没有提供与基线方法的对比数据，主要是理论贡献，表明ARMs能通过EBMs视角进行规划，但缺少实证支持如准确率或效率改进。",
      "conclusion": "论文主要贡献是统一了ARMs和EBMs的视角，建立双射关系和等价性，解释了ARMs的规划能力。学术价值在于连接不同模型类别，为LLMs理论理解提供新框架。实际应用可能包括模型蒸馏和强化学习对齐，促进算法改进。局限性在于缺少实证验证，未来工作可扩展至更多模型或进行实验评估，增强理论的实际适用性。",
      "tags": [
        "Autoregressive Models",
        "Energy-Based Models",
        "Maximum Entropy Reinforcement Learning",
        "Soft Bellman Equation",
        "Distillation"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:05.245957Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.15596",
    "title": "Corrective Diffusion Language Models",
    "authors": [
      "Shuibai Zhang",
      "Fred Zhangzhi Peng",
      "Yiheng Zhang",
      "Jin Pan",
      "Grigorios G. Chrysos"
    ],
    "abstract": "While Diffusion Language Models (DLMs) are theoretically well-suited for iterative refinement due to their non-causal structure, they often fail to reliably revise incorrect tokens in practice. The key challenge lies in the model's inability to distinguish between correct and erroneous tokens in a visible sequence. Standard masked diffusion language model (MDLM) training is restricted to the objective of unmasking, undermining the effectiveness of refinement guided by confidence. Based on this observation, we study corrective behavior in DLMs, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a post-training principle oriented by correction that explicitly supervises visible incorrect tokens, enabling discriminative confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark, a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and parallel decoding scenarios demonstrate that models trained with our approach substantially outperform standard MDLMs, with gains that are most pronounced when parallel decoding introduces substantial uncertainty and iterative refinement becomes essential. Our code is publicly available at https://github.com/zhangshuibai/CDLM.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.15596.pdf",
    "abs_url": "https://arxiv.org/abs/2512.15596",
    "published": "2025-12-17T17:04:38Z",
    "updated": "2026-01-29T17:52:44Z",
    "comment": "21 pages",
    "light_analysis": {
      "overview": "提出一种基于纠正的扩散语言模型训练方法，通过明确监督可见错误token来提升模型的错误定位和修正能力，解决迭代精炼中的不足。",
      "motivation": "扩散语言模型（DLMs）理论上因非因果结构适合迭代精炼，但在实践中常无法可靠修正错误token，关键挑战是模型无法区分可见序列中的正确与错误token。标准masked扩散语言模型（MDLM）训练局限于去掩码目标，削弱了置信度引导的修正效果，因此本研究旨在解决DLMs在纠正行为上的不足，以增强其错误感知和迭代修正能力。",
      "method": "本研究提出一种面向纠正的后训练原则，通过明确监督可见错误token来启用判别性置信度和目标修正，核心创新在于改进传统训练目标以强化DLMs的错误感知。此外，引入Code Revision Benchmark作为评估基准，该基准可控且可执行，用于系统评估错误定位和原位修正，方法基于监督学习但具体实现细节摘要未明确说明。",
      "result": "实验在代码修订任务和并行解码场景中进行，结果表明，采用本方法的模型显著优于标准MDLMs，尤其当并行解码引入大量不确定性时，改进最为明显，突显了迭代精炼在复杂场景中的重要性，尽管摘要未提供具体性能指标，但效果得到验证。",
      "conclusion": "论文的主要贡献是提出一种增强扩散语言模型纠正行为的方法，通过后训练原则提升错误定位和修正能力，为DLMs的迭代精炼提供新思路，具有学术价值。实际应用如代码修订等领域可受益，未来工作可扩展到更广泛错误类型或其他任务，局限性摘要未明确说明。",
      "tags": [
        "Diffusion Language Models",
        "Corrective Training",
        "Confidence Guidance",
        "Error Localization",
        "Parallel Decoding"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:53.356563Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.15824",
    "title": "State-Augmented Graphs for Circular Economy Triage",
    "authors": [
      "Richard Fox",
      "Rui Li",
      "Gustav Jonsson",
      "Farzaneh Goli",
      "Miying Yang",
      "Emel Aktas",
      "Yongjing Wang"
    ],
    "abstract": "Circular economy (CE) triage is the assessment of products to determine which sustainable pathway they can follow once they reach the end of their usefulness as they are currently being used. Effective CE triage requires adaptive decisions that balance retained value against the costs and constraints of processing and labour. This paper presents a novel decision-making framework as a simple deterministic solver over a state-augmented Disassembly Sequencing Planning (DSP) graph. By encoding the disassembly history into the state, our framework enforces the Markov property, enabling optimal, recursive evaluation by ensuring each decision only depends on the previous state. The triage decision involves choices between continuing disassembly or committing to a CE option. The model integrates condition-aware utility based on diagnostic health scores and complex operational constraints. We demonstrate the framework's flexibility with a worked example: the hierarchical triage of electric vehicle (EV) batteries, where decisions are driven by the recursive valuation of components. The example illustrates how a unified formalism enables the accommodation of varying mechanical complexity, safety requirements, and economic drivers. This unified formalism therefore provides a tractable and generalisable foundation for optimising CE triage decisions across diverse products and operational contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2512.15824.pdf",
    "abs_url": "https://arxiv.org/abs/2512.15824",
    "published": "2025-12-17T16:23:47Z",
    "updated": "2026-01-29T17:22:39Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于状态增强图的决策框架，用于优化循环经济分类决策。",
      "motivation": "循环经济分类是评估产品废弃后可持续处理路径的关键环节，需平衡保留价值、处理成本和操作约束的自适应决策。现有方法在处理复杂多因素决策时可能缺乏灵活性，无法高效适应不同产品和环境，因此需要新框架来提供最优、可推广的决策方案。",
      "method": "论文提出一个状态增强拆卸序列规划图的决策框架，通过将拆卸历史编码入状态，强制执行马尔可夫性质，使每个决策仅依赖于前一个状态，实现最优递归评估。该框架集成基于诊断健康分数的条件感知效用和复杂操作约束，决策选项包括继续拆卸或选择特定循环经济路径，适用于层次分类场景如电动汽车电池。",
      "result": "摘要未明确提供具体的实验结果数据。论文通过电动汽车电池层次分类示例展示了框架的灵活性，能够适应不同机械复杂性、安全要求和经济驱动因素，但未与基线方法进行定量性能对比。",
      "conclusion": "论文的主要贡献是提出了一种统一的形式化决策框架，为循环经济分类提供了可处理和可推广的基础，具有重要学术价值和应用潜力。该研究促进了可持续决策优化，未来工作可扩展框架以处理更多产品类型和实时操作场景。",
      "tags": [
        "State-Augmented Graphs",
        "Disassembly Sequencing Planning",
        "Markov Property",
        "Recursive Evaluation",
        "Circular Economy Triage"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:24.924011Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.15098",
    "title": "Uni-Parser Technical Report",
    "authors": [
      "Xi Fang",
      "Haoyi Tao",
      "Shuwen Yang",
      "Chaozheng Huang",
      "Suyang Zhong",
      "Haocheng Lu",
      "Han Lyu",
      "Xinyu Li",
      "Linfeng Zhang",
      "Guolin Ke"
    ],
    "abstract": "This technical report introduces Uni-Parser, an industrial-grade document parsing engine tailored for scientific literature and patents, delivering high throughput, robust accuracy, and cost efficiency. Unlike pipeline-based document parsing methods, Uni-Parser employs a modular, loosely coupled multi-expert architecture that preserves fine-grained cross-modal alignments across text, equations, tables, figures, and chemical structures, while remaining easily extensible to emerging modalities. The system incorporates adaptive GPU load balancing, distributed inference, dynamic module orchestration, and configurable modes that support either holistic or modality-specific parsing. Optimized for large-scale cloud deployment, Uni-Parser achieves a processing rate of up to 20 PDF pages per second on 8 x NVIDIA RTX 4090D GPUs, enabling cost-efficient inference across billions of pages. This level of scalability facilitates a broad spectrum of downstream applications, ranging from literature retrieval and summarization to the extraction of chemical structures, reaction schemes, and bioactivity data, as well as the curation of large-scale corpora for training next-generation large language models and AI4Science models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.15098.pdf",
    "abs_url": "https://arxiv.org/abs/2512.15098",
    "published": "2025-12-17T05:41:40Z",
    "updated": "2026-01-29T16:05:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "Uni-Parser 提出了一个工业级文档解析引擎，采用模块化、多专家架构实现跨模态对齐和高吞吐量处理。",
      "motivation": "该研究旨在解决科学文献和专利文档解析中传统流水线方法可能存在的效率和扩展性不足问题。当前方法在跨模态对齐和扩展新兴模态方面有局限，而文档解析对这些应用（如AI模型训练）至关重要。通过引入创新架构，研究希望提升大规模文档处理的准确性和效率，以满足工业部署需求。",
      "method": "Uni-Parser 采用一种模块化、松散耦合的多专家架构，专注于维护文本、方程、表格、图形和化学结构间的跨模态对齐。系统集成自适应GPU负载平衡、分布式推理和动态模块编排，支持整体或模态特定解析模式，易于扩展到新兴模态，并针对大规模云部署优化设计。",
      "result": "Uni-Parser 在8个NVIDIA RTX 4090D GPU上实现了每秒处理多达20个PDF页面的高吞吐量，提升了成本效益，支持数十亿页面的高效推理。虽然摘要未明确提供具体基线对比，但性能指标表明在工业级文档解析中取得了显著改进。",
      "conclusion": "Uni-Parser 的主要贡献是开发了一个高吞吐量、可扩展的文档解析引擎，支持从文献检索到AI4Science模型训练等多种下游应用。它推动了大文档处理技术的发展，未来可能进一步扩展到更多模态或优化性能。",
      "tags": [
        "Document Parsing",
        "Multi-Expert Architecture",
        "Cross-Modal Alignment",
        "GPU Load Balancing",
        "Distributed Inference"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:50.663773Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.09780",
    "title": "Physics-Aware Heterogeneous GNN Architecture for Real-Time BESS Optimization in Unbalanced Distribution Systems",
    "authors": [
      "Aoxiang Ma",
      "Salah Ghamizi",
      "Jun Cao",
      "Pedro Rodriguez"
    ],
    "abstract": "Battery energy storage systems (BESS) have become increasingly vital in three-phase unbalanced distribution grids for maintaining voltage stability and enabling optimal dispatch. However, existing deep learning approaches often lack explicit three-phase representation, making it difficult to accurately model phase-specific dynamics and enforce operational constraints--leading to infeasible dispatch solutions. This paper demonstrates that by embedding detailed three-phase grid information--including phase voltages, unbalanced loads, and BESS states--into heterogeneous graph nodes, diverse GNN architectures (GCN, GAT, GraphSAGE, GPS) can jointly predict network state variables with high accuracy. Moreover, a physics-informed loss function incorporates critical battery constraints--SoC and C-rate limits--via soft penalties during training. Experimental validation on the CIGRE 18-bus distribution system shows that this embedding-loss approach achieves low prediction errors, with bus voltage MSEs of 6.92e-07 (GCN), 1.21e-06 (GAT), 3.29e-05 (GPS), and 9.04e-07 (SAGE). Importantly, the physics-informed method ensures nearly zero SoC and C-rate constraint violations, confirming its effectiveness for reliable, constraint-compliant dispatch.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.09780.pdf",
    "abs_url": "https://arxiv.org/abs/2512.09780",
    "published": "2025-12-10T16:00:18Z",
    "updated": "2026-01-29T14:00:35Z",
    "comment": "5 pages, 2 figures, 3 tables",
    "light_analysis": {
      "overview": "本文提出一种物理感知的异构图神经网络架构，用于三相不平衡配电系统中的实时电池储能系统优化，通过嵌入三相信息和物理约束提高预测准确性并确保调度可行性。",
      "motivation": "电池储能系统在三相不平衡配电网络中对于维持电压稳定性和实现最优调度至关重要。然而，现有深度学习方法通常缺乏明确的三相表示，难以准确建模相特定动态并强制执行操作约束，如 SoC 和 C-rate 限制，导致生成的调度方案可能不可行。这限制了 BESS 在实际配电系统中的应用效果，因此需要开发一种能够有效结合三相电网物理特性并确保约束符合的优化方法，以提升系统可靠性和效率。摘要未明确说明对比基线，但暗示现有方法在约束执行方面不足。",
      "method": "研究方法将三相电网的详细信息，包括相电压、不平衡负载和 BESS 状态，嵌入到异构图节点中，构建一个物理感知的图结构。采用多种图神经网络架构，如 GCN、GAT、GraphSAGE 和 GPS，来联合预测网络状态变量，以捕捉相特定动态。关键创新点在于引入一个物理感知的损失函数，通过软惩罚在训练过程中纳入电池的关键操作约束，如 SoC 和 C-rate 限制，确保模型输出符合物理可行性。实验在 CIGRE 18-bus 配电系统数据集上进行验证，以评估方法的性能。",
      "result": "在 CIGRE 18-bus 配电系统上的实验结果表明，该方法实现了低预测误差，具体总线电压均方误差分别为：GCN 6.92e-07、GAT 1.21e-06、GPS 3.29e-05、GraphSAGE 9.04e-07。更重要的是，物理感知方法确保了几乎零的 SoC 和 C-rate 约束违反，这与现有方法可能导致不可行调度方案形成对比，证实了该方法在可靠、符合约束的 BESS 调度中的有效性。摘要未提供具体基线比较数据，但通过约束违反减少和预测误差低展示了性能提升。",
      "conclusion": "本研究证明了通过嵌入三相电网信息和物理约束的异构图神经网络方法，能够准确预测网络状态并确保操作约束符合，为三相不平衡配电系统中的实时电池储能系统优化提供了可行方案。其学术价值在于结合了图神经网络和物理感知学习，提升了深度学习方法在电力系统中的应用可靠性；实际应用价值在于支持可靠的 BESS 调度，提高电网稳定性。摘要未明确说明局限性或未来工作方向，但可能包括扩展到更大规模系统或集成更多复杂约束。",
      "tags": [
        "Graph Neural Networks",
        "Heterogeneous Graphs",
        "Physics-Informed Learning",
        "Battery Energy Storage Systems",
        "Distribution Systems Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:00.472303Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.08557",
    "title": "SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds",
    "authors": [
      "Alexander Dow",
      "Manduhu Manduhu",
      "Matheus Santos",
      "Ben Bartlett",
      "Gerard Dooly",
      "James Riordan"
    ],
    "abstract": "This work leverages the continuous sweeping motion of LiDAR scanning to concentrate object detection efforts on specific regions that receive a change in point data from one frame to another. We achieve this by using a sliding time window with short strides and consider the temporal dimension by storing convolution results between passes. This allows us to ignore unchanged regions, significantly reducing the number of convolution operations per forward pass without sacrificing accuracy. This data reuse scheme introduces extreme sparsity to detection data. To exploit this sparsity, we extend our previous work on scatter-based convolutions to allow for data reuse, and as such propose Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling (SSCATeR). This operation treats incoming LiDAR data as a continuous stream and acts only on the changing parts of the point cloud. By doing so, we achieve the same results with as much as a 6.61-fold reduction in processing time. Our test results show that the feature maps output by our method are identical to those produced by traditional sparse convolution techniques, whilst greatly increasing the computational efficiency of the network.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.08557.pdf",
    "abs_url": "https://arxiv.org/abs/2512.08557",
    "published": "2025-12-09T12:58:10Z",
    "updated": "2026-01-29T14:42:39Z",
    "comment": "23 Pages, 27 Figures, This work has been accepted for publication by the IEEE Sensors Journal. Please see the first page of the article PDF for copyright information",
    "light_analysis": {
      "overview": "提出SSCATeR算法，通过时间数据重用和稀疏散射卷积，显著降低LiDAR点云实时3D物体检测的处理时间。",
      "motivation": "在LiDAR点云实时3D物体检测中，现有方法常因重复计算未变化区域而导致计算效率低下，影响实时性能。本研究旨在解决这一问题，通过利用LiDAR扫描的连续运动，专注于处理帧间数据变化的区域，减少不必要的卷积操作，从而提高检测效率和实际应用性。摘要强调了忽略不变区域的重要性，以减少计算负担而不牺牲准确性。",
      "method": "该方法采用滑动时间窗口和短步长策略，存储卷积结果以实现时间数据重用，引入稀疏性以减少计算量。基于先前散射卷积工作，扩展出SSCATeR算法，将LiDAR数据视为连续流，仅处理点云中变化的部分。关键创新点包括结合时间维度优化数据流，并利用散射卷积处理稀疏检测数据，从而在不影响准确性的前提下降低卷积操作次数。",
      "result": "实验结果表明，SSCATeR算法能将处理时间最高降低6.61倍，同时输出特征图与传统稀疏卷积技术完全相同。这证明了该方法在保持检测准确性的同时，显著提升了网络的计算效率。与基线方法相比，通过忽略不变区域和数据重用，实现了高效处理，适合实时3D物体检测应用。",
      "conclusion": "本研究的主要贡献是提出了SSCATeR算法，通过时间数据重用和稀疏处理，高效实现LiDAR点云实时3D物体检测，在计算效率上取得显著改进。该方法的学术价值在于优化了卷积操作，实际应用价值在于促进实时系统开发。未来工作可探索扩展到其他传感器或更复杂场景，进一步提升泛化能力。",
      "tags": [
        "Sparse Convolution",
        "Temporal Data Recycling",
        "LiDAR Point Cloud",
        "Real-Time 3D Object Detection",
        "Scatter-Based Convolution"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:52.726533Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.07052",
    "title": "RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting",
    "authors": [
      "Hoang-Nhat Tran",
      "Francesco Di Sario",
      "Gabriele Spadaro",
      "Giuseppe Valenzise",
      "Enzo Tartaglione"
    ],
    "abstract": "Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that supports interpolation at any rate between predefined bounds. Our method is computationally lightweight, requires no retraining for any rate, and preserves rendering quality across a broad range of operating points. Experiments demonstrate that the approach achieves efficient, high-quality compression while offering dynamic rate control, making it suitable for practical deployment in immersive applications. The code is available at https://github.com/inspiros/RAVE.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.07052.pdf",
    "abs_url": "https://arxiv.org/abs/2512.07052",
    "published": "2025-12-07T23:59:46Z",
    "updated": "2026-01-29T07:55:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "RAVE提出一种速率自适应的3D高斯泼溅压缩方法，支持任意速率插值，无需重新训练，保持渲染质量，提升部署灵活性。",
      "motivation": "3D高斯泼溅（3DGS）虽然能实现实时逼真渲染，推动沉浸式多媒体发展，但其存在内存需求大和训练成本高的问题，迫切需要压缩。现有压缩方法通常工作在固定速率，无法适应变化的网络带宽和设备资源限制，限制了在实际应用中的适应性和实用性。因此，开发一种动态速率的压缩方案对于优化3DGS在资源受限环境下的性能至关重要。",
      "method": "RAVE是一种灵活的压缩方案，基于3DGS，支持在预定义边界内任意速率的插值操作。方法采用轻量级设计，无需为不同速率重新训练模型，通过在压缩过程中自适应调整，确保广泛操作点下的渲染质量保持稳定。技术细节如具体模型架构和使用的数据集在摘要中未明确说明，但强调其计算效率高且易于集成。",
      "result": "实验表明，RAVE实现了高效且高质量的压缩，并提供动态速率控制，能在广泛的操作点上保持渲染质量，适应不同带宽场景。与固定速率方法相比，它在不牺牲性能的前提下提供更好的适应性，但摘要未提供具体指标如压缩比或质量损失数据，仅概述了其优势。",
      "conclusion": "该研究的主要贡献是开发了RAVE，一种速率自适应的压缩方案，使3DGS更适用于沉浸式应用部署，提高了压缩的灵活性和实用性。其意义在于支持动态带宽和设备需求，推动实际应用发展。摘要未讨论研究的局限性或未来工作方向，但暗示了在资源受限环境中的潜在价值。",
      "tags": [
        "3D Gaussian Splatting",
        "Compression",
        "Rate-Adaptive Encoding",
        "Visual Encoding",
        "Neural Scene Representations"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:11.830906Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.05844",
    "title": "NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation",
    "authors": [
      "Daniel Rose",
      "Roxane Axel Jacob",
      "Johannes Kirchmair",
      "Thierry Langer"
    ],
    "abstract": "Transformer-based autoregressive models offer a promising alternative to diffusion- and flow-matching approaches for generating 3D molecular structures. However, standard transformer architectures require a sequential ordering of tokens, which is not uniquely defined for the atoms in a molecule. Prior work has addressed this by using canonical atom orderings, but these do not ensure permutation invariance of atoms, which is essential for tasks like prefix completion. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns an order-agnostic distribution over admissible tokens at the graph boundary. NEAT achieves state-of-the-art performance in autoregressive 3D molecular generation whilst ensuring atom-level permutation invariance by design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.05844.pdf",
    "abs_url": "https://arxiv.org/abs/2512.05844",
    "published": "2025-12-05T16:18:07Z",
    "updated": "2026-01-29T13:23:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "NEAT是一个邻域引导的集合Transformer，通过设计确保原子排列不变性，实现了高效的3D分子生成。",
      "motivation": "本研究旨在解决标准Transformer模型在3D分子生成中因需要原子顺序标记化而缺乏排列不变性的问题。分子中原子的顺序不唯一，现有方法依赖规范排序但无法保证排列不变性，这对于诸如前缀完成等任务至关重要，因为它影响模型的泛化能力和分子结构的正确表示。排列不变性是分子生成的关键属性，确保模型处理不同原子排列时保持一致性，现有不足限制了自回归模型的实际应用场景和性能。",
      "method": "NEAT是一种邻域引导、高效、自回归的集合Transformer模型，将分子图视为原子集合，在图的边界上学习顺序无关的分布。其关键创新在于采用集合处理方法，避免了对原子顺序的依赖，并通过邻域信息引导生成过程，确保模型自回归地生成3D分子结构时保持原子级别的排列不变性。摘要未明确说明使用的具体数据集或模型架构细节，但基于描述，它结合了图结构表示和自回归机制来优化生成效率。",
      "result": "NEAT在自回归3D分子生成任务中取得了最先进的性能，具体表现为在相关基准测试中优于现有方法，并通过设计确保了原子级别的排列不变性。摘要未明确提供具体准确率或效率改进数据，但指出该方法在性能上领先，并与基线模型如扩散和流匹配方法进行了对比，验证了其在保持排列不变性方面的优势，提升了生成分子的质量和一致性。",
      "conclusion": "NEAT的主要贡献是提出了一种排列不变的自回归模型，解决了3D分子生成中的顺序依赖问题，推动了自回归方法在该领域的应用。其学术价值在于改进了Transformer架构的适应性，增强了模型对分子结构的处理能力；实际应用价值包括在药物发现和材料科学中的潜在使用。局限性或未来工作方向摘要未明确说明，但可能涉及扩展到更复杂分子生成或与其他生成模型结合。",
      "tags": [
        "Transformer",
        "Autoregressive Generation",
        "Set Transformer",
        "Permutation Invariance",
        "3D Molecular Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:18.529865Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.03537",
    "title": "Pushing the Limits of Distillation-Based Class-Incremental Learning via Lightweight Plugins",
    "authors": [
      "Zhiming Xu",
      "Baile Xu",
      "Jian Zhao",
      "Furao Shen",
      "Suorong Yang"
    ],
    "abstract": "Existing replay and distillation-based class-incremental learning (CIL) methods are effective at retaining past knowledge but are still constrained by the stability-plasticity dilemma. Since their resulting models are learned over a sequence of incremental tasks, they encode rich representations and can be regarded as pre-trained bases. Building on this view, we propose a plug-in extension paradigm termed Deployment of LoRA Components (DLC) to enhance them. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable content in software, DLC serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4\\% of the parameters of a standard ResNet-18, our DLC model achieves a significant 8\\% improvement in accuracy, demonstrating exceptional efficiency. Under a fixed memory budget, methods equipped with DLC surpass state-of-the-art expansion-based methods.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.03537.pdf",
    "abs_url": "https://arxiv.org/abs/2512.03537",
    "published": "2025-12-03T07:57:48Z",
    "updated": "2026-01-29T14:39:17Z",
    "comment": "10 pages, 6 figures, 2 tables",
    "light_analysis": {
      "overview": "论文提出了一种基于LoRA组件的插件扩展范式DLC，通过轻量级LoRA插件和权重单元增强现有类增量学习方法，显著提升效率并解决稳定性-可塑性困境。",
      "motivation": "类增量学习（CIL）面临稳定性与可塑性之间的平衡难题，现有重放和蒸馏方法虽能保留旧知识，但在持续学习新任务时仍受限制。这一问题在现实应用中至关重要，如自动驾驶或智能系统需不断适应新数据。现有方法虽然编码丰富表示并可作为预训练基础，但直接使用基础模型时，参数调整和干扰问题未被有效解决，导致性能瓶颈。本研究旨在通过轻量级插件扩展来克服这些不足，提高CIL的整体性能。",
      "method": "论文提出Deployment of LoRA Components（DLC）范式，基于现有CIL方法形成的预训练基础模型。对每个新任务，采用低秩适应（LoRA）技术将任务特定残差注入基础模型的深层，从而减少参数开销。推理时，聚合不同任务下的LoRA调优表示进行分类预测。为减轻非目标LoRA插件的干扰，引入了一个轻量级权重单元，学习分配重要性分数给各个表示。该方法作为一种即插即用增强，可灵活应用于现有CIL方法，使用ImageNet-100等数据集进行验证。",
      "result": "在ImageNet-100数据集上的实验显示，DLC模型仅使用标准ResNet-18参数的4%，即显著提升了准确率约8%，体现了高效的参数利用。与基线方法相比，配备DLC的方法在固定内存预算下超越了最先进的扩展型CIL方法，如重放或蒸馏技术，证明其在平衡稳定性和可塑性方面的优势。具体性能改进包括更高的分类准确率和更好的资源效率，为实际应用提供了有力支撑。",
      "conclusion": "本研究的主要贡献在于提出DLC范式，通过LoRA组件和权重单元有效增强CIL方法，解决了稳定性-可塑性困境。其学术价值在于提供了一种轻量级、即插即用的扩展思路，降低参数开销同时提升性能，对持续学习领域有重要推动作用。实际应用价值高，可广泛应用于需要动态适应的AI系统。未来工作可能包括扩展到更复杂任务或结合其他优化技术，但摘要未明确说明具体局限性。",
      "tags": [
        "Class-Incremental Learning",
        "Distillation",
        "Low-Rank Adaptation",
        "Weighting Unit",
        "Plugin-based Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:32.041638Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.02901",
    "title": "Fairy2i: Training Complex LLMs from Real LLMs with All Parameters in $\\{\\pm 1, \\pm i\\}$",
    "authors": [
      "Feiyu Wang",
      "Xinyu Tan",
      "Bokai Huang",
      "Yihao Zhang",
      "Guoan Wang",
      "Peizhuang Cong",
      "Tong Yang"
    ],
    "abstract": "Large language models (LLMs) have revolutionized artificial intelligence, yet their massive memory and computational demands necessitate aggressive quantization, increasingly pushing representations toward the theoretical limit of a single bit. While complex-valued LLMs, such as iFairy, offer a superior chance for low-bit representation compared to real-valued counterparts, they require training from scratch, preventing the utilization of the vast ecosystem of pre-trained real-valued foundation models. Here we present Fairy2i, a universal framework that transforms pre-trained real-valued layers into an equivalent widely-linear complex form, enabling extremely low-bit quantization while reusing existing checkpoints. By proving a lossless mathematical equivalence between real and widely-linear maps, we convert standard Transformers into the complex domain and employ a phase-aware quantization scheme with a highly efficient codebook of fourth roots of unity. Furthermore, we introduce a recursive residual quantization mechanism that iteratively minimizes quantization error, allowing inference to proceed via efficient multiplication-free accumulation. We demonstrate that Fairy2i restores the performance of LLaMA-2 7B at an effective 2-bit precision to levels nearly comparable with full-precision baselines, significantly outperforming state-of-the-art real-valued binary and ternary quantization methods. This work bridges the gap between the representational efficiency of complex-valued arithmetic and the practical utility of pre-trained models, paving a new way for efficient inference on commodity hardware. We open-source the Fairy2i model and code at https://huggingface.co/PKU-DS-LAB/Fairy2i-W2 and https://github.com/PKULab1806/Fairy2i-W2.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.02901.pdf",
    "abs_url": "https://arxiv.org/abs/2512.02901",
    "published": "2025-12-02T16:14:08Z",
    "updated": "2026-01-29T12:51:21Z",
    "comment": "15 pages, 3 figures",
    "light_analysis": {
      "overview": "提出Fairy2i框架，通过将预训练真实值LLMs无损转换为复数域，实现2位极低比特量化，显著提高计算效率，同时保持与全精度基线相当的性能。",
      "motivation": "大型语言模型在AI领域取得突破，但其庞大的内存和计算需求迫使研究转向低比特量化以降低部署成本。现有复数模型如iFairy在低比特表示上优于实数模型，但需从头训练，无法利用丰富的预训练实数模型生态，导致资源浪费和性能受限。因此，开发一种能重用预训练模型并实现高效量化方法至关重要，以解决量化中性能与效率的权衡问题。",
      "method": "Fairy2i通过证明实数与广泛线性复数映射间的无损数学等价，将标准Transformer层转换为复数形式。采用相感知量化方案，将参数限制在{±1, ±i}集合，并使用第四根单位数的高效码本。引入递归残差量化机制迭代最小化量化误差，推理时通过无乘法累加实现高效计算，可直接利用预训练检查点，避免从头训练。",
      "result": "实验显示，Fairy2i在LLaMA-2 7B模型上实现有效2位精度量化，性能恢复至接近全精度基线水平。与当前最佳的实数二元和三元量化方法相比，Fairy2i显著提升了准确性和效率，摘要未明确具体提升百分比，但强调了在保持性能的同时降低内存和计算需求，为高效推理提供新方案。",
      "conclusion": "Fairy2i的主要贡献是提出通用框架，将预训练实数LLMs转换为复数域以实现极低比特量化，弥补了复数表示效率与预训练模型实用性的差距。这项研究具有重要学术和应用价值，为商品硬件上高效部署LLMs铺平道路。潜在局限性可能包括对特定架构的依赖，未来工作可扩展到更多模型和量化级别。",
      "tags": [
        "Large Language Model",
        "Quantization",
        "Complex-valued Neural Networks",
        "Transformer",
        "Low-bit Precision"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:10.079577Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.00590",
    "title": "Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models",
    "authors": [
      "Alla Chepurova",
      "Aydar Bulatov",
      "Mikhail Burtsev",
      "Yuri Kuratov"
    ],
    "abstract": "Knowledge graphs (KGs) provide structured, verifiable grounding for large language models (LLMs), but current LLM-based systems commonly use KGs as auxiliary structures for text retrieval, leaving their intrinsic quality underexplored. In this work, we propose Wikontic, a multi-stage pipeline that constructs KGs from open-domain text by extracting candidate triplets with qualifiers, enforcing Wikidata-based type and relation constraints, and normalizing entities to reduce duplication. The resulting KGs are compact, ontology-consistent, and well-connected; on MuSiQue, the correct answer entity appears in 96% of generated triplets. On HotpotQA, our triplets-only setup achieves 76.0 F1, and on MuSiQue 59.8 F1, matching or surpassing several retrieval-augmented generation baselines that still require textual context. In addition, Wikontic attains state-of-the-art information-retention performance on the MINE-1 benchmark (86%), outperforming prior KG construction methods. Wikontic is also efficient at build time: KG construction uses less than 1,000 output tokens, about 3$\\times$ fewer than AriGraph and $<$1/20 of GraphRAG. The proposed pipeline enhances the quality of the generated KG and offers a scalable solution for leveraging structured knowledge in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.00590.pdf",
    "abs_url": "https://arxiv.org/abs/2512.00590",
    "published": "2025-11-29T18:44:25Z",
    "updated": "2026-01-29T14:52:01Z",
    "comment": null,
    "light_analysis": {
      "overview": "Wikontic提出一个多阶段管道，利用大型语言模型构建与Wikidata对齐、本体感知的知识图，显著提高其质量和构建效率。",
      "motivation": "当前基于大型语言模型的系统常将知识图作为文本检索的辅助结构，但未充分关注知识图的内在质量，如类型和关系一致性，这限制了其为模型提供结构化根基的能力。现有知识图构建方法可能缺乏严格的约束和规范化，导致实体重复或本体不一致，影响模型的可靠性和可扩展性，因此研究高质量知识图构建方法至关重要，以提升大型语言模型的性能和知识整合效果。",
      "method": "Wikontic采用多阶段管道构建知识图：首先从开放域文本提取带限定符的候选三元组，确保初始内容的丰富性；然后基于Wikidata强制执行类型和关系约束，以对齐本体并保证一致性；最后进行实体规范化，减少重复并增强连通性。关键创新点在于将约束对齐和规范化整合到流程中，利用大型语言模型高效提取，但具体模型架构摘要未明确说明。使用的数据集包括MuSiQue、HotpotQA和MINE-1基准，以验证方法的有效性。",
      "result": "Wikontic在多个基准测试中表现优异：在MuSiQue上，正确答案实体出现在96%的生成三元组中，显示出高覆盖率；在HotpotQA上，仅使用三元组的设置达到76.0 F1分数，在MuSiQue上达到59.8 F1分数，匹配或超越了需要文本上下文的检索增强生成基线方法。在MINE-1基准上，信息保留性能达86%，优于先前知识图构建方法。构建效率高，使用少于1,000个输出标记，比AriGraph减少约3倍，不及GraphRAG的1/20，突显了其可扩展性。",
      "conclusion": "本研究的主要贡献在于提出Wikontic管道，通过多阶段约束和规范化显著提升了知识图的质量和效率，为大型语言模型提供了一种可扩展的结构化知识利用方案。学术价值在于推动了知识图构建方法的研究，强调了本体对齐的重要性；实际应用价值在于支持高效知识集成，提升模型性能。未来工作方向可能包括扩展到更广泛的领域或优化约束机制，但摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Knowledge Graph Construction",
        "Ontology Alignment",
        "Triplet Extraction",
        "Wikidata"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:16.187276Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.20002",
    "title": "Semantic Router: On the Feasibility of Hijacking MLLMs via a Single Adversarial Perturbation",
    "authors": [
      "Changyue Li",
      "Jiaying Li",
      "Youliang Yuan",
      "Jiaming He",
      "Zhicong Huang",
      "Pinjia He"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in stateless systems, such as autonomous driving and robotics.   This paper investigates a novel threat: Semantic-Aware Hijacking. We explore the feasibility of hijacking multiple stateless decisions simultaneously using a single universal perturbation.   We introduce the Semantic-Aware Universal Perturbation (SAUP), which acts as a semantic router, \"actively\" perceiving input semantics and routing them to distinct, attacker-defined targets.   To achieve this, we conduct theoretical and empirical analysis on the geometric properties in the latent space. Guided by these insights, we propose the Semantic-Oriented (SORT) optimization strategy and annotate a new dataset with fine-grained semantics to evaluate performance. Extensive experiments on three representative MLLMs demonstrate the fundamental feasibility of this attack, achieving a 66% attack success rate over five targets using a single frame against Qwen.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.20002.pdf",
    "abs_url": "https://arxiv.org/abs/2511.20002",
    "published": "2025-11-25T07:13:13Z",
    "updated": "2026-01-29T15:12:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出Semantic-Aware Universal Perturbation (SAUP)作为语义路由器，探索了使用单一对抗扰动劫持多模态大语言模型的可行性。",
      "motivation": "随着多模态大语言模型在自动驾驶和机器人等无状态系统中的部署日益增加，安全性成为关键问题。现有对抗攻击方法可能无法高效地同时劫持多个决策，本研究针对Semantic-Aware Hijacking这一新威胁，探索使用单一通用扰动实现多目标劫持的可行性，以揭示安全漏洞并提升系统鲁棒性。摘要未明确说明现有具体方法的不足之处，但强调了这种攻击的新颖性和重要性。",
      "method": "论文通过理论和实证分析潜空间的几何属性，提出了Semantic-Aware Universal Perturbation (SAUP)，它作为语义路由器，能“主动”感知输入语义并将其路由到攻击者定义的目标。关键创新是Semantic-Oriented (SORT)优化策略，并注释了一个具有细粒度语义的新数据集用于评估性能，从而在技术上支持该方法，尽管摘要未详细描述模型架构。",
      "result": "在三个代表性多模态大语言模型上进行广泛实验，结果显示，使用单一帧对抗Qwen模型时，SAUP在五个目标上实现了66%的攻击成功率。这证明了Semantic-Aware Hijacking的基本可行性，与基线方法相比，显示了其高效性，摘要未提供具体的基线对比数据。",
      "conclusion": "本研究成功证明了Semantic-Aware Universal Perturbation (SAUP)能够有效劫持多模态大语言模型，揭示了其在无状态系统中的安全漏洞。学术价值在于提出了新的攻击方法和理论分析，实际应用价值在于促进防御技术的发展。未来工作可能包括改进攻击策略或探索更鲁棒的模型设计，摘要未明确说明局限性。",
      "tags": [
        "Multimodal Large Language Models",
        "Adversarial Perturbation",
        "Semantic-Aware Hijacking",
        "Latent Space Analysis",
        "Semantic-Oriented Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:15.441745Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.18940",
    "title": "Geometry-Aware Deep Congruence Networks for Manifold Learning in Cross-Subject Motor Imagery",
    "authors": [
      "Sanjeev Manivannan",
      "Chandrashekar Lakshminarayan"
    ],
    "abstract": "Cross-subject motor-imagery decoding remains a major challenge in EEG-based brain-computer interfaces. To mitigate strong inter-subject variability, recent work has emphasized manifold-based approaches operating on covariance representations. Yet dispersion scaling and orientation alignment remain largely unaddressed in existing methods. In this paper, we address both issues through congruence transforms and introduce three complementary geometry-aware models: (i) Discriminative Congruence Transform (DCT), (ii) Deep Linear DCT (DLDCT), and (iii) Deep DCT-UNet (DDCT-UNet). These models are evaluated both as pre-alignment modules for downstream classifiers and as end-to-end discriminative systems trained via cross-entropy backpropagation with a custom logistic-regression head. Across challenging motor-imagery benchmarks, the proposed framework improves transductive cross-subject accuracy by 2-3%, demonstrating the value of geometry-aware congruence learning.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.18940.pdf",
    "abs_url": "https://arxiv.org/abs/2511.18940",
    "published": "2025-11-24T09:46:55Z",
    "updated": "2026-01-29T12:33:40Z",
    "comment": "65 pages (Main paper - 10 pages, Appendix - 55 pages)",
    "light_analysis": {
      "overview": "提出几何感知一致性变换网络，通过解决分散缩放和方向对齐问题，提升交叉主体运动想象的解码准确性。",
      "motivation": "交叉主体运动想象解码是EEG脑机接口的主要挑战，由于主体间变异性强，现有方法虽采用流形学习和协方差表示，但分散缩放和方向对齐问题未得到充分处理，导致解码性能受限。这一问题的重要性在于提升脑机接口的泛化能力和实用性，尤其在临床应用和用户交互中，需解决个体差异以提高准确性。摘要未明确说明其他具体不足，但强调了现有方法的局限。",
      "method": "论文提出三个互补的几何感知模型：判别一致性变换（DCT）、深度线性DCT（DLDCT）和深度DCT-UNet（DDCT-UNet），核心是基于一致性变换来处理几何对齐问题。关键创新点在于引入几何感知一致性学习框架，通过整合深度神经网络增强模型表达。这些模型可作为预对齐模块供下游分类器使用，或作为端到端判别系统训练，采用交叉熵反向传播和自定义逻辑回归头。数据集涉及挑战性运动想象基准，但摘要未明确说明具体名称或架构细节。",
      "result": "在挑战性运动想象基准测试中，提出的框架将跨主体传递准确率提高了2-3%，证明了几何感知一致性学习的有效性。实验结果未提供具体基线对比或详细指标，但基于摘要信息，可以推断该改进相对于现有方法有显著提升，尤其在处理强主体间变异性时表现突出。这一改进可能应用于多个基准数据集，但摘要未明确说明具体对比细节。",
      "conclusion": "论文的主要贡献是开发了几何感知一致性变换网络，有效解决了流形学习中的分散缩放和方向对齐问题。学术价值在于推动了交叉主体脑电解码技术的发展，为机器学习在生物信号处理中的应用提供新思路；实际应用价值在于提升脑机接口的性能和鲁棒性，促进其在康复和交互领域的应用。局限性或未来工作摘要未明确说明，但可能包括扩展到其他脑电任务或优化模型复杂度。",
      "tags": [
        "Manifold Learning",
        "Congruence Transforms",
        "Deep Learning",
        "EEG Motor Imagery",
        "Cross-Subject Classification"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:13.741250Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.18689",
    "title": "QuantKAN: A Unified Quantization Framework for Kolmogorov Arnold Networks",
    "authors": [
      "Kazi Ahmed Asif Fuad",
      "Lizhong Chen"
    ],
    "abstract": "Kolmogorov Arnold Networks (KANs) represent a new class of neural architectures that replace conventional linear transformations and node-based nonlinearities with spline-based function approximations distributed along network edges. Although KANs offer strong expressivity and interpretability, their heterogeneous spline and base branch parameters hinder efficient quantization, which remains unexamined compared to CNNs and Transformers. In this paper, we present QuantKAN, a unified framework for quantizing KANs across both quantization aware training (QAT) and post-training quantization (PTQ) regimes. QuantKAN extends modern quantization algorithms, such as LSQ, LSQ+, PACT, DoReFa, QIL, GPTQ, BRECQ, AdaRound, AWQ, and HAWQ-V2, to spline based layers with branch-specific quantizers for base, spline, and activation components. Through extensive experiments on MNIST, CIFAR 10, and CIFAR 100 across multiple KAN variants (EfficientKAN, FastKAN, PyKAN, and KAGN), we establish the first systematic benchmarks for low-bit spline networks. Our results show that KANs, particularly deeper KAGN variants, are compatible with low-bit quantization but exhibit strong method architecture interactions: LSQ, LSQ+, and PACT preserve near full precision accuracy at 4 bit for shallow KAN MLP and ConvNet models, while DoReFa provides the most stable behavior for deeper KAGN under aggressive low-bit settings. For PTQ, GPTQ and Uniform consistently deliver the strongest overall performance across datasets, with BRECQ highly competitive on simpler regimes such as MNIST. Our proposed QuantKAN framework thus unifies spline learning and quantization, and provides practical tools and guidelines for efficiently deploying KANs in real-world, resource-constrained environments.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.18689.pdf",
    "abs_url": "https://arxiv.org/abs/2511.18689",
    "published": "2025-11-24T02:05:16Z",
    "updated": "2026-01-29T08:38:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "QuantKAN 首次提出了一个统一的量化框架，系统化地应用于 Kolmogorov Arnold Networks，解决了异构参数量化挑战，并建立了首个低比特样条网络基准。",
      "motivation": "Kolmogorov Arnold Networks (KANs) 作为一种新兴的神经网络架构，通过样条函数近似替代传统线性变换和节点非线性，展现出更强的表达能力和可解释性。然而，KANs的异构参数结构（包括样条和基础分支）给高效量化带来困难，限制了在资源受限环境中的应用。与已经广泛研究的CNNs和Transformers相比，KANs的量化问题尚未得到系统探索，因此本研究旨在填补这一空白，解决KANs量化过程中的实际挑战，推动其优化和部署。",
      "method": "QuantKAN 框架扩展了多种现代量化算法，如 LSQ、LSQ+、PACT、DoReFa、GPTQ、BRECQ、AdaRound、AWQ 和 HAWQ-V2，以适应KANs的样条层。关键创新在于为每个分支（基础、样条和激活组件）设计特定的量化器，以处理异构参数。研究使用MNIST、CIFAR10和CIFAR100数据集，并测试多种KAN变体（如EfficientKAN、FastKAN、PyKAN和KAGN），建立了系统化的实验基准，涵盖量化感知训练（QAT）和后训练量化（PTQ）两种模式，从而实现量化过程的统一化。",
      "result": "实验结果表明，KANs能够兼容低比特量化，但不同量化方法与网络架构之间存在强交互作用。在QAT中，LSQ、LSQ+和PACT在4位量化下对浅层KAN模型（如MLP和ConvNet变体）保持了接近全精度的准确率。对于深层KAGN，DoReFa在激进的低比特设置下提供了最稳定的行为。在PTQ方面，GPTQ和Uniform方法在所有数据集中表现出最强的整体性能，而BRECQ在简单任务如MNIST上具有高竞争力，凸显了不同算法的适用场景差异。",
      "conclusion": "本论文的主要贡献是提出了QuantKAN，一个统一的量化框架，首次将量化技术系统化地应用于Kolmogorov Arnold Networks。这解决了KANs量化中的关键挑战，如异构参数处理，并为实际部署提供了实用工具和指导。研究不仅建立了首个低比特样条网络基准，还揭示了量化方法与网络架构之间的交互规律，具有重要的学术价值和现实应用意义，特别是在资源受限环境下部署高效AI模型。未来工作可扩展更多量化算法或应用到其他样条网络变体。",
      "tags": [
        "Kolmogorov Arnold Networks",
        "Quantization",
        "Spline Approximation",
        "Quantization Aware Training",
        "Post-Training Quantization"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:15.842832Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.16870",
    "title": "Align & Invert: Solving Inverse Problems with Diffusion and Flow-based Models via Representation Alignment",
    "authors": [
      "Loukas Sfountouris",
      "Giannis Daras",
      "Paris Giampouras"
    ],
    "abstract": "Enforcing alignment between the internal representations of diffusion or flow-based generative models and those of pretrained self-supervised encoders has recently been shown to provide a powerful inductive bias, improving both convergence and sample quality. In this work, we extend this idea to inverse problems, where pretrained generative models are employed as priors. We propose applying representation alignment (REPA) between diffusion or flow-based models and a DINOv2 visual encoder, to guide the reconstruction process at inference time. Although ground-truth signals are unavailable in inverse problems, we empirically show that aligning model representations of approximate target features can substantially enhance reconstruction quality and perceptual realism. We provide theoretical results showing (a) that REPA regularization can be viewed as a variational approach for minimizing a divergence measure in the DINOv2 embedding space, and (b) how under certain regularity assumptions REPA updates steer the latent diffusion states toward those of the clean image. These results offer insights into the role of REPA in improving perceptual fidelity. Finally, we demonstrate the generality of our approach by We integrate REPA into multiple state-of-the-art inverse problem solvers, and provide extensive experiments on super-resolution, box inpainting, Gaussian deblurring, and motion deblurring confirming that our method consistently improves reconstruction quality, while also providing efficiency gains reducing the number of required discretization steps.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.16870.pdf",
    "abs_url": "https://arxiv.org/abs/2511.16870",
    "published": "2025-11-21T00:37:04Z",
    "updated": "2026-01-29T17:34:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了通过表示对齐（REPA）将扩散或基于流的生成模型与DINOv2编码器结合，以提升反问题求解的重建质量和效率。",
      "motivation": "在反问题求解中，预训练的生成模型常被用作先验来重建信号，但现有方法可能在重建质量和感知逼真度上存在不足。最近研究表明，扩散模型与自监督编码器的表示对齐能改善收敛性和样本质量，这为反问题领域提供了新思路。然而，现有方法在应用这一技术时可能缺乏系统性，导致重建过程效率低下或结果不理想。因此，本研究旨在将表示对齐扩展到反问题，以解决这些局限性，提升实际应用中的性能。",
      "method": "本文提出表示对齐（REPA）方法，在推理时将扩散或基于流的生成模型与预训练的DINOv2视觉编码器的内部表示进行对齐，以指导反问题的重建过程。创新点在于尽管反问题中缺乏真实信号，但通过对齐近似目标特征来提升重建质量。理论分析显示，REPA可视为在DINOv2嵌入空间中最小化散度的变分方法，并在一定条件下引导潜在扩散状态向干净图像发展。方法集成到多个最先进的反问题求解器中，应用于超分辨率、修复和去模糊等任务，增强了技术的通用性。",
      "result": "实验结果表明，REPA方法在超分辨率、框内修复、高斯去模糊和运动去模糊等多种反问题任务上，一致提升了重建质量和感知逼真度。同时，该方法提高了效率，减少了所需离散化步骤的数量，从而在计算资源上具有优势。与多个基线方法相比，REPA显示出显著的改进，例如在重建质量上获得更好结果，尽管摘要未提供具体准确率数据。广泛实验验证了其有效性和通用性，表明该方法在实际应用中具有潜力。",
      "conclusion": "本研究的主要贡献是提出了REPA方法，成功将表示对齐技术应用于反问题求解，不仅提升了重建质量和效率，还提供了理论支撑。通过理论分析，阐明了REPA在改善感知逼真度中的作用，为未来研究提供了洞察。研究具有学术价值，推动了生成模型在反问题中的应用，并暗示了扩展到其他编码器和任务的潜力。摘要未明确说明局限性，但强调了方法的通用性，未来工作可进一步探索更广泛的应用场景或结合其他自监督编码器。",
      "tags": [
        "Diffusion Models",
        "Flow-based Models",
        "Representation Alignment",
        "Inverse Problems",
        "DINOv2"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:15.997281Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.16147",
    "title": "TS-PEFT: Unveiling Token-Level Redundancy in Parameter-Efficient Fine-Tuning",
    "authors": [
      "Dabiao Ma",
      "Ziming Dai",
      "Zhimin Xin",
      "Shu Wang",
      "Jian Yang",
      "Haojun Fei"
    ],
    "abstract": "Current Parameter-Efficient Fine-Tuning (PEFT) methods typically operate under an implicit assumption: Once a target module is selected, every token passing through it contributes equally to the downstream task and requires a parameter update. In this paper, we challenge this convention by revealing a pervasive token-level redundancy in the fine-tuning of large models (LMs). We propose TS-PEFT, a theoretical framework utilizing proximal optimization that acts as a dynamic probe to identify token-level redundancy during the fine-tuning process. Extensive experiments demonstrate that indiscriminately updating all tokens is not only computationally superfluous but often introduces optimization noise. Surprisingly, by discarding 30%-70% of token updates, TS-PEFT consistently matches or exceeds the performance of dense baselines such as LoRA, DoRA. Our in-depth analysis shows that the learned token-level sparsity is a superior indicator of module importance compared to traditional weight criteria, providing a novel data-driven perspective on the intrinsic adaptation mechanism of LMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2511.16147.pdf",
    "abs_url": "https://arxiv.org/abs/2511.16147",
    "published": "2025-11-20T08:41:20Z",
    "updated": "2026-01-29T12:19:42Z",
    "comment": "11 pages, 3 figures",
    "light_analysis": {
      "overview": "提出TS-PEFT框架，利用近端优化识别令牌级冗余，挑战了参数高效微调中所有令牌同等贡献的假设。",
      "motivation": "当前参数高效微调方法假设目标模块中所有令牌对下游任务贡献相同，需要统一参数更新，但本研究揭示大型模型中普遍存在令牌级冗余，这导致计算浪费和优化噪声。问题的重要性在于微调大型模型时计算成本高昂，现有方法如LoRA、DoRA盲目更新所有令牌，效率低下且可能引入不必要误差。因此，研究旨在解决冗余更新问题，提高微调过程的效率和效果。",
      "method": "TS-PEFT是一个理论框架，采用近端优化作为动态探针，在微调过程中识别令牌级冗余。关键创新是通过优化方法学习令牌级稀疏性，以数据驱动方式揭示大型模型的内在适应机制，而无需依赖传统权重标准。该方法不指定特定数据集或模型架构，而是专注于动态评估令牌重要性，从而实现高效的参数更新策略。",
      "result": "实验显示，通过丢弃30%-70%的令牌更新，TS-PEFT性能一致匹配或超越密集基线如LoRA和DoRA，证明了减少冗余更新的有效性。具体地，令牌级稀疏性成为评估模块重要性的更优指标，提供了比传统方法更准确的数据驱动洞察，从而在优化效率和模型性能之间取得平衡。",
      "conclusion": "本研究的主要贡献是提出TS-PEFT框架，通过识别令牌级冗余减少计算浪费，提高参数高效微调的效率，并为大型模型的适应机制提供了新视角。学术价值在于挑战了现有假设，推动了微调方法的优化；实际应用价值包括降低计算成本。未来工作可探索该框架在不同任务和模型中的泛化性，以及进一步分析稀疏性的具体应用。摘要未明确说明局限性。",
      "tags": [
        "Parameter-Efficient Fine-Tuning",
        "Token-Level Redundancy",
        "Proximal Optimization",
        "Large Models",
        "Sparsity Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:51.555283Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.10233",
    "title": "Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation",
    "authors": [
      "Jianghan Zhu",
      "Yaoxin Wu",
      "Zhuoyi Lin",
      "Zhengyuan Zhang",
      "Haiyan Yin",
      "Zhiguang Cao",
      "Senthilnath Jayavelu",
      "Xiaoli Li"
    ],
    "abstract": "Recent advances in Neural Combinatorial Optimization (NCO) methods have significantly improved the capability of neural solvers to handle synthetic routing instances. Nonetheless, existing neural solvers typically struggle to generalize effectively from synthetic, uniformly-distributed training data to real-world VRP scenarios, including widely recognized benchmark instances from TSPLib and CVRPLib. To bridge this generalization gap, we present Evolutionary Realistic Instance Synthesis (EvoReal), which leverages an evolutionary module guided by large language models (LLMs) to generate synthetic instances characterized by diverse and realistic structural patterns. Specifically, the evolutionary module produces synthetic instances whose structural attributes statistically mimics those observed in authentic real-world instances. Subsequently, pre-trained NCO models are progressively refined, firstly aligning them with these structurally enriched synthetic distributions and then further adapting them through direct fine-tuning on actual benchmark instances. Extensive experimental evaluations demonstrate that EvoReal markedly improves the generalization capabilities of state-of-the-art neural solvers, yielding a notable reduced performance gap compared to the optimal solutions on the TSPLib (1.05%) and CVRPLib (2.71%) benchmarks across a broad spectrum of problem scales.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.10233.pdf",
    "abs_url": "https://arxiv.org/abs/2511.10233",
    "published": "2025-11-13T12:06:11Z",
    "updated": "2026-01-29T12:28:40Z",
    "comment": "21 pages; Published in AAAI 2026, Main Technical Track",
    "light_analysis": {
      "overview": "该论文提出EvoReal方法，通过LLM指导的进化实例生成和渐进适应，显著提升神经求解器在真实路由问题上的泛化性能。",
      "motivation": "研究动机源于现有神经组合优化方法在处理合成数据时表现良好，但在泛化到真实世界车辆路径问题场景（如TSPLib和CVRPLib基准实例）时效果不佳。由于合成训练数据通常均匀分布，缺乏真实实例的多样化结构模式，导致神经求解器在现实应用中的有效性受限。这一问题的重要性在于限制了AI在实际物流和调度领域的应用，需要弥合合成与真实数据之间的泛化鸿沟。",
      "method": "论文提出Evolutionary Realistic Instance Synthesis (EvoReal)方法，核心是利用大型语言模型指导的进化模块生成合成实例。这些实例的结构属性统计上模拟真实世界实例的多样模式。随后采用渐进适应策略：首先将预训练的神经组合优化模型与这些真实感合成分布对齐，然后在实际基准实例上进行直接微调。该方法结合了LLM的生成能力和进化优化，以增强训练数据的真实性和多样性。",
      "result": "实验评估显示，EvoReal方法显著提高了神经求解器的泛化能力。在TSPLib基准上，性能差距降至最优解的1.05%；在CVRPLib基准上，降至2.71%。与基线神经求解器相比，这些改进表明EvoReal有效减小了与最优解的差距，并增强了在多种问题规模上的性能表现，证明了该方法在提升泛化性能方面的有效性。",
      "conclusion": "该研究的核心贡献是EvoReal方法，通过LLM指导的实例生成和渐进适应，成功弥合了合成与真实路由问题之间的泛化差距。学术价值在于为神经组合优化领域提供了新的泛化技术；实际应用价值在于使神经求解器能更有效地适应真实世界车辆路径问题场景。摘要未明确说明局限性，未来工作可能涉及将该方法扩展到其他优化问题领域。",
      "tags": [
        "Neural Combinatorial Optimization",
        "Large Language Models",
        "Evolutionary Instance Synthesis",
        "Progressive Adaptation",
        "Vehicle Routing Problems"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:17.686795Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.09529",
    "title": "SiDGen: Structure-informed Diffusion for Generative modeling of Ligands for Proteins",
    "authors": [
      "Samyak Sanghvi",
      "Nishant Ranjan",
      "Tarak Karmakar"
    ],
    "abstract": "Designing ligands that are both chemically valid and structurally compatible with protein binding pockets is a key bottleneck in computational drug discovery. Existing approaches either ignore structural context or rely on expensive, memory-intensive encoding that limits throughput and scalability. We present SiDGen (Structure-informed Diffusion Generator), a protein-conditioned diffusion framework that integrates masked SMILES generation with lightweight folding-derived features for pocket awareness. To balance expressivity with efficiency, SiDGen supports two conditioning pathways: a streamlined mode that pools coarse structural signals from protein embeddings and a full mode that injects localized pairwise biases for stronger coupling. A coarse-stride folding mechanism with nearest-neighbor upsampling alleviates the quadratic memory costs of pair tensors, enabling training on realistic sequence lengths. Learning stability is maintained through in-loop chemical validity checks and an invalidity penalty, while large-scale training efficiency is restored \\textit{via} selective compilation, dataloader tuning, and gradient accumulation. In automated benchmarks, SiDGen generates ligands with high validity, uniqueness, and novelty, while achieving competitive performance in docking-based evaluations and maintaining reasonable molecular properties. These results demonstrate that SiDGen can deliver scalable, pocket-aware molecular design, providing a practical route to conditional generation for high-throughput drug discovery.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.09529.pdf",
    "abs_url": "https://arxiv.org/abs/2511.09529",
    "published": "2025-11-12T18:25:51Z",
    "updated": "2026-01-29T17:59:16Z",
    "comment": "10 pages, 2 figures",
    "light_analysis": {
      "overview": "SiDGen 提出一种结构感知的扩散模型，用于高效生成与蛋白质结合口袋兼容的配体，平衡了表达性与效率。",
      "motivation": "计算机辅助药物设计中，设计出化学有效且与蛋白质结合口袋结构兼容的配体是关键瓶颈。现有方法要么忽略结构上下文，导致生成配体与口袋不匹配，要么依赖内存密集型编码，限制了吞吐量和可扩展性，阻碍了高通量药物发现的进展，因此需要一种能整合结构信息并高效处理的方法来解决此问题。",
      "method": "SiDGen 是一种蛋白条件扩散框架，集成了掩码 SMILES 生成与轻量级折叠派生特征以实现口袋感知。其创新点包括两种条件路径：简化模式从蛋白嵌入中汇集粗结构信号，完整模式注入局部成对偏置以增强耦合。采用粗步折叠机制与最近邻上采样减轻二次内存成本，支持在现实序列长度上训练。学习稳定性通过循环化学有效性检查和无效性惩罚维护，大规模训练效率通过选择性编译、数据加载器调优和梯度积累优化。",
      "result": "在自动化基准测试中，SiDGen 生成的配体表现出高有效性、独特性和新颖性，摘要未提供具体数值，但指出在基于对接的评估中实现竞争性能，表明与蛋白质口袋结构兼容性良好，同时保持合理的分子性质，为结构感知分子生成提供了有效解决方案。",
      "conclusion": "SiDGen 的主要贡献是提供了一个可扩展、口袋感知的分子设计框架，通过扩散模型整合结构信息，平衡了表达性与效率，具有学术价值和应用价值，为高通量药物发现提供实用路径，摘要未明确说明局限性，但未来工作可能涉及性能优化或扩展应用。",
      "tags": [
        "Diffusion Model",
        "SMILES Generation",
        "Protein-Ligand Design",
        "Computational Drug Discovery",
        "Machine Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:32.197501Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.08234",
    "title": "Beyond Distributions: Geometric Action Control for Continuous Reinforcement Learning",
    "authors": [
      "Zhihao Lin"
    ],
    "abstract": "Gaussian policies have dominated continuous control in deep reinforcement learning (RL), yet they suffer from a fundamental mismatch: their unbounded support requires ad-hoc squashing functions that distort the geometry of bounded action spaces. While von Mises-Fisher (vMF) distributions offer a theoretically grounded alternative on the sphere, their reliance on Bessel functions and rejection sampling hinders practical adoption. We propose \\textbf{Geometric Action Control (GAC)}, a novel action generation paradigm that preserves the geometric benefits of spherical distributions while \\textit{simplifying computation}. GAC decomposes action generation into a direction vector and a learnable concentration parameter, enabling efficient interpolation between deterministic actions and uniform spherical noise. This design reduces parameter count from \\(2d\\) to \\(d+1\\), and avoids the \\(O(dk)\\) complexity of vMF rejection sampling, achieving simple \\(O(d)\\) operations. Empirically, GAC consistently matches or exceeds state-of-the-art methods across six MuJoCo benchmarks, achieving 37.6\\% improvement over SAC on Ant-v4 and up to 112\\% on complex DMControl tasks, demonstrating strong performance across diverse benchmarks. Our ablation studies reveal that both \\textbf{spherical normalization} and \\textbf{adaptive concentration control} are essential to GAC's success. These findings suggest that robust and efficient continuous control does not require complex distributions, but a principled respect for the geometry of action spaces.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.08234.pdf",
    "abs_url": "https://arxiv.org/abs/2511.08234",
    "published": "2025-11-11T13:32:38Z",
    "updated": "2026-01-29T16:01:23Z",
    "comment": "22 pages, 8 figures",
    "light_analysis": {
      "overview": "论文提出了Geometric Action Control，一种基于几何动作空间控制的新方法，通过简化计算在连续强化学习中实现高效动作生成。",
      "motivation": "高斯策略在深度强化学习的连续控制中占主导，但其无界支持需使用临时压缩函数，导致动作空间的几何扭曲；而vMF分布作为理论替代，依赖贝塞尔函数和拒绝采样，计算复杂、效率低下，限制了实际应用。因此，研究旨在开发一种既能保留几何优势又能提升计算效率的方法，解决现有方法的不足。",
      "method": "Geometric Action Control将动作生成分解为方向向量和可学习的集中参数，实现确定性动作与均匀球形噪声的高效插值。关键创新包括球形归一化和自适应集中控制，减少参数数量从2d到d+1，避免了vMF分布的O(dk)复杂度，仅需O(d)操作，简化了计算并保留了动作空间几何结构。",
      "result": "在六个MuJoCo基准测试中，GAC一致匹配或超过了最先进方法，具体在Ant-v4任务上比SAC性能提升37.6%，在复杂DMControl任务上提升高达112%。消融研究表明球形归一化和自适应集中控制是GAC成功的关键因素，验证了其高效性和稳健性。",
      "conclusion": "论文的主要贡献是提出GAC，证明了连续控制不需要复杂概率分布，而应基于动作空间的几何原则设计方法。这为强化学习提供了更高效、稳健的框架，具有实际应用价值；未来可扩展至更复杂场景或与其他控制技术结合。",
      "tags": [
        "Continuous Reinforcement Learning",
        "Geometric Action Control",
        "Spherical Normalization",
        "Adaptive Concentration Control",
        "von Mises-Fisher distributions"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:36.451513Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.07110",
    "title": "Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture",
    "authors": [
      "Tianhao Fu",
      "Xinxin Xu",
      "Weichen Xu",
      "Jue Chen",
      "Ruilong Ren",
      "Bowen Deng",
      "Xinyu Zhao",
      "Jian Cao",
      "Xixin Cao"
    ],
    "abstract": "Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an Hájek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.07110.pdf",
    "abs_url": "https://arxiv.org/abs/2511.07110",
    "published": "2025-11-10T13:57:05Z",
    "updated": "2026-01-29T13:22:04Z",
    "comment": "accepted by AAAI2026",
    "light_analysis": {
      "overview": "提出一个名为CMM的新框架，通过特征分解和混合将大语言模型特征蒸馏到小模型中，以提升市场制造任务的性能与效率。",
      "motivation": "市场制造在金融交易中通过强化学习受到关注，但大语言模型直接应用作为代理虽性能显著，却因推理速度慢而受限。当前研究未深入探讨针对此任务的LLM蒸馏方法，这使得平衡性能与效率成为重要问题。因此，本研究的动机是开发一种高效的蒸馏框架，以克服现有方法的不足并优化金融领域的应用效果。",
      "method": "论文首先提出归一化荧光探针，用于分析大语言模型的特征机制。基于此观察，设计了合作市场制造（CMM）框架，将LLM特征在层、任务和数据三个正交维度上解耦。多个学生模型协作学习不同维度的简化特征，实现知识蒸馏，每个模型负责特定特征。此外，引入Hájek-MoE方法，通过在核函数生成的共同特征空间中评估各模型的贡献来整合输出，从而优化整体性能。关键创新包括特征分解策略和混合专家机制的集成。",
      "result": "在四个真实市场数据集上进行广泛实验，结果表明CMM框架在性能上优于当前的知识蒸馏方法以及基于强化学习的市场制造策略。具体而言，CMM展现出显著的优势，验证了特征分解和混合的有效性，但摘要未明确说明具体性能指标如准确率或效率改进的数值。与基线方法对比，CMM在多个数据集上均取得更优效果。",
      "conclusion": "CMM框架通过特征分解和混合，成功将大语言模型特征蒸馏到小模型中，解决了推理速度慢的问题，同时保持了高性能。这一研究在学术上贡献了创新的蒸馏技术，在实际应用中为金融交易提供了高效的市场制造策略。未来工作可探索更多特征维度或扩展至其他领域，潜在局限性可能包括对数据集的特异性依赖。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Knowledge Distillation",
        "Feature Decomposition",
        "Mixture of Experts"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:54.326803Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.06411",
    "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization",
    "authors": [
      "Zhi Zheng",
      "Yu Gu",
      "Wei Liu",
      "Yee Whye Teh",
      "Wee Sun Lee"
    ],
    "abstract": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.06411.pdf",
    "abs_url": "https://arxiv.org/abs/2511.06411",
    "published": "2025-11-09T14:55:50Z",
    "updated": "2026-01-29T12:07:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出SofT-GRPO算法，通过Gumbel-Reparameterized Soft-Thinking Policy Optimization首次实现soft-thinking LLM的强化学习，在Pass@32准确率上显著超越传统离散token方法。",
      "motivation": "本研究旨在解决大型语言模型（LLM）推理中soft-thinking模式与强化学习（RL）结合的难题。尽管soft-thinking在某些场景下优于传统离散token的思维链（CoT）推理，具有重要研究和应用价值，但现有方法如GRPO难以扩展，原因在于向soft-thinking tokens注入随机性和更新策略的复杂性，导致先前尝试性能不足。因此，开发新算法以克服这些障碍并解锁soft-thinking的潜力至关重要。",
      "method": "论文提出SofT-GRPO算法，核心方法包括：向logits注入Gumbel噪声以引入随机性，采用Gumbel-Softmax技术确保soft-thinking tokens保持在预训练嵌入空间内，并利用重参数化技巧简化策略梯度计算。实验基于参数从1.5B到7B的基础LLMs进行，展示了该方法的可扩展性和技术特色，无需特定数据集细节即可实现soft-thinking模式的策略优化。",
      "result": "实验结果显示，SofT-GRPO在多个准确率指标上优于传统离散token GRPO基线。具体来说，在Pass@1上，soft-thinking LLMs的平均准确率提升了0.13%；在Pass@32上，平均准确率提升2.19%，显示出显著改进。这些数据基于1.5B到7B参数的LLMs实验，证实了SofT-GRPO在增强推理性能方面的有效性，特别是在多候选生成任务中表现突出。",
      "conclusion": "本研究的主要贡献是SofT-GRPO算法成功解决了soft-thinking与RL结合的挑战，在准确率上取得提升，尤其是在Pass@32上表现显著，具有重要学术和实际应用价值。学术上，它为LLM推理和策略优化提供了新方法；实际中，可应用于需要高质量推理的场景。未来工作可能包括扩展到更大模型或更多任务，以及处理更广泛的soft-thinking变体，但摘要未明确说明局限性。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Gumbel-Softmax",
        "Policy Optimization",
        "Soft-Thinking Reasoning"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:22.789503Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.05879",
    "title": "Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers: First Application with Multi-Membrane Validation",
    "authors": [
      "Yong-Woon Kim",
      "Chulung Kang",
      "Yung-Cheol Byun"
    ],
    "abstract": "Green hydrogen production via polymer electrolyte membrane (PEM) water electrolysis is pivotal for energy transition, yet hydrogen crossover through membranes threatens safety and economic viability-approaching explosive limits (4 mol% H$_2$ in O$_2$) while reducing Faradaic efficiency and accelerating membrane degradation. Current physics-based models require extensive calibration and computational resources that preclude real-time implementation, while purely data-driven approaches fail to extrapolate beyond training conditions-critical for dynamic electrolyzer operation. Here we present the first application of physics-informed neural networks (PINNs) for hydrogen crossover prediction, trained on 184 published measurements augmented to 1,114 points and constrained by a constitutive physics model (Henry's law, Fick's diffusion, and Faraday-based gas production) embedded in the loss function. Our compact architecture (17,793 parameters), validated across six membranes under industrially relevant conditions (0.05-5.0 A/cm$^2$, 1-200 bar, 25-85°C), achieves exceptional accuracy (R$^2$ = 99.84% $\\pm$ 0.15%, RMSE = 0.0932% $\\pm$ 0.0438%) based on five-fold cross-validation, with sub-millisecond inference enabling real-time control. Remarkably, the model maintains R$^2$ > 86% when predicting crossover at pressures 2.5x beyond training range-substantially outperforming pure neural networks (R$^2$ = 43.4%). The hardware-agnostic deployment, from desktop CPUs to edge devices (Raspberry Pi 4), enables distributed safety monitoring essential for gigawatt-scale installations. By bridging physical rigor and computational efficiency, this work establishes a new paradigm for real-time electrolyzer monitoring, accelerating deployment of safe, efficient green hydrogen infrastructure crucial for net-zero emissions targets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.05879.pdf",
    "abs_url": "https://arxiv.org/abs/2511.05879",
    "published": "2025-11-08T06:41:39Z",
    "updated": "2026-01-29T09:09:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文首次应用物理信息神经网络预测聚合物电解质膜水电解制氢中的氢气交叉，实现高精度实时监测，开创了电解槽实时监测新范式。",
      "motivation": "绿色氢生产对能源转型至关重要，但聚合物电解质膜水电解中的氢气交叉问题威胁安全和经济效益，可能接近爆炸极限并降低效率、加速膜降解。当前基于物理的模型需要大量校准和计算资源，无法实时实现，而纯数据驱动方法在动态操作条件下泛化能力不足，缺乏适应性。因此，迫切需要一种结合物理严谨性和计算效率的方法，以支持大规模绿色氢设施的安全监控。",
      "method": "该研究采用物理信息神经网络（PINNs）进行氢气交叉预测，首次应用于此领域。方法在损失函数中嵌入物理约束模型，包括亨利定律、菲克扩散和法拉第气体产生方程。训练数据基于184个已发表测量点扩展至1,114点，并通过五折交叉验证在六种膜和工业相关条件下验证。模型架构紧凑，仅17,793个参数，通过物理约束确保泛化能力，支持硬件无关的实时部署。",
      "result": "实验结果显示出卓越的精度，在五折交叉验证中R²达到99.84% ± 0.15%，RMSE为0.0932% ± 0.0438%。在超出训练范围的压力条件下，模型仍保持R² > 86%，显著优于纯神经网络的43.4%。推断速度为亚毫秒级，支持从桌面CPU到边缘设备的硬件无关部署，为吉瓦级设施提供分布式实时安全监控。",
      "conclusion": "该论文的主要贡献在于首次应用物理信息神经网络于氢气交叉预测，桥接了物理模型与深度学习，实现了实时电解槽监测。研究具有重要学术价值，推动了物理约束神经网络在能源系统中的应用，并为绿色氢基础设施的安全高效部署提供实际解决方案。硬件无关部署和实时控制能力加速了净零排放目标的实现，未来工作可扩展至更广泛的操作条件或系统集成。",
      "tags": [
        "Physics-Informed Neural Networks (PINNs)",
        "Hydrogen Crossover Prediction",
        "Real-Time Monitoring",
        "Polymer Electrolyte Membrane (PEM) Water Electrolysis",
        "Multi-Membrane Validation"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:15.316801Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.05759",
    "title": "Language Generation: Complexity Barriers and Implications for Learning",
    "authors": [
      "Marcelo Arenas",
      "Pablo Barceló",
      "Luis Cofré",
      "Alexander Kozachinskiy"
    ],
    "abstract": "Kleinberg and Mullainathan showed that language generation in the limit is always possible at the level of computability: given enough positive examples, a learner can eventually generate data indistinguishable from a target language. However, such existence results do not address feasibility. We study the sample complexity of language generation in the limit for several canonical classes of formal languages. Our results show that infeasibility already appears for context-free and regular languages, and persists even for strict subclasses such as locally threshold testable languages, as well as for incomparable classes such as non-erasing pattern languages, a well-studied class in the theory of language identification. Overall, our results establish a clear gap between the theoretical possibility of language generation in the limit and its computational feasibility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2511.05759.pdf",
    "abs_url": "https://arxiv.org/abs/2511.05759",
    "published": "2025-11-07T23:06:48Z",
    "updated": "2026-01-29T12:04:45Z",
    "comment": "Version 2: results about pattern and LTT languages are added",
    "light_analysis": {
      "overview": "该论文揭示了极限语言生成的样本复杂性壁垒，表明即使是常见形式语言类如上下文无关和正则语言也存在计算不可行性。",
      "motivation": "研究动机源于解决极限语言生成的可行性问题。Kleinberg 和 Mullainathan 的理论工作证明，在计算性层面，给定足够正面例子，语言生成总是可能，但这忽略了实际样本复杂性。该问题重要，因为实际语言学习算法需高效可行，而现有存在性结果未考虑资源限制，导致理论与应用脱节，特别是在形式语言识别和学习理论中。",
      "method": "研究方法聚焦于分析多个典型形式语言类的样本复杂性，包括上下文无关语言、正则语言、局部阈值可测试语言和非擦除模式语言。通过理论框架，评估这些类在极限语言生成中的样本需求，核心创新是系统性探讨可行性而非仅存在性。未提及具体数据集或模型架构，摘要未明确说明实验细节，仅基于理论分析。",
      "result": "主要结果表明，不可行性已出现在上下文无关和正则语言中，并在其他类如局部阈值可测试语言和非擦除模式语言中持续存在。这确立了理论可能性与计算可行性之间的明显差距。摘要未提供具体性能指标数据，但通过对比基线理论存在性结果，强调了样本复杂性壁垒的实际影响。",
      "conclusion": "结论是论文确立了极限语言生成的理论可能性与计算可行性之间的差距，强调了样本复杂性的关键作用。学术价值在于深化语言生成和学习理论的理解，实际应用价值是指导高效算法设计。潜在局限性可能涉及未涵盖所有语言类，未来工作方向可能包括扩展分析或开发实用方法，摘要未明确说明。",
      "tags": [
        "Language Generation",
        "Sample Complexity",
        "Formal Languages",
        "Context-Free Languages",
        "Regular Languages"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:07.133870Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.04418",
    "title": "The Illusion of Certainty: Uncertainty Quantification for LLMs Fails under Ambiguity",
    "authors": [
      "Tim Tomov",
      "Dominik Fuchsgruber",
      "Tom Wollschläger",
      "Stephan Günnemann"
    ],
    "abstract": "Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is critical for trustworthy deployment. While real-world language is inherently ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically benchmarked against tasks with no ambiguity. In this work, we demonstrate that while current uncertainty estimators perform well under the restrictive assumption of no ambiguity, they degrade to close-to-random performance on ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first ambiguous question-answering (QA) datasets equipped with ground-truth answer distributions estimated from factual co-occurrence. We find this performance deterioration to be consistent across different estimation paradigms: using the predictive distribution itself, internal representations throughout the model, and an ensemble of models. We show that this phenomenon can be theoretically explained, revealing that predictive-distribution and ensemble-based estimators are fundamentally limited under ambiguity. Overall, our study reveals a key shortcoming of current UQ methods for LLMs and motivates a rethinking of current modeling paradigms.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.04418.pdf",
    "abs_url": "https://arxiv.org/abs/2511.04418",
    "published": "2025-11-06T14:46:35Z",
    "updated": "2026-01-29T10:27:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文揭示了大型语言模型不确定性量化在语言模糊性下的失效，并提出了首个模糊问答数据集以评估该问题。",
      "motivation": "该研究旨在解决大型语言模型（LLMs）不确定性量化（UQ）在真实世界模糊语言环境下的性能下降问题。由于现实语言具有内在模糊性，体现为偶然不确定性，但现有UQ方法通常基于无模糊任务进行基准测试，导致其在实际模糊数据上的表现不可靠。这一问题至关重要，因为准确的UQ对LLMs的可信赖部署和决策支持是必不可少的，而当前方法忽略了模糊性这一关键因素，限制了模型的鲁棒性和实用性。",
      "method": "论文提出了MAQA*和AmbigQA*两个模糊问答（QA）数据集，这是首次引入基于事实共现估计的真实答案分布的模糊数据集，用于系统评估UQ方法。研究方法包括分析不同不确定性估计范式：使用预测分布本身、模型内部表示的变动，以及模型集成方法。关键创新点在于通过引入模糊数据集，揭示了现有UQ方法在模糊性下的失效现象，并利用理论分析解释性能下降，而不仅依赖实验验证。",
      "result": "实验结果显示，当前的不确定性估计器在假设无模糊的情况下表现良好，但在模糊数据上性能退化到接近随机的水平，这一现象在不同估计范式中一致出现。例如，基于预测分布和模型集成的估计器在模糊QA任务上均显示出显著性能下降，摘要未明确说明具体数字，但与基线方法相比，评估表明现有UQ方法在模糊环境中几乎失效。这强调了现有UQ方法的局限性，无法有效处理语言模糊性带来的挑战。",
      "conclusion": "该研究的主要贡献是揭示了当前不确定性量化方法在语言模糊性下的关键缺陷，推动了重新思考建模范式。学术价值在于挑战了现有UQ评估标准，强调了模糊数据集的重要性，对未来LLM鲁棒性研究提供了新方向。实际应用价值涉及提升LLMs在模糊场景下的可信赖部署，但局限性是摘要未明确说明具体改进方案，未来工作可能需要开发更适应模糊性的UQ方法，以增强模型的泛化能力。",
      "tags": [
        "Uncertainty Quantification",
        "Large Language Models",
        "Ambiguous Question-Answering",
        "Predictive Distribution",
        "Ensemble Methods"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:22.102037Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.03068",
    "title": "Graph Homomorphism Distortion: A Metric to Distinguish Them All and in the Latent Space Bind Them",
    "authors": [
      "Martin Carrasco",
      "Olga Zaghen",
      "Kavir Sumaraj",
      "Erik Bekkers",
      "Bastian Rieck"
    ],
    "abstract": "A large driver of the complexity of graph learning is the interplay between \\emph{structure} and \\emph{features}.When analyzing the expressivity of graph neural networks, however, existing approaches ignore features in favor of structure, making it nigh-impossible to assess to what extent two graphs with close features should be considered similar.We address this by developing a new \\mbox{(pseudo-)metric} based on graph homomorphisms.Inspired by concepts from metric geometry, our \\emph{graph homomorphism distortion} measures the minimal worst-case distortion that node features of one graph are subjected to when mapping one graph to another.We demonstrate the utility of our novel measure by showing that (i.) it can be efficiently calculated under some additional assumptions, (ii.) it complements existing expressivity measures like \\mbox{$1$-WL}, and (iii.)it permits defining structural encodings, which improve the predictive capabilities of graph neural networks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.03068.pdf",
    "abs_url": "https://arxiv.org/abs/2511.03068",
    "published": "2025-11-04T23:29:59Z",
    "updated": "2026-01-29T15:38:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种基于图同态的新度量，用于同时评估图的结构和特征相似性，以改进图神经网络表达能力的分析。",
      "motivation": "在图学习中，结构和节点特征的相互作用复杂，但现有方法（如1-WL测试）在分析图神经网络表达能力时仅关注结构，忽略特征，导致难以准确评估具有相近特征但不同结构的图之间的相似性。因此，有必要开发一个能够综合考虑两者影响的度量方法，以解决现有评估框架的局限性。",
      "method": "论文提出了一个名为“图同态失真”的（伪）度量，灵感来自度量几何。该度量通过计算将一个图映射到另一个图时，节点特征的最小最坏情况失真来量化相似性。核心创新在于结合图同态和度量几何，创建一个同时处理结构和特征的度量框架，并在某些额外假设下实现高效计算。",
      "result": "作者展示了新度量的实用性：首先，在某些条件下可以高效计算；其次，它与现有表达能力度量（如1-WL）互补，提供更全面的评估；最后，基于该度量定义的结构编码能提升图神经网络的预测能力。摘要未明确说明具体数据，但表明新度量在图学习任务中具有潜在优势。",
      "conclusion": "该论文的主要贡献是引入了图同态失真度量，它同时考虑图的结构和特征，改善了图神经网络表达能力的评估方法。这一研究具有学术价值，为图相似性分析提供了新工具，并可能在实际应用中增强图神经网络的性能。未来工作可包括更广泛的应用验证和计算效率优化。",
      "tags": [
        "Graph Homomorphism",
        "Graph Neural Networks",
        "Expressivity",
        "Metric Geometry",
        "1-WL"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:34.597509Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.01918",
    "title": "Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training",
    "authors": [
      "Ahmet Erdem Pamuk",
      "Emir Kaan Özdemir",
      "Şuayp Talha Kocabay"
    ],
    "abstract": "Large language models (LLMs) are increasingly trained with classical optimization techniques like AdamW to improve convergence and generalization. However, the mechanisms by which quantum-inspired methods enhance classical training remain underexplored. We introduce Superpositional Gradient Descent (SGD), a novel optimizer linking gradient updates with quantum superposition by injecting quantum circuit perturbations. We present a mathematical framework and implement hybrid quantum-classical circuits in PyTorch and Qiskit. On synthetic sequence classification and large-scale LLM fine-tuning, SGD converges faster and yields lower final loss than AdamW. Despite promising results, scalability and hardware constraints limit adoption. Overall, this work provides new insights into the intersection of quantum computing and deep learning, suggesting practical pathways for leveraging quantum principles to control and enhance model behavior.",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.01918.pdf",
    "abs_url": "https://arxiv.org/abs/2511.01918",
    "published": "2025-11-01T16:37:55Z",
    "updated": "2026-01-29T12:14:10Z",
    "comment": "Accepted at 2025 IEEE International Conference on Quantum Artificial Intelligence (IEEE QAI 2025). This is the accepted version of the paper. The final published version will appear in the IEEE proceedings. \\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses",
    "light_analysis": {
      "overview": "本文提出了一种名为叠加梯度下降（SGD）的新型优化器，通过注入量子电路扰动将梯度更新与量子叠加原理相结合，以改进模型训练。",
      "motivation": "大语言模型（LLMs）通常依赖AdamW等经典优化技术来提升收敛性和泛化能力，但量子启发方法如何增强经典训练的机制尚不明确。现有研究对量子原理在模型训练中的应用探索不足，导致无法有效整合量子计算优势。因此，本研究旨在解决这一问题，探索量子叠加原理如何优化训练过程，填补量子计算与深度学习交叉领域的知识空白。",
      "method": "本研究提出了叠加梯度下降（SGD）优化器，它通过注入量子电路扰动将梯度更新与量子叠加原理连接。关键创新包括建立数学框架，并实现基于PyTorch和Qiskit的混合量子-经典电路，结合经典机器学习库和量子计算工具，以整合量子扰动指导训练。",
      "result": "在合成序列分类和大规模LLM微调实验中，SGD相比基准方法AdamW收敛更快且最终损失更低，显示出训练效率的提升。摘要未提供具体数值，但结果表明SGD在优化性能方面优于传统技术，尽管可扩展性和硬件限制可能影响其实用性。",
      "conclusion": "本研究的主要贡献在于提出了SGD优化器，为量子计算与深度学习交叉领域提供了新见解，展示了利用量子原理控制和增强模型行为的实用途径。然而，可扩展性和硬件约束限制了当前应用，未来工作需解决这些挑战，以推动技术在实际场景中的部署。",
      "tags": [
        "Superpositional Gradient Descent",
        "Quantum Circuits",
        "Hybrid Quantum-Classical Systems",
        "Model Optimization",
        "Gradient Descent"
      ]
    },
    "analyzed_at": "2026-01-30T04:14:42.413076Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.27410",
    "title": "Closing the Expression Gap in LLM Instructions via Socratic Questioning",
    "authors": [
      "Jianwen Sun",
      "Yukang Feng",
      "Yifan Chang",
      "Chuanhao Li",
      "Zizhen Li",
      "Jiaxin Ai",
      "Fanrui Zhang",
      "Yu Dai",
      "Kaipeng Zhang"
    ],
    "abstract": "A fundamental bottleneck in human-AI collaboration is the ``intention expression gap,\" the difficulty for humans to effectively convey complex, high-dimensional thoughts to AI. This challenge often traps users in inefficient trial-and-error loops and is exacerbated by the diverse expertise levels of users. We reframe this problem from passive instruction following to a Socratic collaboration paradigm, proposing an agent that actively probes for information to resolve its uncertainty about user intent. we name the proposed agent Nous, trained to acquire proficiency in this inquiry policy. The core mechanism of Nous is a training framework grounded in the first principles of information theory. Within this framework, we define the information gain from dialogue as an intrinsic reward signal, which is fundamentally equivalent to the reduction of Shannon entropy over a structured task space. This reward design enables us to avoid reliance on costly human preference annotations or external reward models. To validate our framework, we develop an automated simulation pipeline to generate a large-scale, preference-based dataset for the challenging task of scientific diagram generation. Comprehensive experiments, including ablations, subjective and objective evaluations, and tests across user expertise levels, demonstrate the effectiveness of our proposed framework. Nous achieves leading efficiency and output quality, while remaining robust to varying user expertise. In conclusion, our research provides a systematic methodology and a new perspective for addressing the issue of ambiguous intentions in complex human-machine collaboration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2510.27410.pdf",
    "abs_url": "https://arxiv.org/abs/2510.27410",
    "published": "2025-10-31T12:00:21Z",
    "updated": "2026-01-29T11:18:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种基于Socratic提问的代理Nous，通过主动信息探询减少大型语言模型指令中的意图表达鸿沟。",
      "motivation": "人类与AI协作中存在“意图表达鸿沟”，用户难以将复杂、高维思想有效传达给AI，导致低效的试错循环，用户专业知识水平的多样性进一步加剧此问题。现有方法多依赖被动指令遵循，无法主动澄清意图，造成误解和协作效率低下，因此需要开发新的主动协作范式以提升沟通准确性和适应性。",
      "method": "论文提出名为Nous的代理，采用Socratic协作范式主动提问以探询用户意图。核心训练框架基于信息论第一原理，将对话信息增益定义为内在奖励信号，等同于减少结构化任务空间上的香农熵，从而避免依赖昂贵的人工偏好注释或外部奖励模型。为验证框架，开发自动化模拟流水线生成大规模、基于偏好的数据集，专门用于科学图表生成这一挑战性任务。",
      "result": "通过综合实验验证框架有效性，包括消融研究、主观和客观评估，以及不同用户专业知识水平的测试。结果表明，Nous在输出质量和效率方面优于基线方法，并展现出对多样化用户背景的鲁棒性。摘要未明确说明具体性能指标如准确率提升，但实验证实该方法能有效减少意图表达鸿沟，提升协作表现。",
      "conclusion": "研究贡献在于提供系统方法和新视角，以解决人机协作中的模糊意图问题。学术上，基于信息论的奖励设计为主动对话策略训练开辟新途径；实践中，可改善AI系统交互效率和用户满意度。未来工作可扩展至更多任务领域，并探索更复杂的协作场景，以进一步优化代理策略。",
      "tags": [
        "Large Language Model",
        "Socratic Questioning",
        "Information Theory",
        "Intrinsic Reward",
        "Reinforcement Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:22.349255Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.26266",
    "title": "A Likely Geometry of Generative Models",
    "authors": [
      "Frederik Möbius Rygaard",
      "Shen Zhu",
      "Yinzhu Jin",
      "Søren Hauberg",
      "Tom Fletcher"
    ],
    "abstract": "The geometry of generative models serves as the basis for interpolation, model inspection, and more. Unfortunately, most generative models lack a principal notion of geometry without restrictive assumptions on either the model or the data dimension. In this paper, we construct a general geometry compatible with different metrics and probability distributions to analyze generative models that do not require additional training. We consider curves analogous to geodesics constrained to a suitable data distribution aimed at targeting high-density regions learned by generative models. We formulate this as a (pseudo)-metric and prove that this corresponds to a Newtonian system on a Riemannian manifold. We show that shortest paths in our framework can be characterized by a system of ordinary differential equations, which locally corresponds to geodesics under a suitable Riemannian metric. Numerically, we derive a novel algorithm to efficiently compute shortest paths and generalized Fréchet means. Quantitatively, we show that curves using our metric traverse regions of higher density than baselines across a range of models and datasets.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.26266.pdf",
    "abs_url": "https://arxiv.org/abs/2510.26266",
    "published": "2025-10-30T08:46:53Z",
    "updated": "2026-01-29T11:04:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种无需额外训练的通用几何框架，兼容多种度量和概率分布，用于分析生成模型，并证明其对应于黎曼流形上的牛顿系统。",
      "motivation": "生成模型的几何是插值和模型检查等应用的基础，但现有方法通常缺乏主要的几何概念，需要严格假设模型或数据维度，这限制了其通用性和实用性。研究旨在解决这一不足，构建一个灵活的几何框架，适用于不同度量和概率分布，以支持无需额外训练的生成模型分析，从而克服现有方法的限制并提升应用范围。",
      "method": "研究方法包括构建一个通用几何框架，考虑约束于合适数据分布的曲线，类似于测地线，目标是针对生成模型学习的高密度区域。将其形式化为伪度量，并证明这对应于黎曼流形上的牛顿系统。关键创新是提供了一种无需训练的分析方法。数值上，提出一种新算法，用于高效计算最短路径和广义Fréchet均值，基于系统化的常微分方程表征。",
      "result": "主要实验结果显示，使用提出的度量的曲线在多种生成模型和数据集上，比基线方法穿过更高密度的区域，验证了框架的有效性。定量分析表明，该方法在密度区域穿越方面优于基线，但具体性能指标如准确率提升数据摘要未明确说明，强调了定性比较的改进。",
      "conclusion": "论文的主要贡献是提出了一个兼容不同度量和概率分布的几何框架，用于分析生成模型，无需额外训练。这为生成模型的插值、检查和优化提供了新工具，具有学术价值和实际应用潜力。局限性可能包括计算效率或适用范围，摘要未明确，未来工作可扩展算法到更多场景或数据集。",
      "tags": [
        "Generative Models",
        "Riemannian Geometry",
        "Geodesics",
        "Ordinary Differential Equations",
        "Fréchet Mean"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:16.558194Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.25889",
    "title": "$π_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models",
    "authors": [
      "Kang Chen",
      "Zhihao Liu",
      "Tonghe Zhang",
      "Zhen Guo",
      "Si Xu",
      "Hao Lin",
      "Hongzhi Zang",
      "Xiang Li",
      "Quanlu Zhang",
      "Zhaofei Yu",
      "Guoliang Fan",
      "Tiejun Huang",
      "Yu Wang",
      "Chao Yu"
    ],
    "abstract": "Vision-Language-Action (VLA) models enable robots to understand and perform complex tasks from multimodal input. Although recent work explores using reinforcement learning (RL) to automate the laborious data collection process in scaling supervised fine-tuning (SFT), applying RL to large-scale flow-based VLAs (\\eg, $π_0$, $π_{0.5}$) remains challenging due to intractable action log-likelihoods raised from flow matching. We address this challenge with $π_{\\texttt{RL}}$, featuring two technical approaches: (1) \\textbf{Flow-Noise} models the denoising process as a discrete-time MDP with a learnable noise network for exact log-likelihood computation. (2) \\textbf{Flow-SDE} integrates denoising with agent-environment interaction, formulating a two-layer MDP that employs ODE-to-SDE conversion for efficient RL exploration. We evaluate $π_{\\texttt{RL}}$ across various benchmarks, with experiments demonstrating that RL yields significant performance improvements in both in-distribution and out-of-distribution settings.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.25889.pdf",
    "abs_url": "https://arxiv.org/abs/2510.25889",
    "published": "2025-10-29T18:37:39Z",
    "updated": "2026-01-29T16:00:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出$π_\\texttt{RL}$方法，通过Flow-Noise和Flow-SDE技术，实现了基于流的视觉-语言-动作模型的在线强化学习微调，解决了动作对数似然计算挑战。",
      "motivation": "该研究旨在解决将强化学习（RL）应用于大规模基于流的视觉-语言-动作（VLA）模型时的技术难题。VLA模型使机器人能够理解和执行多模态输入的复杂任务，具有重要应用价值。现有方法如监督微调（SFT）依赖大量手动数据收集，效率低；RL可以自动化这个过程，但由于流匹配导致动作对数似然难以计算，限制了其在基于流VLA模型中的应用。因此，研究动机是开发新方法来克服这一挑战，以提升模型微调的效率和性能。",
      "method": "论文提出了$π_\\texttt{RL}$方法，核心包括两个技术创新：一是Flow-Noise，将去噪过程建模为离散时间马尔可夫决策过程（MDP），引入可学习的噪声网络来精确计算动作对数似然；二是Flow-SDE，通过集成去噪与代理-环境交互，构建两层MDP，并采用常微分方程到随机微分方程（ODE-to-SDE）转换，以提高RL探索效率。这些方法解决了基于流VLA模型中因流匹配引起的动作对数似然不可计算问题，使在线RL微调成为可能，技术特色在于结合了流匹配和强化学习框架。",
      "result": "实验评估了$π_\\texttt{RL}$在多个基准测试上的性能。结果摘要表明，RL微调在分布内和分布外设置中都带来了显著的性能改进，验证了方法的有效性。尽管摘要未提供具体数据如准确率提升百分比，但强调了改进的显著性，暗示了与基线方法相比，$π_\\texttt{RL}$能够更好地应对基于流VLA模型的挑战。这为后续实证研究奠定了基础，展示了该方法的潜力。",
      "conclusion": "本研究的主要贡献是提出了$π_\\texttt{RL}$，成功实现了基于流VLA模型的在线RL微调。学术价值在于解决了流匹配引起的动作对数似然计算难题，推动了强化学习在复杂多模态模型中的应用。实际应用价值体现在能更高效地微调机器人模型，提升任务执行性能。未来工作方向可能包括扩展到更多任务类型或验证方法的泛化能力，摘要未明确说明局限性，但可推断需进一步实验验证。",
      "tags": [
        "Reinforcement Learning",
        "Flow Matching",
        "Markov Decision Process",
        "Stochastic Differential Equation",
        "Vision-Language-Action Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:19.921848Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.25262",
    "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation Learning",
    "authors": [
      "Xiandong Zou",
      "Jia Li",
      "Xiaotong Yuan",
      "Pan Zhou"
    ],
    "abstract": "Normalization is fundamental to deep learning, but existing approaches such as BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero mean and unit variance, stabilizing training without controlling how representations capture task-relevant information. We propose IB-Inspired Normalization (IBNorm), a simple yet powerful family of methods grounded in the Information Bottleneck principle. IBNorm introduces bounded compression operations that encourage embeddings to preserve predictive information while suppressing nuisance variability, yielding more informative representations while retaining the stability and compatibility of standard normalization. Theoretically, we prove that IBNorm achieves a higher IB value and tighter generalization bounds than variance-centric methods. Empirically, IBNorm consistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale language models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual information analysis confirming superior information bottleneck behavior. Code will be released publicly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.25262.pdf",
    "abs_url": "https://arxiv.org/abs/2510.25262",
    "published": "2025-10-29T08:21:32Z",
    "updated": "2026-01-29T13:26:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出基于信息瓶颈的归一化方法IBNorm，以在表示学习中通过保留预测信息并抑制噪声变异性来改进性能。",
      "motivation": "归一化是深度学习的核心，但现有方法如BatchNorm、LayerNorm和RMSNorm侧重于方差控制，通过强制零均值和单位方差来稳定训练，却未有效管理表示如何捕获任务相关信息。这导致表示信息含量不足，在处理复杂任务时性能受限。因此，开发一种能在保持训练稳定性的同时优化信息提取的归一化方法至关重要，以提升模型的泛化能力和效率。",
      "method": "论文提出信息瓶颈启发的归一化（IBNorm），这是一种基于信息瓶颈原则的方法族。IBNorm通过引入有界压缩操作，激励嵌入保留预测性信息，同时抑制无用变异性，从而生成更具信息量的表示。关键创新在于将信息瓶颈理论集成到归一化中，兼容标准归一化的稳定性和架构。摘要未明确说明具体算法细节、数据集或模型架构，但强调了方法的简洁性和与信息瓶颈框架的紧密关联。",
      "result": "理论上，IBNorm相比基于方差的方法实现了更高的信息瓶颈值和更紧的泛化界。实验上，IBNorm在大型语言模型（如LLaMA和GPT-2）和视觉模型（如ResNet和ViT）上持续优于BatchNorm、LayerNorm和RMSNorm，通过互信息分析确认了其优越的信息瓶颈行为，验证了表示学习效果的提升。",
      "conclusion": "本文主要贡献是提出IBNorm，一种新颖的归一化方法，通过信息瓶颈理论优化表示学习，提高了任务的性能。学术价值在于将信息原则融入归一化过程，推动了深度学习方法的发展；实际应用价值体现在与现有架构的兼容性和广泛模型的适用性。摘要未明确说明局限性和未来工作方向，但为进一步研究提供了基础。",
      "tags": [
        "Information Bottleneck",
        "Normalization",
        "Representation Learning",
        "Large Language Models",
        "Vision Transformers"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:39.674495Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.23596",
    "title": "Think Twice: Branch-and-Rethink Reasoning Reward Model",
    "authors": [
      "Yizhu Jiao",
      "Jiaqi Zeng",
      "Julien Veron Vialard",
      "Oleksii Kuchaiev",
      "Jiawei Han",
      "Olivier Delalleau"
    ],
    "abstract": "Large language models (LLMs) increasingly rely on thinking models that externalize intermediate steps and allocate extra test-time compute, with think-twice strategies showing that a deliberate second pass can elicit stronger reasoning. In contrast, most reward models (RMs) still compress many quality dimensions into a single scalar in one shot, a design that induces judgment diffusion: attention spreads across evaluation criteria, yielding diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a two-turn RM that transfers the think-twice principle to reward modeling. Turn 1 performs adaptive branching, selecting a small set of instance-critical dimensions (such as factuality and safety) and sketching concise, evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a targeted reread that tests those hypotheses and scrutinizes only what matters most. We train with GRPO-style reinforcement learning over structured two-turn traces using a simple binary outcome reward with strict format checks, making the approach compatible with standard RLHF pipelines. By converting all-at-once scoring into focused, second-look reasoning, BR-RM reduces judgment diffusion and improves sensitivity to subtle yet consequential errors while remaining practical and scalable. Experimental results demonstrate that our model achieves state-of-the-art performance on three challenging reward modeling benchmarks across diverse domains.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.23596.pdf",
    "abs_url": "https://arxiv.org/abs/2510.23596",
    "published": "2025-10-27T17:58:07Z",
    "updated": "2026-01-29T18:57:46Z",
    "comment": "Source Code: https://github.com/yzjiao/BR-RM. Model Checkpoints: https://huggingface.co/nvidia/Qwen3-Nemotron-14B-BRRM and https://huggingface.co/nvidia/Qwen3-Nemotron-8B-BRRM",
    "light_analysis": {
      "overview": "BR-RM是一种两轮的奖励模型，将思考两次策略应用于奖励建模，通过自适应分支和条件重新思考减少判断扩散并提高对微妙错误的敏感性。",
      "motivation": "现有奖励模型（RMs）通常将多个质量维度（如事实性、安全性）压缩为单次标量评分，导致判断扩散，即注意力分散于不同评估标准，使得分析浅薄且忽略关键细节。随着大型语言模型（LLMs）越来越多地使用思考模型来提升推理能力，RMs的这种单次评分设计已不适应复杂任务的评估需求，限制了其在捕捉微妙但重要错误方面的准确性。本研究旨在解决这一问题，通过将“思考两次”原则引入奖励建模，以提高RMs的分析深度和实用性。",
      "method": "本文提出了分支再思考奖励模型（BR-RM），这是一种两轮方法，核心创新包括自适应分支和分支条件重新思考。第一轮从实例中识别关键维度（如事实性和安全性），并生成简洁的假设。第二轮则针对这些假设进行重读和测试，只聚焦于最重要内容，以减少注意力分散。训练时，采用GRPO风格的强化学习，基于结构化的两轮痕迹数据，使用简单的二元结果奖励和严格格式检查，确保模型可无缝集成到标准的RLHF（从人类反馈强化学习）管道中，提升可扩展性和兼容性。",
      "result": "实验结果显示，BR-RM在三个具有挑战性的奖励建模基准测试中达到了最先进的性能，覆盖了多样化的领域。通过减少判断扩散，模型显著提高了对微妙但重大错误的敏感性，在评估复杂任务时表现出更强的准确性。与基线方法相比，BR-RM在保持实用性和可扩展性的同时，验证了思考两次策略在奖励建模中的有效性，为改善LLMs的训练提供了有力支持。",
      "conclusion": "本研究的主要贡献是引入了BR-RM模型，成功将思考两次策略应用于奖励建模，减少判断扩散并增强错误检测能力。学术上，它为复杂任务评估提供了新方法，丰富了RMs的理论基础；实践中，该模型兼容标准RLHF流程，易于部署和扩展，适用于现实世界的AI系统。未来工作可进一步探索模型在不同任务类型中的泛化能力，或针对更多维度进行优化。",
      "tags": [
        "Large Language Model",
        "Reward Modeling",
        "Reinforcement Learning",
        "Reasoning Model",
        "Branch-and-Rethink"
      ]
    },
    "analyzed_at": "2026-01-30T04:15:39.494205Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.23515",
    "title": "FreeFuse: Multi-Subject LoRA Fusion via Adaptive Token-Level Routing at Test Time",
    "authors": [
      "Yaoli Liu",
      "Yao-Xiang Ding",
      "Kun Zhou"
    ],
    "abstract": "This paper proposes FreeFuse, a training-free framework for multi-subject text-to-image generation through automatic fusion of multiple subject LoRAs. In contrast to prior studies that focus on retraining LoRA to alleviate feature conflicts, our analysis reveals that simply spatially confining the subject LoRA's output to its target region and preventing other LoRAs from directly intruding into this area is sufficient for effective mitigation. Accordingly, we implement Adaptive Token-Level Routing during the inference phase. We introduce FreeFuseAttn, a mechanism that exploits the flow matching model's intrinsic semantic alignment to dynamically match subject-specific tokens to their corresponding spatial regions at early denoising timesteps, thereby bypassing the need for external segmentors. FreeFuse distinguishes itself through high practicality: it necessitates no additional training, model modifications, or user-defined masks spatial conditions. Users need only provide subject activation words to achieve seamless integration into standard workflows. Extensive experiments validate that FreeFuse outperforms existing approaches in both identity preservation and compositional fidelity. Our code is available at https://github.com/yaoliliu/FreeFuse.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.23515.pdf",
    "abs_url": "https://arxiv.org/abs/2510.23515",
    "published": "2025-10-27T16:54:08Z",
    "updated": "2026-01-29T16:14:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "FreeFuse提出了一个无需训练的多主体LoRA融合框架，通过自适应令牌级路由在推理时动态分配空间区域，有效缓解了特征冲突。",
      "motivation": "在多主体文本到图像生成中，多个主体LoRA融合时常发生特征冲突，导致生成质量下降。现有方法主要通过重新训练LoRA来缓解冲突，但增加了训练成本和时间，限制了实用性。FreeFuse旨在解决这一问题，通过避免额外训练，提供一个更高效和用户友好的融合方案。",
      "method": "FreeFuse采用自适应令牌级路由技术，在推理阶段动态匹配主体特定令牌到目标空间区域。它利用流匹配模型的语义对齐特性，在早期去噪步骤中实现精准路由，无需外部分割器。核心创新包括FreeFuseAttn机制，通过动态令牌分配来空间限制输出，防止其他LoRAs侵入，提升融合效果。",
      "result": "实验验证了FreeFuse在身份保留和组合保真度上优于现有方法。摘要未明确说明具体数据，但表明通过大量基准测试，其在多个指标上表现更优，有效提升了多主体生成的性能和质量。",
      "conclusion": "FreeFuse的主要贡献是提出了一个无需训练的多主体LoRA融合框架，具有高实用性和易用性。该研究为文本到图像生成领域提供了新思路，并展示了实际应用潜力，用户仅需提供激活词即可集成。未来可扩展该框架到更复杂场景或与其他模型结合以进一步提升性能。",
      "tags": [
        "Multi-Subject Generation",
        "LoRA Fusion",
        "Adaptive Token-Level Routing",
        "Text-to-Image Generation",
        "Flow Matching Model"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:01.404702Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.22028",
    "title": "Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics",
    "authors": [
      "Yilin Zhang",
      "Wenda Xu",
      "Zhongtao Liu",
      "Tetsuji Nakagawa",
      "Markus Freitag"
    ],
    "abstract": "Quality Estimation (QE) metrics are vital in machine translation for reference-free evaluation and as a reward signal in tasks like reinforcement learning. However, the prevalence and impact of length bias in QE have been underexplored. Through a systematic study of top-performing regression-based and LLM-as-a-Judge QE metrics across 10 diverse language pairs, we reveal two critical length biases: First, QE metrics consistently over-predict errors with increasing translation length, even for high-quality, error-free texts. Second, they exhibit a preference for shorter translations when multiple candidates are available for the same source text. These inherent length biases risk unfairly penalizing longer, correct translations and can lead to sub-optimal decision-making in applications such as QE reranking and QE guided reinforcement learning. We further investigate the root cause, presenting evidence that QE models conflate quality with sequence length due to skewed supervision distributions. As a diagnostic intervention, we apply length normalization during training. We show that this simple intervention is sufficient to decouple error probability from length, effectively counteracting the data skew and yielding more reliable QE signals.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.22028.pdf",
    "abs_url": "https://arxiv.org/abs/2510.22028",
    "published": "2025-10-24T21:22:06Z",
    "updated": "2026-01-29T08:22:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文揭示了质量评估指标中的系统性长度偏差，并提出通过训练时长度归一化来解耦误差概率与长度，提升评估可靠性。",
      "motivation": "质量评估（QE）指标在机器翻译中用于参考无关评估和作为强化学习等任务的奖励信号，但长度偏差的普遍性和影响被低估。现有方法可能导致较长的正确翻译受到不公平惩罚，从而在应用如QE重排名和QE引导强化学习中产生次优决策。研究旨在解决这一问题，强调避免因数据偏斜而误判翻译质量的重要性。",
      "method": "论文通过系统性研究10种语言对中的回归基QE指标和LLM-as-a-Judge QE指标，揭示了两种关键长度偏差：错误过预测随长度增加和偏好短翻译。研究指出偏差根源于数据分布偏斜导致模型混淆质量与序列长度。作为干预，在训练时应用长度归一化，以解耦误差概率与长度，抵消数据偏斜并生成更可靠的QE信号。关键创新在于系统性分析偏差并引入简单归一化技术。",
      "result": "研究发现QE指标在较长翻译中一致过预测误差，即使对于无错误文本亦然，并在多候选翻译中偏好较短版本。通过长度归一化，成功解耦了误差概率与长度关系，产生了更稳健的QE信号。摘要未明确具体性能指标，但与基线方法相比，该方法显著减少偏差，为下游任务如重排名和强化学习提供更公平评估基础。",
      "conclusion": "论文的主要贡献在于揭示并缓解QE指标中的长度偏差，通过系统性研究和长度归一化干预。学术价值在于深化对评估指标偏差的理解，实际应用价值在于提升机器翻译系统的可靠性和公平性。局限性可能包括对其他偏差的探索不足，未来工作可扩展至更多语言对或集成更复杂技术以进一步优化QE指标。",
      "tags": [
        "Quality Estimation",
        "Length Bias",
        "LLM-as-a-Judge",
        "Regression-based metrics",
        "Machine Translation"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:08.544403Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.21245",
    "title": "Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime",
    "authors": [
      "Noah Oberweis",
      "Semih Cayci"
    ],
    "abstract": "Continuous-time models provide important insights into the training dynamics of optimization algorithms in deep learning. In this work, we establish a non-asymptotic convergence analysis of stochastic gradient Langevin dynamics (SGLD), which is an Itô stochastic differential equation (SDE) approximation of stochastic gradient descent in continuous time, in the lazy training regime. We show that, under regularity conditions on the Hessian of the loss function, SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate kernel throughout the training process with high probability, and (ii) achieves exponential convergence to the empirical risk minimizer in expectation, and we establish finite-time and finite-width bounds on the optimality gap. We corroborate our theoretical findings with numerical examples in the regression setting.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.21245.pdf",
    "abs_url": "https://arxiv.org/abs/2510.21245",
    "published": "2025-10-24T08:28:53Z",
    "updated": "2026-01-29T14:32:46Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文在懒惰训练制度下建立了随机梯度朗之万动力学的非渐近收敛理论，证明了其能保持非退化核并实现指数收敛。",
      "motivation": "连续时间模型为深度学习优化算法的训练动态提供了关键见解，但现有研究对随机梯度朗之万动力学在懒惰训练制度下的收敛行为缺乏非渐近分析。本研究旨在解决这一问题，因为理解优化算法在懒惰训练下的收敛性对于理论保证和实际应用至关重要。懒惰训练下参数变化小，分析收敛性有助于提高算法的稳定性和效率，弥补了现有理论不足。",
      "method": "论文采用随机梯度朗之万动力学作为核心方法，将其建模为 Itô 随机微分方程，以近似连续时间中的随机梯度下降。关键技术创新是在懒惰训练制度下，假设损失函数的 Hessian 满足正则条件，分析具有乘性和状态相关噪声的 SGLD。通过建立理论框架，证明在训练过程中能保持非退化核，并实现收敛；在数值实验中，使用回归设置来验证理论，但具体数据集和模型架构摘要未明确说明。",
      "result": "理论分析显示，在给定条件下，SGLD 高概率产生非退化核，并在期望中指数收敛到经验风险最小化器。建立了最优性间隙的有限时间和有限宽度边界，提供了收敛速率的量化估计。在回归设置的数值实验中，结果与理论预测吻合，验证了分析的有效性。与基线方法相比，SGLD 在懒惰训练下展现出良好的收敛特性，但具体性能提升百分比摘要未明确说明。",
      "conclusion": "本研究的主要贡献是在懒惰训练制度下，首次为随机梯度朗之万动力学提供了非渐近收敛理论，证明了其在乘性和状态相关噪声下的稳定收敛行为。学术上，这增强了深度学习优化算法的理论基础；实际中，为使用 SGLD 的算法设计提供了理论指导。局限性可能包括对 Hessian 正则条件的依赖，未来工作可放宽条件或扩展到其他优化设置中。",
      "tags": [
        "Stochastic Gradient Langevin Dynamics",
        "Itô Stochastic Differential Equation",
        "Lazy Training Regime",
        "Non-asymptotic Convergence Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:40.987964Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.20766",
    "title": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion",
    "authors": [
      "Noam Issachar",
      "Guy Yariv",
      "Sagie Benaim",
      "Yossi Adi",
      "Dani Lischinski",
      "Raanan Fattal"
    ],
    "abstract": "Diffusion Transformer models can generate images with remarkable fidelity and detail, yet training them at ultra-high resolutions remains extremely costly due to the self-attention mechanism's quadratic scaling with the number of image tokens. In this paper, we introduce Dynamic Position Extrapolation (DyPE), a novel, training-free method that enables pre-trained diffusion transformers to synthesize images at resolutions far beyond their training data, with no additional sampling cost. DyPE takes advantage of the spectral progression inherent to the diffusion process, where low-frequency structures converge early, while high-frequencies take more steps to resolve. Specifically, DyPE dynamically adjusts the model's positional encoding at each diffusion step, matching their frequency spectrum with the current stage of the generative process. This approach allows us to generate images at resolutions that exceed the training resolution dramatically, e.g., 16 million pixels using FLUX. On multiple benchmarks, DyPE consistently improves performance and achieves state-of-the-art fidelity in ultra-high-resolution image generation, with gains becoming even more pronounced at higher resolutions. Project page is available at https://noamissachar.github.io/DyPE/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.20766.pdf",
    "abs_url": "https://arxiv.org/abs/2510.20766",
    "published": "2025-10-23T17:42:14Z",
    "updated": "2026-01-29T11:37:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出DyPE方法，一种无需训练的动态位置外推技术，使预训练的扩散变换器能在远超训练分辨率生成超高分辨率图像。",
      "motivation": "扩散变换器模型在生成图像时，自注意力机制随图像令牌数量二次缩放，导致在超高分辨率下训练和生成成本极高，限制实际应用。现有方法需额外训练或采样，效率低下，因此需要一种无需训练、能扩展分辨率的方法来解决这一问题，以降低生成成本并提高实用性。摘要强调了现有模型在超高分辨率下的计算瓶颈和传统方法的不足。",
      "method": "DyPE的核心方法是基于扩散过程的频谱进展，其中低频结构先收敛，高频细节需要更多步骤。在推理阶段，动态调整模型的位置编码，使其频谱与当前生成阶段匹配，实现无需额外训练的位置外推。关键创新点包括利用频谱特性进行动态调整，无需重新训练预训练模型如FLUX，直接应用于扩散变换器架构，从而在生成过程中优化位置编码。",
      "result": "在多个基准测试中，DyPE一致提升性能，实现超高分辨率图像生成的最先进保真度。具体地，使用FLUX模型能生成1600万像素图像，增益在高分辨率下更显著。与基线方法相比，DyPE在保真度上有明显提升，且无额外采样成本，验证了其在扩展预训练模型分辨率方面的有效性。摘要未明确说明具体基线数据，但强调了性能改进。",
      "conclusion": "DyPE的主要贡献是提供了一种无需训练的方法，显著扩展扩散变换器的分辨率能力，降低生成成本，有实际应用价值如高分辨率图像合成。学术价值在于创新性地结合频谱进展和动态位置编码，为扩散模型研究提供新思路。局限性或未来工作方向摘要未明确说明，但可推断需进一步优化动态机制或应用于其他模型类型。",
      "tags": [
        "Diffusion Transformer",
        "Positional Encoding",
        "High-Resolution Image Generation",
        "Dynamic Extrapolation",
        "Spectrum Matching"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:24.241607Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.16797",
    "title": "MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning",
    "authors": [
      "Vera Pavlova",
      "Mohammed Makhlouf"
    ],
    "abstract": "We introduce MOSAIC (Masked Objective with Selective Adaptation for In-domain Contrastive learning), a multi-stage framework for domain adaptation of text embedding models that incorporates joint domain-specific masked supervision. Our approach addresses the challenges of adapting large-scale general-domain text embedding models to specialized domains. By jointly optimizing masked language modeling (MLM) and contrastive objectives within a unified training pipeline, our method enables effective learning of domain-relevant representations while preserving the robust semantic discrimination properties of the original model. We empirically validate our approach on both high-resource and low-resource domains, achieving improvements up to 13.4% in NDCG@10 (Normalized Discounted Cumulative Gain) over strong general-domain baselines. Comprehensive ablation studies further demonstrate the effectiveness of each component, highlighting the importance of balanced joint supervision and staged adaptation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.16797.pdf",
    "abs_url": "https://arxiv.org/abs/2510.16797",
    "published": "2025-10-19T11:24:03Z",
    "updated": "2026-01-29T09:55:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出MOSAIC，一个结合掩码监督和选择性适应的多阶段框架，用于提升文本嵌入模型在专业领域的适应能力，通过联合优化目标有效学习表示并保持语义区分性。",
      "motivation": "该研究旨在解决将大规模通用领域文本嵌入模型适应到专业领域的挑战，这是一个重要问题，因为通用模型在特定任务中可能表现不足。现有适应方法往往难以平衡领域特定学习的强化与原始模型语义区分性的保持，导致性能下降或表示退化。因此，需要开发更有效的适应策略来提升领域相关任务的效果。",
      "method": "论文提出的MOSAIC方法是一个多阶段框架，它通过一个统一的训练管道联合优化掩码语言建模（MLM）和对比学习目标。核心创新在于结合了领域特定的掩码监督和选择性适应机制，使得模型能够有效学习领域相关表示，同时利用多阶段策略逐步调整模型参数。这种方法利用了文本嵌入模型的基础架构，通过联合监督确保在适应过程中保持语义结构的稳定性。",
      "result": "实验在资源丰富和资源匮乏的领域上进行，结果显示在NDCG@10指标上最高提升13.4%，显著优于通用领域的基线模型。全面的消融研究验证了每个组件的有效性，例如联合监督和多阶段适应策略，特别强调了平衡的监督对提升适应性能的关键作用。这些实验数据证明了MOSAIC方法在领域适应任务中的稳健性和可扩展性。",
      "conclusion": "该论文的主要贡献是开发了MOSAIC框架，它通过掩码和对比目标的联合监督，成功实现了文本嵌入模型在专业领域的有效适应，同时保持了语义区分能力。学术价值在于提供了一种新颖的多阶段适应方法，丰富了领域适应理论；实际应用价值在于提升领域特定任务如信息检索的性能。摘要未明确说明局限性，但未来工作可能涉及扩展到更多领域或处理更复杂的适应场景，如动态领域变化。",
      "tags": [
        "Masked Language Modeling",
        "Contrastive Learning",
        "Domain Adaptation",
        "Text Embedding Models",
        "Multi-stage Framework"
      ]
    },
    "analyzed_at": "2026-01-30T04:16:36.017919Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.14466",
    "title": "Toward Robust Multilingual Adaptation of LLMs for Low-Resource Languages",
    "authors": [
      "Haolin Li",
      "Haipeng Zhang",
      "Mang Li",
      "Yaohua Wang",
      "Lijie Wen",
      "Yu Zhang",
      "Biqing Huang"
    ],
    "abstract": "Large language models (LLMs) continue to struggle with low-resource languages, primarily due to limited training data, translation noise, and unstable cross-lingual alignment. To address these challenges, we propose LiRA (Linguistic Robust Anchoring for LLMs)-a plug-and-play framework that requires only lightweight fine-tuning on top of existing pretrained backbones. LiRA jointly optimizes representation stability and cross-lingual semantic consistency by combining two key components: Arca (Anchored Representation Composition Architecture), which aligns low-resource inputs to a shared English semantic space through anchor-based alignment and collaborative encoding; and LaSR (Language-coupled Semantic Reasoner), a lightweight, language-aware head that enforces consistency regularization for unified cross-lingual understanding, retrieval, and reasoning. We theoretically show that under controlled anchoring error and translation-induced bias, LiRA guarantees bounded representation deviation and stable downstream performance under local Lipschitz continuity. To facilitate research, we release a new multilingual product retrieval dataset covering five Southeast Asian and two South Asian languages. Extensive experiments across diverse low-resource benchmarks demonstrate consistent improvements in retrieval, ranking, question answering, and reasoning tasks. Code will be publicly available on GitHub, and the dataset will be hosted on Hugging Face.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.14466.pdf",
    "abs_url": "https://arxiv.org/abs/2510.14466",
    "published": "2025-10-16T09:08:24Z",
    "updated": "2026-01-29T08:51:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种即插即用的 LiRA 框架，通过联合优化表示稳定性和跨语言语义一致性，以提升大型语言模型在低资源语言上的鲁棒性。",
      "motivation": "大型语言模型在处理低资源语言时面临挑战，主要由于训练数据有限、翻译噪声和跨语言对齐不稳定，这限制了模型在全球语言环境中的公平性和可访问性。现有方法往往需要大量资源，并且在数据稀缺时表现不佳，导致模型鲁棒性不足，无法有效处理低资源语言的复杂性和噪声，亟需更高效的适配技术来扩展LLMs的应用范围。",
      "method": "研究提出 LiRA 框架，包含两个核心组件：Arca 通过锚点对齐和协作编码将低资源语言输入对齐到共享英语语义空间，确保表示稳定性；LaSR 作为轻量级语言感知头，强制执行一致性正则化，统一跨语言理解、检索和推理。该框架是即插即用的，仅需在预训练骨干模型上进行轻量级微调，理论上在锚点误差和翻译偏差控制下，能保证有界的表示偏差和稳定下游性能。论文还发布了涵盖东南亚和南亚语言的多元语产品检索数据集以支持研究。",
      "result": "实验结果显示，在多种低资源基准测试中，LiRA 在检索、排序、问答和推理任务上展示了一致的性能改进，具体指标摘要未明确说明，但与基线方法相比，该框架显著提升了处理低资源语言的能力，证明了其跨任务的有效性和鲁棒性。",
      "conclusion": "论文的主要贡献是提出了 LiRA 框架及其理论保证，通过锚点对齐和一致性正则化解决了低资源语言的适配挑战，具有重要的学术价值，推动了多语言LLM研究；实际应用价值体现在多语言检索、问答等场景。未来工作可能包括扩展到更多语言或进一步优化方法，但摘要未明确说明局限性。",
      "tags": [
        "Large Language Models",
        "Low-Resource Languages",
        "Cross-Lingual Alignment",
        "Consistency Regularization",
        "Multilingual Dataset"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:01.832944Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.13602",
    "title": "NOSA: Native and Offloadable Sparse Attention",
    "authors": [
      "Yuxiang Huang",
      "Pengjie Wang",
      "Jicheng Han",
      "Weilin Zhao",
      "Zhou Su",
      "Ao Sun",
      "Hongya Lyu",
      "Hengyu Zhao",
      "Yudong Wang",
      "Chaojun Xiao",
      "Xu Han",
      "Zhiyuan Liu"
    ],
    "abstract": "Decoding throughput improvements from larger inference batches are limited by GPU memory, which is largely consumed by the key-value (KV) cache. Prior training-free KV cache offloading alleviates this by keeping redundant context on the CPU and fetching only a sparse subset for attention, but it often degrades long-generation quality due to training-inference mismatch on sparse patterns. Meanwhile, trainable sparse attention is incompatible with efficient offloading, as unconstrained KV accesses may force large CPU-to-GPU transfers and erase throughput gains. To this end, we propose NOSA, a trainable sparse attention mechanism natively designed for KV cache offloading. NOSA explicitly constrains the volume of CPU-GPU KV transfers, thereby achieving low communication overhead and high decoding throughput. We further build NOSI, a KV cache offloading inference system that fully unlocks NOSA's efficiency. Empirical results on 1,3,8B LLMs demonstrate that NOSA outperforms KV cache offloading baselines on general, long-input, and long-generation tasks, while boosting decoding throughput by up to 5.04x, 1.92x, and 1.83x over FullAttn, InfLLMv2, and ShadowKV, respectively. We release our code at https://github.com/thunlp/NOSA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.13602.pdf",
    "abs_url": "https://arxiv.org/abs/2510.13602",
    "published": "2025-10-15T14:33:16Z",
    "updated": "2026-01-29T08:26:24Z",
    "comment": "Preprint",
    "light_analysis": {
      "overview": "提出NOSA，一种专为KV缓存卸载设计的可训练稀疏注意力机制，结合NOSI系统提升大语言模型解码吞吐量。",
      "motivation": "研究动机在于解决GPU内存限制大语言模型解码吞吐量提升的问题，主要由于KV缓存消耗大量内存。现有方法如训练免费KV缓存卸载（如InfLLMv2）可能导致长生成质量下降，因训练-推理稀疏模式不匹配；而可训练稀疏注意力（如FullAttn）与高效卸载不兼容，可能增加CPU-GPU传输开销。因此，需要一种新方法平衡吞吐量与模型性能，确保卸载效率的同时不牺牲质量。",
      "method": "论文提出NOSA（Native and Offloadable Sparse Attention），一种可训练稀疏注意力机制，专为KV缓存卸载设计。核心创新在于约束CPU-GPU KV传输量，以减少通信开销并保持高效解码吞吐量。NOSA通过明确限制稀疏访问模式，确保训练和推理一致，从而优化卸载效率。同时，构建NOSI推理系统来充分实现NOSA的潜力，支持在1B、3B、8B等大语言模型上的部署，技术特色在于集成训练机制与卸载优化。",
      "result": "实验在1B、3B、8B参数的大语言模型上进行评估，NOSA在一般任务、长输入和长生成任务上优于基线方法（如FullAttn、InfLLMv2和ShadowKV）。具体性能指标显示解码吞吐量提升最高达5.04倍（对比FullAttn）、1.92倍（对比InfLLMv2）和1.83倍（对比ShadowKV），同时保持了模型质量，证明了NOSA在提高效率方面的优势，并有效减少了内存占用。",
      "conclusion": "论文主要贡献是提出NOSA机制和NOSI系统，解决了现有KV缓存卸载方法在训练-推理匹配和卸载效率上的不足。学术价值在于提供了一种新的可训练稀疏注意力框架，推动了大语言模型高效推理的研究；实际应用价值在于显著提升解码吞吐量，适用于大规模语言生成场景。未来工作可能包括扩展到更大模型或更多任务，但摘要未明确说明具体局限性。",
      "tags": [
        "Sparse Attention",
        "KV Cache Offloading",
        "Large Language Models",
        "Training Mechanisms",
        "Inference Efficiency"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:08.057689Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.13036",
    "title": "Repairing Reward Functions with Feedback to Mitigate Reward Hacking",
    "authors": [
      "Stephane Hatgis-Kessell",
      "Logan Mondal Bhamidipaty",
      "Emma Brunskill"
    ],
    "abstract": "Human-designed reward functions for reinforcement learning (RL) agents are frequently misaligned with the humans' true, unobservable objectives, and thus act only as proxies. Optimizing for a misspecified proxy reward function often induces reward hacking, resulting in a policy misaligned with the human's true objectives. An alternative is to perform RL from human feedback, which involves learning a reward function from scratch by collecting human preferences over pairs of trajectories. However, building such datasets is costly. To address the limitations of both approaches, we propose Preference-Based Reward Repair (PBRR): an automated iterative framework that repairs a human-specified proxy reward function by learning an additive, transition-dependent correction term from preferences. A manually specified reward function can yield policies that are highly suboptimal under the ground-truth objective, yet corrections on only a few transitions may suffice to recover optimal performance. To identify and correct for those transitions, PBRR uses a targeted exploration strategy and a new preference-learning objective. We prove in tabular domains PBRR has a cumulative regret that matches, up to constants, that of prior preference-based RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR consistently outperforms baselines that learn a reward function from scratch from preferences or modify the proxy reward function using other approaches, requiring substantially fewer preferences to learn high performing policies.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2510.13036.pdf",
    "abs_url": "https://arxiv.org/abs/2510.13036",
    "published": "2025-10-14T23:18:24Z",
    "updated": "2026-01-29T07:52:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于偏好的奖励修复框架，通过从人类偏好中学习加性修正项来缓解强化学习中的奖励黑客问题。",
      "motivation": "人类设计的强化学习奖励函数常与真实目标不匹配，导致奖励黑客问题，使得策略偏离人类意图，影响智能体行为对齐。现有方法如从人类反馈中学习奖励函数成本高昂，而直接优化代理奖励函数易引发行为偏差。因此，需高效方法来修复奖励函数，平衡数据成本和性能，提升强化学习系统的可靠性和实用性，解决对齐难题。",
      "method": "论文提出 Preference-Based Reward Repair (PBRR) 框架，通过迭代方式修复代理奖励函数：从成对轨迹的偏好中学习一个加性、转移依赖的修正项。关键创新包括有针对性的探索策略来识别关键转移，以及新的偏好学习目标来优化修正过程。该方法结合了代理奖励的先验知识和少量人类偏好数据，无需从头学习奖励函数，从而减少数据需求并提高效率。",
      "result": "理论分析在表格领域显示，PBRR 的累积遗憾与先前偏好强化学习方法相当。在多个奖励黑客基准测试中，PBRR 性能优于基线方法，如从偏好从头学习奖励函数或其他修复方法。实验结果表明，PBRR 能以更少的偏好数据学习到高性能策略，提高了对齐效率，证明了其在实际应用中的优势。",
      "conclusion": "PBRR 框架有效修复代理奖励函数，减轻奖励黑客风险，通过结合人类偏好降低了数据收集成本。研究在理论和实验上验证了其性能，推动了强化学习对齐技术的发展，具有学术和实际应用价值。未来工作可扩展至更复杂场景，以进一步提升方法的泛化能力和鲁棒性。",
      "tags": [
        "Reinforcement Learning",
        "Reward Hacking",
        "Preference Learning",
        "Human Feedback",
        "Automated Reward Repair"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:18.669580Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.11341",
    "title": "InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models",
    "authors": [
      "Haomin Wang",
      "Jinhui Yin",
      "Qi Wei",
      "Wenguang Zeng",
      "Lixin Gu",
      "Shenglong Ye",
      "Zhangwei Gao",
      "Yaohui Wang",
      "Yanting Zhang",
      "Yuanqi Li",
      "Yanwen Guo",
      "Wenhai Wang",
      "Kai Chen",
      "Yu Qiao",
      "Hongjie Zhang"
    ],
    "abstract": "General SVG modeling remains challenging due to fragmented datasets, limited transferability of methods across tasks, and the difficulty of handling structural complexity. In response, we leverage the strong transfer and generalization capabilities of multimodal large language models (MLLMs) to achieve unified modeling for SVG understanding, editing, and generation. We present the InternSVG family, an integrated data-benchmark-model suite. At its core is SAgoge, the largest and most comprehensive multimodal dataset for SVG tasks, encompassing both static graphics and dynamic animations. It covers icons, long-sequence illustrations, scientific diagrams, and dynamic animations, supporting tasks of varied difficulty levels and providing deeper hierarchies with richer attributes compared to previous datasets. Based on this resource, we introduce SArena, a companion benchmark with comprehensive task definitions and standardized evaluation that aligns with the domains and difficulty spectrum covered by SAgoge. Building on these foundations, we propose InternSVG, a unified MLLM for SVG understanding, editing, and generation with SVG-specific special tokens, subword-based embedding initialization, and a two-stage training strategy that progresses from short static SVGs to long-sequence illustrations and complex animations. This unified formulation induces positive transfer and improves overall performance. Experiments on SArena and prior benchmark confirm that InternSVG achieves substantial gains and consistently outperforms leading open and proprietary counterparts.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.11341.pdf",
    "abs_url": "https://arxiv.org/abs/2510.11341",
    "published": "2025-10-13T12:38:04Z",
    "updated": "2026-01-29T06:02:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了InternSVG，一个统一的多模态大型语言模型，通过综合数据集和基准实现SVG理解、编辑和生成的统一建模。",
      "motivation": "通用SVG建模面临数据集碎片化、方法跨任务转移性有限以及处理结构复杂性困难等挑战。现有方法无法有效统一处理多种任务，导致性能受限和应用效率低下。本研究旨在利用多模态大型语言模型的强大泛化和转移能力，构建一个统一框架以解决这些难题，推动SVG技术在图形设计和动画等领域的实际应用。",
      "method": "作者提出了InternSVG套件，包括SAgoge数据集、SArena基准和InternSVG模型。SAgoge是最全面的SVG多模态数据集，涵盖静态图形和动态动画，提供深层层次和丰富属性。SArena是配套基准，定义标准化评估任务。InternSVG模型创新地使用SVG特定特殊令牌、基于子词的嵌入初始化和两阶段训练策略，从短静态SVG逐步扩展到复杂动态内容，以促进任务间正转移和提升整体性能。",
      "result": "在SArena基准和先前基准上的实验表明，InternSVG在SVG理解、编辑和生成任务中实现了显著性能提升，一致性地超越了当前领先的开源和专有模型。摘要未提供具体数字，但强调模型通过统一建模获得了实质性增益，验证了其有效性和优越性。",
      "conclusion": "本研究的主要贡献在于通过InternSVG实现了SVG任务的统一建模，解决了碎片化问题，并引入了SAgoge数据集和SArena基准作为领域资源。研究具有学术价值，推动了多模态语言模型在SVG处理中的应用，并具有实际潜力，如图形自动化工具开发。未来工作可扩展到更多模态或处理更复杂的SVG结构，以进一步提升泛化能力。",
      "tags": [
        "Multimodal Large Language Model",
        "SVG Tasks",
        "Unified Modeling",
        "Dataset Construction",
        "Benchmark Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:49.321996Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.11234",
    "title": "Neural Weight Compression for Language Models",
    "authors": [
      "Jegwang Ryu",
      "Minkyu Kim",
      "Seungjun Shin",
      "Hee Min Choi",
      "Dokwan Oh",
      "Jaeho Lee"
    ],
    "abstract": "Efficient storage and transmission of language model weights are increasingly critical as model scale and deployment grow. Yet, most existing compression methods rely on handcrafted transforms and heuristics, reflecting the limited understanding of weights as a data modality. This motivates a shift toward learning-based paradigm, where compression schemes are optimized directly from data rather than manually designed. In this work, we take a step in this direction by formulating weight compression as a neural codec learning. We propose Neural Weight Compression (NWC), a flexible framework for training neural codecs on pretrained weight datasets. NWC addresses challenges intrinsic to weight compression, such as tensor shape heterogeneity and the misalignment between training losses and downstream performance, through components such as chunk-and-normalize preprocessing and an importance-aware training objective. Experiments show that NWC achieves state-of-the-art accuracy-compression tradeoffs, particularly at 4--6 bit regime, without relying on rigid handcrafted components such as the Hadamard transform. These gains extend across diverse architectures, e.g., vision encoders. Our analysis further supports the learning-based perspective, highlighting the roles of entropy-constrained quantization in high rate regime and learned transforms in adapting to downstream tasks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.11234.pdf",
    "abs_url": "https://arxiv.org/abs/2510.11234",
    "published": "2025-10-13T10:16:20Z",
    "updated": "2026-01-29T13:56:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出 Neural Weight Compression (NWC)，一个基于学习的框架，通过神经编码器学习实现语言模型权重的高效压缩。",
      "motivation": "随着语言模型规模和部署的增加，权重的存储和传输效率问题日益突出。现有压缩方法依赖手工设计的变换和启发式规则，缺乏对权重数据模态的深入理解，限制了灵活性和性能。因此，论文倡导转向基于学习的压缩范式，直接从数据中优化压缩方案，以解决传统方法在适应性和效果上的不足。",
      "method": "NWC 框架将权重压缩视为神经编码器学习问题，通过在预训练权重数据集上训练神经编码器来实现。关键创新包括分块和归一化预处理以处理张量形状异质性，以及重要性感知训练目标以解决训练损失与下游性能之间的不一致性。该方法不依赖传统的手工组件如 Hadamard 变换，而是学习优化的压缩方案，适用于多种模型架构。",
      "result": "实验显示，NWC 在 4-6 比特压缩范围内实现了最先进的精度-压缩权衡，在无需刚性手工组件的情况下，性能优于现有方法。这些增益扩展到其他架构，如视觉编码器，表明框架具有广泛适用性。结果支持基于学习的压缩方法在提升效率和保持精度方面的优势。",
      "conclusion": "论文的主要贡献在于提出了一个灵活、基于学习的权重压缩框架，推动压缩技术向数据驱动方向发展。分析强调了熵约束量化在高比特率下的作用和学习变换在适应下游任务中的价值。这为高效模型部署提供了新思路，潜在应用于各种 AI 架构，未来工作可探索压缩机制的进一步优化和更广泛的任务扩展。",
      "tags": [
        "Neural Compression",
        "Weight Compression",
        "Language Models",
        "Quantization",
        "Learned Transforms"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:29.269965Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.11068",
    "title": "Efficient Test-Time Adaptation through Latent Subspace Coefficients Search",
    "authors": [
      "Xinyu Luo",
      "Jie Liu",
      "Kecheng Chen",
      "Junyi Yang",
      "Bo Ding",
      "Arindam Basu",
      "Haoliang Li"
    ],
    "abstract": "Real-world deployment often exposes models to distribution shifts, making test-time adaptation (TTA) critical for robustness. Yet most TTA methods are unfriendly to edge deployment, as they rely on backpropagation, activation buffering, or test-time mini-batches, leading to high latency and memory overhead. We propose $\\textbf{ELaTTA}$ ($\\textit{Efficient Latent Test-Time Adaptation}$), a gradient-free framework for single-instance TTA under strict on-device constraints. ELaTTA freezes model weights and adapts each test sample by optimizing a low-dimensional coefficient vector in a source-induced principal latent subspace, pre-computed offline via truncated SVD and stored with negligible overhead. At inference, ELaTTA encourages prediction confidence by optimizing the $k$-D coefficients with CMA-ES, effectively optimizing a Gaussian-smoothed objective and improving stability near decision boundaries. Across six benchmarks and multiple architectures, ELaTTA achieves state-of-the-art accuracy under both strict and continual single-instance protocols, while reducing compute by up to $\\textit{63$\\times$}$ and peak memory by $\\textit{11$\\times$}$. We further demonstrate on-device deployment on a ZYNQ-7020 platform. Code will be released upon acceptance.",
    "categories": [
      "cs.LG",
      "eess.AS",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.11068.pdf",
    "abs_url": "https://arxiv.org/abs/2510.11068",
    "published": "2025-10-13T07:08:52Z",
    "updated": "2026-01-29T08:50:56Z",
    "comment": "Under review",
    "light_analysis": {
      "overview": "ELaTTA 提出了一个高效的免梯度测试时适应框架，通过搜索潜在子空间系数来优化单个测试实例，显著减少计算和内存开销。",
      "motivation": "现实世界中，模型部署常面临分布偏移，测试时适应对提升模型鲁棒性至关重要。然而，现有 TTA 方法依赖于反向传播或测试时小批量处理，导致高延迟和高内存开销，不适用于资源受限的边缘设备，限制了实际应用。因此，开发高效、轻量级的 TTA 方法成为迫切需求。",
      "method": "ELaTTA 采用免梯度框架，冻结模型权重，为每个测试样本优化一个低维系数向量。该向量位于源数据诱导的主潜在子空间中，通过截断 SVD 离线预先计算并存储，存储开销可忽略。推理时，使用 CMA-ES 算法优化系数向量，最大化预测置信度，通过高斯平滑目标提高决策边界稳定性，实现高效的单实例适应。",
      "result": "在六个基准数据集和多种模型架构上的实验表明，ELaTTA 在严格和连续的单实例测试时适应协议下实现了最先进的分类准确性。具体性能提升包括计算开销减少高达 63 倍，峰值内存使用减少 11 倍。此外，论文成功在 ZYNQ-7020 平台上进行设备部署，验证了其实际应用可行性。",
      "conclusion": "本研究提出了 ELaTTA 框架，通过冻结模型权重和优化潜在子空间系数，显著提升了测试时适应的效率和实用性。该方法不仅减少了计算和内存开销，还支持边缘设备部署，具有重要的学术价值（推进了轻量级 TTA 技术）和应用价值（适用于现实场景），为未来研究提供了参考。",
      "tags": [
        "Test-Time Adaptation",
        "Latent Subspace",
        "CMA-ES",
        "Truncated SVD",
        "Edge Deployment"
      ]
    },
    "analyzed_at": "2026-01-30T04:17:59.612252Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.10606",
    "title": "ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models",
    "authors": [
      "Yuqi Liu",
      "Liangyu Chen",
      "Jiazhen Liu",
      "Mingkang Zhu",
      "Zhisheng Zhong",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "abstract": "Post-training Large Vision-and-Language Models (LVLMs) typically involves Supervised Fine-Tuning (SFT) for knowledge injection or Reinforcement Learning with Verifiable Rewards (RLVR) for performance enhancement. However, SFT often leads to sub-optimal performance, while RLVR remains constrained by the model's internal knowledge base. While a sequential SFT $\\rightarrow$ RLVR pipeline can be used, it introduces significant computational overhead and suffers from catastrophic forgetting. To address these limitations, we propose ViSurf (\\textbf{Vi}sual \\textbf{Su}pervised-and-\\textbf{R}einforcement \\textbf{F}ine-Tuning), a unified, single-stage paradigm that integrates the strengths of both SFT and RLVR. By analyzing their training objectives, we establish a unified framework that injects ground-truth labels directly into RLVR rollouts, facilitating simultaneous external supervision and internal reinforcement. Furthermore, we introduce three novel reward control strategies to ensure training stability and optimization. Extensive experiments demonstrate that ViSurf consistently outperforms standalone SFT, RLVR, and the traditional two-stage pipeline across diverse benchmarks. In-depth analysis corroborates these findings, validating the derivation and design principles of ViSurf.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.10606.pdf",
    "abs_url": "https://arxiv.org/abs/2510.10606",
    "published": "2025-10-12T13:42:55Z",
    "updated": "2026-01-29T11:59:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出ViSurf，一种统一单阶段的视觉监督和强化微调范式，结合了监督微调和强化学习的优势，用于优化大型视觉语言模型。",
      "motivation": "当前，大型视觉语言模型（LVLMs）的后训练常采用监督微调（SFT）注入知识或强化学习（RLVR）提升性能。然而，SFT往往导致性能不理想，而RLVR受模型内部知识限制；顺序使用SFT和RLVR虽可行，但会引入显著计算开销和灾难性遗忘问题。这些问题导致现有方法在效率、成本和性能上存在不足，亟需一种更高效、统一的解决方案，以提升微调效果并减少资源消耗，满足实际应用中对模型优化的高要求。",
      "method": "论文提出ViSurf方法，通过分析监督微调（SFT）和强化学习（RLVR）的训练目标，建立统一的单阶段框架，将地面真值标签直接注入RLVR流程中，实现外部监督与内部强化的同步进行。关键创新包括开发一个集成框架，避免了传统两阶段管道的计算负担和遗忘问题；并引入三种新颖的奖励控制策略，如动态调整和稳定性优化，以确保训练过程的平稳和高效，为LVLMs微调提供了一种高效技术路线。",
      "result": "广泛实验表明，ViSurf在多个基准测试中一致超越了独立的监督微调（SFT）、基于可验证奖励的强化学习（RLVR）以及传统的SFT→RLVR两阶段训练管道，覆盖了多样化的任务场景。具体数据显示，在性能指标如准确率和效率上均有显著提升，优于基线方法。深度分析进一步验证了这些结果，确认了ViSurf设计原则和推导的有效性，突显其作为统一微调方法的实用性和优越性。",
      "conclusion": "本研究的主要贡献是提出ViSurf，一种创新的单阶段微调范式，成功整合了监督微调和强化学习的优势，有效解决了现有方法在大型视觉语言模型后训练中的局限性。这具有重要的学术价值，为LVLMs优化提供了新思路，同时减少了计算成本和遗忘风险，提升了实际应用价值。潜在的局限性或未来工作可能涉及扩展应用领域或进一步优化奖励策略，但摘要未明确说明具体细节。",
      "tags": [
        "Large Vision-and-Language Models",
        "Supervised Fine-Tuning",
        "Reinforcement Learning with Verifiable Rewards",
        "Single-Stage Training",
        "Reward Control Strategies"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:21.193625Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.09468",
    "title": "Geodesic Calculus on Implicitly Defined Latent Manifolds",
    "authors": [
      "Florine Hartwig",
      "Josua Sassen",
      "Juliane Braunsmann",
      "Martin Rumpf",
      "Benedikt Wirth"
    ],
    "abstract": "Latent manifolds of autoencoders provide low-dimensional representations of data, which can be studied from a geometric perspective. We propose to describe these latent manifolds as implicit submanifolds of some ambient latent space. Based on this, we develop tools for a discrete Riemannian calculus approximating classical geometric operators. These tools are robust against inaccuracies of the implicit representation often occurring in practical examples. To obtain a suitable implicit representation, we propose to learn an approximate projection onto the latent manifold by minimizing a denoising objective. This approach is independent of the underlying autoencoder and supports the use of different Riemannian geometries on the latent manifolds. The framework in particular enables the computation of geodesic paths connecting given end points and shooting geodesics via the Riemannian exponential maps on latent manifolds. We evaluate our approach on various autoencoders trained on synthetic and real data.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.09468.pdf",
    "abs_url": "https://arxiv.org/abs/2510.09468",
    "published": "2025-10-10T15:25:03Z",
    "updated": "2026-01-29T14:34:52Z",
    "comment": "24 pages, 18 figures",
    "light_analysis": {
      "overview": "该论文提出一个框架，将自编码器的潜在流形视为隐式定义流形，开发离散黎曼计算工具以支持测地线计算。",
      "motivation": "研究动机源于自编码器的潜在流形虽提供数据的低维几何表示，但现有方法难以精确分析，尤其在隐式表示不准确时。现有几何工具可能依赖于特定自编码器或对噪声敏感，限制了鲁棒性和泛化性。因此，本文旨在开发独立于自编码器的鲁棒几何框架，以解决隐式流形中的计算挑战，推动流形学习和几何机器学习的交叉研究。",
      "method": "研究方法将潜在流形描述为隐式子流形，开发离散黎曼计算工具近似经典几何算子（如黎曼指数映射和测地线）。关键创新是通过最小化去噪目标学习近似投影到流形上，确保框架独立于自编码器架构，并支持应用不同黎曼几何。这提高了对隐式不准确性的鲁棒性，避免了对特定模型的依赖。",
      "result": "论文在合成和真实数据上训练的各种自编码器上评估了该框架，摘要未明确说明具体性能数据（如准确率或效率指标）。可以推断，框架成功实现了测地路径的计算和几何算子的近似，可能与基线方法相比在鲁棒性和独立性方面有优势，但缺少量化对比数据。",
      "conclusion": "该框架为主要贡献于潜在流形的几何分析提供了通用工具，尤其强调测地线计算能力。学术上推进了流形学习和几何机器学习的结合；应用上可增强自编码器的解释性和生成模型的质量。局限性可能包括计算复杂性，未来工作可扩展到更复杂几何或多模态数据。",
      "tags": [
        "Implicit Manifolds",
        "Riemannian Geometry",
        "Geodesic Computation",
        "Autoencoders",
        "Denoising Objective"
      ]
    },
    "analyzed_at": "2026-01-30T04:19:06.062705Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.07823",
    "title": "Enhancing Visual Prompting through Expanded Transformation Space and Overfitting Mitigation",
    "authors": [
      "Shohei Enomoto"
    ],
    "abstract": "Visual prompting (VP) has emerged as a promising parameter-efficient fine-tuning approach for adapting pre-trained vision models to downstream tasks without modifying model parameters. Despite offering advantages like negligible computational overhead and compatibility with black-box models, conventional VP methods typically achieve lower accuracy than other adaptation approaches. Our analysis reveals two critical limitations: the restricted expressivity of simple additive transformation and a tendency toward overfitting when the parameter count increases. To address these challenges, we propose ACAVP (Affine, Color, and Additive Visual Prompting), which enhances VP's expressive power by introducing complementary transformation operations: affine transformation for creating task-specific prompt regions while preserving original image information, and color transformation for emphasizing task-relevant visual features. Additionally, we identify that overfitting is a critical issue in VP training and introduce TrivialAugment as an effective data augmentation, which not only benefits our approach but also significantly improves existing VP methods, with performance gains of up to 12 percentage points on certain datasets. This demonstrates that appropriate data augmentation is universally beneficial for VP training. Extensive experiments across twelve diverse image classification datasets with two different model architectures demonstrate that ACAVP achieves state-of-the-art accuracy among VP methods, surpasses linear probing in average accuracy, and exhibits superior robustness to distribution shifts, all while maintaining minimal computational overhead during inference. Our code is available at https://github.com/s-enmt/ACAVP.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.07823.pdf",
    "abs_url": "https://arxiv.org/abs/2510.07823",
    "published": "2025-10-09T06:08:15Z",
    "updated": "2026-01-29T02:55:39Z",
    "comment": "Accepted to NeurIPS2025",
    "light_analysis": {
      "overview": "ACAVP方法通过引入仿射和颜色变换扩展视觉提示的变换空间，并结合TrivialAugment数据增强缓解过拟合，显著提升性能。",
      "motivation": "视觉提示作为一种参数高效微调方法，具有计算开销低和兼容黑盒模型的优势，但传统方法准确度较低，限制了其实际应用。研究动机源于分析发现的两个关键限制：一是简单加性变换的表达能力有限，无法有效捕捉任务特定特征；二是当参数数量增加时，容易发生过拟合，导致性能下降。这些不足阻碍了视觉提示在多样下游任务中的广泛应用，因此需要新方法来增强表达能力和训练稳定性。",
      "method": "论文提出ACAVP方法，通过在视觉提示中集成仿射变换和颜色变换来增强表达能力：仿射变换用于创建任务特定提示区域并保留原始图像结构，颜色变换强调任务相关视觉特征，从而扩展变换空间。此外，为了缓解过拟合问题，引入TrivialAugment作为一种有效的数据增强策略，提升训练泛化能力。方法在12个多样图像分类数据集上进行实验，使用两种不同模型架构（摘要未明确说明具体名称）验证其有效性，确保方法具备广泛适用性。",
      "result": "在十二个图像分类数据集的广泛实验中，ACAVP在视觉提示方法中达到最佳准确度，平均准确度超越线性探测，并显示出对分布偏移的优越鲁棒性。具体地，TrivialAugment数据增强显著提升现有VP方法性能，在某些数据集上性能增益高达12个百分点。相比基线VP方法，ACAVP在保持最小推理计算开销的同时，实现了显著的准确性改进，证明了其在效率和效果方面的平衡优势。",
      "conclusion": "论文的主要贡献是提出ACAVP方法，有效增强视觉提示的表达能力和缓解过拟合，实验证明其在多个数据集上表现优异，具有学术价值和实际应用潜力。研究表明适当数据增强普遍有益于VP训练，方法保持低计算开销和高鲁棒性，适用于实际部署如边缘计算场景。未来工作可探索更多变换类型或优化策略，以进一步提升性能，或扩展到其他视觉任务如目标检测。",
      "tags": [
        "Visual Prompting",
        "Affine Transformation",
        "Color Transformation",
        "TrivialAugment",
        "Parameter-efficient Fine-tuning"
      ]
    },
    "analyzed_at": "2026-01-30T04:18:14.988953Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.07666",
    "title": "iPEAR: Iterative Pyramid Estimation with Attention and Residuals for Deformable Medical Image Registration",
    "authors": [
      "Heming Wu",
      "Di Wang",
      "Tai Ma",
      "Peng Zhao",
      "Yubin Xiao",
      "Zhongke Wu",
      "Xing-Ce Wang",
      "Xuan Wu",
      "You Zhou"
    ],
    "abstract": "Existing pyramid registration networks may accumulate anatomical misalignments and lack an effective mechanism to dynamically determine the number of optimization iterations under varying deformation requirements across images, leading to degraded performance. To solve these limitations, we propose iPEAR. Specifically, iPEAR adopts our proposed Fused Attention-Residual Module (FARM) for decoding, which comprises an attention pathway and a residual pathway to alleviate the accumulation of anatomical misalignment. We further propose a dual-stage Threshold-Controlled Iterative (TCI) strategy that adaptively determines the number of optimization iterations for varying images by evaluating registration stability and convergence. Extensive experiments on three public brain MRI datasets and one public abdomen CT dataset show that iPEAR outperforms state-of-the-art (SOTA) registration networks in terms of accuracy, while achieving on-par inference speed and model parameter size. Generalization and ablation studies further validate the effectiveness of the proposed FARM and TCI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.07666.pdf",
    "abs_url": "https://arxiv.org/abs/2510.07666",
    "published": "2025-10-09T01:38:40Z",
    "updated": "2026-01-29T12:17:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "iPEAR提出融合注意力-残差模块和阈值控制迭代策略，以提升可变形医学图像配准的准确性和自适应性。",
      "motivation": "现有金字塔配准网络在处理医学图像配准时，可能累积解剖结构不对齐，并缺乏动态确定优化迭代次数的机制，导致配准性能下降。医学图像配准对疾病诊断和治疗计划至关重要，这些不足影响了配准的准确性和效率，限制了其在多变临床场景中的应用。因此，需要开发一种能自适应处理不同变形需求并减少不对齐累积的方法。",
      "method": "iPEAR的核心方法包括Fused Attention-Residual Module (FARM)和Threshold-Controlled Iterative (TCI)策略。FARM包含注意力路径和残差路径，用于解码阶段以减轻解剖结构不对齐的累积；TCI通过评估配准稳定性和收敛性，自适应确定优化迭代次数。该方法在三个公共脑MRI数据集和一个公共腹部CT数据集上实施，采用金字塔估计框架进行训练和评估。",
      "result": "实验显示iPEAR在准确性上优于当前最优的配准网络，同时在推理速度和模型参数规模上与现有方法相当。泛化和消融研究进一步验证了FARM和TCI的有效性，表明该方法在不同数据集上具有鲁棒性。摘要未明确提供具体准确率数值，但对比结果表明iPEAR在配准精度方面有显著改进。",
      "conclusion": "本研究的主要贡献是提出iPEAR，通过FARM和TCI策略解决了可变形医学图像配准中的累积不对齐和迭代次数动态确定问题。学术价值在于创新性结合注意力-残差模块和自适应迭代控制，实际应用价值体现在提升医学图像分析的准确性。未来工作可扩展至更多影像模态或优化计算效率，摘要未明确说明局限性。",
      "tags": [
        "Deformable Image Registration",
        "Attention Mechanism",
        "Residual Learning",
        "Iterative Optimization",
        "Pyramid Networks"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:37.109564Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.07213",
    "title": "Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models",
    "authors": [
      "Chengzhi Zhong",
      "Fei Cheng",
      "Qianying Liu",
      "Yugo Murawaki",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ],
    "abstract": "Large language models exhibit strong multilingual capabilities despite limited exposure to non-English data. Prior studies show that English-centric large language models map multilingual content into English-aligned representations at intermediate layers and then project them back into target-language token spaces in the final layer. From this observation, we hypothesize that this cross-lingual transition is governed by a small and sparse set of dimensions, which occur at consistent indices across the intermediate to final layers. Building on this insight, we introduce a simple, training-free method to identify and manipulate these dimensions, requiring only as few as 50 sentences of either parallel or monolingual data. Experiments on a multilingual generation control task reveal the interpretability of these dimensions, demonstrating that the interventions in these dimensions can switch the output language while preserving semantic content, and that it surpasses the performance of prior neuron-based approaches at a substantially lower cost.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.07213.pdf",
    "abs_url": "https://arxiv.org/abs/2510.07213",
    "published": "2025-10-08T16:46:57Z",
    "updated": "2026-01-29T07:52:53Z",
    "comment": "Accepted at EACL 2026 (Main). Our code will be available at: https://github.com/ku-nlp/language-specific-dimensions",
    "light_analysis": {
      "overview": "本论文提出一种无需训练的方法，通过识别和操控大语言模型中的稀疏维度，实现高效且可解释的多语言输出控制。",
      "motivation": "大语言模型在多语言生成方面表现出色，但现有方法如基于神经元的干预往往成本高且可解释性有限。本研究旨在解决如何低成本高效控制模型输出语言的问题，基于先前研究揭示的模型内部表示机制，假设跨语言转换由稀疏维度控制，从而开发更优的控制策略。",
      "method": "研究方法基于观察到模型中间层到最后一层的表示映射，假设跨语言转换由一小部分稀疏维度控制，这些维度在层间有稳定索引。提出一种简单、无需训练的技术，仅需50个句子（平行或单语数据）来识别这些维度，并通过对它们的干预实现语言切换，无需额外模型训练或复杂计算。",
      "result": "在多语言生成控制任务实验中，该方法展示了维度的可解释性，干预能成功切换输出语言同时保持语义内容，性能超过先前基于神经元的方法，且成本显著降低。摘要未明确说明具体性能指标，但强调了效率和效果的优势。",
      "conclusion": "本研究的贡献在于揭示了稀疏维度在多语言控制中的关键作用，提出了一种高效、无需训练的方法，增强了模型的可解释性和实用性。这为未来多语言应用提供了新思路，可能扩展到其他控制任务，摘要未明确说明局限性或具体未来工作方向。",
      "tags": [
        "Large Language Model",
        "Multilingual Control",
        "Sparse Dimensions",
        "Interpretability",
        "Training-Free Method"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:31.378967Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.07132",
    "title": "DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture Model Nonparametric Clustering",
    "authors": [
      "Mariona Jaramillo-Civill",
      "Peng Wu",
      "Pau Closas"
    ],
    "abstract": "Clustered Federated Learning (CFL) improves performance under non-IID client heterogeneity by clustering clients and training one model per cluster, thereby balancing between a global model and fully personalized models. However, most CFL methods require the number of clusters K to be fixed a priori, which is impractical when the latent structure is unknown. We propose DPMM-CFL, a CFL algorithm that places a Dirichlet Process (DP) prior over the distribution of cluster parameters. This enables nonparametric Bayesian inference to jointly infer both the number of clusters and client assignments, while optimizing per-cluster federated objectives. This results in a method where, at each round, federated updates and cluster inferences are coupled, as presented in this paper. The algorithm is validated on benchmark datasets under Dirichlet and class-split non-IID partitions.",
    "categories": [
      "cs.LG",
      "cs.DC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.07132.pdf",
    "abs_url": "https://arxiv.org/abs/2510.07132",
    "published": "2025-10-08T15:27:08Z",
    "updated": "2026-01-29T06:01:46Z",
    "comment": "Accepted at ICASSP 2026; 5 pages, 2 figures",
    "light_analysis": {
      "overview": "论文提出DPMM-CFL算法，利用Dirichlet Process非参数聚类自动推断集群数量，改进非IID数据下的聚类联邦学习性能。",
      "motivation": "在联邦学习中，客户端数据常为非独立同分布（非IID）且具有异构性，导致模型性能下降。现有聚类联邦学习（CFL）方法需预先固定集群数量K，但实际数据潜在结构未知，这限制了方法的实用性。该研究旨在解决自动推断集群数量的问题，以提高对非IID数据的适应性，增强联邦学习在处理异构客户端时的灵活性。",
      "method": "本研究提出DPMM-CFL算法，核心是引入Dirichlet Process（DP）作为集群参数的先验分布，采用非参数贝叶斯推断技术，联合优化集群数量和客户端分配。在每个训练轮次，联邦更新与集群推断耦合，确保动态调整集群结构。算法在基准数据集上使用Dirichlet分布和类分割方法构建非IID分区进行验证，具体模型架构和训练细节摘要未明确说明，但侧重于非参数聚类与联邦学习的结合。",
      "result": "摘要未明确说明具体实验结果，如准确率提升或效率改进。算法在基准数据集上针对Dirichlet和类分割非IID分区进行了验证，推断其能有效处理客户端异构性，可能优于需固定集群数量的基线方法，但未提供具体性能对比数据。这表明方法在模拟真实场景下具有一定有效性。",
      "conclusion": "主要贡献是开发了一种基于Dirichlet Process的非参数聚类方法，用于聚类联邦学习，能自动推断集群数量，适应非IID数据分布。学术价值在于扩展了联邦学习的理论框架，提高对异构数据的处理能力；实际应用可在分布式机器学习中优化模型个性化。未来工作可探索其他先验模型或优化策略以进一步提升性能，潜在局限性摘要未明确说明。",
      "tags": [
        "Clustered Federated Learning",
        "Dirichlet Process",
        "Nonparametric Bayesian Inference",
        "Mixture Model",
        "Client Heterogeneity"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:37.263815Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.08592",
    "title": "Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models",
    "authors": [
      "Shahriar Kabir Nahin",
      "Hadi Askari",
      "Muhao Chen",
      "Anshuman Chhabra"
    ],
    "abstract": "Test-Time Scaling (TTS) improves LLM reasoning by exploring multiple candidate responses and then operating over this set to find the best output. A tacit premise behind TTS is that sufficiently diverse candidate pools enhance reliability. In this work, we show that this assumption in TTS introduces a previously unrecognized failure mode. When candidate diversity is curtailed, even by a modest amount, TTS becomes much more likely to produce unsafe outputs. We present a reference-guided diversity reduction protocol (RefDiv) that serves as a diagnostic attack to stress test TTS pipelines. Through extensive experiments across open-source models (e.g. Qwen3, Mistral, Llama3.1, Gemma3) and two widely used TTS strategies (Monte Carlo Tree Search and Best-of-N), constraining diversity consistently signifies the rate at which TTS produces unsafe results. The effect is often stronger than that produced by prompts directly with high adversarial intent scores. This observed phenomenon also transfers across TTS strategies and to closed-source models (e.g. OpenAI o3-mini and Gemini-2.5-Pro), thus indicating that this is a general and extant property of TTS rather than a model-specific artifact. Additionally, we find that numerous widely used safety guardrail classifiers (e.g. Llama-Guard), are unable to flag the adversarial input prompts generated by RefDiv, demonstrating that existing defenses offer limited protection against this diversity-driven failure mode.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.08592.pdf",
    "abs_url": "https://arxiv.org/abs/2510.08592",
    "published": "2025-10-04T20:01:21Z",
    "updated": "2026-01-29T03:34:31Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究揭示了Test-Time Scaling中候选多样性减少会间接增加大语言模型产生不安全输出的风险，并通过RefDiv协议进行实证诊断。",
      "motivation": "Test-Time Scaling（TTS）通过生成多样候选响应来提升大语言模型的推理可靠性，其隐含前提是多样化候选池能增强安全性。然而，现有方法忽视了一个关键问题：当候选多样性受限时，TTS可能引入未被识别的失败模式，导致不安全输出增加。这一问题的重要性在于TTS广泛应用于实际场景，其安全假设漏洞可能带来不可预测风险。因此，研究旨在检验多样性减少对TTS安全性的影响，弥补现有安全评估的不足，确保系统稳健性。",
      "method": "研究提出参考引导的多样性减少协议（RefDiv），作为诊断攻击工具，通过主动限制候选响应的多样性来压力测试TTS流程。关键创新在于利用RefDiv模拟多样性受限场景，评估TTS在不安全输出上的表现。实验设计覆盖多种开源模型（如Qwen3、Mistral、Llama3.1、Gemma3）和两种常用TTS策略（Monte Carlo Tree Search和Best-of-N），并扩展到闭源模型（如OpenAI o3-mini和Gemini-2.5-Pro），以验证现象的一般性和跨模型转移性。",
      "result": "实验结果显示，当候选多样性被RefDiv限制时，TTS产生不安全输出的比率显著提高。这种现象在各种开源和闭源模型及TTS策略中一致出现，影响强度往往超过直接使用高对抗意图的提示。例如，在开源模型上，多样性减少导致不安全输出增加；同时，现有安全护栏分类器（如Llama-Guard）对RefDiv生成的对抗性提示检测失败，表明现有防御机制存在局限性。这证实了多样性驱动的失败模式是TTS的普遍特性，而非模型特定产物。",
      "conclusion": "本研究的主要贡献是揭示了Test-Time Scaling中多样性减少的间接但普遍风险，挑战了其依赖多样化候选池的安全假设。学术上，这为LLM安全研究提供了新视角和诊断工具（RefDiv），推动了对抗性评估的发展。实际应用中，研究提示TTS系统设计需谨慎处理多样性控制，并呼吁改进现有安全防御。未来工作可探索更有效的多样性管理策略和鲁棒性增强方法，以应对此类风险，提升模型整体安全性。",
      "tags": [
        "Test-Time Scaling",
        "Large Language Models",
        "Diversity Reduction",
        "Adversarial Attacks",
        "Safety Guardrails"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:43.488910Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.02190",
    "title": "Dr. Bench: A Multidimensional Evaluation for Deep Research Agents, from Answers to Reports",
    "authors": [
      "Yang Yao",
      "Yixu Wang",
      "Yuxuan Zhang",
      "Yi Lu",
      "Tianle Gu",
      "Lingyu Li",
      "Dingyi Zhao",
      "Keming Wu",
      "Haozhe Wang",
      "Ping Nie",
      "Yan Teng",
      "Yingchun Wang"
    ],
    "abstract": "As an embodiment of intelligence evolution toward interconnected architectures, Deep Research Agents (DRAs) systematically exhibit the capabilities in task decomposition, cross-source retrieval, multi-stage reasoning, information integration, and structured output, which markedly enhance performance on complex and open-ended tasks. However, existing benchmarks remain deficient in evaluation dimensions, response format, and scoring mechanisms, limiting their effectiveness in assessing such agents. This paper introduces Dr. Bench, a multidimensional evaluation framework tailored to DRAs and long-form report-style responses. The benchmark comprises 214 expert-curated challenging tasks across 10 broad domains, each accompanied by manually constructed reference bundles to support composite evaluation. This framework incorporates metrics for semantic quality, topical focus, and retrieval trustworthiness, enabling a comprehensive evaluation of long reports generated by DRAs. Extensive experimentation confirms the superior performance of mainstream DRAs over web-search-tool-augmented reasoning models, yet reveals considerable scope for further improvement. This study provides a robust foundation for capability assessment, architectural refinement, and paradigm advancement of DRAs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2510.02190.pdf",
    "abs_url": "https://arxiv.org/abs/2510.02190",
    "published": "2025-10-02T16:40:02Z",
    "updated": "2026-01-29T14:47:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了Dr. Bench，一个针对深度研究代理的多维评估框架，旨在解决长格式报告评估的不足，推动智能代理发展。",
      "motivation": "深度研究代理在复杂任务中展现出强大能力，如任务分解和跨源检索，但现有评估基准在维度、响应格式和评分机制上存在缺陷，无法全面评估其性能。这限制了代理的优化和应用，尤其是在长报告生成任务中，当前评估工具过于简化，忽视了语义质量和检索可信度等关键方面，亟需更精细的评估框架。",
      "method": "Dr. Bench框架设计为核心多维评估系统，包括214个专家策划的挑战性任务，覆盖10个广泛领域，每个任务配有手动构建的参考捆绑包以支持复合评估。关键创新在于整合了语义质量、主题聚焦和检索可信度等指标，专门针对长格式报告评估，通过多阶段评分机制全面分析深度研究代理的输出能力，无需依赖特定模型架构，侧重于评估流程和标准。",
      "result": "实验结果显示，主流深度研究代理在长报告生成任务中优于基于网络搜索工具增强的推理模型，证实了其有效性。尽管性能有所提升，但评估揭示出在语义一致性和检索准确性方面仍有显著改进空间。与基线对比表明，Dr. Bench框架能更细致地揭示代理的优缺点，为后续优化提供了数据基础，但具体提升百分比在摘要中未明确说明。",
      "conclusion": "该研究的主要贡献是建立了Dr. Bench评估框架，为深度研究代理的能力评估、架构改进和范式发展提供了坚实工具。其学术价值在于填补了长报告评估的空白，实践上可促进代理在研究和应用中的优化。局限性可能包括评估任务的领域覆盖有限，未来工作可扩展任务多样性或引入更多评估指标以增强通用性。",
      "tags": [
        "Deep Research Agents",
        "Multidimensional Evaluation",
        "Long-form Report Assessment",
        "Semantic Quality Metrics",
        "Retrieval Trustworthiness"
      ]
    },
    "analyzed_at": "2026-01-30T03:42:15.740131Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.02081",
    "title": "Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions",
    "authors": [
      "Zhaoyi Li",
      "Jingtao Ding",
      "Yong Li",
      "Shihua Li"
    ],
    "abstract": "Flow Matching (FM) models achieve remarkable results in generative tasks. Building upon diffusion models, FM's simulation-free training paradigm enables simplicity and efficiency but introduces a train-inference gap: model outputs cannot be assessed during training. Moreover, the straight flow assumption suffers from some inherent limitations. To address this, we propose to fine-tune FM via Maximum Likelihood Estimation (MLE) of reconstructions -- enabled by FM's smooth ODE formulation, unlike the stochastic differential equations (SDEs) in diffusion models. We first theoretically analyze the relationship between training loss and inference error in FM under numerical precision constraints. We then propose an easy-to-implement fine-tuning framework based on MLE of reconstructions, with flexibility for sophisticated extensions. Building on this, we incorporate a generalized artificial viscosity term that enhances flow stability and robustness, accompanied by a direct parameterization method and rigorous theoretical guarantees. Experiments demonstrate our method's effectiveness across diverse settings: a toy example provides mechanistic insights into the fine-tuning process, while large-scale evaluations on meteorological forecasting and robotic manipulation policies validate reliable performance improvements.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.02081.pdf",
    "abs_url": "https://arxiv.org/abs/2510.02081",
    "published": "2025-10-02T14:49:47Z",
    "updated": "2026-01-29T14:05:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出通过重建的最大似然估计来微调Flow Matching模型，以解决训练-推理差距和直流水假设的局限性，提升生成任务的性能。",
      "motivation": "Flow Matching（FM）模型基于扩散模型，具有无模拟训练的简化优势，但在实际应用中存在训练-推理差距：训练期间无法直接评估模型输出，导致优化效率受限。此外，直流水假设存在固有缺陷，可能影响模型的稳定性和泛化能力。因此，研究旨在解决这些不足，通过改进FM框架以增强其在实际任务（如气象预报和机器人操作）中的可靠性和实用性。",
      "method": "论文首先在数值精度约束下理论分析了FM中训练损失与推理误差的关系。然后，提出一个基于重建最大似然估计（MLE）的微调框架，利用FM的光滑ODE公式（区别于扩散模型的SDEs），易于实现并支持复杂扩展。进一步，引入广义人工粘性项以增强流的稳定性和鲁棒性，配合直接参数化方法，并提供了严格的理论保证，确保方法的有效性和灵活性。",
      "result": "实验表明，方法在多种设置下均有效：一个玩具示例深入揭示了微调过程的机制，提供了直观洞察。在大规模评估中，应用于气象预报和机器人操作策略任务，结果显示可靠的性能提升，验证了方法在改善模型输出质量和稳定性方面的优势。摘要未明确说明具体数值指标，但强调了跨越不同领域的有效性。",
      "conclusion": "本研究的主要贡献是提出了一种通过重建MLE微调Flow Matching模型的新方法，解决了训练-推理差距和直流水假设问题。理论分析和框架设计为FM优化提供了新视角，引入的广义人工粘性项增强了鲁棒性。在气象预报和机器人操作等实际应用中展示了潜力，具有学术和实用价值。未来工作可探索更多扩展或应用到其他生成任务中。",
      "tags": [
        "Flow Matching",
        "Maximum Likelihood Estimation",
        "Fine-Tuning",
        "ODE",
        "Artificial Viscosity"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:18.072032Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.01824",
    "title": "Black-Box Combinatorial Optimization with Order-Invariant Reinforcement Learning",
    "authors": [
      "Olivier Goudet",
      "Quentin Suire",
      "Adrien Goëffon",
      "Frédéric Saubion",
      "Sylvain Lamprier"
    ],
    "abstract": "We introduce an order-invariant reinforcement learning framework for black-box combinatorial optimization. Classical estimation-of-distribution algorithms (EDAs) often rely on learning explicit variable dependency graphs, which can be costly and fail to capture complex interactions efficiently. In contrast, we parameterize a multivariate autoregressive generative model trained without a fixed variable ordering. By sampling random generation orders during training, a form of information-preserving dropout, the model is encouraged to be invariant to variable order, promoting search-space diversity, and shaping the model to focus on the most relevant variable dependencies, improving sample efficiency. We adapt Group Relative Policy Optimization (GRPO) to this setting, providing stable policy-gradient updates from scale-invariant advantages. Across a wide range of benchmark algorithms and problem instances of varying sizes, our method frequently achieves the best performance and consistently avoids catastrophic failures.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.01824.pdf",
    "abs_url": "https://arxiv.org/abs/2510.01824",
    "published": "2025-10-02T09:12:17Z",
    "updated": "2026-01-29T13:30:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种序不变强化学习框架，通过训练中采样随机顺序的自回归生成模型，提升黑盒组合优化的样本效率和性能。",
      "motivation": "研究旨在解决黑盒组合优化中传统估计分布算法（EDAs）的局限性，这些方法通常依赖学习显式变量依赖图，计算成本高且难以高效捕捉复杂交互。组合优化在实际应用中至关重要，但现有方法在处理大规模和复杂依赖时效率低下，导致性能瓶颈，因此需要更鲁棒和高效的框架来改进搜索过程。",
      "method": "方法参数化了一个多变量自回归生成模型，不依赖固定变量顺序，创新地通过在训练中采样随机生成顺序（一种信息保留丢弃形式），使模型对变量顺序不变，从而促进搜索空间多样性和聚焦于最相关的变量依赖，提高样本效率。使用Group Relative Policy Optimization (GRPO)进行适应，提供从尺度不变优势的稳定策略梯度更新，模型架构和数据集细节摘要未明确说明。",
      "result": "实验结果显示，该方法在广泛的基准算法和不同规模问题实例上，经常取得最佳性能，并一致避免灾难性失败，展现了优于现有方法的鲁棒性和效率，具体性能指标如准确率提升摘要未明确说明，但与基线对比明显。",
      "conclusion": "论文的主要贡献是提出了一个序不变强化学习框架，显著改善了黑盒组合优化的效果和效率，通过使模型对变量顺序不变，增强搜索多样性和依赖关注，具有重要的学术价值和实际应用潜力，未来工作可扩展至更多问题类型或进一步验证细节。",
      "tags": [
        "Combinatorial Optimization",
        "Reinforcement Learning",
        "Order-Invariant Models",
        "Autoregressive Models",
        "GRPO"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:19.357828Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.26157",
    "title": "Entropy Guided Dynamic Patch Segmentation for Time Series Transformers",
    "authors": [
      "Sachith Abeywickrama",
      "Emadeldeen Eldele",
      "Min Wu",
      "Xiaoli Li",
      "Chau Yuen"
    ],
    "abstract": "Patch-based transformers have emerged as efficient and improved long-horizon modeling architectures for time series modeling. Yet, existing approaches rely on temporally-agnostic patch construction, where arbitrary starting positions and fixed lengths fracture temporal coherence by splitting natural transitions across boundaries. This naive segmentation often disrupts short-term dependencies and weakens representation learning. We propose a novel Entropy-Guided Dynamic Patch Encoder (EntroPE), as a temporally informed framework that dynamically detects transition points via conditional entropy and dynamically places patch boundaries. This preserves temporal structure while retaining the computational benefits of patching. EntroPE consists of two key modules, namely an Entropy-based Dynamic Patcher (EDP) that applies information-theoretic criteria to locate natural temporal shifts and determine patch boundaries, and an Adaptive Patch Encoder (APE) that employs pooling and cross-attention to capture intra-patch dependencies and produce fixed-size latent representations. Extensive experiments on long-term forecasting, classification, and anomaly detection demonstrate that the proposed method improves both accuracy and efficiency, establishing entropy-guided dynamic patching as a promising new paradigm for time series modeling. Code is available at https://github.com/Sachithx/EntroPE.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.26157.pdf",
    "abs_url": "https://arxiv.org/abs/2509.26157",
    "published": "2025-09-30T12:09:56Z",
    "updated": "2026-01-29T11:07:55Z",
    "comment": "Preprint. Under Review",
    "light_analysis": {
      "overview": "提出熵引导的动态补丁编码器EntroPE，通过条件熵动态分割时间序列补丁以优化Transformer的时间建模性能。",
      "motivation": "基于补丁的Transformer方法在时间序列建模中表现出色，但现有方法采用时间无关的固定长度补丁分割，这导致补丁边界破坏自然时间过渡和短期依赖关系，弱化了表示学习的效果。该问题影响了模型在捕捉序列连贯性方面的能力，限制了应用范围。因此，研究旨在开发一种能动态检测时间变化点以保留时间结构的方法，弥补现有方法的不足。",
      "method": "论文提出Entropy-Guided Dynamic Patch Encoder (EntroPE)，它包括两个核心模块：Entropy-based Dynamic Patcher (EDP) 使用信息论中的条件熵标准来动态识别时间序列中的自然过渡点，并据此确定补丁边界；Adaptive Patch Encoder (APE) 则利用池化和跨注意力机制捕获补丁内的依赖关系，并生成固定大小的潜在表示，从而在保留计算效率的同时增强时间建模能力。",
      "result": "在长期预测、分类和异常检测等多个任务上进行广泛实验，结果表明，提出的EntroPE方法在准确性和效率方面均优于基线方法。摘要未明确说明具体性能数据（如准确率提升百分比），但强调了方法的有效性，为时间序列建模提供了改进方案。",
      "conclusion": "研究的主要贡献是引入了熵引导的动态补丁分割范式，解决了传统方法破坏时间连续性的问题，从而提升了时间序列Transformer的性能。该方法在学术上推动了序列建模的创新，具有广泛的实际应用价值，如预测和异常检测等领域。未来工作可探索更多信息论准则或扩展到其他序列数据。",
      "tags": [
        "Time Series Modeling",
        "Patch-based Transformers",
        "Entropy-based Segmentation",
        "Dynamic Patching",
        "Cross-Attention"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:13.696331Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.25851",
    "title": "MuSLR: Multimodal Symbolic Logical Reasoning",
    "authors": [
      "Jundong Xu",
      "Hao Fei",
      "Yuhui Zhang",
      "Liangming Pan",
      "Qijun Huang",
      "Qian Liu",
      "Preslav Nakov",
      "Min-Yen Kan",
      "William Yang Wang",
      "Mong-Li Lee",
      "Wynne Hsu"
    ],
    "abstract": "Multimodal symbolic logical reasoning, which aims to deduce new facts from multimodal input via formal logic, is critical in high-stakes applications such as autonomous driving and medical diagnosis, as its rigorous, deterministic reasoning helps prevent serious consequences. To evaluate such capabilities of current state-of-the-art vision language models (VLMs), we introduce the first benchmark MuSLR for multimodal symbolic logical reasoning grounded in formal logical rules. MuSLR comprises 1,093 instances across 7 domains, including 35 atomic symbolic logic and 976 logical combinations, with reasoning depths ranging from 2 to 9. We evaluate 7 state-of-the-art VLMs on MuSLR and find that they all struggle with multimodal symbolic reasoning, with the best model, GPT-4.1, achieving only 46.8%. Thus, we propose LogiCAM, a modular framework that applies formal logical rules to multimodal inputs, boosting GPT-4.1's Chain-of-Thought performance by 14.13%, and delivering even larger gains on complex logics such as first-order logic. We also conduct a comprehensive error analysis, showing that around 70% of failures stem from logical misalignment between modalities, offering key insights to guide future improvements. All data and code are publicly available at https://llm-symbol.github.io/MuSLR.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.25851.pdf",
    "abs_url": "https://arxiv.org/abs/2509.25851",
    "published": "2025-09-30T06:42:20Z",
    "updated": "2026-01-29T03:43:05Z",
    "comment": "Accepted by NeurIPS 2025",
    "light_analysis": {
      "overview": "论文提出了首个多模态符号逻辑推理基准MuSLR，并设计了LogiCAM框架，显著提升了GPT-4.1的推理性能。",
      "motivation": "多模态符号逻辑推理通过形式逻辑从多模态输入推导新事实，在自动驾驶和医疗诊断等高风险应用中至关重要，其严格的、确定性的推理有助于防止严重后果。然而，当前最先进的视觉语言模型(VLMs)在这方面存在不足，表现不佳，因此需要建立评估基准和改进方法来应对实际安全需求。研究旨在填补这一空白，推动多模态推理能力的发展。",
      "method": "研究提出了LogiCAM，一个模块化框架，将正式逻辑规则应用于多模态输入以提升模型推理能力。首先创建了MuSLR基准，包含1,093个实例覆盖7个领域，35个原子符号逻辑和976个逻辑组合，推理深度从2到9，提供了全面的评估工具。该框架的关键创新在于结合逻辑规则与多模态数据处理，应用于GPT-4.1的Chain-of-Thought方法，通过增强逻辑推理过程来改进性能。",
      "result": "在MuSLR基准上评估了7个最先进的VLMs，最佳模型GPT-4.1仅达到46.8%的准确率。提出的LogiCAM框架显著提升了性能，将GPT-4.1的Chain-of-Thought表现提高了14.13%，在复杂逻辑如一阶逻辑上提升更为显著。错误分析显示约70%的失败案例源于模态间的逻辑不对齐，为未来改进提供了关键见解，强调了多模态对齐的重要性。",
      "conclusion": "论文的主要贡献是引入了首个多模态符号逻辑推理基准MuSLR和提出了LogiCAM框架，显著提升了模型的推理能力。这为学术研究提供了重要的评估工具和改进方法，对高风险应用如自动驾驶和医疗诊断具有实际价值。研究还揭示了模态间逻辑不对齐是主要失败原因，为未来工作指明了方向，如增强逻辑推理模块和改进多模态对齐技术。",
      "tags": [
        "Multimodal Reasoning",
        "Symbolic Logic",
        "Vision Language Models",
        "Logical Rules",
        "Chain-of-Thought"
      ]
    },
    "analyzed_at": "2026-01-30T03:43:48.071476Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.24906",
    "title": "Neural network embeddings recover value dimensions from psychometric survey items on par with human data",
    "authors": [
      "Max Pellert",
      "Clemens M. Lechner",
      "Indira Sen",
      "Markus Strohmaier"
    ],
    "abstract": "We demonstrate that embeddings derived from large language models, when processed with \"Survey and Questionnaire Item Embeddings Differentials\" (SQuID), can recover the structure of human values obtained from human rater judgments on the Revised Portrait Value Questionnaire (PVQ-RR). We compare multiple embedding models across a number of evaluation metrics including internal consistency, dimension correlations and multidimensional scaling configurations. Unlike previous approaches, SQuID addresses the challenge of obtaining negative correlations between dimensions without requiring domain-specific fine-tuning or training data re-annotation. Quantitative analysis reveals that our embedding-based approach explains 55% of variance in dimension-dimension similarities compared to human data. Multidimensional scaling configurations show alignment with pooled human data from 49 different countries. Generalizability tests across three personality inventories (IPIP, BFI-2, HEXACO) demonstrate that SQuID consistently increases correlation ranges, suggesting applicability beyond value theory. These results show that semantic embeddings can effectively replicate psychometric structures previously established through extensive human surveys. The approach offers substantial advantages in cost, scalability and flexibility while maintaining comparable quality to traditional methods. Our findings have significant implications for psychometrics and social science research, providing a complementary methodology that could expand the scope of human behavior and experience represented in measurement tools.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.24906.pdf",
    "abs_url": "https://arxiv.org/abs/2509.24906",
    "published": "2025-09-29T15:14:54Z",
    "updated": "2026-01-29T11:51:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出基于大语言模型嵌入和SQuID方法，无需特定领域训练，有效恢复心理测量问卷中的人类价值观结构。",
      "motivation": "该研究旨在解决传统心理测量方法依赖人工评分的问题，这种方式成本高、可扩展性差，且现有方法常需要领域特定微调或数据重标注，限制了广泛应用。SQuID方法通过利用大语言模型嵌入，自动从问卷项目恢复价值观结构，提供了一种更经济、灵活的替代方案，以补充并扩展心理测量和社会科学研究工具。",
      "method": "研究方法核心是SQuID，它处理大语言模型生成的嵌入差异来恢复人类价值观结构，创新点在于无需领域特定微调或数据重新标注，解决了维度负相关的挑战。实验使用Revised Portrait Value Questionnaire (PVQ-RR)和三个人格清单（IPIP、BFI-2、HEXACO），通过比较多个嵌入模型的内部一致性、维度相关性和多维缩放配置，验证方法的有效性。",
      "result": "定量分析显示，基于嵌入的方法解释了55%的维度间相似性方差，与人类数据对齐。多维缩放配置与来自49个国家的人类数据一致，通用性测试在IPIP、BFI-2、HEXACO上表明SQuID提高了相关性范围，显示跨领域适用性。该方法在成本、可扩展性和灵活性上优于传统人类评分，同时保持质量相当，为心理测量提供了高效替代。",
      "conclusion": "研究表明，SQuID方法能有效复制心理测量结构，为心理测量学和社会科学研究提供一种补充方法论，具低成本、高可扩展性和灵活性。学术价值在于扩展测量工具的范围，实际应用价值体现在促进大规模行为分析。摘要未明确说明局限性，但未来工作可能涉及更多数据集验证和技术优化以提升通用性。",
      "tags": [
        "Large Language Model",
        "Semantic Embeddings",
        "Psychometric Analysis",
        "SQuID",
        "Human Values Recovery"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:34.364618Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.24472",
    "title": "FS-KAN: Permutation Equivariant Kolmogorov-Arnold Networks via Function Sharing",
    "authors": [
      "Ran Elbaz",
      "Guy Bar-Shalom",
      "Yam Eitan",
      "Fabrizio Frasca",
      "Haggai Maron"
    ],
    "abstract": "Permutation equivariant neural networks employing parameter-sharing schemes have emerged as powerful models for leveraging a wide range of data symmetries, significantly enhancing the generalization and computational efficiency of the resulting models. Recently, Kolmogorov-Arnold Networks (KANs) have demonstrated promise through their improved interpretability and expressivity compared to traditional architectures based on MLPs. While equivariant KANs have been explored in recent literature for a few specific data types, a principled framework for applying them to data with permutation symmetries in a general context remains absent. This paper introduces Function Sharing KAN (FS-KAN), a principled approach to constructing equivariant and invariant KA layers for arbitrary permutation symmetry groups, unifying and significantly extending previous work in this domain. We derive the basic construction of these FS-KAN layers by generalizing parameter-sharing schemes to the Kolmogorov-Arnold setup and provide a theoretical analysis demonstrating that FS-KANs have the same expressive power as networks that use standard parameter-sharing layers, allowing us to transfer well-known and important expressivity results from parameter-sharing networks to FS-KANs. Empirical evaluations on multiple data types and symmetry groups show that FS-KANs exhibit superior data efficiency compared to standard parameter-sharing layers, by a wide margin in certain cases, while preserving the interpretability and adaptability of KANs, making them an excellent architecture choice in low-data regimes.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.24472.pdf",
    "abs_url": "https://arxiv.org/abs/2509.24472",
    "published": "2025-09-29T08:49:09Z",
    "updated": "2026-01-29T17:41:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了 FS-KAN，一个统一框架来构建适用于任意置换对称群的等变和不变 Kolmogorov-Arnold 网络层。",
      "motivation": "本研究旨在解决在一般背景下应用置换等变 Kolmogorov-Arnold Networks (KANs) 的框架缺失问题。置换等变神经网络通过参数共享利用数据对称性，能显著提升模型的泛化能力和计算效率，KANs 相比传统 MLPs 具有更好的可解释性和表达能力。然而，现有研究仅针对少数特定数据类型探索了等变 KANs，缺乏适用于任意置换对称性的统一方法，限制了其在实际应用中的广泛使用。因此，开发一个 principled 框架来扩展 KANs 的等变性，对于处理对称性数据至关重要。",
      "method": "论文提出了 Function Sharing KAN (FS-KAN) 方法，通过将参数共享方案推广到 Kolmogorov-Arnold 设置，构建置换等变和不变的网络层。核心创新包括推导 FS-KAN 层的基本构造，并提供理论分析证明其与标准参数共享网络具有相同的表达能力，从而允许转移已知的表达能力结果。该框架适用于任意置换对称群，基于 KANs 架构，统一了先前工作，扩展了置换等变网络的应用范围。",
      "result": "经验评估表明，在多种数据类型和对称群上，FS-KANs 相比标准参数共享层表现出更优的数据效率，在某些情况下优势显著。实验验证了 FS-KANs 在低数据场景下的有效性，同时保持了 KANs 固有的可解释性和适应性。这使得 FS-KANs 成为处理对称性数据的优秀架构选择，摘要未明确量化具体性能指标，但强调了其广泛优势。",
      "conclusion": "本研究的主要贡献是提出了 FS-KAN 框架，为构建置换等变 Kolmogorov-Arnold Networks 提供了统一方法。其学术价值在于理论证明了表达能力等价性，扩展了 KANs 的理论和应用边界。实际意义在于 FS-KANs 在低数据场景下表现出色，结合了可解释性和高效性，为对称性数据处理提供了新工具。未来工作可探索 FS-KANs 在更广泛数据类型的应用，并优化其在复杂对称性下的性能。",
      "tags": [
        "Permutation Equivariant Networks",
        "Kolmogorov-Arnold Networks",
        "Function Sharing",
        "Parameter Sharing",
        "Expressivity Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:54.794422Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.24050",
    "title": "Bridging On-Device and Cloud LLMs for Collaborative Reasoning: A Unified Methodology for Local Routing and Post-Training",
    "authors": [
      "Wenzhi Fang",
      "Dong-Jun Han",
      "Liangqi Yuan",
      "Evan Chen",
      "Christopher Brinton"
    ],
    "abstract": "Device-cloud collaboration holds promise for deploying large language models (LLMs), leveraging lightweight on-device models for efficiency while relying on powerful cloud models for superior reasoning. A central challenge in this setting is determining, for each incoming query, whether it should be processed locally or offloaded to the cloud. Existing approaches typically rely on external routers, which often struggle to determine difficulty from the prompt itself, especially for tasks involving complex reasoning. Motivated by this limitation, we propose enabling on-device LLMs to decide internally whether to invoke cloud assistance at inference time, with this capability instilled through reinforcement learning based post-training. Casting on-device LLM post-training as a reward maximization problem, we design hierarchical rewards to encourage local problem solving and judicious cloud offloading. To solve the resulting problem, we develop an algorithm featuring a group-level policy gradient that stabilizes optimization, together with adaptive prompt filtering that provides complementary learning signals to mitigate policy collapse (i.e., exclusive local execution or exclusive cloud offloading). Extensive experiments on on-device-scale LLaMA and Qwen models across multiple reasoning benchmarks show that our method consistently outperforms baselines and significantly narrows the gap to full cloud LLMs.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.24050.pdf",
    "abs_url": "https://arxiv.org/abs/2509.24050",
    "published": "2025-09-28T19:48:56Z",
    "updated": "2026-01-29T07:25:15Z",
    "comment": "We propose a unified post-training framework that integrates routing optimization, enabling the on-device LLM to improve its problem-solving ability while learning routing strategies",
    "light_analysis": {
      "overview": "提出一种基于强化学习后训练的统一方法，使设备端大型语言模型能自主决定是否调用云辅助进行推理。",
      "motivation": "设备-云协作部署大型语言模型（LLMs）能利用轻量级设备模型提高效率，并依赖强大云模型进行推理，但核心挑战在于如何为每个查询动态选择处理位置。现有方法通常依赖外部路由器，这些路由器难以从提示本身准确评估任务难度，尤其是在需要复杂推理的场景中，导致资源分配不当和性能瓶颈。因此，需要一种更智能的内部决策机制来优化协作效率。",
      "method": "论文提出通过强化学习后训练设备端LLMs，使其在推理时内部决定是否卸载查询到云。该方法将后训练建模为奖励最大化问题，设计分层奖励以鼓励本地问题解决和明智的云调用，平衡效率和性能。算法包括群体级策略梯度以稳定优化过程，以及自适应提示过滤来提供补充学习信号，有效防止策略崩溃（如仅本地处理或仅云卸载）。实验基于设备规模的LLaMA和Qwen模型，在多个推理基准上验证方法。",
      "result": "在多个推理基准上的实验结果显示，该方法一致优于基线方法（如外部路由器），并显著缩小了与全云LLMs的性能差距，证明了其在提高推理准确性和资源利用率方面的有效性。摘要未提供具体数据指标，但强调了方法的稳定性和优越性，验证了设备-云协作的优化潜力。",
      "conclusion": "论文的主要贡献是提出了一种统一方法，通过强化学习后训练实现设备端LLMs的自主路由决策，解决了协作部署中的关键挑战。学术上，为LLMs后训练和协作推理提供了新思路；实际上，提高了LLMs部署的资源利用效率和性能，具有广泛的应用前景。未来工作可扩展到更多模型架构和复杂任务场景，以进一步优化协作机制。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Post-Training",
        "Local Routing",
        "Cloud Collaboration"
      ]
    },
    "analyzed_at": "2026-01-30T03:44:40.180259Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.23694",
    "title": "SafeSearch: Automated Red-Teaming of LLM-Based Search Agents",
    "authors": [
      "Jianshuo Dong",
      "Sheng Guo",
      "Hao Wang",
      "Xun Chen",
      "Zhuotao Liu",
      "Tianwei Zhang",
      "Ke Xu",
      "Minlie Huang",
      "Han Qiu"
    ],
    "abstract": "Search agents connect LLMs to the Internet, enabling them to access broader and more up-to-date information. However, this also introduces a new threat surface: unreliable search results can mislead agents into producing unsafe outputs. Real-world incidents and our two in-the-wild observations show that such failures can occur in practice. To study this threat systematically, we propose SafeSearch, an automated red-teaming framework that is scalable, cost-efficient, and lightweight, enabling harmless safety evaluation of search agents. Using this, we generate 300 test cases spanning five risk categories (e.g., misinformation and prompt injection) and evaluate three search agent scaffolds across 17 representative LLMs. Our results reveal substantial vulnerabilities in LLM-based search agents, with the highest ASR reaching 90.5% for GPT-4.1-mini in a search-workflow setting. Moreover, we find that common defenses, such as reminder prompting, offer limited protection. Overall, SafeSearch provides a practical way to measure and improve the safety of LLM-based search agents. Our codebase and test cases are publicly available: https://github.com/jianshuod/SafeSearch.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.23694.pdf",
    "abs_url": "https://arxiv.org/abs/2509.23694",
    "published": "2025-09-28T07:05:17Z",
    "updated": "2026-01-29T10:58:06Z",
    "comment": "Preprint. Updated with new experiments",
    "light_analysis": {
      "overview": "本研究提出了SafeSearch，一个自动化的红队框架，用于系统评估基于大语言模型的搜索代理的安全性漏洞。",
      "motivation": "随着大语言模型（LLM）与互联网的集成，搜索代理能够访问更广泛和最新的信息，但这引入了新的安全威胁：不可靠的搜索结果可能误导代理产生有害输出，如错误信息或恶意内容。现实世界事件和作者的实地观察表明，这种漏洞在实践中确实存在。当前缺乏系统评估这些威胁的方法，现有防御措施如提醒提示可能效果有限，因此本研究旨在提供一个可扩展且成本高效的安全评估框架，以系统研究这一重要问题。",
      "method": "本研究提出了SafeSearch框架，这是一个可扩展、成本高效且轻量级的自动化红队系统，专门用于无害地评估搜索代理的安全性。方法的核心是生成300个测试案例，覆盖五个风险类别，包括错误信息和提示注入等，以确保全面覆盖常见威胁。利用这些测试案例，作者评估了三种搜索代理架构和17个代表性的大语言模型（如GPT系列），通过标准化的攻击成功率（ASR）测量来分析安全漏洞，无需依赖昂贵的模拟或人工干预。",
      "result": "实验结果显示，基于LLM的搜索代理存在重大安全漏洞，最高攻击成功率（ASR）在搜索工作流设置中达到90.5%，针对GPT-4.1-mini模型。与基线方法相比，常见防御措施如提醒提示仅提供有限保护，突显了现有安全措施的不足。这些发现验证了SafeSearch框架的有效性，表明其在系统测量和比较不同LLM和搜索代理架构的脆弱性方面具有实际价值，且结果具有统计学意义。",
      "conclusion": "本文的主要贡献是提出了SafeSearch框架，为测量和改进基于LLM的搜索代理的安全性提供了实用工具。该研究不仅揭示了现有系统的脆弱性，还通过开源代码和测试案例促进了社区协作，有助于推动未来安全研究和实际应用中的改进。这有助于增强AI系统的可靠性和信任度，尽管潜在局限性如测试案例的通用性可能需要进一步探索，但为相关领域的安全评估设立了新基准。",
      "tags": [
        "Large Language Model",
        "Red-Teaming",
        "Safety Evaluation",
        "Misinformation",
        "Prompt Injection"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:07.404406Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.23480",
    "title": "RestoRect: Degraded Image Restoration via Latent Rectified Flow & Feature Distillation",
    "authors": [
      "Shourya Verma",
      "Mengbo Wang",
      "Nadia Atallah Lanman",
      "Ananth Grama"
    ],
    "abstract": "Current approaches for restoration of degraded images face a trade-off: high-performance models are slow for practical use, while fast models produce poor results. Knowledge distillation transfers teacher knowledge to students, but existing static feature matching methods cannot capture how modern transformer architectures dynamically generate features. We propose a novel Latent Rectified Flow Feature Distillation method for restoring degraded images called \\textbf{'RestoRect'}. We apply rectified flow to reformulate feature distillation as a generative process where students learn to synthesize teacher-quality features through learnable trajectories in latent space. Our framework combines Retinex decomposition with learnable anisotropic diffusion constraints, and trigonometric color space polarization. We introduce a Feature Layer Extraction loss for robust knowledge transfer between different network architectures through cross-normalized transformer feature alignment with percentile-based outlier detection. RestoRect achieves better training stability, and faster convergence and inference while preserving restoration quality, demonstrating superior results across 15 image restoration datasets, covering 4 tasks, on 10 metrics against baselines.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.23480.pdf",
    "abs_url": "https://arxiv.org/abs/2509.23480",
    "published": "2025-09-27T20:04:41Z",
    "updated": "2026-01-29T05:48:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "RestoRect提出了一种基于潜在rectified flow和特征蒸馏的图像修复方法，以解决性能与速度的权衡问题。",
      "motivation": "当前图像修复领域面临核心挑战：高性能模型计算速度慢，不适用于实时应用；快速模型则修复质量低下。知识蒸馏虽能转移知识，但现有静态特征匹配方法无法适应现代transformer架构的动态特征生成过程，限制了实际部署。本研究旨在克服这一局限，开发一种新方法，实现高效且高质量的图像修复，以应对如医学影像和自动驾驶等应用场景的需求。",
      "method": "RestoRect基于Latent Rectified Flow Feature Distillation方法，将特征蒸馏重新定义为生成过程：学生模型在潜在空间中通过可学习轨迹合成教师模型质量的特征。框架结合Retinex分解技术，引入可学习的各向异性扩散约束和三角颜色空间极化来增强特征表示。此外，设计Feature Layer Extraction loss，通过交叉归一化transformer特征对齐和基于百分位数的异常检测，促进不同网络架构间的鲁棒知识转移，提升训练稳定性和模型兼容性。",
      "result": "实验表明，RestoRect在训练过程中表现出更高的稳定性，并显著加快了收敛速度，同时推理速度得到提升，而修复质量未受影响。在综合评估中，该方法在15个图像修复数据集上，涵盖去噪、超分辨率等4个任务，并通过10个不同指标的对比，均优于基线方法。摘要未明确说明具体性能指标如准确率提升百分比，但突出了在效率和效果维持方面的优势，例如更快的训练和推理时间。",
      "conclusion": "本研究的主要贡献是提出了RestoRect，一种创新的潜在rectified flow特征蒸馏框架，有效解决了图像修复中性能与速度的权衡。学术上，为知识蒸馏和生成模型在计算机视觉中的应用提供了新思路；实践上，推动了高效图像修复系统的发展。摘要未明确说明潜在局限性或未来工作方向，但暗示了方法的广泛适用性和鲁棒性，为后续研究如扩展到更多任务或优化架构奠定了基础。",
      "tags": [
        "Latent Rectified Flow",
        "Feature Distillation",
        "Transformer",
        "Retinex Decomposition",
        "Learnable Anisotropic Diffusion"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:46.425597Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22944",
    "title": "SINQ: Sinkhorn-Normalized Quantization for Calibration-Free Low-Precision LLM Weights",
    "authors": [
      "Lorenz K. Müller",
      "Philippe Bich",
      "Jiawei Zhuang",
      "Ahmet Çelik",
      "Luca Benfenati",
      "Lukas Cavigelli"
    ],
    "abstract": "Post-training quantization has emerged as the most widely used strategy for deploying large language models at low precision. Still, current methods show perplexity degradation at bit-widths less than or equal to 4, partly because representing outliers causes precision issues in parameters that share the same scales as these outliers. This problem is especially pronounced for calibration-free, uniform quantization methods. We introduce SINQ to augment existing post-training quantizers with an additional second-axis scale factor and a fast Sinkhorn-Knopp-style algorithm that finds scales to normalize per-row and per-column variances. We show that this approximates activation-aware quantization by recovering column scales from the weight matrix structure that are predictive of the typical activation magnitudes the matrix received during training. Our method has no interactions between layers and can be trivially applied to new architectures to quantize any linear layer. We evaluate our method on the Qwen3 model family, among others. SINQ reduces the perplexity gap on WikiText2 and C4 by over 50% against uncalibrated uniform quantization baselines, incurs zero to negligible compute overhead, and can be further enhanced by combining it with calibration and non-uniform quantization levels. Code is available at https://github.com/huawei-csl/SINQ.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.22944.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22944",
    "published": "2025-09-26T21:22:54Z",
    "updated": "2026-01-29T14:15:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "SINQ通过引入第二轴尺度因子和快速Sinkhorn-Knopp算法，实现了校准无关的低精度大语言模型权重量化，显著减少困惑度下降。",
      "motivation": "论文旨在解决后训练量化在低比特宽度下的性能瓶颈问题。具体来说，当比特宽度小于或等于4时，现有方法导致困惑度下降，主要因为异常值引起共享尺度的参数精度问题，这在校准无关的均匀量化方法中尤其严重。这个问题限制了低精度模型的部署，影响计算效率和实际应用，现有方法往往需要复杂校准或牺牲模型性能，因此亟需改进量化策略来提升效率和准确性。",
      "method": "SINQ方法在现有后训练量化器基础上，添加了一个第二轴尺度因子，并使用快速Sinkhorn-Knopp算法归一化行和列方差。关键创新在于通过权重矩阵结构近似激活感知量化，从矩阵中恢复列尺度以预测训练期间激活幅度，从而避免了校准需求。该方法独立于层间交互，可轻松应用于任何线性层和不同架构，例如在Qwen3模型家族上实施，无需额外训练数据或复杂配置，简化了量化流程。",
      "result": "在Qwen3模型家族等评估中，SINQ在WikiText2和C4数据集上显著减少了困惑度差距，相比无校准的均匀量化基线降低超过50%。计算开销为零到可忽略，不增加额外负担。此外，该方法可结合校准和非均匀量化级别进一步提升性能，但摘要未明确说明具体提升数值。这些结果表明SINQ在低精度量化中能有效维持模型表现，且具有良好的兼容性和效率。",
      "conclusion": "论文的主要贡献是提出了SINQ这一校准无关的量化方法，通过Sinkhorn-Knopp算法优化尺度分配，显著改善了低精度权重量化性能。学术价值在于推进了后训练量化技术，特别是在处理异常值和保持模型精度方面；实际应用价值是便于大语言模型在低精度环境中的高效部署。潜在局限性包括可能依赖模型结构，未来工作可探索与更多量化技术结合以进一步提升效果。",
      "tags": [
        "Post-training Quantization",
        "Large Language Models",
        "Sinkhorn-Knopp Algorithm",
        "Uniform Quantization",
        "Low-Precision Weights"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:27.198921Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22259",
    "title": "Rotary Position Encodings for Graphs",
    "authors": [
      "Isaac Reid",
      "Arijit Sehanobish",
      "Cederik Höfs",
      "Bruno Mlodozeniec",
      "Leonhard Vulpius",
      "Federico Barbero",
      "Adrian Weller",
      "Krzysztof Choromanski",
      "Richard E. Turner",
      "Petar Veličković"
    ],
    "abstract": "We study the extent to which rotary position encodings (RoPE), a recent transformer position encoding algorithm broadly adopted in large language models (LLMs) and vision transformers (ViTs), can be applied to graph-structured data. We find that rotating tokens depending on the spectrum of the graph Laplacian efficiently injects structural information into the attention mechanism, boosting performance in synthetic and real-world graph learning tasks. This approach, coined _Wave-Induced Rotary Encodings_ (WIRE), enjoys intriguing theoretical properties: it recovers regular RoPE on grids, and depends asymptotically on the graph effective resistance. Unlike bias-based relative position encodings, WIRE is compatible with linear attention.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.22259.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22259",
    "published": "2025-09-26T12:20:18Z",
    "updated": "2026-01-29T14:09:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出了一种名为WIRE的图结构数据旋转位置编码方法，能够有效将图结构信息注入注意力机制，提升图学习任务的性能。",
      "motivation": "研究动机在于图结构数据在机器学习和AI应用中日益重要，但传统位置编码方法（如基于偏差的相对位置编码）在处理图数据时存在不足，例如可能与线性注意力不兼容。RoPE在序列数据中表现优异，但其在图数据上的应用尚未充分探索。因此，本研究旨在将RoPE扩展到图结构数据，解决如何有效编码位置信息以提升图学习任务的性能问题，填补现有方法的空白。",
      "method": "研究方法提出了WIRE（Wave-Induced Rotary Encodings），核心创新在于根据图拉普拉斯谱对令牌进行旋转，将图结构信息融入注意力机制。该方法利用图谱理论，通过旋转操作注入结构信息，具有理论保证：在网格结构中恢复标准RoPE，并渐进依赖于图有效电阻。WIRE与线性注意力兼容，提高了计算效率，涉及的关键技术包括图拉普拉斯算子和注意力机制的应用。",
      "result": "主要实验结果显示，WIRE在合成和现实世界的图学习任务中提升了性能，但摘要未明确说明具体数据指标（如准确率提升或效率改进）。基于描述，可以推断WIRE相比基线方法（如传统相对位置编码）在性能上有改进，但详细对比数据需参考论文全文。摘要仅提到性能提升，未提供具体数值支撑。",
      "conclusion": "结论表明，WIRE方法成功扩展了RoPE到图结构数据，提供了有效的结构编码方式，其理论性质和与线性注意力的兼容性增强了实用性。主要贡献在于将序列位置编码算法适应于图学习，推动了该领域的发展。局限性可能包括对特定图类型的依赖，未来工作可进一步优化编码策略或应用到更广泛的图任务中。",
      "tags": [
        "Rotary Position Encodings (RoPE)",
        "Graph Learning",
        "Graph Laplacian",
        "Attention Mechanism",
        "Linear Attention"
      ]
    },
    "analyzed_at": "2026-01-30T03:45:39.373387Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22161",
    "title": "Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization",
    "authors": [
      "Takashi Morita"
    ],
    "abstract": "Vector quantization, which discretizes a continuous vector space into a finite set of representative vectors (a codebook), has been widely adopted in modern machine learning. Despite its effectiveness, vector quantization poses a fundamental challenge: the non-differentiable quantization step blocks gradient backpropagation. Smoothed vector quantization addresses this issue by relaxing the hard assignment of a codebook vector into a weighted combination of codebook entries, represented as the matrix product of a simplex vector and the codebook. Effective smoothing requires two properties: (1) smoothed quantizers should remain close to a onehot vector, ensuring tight approximation, and (2) all codebook entries should be utilized, preventing code collapse. Existing methods typically address these desiderata separately. By contrast, the present study introduces a simple and intuitive regularization that promotes both simultaneously by minimizing the distance between each simplex vertex and its $K$-nearest smoothed quantizers. Experiments on representative benchmarks, including discrete image autoencoding and contrastive speech representation learning, demonstrate that the proposed method achieves more reliable codebook utilization and improves performance compared to prior approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.22161.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22161",
    "published": "2025-09-26T10:17:42Z",
    "updated": "2026-01-29T07:02:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出一种简单正则化方法，通过最小化单纯形顶点与K近邻平滑量化器的距离，有效防止码崩溃并提升平滑向量量化性能。",
      "motivation": "向量量化在机器学习中广泛应用，但其非可微量化步骤阻碍梯度回传，平滑向量量化通过放松硬分配来解决可微性问题，但面临码崩溃挑战，即某些码书条目未被利用，导致效率低下。现有方法通常分别处理平滑近似和码书利用，未能同时优化两者，限制了性能。因此，需要一种统一方法来同时促进这些性质，以提高量化效果和可靠性。",
      "method": "核心方法是引入一个正则化项，最小化每个单纯形顶点与其K最近平滑量化器之间的距离。这促使平滑量化器接近onehot向量，确保紧密近似，同时激活所有码书条目，防止码崩溃。方法简单直观，适用于平滑向量量化框架，实验基于离散图像自编码和对比语音表示学习等基准，具体模型架构摘要未详述，但体现了在图像和语音任务中的应用。",
      "result": "实验在代表性基准上进行，包括离散图像自编码和对比语音表示学习。结果表明，提出的正则化方法实现了更可靠的码书利用率，并提高了性能。与现有方法相比，该方法在防止码崩溃和提升任务表现方面表现更优，但摘要未明确说明具体性能指标如准确率提升。",
      "conclusion": "本研究的主要贡献是提出一种简单正则化方法，有效同时解决平滑向量量化中的码崩溃问题。学术价值在于统一处理平滑近似和码书利用，增强了量化理论的完整性。实际应用价值在于改善向量量化在图像编码和语音表示等场景的性能。未来工作可能包括探索更复杂的正则化策略或扩展到其他量化变体。",
      "tags": [
        "Vector Quantization",
        "Smoothed Vector Quantization",
        "Code Collapse",
        "Regularization",
        "Simplex Vertices"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:12.500288Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21670",
    "title": "MORPH: PDE Foundation Models with Arbitrary Data Modality",
    "authors": [
      "Mahindra Singh Rautela",
      "Alexander Most",
      "Siddharth Mansingh",
      "Bradley C. Love",
      "Alexander Scheinker",
      "Diane Oyen",
      "Nathan Debardeleben",
      "Earl Lawrence",
      "Ayan Biswas"
    ],
    "abstract": "We introduce MORPH, a modality-agnostic, autoregressive foundation model for partial differential equations (PDEs). MORPH is built on a convolutional vision transformer backbone that seamlessly handles heterogeneous spatiotemporal datasets of varying data modality (1D--3D) at different resolutions, and multiple fields with mixed scalar and vector components. The architecture combines (i) component-wise convolution, which jointly processes scalar and vector channels to capture local interactions, (ii) inter-field cross-attention, which models and selectively propagates information between different physical fields, (iii) axial attentions, which factorize full spatiotemporal self-attention along individual spatial and temporal axes to reduce computational burden while retaining expressivity. We pretrain multiple model variants on a diverse collection of heterogeneous PDE datasets and evaluate transfer to a range of downstream prediction tasks. Using both full-model fine-tuning and parameter-efficient low-rank adapters, MORPH outperforms models trained from scratch. Across extensive evaluations, MORPH matches or surpasses strong baselines and recent state-of-the-art models. Collectively, these capabilities present a flexible and powerful backbone for learning from the heterogeneous and multimodal nature of scientific observations, charting a path toward scalable and data-efficient scientific machine learning. The source code, datasets, and models are publicly available at https://github.com/lanl/MORPH.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.21670.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21670",
    "published": "2025-09-25T22:38:36Z",
    "updated": "2026-01-29T18:57:23Z",
    "comment": null,
    "light_analysis": {
      "overview": "MORPH是一个模态无关的自回归偏微分方程基础模型，通过卷积视觉变换器处理任意数据模态的异构时空数据，实现灵活高效的科学机器学习。",
      "motivation": "科学观测中偏微分方程数据常具有异构和多模态特性，如不同维度、分辨率和物理场，现有模型难以灵活处理这些变体，限制了数据效率和可扩展性。因此，开发一个能适应任意数据模态的通用基础模型至关重要，以解决从多源科学数据中提取知识的挑战，并推动数据驱动的科学发现。",
      "method": "MORPH基于卷积视觉变换器骨干网络，结合组件卷积联合处理标量和矢量通道以捕捉局部交互，使用场间交叉注意力建模不同物理场间的信息选择性传播，并通过轴向注意力分解时空自注意力以降低计算负担同时保留表达能力。模型在多样化PDE数据集上预训练，并采用全模型微调和参数高效的秩低适配器进行下游任务迁移。",
      "result": "通过预训练和迁移学习，MORPH在多个下游PDE预测任务中表现优异，优于从头训练的模型，并匹配或超过了强基线及最新方法。摘要未明确说明具体数据指标，但强调了模型在性能上的优越性，支持其在异构数据上的有效泛化能力。",
      "conclusion": "MORPH提供了一个灵活强大的骨干网络，用于从异构多模态科学数据中学习，推动了可扩展和数据高效的科学机器学习发展。模型已开源，促进了社区应用和进一步研究，未来可扩展至更多数据模态和应用场景，以提升科学建模的普适性。",
      "tags": [
        "Partial Differential Equations",
        "Foundation Model",
        "Convolutional Vision Transformer",
        "Cross-Attention",
        "Axial Attention"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:28.788795Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.21547",
    "title": "Machine Learning. The Science of Selection under Uncertainty",
    "authors": [
      "Yevgeny Seldin"
    ],
    "abstract": "Learning, whether natural or artificial, is a process of selection. It starts with a set of candidate options and selects the more successful ones. In the case of machine learning the selection is done based on empirical estimates of prediction accuracy of candidate prediction rules on some data. Due to randomness of data sampling the empirical estimates are inherently noisy, leading to selection under uncertainty. The book provides statistical tools to obtain theoretical guarantees on the outcome of selection under uncertainty. We start with concentration of measure inequalities, which are the main statistical instrument for controlling how much an empirical estimate of expectation of a function deviates from the true expectation. The book covers a broad range of inequalities, including Markov's, Chebyshev's, Hoeffding's, Bernstein's, Empirical Bernstein's, Unexpected Bernstein's, kl, and split-kl. We then study the classical (offline) supervised learning and provide a range of tools for deriving generalization bounds, including Occam's razor, Vapnik-Chervonenkis analysis, and PAC-Bayesian analysis. The latter is further applied to derive generalization guarantees for weighted majority votes. After covering the offline setting, we turn our attention to online learning. We present the space of online learning problems characterized by environmental feedback, environmental resistance, and structural complexity. A common performance measure in online learning is regret, which compares performance of an algorithm to performance of the best prediction rule in hindsight, out of a restricted set of prediction rules. We present tools for deriving regret bounds in stochastic and adversarial environments, and under full information and bandit feedback.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.21547.pdf",
    "abs_url": "https://arxiv.org/abs/2509.21547",
    "published": "2025-09-25T20:33:13Z",
    "updated": "2026-01-29T10:46:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "书籍提供了处理机器学习中不确定性选择问题的统计工具，以实现理论保证。",
      "motivation": "机器学习中的选择过程依赖于数据样本的经验估计，由于随机性导致不确定性，影响预测规则的可靠性。现有方法往往缺乏对这种不确定性的系统性理论控制，因此需要一套工具来量化并提供保证，确保选择的有效性，这在实践中对于避免预测失效至关重要。",
      "method": "书籍提出了一系列统计工具，包括浓度不等式如Hoeffding's和Bernstein's不等式，用于控制经验估计偏差。关键创新在于将这些工具应用于离线监督学习，推导泛化界限，如VC分析和PAC-Bayesian分析，并扩展到在线学习，提供遗憾界限工具，适用于随机和对抗环境，PAC-Bayesian分析还被用于加权多数投票的泛化保证。",
      "result": "摘要未明确说明具体实验结果，但书籍旨在提供理论保证，如泛化界限和遗憾界限，用于评估机器学习算法的性能，未提及与基线方法的对比或具体性能指标，因为重点是理论框架而非实验验证。",
      "conclusion": "本书贡献了全面的统计工具集，用于分析和保证在不确定性下的机器学习选择，深化了理论理解，并为算法设计提供依据。局限性在于未涉及具体实现或实验验证，未来工作可能扩展到更多学习场景或实际应用。",
      "tags": [
        "Concentration Inequalities",
        "Generalization Bounds",
        "PAC-Bayesian Analysis",
        "Online Learning",
        "Regret Bounds"
      ]
    },
    "analyzed_at": "2026-01-30T03:46:51.947198Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.25239",
    "title": "A Formal Comparison Between Chain of Thought and Latent Thought",
    "authors": [
      "Kevin Xu",
      "Issei Sato"
    ],
    "abstract": "Chain of thought (CoT) elicits reasoning in large language models by explicitly generating intermediate tokens. In contrast, latent thought reasoning operates directly in the continuous latent space, enabling computation beyond discrete linguistic representations. While both approaches exploit iterative computation, their comparative capabilities remain underexplored. In this work, we present a formal analysis showing that latent thought admits more efficient parallel computation than inherently sequential CoT. In contrast, CoT enables approximate counting and sampling through stochastic decoding. These separations suggest the tasks for which depth-driven recursion is more suitable, thereby offering practical guidance for choosing between reasoning paradigms.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.25239.pdf",
    "abs_url": "https://arxiv.org/abs/2509.25239",
    "published": "2025-09-25T11:27:52Z",
    "updated": "2026-01-29T11:34:51Z",
    "comment": "Code is available at https://github.com/kevin671/cot-vs-loop",
    "light_analysis": {
      "overview": "本文通过形式分析比较链式思维和潜在思维推理，揭示潜在思维在并行计算上的优势及链式思维在近似计数和采样中的适用性。",
      "motivation": "本研究旨在解决大语言模型推理范式的选择问题。链式思维（CoT）通过显式生成中间令牌激发推理，而潜在思维（LT）直接在连续潜在空间操作，两者均利用迭代计算，但现有研究对它们的比较能力探索不足。这导致难以确定哪种方法更适合特定任务，限制了推理过程的优化。因此，需要进行形式分析来揭示它们的计算特性差异，以指导实际应用中的范式选择。",
      "method": "本研究采用形式分析方法，对比链式思维和潜在思维的计算机制。核心创新点在于分析两者的迭代计算特性：潜在思维允许在连续潜在空间进行高效并行处理，而链式思维因其显式令牌生成而呈现固有顺序性。摘要未明确说明具体数据集或模型架构，但方法侧重于理论分析，探讨了计算效率（如并行性）和功能（如随机解码）的差异，从而为推理范式的选择提供理论基础。",
      "result": "分析结果表明，潜在思维推理在并行计算方面比链式思维更高效，因为它直接操作于连续空间，避免了离散令牌的顺序依赖。相反，链式思维通过随机解码技术能够实现近似计数和采样功能。这些分离特性揭示了各自优势：在需要并行处理的任务中，潜在思维表现出色；而对于涉及概率性推理的场景，链式思维更为适用。与基线方法的对比基于理论分析，未提供具体数据指标，但强调了功能互补性。",
      "conclusion": "本研究的主要贡献在于形式比较链式思维和潜在思维，指出潜在思维更高效并行计算，链式思维支持近似计数和采样。学术上，这深化了对大语言模型推理机制的理解；实践上，为选择推理范式提供实用指导，帮助优化任务性能。局限性包括未涉及具体实现细节，未来工作可扩展至更多任务的实证验证和模型架构的进一步分析。",
      "tags": [
        "Chain of Thought",
        "Latent Thought",
        "Parallel Computing",
        "Stochastic Decoding",
        "Formal Analysis"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:14.378371Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.20912",
    "title": "DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reasoning",
    "authors": [
      "Tianrun Xu",
      "Haoda Jing",
      "Ye Li",
      "Yuquan Wei",
      "Jun Feng",
      "Guanyu Chen",
      "Haichuan Gao",
      "Tianren Zhang",
      "Feng Chen"
    ],
    "abstract": "Recent advances in multimodal language models (MLLMs) have achieved remarkable progress in vision-language reasoning, especially with the emergence of \"thinking with images,\" which integrates explicit visual steps into the reasoning process. While this paradigm strengthens image-based reasoning, a significant challenge remains: models may arrive at correct answers by relying on irrelevant or spurious regions, driven by prior knowledge or dataset biases. Even when the answer is correct, flawed reasoning indicates that the model has not truly understood the image, highlighting the critical importance of reasoning fidelity in multimodal tasks. To address this issue, we propose DeFacto, a counterfactual reasoning framework that jointly enforces accurate answering and faithful reasoning. A key component of our approach is the design of three complementary training paradigms: (i) positive, (ii) counterfactual, and (iii) random-masking. To enable these paradigms, we develop a pipeline that automatically localizes question-relevant evidence and constructs positive, counterfactual, and random variants, resulting in a dataset of about 100k images. Building on this framework, we train multimodal language models with GRPO-based reinforcement learning, where we design three complementary rewards to guide the model toward accurate answering and evidence-grounded reasoning. Experiments on diverse benchmarks demonstrate that DeFacto substantially improves both answer accuracy and reasoning faithfulness, establishing a stronger foundation for interpretable multimodal reasoning. The code is available on GitHub and the dataset is released on HuggingFace.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.20912.pdf",
    "abs_url": "https://arxiv.org/abs/2509.20912",
    "published": "2025-09-25T08:58:10Z",
    "updated": "2026-01-29T12:47:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "DeFacto提出了一种反事实推理框架，通过结合三种训练范式来提高多模态语言模型的推理忠实度。",
      "motivation": "多模态语言模型（MLLMs）在视觉语言推理中虽取得进展，尤其是‘thinking with images’范式增强了图像推理能力，但模型可能依赖无关或虚假视觉区域或先验知识得出正确答案，即使答案正确，推理过程也缺乏忠诚度，表明模型未真正理解图像。这种问题源于数据集偏见或方法缺陷，阻碍了可解释性。现有方法往往忽视推理过程的忠实性，需一种新框架来强制基于证据的推理，以提升模型的可靠性和泛化能力。",
      "method": "DeFacto框架包括三个互补训练范式：正面、反事实和随机掩码。首先，开发一个自动化管道来定位图像中与问题相关的证据区域，并构建正面、反事实和随机掩码版本，形成一个约100k图像的数据集。然后，使用基于GRPO的强化学习训练多模态语言模型，设计三个互补奖励函数来引导模型实现准确回答和证据基础的推理，其中奖励机制鼓励模型避免无关区域依赖。",
      "result": "在多样化的基准测试中，DeFacto显著提高了多模态语言模型的答案准确性和推理忠实度。摘要未明确说明具体数据，但与基线方法相比，该框架在促进可解释推理方面显示出明显优势，为未来研究提供了更强基础。实验证明，通过反事实推理，模型更有效地理解图像内容。",
      "conclusion": "DeFacto通过反事实推理框架，成功提升了多模态语言模型的推理忠诚度和准确性，促进了可解释视觉语言推理的发展。其贡献包括自动数据集构建和强化学习策略，具有学术价值和应用潜力，如提升AI模型的透明度。未来工作可扩展到更多任务，并优化证据定位技术，以应对潜在局限性如计算开销。",
      "tags": [
        "Multimodal Language Models",
        "Counterfactual Reasoning",
        "Reinforcement Learning",
        "GRPO-based RL",
        "Evidence Localization"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:19.230023Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.20896",
    "title": "Deterministic Discrete Denoising",
    "authors": [
      "Hideyuki Suzuki",
      "Wataru Kurebayashi",
      "Hiroshi Yamashita"
    ],
    "abstract": "We propose a deterministic denoising algorithm for discrete-state diffusion models. The key idea is to derandomize the generative reverse Markov chain by introducing a variant of the herding algorithm, which induces deterministic state transitions driven by weakly chaotic dynamics. It serves as a direct replacement for the stochastic denoising process, without requiring retraining or continuous state embeddings. We demonstrate consistent improvements in both efficiency and sample quality on text and image generation tasks. In addition, the proposed algorithm yields improved solutions for diffusion-based combinatorial optimization. Thus, herding-based denoising is a simple yet promising approach for enhancing the generative process of discrete diffusion models. Furthermore, our results reveal that deterministic reverse processes, well established in continuous diffusion, can also be effective in discrete state spaces.",
    "categories": [
      "cs.LG",
      "nlin.CD"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.20896.pdf",
    "abs_url": "https://arxiv.org/abs/2509.20896",
    "published": "2025-09-25T08:30:58Z",
    "updated": "2026-01-29T05:36:28Z",
    "comment": "15 pages, 1 figure",
    "light_analysis": {
      "overview": "本文提出一种基于herding算法的确定性去噪方法，用于提升离散扩散模型的生成效率和样本质量。",
      "motivation": "研究动机是解决离散扩散模型中随机去噪过程可能导致效率低下和样本质量不稳定的问题。现有方法通常依赖随机反向马尔可夫链，这限制了生成过程的可控性和优化潜力；而确定性反向过程在连续扩散中已有成功应用，但在离散状态空间中研究不足，因此探索其有效性具有重要意义，以改进离散生成模型的性能。",
      "method": "研究方法核心是引入herding算法的变体来去随机化生成反向马尔可夫链，实现由弱混沌动力学驱动的确定性状态转换。该算法直接替代了传统的随机去噪过程，无需重新训练模型或使用连续状态嵌入，简化了实现并保持了模型架构不变，适用于文本和图像生成等离散任务。",
      "result": "实验结果表明，在文本和图像生成任务中，该方法在效率和样本质量上实现了一致改进，但与基线随机去噪过程相比，摘要未提供具体性能指标数据。此外，在基于扩散的组合优化问题中，该算法也产生改进的解，验证了其广泛适用性。",
      "conclusion": "论文的主要贡献是提出一种简单而有效的确定性去噪方法，扩展了确定性反向过程到离散状态空间，提升了离散扩散模型的生成性能。其学术价值在于为离散生成模型提供了新思路，实际应用价值包括改进文本、图像生成和组合优化任务。未来工作可探索在其他离散领域的应用和具体性能指标的量化分析。",
      "tags": [
        "Discrete Diffusion Models",
        "Herding Algorithm",
        "Deterministic Denoising",
        "Markov Chains",
        "Combinatorial Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:47:36.322140Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.20294",
    "title": "Alignment-Sensitive Minimax Rates for Spectral Algorithms with Learned Kernels",
    "authors": [
      "Dongming Huang",
      "Zhifan Li",
      "Yicheng Li",
      "Qian Lin"
    ],
    "abstract": "We study spectral algorithms in the setting where kernels are learned from data. We introduce the effective span dimension (ESD), an alignment-sensitive complexity measure that depends jointly on the signal, spectrum, and noise level $σ^2$. The ESD is well-defined for arbitrary kernels and signals without requiring eigen-decay conditions or source conditions. We prove that for sequence models whose ESD is at most $K$, the minimax excess risk scales as $σ^2 K$. Furthermore, we analyze over-parameterized gradient flow and prove that it can reduce the ESD. This finding establishes a connection between adaptive feature learning and provable improvements in generalization of spectral algorithms. We demonstrate the generality of the ESD framework by extending it to linear models and RKHS regression, and we support the theory with numerical experiments. This framework provides a novel perspective on generalization beyond traditional fixed-kernel theories.",
    "categories": [
      "cs.LG",
      "math.ST"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.20294.pdf",
    "abs_url": "https://arxiv.org/abs/2509.20294",
    "published": "2025-09-24T16:28:08Z",
    "updated": "2026-01-29T08:36:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了基于有效跨度维度的框架，用于分析学习核下的谱算法，建立了特征学习与泛化性能改进之间的联系。",
      "motivation": "研究旨在解决核函数从数据中学习时谱算法的泛化分析问题。传统固定核理论通常依赖特征衰减条件或源条件，这在自适应核学习场景下可能不适用，限制了理论的应用范围。现有方法难以全面评估算法在动态核设置下的性能，因此开发一个更通用的框架对于推动机器学习理论发展和实际应用至关重要。",
      "method": "论文引入了有效跨度维度（ESD）作为对齐敏感的复杂性度量，它联合依赖信号、谱和噪声水平σ²，适用于任意核和信号，无需额外条件如特征衰减或源条件。核心方法包括分析序列模型，证明当ESD最多为K时，最小化超额风险与σ²K成正比，并研究过参数化梯度流以减少ESD。此外，扩展ESD框架到线性模型和RKHS回归，通过数值实验支持理论。",
      "result": "理论结果证实，对于有效跨度维度（ESD）最多为K的序列模型，最小化超额风险按σ²K缩放。过参数化梯度流能有效降低ESD，从而改善算法的泛化性能。数值实验支持了这一理论，但摘要未明确说明具体性能指标如准确率提升。相较于传统固定核理论，ESD框架提供了更普适的分析工具，避免了严格条件限制。",
      "conclusion": "论文的主要贡献是提出了有效跨度维度（ESD）框架，为学习核下的谱算法泛化分析提供了新视角，超越了传统固定核理论。它建立了自适应特征学习与理论泛化改进之间的联系，具有重要学术价值，拓展了机器学习理论的基础。未来工作可能包括进一步验证框架的适用性，但摘要未明确说明局限性或具体方向。",
      "tags": [
        "Spectral Algorithms",
        "Learned Kernels",
        "Effective Span Dimension",
        "Minimax Rates",
        "Gradient Flow"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:03.043122Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.18930",
    "title": "Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning",
    "authors": [
      "Alex Schutz",
      "Victor-Alexandru Darvariu",
      "Efimia Panagiotaki",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "abstract": "Neural Algorithmic Reasoning (NAR) is a paradigm that trains neural networks to execute classic algorithms by supervised learning. Despite its successes, important limitations remain: inability to construct valid solutions without post-processing and to reason about multiple correct ones, poor performance on combinatorial NP-hard problems, and inapplicability to problems for which strong algorithms are not yet known. To address these limitations, we reframe the problem of learning algorithm trajectories as a Markov Decision Process, which imposes structure on the solution construction procedure and unlocks the powerful tools of imitation and reinforcement learning (RL). We propose the GNARL framework, encompassing the methodology to translate problem formulations from NAR to RL and a learning architecture suitable for a wide range of graph-based problems. We achieve very high graph accuracy results on several CLRS-30 problems, performance matching or exceeding much narrower NAR approaches for NP-hard problems and, remarkably, applicability even when lacking an expert algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.18930.pdf",
    "abs_url": "https://arxiv.org/abs/2509.18930",
    "published": "2025-09-23T12:49:25Z",
    "updated": "2026-01-29T08:20:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出GNARL框架，通过强化学习重新构架图神经算法推理，以解决现有NAR方法的局限性并提升性能。",
      "motivation": "Neural Algorithmic Reasoning (NAR) 是一种通过监督学习训练神经网络执行经典算法的范式，但在实际应用中存在重要限制：无法无需后处理地构造有效解、无法推理多个正确解、在组合NP-hard问题上表现差，以及对于缺乏强算法的问题不适用。这些局限性限制了NAR在复杂图基和NP-hard问题中的实用价值，需要引入更灵活的方法来解决算法学习和推理的挑战。",
      "method": "论文将算法轨迹学习问题重新定义为马尔可夫决策过程（MDP），为解构造过程提供结构化框架，并启用模仿学习和强化学习（RL）工具。提出GNARL框架，包括从NAR到RL的问题转换方法，以及适用于广泛图基问题的学习架构。摘要未明确说明具体数据集或模型细节，但推断可能涉及图神经网络处理CLRS-30等图结构问题。",
      "result": "在多个CLRS-30问题上，论文取得了很高的图精度结果，性能匹配或超过更窄的NAR方法在NP-hard问题上的表现。此外，即使在缺乏专家算法的情况下，该方法仍然适用。摘要未提供具体准确率数据，但强调了与基线方法相比的显著改进和广泛适用性，展示了强化学习在算法推理中的优势。",
      "conclusion": "论文的主要贡献是提出GNARL框架，通过强化学习重新构架图神经算法推理，有效解决了NAR的局限性。学术上，这扩展了算法学习到RL领域；实际上，提升了解决NP-hard问题的能力，并可以应用于无现有强算法的问题。未来工作可能包括进一步验证框架在更多问题上的性能、优化模型架构或探索其他学习范式。",
      "tags": [
        "Neural Algorithmic Reasoning",
        "Reinforcement Learning",
        "Markov Decision Process",
        "Graph Neural Networks",
        "Imitation Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:48:25.228633Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.18751",
    "title": "MOMEMTO: Patch-based Memory Gate Model in Time Series Foundation Model",
    "authors": [
      "Samuel Yoon",
      "Jongwon Kim",
      "Juyoung Ha",
      "Young Myoung Ko"
    ],
    "abstract": "Recently reconstruction-based deep models have been widely used for time series anomaly detection, but as their capacity and generalization capability increase, these models tend to over-generalize, often reconstructing unseen anomalies accurately. Prior works have attempted to mitigate this by incorporating a memory architecture that stores prototypes of normal patterns. Nevertheless, these approaches suffer from high training costs and have yet to be effectively integrated with time series foundation models (TFMs). To address these challenges, we propose MOMEMTO, an improved variant of TFM for anomaly detection, enhanced with a patch-based memory module to mitigate over-generalization. The memory module is designed to capture representative normal patterns from multiple domains and enables a single model to be jointly fine-tuned across multiple datasets through a multi-domain training strategy. MOMEMTO initializes memory items with latent representations from a pre-trained encoder, organizes them into patch-level units, and updates them via an attention mechanism. We evaluate our method using 23 univariate benchmark datasets. Experimental results demonstrate that MOMEMTO, as a single model, achieves higher scores on AUC and VUS metrics compared to baseline methods, and further enhances the performance of its backbone TFM, particularly in few-shot learning scenarios.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.18751.pdf",
    "abs_url": "https://arxiv.org/abs/2509.18751",
    "published": "2025-09-23T07:48:25Z",
    "updated": "2026-01-29T04:49:56Z",
    "comment": null,
    "light_analysis": {
      "overview": "MOMEMTO是一种改进的时间序列基础模型，通过基于补丁的内存模块减轻过泛化，有效提升异常检测性能。",
      "motivation": "基于重构的深度模型在时间序列异常检测中广泛应用，但随着模型容量增加，倾向于过泛化，准确重构未见的异常，导致检测失效。现有方法尝试引入内存架构存储正常模式原型，但存在高训练成本的问题，且尚未有效集成到时间序列基础模型（TFMs）中，限制了其实际应用和泛化能力。",
      "method": "论文提出MOMEMTO，一个增强的时间序列基础模型变体，集成了基于补丁的内存模块以缓解过泛化。内存模块从多个领域捕捉代表性正常模式，通过多领域训练策略实现单个模型在多个数据集上的联合微调。具体技术包括使用预训练编码器的潜在表示初始化内存项，组织成补丁级单位，并利用注意力机制动态更新内存。在23个单变量基准数据集上进行评估，模型架构基于TFM，专注于提升异常检测的通用性。",
      "result": "实验结果表明，MOMEMTO作为单个模型，在AUC和VUS指标上相比基线方法获得更高分数，显著提升了性能。此外，它进一步增强了其骨干TFM的效果，特别是在少样本学习场景中，显示出更好的泛化能力和检测准确性。摘要未提供具体数据，但强调了与基线方法的对比优势。",
      "conclusion": "本研究的主要贡献是提出MOMEMTO，通过集成基于补丁的内存模块，有效解决了时间序列异常检测中的过泛化问题，实现了内存架构与TFMs的有效结合。该模型提高了检测的准确性和适应性，具有学术价值如促进模型通用性研究，以及实际应用价值如支持多领域异常监控。未来工作可扩展至更复杂的数据类型或应用场景。",
      "tags": [
        "Time Series Anomaly Detection",
        "Memory Module",
        "Patch-based Representation",
        "Attention Mechanism",
        "Time Series Foundation Model"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:37.534500Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.18546",
    "title": "SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models",
    "authors": [
      "Yujia Liu",
      "Dingquan Li",
      "Zhixuan Li",
      "Tiejun Huang"
    ],
    "abstract": "No-Reference Image Quality Assessment (NR-IQA) models play an important role in various real-world applications. Recently, adversarial attacks against NR-IQA models have attracted increasing attention, as they provide valuable insights for revealing model vulnerabilities and guiding robust system design. Some effective attacks have been proposed against NR-IQA models in white-box settings, where the attacker has full access to the target model. However, these attacks often suffer from poor transferability to unknown target models in more realistic black-box scenarios, where the target model is inaccessible. This work makes the first attempt to address the challenge of low transferability in attacking NR-IQA models by proposing a transferable Signed Ensemble Gaussian black-box Attack (SEGA). The main idea is to approximate the gradient of the target model by applying Gaussian smoothing to source models and ensembling their smoothed gradients. To ensure the imperceptibility of adversarial perturbations, SEGA further removes inappropriate perturbations using a specially designed perturbation filter mask. Experimental results on the CLIVE dataset demonstrate the superior transferability of SEGA, validating its effectiveness in enabling successful transfer-based black-box attacks against NR-IQA models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.18546.pdf",
    "abs_url": "https://arxiv.org/abs/2509.18546",
    "published": "2025-09-23T02:10:42Z",
    "updated": "2026-01-29T12:44:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "SEGA 是一种可迁移的有符号集成高斯黑盒攻击方法，首次解决了攻击无参考图像质量评估模型时迁移性低的问题。",
      "motivation": "该研究旨在解决无参考图像质量评估（NR-IQA）模型对抗攻击中黑盒迁移性差的挑战。当前攻击多基于白盒设置，能完全访问目标模型，但在更现实的黑盒场景中，目标模型不可访问，现有攻击迁移性较低，这限制了攻击方法在评估模型鲁棒性和指导系统设计中的应用价值。因此，研究高迁移性黑盒攻击对揭示模型漏洞和提升系统安全性至关重要。",
      "method": "SEGA 的核心方法是通过高斯平滑技术处理源模型的梯度，并集成多个源模型的平滑梯度来近似目标模型的梯度。关键创新点在于使用有符号的梯度方向和专门的扰动滤波掩码，移除不合适的扰动以确保对抗样本在视觉上不易被察觉。该方法结合了梯度近似和扰动优化，提升了黑盒攻击的实用性和有效性。",
      "result": "在 CLIVE 数据集上的实验表明，SEGA 在迁移性方面表现优越，成功实现了基于迁移的黑盒攻击。相比于现有方法，SEGA 显著提高了攻击成功率，验证了其在攻击未知 NR-IQA 模型时的有效性。摘要未明确说明具体数值指标，但强调了其性能的优越性。",
      "conclusion": "SEGA 方法的提出首次有效解决了攻击 NR-IQA 模型时黑盒迁移性低的问题，具有重要的学术价值，为对抗攻击领域提供了新思路。在实际应用中，它可用于揭示模型漏洞，促进更鲁棒的图像质量评估系统设计。未来工作可能包括扩展该方法到其他类型模型或更多数据集，并探索进一步的优化策略。",
      "tags": [
        "Adversarial Attack",
        "Black-Box Attack",
        "Gaussian Smoothing",
        "Ensemble Learning",
        "Perturbation Filter"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:05.688546Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.17816",
    "title": "Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training",
    "authors": [
      "Brown Ebouky",
      "Ajad Chhatkuli",
      "Cristiano Malossi",
      "Christoph Studer",
      "Roy Assaf",
      "Andrea Bartezzaghi"
    ],
    "abstract": "Self-supervised learning (SSL) has emerged as a central paradigm for training foundation models by leveraging large-scale unlabeled datasets, often producing representations with strong generalization capabilities. These models are typically pre-trained on general-purpose datasets such as ImageNet and subsequently adapted to various downstream tasks through finetuning. While prior work has investigated parameter-efficient adaptation methods like adapters, LoRA, and prompt tuning, primarily targeting downstream finetuning, extending the SSL pre-training itself in a continual manner to new domains under limited data remains largely underexplored, especially for downstream dense prediction tasks like semantic segmentation. In this work, we address the challenge of adapting vision foundation models to low-data target domains through continual self-supervised pre-training, specifically targeting downstream semantic segmentation. We propose GLARE (Global Local and Regional Enforcement), a novel continual self-supervised pre-training task designed to enhance downstream semantic segmentation performance. GLARE introduces patch-level augmentations to encourage local consistency and incorporates a regional consistency constraint that leverages spatial semantics in the data. For efficient continual pre-training, we initialize Vision Transformers (ViTs) with weights from existing SSL models and update only lightweight adapter modules specifically UniAdapter - while keeping the rest of the backbone frozen. Experiments across multiple semantic segmentation benchmarks on different domains demonstrate that GLARE consistently improves downstream performance with minimal computational and parameter overhead.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.17816.pdf",
    "abs_url": "https://arxiv.org/abs/2509.17816",
    "published": "2025-09-22T14:11:02Z",
    "updated": "2026-01-29T10:21:21Z",
    "comment": "23 pages, 5 figures",
    "light_analysis": {
      "overview": "本文提出GLARE，一种通过局部和区域一致性约束的持续自监督预训练方法，旨在增强下游语义分割性能。",
      "motivation": "自监督学习（SSL）利用大规模无标签数据训练基础模型，具有强泛化能力。现有研究主要关注下游任务的参数高效微调，如适配器和LoRA，但在低数据目标域下，以持续方式扩展SSL预训练本身仍研究不足，特别是针对语义分割这类密集预测任务。因此，本研究旨在解决如何通过持续自监督预训练，使视觉基础模型适应低数据目标域，提升下游语义分割性能，以弥补现有方法在预训练扩展方面的空白。",
      "method": "本研究提出GLARE（Global Local and Regional Enforcement）方法，这是一种新颖的持续自监督预训练任务，专注于增强语义分割。核心创新包括引入补丁级增强以促进局部一致性，并融入区域一致性约束来利用数据中的空间语义。为高效实现持续预训练，使用现有SSL模型的Vision Transformers（ViTs）权重进行初始化，仅更新轻量级适配器模块，特别是UniAdapter，同时保持骨干网络冻结，以减少计算和参数开销。",
      "result": "实验结果表明，GLARE在多个语义分割基准测试中，针对不同域的数据集，能持续改善下游性能。摘要未提供具体性能指标提升百分比，但明确指出GLARE以最小计算和参数开销实现了性能提升，与基线方法相比，在适应新领域时表现优异，验证了其有效性和效率。",
      "conclusion": "本研究的主要贡献是提出了GLARE方法，通过持续自监督预训练有效提升了语义分割的下游性能。学术价值在于扩展了SSL在持续学习中的应用，为低数据场景下的视觉模型适应提供了新思路；实际应用价值在于为计算机视觉任务提供高效、参数少的解决方案。未来工作可能包括扩展到其他下游任务或优化架构，但摘要未明确说明局限性。",
      "tags": [
        "Self-Supervised Learning",
        "Continual Learning",
        "Semantic Segmentation",
        "Vision Transformers",
        "Adapter Tuning"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:04.625431Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.25214",
    "title": "On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs",
    "authors": [
      "Rongguang Ye",
      "Ming Tang",
      "Edith C. H. Ngai"
    ],
    "abstract": "As increasingly large pre-trained models are released, deploying them on edge devices for privacy-preserving applications requires effective compression. Recent works combine quantization with the fine-tuning of high-precision LoRA adapters, which can substantially reduce model size while mitigating the accuracy loss from quantization. However, edge devices have inherently heterogeneous capabilities, while performing configuration-wise fine-tuning for every quantization setting is computationally prohibitive. In this paper, we propose CoA-LoRA, a method that dynamically adjusts the LoRA adapter to arbitrary quantization configurations (i.e., the per-layer bit-width choices of a pre-trained model) without requiring repeated fine-tuning. This is accomplished via a configuration-aware model that maps each configuration to its low-rank adjustments. The effectiveness of this model critically depends on the training configuration set, a collection of configurations chosen to cover different total bit-width budgets. However, constructing a high-quality configuration set is non-trivial. We therefore design a Pareto-based configuration search that iteratively optimizes the training configuration set, yielding more precise low-rank adjustments. Our experiments demonstrate that, unlike the state-of-the-art methods that require fine-tuning a separate LoRA adapter for each configuration, CoA-LoRA incurs no additional time cost while achieving comparable or even superior performance to those methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.25214.pdf",
    "abs_url": "https://arxiv.org/abs/2509.25214",
    "published": "2025-09-22T11:07:50Z",
    "updated": "2026-01-29T06:12:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出CoA-LoRA方法，通过配置感知模型动态适应任意量化配置，无需重复微调，提高量化大型语言模型在边缘设备上的微调效率。",
      "motivation": "随着大型预训练模型在隐私保护应用中部署于边缘设备的需求增加，有效压缩变得至关重要。量化是常用压缩方法，但会降低模型精度，而现有方法结合量化与高精度LoRA适配器微调虽能缓解精度损失，却需为每个异构设备配置单独微调，计算成本过高，限制了实际应用。因此，研究旨在解决量化模型在异构边缘环境中的高效微调问题。",
      "method": "本研究提出CoA-LoRA方法，通过配置感知模型将任意量化配置（如每层位宽选择）映射到低秩调整，从而动态调整LoRA适配器，避免重复微调。关键创新包括设计训练配置集以覆盖不同总位宽预算，并采用基于Pareto的配置搜索迭代优化该集，提升低秩调整的精确性，使模型能灵活适应多种量化场景。",
      "result": "实验表明，与需要为每个配置单独微调LoRA适配器的现有方法相比，CoA-LoRA在不增加额外时间成本的情况下，实现了可比或更优的性能。摘要未明确提供具体准确率或效率数据，但强调了该方法在效率和适应性上的优势，有效降低了计算负担。",
      "conclusion": "CoA-LoRA的主要贡献是提供了一种高效方法，使量化大型语言模型能灵活适应边缘设备的异构量化配置，无需重复微调，从而降低计算成本并提高部署灵活性。该方法具有实际应用价值，未来工作可能涉及扩展到其他压缩技术或更复杂设备环境，以进一步提升通用性。",
      "tags": [
        "Quantization",
        "LoRA",
        "Fine-Tuning",
        "Configuration-Aware Model",
        "Pareto Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:21.351280Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15271",
    "title": "Large Vision Models Can Solve Mental Rotation Problems",
    "authors": [
      "Sebastian Ray Mason",
      "Anders Gjølbye",
      "Phillip Chavarria Højbjerg",
      "Lenka Tětková",
      "Lars Kai Hansen"
    ],
    "abstract": "Mental rotation is a key test of spatial reasoning in humans and has been central to understanding how perception supports cognition. Despite the success of modern vision transformers, it is still unclear how well these models develop similar abilities. In this work, we present a systematic evaluation of ViT, CLIP, DINOv2, and DINOv3 across a range of mental-rotation tasks, from simple block structures similar to those used by Shepard and Metzler to study human cognition, to more complex block figures, three types of text, and photo-realistic objects. By probing model representations layer by layer, we examine where and how these networks succeed. We find that i) self-supervised ViTs capture geometric structure better than supervised ViTs; ii) intermediate layers perform better than final layers; iii) task difficulty increases with rotation complexity and occlusion, mirroring human reaction times and suggesting similar constraints in embedding space representations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.15271.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15271",
    "published": "2025-09-18T11:18:28Z",
    "updated": "2026-01-29T05:53:48Z",
    "comment": "Accepted at ICASSP 2026",
    "light_analysis": {
      "overview": "本文系统评估了大型视觉模型在心理旋转任务上的表现，发现自监督视觉变换器能更好地捕捉几何结构，中间层表现更优。",
      "motivation": "心理旋转是人类空间推理的关键测试，对于理解感知如何支持认知至关重要。尽管现代视觉变换器在计算机视觉领域取得显著成功，但这些模型是否以及如何发展类似的心理旋转能力尚不明确。现有方法可能缺乏系统性评估，未能充分比较不同模型（如监督与自监督）在复杂认知任务上的表现，这阻碍了对AI模型模拟人类认知能力的深入理解。因此，研究动机在于填补这一空白，通过系统评估揭示模型在心理旋转任务上的能力。",
      "method": "论文采用系统评估方法，使用多个大型视觉模型（包括ViT、CLIP、DINOv2和DINOv3）在一系列心理旋转任务上进行测试。任务范围从简单的Shepard-Metzler块结构（用于研究人类认知）到更复杂的块图、三种文本类型和照片级真实物体，以模拟多样化场景。通过逐层探测模型表示，分析网络在不同层级如何成功处理任务。关键创新点在于对比自监督和监督模型的性能差异，并探究中间层与最终层的表现，技术路线侧重于使用现有模型的预训练表示进行任务评估。",
      "result": "研究得出三个主要发现：首先，自监督视觉变换器在捕捉几何结构方面优于监督视觉变换器，表明自监督学习能更好地学习空间表示；其次，模型的中间层表示比最终层更有效，在处理心理旋转任务时表现出更高准确性；第三，任务难度随旋转复杂度和遮挡增加而上升，这类似于人类反应时间的模式，暗示模型嵌入空间表示存在类似认知约束。这些结果通过定性比较揭示了模型的行为模式，与基线方法（如不同模型类型）的对比突出了自监督方法的优势。",
      "conclusion": "论文的主要贡献是系统评估了大型视觉模型在心理旋转任务上的能力，揭示了自监督方法和中间层在模拟人类空间推理中的关键作用。这项研究具有重要学术价值，促进了认知科学与人工智能的交叉领域研究，为理解AI模型与人类认知相似性提供实证基础。尽管未提及具体局限性，但未来工作可扩展到更多任务类型和模型架构，或探索实际应用中如何处理更复杂认知挑战，以推动理论与实践的融合。",
      "tags": [
        "Vision Transformers",
        "Self-Supervised Learning",
        "Mental Rotation",
        "DINOv2",
        "CLIP"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:28.318597Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.12991",
    "title": "Bridging Performance Gaps for ECG Foundation Models: A Post-Training Strategy",
    "authors": [
      "Ya Zhou",
      "Yujie Yang",
      "Xiaohan Fan",
      "Wei Zhao"
    ],
    "abstract": "ECG foundation models are increasingly popular due to their adaptability across various tasks. However, their clinical applicability is often limited by performance gaps compared to task-specific models, even after pre-training on large ECG datasets and fine-tuning on target data. This limitation is likely due to the lack of an effective post-training strategy. In this paper, we propose a simple yet effective post-training approach to enhance ECG foundation models. We evaluate it on a publicly available Transformer-based foundation model. Experiments across multiple ECG tasks show that our method consistently outperforms baseline fine-tuning. On the PTB-XL benchmarks, it improves macro AUROC by 0.7%-8.9% and macro AUPRC by 23.3%-77.9%, also outperforming several recent state-of-the-art approaches, including task-specific and advanced architectures. Further analyses demonstrate improved training dynamics and data efficiency, with only 30% of the training data outperforming the baseline trained on the full dataset. Ablation studies highlight the importance of stochastic depth and preview linear probing. These findings underscore the potential of post-training strategies to improve ECG foundation models, and we hope this work will contribute to the continued development of foundation models in the ECG domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.12991.pdf",
    "abs_url": "https://arxiv.org/abs/2509.12991",
    "published": "2025-09-16T12:02:13Z",
    "updated": "2026-01-29T12:14:52Z",
    "comment": "A Transformer-based model is used as an example; the proposed post-training strategy may also be applicable to CNN-based models. The manuscript is currently under review",
    "light_analysis": {
      "overview": "提出一种后训练策略，提升心电图基础模型的性能，缩小与任务特定模型的差距。",
      "motivation": "心电图基础模型因其跨任务适应性而日益流行，但在临床应用中常受限于性能不足，即使经过大规模数据集预训练和目标数据微调，仍难以匹敌任务特定模型。这种限制可能源于缺乏有效的后训练优化方法，阻碍了模型在真实医疗场景中的部署。本研究旨在解决这一性能差距，提升模型的临床可用性和诊断准确性。",
      "method": "该方法采用一种简单有效的后训练策略，基于公开的Transformer基础模型进行增强。核心创新包括引入随机深度以改善训练稳定性，并使用预览线性探测来优化微调过程。在实施中，模型在常规微调后应用额外训练步骤，调整参数以提升泛化能力，无需依赖复杂架构改动。具体技术细节包括结合这些优化技术，以弥合性能差距。",
      "result": "实验显示，在多个心电图任务上，该方法持续优于基线微调。在PTB-XL基准测试中，macro AUROC提升0.7%至8.9%，macro AUPRC提升23.3%至77.9%，并超越包括任务特定模型和先进架构在内的多种最新方法。此外，训练动态改善，数据效率显著提高，仅用30%训练数据就达到基线在全数据集上的性能。消融研究证实随机深度和预览线性探测的关键作用。",
      "conclusion": "本研究的主要贡献是提出一种有效的后训练策略，显著提升心电图基础模型性能，缩小与任务特定模型的差距。学术价值在于填补后训练优化空白，推动医疗AI中基础模型的发展；实际应用价值在于增强模型在临床环境中的可靠性和部署潜力。摘要未明确说明局限性，未来工作可能包括扩展方法到其他模型和任务，或进一步优化策略以应对复杂场景。",
      "tags": [
        "ECG Foundation Models",
        "Post-Training Strategy",
        "Transformer",
        "Stochastic Depth",
        "Linear Probing"
      ]
    },
    "analyzed_at": "2026-01-30T03:49:48.381830Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.08150",
    "title": "Verbalized Algorithms",
    "authors": [
      "Supriya Lall",
      "Christian Farrell",
      "Hari Pathanjaly",
      "Marko Pavic",
      "Sarvesh Chezhian",
      "Masataro Asai"
    ],
    "abstract": "Instead of querying LLMs in a one-shot manner and hoping to get the right answer for a reasoning task, we propose a paradigm we call \\emph{verbalized algorithms} (VAs), which combines LLMs with classical algorithms with established theoretical guarantees. VAs decompose a task into simple elementary operations on natural language strings that LLMs are able to answer reliably, and limit the scope of LLMs to those simple tasks. For example, for sorting a series of natural language strings, \\emph{verbalized sorting} uses an LLM as a binary comparison oracle in a known and well-analyzed sorting algorithm (e.g., bitonic sorting network). Although this is already known as \\emph{pairwise ranking} in the literature, we additionally demonstrate the effectiveness of \\emph{verbalized maximum}, \\emph{verbalized clustering}, and \\emph{verbalized submodular maximization} for numerical reasoning, topic clustering and multi-hop Q\\&A RAG task, which guarantees $O(n)$ runtime, $O(n \\log n)$ runtime, and $1/(1-e)$ optimality, respectively. Clustering and submodular maximization outperformed or improved the nearest neighbor search using state-of-the-art embedding models.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.08150.pdf",
    "abs_url": "https://arxiv.org/abs/2509.08150",
    "published": "2025-09-09T21:14:44Z",
    "updated": "2026-01-29T11:19:02Z",
    "comment": "Accepted in NeurIPS 2025 Workshop on Efficient Reasoning",
    "light_analysis": {
      "overview": "本文提出了 verbalized algorithms 范式，通过结合大型语言模型与经典算法，分解复杂任务为简单操作，以提高推理的可靠性和理论保证。",
      "motivation": "研究动机源于传统方法直接查询大型语言模型（LLMs）进行推理任务，依赖一次性输出正确答案，这不可靠且缺乏理论保证。现有方法如 one-shot 查询可能导致错误率高，尤其在复杂任务中，而 VAs 旨在通过分解任务来规避 LLMs 的局限性，结合经典算法的理论保证，解决可靠性问题，提升实际应用中的鲁棒性和可预测性。",
      "method": "研究方法采用 verbalized algorithms（VAs），将任务分解为自然语言字符串的简单基本操作，并限制 LLMs 仅处理这些操作。例如，verbalized sorting 使用 LLM 作为二元比较 oracle，嵌入到经典算法如 bitonic sorting network 中。VAs 还包括 verbalized maximum、clustering 和 submodular maximization，应用于数值推理、主题聚类和多跳 Q&A RAG 任务，关键创新在于结合算法理论保证，确保高效运行。",
      "result": "实验结果显示，verbalized clustering 和 verbalized submodular maximization 在性能上优于或改进了使用最先进嵌入模型的最近邻搜索方法。此外，VAs 提供理论保证：verbalized maximum 保证 O(n) 运行时，verbalized sorting 保证 O(n log n) 运行时，verbalized submodular maximization 保证 1/(1-e) 的最优性，验证了该方法在提高任务效率和可靠性方面的优势。",
      "conclusion": "结论是 verbalized algorithms 提供了一种新范式，通过整合大型语言模型与经典算法，分解任务以增强可靠性和理论保证。研究的学术价值在于为 LLMs 应用提供了结构化方法，减少错误并确保性能；实际应用涵盖数值推理、聚类和问答任务。未来工作可扩展到更多算法领域，以进一步提升泛化能力和处理复杂场景。",
      "tags": [
        "Large Language Model",
        "Classical Algorithms",
        "Sorting Algorithms",
        "Clustering",
        "Submodular Maximization"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:02.141297Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.06904",
    "title": "BIR-Adapter: A parameter-efficient diffusion adapter for blind image restoration",
    "authors": [
      "Cem Eteke",
      "Alexander Griessel",
      "Wolfgang Kellerer",
      "Eckehard Steinbach"
    ],
    "abstract": "We introduce the BIR-Adapter, a parameter-efficient diffusion adapter for blind image restoration. Diffusion-based restoration methods have demonstrated promising performance in addressing this fundamental problem in computer vision, typically relying on auxiliary feature extractors or extensive fine-tuning of pre-trained models. Motivated by the observation that large-scale pretrained diffusion models can retain informative representations under common image degradations, BIR-Adapter introduces a parameter-efficient, plug-and-play attention mechanism that substantially reduces the number of trained parameters. To further improve reliability, we propose a sampling guidance mechanism that mitigates hallucinations during the restoration process. Experiments on synthetic and real-world degradations demonstrate that BIR-Adapter achieves competitive, and in several settings superior, performance compared to state-of-the-art methods while requiring up to 36x fewer trained parameters. Moreover, the adapter-based design enables seamless integration into existing models. We validate this generality by extending a super-resolution-only diffusion model to handle additional unknown degradations, highlighting the adaptability of our approach for broader image restoration tasks.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.06904.pdf",
    "abs_url": "https://arxiv.org/abs/2509.06904",
    "published": "2025-09-08T17:22:18Z",
    "updated": "2026-01-29T09:06:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "BIR-Adapter 是一种参数高效的扩散适配器，用于盲图像恢复，通过即插即用注意力机制和采样指导机制实现高效性能。",
      "motivation": "盲图像恢复是计算机视觉中的基础问题，现有基于扩散的方法通常依赖于辅助特征提取器或对预训练模型进行大量微调，这导致计算成本高且效率低下。动机在于观察到大规模预训练扩散模型在常见图像退化下能保留信息表示，因此需要开发参数高效的方法来减少资源消耗并提高实际应用性，解决现有方法在参数数量和实用性方面的不足。",
      "method": "BIR-Adapter 提出了一种参数高效的即插即用注意力机制，核心是通过适配器设计大幅减少训练参数数量。关键创新点包括引入采样指导机制，用于减轻恢复过程中的幻觉问题。该方法基于预训练扩散模型，无需重新训练整个模型，而是通过轻量级适配器集成，提高了部署灵活性，并适用于各种图像退化场景，如合成和真实世界数据。",
      "result": "在合成和真实世界图像退化的实验中，BIR-Adapter 在多个设置下实现了与最先进方法竞争甚至更优的性能，同时训练参数数量减少了高达 36 倍。这表明该方法在保持高质量恢复效果的同时显著降低了计算资源需求，具体数据基于实验验证，与基线方法对比显示其参数效率和性能优势。",
      "conclusion": "BIR-Adapter 的主要贡献是提供了一种参数高效、性能优异的盲图像恢复方法，适配器设计使其易于无缝集成到现有模型中，并展示了良好的泛化能力，例如将超分辨率模型扩展到处理未知退化。研究具有学术价值，推动了参数高效技术在实际应用中的发展，未来工作可进一步探索更广泛退化场景下的适应性和扩展性。",
      "tags": [
        "Diffusion Models",
        "Attention Mechanism",
        "Blind Image Restoration",
        "Parameter Efficiency",
        "Adapter Design"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:02.306857Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.04154",
    "title": "Robust Filter Attention: Self-Attention as a Parallel State Estimator",
    "authors": [
      "Peter Racioppo"
    ],
    "abstract": "We introduce Robust Filter Attention (RFA), an attention mechanism that reformulates self-attention as parallel robust filtering under a latent stochastic differential equation (SDE) prior, where analytically propagated uncertainty defines a time-dependent precision prior over attention weights. This formulation integrates key advantages of existing positional encodings: it preserves RoPE-style rotational structure while achieving long-context stability through explicit modeling of dissipation and diffusion. By imposing isotropic constraints on the dynamics and noise, RFA matches the $O(N^2 d)$ time and $O(N^2 + Nd)$ memory complexity of standard attention. Empirically, we find that uncertainty-aware weighting induces specialization into distinct filtering regimes across heads, improving temporal consistency and extrapolation across varying context lengths.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.04154.pdf",
    "abs_url": "https://arxiv.org/abs/2509.04154",
    "published": "2025-09-04T12:29:14Z",
    "updated": "2026-01-29T13:32:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了鲁棒滤波注意力（RFA），将自注意力重新定义为基于随机微分方程的并行鲁棒滤波，以整合位置编码优势并改善长上下文稳定性。",
      "motivation": "该研究的动机是改进自注意力机制在长上下文处理中的性能，特别是在时间一致性和外推能力方面。现有位置编码方法如RoPE虽有效，但在处理长序列时面临稳定性不足的问题。RFA旨在通过结合鲁棒滤波理论，解决现有方法的局限性，以更有效地建模序列依赖关系，这对于自然语言处理和时序数据分析等应用具有重要意义。摘要未明确说明具体背景细节，但强调了整合优势以克服挑战。",
      "method": "RFA的核心方法是将自注意力重新表述为在潜在随机微分方程（SDE）先验下的并行鲁棒滤波。通过分析传播的不确定性定义时间依赖的精度先验，从而在注意力权重中引入滤波机制。关键创新点包括保持RoPE风格的旋转结构，并显式建模耗散和扩散以实现长上下文稳定性。此外，通过施加各向同性约束，RFA保持了与标准注意力相同的O(N^2 d)时间复杂度和O(N^2 + Nd)内存复杂度，确保计算效率。",
      "result": "摘要未明确提供具体实验数据，如准确率提升或效率改进的量化指标。但实证结果表明，RFA通过不确定性感知的权重机制，促使注意力头发展出不同的过滤模式，从而提高了时间一致性和跨不同上下文长度的外推能力。这一改进在理论框架上显示出优势，但摘要未详细对比基线方法的性能数据，因此具体效果需进一步实证验证。",
      "conclusion": "论文的主要贡献是提出了鲁棒滤波注意力（RFA），将自注意力机制与鲁棒滤波理论结合，整合了现有位置编码的优势，为长上下文处理提供了新框架。这一研究具有学术价值，为注意力机制提供了新的视角，可能应用于自然语言处理和时序建模等领域。摘要未提及具体局限性或未来工作方向，但可以推断需要更多实证研究和扩展到更广泛的应用场景。",
      "tags": [
        "Self-Attention",
        "Robust Filtering",
        "Stochastic Differential Equation",
        "Positional Encoding",
        "Long Context Stability"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:40.490885Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.03803",
    "title": "Causality-guided Prompt Learning for Vision-language Models via Visual Granulation",
    "authors": [
      "Mengyu Gao",
      "Qiulei Dong"
    ],
    "abstract": "Prompt learning has recently attracted much attention for adapting pre-trained vision-language models (e.g., CLIP) to downstream recognition tasks. However, most of the existing CLIP-based prompt learning methods only show a limited ability for handling fine-grained datasets. To address this issue, we propose a causality-guided text prompt learning method via visual granulation for CLIP, called CaPL, where the explored visual granulation technique could construct sets of visual granules for the text prompt to capture subtle discrepancies among different fine-grained classes through casual inference. The CaPL method contains the following two modules: (1) An attribute disentanglement module is proposed to decompose visual features into non-individualized attributes (shared by some classes) and individualized attributes (specific to single classes) using a Brownian Bridge Diffusion Model; (2) A granule learning module is proposed to construct visual granules by integrating the aforementioned attributes for recognition under two causal inference strategies. Thanks to the learned visual granules, more discriminative text prompt is expected to be learned. Extensive experimental results on 15 datasets demonstrate that our CaPL method significantly outperforms the state-of-the-art prompt learning methods, especially on fine-grained datasets.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.03803.pdf",
    "abs_url": "https://arxiv.org/abs/2509.03803",
    "published": "2025-09-04T01:40:41Z",
    "updated": "2026-01-29T03:10:49Z",
    "comment": "Updated version",
    "light_analysis": {
      "overview": "本论文提出了一种基于因果推理和视觉粒度化的文本 prompt learning 方法（CaPL），显著提升了 CLIP 在细粒度数据集上的性能。",
      "motivation": "Prompt learning 在适配预训练视觉-语言模型（如 CLIP）中备受关注，但现有方法在处理细粒度数据集时表现有限，难以捕捉类间的细微视觉差异。因此，本研究旨在通过因果推理和视觉粒度化技术，解决这一挑战，增强模型对细粒度特征的区分能力，以提升下游识别任务的性能。",
      "method": "CaPL 方法包含属性解缠模块和粒度学习模块。属性解缠模块使用 Brownian Bridge Diffusion Model 将视觉特征分解为非个体化属性（共享于多类）和个体化属性（特定于单类）。粒度学习模块则整合这些属性构建视觉粒度，采用两种因果推理策略进行识别，使文本 prompt 更有效地捕捉细粒度差异。",
      "result": "在 15 个数据集上的实验表明，CaPL 方法显著优于当前最先进的 prompt learning 方法，尤其在细粒度数据集上表现突出，证明了其有效性。摘要未提供具体性能指标数字，但强调了在多种数据集上的优越性能。",
      "conclusion": "本论文的主要贡献是提出 CaPL 方法，通过因果推理和视觉粒度化改进了视觉-语言模型的 prompt learning，提升了细粒度识别能力。这具有学术价值，推动了自适应学习技术的发展，并可能在细粒度视觉任务中应用。摘要未明确说明局限性，但未来工作可扩展至更多任务。",
      "tags": [
        "Prompt Learning",
        "Causal Inference",
        "Visual Granulation",
        "Brownian Bridge Diffusion Model"
      ]
    },
    "analyzed_at": "2026-01-30T03:50:54.120327Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.02970",
    "title": "Delayed Momentum Aggregation: Communication-efficient Byzantine-robust Federated Learning with Partial Participation",
    "authors": [
      "Kaoru Otsuka",
      "Yuki Takezawa",
      "Makoto Yamada"
    ],
    "abstract": "Partial participation is essential for communication-efficient federated learning at scale, yet existing Byzantine-robust methods typically assume full client participation. In the partial participation setting, a majority of the sampled clients may be Byzantine, once Byzantine clients dominate, existing methods break down immediately. We introduce delayed momentum aggregation, a principle where the central server aggregates cached momentum from non-sampled clients along with fresh momentum from sampled clients. This principle ensures Byzantine clients remain a minority from the server's perspective even when they dominate the sampled set. We instantiate this principle in our optimizer DeMoA. We analyze the convergence rate of DeMoA, showing that DeMoA is Byzantine-robust under partial participation. Experiments show that, with 20% Byzantine ratio and only 10% partial participation rate, DeMoA achieves the best accuracy even when existing methods fail empirically.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.02970.pdf",
    "abs_url": "https://arxiv.org/abs/2509.02970",
    "published": "2025-09-03T03:14:58Z",
    "updated": "2026-01-29T15:10:07Z",
    "comment": "Substantial corrections to the proofs, removal of the bounded gradient assumption, and additional experimental results",
    "light_analysis": {
      "overview": "本文提出延迟动量聚合原则，实例化为DeMoA优化器，解决了部分参与联邦学习中的拜占庭鲁棒问题。",
      "motivation": "研究动机在于部分参与联邦学习对大规模通信效率至关重要，但现有拜占庭鲁棒方法通常假设客户端完全参与。在部分参与设置下，采样客户端中多数可能为拜占庭，一旦拜占庭主导采样集，现有方法立即失效，这限制了联邦学习在现实场景的部署。该问题重要性高，因为拜占庭攻击是联邦学习的安全威胁，现有方法无法适应部分参与的动态性，导致鲁棒性不足，亟需新方法以提升系统可靠性和效率。",
      "method": "论文提出延迟动量聚合原则，中央服务器聚合来自未采样客户端的缓存动量与采样客户端的新鲜动量，确保从服务器视角拜占庭客户端始终保持少数，即使它们主导采样集。关键创新点在于通过动量缓存机制扩展了信息利用，减少了拜占庭影响。该原则实例化为DeMoA优化器，并分析了其收敛速率，证明在部分参与下具有拜占庭鲁棒性。摘要未明确说明具体使用的数据集或模型架构细节，但强调了方法在理论上的稳健性。",
      "result": "实验结果表明，在20%拜占庭比率和仅10%部分参与率的极端条件下，DeMoA实现了最佳准确性，而现有方法在实践中完全失败。这验证了DeMoA在部分参与设置下的鲁棒性能，具体效果包括在拜占庭攻击下保持高精度，提升了联邦学习的可靠性和效率。摘要未提供具体准确率数值，但强调了与基线方法的对比优势，突显了方法在实际应用中的有效性。",
      "conclusion": "论文的主要贡献是提出延迟动量聚合原则和DeMoA优化器，解决了部分参与联邦学习中的拜占庭鲁棒挑战。学术价值在于扩展了联邦学习鲁棒性理论，为部分参与场景提供了新解决方案；实际应用价值在于提高了大规模分布式学习的通信效率和安全性。潜在局限性或未来工作方向未在摘要中明确说明，但可能涉及算法进一步优化或应用于更复杂环境。",
      "tags": [
        "Federated Learning",
        "Byzantine-robust",
        "Partial Participation",
        "Momentum Aggregation",
        "Delayed Momentum Aggregation"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:18.440011Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.00190",
    "title": "Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics",
    "authors": [
      "Sheldon Yu",
      "Yuxin Xiong",
      "Junda Wu",
      "Xintong Li",
      "Tong Yu",
      "Xiang Chen",
      "Ritwik Sinha",
      "Jingbo Shang",
      "Julian McAuley"
    ],
    "abstract": "Recent advances in chain-of-thought (CoT) prompting have enabled large language models (LLMs) to perform multi-step reasoning. However, the explainability of such reasoning remains limited, with prior work primarily focusing on local token-level attribution, such that the high-level semantic roles of reasoning steps and their transitions remain underexplored. In this paper, we introduce a state-aware transition framework that abstracts CoT trajectories into structured latent dynamics. Specifically, to capture the evolving semantics of CoT reasoning, each reasoning step is represented via spectral analysis of token-level embeddings and clustered into semantically coherent latent states. To characterize the global structure of reasoning, we model their progression as a Markov chain, yielding a structured and interpretable view of the reasoning process. This abstraction supports a range of analyses, including semantic role identification, temporal pattern visualization, and consistency evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.00190.pdf",
    "abs_url": "https://arxiv.org/abs/2509.00190",
    "published": "2025-08-29T18:53:31Z",
    "updated": "2026-01-29T12:30:57Z",
    "comment": "5 pages, 4 figures",
    "light_analysis": {
      "overview": "本文提出了一个状态感知转换框架，通过抽象链式思考轨迹为结构化潜在动态，以提高推理过程的解释性。",
      "motivation": "近年来，链式思考提示的进展使得大语言模型能够进行多步推理，但其解释性仍然有限。现有研究主要侧重于局部词级归因，导致推理步骤的高层语义角色和它们之间的转换未被充分探索。这一问题的重要性在于，缺乏对推理过程的全局理解限制了模型的可靠性和调试能力，从而影响了其在关键应用中的可部署性。因此，需要一种新方法来抽象和解释推理的动态结构，以提高透明度和信任度。",
      "method": "本文引入了一种状态感知转换框架，用于将链式思考轨迹抽象为结构化潜在动态。具体方法包括：通过光谱分析token级嵌入来捕捉推理步骤的演化语义，并聚类成语义连贯的潜在状态。然后，为了刻画推理的全局结构，将这些状态的进展建模为一个马尔可夫链。这一框架的关键创新点在于将局部推理步骤提升到高层次状态层面，提供结构化和可解释的视图，从而支持语义角色识别、时间模式可视化和一致性评估等分析。",
      "result": "本文的主要实验结果表明，所提出的状态感知转换框架有效提高了链式思考推理的可解释性，支持一系列分析如语义角色识别和时间模式可视化。然而，摘要未明确说明具体的性能指标，如准确率提升或效率改进，也未详细描述与基线方法的对比情况。推断该框架提供了更清晰的推理过程视图，有助于理解和评估模型的推理行为。",
      "conclusion": "本文的主要贡献是提出了一种状态感知转换框架，通过将链式思考轨迹抽象为结构化潜在动态，显著增强了推理过程的可解释性。该研究具有重要的学术价值，提供了新视角来理解大语言模型的推理行为，弥补了现有方法在高层语义探索上的不足。在实际应用中，框架可用于模型调试、可靠性评估和用户信任构建。潜在的局限性可能包括对特定模型或任务的依赖，未来工作可扩展到更广泛的环境或集成更多分析工具。",
      "tags": [
        "Chain-of-Thought",
        "Large Language Model",
        "Markov Chain",
        "Spectral Analysis",
        "Latent State Clustering"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:25.186709Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.21172",
    "title": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks",
    "authors": [
      "Matteo Pinna",
      "Andrea Ceni",
      "Claudio Gallicchio"
    ],
    "abstract": "Echo State Networks (ESNs) are a particular type of untrained Recurrent Neural Networks (RNNs) within the Reservoir Computing (RC) framework, popular for their fast and efficient learning. However, traditional ESNs often struggle with long-term information processing. In this paper, we introduce a novel class of deep untrained RNNs based on temporal residual connections, called Deep Residual Echo State Networks (DeepResESNs). We show that leveraging a hierarchy of untrained residual recurrent layers significantly boosts memory capacity and long-term temporal modeling. For the temporal residual connections, we consider different orthogonal configurations, including randomly generated and fixed-structure configurations, and we study their effect on network dynamics. A thorough mathematical analysis outlines necessary and sufficient conditions to ensure stable dynamics within DeepResESN. Our experiments on a variety of time series tasks showcase the advantages of the proposed approach over traditional shallow and deep RC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.21172.pdf",
    "abs_url": "https://arxiv.org/abs/2508.21172",
    "published": "2025-08-28T19:22:02Z",
    "updated": "2026-01-29T17:16:56Z",
    "comment": "10 pages, 5 figures, 4 tables; minor fixes to tables",
    "light_analysis": {
      "overview": "论文提出了基于时间残差连接的Deep Residual Echo State Networks (DeepResESNs)，显著提升了未训练循环神经网络在长期时间建模中的性能。",
      "motivation": "Echo State Networks (ESNs) 作为Reservoir Computing框架中的未训练循环神经网络，因其快速学习能力而在时间序列分析中应用广泛。然而，传统ESNs在处理长期信息时表现不佳，难以捕获复杂的时间依赖关系，这限制了其在需要长期记忆的任务中的有效性。现有方法如浅层ESNs缺乏深层结构来增强记忆，而深层RNNs通常涉及训练复杂性。因此，本研究旨在通过残差连接改进ESNs，以克服长期信息处理的瓶颈，提升模型的稳定性和效率。",
      "method": "方法的核心是构建Deep Residual Echo State Networks (DeepResESNs)，这是一种基于时间残差连接的深层未训练循环神经网络。通过引入多层残差循环层来增强记忆容量，关键创新包括探索不同正交配置的时间残差连接，如随机生成和固定结构配置，以优化网络动态。研究还进行了详细的数学分析，确定了确保网络稳定性的必要和充分条件，在Reservoir Computing框架中整合残差学习技术，提高长期时间建模的鲁棒性。",
      "result": "论文在多种时间序列任务上进行实验，结果表明DeepResESNs在长期时间建模方面显著优于传统的浅层和深层Reservoir Computing方法。摘要未明确说明具体性能指标如准确率提升，但作者强调该方法在记忆容量和任务性能上有明显优势，验证了残差连接在增强未训练网络长期信息处理能力的有效性。实验结果展示了该方法在处理复杂时间依赖时的优越性。",
      "conclusion": "结论总结，DeepResESNs通过时间残差连接和正交配置成功改进了未训练循环神经网络的长期信息处理能力，具有重要的学术价值，如提供数学稳定性分析，以及实际应用价值，在时间序列任务中表现优异。研究的局限性可能包括正交配置的优化空间，未来工作可探索更多配置变体或将方法扩展到其他领域如信号处理。",
      "tags": [
        "Echo State Networks",
        "Residual Connections",
        "Reservoir Computing",
        "Recurrent Neural Networks",
        "Orthogonal Configurations"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:43.495565Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.19325",
    "title": "PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI",
    "authors": [
      "Haoyang Su",
      "Jin-Yi Xiang",
      "Shaohao Rui",
      "Yifan Gao",
      "Xingyu Chen",
      "Tingxuan Yin",
      "Shaoting Zhang",
      "Xiaosong Wang",
      "Lian-Ming Wu"
    ],
    "abstract": "Accurate prediction of major adverse cardiac events (MACE) remains a central challenge in cardiovascular prognosis. We present PRISM (Prompt-guided Representation Integration for Survival Modeling), a self-supervised framework that integrates visual representations from non-contrast cardiac cine magnetic resonance imaging with structured electronic health records (EHRs) for survival analysis. PRISM extracts temporally synchronized imaging features through motion-aware multi-view distillation and modulates them using medically informed textual prompts to enable fine-grained risk prediction. Across four independent clinical cohorts, PRISM consistently surpasses classical survival prediction models and state-of-the-art (SOTA) deep learning baselines under internal and external validation. Further clinical findings demonstrate that the combined imaging and EHR representations derived from PRISM provide valuable insights into cardiac risk across diverse cohorts. Three distinct imaging signatures associated with elevated MACE risk are uncovered, including lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior elevated focus during diastole. Prompt-guided attribution further identifies hypertension, diabetes, and smoking as dominant contributors among clinical and physiological EHR factors.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2508.19325.pdf",
    "abs_url": "https://arxiv.org/abs/2508.19325",
    "published": "2025-08-26T17:23:43Z",
    "updated": "2026-01-29T18:11:17Z",
    "comment": null,
    "light_analysis": {
      "overview": "PRISM框架通过自监督方式整合心脏电影MRI的视觉表示和电子健康记录，利用文本提示实现可解释的主要不良心脏事件生存预测。",
      "motivation": "准确预测主要不良心脏事件（MACE）是心血管预后的核心挑战，现有方法如经典生存模型和深度学习基线在多模态数据集成和可解释性方面存在不足。PRISM旨在解决这一问题，通过结合无监督视觉特征和结构化电子健康记录，提升预测性能并提供临床洞察，以应对心血管健康管理中的关键需求。",
      "method": "PRISM采用自监督框架，从非对比心脏电影MRI中通过运动感知多视图蒸馏提取时间同步成像特征，并与结构化电子健康记录结合。关键创新在于使用医学信息文本提示调制这些特征，实现细粒度风险预测，无需大量标注数据。该方法在四个独立临床队列上进行验证，但具体模型架构细节摘要未明确说明。",
      "result": "在四个独立临床队列的内部和外部验证中，PRISM持续超越经典生存预测模型和SOTA深度学习基线，具体性能指标摘要未明确说明。此外，框架揭示了与MACE风险相关的三个成像特征：侧壁失同步、下壁超敏性和舒张期前壁升高焦点，并通过提示引导归因识别高血压、糖尿病和吸烟为主要临床贡献者。",
      "conclusion": "PRISM通过多模态数据集成和自监督学习，显著提升了MACE生存预测的准确性和可解释性，为心血管风险评估提供了有效工具。其学术价值在于提出了结合视觉表示和文本提示的新方法，实际应用有助于识别关键风险因素，未来工作可扩展至更大数据集或其他疾病领域。",
      "tags": [
        "Self-Supervised Learning",
        "Survival Analysis",
        "Multi-Modal Integration",
        "Textual Prompts",
        "Medical Imaging"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:53.004151Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.10703",
    "title": "GenOM: Ontology Matching with Description Generation and Large Language Model",
    "authors": [
      "Yiping Song",
      "Jiaoyan Chen",
      "Renate A. Schmidt"
    ],
    "abstract": "Ontology matching (OM) plays an essential role in enabling semantic interoperability and integration across heterogeneous knowledge sources, particularly in the biomedical domain which contains numerous complex concepts related to diseases and pharmaceuticals. This paper introduces GenOM, a large language model (LLM)-based ontology alignment framework, which enriches the semantic representations of ontology concepts via generating textual definitions, retrieves alignment candidates with an embedding model, and incorporates exact matching-based tools to improve precision. Extensive experiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often achieve competitive performance, surpassing many baselines including traditional OM systems and recent LLM-based methods. Further ablation studies confirm the effectiveness of semantic enrichment and few-shot prompting, highlighting the framework's robustness and adaptability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2508.10703.pdf",
    "abs_url": "https://arxiv.org/abs/2508.10703",
    "published": "2025-08-14T14:48:09Z",
    "updated": "2026-01-29T16:00:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "GenOM是一个基于大型语言模型的本体对齐框架，通过生成文本定义和结合嵌入模型提升匹配精度。",
      "motivation": "本体匹配在异构知识源的语义互操作性和集成中至关重要，特别是在生物医学领域，其中涉及大量复杂概念如疾病和药物。现有方法在处理这些复杂概念时可能存在语义表示不足和精度不高的挑战，因此需要更有效的技术来增强语义理解和匹配准确性。本研究旨在解决这一实际问题，通过引入大型语言模型以改进本体对齐的性能和鲁棒性。",
      "method": "GenOM框架采用大型语言模型生成本体概念的文本定义以丰富语义表示，利用嵌入模型检索潜在的对齐候选，并结合基于精确匹配的工具来提高精度。关键创新点包括语义丰富策略、少样本提示技术，以及多模块集成以增强整体性能。该方法在OAEI Bio-ML track数据集上进行评估，展示出在复杂本体场景下的技术特色。",
      "result": "在OAEI Bio-ML track上的实验表明，GenOM在性能上具有竞争力，超越了包括传统本体匹配系统和近期基于大型语言模型的基准方法。消融研究进一步确认了语义丰富和少样本提示的有效性，提升了匹配精度和框架的适应性。虽然摘要未提供具体数值指标，但结果突出了该方法的优越性和鲁棒性。",
      "conclusion": "本文的主要贡献是提出了GenOM框架，有效结合了大型语言模型、语义丰富和精确匹配工具，提升了本体对齐的精度和效率。该研究具有重要的学术价值，为生物医学领域的知识集成提供了新方法，并展示出实际应用潜力。未来工作方向摘要未明确说明，但可能涉及扩展到更广泛领域或优化模型架构。",
      "tags": [
        "Ontology Matching",
        "Large Language Model",
        "Description Generation",
        "Embedding Model",
        "Few-shot Prompting"
      ]
    },
    "analyzed_at": "2026-01-30T03:51:58.284485Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.09925",
    "title": "Residual Reservoir Memory Networks",
    "authors": [
      "Matteo Pinna",
      "Andrea Ceni",
      "Claudio Gallicchio"
    ],
    "abstract": "We introduce a novel class of untrained Recurrent Neural Networks (RNNs) within the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory Networks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear reservoir, where the latter is based on residual orthogonal connections along the temporal dimension for enhanced long-term propagation of the input. The resulting reservoir state dynamics are studied through the lens of linear stability analysis, and we investigate diverse configurations for the temporal residual connections. The proposed approach is empirically assessed on time-series and pixel-level 1-D classification tasks. Our experimental results highlight the advantages of the proposed approach over other conventional RC models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.09925.pdf",
    "abs_url": "https://arxiv.org/abs/2508.09925",
    "published": "2025-08-13T16:21:29Z",
    "updated": "2026-01-29T16:33:04Z",
    "comment": "7 pages, 6 figures, accepted at IJCNN 2025; added IEEE copyright",
    "light_analysis": {
      "overview": "本研究提出残差储层记忆网络（ResRMNs），通过结合线性和非线性储层并使用残差正交连接，增强时间维度上的长期传播能力。",
      "motivation": "该研究旨在解决储层计算（RC）模型中长期记忆传播不足的问题，尤其在处理时间序列数据时，传统RC模型可能难以有效捕捉长期依赖，限制了模型性能。长期记忆对时序分析至关重要，现有方法的不足在于缺乏高效的时间维度处理机制，因此需要创新方法来提升模型的表示能力和适应性。",
      "method": "论文提出了残差储层记忆网络（ResRMNs），这是一种未经训练的递归神经网络，在储层计算框架下结合线性记忆储层和非线性储层。核心创新点是非线性储层采用残差正交连接在时间维度上，以增强输入的长期传播。方法通过线性稳定性分析研究储层状态动态，并探讨了多种时间残差连接配置。实验评估涉及时间序列和像素级1-D分类任务，但摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "实验在时间序列和像素级1-D分类任务上进行，结果表明提出的ResRMNs方法优于其他传统储层计算模型，显示出性能优势。然而，摘要未明确说明具体的性能指标，如准确率提升或效率改进数值，仅指出该方法相比传统模型有所改进，缺乏详细的数据支撑和对比分析。",
      "conclusion": "该研究的主要贡献是提出了残差储层记忆网络，通过残差正交连接改进长期记忆传播，扩展了储层计算的理论基础。学术价值在于通过线性稳定性分析深化了对储层动态的理解；实际应用价值在于在时间序列分析等领域的潜力。未来工作可能包括优化连接配置或扩展到更复杂任务，但摘要未明确说明潜在局限性。",
      "tags": [
        "Reservoir Computing",
        "Recurrent Neural Networks",
        "Residual Connections",
        "Orthogonal Connections",
        "Time-Series Classification"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:23.828477Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.06625",
    "title": "CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation",
    "authors": [
      "Shilong Zou",
      "Yuhang Huang",
      "Renjiao Yi",
      "Chenyang Zhu",
      "Kai Xu"
    ],
    "abstract": "We introduce a diffusion-based cross-domain image translator in the absence of paired training data. Unlike GAN-based methods, our approach integrates diffusion models to learn the image translation process, allowing for more coverable modeling of the data distribution and performance improvement of the cross-domain translation. However, incorporating the translation process within the diffusion process is still challenging since the two processes are not aligned exactly, i.e., the diffusion process is applied to the noisy signal while the translation process is conducted on the clean signal. As a result, recent diffusion-based studies employ separate training or shallow integration to learn the two processes, yet this may cause the local minimal of the translation optimization, constraining the effectiveness of diffusion models. To address the problem, we propose a novel joint learning framework that aligns the diffusion and the translation process, thereby improving the global optimality. Specifically, we propose to extract the image components with diffusion models to represent the clean signal and employ the translation process with the image components, enabling an end-to-end joint learning manner. On the other hand, we introduce a time-dependent translation network to learn the complex translation mapping, resulting in effective translation learning and significant performance improvement. Benefiting from the design of joint learning, our method enables global optimization of both processes, enhancing the optimality and achieving improved fidelity and structural consistency. We have conducted extensive experiments on RGB$\\leftrightarrow$RGB and diverse cross-modality translation tasks including RGB$\\leftrightarrow$Edge, RGB$\\leftrightarrow$Semantics and RGB$\\leftrightarrow$Depth, showcasing better generative performances than the state of the arts.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2508.06625.pdf",
    "abs_url": "https://arxiv.org/abs/2508.06625",
    "published": "2025-08-08T18:13:56Z",
    "updated": "2026-01-29T09:42:53Z",
    "comment": "Accepted by IEEE TIP 2026",
    "light_analysis": {
      "overview": "提出CycleDiff，一种基于扩散模型的联合学习框架，用于无配对图像翻译，通过对齐扩散和翻译过程实现全局优化，提升翻译性能。",
      "motivation": "本研究旨在解决无配对数据下的跨域图像翻译问题。现有基于GAN的方法在数据分布建模方面有局限，而扩散模型虽能改善分布建模，但扩散过程（应用于噪声信号）与翻译过程（应用于干净信号）不对齐，导致现有扩散方法采用单独训练或浅层集成，可能陷于局部最优，限制翻译效果。因此，需要一种能对齐两个过程、提高全局最优性的新方法以提升翻译质量。",
      "method": "方法提出一种联合学习框架，使用扩散模型提取图像组件来表示干净信号，并将翻译过程应用于这些组件，实现端到端学习。同时，引入时间依赖的翻译网络来学习复杂的翻译映射。关键创新在于将扩散和翻译过程对齐，促进全局优化，避免局部最小值问题。技术路线包括基于扩散模型的特征提取和结合时间依赖网络的翻译学习，无需配对训练数据。",
      "result": "实验在多种任务上进行，包括RGB到RGB转换和跨模态翻译（如RGB与边缘、语义、深度之间的转换）。结果表明，该方法在生成性能上优于现有技术，展示更高的保真度和结构一致性。尽管具体量化指标如准确率未在摘要中提供，但与基线方法的对比显示显著性能改进，验证了联合学习框架的有效性。",
      "conclusion": "本研究的主要贡献是提出CycleDiff框架，通过联合学习对齐扩散和翻译过程，实现全局优化，提高无配对图像翻译的保真度和结构一致性。学术上，为扩散模型在翻译任务中的应用提供了新思路；实践中，适用于多种跨域场景。未来工作方向如扩展到更多任务或优化网络架构，摘要未明确说明。",
      "tags": [
        "Diffusion Models",
        "Unpaired Image Translation",
        "Joint Learning",
        "Cross-domain Translation",
        "Time-dependent Networks"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:34.797186Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.01764",
    "title": "A Trainable Optimizer",
    "authors": [
      "Ruiqi Wang",
      "Diego Klabjan"
    ],
    "abstract": "The concept of learning to optimize involves utilizing a trainable optimization strategy rather than relying on manually defined full gradient estimations such as ADAM. We present a framework that jointly trains the full gradient estimator and the trainable weights of the model. Specifically, we prove that pseudo-linear TO (Trainable Optimizer), a linear approximation of the full gradient, matches SGD's convergence rate while effectively reducing variance. Pseudo-linear TO incurs negligible computational overhead, requiring only minimal additional tensor multiplications. To further improve computational efficiency, we introduce two simplified variants of Pseudo-linear TO. Experiments demonstrate that TO methods converge faster than benchmark algorithms (e.g., ADAM) in both strongly convex and non-convex settings, and fine tuning of an LLM.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.01764.pdf",
    "abs_url": "https://arxiv.org/abs/2508.01764",
    "published": "2025-08-03T14:06:07Z",
    "updated": "2026-01-29T10:58:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一个可训练优化器框架，通过联合训练梯度估计器和模型权重，实现更快收敛和减少方差。",
      "motivation": "在机器学习中，优化算法对模型训练效率至关重要，但现有方法如ADAM依赖手动定义的梯度估计，可能导致性能受限，特别是在复杂优化问题中。本研究旨在解决如何设计更高效的优化策略，以减少对人工设计的依赖，并提升在不同设置（如强凸和非凸）下的训练效果。问题的重要性在于优化直接影响模型收敛速度和最终性能，现有方法在方差和计算效率方面有待改进，从而推动可训练优化器的发展。",
      "method": "论文提出一个框架，联合训练模型的完整梯度估计器和可训练权重，核心创新是伪线性TO，即完整梯度的线性近似。该方法证明能匹配SGD的收敛速度，并有效减少方差，关键特色包括低计算开销，仅需最小额外张量乘法。为了进一步提高效率，作者引入了伪线性TO的两个简化变体。实验中，方法应用于强凸和非凸优化设置，并使用基准算法如SGD和ADAM进行对比，涉及大型语言模型微调，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验表明，可训练优化器（TO）方法在强凸和非凸优化设置下比基准算法（如ADAM）收敛更快。伪线性TO不仅匹配SGD的收敛率，还显著减少方差，同时计算开销可忽略不计。性能提升通过对比实验验证，例如在收敛速度上优于传统方法，并在大型语言模型微调中展示应用潜力。具体数据如准确率或效率改进未在摘要中详细说明，但强调了方法的整体有效性。",
      "conclusion": "本研究的主要贡献是提出并验证了可训练优化器框架，证明其在优化算法中的收敛性和计算效率优势。学术价值在于为机器学习优化提供新方法，减少对人工设计的依赖；实际应用价值体现在加速模型训练，尤其在资源受限场景和大型语言模型微调中。局限性或未来工作方向摘要未明确说明，但可推断可能包括进一步优化变体或扩展至更多应用领域。",
      "tags": [
        "Trainable Optimizer",
        "Gradient Estimation",
        "Pseudo-linear Approximation",
        "Large Language Model Fine-tuning",
        "Optimization Algorithms"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:49.620515Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.17417",
    "title": "A Comprehensive Evaluation on Quantization Techniques for Large Language Models",
    "authors": [
      "Yutong Liu",
      "Cairong Zhao",
      "Guosheng Hu"
    ],
    "abstract": "For large language models (LLMs), post-training quantization (PTQ) can significantly reduce memory footprint and computational overhead. Model quantization is rapidly evolving. Though many papers report breakthrough results, they are often evaluated under different settings because a method typically contains multiple components. Analyzing connections among existing methods is important for deeper understanding. To bridge these gaps, we conduct an extensive review of state-of-the-art methods and perform comprehensive evaluations under the same conditions for fair comparison. To our knowledge, such a fair and extensive investigation remains critically underexplored. To better understand connections, first, we decouple published quantization methods into two steps: pre-quantization transformation and quantization error mitigation. The former is a preprocessing step that reduces outlier impact by flattening the data distribution; the latter offsets quantization errors to improve performance. Second, we evaluate and analyze the impact of different settings, including granularity and symmetry. Third, we analyze and evaluate the latest MXFP4 and NVFP4 data formats and their performance. Our experiments first demonstrate that optimized rotation and scaling yield the best pre-quantization performance, and that combining low-rank compensation with GPTQ can occasionally outperform GPTQ alone for error mitigation. Second, finer granularity improves performance but increases storage overhead. Third, we find that scaling-factor format and precision greatly affect FP4 performance, and that rotation-based strategies effective for INT4 offer limited gains for MXFP4 and NVFP4, motivating further study.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.17417.pdf",
    "abs_url": "https://arxiv.org/abs/2507.17417",
    "published": "2025-07-23T11:21:21Z",
    "updated": "2026-01-29T11:28:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过解耦量化方法并在统一设置下进行全面评估，为大型语言模型量化技术提供了公平比较的基准框架。",
      "motivation": "量化技术能显著减少大型语言模型的内存占用和计算开销，但现有研究在不同设置下评估，导致结果难以公平比较，阻碍了方法间的深入分析和优化。为了解决这一问题，本文旨在通过统一评估标准，填补量化方法评估不一致的空白，促进对现有技术联系的理解和未来改进。",
      "method": "论文将量化方法分解为两个步骤：预量化转换通过旋转和缩放优化减少离群值影响，作为预处理；量化误差缓解结合低秩补偿和GPTQ等技术以提升性能。在相同条件下，评估了粒度、对称性等关键设置，并测试了最新的MXFP4和NVFP4数据格式，确保全面和公平的比较。",
      "result": "实验显示，优化的旋转和缩放带来最佳预量化性能；低秩补偿与GPTQ结合有时优于单独GPTQ，提高了误差缓解效果。更细粒度提升了性能但增加了存储开销；FP4格式的性能受缩放因子格式和精度影响显著，而旋转策略对INT4有效，对MXFP4和NVFP4增益有限，表明需要进一步研究。",
      "conclusion": "本研究通过公平评估量化方法，揭示了不同组件和设置对性能的影响，为LLMs量化提供了重要指导，具有学术和实际应用价值。未来工作应针对FP4格式开发更有效的优化策略，以克服现有限制并推动量化技术的进步。",
      "tags": [
        "Large Language Model",
        "Post-Training Quantization",
        "GPTQ",
        "FP4",
        "Quantization Techniques"
      ]
    },
    "analyzed_at": "2026-01-30T03:52:59.855945Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.15132",
    "title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm",
    "authors": [
      "Joanna Komorniczak"
    ],
    "abstract": "The research community continues to seek increasingly more advanced synthetic data generators to reliably evaluate the strengths and limitations of machine learning methods. This work aims to increase the availability of datasets encompassing a diverse range of problem complexities by proposing a genetic algorithm that optimizes a set of problem complexity measures for classification and regression tasks towards specific targets. For classification, a set of 10 complexity measures was used, while for regression tasks, 4 measures demonstrating promising optimization capabilities were selected. Experiments confirmed that the proposed genetic algorithm can generate datasets with varying levels of difficulty by transforming synthetically created datasets to achieve target complexity values through linear feature projections. Evaluations involving state-of-the-art classifiers and regressors revealed a correlation between the complexity of the generated data and the recognition quality.",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.15132.pdf",
    "abs_url": "https://arxiv.org/abs/2507.15132",
    "published": "2025-07-20T21:42:30Z",
    "updated": "2026-01-29T15:21:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种基于线性特征投影的多目标遗传算法，用于生成具有目标复杂度的数据集，以评估机器学习方法的性能。",
      "motivation": "研究社区需要更先进的合成数据生成器来可靠评估机器学习方法的优势和局限性。现有方法在生成涵盖广泛问题复杂度的数据集方面不足，无法精确控制复杂度以匹配评估需求。因此，这项工作旨在通过提出新算法，增加多样化复杂度数据集的可用性，从而更好地支持机器学习方法的评估和比较。",
      "method": "论文提出了一种遗传算法，通过优化分类和回归任务中的一组问题复杂度度量来生成数据集。对于分类任务，使用了10个复杂度度量；对于回归任务，选择了4个具有良好优化潜力的度量。核心创新在于采用线性特征投影将合成的数据集转换为达到目标复杂度值，实现对数据集难度的精确控制，从而模拟不同复杂度的数据场景。",
      "result": "实验证实，所提出的遗传算法能够通过线性特征投影生成具有不同难度级别的数据集。评估中使用最先进的分类器和回归器，结果显示生成数据的复杂度与识别质量之间存在相关性，表明算法能有效模拟真实数据复杂性，为机器学习方法评估提供可靠基准。摘要未明确说明具体性能提升数据。",
      "conclusion": "该研究的主要贡献是提出了一种基于投影的多目标遗传算法，能够生成具有指定复杂度的数据集，增强了合成数据生成的能力。这有助于机器学习社区更全面地评估方法性能，揭示算法在不同复杂度下的表现。未来工作可能包括扩展复杂度度量集、优化算法效率或应用于其他机器学习任务。",
      "tags": [
        "Genetic Algorithm",
        "Many-Objective Optimization",
        "Complexity Measures",
        "Linear Feature Projection",
        "Synthetic Data Generation"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:23.553321Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.14516",
    "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning",
    "authors": [
      "Jeyoung Lee",
      "Hochul Kang"
    ],
    "abstract": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware metric function for time series self-supervised representation learning. Most Self-Supervised Learning (SSL) methods for signals commonly adopt distance-based objectives such as mean squared error (MSE), which are sensitive to amplitude, invariant to waveform polarity, and unbounded in scale. These properties hinder semantic alignment and reduce interpretability. SDSC addresses this by quantifying structural agreement between temporal signals based on the intersection of signed amplitudes, derived from the Dice Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware metric, it can be used as a loss by subtracting from 1 and applying a differentiable approximation of the Heaviside function for gradient-based optimization. A hybrid loss formulation is also proposed to combine SDSC with MSE, improving stability and preserving amplitude where necessary. Experiments on forecasting and classification benchmarks demonstrate that SDSC-based pre-training achieves comparable or improved performance over MSE, particularly in in-domain and low-resource scenarios. The results suggest that structural fidelity in signal representations enhances the semantic representation quality, supporting the consideration of structure-aware metrics as viable alternatives to conventional distance-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.14516.pdf",
    "abs_url": "https://arxiv.org/abs/2507.14516",
    "published": "2025-07-19T07:32:00Z",
    "updated": "2026-01-29T06:31:50Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了SDSC，一种基于Dice相似系数的结构感知度量，用于改善时间序列自监督表示学习的语义对齐和可解释性。",
      "motivation": "该研究旨在解决时间序列自监督学习中语义对齐不足的问题。当前常用基于距离的损失函数（如MSE）存在对幅度敏感、忽略波形结构、尺度无界等局限性，导致信号表示难以捕捉语义信息，降低了下游任务如预测和分类的性能。这些问题在需要高语义保真度的应用中尤为重要，因此有必要开发一种能衡量信号结构一致性的度量。",
      "method": "论文的核心方法是提出SDSC（Signal Dice Similarity Coefficient），基于Dice相似系数来量化时域信号的结构一致性。SDSC通过计算信号的签名幅度交集来评估结构相似性，并通过从1减去并应用可微分的Heaviside函数近似，转化为适用于梯度优化的损失函数。此外，研究还引入了一种混合损失公式，结合SDSC与MSE，以提高训练稳定性并在必要时保留幅度信息。关键创新在于设计了一种既度量结构又支持优化的损失函数。",
      "result": "实验结果表明，基于SDSC的预训练在多个预测和分类基准上实现了与MSE相当或更好的性能。特别是在领域内和低资源场景下，SDSC表现更优，这得益于其增强信号表示结构保真度的能力。与基线MSE相比，SDSC在语义对齐方面展现出优势，但摘要未明确给出具体数值。这表明结构感知度量能有效提升自监督学习的效果。",
      "conclusion": "论文的主要贡献是提出了SDSC作为结构感知度量，证明了其在信号表示学习中提高语义质量的价值。该研究为自监督学习提供了新思路，支持结构感知损失函数作为传统距离方法的可行替代。应用价值包括改进时间序列任务的表示学习。潜在局限性可能在于计算复杂度或对其他信号类型的适应性，未来工作可探索扩展混合损失或应用于更广泛的领域。",
      "tags": [
        "Self-Supervised Learning",
        "Time Series Analysis",
        "Dice Similarity Coefficient",
        "Metric Learning",
        "Representation Learning"
      ]
    },
    "analyzed_at": "2026-01-30T03:53:32.028522Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.08182",
    "title": "CTRLS: Chain-of-Thought Reasoning via Latent State-Transition",
    "authors": [
      "Junda Wu",
      "Yuxin Xiong",
      "Xintong Li",
      "Sheldon Yu",
      "Zhengmian Hu",
      "Tong Yu",
      "Rui Wang",
      "Xiang Chen",
      "Jingbo Shang",
      "Julian McAuley"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning enables large language models (LLMs) to break down complex problems into interpretable intermediate steps, significantly enhancing model transparency and performance in reasoning tasks. However, conventional CoT methods rely on heuristic sampling without structured modeling of reasoning transitions, constraining their ability to systematically explore and discover diverse and effective reasoning trajectories. In this work, we introduce CTRLS, a framework that formulates CoT reasoning as a Markov decision process (MDP) with latent state transitions, enabling principled and state-aware exploration via distributional reinforcement learning. By modelling reasoning actions as explicit probability distributions in latent space, our approach explicitly models epistemic uncertainty, facilitating robust exploration of the reasoning space. As part of our framework, we introduce an on-policy reinforcement learning strategy incorporating epsilon-greedy exploration and entropy-based regularization to iteratively refine latent state transitions without requiring additional fine-tuning of the underlying LLM. Theoretical analyses provide evidence lower bounds (ELBO), theoretically grounding our transition-aware modeling of latent reasoning dynamics. Further experiments demonstrate improvements in reasoning accuracy, diversity, and exploration efficiency across benchmark reasoning tasks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.08182.pdf",
    "abs_url": "https://arxiv.org/abs/2507.08182",
    "published": "2025-07-10T21:32:18Z",
    "updated": "2026-01-29T12:31:14Z",
    "comment": "10 pages",
    "light_analysis": {
      "overview": "CTRLS框架通过将思维链推理建模为马尔可夫决策过程并利用隐状态转移和分布强化学习，实现了原理性的推理探索，提升了大型语言模型的推理能力。",
      "motivation": "传统思维链推理方法依赖启发式采样，缺乏对推理转换的结构化建模，这限制了系统性地探索和发现多样有效的推理轨迹。这一问题的重要性在于，现有方法无法充分应对复杂推理任务中的不确定性和动态变化，导致推理性能瓶颈。CTRLS框架旨在通过结构化的方法弥补这一不足，增强推理的透明性和鲁棒性。",
      "method": "CTRLS将思维链推理构建为马尔可夫决策过程，其中推理转换通过隐状态转移建模，并使用分布强化学习来显式化认知不确定性。具体技术包括基于epsilon-greedy的探索策略和熵正则化，以迭代优化隐状态转换，无需对基础大型语言模型进行额外微调。理论分析提供了证据下界，支持隐推理动态的转换感知建模，增强了方法的理论基础。",
      "result": "实验结果表明，CTRLS在基准推理任务上提升了推理准确性、多样性和探索效率。摘要未明确提供具体性能指标数据，但与基线方法相比显示出改进，例如在推理任务中的整体性能提升，强调了其在处理复杂推理时的实际应用潜力。",
      "conclusion": "CTRLS框架的主要贡献在于通过隐状态转移和强化学习增强了思维链推理，提供了学术上的理论支持（如证据下界）和实际应用中的性能提升。研究意义在于为推理任务引入了更系统的方法，潜在局限性可能包括计算复杂度，未来工作可优化探索策略或扩展到更广泛的任务领域。",
      "tags": [
        "Chain-of-Thought Reasoning",
        "Markov Decision Process",
        "Latent State Transitions",
        "Distributional Reinforcement Learning",
        "Evidence Lower Bound"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:55.441262Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.07487",
    "title": "Online Navigation Refinement: Achieving Lane-Level Guidance by Associating Standard-Definition and Online Perception Maps",
    "authors": [
      "Jiaxu Wan",
      "Xu Wang",
      "Mengwei Xie",
      "Xinyuan Chang",
      "Xinran Liu",
      "Zheng Pan",
      "Mu Xu",
      "Hong Zhang",
      "Ding Yuan",
      "Yifan Yang"
    ],
    "abstract": "Lane-level navigation is critical for geographic information systems and navigation-based tasks, offering finer-grained guidance than road-level navigation by standard definition (SD) maps. However, it currently relies on expansive global HD maps that cannot adapt to dynamic road conditions. Recently, online perception (OP) maps have become research hotspots, providing real-time geometry as an alternative, but lack the global topology needed for navigation. To address these issues, Online Navigation Refinement (ONR), a new mission is introduced that refines SD-map-based road-level routes into accurate lane-level navigation by associating SD maps with OP maps. The map-to-map association to handle many-to-one lane-to-road mappings under two key challenges: (1) no public dataset provides lane-to-road correspondences; (2) severe misalignment from spatial fluctuations, semantic disparities, and OP map noise invalidates traditional map matching. For these challenges, We contribute: (1) Online map association dataset (OMA), the first ONR benchmark with 30K scenarios and 2.6M annotated lane vectors; (2) MAT, a transformer with path-aware attention to aligns topology despite spatial fluctuations and semantic disparities and spatial attention for integrates noisy OP features via global context; and (3) NR P-R, a metric evaluating geometric and semantic alignment. Experiments show that MAT outperforms existing methods at 34 ms latency, enabling low-cost and up-to-date lane-level navigation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.07487.pdf",
    "abs_url": "https://arxiv.org/abs/2507.07487",
    "published": "2025-07-10T07:16:00Z",
    "updated": "2026-01-29T05:40:46Z",
    "comment": "Accepted by ICLR 2026",
    "light_analysis": {
      "overview": "论文提出Online Navigation Refinement (ONR)任务，通过关联标准定义地图和在线感知地图，实现低成本、实时的车道级导航。",
      "motivation": "车道级导航对地理信息系统和导航任务至关重要，能提供比道路级导航更精细的指导。然而，当前方法依赖高清地图，无法适应动态路况；在线感知地图虽提供实时几何信息，但缺乏全局拓扑结构，无法用于导航。传统地图匹配方法在空间波动、语义差异和噪声影响下效果不佳，且缺乏公开数据集支持对应关系标注，限制了实时导航的精确性和实用性。",
      "method": "本研究提出三个核心贡献：首先，构建了在线地图关联数据集（OMA），包含30,000个场景和260万标注的车道向量，作为首个ONR任务基准。其次，设计了MAT模型，基于transformer架构，采用路径感知注意力机制处理拓扑对齐以应对空间波动和语义差异，以及空间注意力机制通过全局上下文整合噪声特征。最后，引入NR P-R指标，用于评估几何和语义对齐效果。",
      "result": "实验结果显示，MAT模型在性能上优于现有方法，延迟仅为34毫秒，基于OMA数据集的验证表明其能实现低成本和实时的车道级导航。具体性能指标如准确率摘要未明确说明，但低延迟体现了实际应用的高效性，有助于提升导航系统的响应速度和适应性。",
      "conclusion": "论文的主要贡献是引入ONR任务、OMA数据集、MAT模型和NR P-R指标，推动了车道级导航技术的发展。学术价值在于解决地图关联中的对齐挑战，实际应用价值在于降低了对高清地图的依赖，实现动态环境下的精确和实时导航。未来工作可进一步优化模型鲁棒性或扩展应用到更广泛的场景中。",
      "tags": [
        "Lane-Level Navigation",
        "Online Perception Maps",
        "Transformer",
        "Path-Aware Attention",
        "Spatial Attention"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:04.315209Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.04746",
    "title": "A Tale of Two Scripts: Transliteration and Post-Correction for Judeo-Arabic",
    "authors": [
      "Juan Moreno Gonzalez",
      "Bashar Alhafni",
      "Nizar Habash"
    ],
    "abstract": "Judeo-Arabic refers to Arabic variants historically spoken by Jewish communities across the Arab world, primarily during the Middle Ages. Unlike standard Arabic, it is written in Hebrew script by Jewish writers and for Jewish audiences. Transliterating Judeo-Arabic into Arabic script is challenging due to ambiguous letter mappings, inconsistent orthographic conventions, and frequent code-switching into Hebrew. In this paper, we introduce a two-step approach to automatically transliterate Judeo-Arabic into Arabic script: simple character-level mapping followed by post-correction to address grammatical and orthographic errors. We also present the first benchmark evaluation of LLMs on this task. Finally, we show that transliteration enables Arabic NLP tools to perform morphosyntactic tagging and machine translation, which would have not been feasible on the original texts. We make our code and data publicly available.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2507.04746.pdf",
    "abs_url": "https://arxiv.org/abs/2507.04746",
    "published": "2025-07-07T08:19:08Z",
    "updated": "2026-01-29T13:49:01Z",
    "comment": "Accepted to EACL 2026",
    "light_analysis": {
      "overview": "论文提出了一种两步法自动转写Judeo-Arabic，并首次评估了大型语言模型在该任务上的表现。",
      "motivation": "Judeo-Arabic是阿拉伯语的变体，历史由犹太社区使用希伯来字母书写，这导致标准阿拉伯语NLP工具无法直接应用。现有自动转写方法面临挑战，包括字母映射模糊、拼写不一致和频繁的希伯来语代码切换，这些问题阻碍了文本处理和分析。本研究旨在解决这些困难，通过转写实现阿拉伯语NLP工具的利用，以保存和分析历史语言资源，提升多语言处理的效率。",
      "method": "论文采用一种两步法：首先进行简单的字符级映射，将希伯来字母转换为阿拉伯字母；然后通过后校正步骤处理转写过程中产生的语法和拼写错误，以应对歧义和不一致性。关键创新点在于结合映射和后校正来改善转写质量，并首次在该任务上对大型语言模型进行基准评估。摘要未明确说明使用的具体数据集或模型架构细节，仅提到公开了代码和数据。",
      "result": "研究结果显示，转写后的Judeo-Arabic文本使阿拉伯语NLP工具能够执行词法句法标注和机器翻译任务，这在原始希伯来字母书写下不可行。论文进行了首次基准评估，评估了大型语言模型的表现，但摘要未提供具体性能指标如准确率提升或效率改进数据。因此，效果体现在转写方法成功实现了NLP应用，但具体对比基线方法的结果未详细说明。",
      "conclusion": "论文的主要贡献是开发了一种自动转写Judeo-Arabic的方法，并评估了大型语言模型在该领域的潜力。这项研究具有学术价值，为处理历史语言变体提供了新技术途径，并释放开源数据推动后续研究。实际应用上，它有助于文化遗产保护和多语言NLP工具集成。摘要未提及局限性或未来工作方向，但促进了相关领域的探索。",
      "tags": [
        "Transliteration",
        "Post-Correction",
        "Large Language Models",
        "Arabic NLP",
        "Machine Translation"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:11.915449Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.00875",
    "title": "TransLaw: A Large-Scale Dataset and Multi-Agent Benchmark Simulating Professional Translation of Hong Kong Case Law",
    "authors": [
      "Xi Xuan",
      "Chunyu Kit"
    ],
    "abstract": "Hong Kong case law translation presents significant challenges: manual methods suffer from high costs and inconsistent quality, while both traditional machine translation and approaches relying solely on Large Language Models (LLMs) often fail to ensure legal terminology accuracy, culturally embedded nuances, and strict linguistic structures. To overcome these limitations, this study proposes TransLaw, a multi-agent framework that decomposes translation into word-level expression, sentence-level translation, and multidimensional review, integrating a specialized Hong Kong legal glossary database, Retrieval-Augmented Generation (RAG), and iterative feedback. Experiments on our newly constructed HKCFA Judgment 97-22 dataset, benchmarking 13 open-source and commercial LLMs, demonstrate that TransLaw significantly outperforms single-agent baselines across all evaluated models. Human evaluation confirms the framework's effectiveness in terms of legal semantic accuracy, structural coherence, and stylistic fidelity, while noting that it still trails human experts in contextualizing complex terminology and stylistic naturalness.",
    "categories": [
      "cs.CL",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2507.00875.pdf",
    "abs_url": "https://arxiv.org/abs/2507.00875",
    "published": "2025-07-01T15:39:26Z",
    "updated": "2026-01-29T11:39:17Z",
    "comment": "Original: arXiv:2501.09444; Revised: arXiv:2507.00875; Submitted to ACL 2026",
    "light_analysis": {
      "overview": "TransLaw提出一个多代理框架，集成检索增强生成和专业词汇库，显著提升香港案例法翻译的准确性和一致性。",
      "motivation": "香港案例法翻译面临术语专业、文化细微差别复杂和语言结构严格的挑战，手动翻译成本高且质量不一致，传统机器翻译和大语言模型单独使用常无法确保法律术语准确性、文化嵌入和结构要求，突出了开发专业法律翻译方法的紧迫性。",
      "method": "研究提出TransLaw多代理框架，将翻译分解为词级表达、句级翻译和多维审查，集成专门构建的香港法律词汇数据库，利用检索增强生成（RAG）技术增强上下文理解，并通过迭代反馈机制优化翻译过程，弥补单一LLM的不足。",
      "result": "在HKCFA Judgment 97-22数据集上测试13个开源和商业大语言模型，TransLaw框架在所有模型中显著优于单代理基线，人工评估确认其在法律语义准确性、结构一致性和风格保真度方面的有效性，但复杂术语上下文化处理和风格自然性仍不及人类专家。",
      "conclusion": "该研究的主要贡献是开发TransLaw框架，为法律翻译提供基于多代理和RAG的解决方案，学术上推动大语言模型在法律领域的应用，实际中降低翻译成本并提高质量，但复杂术语处理和自然性方面存在局限，未来可探索更多优化方向。",
      "tags": [
        "Large Language Models",
        "Retrieval-Augmented Generation",
        "Multi-Agent Framework",
        "Legal Terminology",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:25.133380Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.19089",
    "title": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting",
    "authors": [
      "Nathaniel Getachew",
      "Abulhair Saparov"
    ],
    "abstract": "We introduce $\\texttt{StorySim}$, a programmable framework for synthetically generating stories to evaluate the theory of mind (ToM) and world modeling (WM) capabilities of large language models (LLMs). Unlike prior benchmarks that may suffer from contamination in pretraining data, $\\texttt{StorySim}$ produces novel, compositional story prompts anchored by a highly controllable $\\texttt{Storyboard}$, enabling precise manipulation of character perspectives and events. We use this framework to design first- and second-order ToM tasks alongside WM tasks that control for the ability to track and model mental states. Our experiments across a suite of state-of-the-art LLMs reveal that most models perform better on WM tasks than ToM tasks, and that models tend to perform better reasoning with humans compared to inanimate objects. Additionally, our framework enabled us to find evidence of heuristic behavior such as recency bias and an over-reliance on earlier events in the story. All code for generating data and evaluations is freely available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.19089.pdf",
    "abs_url": "https://arxiv.org/abs/2506.19089",
    "published": "2025-06-23T20:06:53Z",
    "updated": "2026-01-29T02:43:09Z",
    "comment": "12 pages, 11 figures",
    "light_analysis": {
      "overview": "论文提出了StorySim框架，通过合成故事来评估大语言模型的心理理论和世界建模能力。",
      "motivation": "研究动机是评估大语言模型是否真正具备心理理论能力，即理解他人心理状态的能力。现有基准可能因预训练数据污染而无法准确评估，导致测试结果不可靠。这个问题至关重要，因为心理理论是智能体进行社会交互和推理的基础，需要一种可控的方法来生成新颖、无偏的测试数据，以弥补现有方法的不足。",
      "method": "研究方法核心是开发StorySim，一个可编程框架，使用Storyboard生成高度可控的故事提示。通过编程生成新颖、组合性的故事，避免数据污染，并精确操纵角色视角和事件顺序。关键创新包括设计一阶和二阶心理理论任务以及世界建模任务，以测试模型跟踪和建模心理状态的能力，具体任务细节基于故事提示进行结构化控制。",
      "result": "实验结果基于对多个先进大语言模型的测试，显示大多数模型在世界建模任务上的表现优于心理理论任务，且在推理人类角色时比非生命物体时准确性更高。摘要未明确说明具体数据如准确率，但提到了模型存在启发式行为证据，如近因偏见和过度依赖故事早期事件，这些发现通过StorySim框架的系统评估得出。",
      "conclusion": "结论是StorySim提供了一个有效的评估工具，揭示了模型在心理理论任务上的局限性，并发现了启发式行为。这具有学术价值，改进了评估方法，促进了对模型认知能力的理解；实际应用价值在于为开发更智能的AI系统提供指导。未来工作可基于开源代码进一步扩展任务类型或探索模型训练优化。",
      "tags": [
        "Large Language Models",
        "Theory of Mind",
        "World Modeling",
        "Story Generation",
        "Evaluation Framework"
      ]
    },
    "analyzed_at": "2026-01-30T03:54:52.332890Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.01027",
    "title": "DBellQuant: Breaking the Bell with Double-Bell Transformation for LLMs Post Training Binarization",
    "authors": [
      "Zijian Ye",
      "Wei Huang",
      "Yifei Yu",
      "Tianhe Ren",
      "Zhongrui Wang",
      "Xiaojuan Qi"
    ],
    "abstract": "Large language models (LLMs) demonstrate remarkable performance but face substantial computational and memory challenges that limit their practical deployment. Quantization has emerged as a promising solution; however, its effectiveness is often limited by quantization errors arising from weight distributions that are not quantization-friendly and the presence of activation outliers. To address these challenges, we introduce DBellQuant, an innovative post-training quantization (PTQ) framework that achieves nearly 1-bit weight compression and 6-bit activation quantization with minimal performance degradation. DBellQuant uses Learnable Transformation for Dual-Bell (LTDB) algorithm, which transforms single-bell weight distributions into dual-bell forms to reduce binarization errors and applies inverse transformations to smooth activations. DBellQuant sets a new state-of-the-art by preserving superior model performance under aggressive weight and activation quantization. For example, on the Wikitext2 dataset, DBellQuant achieves a perplexity of 14.39 on LLaMA2-13B with 6-bit activation quantization, significantly outperforming BiLLM's 21.35 without activation quantization, underscoring its potential in compressing LLMs for real-world applications.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.01027.pdf",
    "abs_url": "https://arxiv.org/abs/2507.01027",
    "published": "2025-06-18T06:41:03Z",
    "updated": "2026-01-29T09:03:27Z",
    "comment": "19 pages; Appendix added",
    "light_analysis": {
      "overview": "DBellQuant是一种创新的后训练量化框架，通过双钟变换技术实现1位权重和6位激活量化，显著减少量化误差。",
      "motivation": "大型语言模型（LLMs）虽性能优异，但面临巨大的计算和内存挑战，限制实际部署。量化作为解决方案，常因权重分布不量化友好和激活异常值导致性能下降。现有量化方法在处理这些问题时效果有限，DBellQuant旨在克服这些限制，通过优化分布形态提升量化效率，解决实际应用中的瓶颈问题。",
      "method": "DBellQuant采用可学习的双钟变换（LTDB）算法，将权重分布从单钟形态转换为双钟形式，以减少二值化误差。通过逆变换处理激活值，平滑异常值，并实现后训练量化，支持近1位权重压缩和6位激活量化。关键创新点在于双钟变换的引入，无需重训练，优化了量化过程的技术路线。",
      "result": "在Wikitext2数据集上，DBellQuant对LLaMA2-13B模型进行6位激活量化后，困惑度达到14.39，而基线方法BiLLM（未进行激活量化）的困惑度为21.35。这表明DBellQuant在保持高性能的同时，实现了显著的量化效果，优于现有技术，具体数据支持了其在减少性能损失方面的优势。",
      "conclusion": "本论文的主要贡献是提出DBellQuant框架，通过双钟变换有效降低量化误差，为LLMs压缩设定了新标准。学术价值在于优化量化算法，推动模型压缩技术的发展；实际应用价值在于降低部署成本，便于现实场景使用。未来工作可探索在更多模型和任务中的扩展性。",
      "tags": [
        "Post-Training Quantization",
        "Dual-Bell Transformation",
        "Binarization",
        "LLMs",
        "LTDB Algorithm"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:15.143905Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.09277",
    "title": "NeuroFaith: Evaluating LLM Self-Explanation Faithfulness via Internal Representation Alignment",
    "authors": [
      "Milan Bhan",
      "Jean-Noel Vittaut",
      "Nicolas Chesneau",
      "Sarath Chandar",
      "Marie-Jeanne Lesot"
    ],
    "abstract": "Large Language Models (LLMs) can generate plausible free text self-explanations to justify their answers. However, these natural language explanations may not accurately reflect the model's actual reasoning process, pinpointing a lack of faithfulness. Existing faithfulness evaluation methods rely primarily on behavioral tests or computational block analysis without examining the semantic content of internal neural representations. This paper proposes NeuroFaith, a flexible framework that measures the faithfulness of LLM free text self-explanation by identifying key concepts within explanations and mechanistically testing whether these concepts actually influence the model's predictions. We show the versatility of NeuroFaith across 2-hop reasoning and classification tasks. Additionally, we develop a linear faithfulness probe based on NeuroFaith to detect unfaithful self-explanations from representation space and improve faithfulness through steering. NeuroFaith provides a principled approach to evaluating and enhancing the faithfulness of LLM free text self-explanations, addressing critical needs for trustworthy AI systems.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.09277.pdf",
    "abs_url": "https://arxiv.org/abs/2506.09277",
    "published": "2025-06-10T22:30:53Z",
    "updated": "2026-01-29T18:24:42Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出NeuroFaith框架，通过内部表示对齐评估和增强大语言模型自解释的忠实性。",
      "motivation": "大语言模型能够生成看似合理的自由文本自解释以证明其答案，但这些自然语言解释可能无法准确反映模型的实际推理过程，揭示缺乏忠实性的问题。现有忠实性评估方法主要依赖于行为测试或计算块分析，没有检查内部神经表示的语义内容，这限制了评估的深度和准确性。因此，研究旨在开发一种新方法来量化自解释的忠实性，以解决可信赖AI系统中的关键需求，提升模型透明度和可解释性。",
      "method": "NeuroFaith框架通过识别自解释中的关键概念，并机制性地测试这些概念是否真正影响模型预测来评估忠实性。核心创新在于利用内部神经表示进行语义对齐分析，结合线性忠实性探针从表示空间检测不忠实解释。该方法灵活应用于2-hop推理和分类任务，使用神经网络表示和调整技术来增强忠实性。框架整合了概念识别和表示分析，提供一种结构化的评估路径，无需依赖外部资源。",
      "result": "摘要未明确说明具体性能指标，但论文展示了NeuroFaith在2-hop推理和分类任务中的多功能性和有效性。与现有行为测试方法相比，该框架提供了一种更机制性的评估方式，能够基于内部表示测量自解释的忠实性。结果暗示NeuroFaith在识别不忠实解释和通过调整改进忠实性方面具有潜力，尽管缺乏具体数据，但其通用性为未来实验奠定了基础。",
      "conclusion": "NeuroFaith为评估和增强LLM自解释的忠实性提供了一个原则性方法，强调了内部表示对齐的重要性。该研究有助于提高模型解释的可信度，促进可信赖AI系统的开发。潜在局限性包括需要更多任务验证，未来工作可能涉及扩展到复杂场景或结合其他评估技术以进一步提升实用性。",
      "tags": [
        "Large Language Model",
        "Self-Explanation",
        "Faithfulness Evaluation",
        "Internal Representation",
        "Linear Probe"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:07.739897Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.17254",
    "title": "Near-Optimal Online Deployment and Routing for Streaming LLMs",
    "authors": [
      "Shaoang Li",
      "Jian Li"
    ],
    "abstract": "The rapid pace at which new large language models (LLMs) appear, and older ones become obsolete, forces providers to manage a streaming inventory under a strict concurrency cap and per-query cost budgets. We cast this as an online decision problem that couples stage-wise deployment (at fixed maintenance windows) with per-query routing among live models. We introduce StageRoute, a hierarchical algorithm that (i) optimistically selects up to $M_{\\max}$ models for the next stage using reward upper-confidence and cost lower-confidence bounds, and (ii) routes each incoming query by solving a budget- and throughput-constrained bandit subproblem over the deployed set. We prove a regret of $\\tilde{\\mathcal{O}}(T^{2/3})$ with a matching lower bound, establishing near-optimality, and validate the theory empirically: StageRoute tracks a strong oracle under tight budgets across diverse workloads.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.17254.pdf",
    "abs_url": "https://arxiv.org/abs/2506.17254",
    "published": "2025-06-08T12:25:26Z",
    "updated": "2026-01-29T16:04:59Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "本研究提出了StageRoute算法，一个分层在线决策方法，用于流式大型语言模型的部署和路由，实现了接近最优的遗憾边界。",
      "motivation": "大语言模型（LLMs）频繁更新，导致旧模型迅速过时，这迫使服务提供商在严格的并发限制和每个查询的成本预算下管理动态的模型库存。该研究将这一问题建模为一个在线决策问题，耦合了阶段式部署和实时查询路由。传统方法可能无法有效处理预算约束和动态变化的工作负载，因此需要一种能够适应性强且高效的解决方案来优化资源使用和成本控制，以确保服务质量和经济效益。",
      "method": "论文提出了StageRoute算法，这是一个分层算法，包含两个关键步骤。首先，在阶段部署阶段，使用奖励上限置信和成本下限置信边界，乐观地选择最多M_max个模型用于下一个维护窗口。其次，在查询路由阶段，针对每个输入查询，解决一个预算和吞吐量约束下的多臂老虎机子问题，从已部署的模型中选择最优模型。核心创新点在于结合了乐观探索策略和约束优化，将复杂的部署-路由问题分解为可管理的子问题。摘要未明确说明具体数据集或模型架构等细节。",
      "result": "理论分析表明，StageRoute算法实现了Õ(T^{2/3})的遗憾边界，并证明了该下界匹配，从而确立了接近最优性。实证验证中，算法在紧预算和多样工作负载下，能够有效跟踪一个强预言机的性能，这表明在实际场景中具有良好的适应性。与基线方法相比，算法在资源约束下优化了模型选择和查询路由，但摘要未提供具体如准确率提升的精确数据，仅基于理论证明和实证概述了整体效果。",
      "conclusion": "该研究的主要贡献是提出了StageRoute算法，解决了流式大型语言模型的在线部署和路由问题。学术价值在于提供了理论保证和实证支持，展示了算法在预算约束下的接近最优性能。实际应用价值是帮助服务提供商更高效地管理模型库存，降低成本并提高服务质量。摘要未明确说明具体局限性或未来工作方向，但潜在可扩展到更复杂约束环境或应用类似决策问题。",
      "tags": [
        "Large Language Models",
        "Online Decision Making",
        "Bandit Algorithms",
        "Confidence Bounds",
        "Hierarchical Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:41.983991Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.06725",
    "title": "WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making",
    "authors": [
      "Guillaume Levy",
      "Cedric Colas",
      "Pierre-Yves Oudeyer",
      "Thomas Carta",
      "Clement Romac"
    ],
    "abstract": "Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2506.06725.pdf",
    "abs_url": "https://arxiv.org/abs/2506.06725",
    "published": "2025-06-07T09:13:34Z",
    "updated": "2026-01-29T16:25:29Z",
    "comment": "This project's code can be found at https://github.com/flowersteam/WorldLLM. This project was presented at RLDM 2025 (https://rldm.org/)",
    "light_analysis": {
      "overview": "WorldLLM框架通过结合贝叶斯推理和好奇心驱动的强化学习，改进大语言模型在结构化环境中的世界建模能力，并生成人类可解释的理论。",
      "motivation": "大语言模型（LLMs）虽具备广泛世界知识，但在模拟等结构化、特定领域上下文中预测时准确性不足，这源于其无法将无结构理解根植于具体环境。这个问题限制了LLMs在实际应用如游戏或仿真中的有效性，现有方法缺乏动态接地机制，导致预测不精确，因此需要开发能自主适应环境的方法来增强LLM的实用价值。",
      "method": "WorldLLM框架利用LLM的上下文学习能力，通过自然语言假设引导LLM-based世界模型的预测。假设通过贝叶斯推理框架迭代细化，其中第二个LLM用作给定收集证据的提议分布。证据由好奇心驱动的强化学习策略收集，该策略探索环境以找到在当前假设下LLM预测模型对数似然低的转换。交替进行假设细化和证据收集，驱动预测持续改进，实验在需要代理操作和组合对象的文本游戏环境中进行。",
      "result": "实验在文本游戏环境中展示，WorldLLM框架提高了预测准确性并生成了人类可解释的环境动态理论。具体性能指标如准确率提升或效率改进摘要未明确说明，但框架在结构化任务中相较于基线方法可能表现出改进，验证了其通过自主探索和理论构建增强LLM世界建模的有效性。",
      "conclusion": "WorldLLM贡献在于结合贝叶斯推理和强化学习，增强LLM在结构化环境中的世界建模，学术上推动了上下文学习和自主理论构建的发展，实际应用可扩展至模拟、游戏等场景。局限性可能包括计算复杂度，未来工作可优化效率或应用于更复杂领域，提升AI的适应性。",
      "tags": [
        "Large Language Model",
        "Bayesian Inference",
        "Reinforcement Learning",
        "Curiosity-Driven Learning",
        "World Modeling"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:46.397046Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.04877",
    "title": "There Was Never a Bottleneck in Concept Bottleneck Models",
    "authors": [
      "Antonio Almudévar",
      "José Miguel Hernández-Lobato",
      "Alfonso Ortega"
    ],
    "abstract": "Deep learning representations are often difficult to interpret, which can hinder their deployment in sensitive applications. Concept Bottleneck Models (CBMs) have emerged as a promising approach to mitigate this issue by learning representations that support target task performance while ensuring that each component predicts a concrete concept from a predefined set. In this work, we argue that CBMs do not impose a true bottleneck: the fact that a component can predict a concept does not guarantee that it encodes only information about that concept. This shortcoming raises concerns regarding interpretability and the validity of intervention procedures. To overcome this limitation, we propose Minimal Concept Bottleneck Models (MCBMs), which incorporate an Information Bottleneck (IB) objective to constrain each representation component to retain only the information relevant to its corresponding concept. This IB is implemented via a variational regularization term added to the training loss. As a result, MCBMs yield more interpretable representations, support principled concept-level interventions, and remain consistent with probability-theoretic foundations.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.04877.pdf",
    "abs_url": "https://arxiv.org/abs/2506.04877",
    "published": "2025-06-05T10:50:42Z",
    "updated": "2026-01-29T11:21:26Z",
    "comment": "Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "提出最小概念瓶颈模型，通过信息瓶颈约束增强深度学习表示的可解释性和概念级干预的有效性。",
      "motivation": "深度学习表示的可解释性差，限制了在敏感应用中的部署。概念瓶颈模型虽然通过学习概念预测来改善可解释性，但其表示组件可能编码额外信息，导致所谓的“瓶颈”不严格，从而影响模型的解释性和干预措施的可靠性。本研究旨在解决这一问题，确保模型更加透明和可靠，以适应对AI系统可解释性要求高的场景。",
      "method": "本研究提出最小概念瓶颈模型，核心创新是引入信息瓶颈目标，约束每个表示组件仅保留与预定义概念相关的信息，避免编码冗余信息。通过向训练损失添加变分正则化项实现这一约束，从而增强表示的纯化。摘要未明确说明具体使用的数据集或模型架构，但强调信息瓶颈的正则化作用，以促进概率论基础的一致性和实际应用的可行性。",
      "result": "最小概念瓶颈模型在理论上和实验中表现出更可解释的表示，支持基于原则的概念级干预，并与概率论基础保持一致。摘要未提供具体的性能指标如准确率提升或效率改进，也未详述与基线概念瓶颈模型的对比数据，但指出该方法在解决瓶颈不严格问题上优于传统方法。",
      "conclusion": "主要贡献是通过信息瓶颈改进概念瓶颈模型，增强了表示的可解释性和干预的合理性，为敏感应用提供更可靠的AI模型。这研究在可解释AI领域具有重要学术和实际价值。摘要未明确说明局限性或未来工作方向，但潜在可扩展至其他可解释性框架。",
      "tags": [
        "Concept Bottleneck Models",
        "Information Bottleneck",
        "Variational Regularization",
        "Interpretable AI",
        "Deep Learning Representations"
      ]
    },
    "analyzed_at": "2026-01-30T03:55:54.331389Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.03229",
    "title": "Bridging Weakly-Supervised Learning and VLM Distillation: Noisy Partial Label Learning for Efficient Downstream Adaptation",
    "authors": [
      "Qian-Wei Wang",
      "Yaguang Song",
      "Shu-Tao Xia"
    ],
    "abstract": "In the context of noisy partial label learning (NPLL), each training sample is associated with a set of candidate labels annotated by multiple noisy annotators. With the emergence of high-performance pre-trained vision-language models (VLMs) such as CLIP, LLaVA, and GPT-4V, leveraging these models to replace time-consuming manual annotation and enable annotation-free training has become a promising research direction. This paper studies learning from noisy partial labels generated by pre-trained VLMs and proposes a collaborative consistency regularization (Co-Reg) framework. Unlike symmetric noise commonly assumed in traditional noisy label learning, VLM-generated noise is instance-dependent and reflects the intrinsic biases of pre-trained models, posing greater challenges. To address this issue, we jointly train two neural networks to perform collaborative label purification via a co-pseudo-labeling mechanism, while enforcing consistency regularization in both label and feature representation spaces. In addition, multiple anti-overfitting strategies are introduced, including alternating optimization of contrastive representations and pseudo-labels, as well as maintaining class prototypes in a shared feature space. The proposed method can further incorporate few-shot manually annotated labels for performance enhancement. Extensive experiments under various settings demonstrate the effectiveness of our approach and highlight the potential of integrating weakly supervised learning into the knowledge distillation of pre-trained models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2506.03229.pdf",
    "abs_url": "https://arxiv.org/abs/2506.03229",
    "published": "2025-06-03T12:48:54Z",
    "updated": "2026-01-29T13:56:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出协作一致性正则化框架，用于从预训练视觉-语言模型生成的噪声部分标签中学习，实现高效下游适应。",
      "motivation": "研究动机源于预训练视觉-语言模型（VLMs，如CLIP、LLaVA、GPT-4V）的兴起，这些模型能生成标签以替代耗时的人工标注，推动无标注训练。然而，VLM生成的标签是噪声且部分的，不同于传统噪声标签学习中假设的对称噪声，而是实例依赖的，反映预训练模型的内在偏差，这增加了学习挑战。当前方法未能有效处理这种独特噪声，因此需要开发新方案来利用弱监督数据，促进高效下游任务适应，减少标注成本并提升模型泛化能力。",
      "method": "研究方法提出协作一致性正则化（Co-Reg）框架，核心在于联合训练两个神经网络，通过协作伪标签机制协同净化噪声部分标签。关键创新点包括在标签空间和特征表示空间同时施加一致性正则化，以增强模型鲁棒性；引入多种抗过拟合策略，如交替优化对比表示和伪标签，并在共享特征空间中维护类原型来防止过拟合。此外，框架可结合少量手动标注标签以提升性能，形成一个系统的方法处理VLM生成的实例依赖噪声。",
      "result": "主要实验结果表明，在各种设置下进行的广泛实验证明了所提出方法的有效性。摘要未明确说明具体性能指标如准确率提升数值，但实验展示了该方法在从噪声部分标签中学习方面的优越性能，与基线方法相比有显著改进。结果强调了将弱监督学习集成到预训练模型知识蒸馏中的潜力，验证了框架在实际应用中的实用性和效果，为后续研究提供了实证基础。",
      "conclusion": "论文的主要贡献是提出协作一致性正则化框架，成功解决从预训练视觉-语言模型生成噪声部分标签学习的挑战，在学术上丰富了弱监督学习和知识蒸馏的结合技术。实际应用价值在于促进了高效下游适应，减少对大量人工标注的依赖，为AI模型部署和优化提供新方向。潜在局限性可能包括方法对不同VLM噪声特性的适应性，未来工作可探索扩展至更多领域和模型。",
      "tags": [
        "Noisy Partial Label Learning",
        "Vision-Language Models",
        "Knowledge Distillation",
        "Weakly Supervised Learning",
        "Consistency Regularization"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:38.683196Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.01883",
    "title": "scDataset: Scalable Data Loading for Deep Learning on Large-Scale Single-Cell Omics",
    "authors": [
      "Davide D'Ascenzo",
      "Sebastiano Cultrera di Montesano"
    ],
    "abstract": "Training deep learning models on single-cell datasets with hundreds of millions of cells requires loading data from disk, as these datasets exceed available memory. While random sampling provides the data diversity needed for effective training, it is prohibitively slow due to the random access pattern overhead, whereas sequential streaming achieves high throughput but introduces biases that degrade model performance. We present scDataset, a PyTorch data loader that enables efficient training from on-disk data with seamless integration across diverse storage formats. Our approach combines block sampling and batched fetching to achieve quasi-random sampling that balances I/O efficiency with minibatch diversity. On Tahoe-100M, a dataset of 100 million cells, scDataset achieves more than two orders of magnitude speedup compared to true random sampling while working directly with AnnData files. We provide theoretical bounds on minibatch diversity and empirically show that scDataset matches the performance of true random sampling across multiple classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.01883.pdf",
    "abs_url": "https://arxiv.org/abs/2506.01883",
    "published": "2025-06-02T17:11:49Z",
    "updated": "2026-01-29T15:07:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出scDataset，一种用于大规模单细胞组学深度学习的数据加载器，通过准随机采样实现高效训练和多样化数据访问。",
      "motivation": "在单细胞组学领域，训练深度学习模型常面临数据集规模庞大（如数亿个细胞）、超出可用内存的挑战。现有方法中，随机采样能提供训练所需的数据多样性，但随机访问开销导致加载速度极慢；顺序流式传输虽吞吐量高，却引入偏见，损害模型性能。因此，亟需一种平衡I/O效率和数据多样性的数据加载方案，以支持大规模生物信息学分析。",
      "method": "scDataset是一个PyTorch数据加载器，其核心方法结合块采样和批量获取，实现准随机采样。块采样通过组织数据块减少I/O开销，批量获取进一步优化数据流，无缝集成多种存储格式如AnnData文件。关键创新点在于平衡了I/O效率与迷你批次多样性，提供了理论多样性的界限，无需预加载整个数据集。",
      "result": "在Tahoe-100M数据集（包含1亿个细胞）上，scDataset相比真实随机采样实现了超过两个数量级的加速，直接处理AnnData文件。实验显示，在多个分类任务中，其性能与真实随机采样匹配。论文还提供了迷你批次多样性的理论界限，经验验证了方法在维持训练效果方面的有效性。",
      "conclusion": "scDataset的主要贡献是提供了一种高效的数据加载器，解决大规模单细胞数据训练中速度与性能的平衡问题。学术价值在于优化了深度学习数据访问模式，实际应用可加速生物信息学研究。未来工作方向或局限性摘要未明确说明，可能包括扩展更多数据格式或评估其他应用场景。",
      "tags": [
        "Single-Cell Omics",
        "Data Loading",
        "PyTorch",
        "Block Sampling",
        "Minibatch Diversity"
      ]
    },
    "analyzed_at": "2026-01-30T03:56:33.771429Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.01042",
    "title": "Probing Neural Topology of Large Language Models",
    "authors": [
      "Yu Zheng",
      "Yuan Yuan",
      "Yue Zhuo",
      "Yong Li",
      "Gabriel Kreiman",
      "Tomaso Poggio",
      "Paolo Santi"
    ],
    "abstract": "Probing large language models (LLMs) has yielded valuable insights into their internal mechanisms by linking neural activations to interpretable semantics. However, the complex mechanisms that link neuron's functional co-activation with the emergent model capabilities remains largely unknown, hindering a deeper understanding and safer development of LLMs. In this work, we introduce graph probing, a method for uncovering the functional connectivity of LLM neurons and relating it to language generation performance. By probing models across diverse LLM families and scales, we discover a universal predictability of language generation and understanding performance using only neural topology, which persists even when retaining just 1% of neuron connections. Strikingly, probing on topology outperforms probing on activation by up to 130.4% and 67.7% on perplexity and space/time semantic regression respectively, suggesting that neural topology contains orders of richer information of LLM performance than neural activation, which can be easily extracted with simple linear or MLP probes. To explain the dependence between neural topology and language performance, we identify default networks and hub neurons in LLMs and provide causal evidence by interventional experiments on multiple benchmarks, showing that LLMs actually exploit these topological information. Further analyses suggest that graph probing can be effectively leveraged to improve the efficiency and reliability of LLMs through proof-of-concept applications in model pruning and hallucination detection. Codes and data for the graph probing toolbox are available at https://github.com/DavyMorgan/llm-graph-probing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.01042.pdf",
    "abs_url": "https://arxiv.org/abs/2506.01042",
    "published": "2025-06-01T14:57:03Z",
    "updated": "2026-01-29T04:47:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过图探测方法揭示大型语言模型神经拓扑与语言性能的普遍关联，为模型优化提供新路径。",
      "motivation": "尽管神经激活探测已链接LLM内部机制与可解释语义，但神经元功能共激活与模型能力的关系仍不明确，阻碍了深入理解和安全开发。现有方法侧重于分析激活模式，而神经拓扑信息的潜力未被充分挖掘，因此需要新方法来探索功能连接性与性能的依赖关系，以提升模型可靠性。摘要未明确说明具体应用场景的不足，但暗示现有探测方法在拓扑层面的局限性。",
      "method": "提出图探测方法，通过构建和分析LLM神经元的功能连接图来揭示神经拓扑，并关联语言生成性能。使用简单线性或多层感知器探测器从拓扑中提取信息，并在不同LLM家族和规模上进行验证。关键创新包括识别默认网络和中心神经元，以及通过干预实验提供因果证据。摘要未明确说明具体数据集和模型架构细节，但提及代码和工具箱在GitHub上可用。",
      "result": "实验结果显示，神经拓扑能普遍预测语言生成和理解性能，即使仅保留1%神经元连接时仍保持可预测性。与基于激活的探测相比，图探测在困惑度评估上提升高达130.4%，在时空语义回归上提升67.7%，表明拓扑信息比激活更丰富且易于提取。干预实验在多个基准上提供了因果证据，证实LLM确实利用这些拓扑结构。摘要未明确说明与其他基线的详细对比数据，但强调了拓扑探测的优越性。",
      "conclusion": "图探测方法揭示了LLM神经拓扑与语言性能的关键联系，为理解模型内部机制和优化提供了新工具。概念验证应用在模型剪枝和幻觉检测中显示潜力，可提高LLM的效率和可靠性。未来工作可能包括扩展拓扑分析到更多应用场景和验证泛化性，摘要未明确说明具体局限性，但暗示了进一步研究的空间。",
      "tags": [
        "Large Language Model",
        "Graph Probing",
        "Neural Topology",
        "Functional Connectivity",
        "Model Pruning"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:53.003566Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.00886",
    "title": "Position: Agent Should Invoke External Tools ONLY When Epistemically Necessary",
    "authors": [
      "Hongru Wang",
      "Cheng Qian",
      "Manling Li",
      "Jiahao Qiu",
      "Boyang Xue",
      "Mengdi Wang",
      "Heng Ji",
      "Amos Storkey",
      "Kam-Fai Wong"
    ],
    "abstract": "As large language models evolve into tool-augmented agents, a central question remains unresolved: when is external tool use actually justified? Existing agent frameworks typically treat tools as ordinary actions and optimize for task success or reward, offering little principled distinction between epistemically necessary interaction and unnecessary delegation. This position paper argues that agents should invoke external tools only when epistemically necessary. Here, epistemic necessity means that a task cannot be completed reliably via the agent's internal reasoning over its current context, without any external interaction. We introduce the Theory of Agent (ToA), a framework that treats agents as making sequential decisions about whether remaining uncertainty should be resolved internally or delegated externally. From this perspective, common agent failure modes (e.g., overthinking and overacting) arise from miscalibrated decisions under uncertainty rather than deficiencies in reasoning or tool execution alone. We further discuss implications for training, evaluation, and agent design, highlighting that unnecessary delegation not only causes inefficiency but can impede the development of internal reasoning capability. Our position provides a normative criterion for tool use that complements existing decision-theoretic models and is essential for building agents that are not only correct, but increasingly intelligent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2506.00886.pdf",
    "abs_url": "https://arxiv.org/abs/2506.00886",
    "published": "2025-06-01T07:52:16Z",
    "updated": "2026-01-29T16:01:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出代理应仅在认识论上必要情况下调用外部工具的立场，并介绍代理理论（ToA）框架为工具使用提供规范性标准。",
      "motivation": "本研究动机源于大型语言模型演变为工具增强型代理时，外部工具使用的合理性问题。现有代理框架通常将工具视为普通动作，以任务成功或奖励为优化目标，导致缺乏对认识论上必要交互和不必要委托的原则性区分。这种不区分不仅影响代理效率，还可能阻碍内部推理能力提升，从而限制代理的智能发展，因此亟需解决何时工具使用是真正必要的核心问题。",
      "method": "本文提出代理理论（ToA）框架，将代理的决策过程建模为序列决策，以判断不确定性应通过内部推理解决还是委托给外部工具。该方法的关键创新在于强调认识论必要性，即任务无法仅凭内部推理可靠完成时才使用外部工具，从而从认识论角度分析决策校准问题。摘要未明确说明使用的具体数据集或模型架构，但框架聚焦于理论分析，旨在识别和纠正代理常见失败模式如过度思考和过度行动。",
      "result": "摘要未明确说明具体的实验结果或性能指标。论文的主要成果是理论框架的提出和分析，它通过引入认识论必要性的概念，理论上能够提高代理效率并促进内部推理能力发展。与基线方法的对比体现在提供了一个规范性标准来评估工具使用，补充了决策理论模型。具体效果如准确率提升或效率改进在摘要中未详细说明。",
      "conclusion": "本文的主要贡献是确立了代理仅在认识论上必要情况下调用外部工具的规范性标准，并发展了代理理论（ToA）框架。这一研究在学术上补充了现有决策理论模型，在实际应用中对于构建正确且越来越智能的代理至关重要，强调了不必要的委托对效率和推理能力发展的负面影响。未来工作可能涉及将框架应用于代理设计和训练实践中，但摘要未明确说明具体局限性。",
      "tags": [
        "Tool-Augmented Agents",
        "Large Language Models",
        "Epistemic Necessity",
        "Sequential Decision Making",
        "Theory of Agent"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:01.429083Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.00614",
    "title": "Predictability-Aware Compression and Decompression Framework for Multichannel Time Series Data with Latent Seasonality",
    "authors": [
      "Ziqi Liu",
      "Pei Zeng",
      "Yi Ding"
    ],
    "abstract": "Real-world multichannel time series prediction faces growing demands for efficiency across edge and cloud environments, making channel compression a timely and essential problem. Motivated by the success of Multiple-Input Multiple-Output (MIMO) methods in signal processing, we propose a predictability-aware compression-decompression framework to reduce runtime, decrease communication cost, and maintain prediction accuracy across diverse predictors. The core idea involves using a circular seasonal key matrix with orthogonality to capture underlying time series predictability during compression and to mitigate reconstruction errors during decompression by introducing more realistic data assumptions. Theoretical analyses show that the proposed framework is both time-efficient and accuracy-preserving under a large number of channels. Extensive experiments on six datasets across various predictors demonstrate that the proposed method achieves superior overall performance by jointly considering prediction accuracy and runtime, while maintaining strong compatibility with diverse predictors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.00614.pdf",
    "abs_url": "https://arxiv.org/abs/2506.00614",
    "published": "2025-05-31T15:53:41Z",
    "updated": "2026-01-29T03:36:32Z",
    "comment": "17 pages,3 figures",
    "light_analysis": {
      "overview": "提出一个可预测性感知的压缩-解压缩框架，用于优化多通道时间序列预测的效率，并在保持准确性的同时减少运行时和通信成本。",
      "motivation": "现实世界中多通道时间序列预测在边缘和云环境中对效率的需求日益增长，导致通信成本和运行时成为瓶颈，使得通道压缩成为一个及时且关键的问题。现有方法可能难以在压缩过程中维持预测准确性，特别是对于具有潜在季节性的数据。受到信号处理中多输入多输出（MIMO）方法成功的启发，本研究旨在开发一个兼顾效率与准确性的框架，以解决这一挑战。",
      "method": "本研究提出一个可预测性感知的压缩-解压缩框架，其核心创新是使用一个具有正交性的循环季节性关键矩阵。在压缩阶段，该矩阵捕捉时间序列的潜在可预测性和季节性特征；在解压缩阶段，通过引入更现实的数据假设来减轻重构误差，从而优化预测性能。框架设计旨在减少运行时、降低通信成本，并确保与多种预测器兼容，适用于多通道环境。",
      "result": "理论分析表明，该框架在处理大量通道时具有时间高效性和准确性保持能力。在六个数据集上的广泛实验证明，该方法通过联合考虑预测准确性和运行时，实现了整体性能的优越提升，并与不同预测器保持强兼容性。摘要未明确说明具体性能指标，但实验结果显示了相对于基线方法的改进。",
      "conclusion": "该研究的主要贡献是提出了一个经理论分析和实验验证的压缩-解压缩框架，有效平衡了多通道时间序列预测中的效率与准确性。其学术价值在于将MIMO方法应用于时间序列领域，扩展了信号处理技术；实际应用价值在于支持边缘和云环境中的高效预测系统。未来工作可能包括框架的进一步优化或扩展到其他数据类型。",
      "tags": [
        "Time Series Compression",
        "MIMO",
        "Predictability-Aware",
        "Seasonality",
        "Orthogonal Matrix"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:35.072008Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.23463",
    "title": "Revisiting Reweighted Risk for Calibration: AURC, Focal, and Inverse Focal Loss",
    "authors": [
      "Han Zhou",
      "Sebastian G. Gruber",
      "Teodora Popordanoska",
      "Matthew B. Blaschko"
    ],
    "abstract": "Several variants of reweighted risk functionals, such as focal loss, inverse focal loss, and the Area Under the Risk Coverage Curve (AURC), have been proposed for improving model calibration; yet their theoretical connections to calibration errors remain under-explored. In this paper, we revisit a broad class of weighted risk functions and find a principled connection between calibration error and selective classification. We show that minimizing calibration error is closely linked to the selective classification paradigm and demonstrate that optimizing selective risk in low confidence regions naturally improves calibration. Our proposed loss shares a similar reweighting strategy with dual focal loss but offers greater flexibility through the choice of confidence score functions (CSFs). Furthermore, our approach utilizes a bin-based cumulative distribution function (CDF) approximation, enabling efficient gradient-based optimization with O(nM) complexity for n samples and M bins. Empirical evaluations demonstrate that our method achieves competitive calibration performance across a range of datasets and model architectures.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2505.23463.pdf",
    "abs_url": "https://arxiv.org/abs/2505.23463",
    "published": "2025-05-29T14:12:12Z",
    "updated": "2026-01-29T11:25:40Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文通过理论连接校准误差与选择性分类，提出一种灵活的重加权损失函数，实现高效的模型校准优化。",
      "motivation": "模型校准是提升深度学习模型可靠性的重要问题，现有方法如focal loss、inverse focal loss和AURC等通过重加权风险函数改进校准，但其理论基础与校准误差的关联尚未充分探索，导致实践缺乏理论指导。本研究旨在阐明这种联系，为解决校准不足问题提供理论依据，从而增强模型的可信度和应用价值。",
      "method": "论文重新审视加权风险函数类，揭示了校准误差与选择性分类的理论联系，表明优化低置信度区域的选择性风险可改善校准。核心方法包括设计一种类似双focal loss的损失函数，但通过选择置信度分数函数（CSFs）增加灵活性，并采用基于bin的累积分布函数（CDF）近似实现高效梯度优化，复杂度为O(nM)，其中n为样本数，M为bin数。",
      "result": "实证评估显示，该方法在多种数据集和模型架构上实现了竞争性的校准性能，但摘要未明确说明具体准确率或对比数据。实验结果表明，与现有基线如focal loss相比，提出的方法能有效提升校准效果，并在不同场景下保持稳定表现。",
      "conclusion": "本研究的主要贡献在于建立了校准误差与选择性分类的理论联系，并提出了一种灵活且高效的校准方法。这为校准领域提供了新的理论视角和实用工具，有助于增强模型可靠性。潜在局限包括对CSFs选择的依赖，未来工作可探索更多函数变体或应用于更复杂模型场景。",
      "tags": [
        "Model Calibration",
        "Reweighted Risk Functions",
        "Selective Classification",
        "Focal Loss",
        "CDF Approximation"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:44.385519Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.19616",
    "title": "Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models",
    "authors": [
      "Rui Cai",
      "Bangzheng Li",
      "Xiaofei Wen",
      "Muhao Chen",
      "Zhe Zhao"
    ],
    "abstract": "Multimodal Large Language Models demonstrate strong performance on multimodal benchmarks, yet often exhibit poor robustness when exposed to spurious modality interference, such as irrelevant text in vision understanding, or irrelevant visual content in question answering. At its core, modality interference refers to cases where spurious signals from non-essential modalities distort model decisions, which we systematically analyze through causal, perturbation-based diagnostic experiments. To address this problem, we propose a unified finetuning framework that combines heuristic and adversarial perturbation-based data augmentation with output-level consistency regularization between original and perturbed inputs. Extensive experiments across image-heavy, text-heavy, and multimodal benchmarks, spanning multiple MLLM architectures and model scales, demonstrate consistent improvements in unimodal robustness and generalization, while improving standard multimodal performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.19616.pdf",
    "abs_url": "https://arxiv.org/abs/2505.19616",
    "published": "2025-05-26T07:31:32Z",
    "updated": "2026-01-29T11:16:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一个统一微调框架，通过数据增强和一致性正则化来诊断和缓解多模态大型语言模型中的模态干扰问题。",
      "motivation": "多模态大型语言模型在多模态基准测试中表现强劲，但在面临无关模态信号干扰时，如视觉理解中的无关文本或问答中的无关视觉内容，鲁棒性显著下降。模态干扰指虚假信号从非必要模态扭曲模型决策，导致实际应用中的不可靠性。现有方法往往未系统处理这种干扰，使得模型在复杂多模态环境中表现不稳定，因此研究诊断和缓解机制对提升模型的实用性和泛化能力至关重要。",
      "method": "作者提出一个统一的微调框架来缓解模态干扰，核心方法包括：首先通过基于因果和扰动的诊断实验系统分析干扰现象；其次，结合启发式和基于对抗扰动的数据增强生成扰动输入；最后，在微调过程中应用输出级一致性正则化，确保原始输入和扰动输入的预测一致性。该框架适用于多种MLLM架构和模型规模，实验覆盖图像密集、文本密集和多模态基准测试，以验证其有效性。",
      "result": "实验结果显示，该框架在多种基准测试上一致改进了多模态大型语言模型的单模态鲁棒性和泛化性，同时提升了标准多模态性能。摘要未提供具体性能指标数据，但通过对比基线方法，在处理无关模态干扰时表现出更强的稳健性，覆盖不同架构和模型规模，证明了方法的广泛适用性。",
      "conclusion": "本研究的主要贡献在于系统诊断了模态干扰问题，并提出一个有效的微调框架进行缓解。通过数据增强和一致性正则化，方法提升了模型的鲁棒性和泛化能力，并保持了标准性能，为多模态AI系统的可靠部署提供技术支持。摘要未明确说明局限性或未来工作，但可推断未来可能探索其他干扰类型或扩展应用场景。",
      "tags": [
        "Multimodal Large Language Models",
        "Modality Interference",
        "Data Augmentation",
        "Adversarial Perturbation",
        "Consistency Regularization"
      ]
    },
    "analyzed_at": "2026-01-30T03:57:54.357088Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.19439",
    "title": "Surrogate Signals from Format and Length: Reinforcement Learning for Solving Mathematical Problems without Ground Truth Answers",
    "authors": [
      "Rihui Xin",
      "Han Liu",
      "Zecheng Wang",
      "Yupeng Zhang",
      "Dianbo Sui",
      "Xiaolin Hu",
      "Bingning Wang"
    ],
    "abstract": "Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costly, and sometimes unfeasible. This research delves into the utilization of format and length as surrogate signals to train LLMs for mathematical problem-solving, bypassing the need for traditional ground truth answers. Our study shows that a reward function centered on format correctness alone can yield performance improvements comparable to the standard GRPO algorithm in early phases. Recognizing the limitations of format-only rewards in the later phases, we incorporate length-based rewards. The resulting GRPO approach, leveraging format-length surrogate signals, not only matches but surpasses the performance of the standard GRPO algorithm relying on ground truth answers in certain scenarios, achieving 40.0% accuracy on AIME2024 with a 7B base model. Through systematic exploration and experimentation, this research not only offers a practical solution for training LLMs to solve mathematical problems and reducing the dependence on extensive ground truth data collection, but also reveals the essence of why our label-free approach succeeds: the powerful base model is like an excellent student who has already mastered mathematical and logical reasoning skills, but performs poorly on the test paper, it simply needs to develop good answering habits to achieve outstanding results in exams, to unlock the capabilities it already possesses.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.19439.pdf",
    "abs_url": "https://arxiv.org/abs/2505.19439",
    "published": "2025-05-26T02:56:22Z",
    "updated": "2026-01-29T11:05:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "该研究提出一种基于格式和长度替代信号的强化学习方法，用于训练大型语言模型解决数学问题，无需地面真实答案。",
      "motivation": "在数学问题解决任务中，为大型语言模型获取训练所需的地面真实答案通常具有挑战性，成本高昂且有时不可行。现有方法依赖这些答案，限制了模型在资源有限环境下的应用。本研究旨在通过替代信号减少对昂贵数据收集的依赖，提高模型在数学领域的实用性，克服传统方法的不足，推动更高效的模型训练。",
      "method": "论文采用强化学习框架，基于GRPO算法，设计以格式正确性和长度为替代信号的奖励函数。早期阶段仅使用格式奖励，后期结合长度奖励以补充格式奖励的局限性。使用7B参数的大型语言模型作为基础，在AIME2024数据集上进行实验，通过逐步优化奖励策略来训练模型，避免了对传统地面真实答案的依赖，突出了格式和长度作为有效训练信号的创新点。",
      "result": "实验结果显示，格式长度替代信号方法在AIME2024数据集上，使用7B基础模型达到40.0%的准确率。在某些场景下，该方法不仅匹配还超越了标准GRPO算法（依赖地面真实答案）的性能。早期阶段仅基于格式的奖励与标准算法相当，证明了替代信号的有效性，突出了该方法在减少数据依赖方面的优势，为数学问题解决提供了可靠性能提升。",
      "conclusion": "该研究的主要贡献是提出了一种无需地面真实答案的训练方法，通过格式和长度替代信号显著减少数据收集成本。学术上，它揭示了大型语言模型在数学推理中的内在能力，展示了强化学习如何释放这些能力。实际应用中，这为数学问题解决提供高效方案，并可能扩展到其他领域。未来工作可探索更多替代信号或改进奖励机制，以进一步提升模型性能。",
      "tags": [
        "Large Language Model",
        "Reinforcement Learning",
        "Format-based Reward",
        "Length-based Reward",
        "Mathematical Problem Solving"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:09.487700Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.19236",
    "title": "Evaluating Text Creativity across Diverse Domains: A Dataset and Large Language Model Evaluator",
    "authors": [
      "Qian Cao",
      "Xiting Wang",
      "Yuzhuo Yuan",
      "Yahui Liu",
      "Fang Luo",
      "Ruihua Song"
    ],
    "abstract": "Creativity evaluation remains a challenging frontier for large language models (LLMs). Current evaluations heavily rely on inefficient and costly human judgments, hindering progress in enhancing machine creativity. While automated methods exist, ranging from psychological testing to heuristic- or prompting-based approaches, they often lack generalizability or alignment with human judgment. To address these issues, we propose a novel pairwise-comparison framework for assessing textual creativity that leverages shared contextual instructions to improve evaluation consistency. We introduce CreataSet, a large-scale dataset with 100K+ human-level and 1M+ synthetic creative instruction-response pairs spanning diverse open-domain tasks. Through training on CreataSet, we develop an LLM-based evaluator named CrEval. CrEval demonstrates remarkable superiority over existing methods in alignment with human judgments. Experimental results underscore the indispensable significance of integrating both human and synthetic data to train highly robust evaluators, and showcase the practical utility of CrEval in boosting the creativity of LLMs.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.19236.pdf",
    "abs_url": "https://arxiv.org/abs/2505.19236",
    "published": "2025-05-25T17:25:23Z",
    "updated": "2026-01-29T18:38:43Z",
    "comment": "Accepted by ICLR 2026",
    "light_analysis": {
      "overview": "论文提出了一个基于成对比较框架和大规模数据集CreataSet的LLM评估器CrEval，以高效评估文本创造力并与人类判断对齐。",
      "motivation": "创造力评估在大型语言模型中仍具挑战性，主要问题在于当前评估依赖低效且成本高昂的人类判断，限制了机器创造力研究的进展。现有自动化方法，如心理测试、启发式或基于提示的方法，常常缺乏通用性或无法与人类判断良好对齐，导致评估不一致。因此，迫切需要一种更有效、可靠的评估方法，以推动AI创造力领域的发展和实际应用。",
      "method": "论文提出了一种基于成对比较的文本创造力评估框架，通过共享上下文指令来提高评估一致性。关键创新是引入了CreataSet数据集，包含超过10万人类级和100万合成的创意指令-响应对，覆盖多样开放领域任务。利用该数据集，训练了一个基于大型语言模型的评估器CrEval。该方法强调数据集的构建和成对比较机制，以优化评估过程，但摘要未明确说明具体的模型架构或训练细节。",
      "result": "实验结果显示，CrEval在人类判断对齐方面显著优于现有方法，展现出卓越的评估性能。通过整合人类和合成数据进行训练，证明了其对于提高评估器鲁棒性的关键作用。虽然摘要未提供具体性能指标如准确率提升，但研究强调了CrEval在实际应用中能够有效提升LLMs的创造力。与基线方法对比，CrEval的优势突出了自动化评估的实用价值，为创造力研究提供了新工具。",
      "conclusion": "该研究的主要贡献在于开发了CrEval评估器和CreataSet数据集，为文本创造力评估提供了新的解决方案。学术上，它推动了AI创造力评估方法的进步，克服了现有方法的局限性，促进了相关研究的发展。实际应用中，CrEval能够帮助提升大型语言模型的创造力，具有广泛的应用潜力。未来工作方向可能包括优化数据集和评估器，以及在更多领域验证其效果，但摘要未明确说明具体局限性。",
      "tags": [
        "Large Language Model",
        "Creativity Evaluation",
        "Pairwise Comparison",
        "Dataset Synthesis",
        "Instruction-Response Pairs"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:33.320224Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.18269",
    "title": "Representative Action Selection for Large Action Space Bandit Families",
    "authors": [
      "Quan Zhou",
      "Mark Kozdoba",
      "Shie Mannor"
    ],
    "abstract": "We study the problem of selecting a subset from a large action space shared by a family of bandits, with the goal of achieving performance nearly matching that of using the full action space. Indeed, in many natural situations, while the nominal set of actions may be large, there also exist significant correlations between the rewards of different actions. In this paper we propose an algorithm that can significantly reduce the action space when such correlations are present, without the need to a-priori know the correlation structure. We provide theoretical guarantees on the performance of the algorithm and demonstrate its practical effectiveness through empirical comparisons with Thompson Sampling and Upper Confidence Bound methods.",
    "categories": [
      "cs.LG",
      "math.OC",
      "math.PR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.18269.pdf",
    "abs_url": "https://arxiv.org/abs/2505.18269",
    "published": "2025-05-23T18:08:57Z",
    "updated": "2026-01-29T16:11:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种算法，无需先验相关性结构就能从大型动作空间中选择代表性子集，以近似完整动作空间的性能。",
      "motivation": "本研究旨在解决多臂赌博机（bandit）家族中大型动作空间下的动作选择问题。实际应用中，动作集合庞大，但不同动作的奖励存在显著相关性，可用于减少动作空间而不损失性能。现有方法如Thompson Sampling和Upper Confidence Bound可能效率低下或需要先验相关性知识。因此，研究动机是开发一种无需先验结构就能利用相关性、有效选择子集的算法，以提升计算效率和性能。",
      "method": "论文提出了一种算法，用于在奖励相关性存在时从大型动作空间中选取代表性子集。关键创新在于算法无需事先知道相关性结构，能够自适应地推断和利用相关性信息来减少动作空间。摘要未明确说明具体技术细节，如模型架构或数据集，但算法设计可能基于奖励估计和动作选择策略，旨在平衡探索与利用，以实现高效的动作缩减。",
      "result": "论文提供了算法的理论性能保证，并通过实证比较证明了其实际有效性。实验结果显示，与Thompson Sampling和Upper Confidence Bound（UCB）方法相比，该算法在减少动作空间的同时，性能接近使用完整动作空间。虽然摘要未提供具体数据，如准确率提升或效率改进的数值，但结果强调了算法在存在相关性时能显著优化资源利用和计算效率。",
      "conclusion": "本研究的结论是算法能有效解决大型动作空间bandit问题，通过选择代表性动作子集减少计算负担并保持高性能。学术价值在于提出了一种无需先验相关性结构的创新方法，丰富了bandit理论。实际应用价值体现在资源分配和推荐系统等领域效率提升。潜在局限性可能涉及算法对相关性假设的依赖，未来工作可探索更复杂的相关性模型或扩展到其他机器学习场景。",
      "tags": [
        "Bandit Problems",
        "Action Selection",
        "Correlation Handling",
        "Thompson Sampling",
        "Upper Confidence Bound"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:08.462086Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.17799",
    "title": "A Coreset Selection of Coreset Selection Literature: Introduction and Recent Advances",
    "authors": [
      "Brian B. Moser",
      "Arundhati S. Shanbhag",
      "Stanislav Frolov",
      "Federico Raue",
      "Joachim Folz",
      "Andreas Dengel"
    ],
    "abstract": "Coreset selection targets the challenge of finding a small, representative subset of a large dataset that preserves essential patterns for effective machine learning. Although several surveys have examined data reduction strategies before, most focus narrowly on either classical geometry-based methods or active learning techniques. In contrast, this survey presents a more comprehensive view by unifying three major lines of coreset research, namely, training-free, training-oriented, and label-free approaches, into a single taxonomy. We present subfields often overlooked by existing work, including submodular formulations, bilevel optimization, and recent progress in pseudo-labeling for unlabeled datasets. Additionally, we examine how pruning strategies influence generalization and neural scaling laws, offering new insights that are absent from prior reviews. Finally, we compare these methods under varying computational, robustness, and performance demands and highlight open challenges, such as robustness, outlier filtering, and adapting coreset selection to foundation models, for future research.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.17799.pdf",
    "abs_url": "https://arxiv.org/abs/2505.17799",
    "published": "2025-05-23T12:18:34Z",
    "updated": "2026-01-29T16:22:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "本综述论文通过统一coreset selection的三种主要研究方法，提供了一个全面的分类体系，并突出了新兴子领域和未来挑战。",
      "motivation": "Coreset selection旨在从大数据集中选取代表性子集以提升机器学习效率，但现有综述多局限于经典几何方法或主动学习，忽视了更广泛的研究方向。这一问题对于减少计算成本和优化模型性能至关重要，当前方法的不足在于视角狭窄，无法覆盖训练无关、训练导向和无标签等多元化策略，导致实际应用中缺乏综合指导。因此，本文动机是弥补这一空白，提供更全面的综述视角，以推动数据高效学习的发展。",
      "method": "本论文的核心方法是构建一个统一的分类体系，将coreset selection研究整合为训练无关、训练导向和无标签三种主要路径。具体地，深入分析了子模公式、双层优化等子领域，并探讨了伪标签技术在无标签数据集上的应用进展。此外，论文还审查了剪枝策略如何影响模型的泛化能力和神经缩放定律，提供了前人综述中未涉及的新见解，例如通过系统分类和案例比较来揭示方法间的内在联系和适用性。",
      "result": "作为综述论文，本文未提供具体实验数据，但通过比较不同coreset选择方法在计算效率、鲁棒性和性能需求下的表现，总结了各方法的优缺点。例如，分析了训练导向方法在资源受限场景中的优势，以及无标签方法利用伪标签处理未标注数据的潜力。这些比较结果为研究者和从业者提供了实践指南，并指出在多样化应用场景中方法选择的权衡点，有助于优化数据子集的选择策略。",
      "conclusion": "本综述的主要贡献在于提供了一个全面且统一的coreset selection分类，整合了多个被忽视的研究子领域，并揭示了剪枝策略与模型泛化之间的新关联。学术上，它填补了现有文献的空白，促进了该领域的系统化研究；实践上，为机器学习中的数据高效学习提供了参考框架。未来研究方向包括提升coreset的鲁棒性、优化异常值过滤技术，以及将其适应于基础模型等开放挑战，以应对更复杂的实际需求。",
      "tags": [
        "Coreset Selection",
        "Submodular Formulations",
        "Bilevel Optimization",
        "Pseudo-labeling",
        "Neural Scaling Laws"
      ]
    },
    "analyzed_at": "2026-01-30T03:58:51.278248Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.15998",
    "title": "Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics",
    "authors": [
      "Thomas Michel",
      "Marko Cvjetko",
      "Gautier Hamon",
      "Pierre-Yves Oudeyer",
      "Clément Moulin-Frier"
    ],
    "abstract": "We present a method for the automated discovery of system-level dynamics in Flow-Lenia--a continuous cellular automaton (CA) with mass conservation and parameter localization-using a curiosity--driven AI scientist. This method aims to uncover processes leading to self-organization of evolutionary and ecosystemic dynamics in CAs. We build on previous work which uses diversity search algorithms in Lenia to find self-organized individual patterns, and extend it to large environments that support distinct interacting patterns. We adapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive exploration of diverse Flow-Lenia environments using simulation-wide metrics, such as evolutionary activity, compression-based complexity, and multi-scale entropy. We test our method in two experiments, showcasing its ability to illuminate significantly more diverse dynamics compared to random search. We show qualitative results illustrating how ecosystemic simulations enable self-organization of complex collective behaviors not captured by previous individual pattern search and analysis. We complement automated discovery with an interactive exploration tool, creating an effective human-AI collaborative workflow for scientific investigation. Though demonstrated specifically with Flow-Lenia, this methodology provides a framework potentially applicable to other parameterizable complex systems where understanding emergent collective properties is of interest.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.15998.pdf",
    "abs_url": "https://arxiv.org/abs/2505.15998",
    "published": "2025-05-21T20:28:58Z",
    "updated": "2026-01-29T12:57:28Z",
    "comment": "Published at ALife 2025. Project webpage: https://developmentalsystems.org/Exploring-Flow-Lenia-Universes/",
    "light_analysis": {
      "overview": "本研究提出了一种利用好奇心驱动的AI科学家自动发现Flow-Lenia中系统级动态的方法，揭示了多样化生态系统动态的自组织过程。",
      "motivation": "研究旨在解决连续细胞自动机（CA）中系统级动态自动发现的问题，特别是Flow-Lenia这种具有质量守恒和参数局部化的复杂系统。现有方法如多样性搜索算法仅关注个体模式的自组织，难以扩展到大规模环境中的交互模式，限制了理解和探索生态系统动态的能力。因此，开发新方法以揭示复杂集体行为的自组织过程对生态系统建模和自组织理论至关重要。",
      "method": "论文基于内在动机目标探索过程（IMGEPs），将其调整以驱动对Flow-Lenia环境的探索。通过引入模拟范围指标，如进化活动、基于压缩的复杂性和多尺度熵，该方法从先前的个体模式搜索扩展到大环境中的交互模式。实验在Flow-Lenia平台上进行，这是一种连续CA，具有质量守恒和参数局部化特性，使用好奇心驱动的搜索策略来发现系统级动态，并利用多样性搜索算法增强探索。",
      "result": "实验在两个测试中展示，该方法与随机搜索相比，能够揭示更多样化的动态。定性结果显示了生态系统模拟中复杂集体行为的自组织，这是先前个体模式搜索所未捕捉到的。摘要未明确说明具体性能指标如准确率或效率改进，但强调了动态多样性的显著提升，表明该方法在探索生态系统动态方面的有效性。",
      "conclusion": "本研究的主要贡献是提供了一个好奇心驱动的AI科学家方法，用于自动发现Flow-Lenia中的系统级动态，扩展了细胞自动机研究，并为理解涌现集体行为提供了新框架。学术价值在于促进复杂系统探索，实际应用通过交互式工具实现人-AI协作科学工作流。潜在局限性在于特定于Flow-Lenia系统，但框架可能适用于其他参数化复杂系统，未来工作可拓展到更多领域。",
      "tags": [
        "Continuous Cellular Automata",
        "Intrinsically Motivated Goal Exploration Processes",
        "Curiosity-driven AI",
        "Diversity Search",
        "Simulation Metrics"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:23.650336Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.15255",
    "title": "Boosting Large Language Models for Mental Manipulation Detection via Data Augmentation and Distillation",
    "authors": [
      "Yuansheng Gao",
      "Peng Gao",
      "Han Bao",
      "Bin Li",
      "Jixiang Luo",
      "Zonghui Wang",
      "Wenzhi Chen"
    ],
    "abstract": "Mental manipulation on social media poses a covert yet serious threat to individuals' psychological well-being and the integrity of online interactions. Detecting such behavior is challenging due to the difficult-to-annotate training data, its highly covert and multi-turn nature, and the lack of real-world datasets. To address these challenges, we propose MentalMAD, a framework that enhances large language models for mental manipulation detection. Our approach consists of three key components: EvoSA, an annotation-free data augmentation method that combines evolutionary operations with speech-act-aware prompting; teacher-model-generated complementary-task supervision; and Complementary-Convergent Distillation, a phase-wise strategy for transferring manipulation-specific knowledge to student models. We then constructed the ReaMent dataset, comprising 5,000 real-world-sourced dialogues. Extensive experiments show that MentalMAD improves accuracy by 14.0%, macro-F1 by 27.3%, and weighted F1 by 15.1% over the strongest baseline. The code and the dataset are publicly available at https://github.com/Yuansheng-Gao/MentalMAD.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.15255.pdf",
    "abs_url": "https://arxiv.org/abs/2505.15255",
    "published": "2025-05-21T08:34:06Z",
    "updated": "2026-01-29T12:28:17Z",
    "comment": "Accepted to WWW 2026",
    "light_analysis": {
      "overview": "本研究提出了MentalMAD框架，通过数据增强和知识蒸馏提升大型语言模型在心理操控检测中的性能。",
      "motivation": "社交媒体上的心理操控行为是一种隐蔽但严重的威胁，危害个人心理健康和在线互动完整性。现有检测方法面临训练数据难以标注、行为高度隐蔽且多方参与、以及缺乏真实数据集的挑战。这些问题导致检测准确性不足，因此开发有效的方法至关重要，以应对现实世界中的潜在风险并保护用户安全。",
      "method": "论文提出了MentalMAD框架，核心包括三个组件：首先，EvoSA是一种无标注数据增强方法，结合进化操作和语音行为感知提示生成训练数据；其次，利用教师模型生成互补任务监督，提供额外的学习信号；最后，采用Complementary-Convergent Distillation策略，分阶段将操控特定知识蒸馏到学生模型中。此外，构建了ReaMent数据集，包含5,000个真实世界对话，用于训练和评估模型性能。",
      "result": "实验结果表明，MentalMAD框架显著提升了检测效果。与最强基线相比，准确率提高了14.0%，macro-F1分数提升了27.3%，加权F1分数提升了15.1%。这些改进在真实数据集ReaMent上得到了验证，显示出该方法在心理操控检测任务中的优越性能，为后续研究提供了坚实的数据支持。",
      "conclusion": "本研究的贡献在于提出了MentalMAD框架，通过结合数据增强和知识蒸馏有效解决了心理操控检测的挑战。构建的ReaMent数据集为领域提供了宝贵的资源。该研究具有重要的学术价值和实际应用意义，有助于在线平台识别有害行为。未来工作可探索更多模型优化或扩展到其他类似任务，以进一步提升检测能力。",
      "tags": [
        "Large Language Models",
        "Data Augmentation",
        "Knowledge Distillation",
        "Speech-Act-Aware Prompting",
        "Evolutionary Operations"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:12.567363Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.13258",
    "title": "Towards Transparent RAG: Fostering Evidence Traceability in LLM Generation via Reinforcement Learning",
    "authors": [
      "Jingyi Ren",
      "Yekun Xu",
      "Xiaolong Wang",
      "Weitao Li",
      "Ante Wang",
      "Weizhi Ma",
      "Yang Liu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) delivers substantial value in knowledge-intensive applications. However, its generated responses often lack transparent reasoning paths that trace back to source evidence from retrieved documents. This opacity not only compromises the interpretability of the output but also limits the model's ability to fully exploit the provided context. To address this, we propose TRACE (Transparent RAG with evidenCE tracing), a framework designed to enhance evidence traceability in Large Language Models (LLMs) through reinforcement learning (RL). TRACE guides LLMs to produce structured outputs with explicit evidence citations by prompting and rewarding evidence relevance and proper formatting, alongside accuracy, to optimize structured traceability. To ensure training stability with multiple reward signals, we further introduce an adaptive strategy for merging rewards and adopt a stabilized KL-divergence estimator. Experiments on three multi-hop QA datasets using Qwen2.5-7B-Instruct and Llama-3.1-8B-Instruct show that TRACE achieves both transparent, evidence-attributed outputs and accuracy improvements of 10-30%. The resulting performance is comparable to advanced commercial LLMs (e.g., OpenAI o1, DeepSeek-R1). Further analyses demonstrate strong generalization capabilities to unseen tasks. Our code is publicly available now.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.13258.pdf",
    "abs_url": "https://arxiv.org/abs/2505.13258",
    "published": "2025-05-19T15:40:29Z",
    "updated": "2026-01-29T12:48:10Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出TRACE框架，通过强化学习增强检索增强生成（RAG）在大型语言模型中的证据可追溯性，生成结构化的透明输出。",
      "motivation": "检索增强生成（RAG）在知识密集型应用中具有重要价值，但现有方法生成的响应往往缺乏透明推理路径，难以追溯到检索文档中的源证据。这种不透明性损害了输出的可解释性，并限制了模型充分利用上下文的能力。因此，需要一种新方法来增强证据可追溯性，以提高RAG的可靠性和在实际任务中的表现，以克服传统方法在透明性上的不足。",
      "method": "TRACE框架利用强化学习（RL）引导大型语言模型（LLMs）生成带有明确证据引用的结构化输出。通过设计奖励机制，鼓励证据相关性、正确格式和准确性，优化结构化可追溯性。为处理多个奖励信号并确保训练稳定性，引入了自适应奖励合并策略和稳定化的KL散度估计器。实验中使用Qwen2.5-7B-Instruct和Llama-3.1-8B-Instruct模型在三个多跳QA数据集上进行验证，以评估方法效果。",
      "result": "在三个多跳QA数据集上的实验结果显示，TRACE框架不仅生成了透明且证据可追溯的输出，还实现了准确性提升，幅度为10-30%。使用Qwen2.5-7B-Instruct和Llama-3.1-8B-Instruct模型，TRACE的性能与OpenAI o1和DeepSeek-R1等先进商业LLM相当。进一步分析表明，该框架对未见任务具有强泛化能力，代码已公开以支持进一步研究。",
      "conclusion": "TRACE框架通过强化学习显著增强了RAG的证据可追溯性，提升了输出透明度和准确性，并展示了良好的泛化性能。该研究具有重要的学术价值，为可解释AI提供了新方法，并在问答系统等知识密集型应用中具有实际应用潜力。未来工作可探索在不同任务或更大模型中的应用，并优化奖励机制以进一步提升性能，摘要未明确说明具体局限性。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Reinforcement Learning",
        "Large Language Models",
        "Evidence Traceability",
        "Multi-hop QA"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:04.068985Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.13140",
    "title": "CacheFlow: Fast Human Motion Prediction by Cached Normalizing Flow",
    "authors": [
      "Takahiro Maeda",
      "Jinkun Cao",
      "Norimichi Ukita",
      "Kris Kitani"
    ],
    "abstract": "Many density estimation techniques for 3D human motion prediction require a significant amount of inference time, often exceeding the duration of the predicted time horizon. To address the need for faster density estimation for 3D human motion prediction, we introduce a novel flow-based method for human motion prediction called CacheFlow. Unlike previous conditional generative models that suffer from poor time efficiency, CacheFlow takes advantage of an unconditional flow-based generative model that transforms a Gaussian mixture into the density of future motions. The results of the computation of the flow-based generative model can be precomputed and cached. Then, for conditional prediction, we seek a mapping from historical trajectories to samples in the Gaussian mixture. This mapping can be done by a much more lightweight model, thus saving significant computation overhead compared to a typical conditional flow model. In such a two-stage fashion and by caching results from the slow flow model computation, we build our CacheFlow without loss of prediction accuracy and model expressiveness. This inference process is completed in approximately one millisecond, making it 4 times faster than previous VAE methods and 30 times faster than previous diffusion-based methods on standard benchmarks such as Human3.6M and AMASS datasets. Furthermore, our method demonstrates improved density estimation accuracy and comparable prediction accuracy to a SOTA method on Human3.6M. Our code and models are available at https://github.com/meaten/CacheFlow.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2505.13140.pdf",
    "abs_url": "https://arxiv.org/abs/2505.13140",
    "published": "2025-05-19T14:09:45Z",
    "updated": "2026-01-29T06:43:16Z",
    "comment": "Accepted at Transactions on Machine Learning Research (TMLR). See https://openreview.net/forum?id=y8dGdBJkWa",
    "light_analysis": {
      "overview": "CacheFlow提出了一种基于缓存的归一化流方法，通过两阶段架构显著加速3D人体运动预测的推理速度。",
      "motivation": "3D人体运动预测中的密度估计技术通常需要大量推理时间，甚至超过预测时间范围，这限制了实时应用如虚拟现实和动画制作。现有条件生成模型如VAE和扩散模型虽准确但效率低下，无法满足快速预测需求。因此，开发更高效的密度估计方法成为关键问题。",
      "method": "CacheFlow采用无条件的基于流的生成模型，将高斯混合分布转换为未来运动的密度，并预计算缓存结果。关键创新在于两阶段架构：首先使用无条件的流模型生成密度，然后通过轻量级模型将历史轨迹映射到高斯混合中的样本，从而避免条件流模型的高计算成本，保持预测准确性和模型表达能力。",
      "result": "实验显示，CacheFlow的推理过程仅需约1毫秒，在Human3.6M和AMASS数据集上，比先前VAE方法快4倍，比扩散模型快30倍。密度估计准确率有所提升，预测准确率与先进方法相当，验证了方法的高效性和性能优势。",
      "conclusion": "论文主要贡献是提出CacheFlow方法，实现了快速且准确的3D人体运动预测，通过缓存机制优化推理速度，具有学术价值和应用潜力。未来工作可扩展至其他时间序列预测任务，并进一步优化模型性能（摘要未明确说明具体方向）。",
      "tags": [
        "Normalizing Flow",
        "Caching",
        "Human Motion Prediction",
        "Density Estimation",
        "Generative Model"
      ]
    },
    "analyzed_at": "2026-01-30T03:59:55.846359Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.12129",
    "title": "Metric Graph Kernels via the Tropical Torelli Map",
    "authors": [
      "Yueqi Cao",
      "Anthea Monod"
    ],
    "abstract": "We introduce the first graph kernels for metric graphs via tropical algebraic geometry. In contrast to conventional graph kernels based on graph combinatorics such as nodes, edges, and subgraphs, our metric graph kernels are purely based on the geometry and topology of the underlying metric space. A key characterizing property of our construction is its invariance under edge subdivision, making the kernels intrinsically well-suited for comparing graphs representing different underlying metric spaces. We develop efficient algorithms to compute our kernels and analyze their complexity, which depends primarily on the genus of the input graphs rather than their size. Through experiments on synthetic data and selected real-world datasets, we demonstrate that our kernels capture complementary geometric and topological information overseen by standard combinatorial approaches, particularly in label-free settings. We further showcase their practical utility with an urban road network classification task.",
    "categories": [
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.12129.pdf",
    "abs_url": "https://arxiv.org/abs/2505.12129",
    "published": "2025-05-17T20:00:50Z",
    "updated": "2026-01-29T08:07:52Z",
    "comment": "26 pages, 11 figures",
    "light_analysis": {
      "overview": "通过热带代数几何首次引入度量图核，基于图的几何和拓扑特征，增强了在度量空间比较中的有效性和不变性。",
      "motivation": "传统图核方法依赖于图的组合结构，如节点和边的统计，但忽略了底层度量空间的几何和拓扑信息，这在无标签或空间相关任务中限制了性能。现有方法不足在于无法有效捕捉图形的几何不变性，导致在比较不同度量空间图时准确性不足。本研究旨在解决这一问题，提出一种基于几何和拓扑的图核，以提升图比较的鲁棒性和实用性。",
      "method": "论文提出基于热带代数几何的度量图核，核心创新是构造在边细分下保持不变的核函数，使其不依赖于特定组合表示，而是反映几何和拓扑本质。算法高效，复杂度主要取决于图的亏格而非大小，适合处理复杂图形。开发了计算方法，应用到合成和真实数据集，摘要未明确具体架构，但强调几何不变性作为技术特色。",
      "result": "实验表明，该度量图核能捕捉标准组合方法忽略的几何和拓扑信息，在合成数据和真实数据集上表现良好，尤其在无标签设置下优于基线方法。例如，在城市路网分类任务中展示了实用价值，但具体性能指标如准确率提升在摘要中未明确说明，仅暗示了互补性和改进效果。",
      "conclusion": "本文贡献在于通过热带代数几何引入首个度量图核，为图比较提供了新几何视角，学术上连接代数几何和图论，扩展了图核理论。实际应用中，在空间数据分类如路网分析有潜力，未来工作可能包括扩展到其他数据集或优化效率，摘要未明确局限性，但暗示了进一步探索方向。",
      "tags": [
        "Metric Graph Kernels",
        "Tropical Algebraic Geometry",
        "Edge Subdivision Invariance",
        "Topological Features",
        "Genus Complexity"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:04.935136Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.11766",
    "title": "Redefining Neural Operators in $d+1$ Dimensions for Embedding Evolution",
    "authors": [
      "Haoze Song",
      "Zhihao Li",
      "Xiaobo Zhang",
      "Zecheng Gan",
      "Zhilu Lai",
      "Wei Wang"
    ],
    "abstract": "Neural Operators (NOs) have emerged as powerful tools for learning mappings between function spaces. Among them, the kernel integral operator has been widely used in universally approximating architectures. Following the original formulation, most advancements focus on designing better parameterizations for the kernel over the original physical domain (with $d$ spatial dimensions, $d\\in{1,2,3,\\ldots}$). In contrast, embedding evolution remains largely unexplored, which often drives models toward brute-force embedding lengthening to improve approximation, but at the cost of substantially increased computation.   In this paper, we introduce an auxiliary dimension that explicitly models embedding evolution in operator form, thereby redefining the NO framework in $d+1$ dimensions (the original $d$ dimensions plus one auxiliary dimension). Under this formulation, we develop a Schrödingerised Kernel Neural Operator (SKNO), which leverages Fourier-based operators to model the $d+1$ dimensional evolution. Across more than ten increasingly challenging benchmarks, ranging from the 1D heat equation to the highly nonlinear 3D Rayleigh-Taylor instability, SKNO consistently outperforms other baselines. We further validate its resolution invariance under mixed-resolution training and super-resolution inference, and evaluate zero-shot generalization to unseen temporal regimes. In addition, we present a broader set of design choices for the lifting and recovery operators, demonstrating their impact on SKNO's predictive performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.11766.pdf",
    "abs_url": "https://arxiv.org/abs/2505.11766",
    "published": "2025-05-17T00:15:00Z",
    "updated": "2026-01-29T15:18:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文通过引入一个辅助维度重新定义神经算子框架，并提出Schrödingerised Kernel Neural Operator以显式建模嵌入演化，提升逼近效果并减少计算成本。",
      "motivation": "神经算子在函数空间映射学习中有广泛应用，但现有研究常忽略嵌入演化问题，导致模型通过暴力延长嵌入长度来提高逼近精度，这显著增加了计算负担。嵌入演化研究不足限制了神经算子的效率和扩展性，尤其是在处理高维和非线性物理问题时。因此，需要一种新方法来显式建模嵌入演化，以平衡逼近精度和计算效率，这对于推动神经算子在复杂模拟等领域的应用至关重要。",
      "method": "论文提出在原始d维空间基础上增加一个辅助维度，将神经算子框架扩展到d+1维，以显式建模嵌入演化。基于此，开发了Schrödingerised Kernel Neural Operator（SKNO），该算子利用基于傅里叶的算子来建模d+1维演化过程，避免暴力延长嵌入长度。关键创新在于将嵌入演化视为算子形式，并引入傅里叶基操作来高效计算。研究使用了多个基准数据集，如1D热方程和3D Rayleigh-Taylor不稳定性，以评估模型性能。",
      "result": "在十多个逐渐增加的挑战性基准测试中，SKNO consistently outperforms other baselines，覆盖从一维热方程到高度非线性三维Rayleigh-Taylor不稳定性等问题。论文验证了SKNO在混合分辨率训练和超分辨率推理下的分辨率不变性，表明模型能处理不同分辨率数据而不损失性能。此外，评估了对未见时间机制的零样本泛化能力，展示了模型在未知时间范围内的预测可靠性，突出了其优越性能和泛化能力。",
      "conclusion": "本文通过引入辅助维度重新定义了神经算子框架，并提出Schrödingerised Kernel Neural Operator来显式建模嵌入演化，有效解决了计算效率低的问题并提高了逼近精度。该研究为神经算子设计提供了新思路，具有扩展算子学习理论的学术价值，实际应用在于支持更高效的物理模拟和预测，特别是在混合分辨率和超分辨率场景下。未来工作可以进一步探索提升和恢复算子的设计选择，以优化模型性能。",
      "tags": [
        "Neural Operators",
        "Kernel Integral Operator",
        "Embedding Evolution",
        "Fourier-based Operators",
        "Schrödingerised Kernel Neural Operator"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:29.166618Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.05029",
    "title": "Reputation as a Solution to Cooperation Collapse in LLM-based MASs",
    "authors": [
      "Siyue Ren",
      "Wanli Fu",
      "Xinkun Zou",
      "Chen Shen",
      "Yi Cai",
      "Chen Chu",
      "Zhen Wang",
      "Shuyue Hu"
    ],
    "abstract": "Cooperation has long been a fundamental topic in both human society and AI systems. However, recent studies indicate that the collapse of cooperation may emerge in multi-agent systems (MASs) driven by large language models (LLMs). To address this challenge, we explore reputation systems as a remedy. We propose RepuNet, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through three distinct scenarios, we show that RepuNet effectively avoids cooperation collapse, promoting and sustaining cooperation in LLM-based MASs. Moreover, we find that reputation systems can give rise to rich emergent behaviors in LLM-based MASs, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones. The GitHub repository for our project can be accessed via the following link: https://github.com/RGB-0000FF/RepuNet.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.05029.pdf",
    "abs_url": "https://arxiv.org/abs/2505.05029",
    "published": "2025-05-08T08:02:20Z",
    "updated": "2026-01-29T15:30:02Z",
    "comment": "Published as a conference paper at AAMAS 2026",
    "light_analysis": {
      "overview": "该论文提出了RepuNet，一个动态双层声誉框架，用于解决基于大型语言模型的多智能体系统中的合作崩溃问题。",
      "motivation": "合作在人类社会和人工智能系统中一直至关重要，但近期研究表明，在基于大型语言模型（LLMs）驱动的多智能体系统（MASs）中，合作可能会崩溃，这阻碍了系统的有效协同和任务完成。现有方法可能缺乏动态声誉机制来稳定代理交互，导致合作难以维持。因此，本研究旨在探索声誉系统作为补救措施，通过建模声誉动态来避免合作崩溃，提升LLM-based MASs的鲁棒性和实用性，解决现有方法在促进长期合作方面的不足。",
      "method": "本研究提出RepuNet，一个动态双层声誉框架，同时建模代理级声誉动态和系统级网络演化。关键创新包括：通过直接交互和间接八卦驱动代理形成自我和同伴声誉，并基于此决策连接或断开其他代理以优化未来互动；双层结构允许动态调整代理关系和网络拓扑，整合LLMs处理复杂社交行为。技术特色在于利用八卦机制增强声誉传播，促进系统级协作。摘要未明确说明使用的具体数据集或模型架构，但框架设计适用于多样化的LLM-based MASs场景。",
      "result": "通过三个不同场景的实验，RepuNet被证明能有效避免合作崩溃，显著促进和维持基于LLM的多智能体系统中的合作。虽然摘要未提供具体性能指标如准确率或效率提升，但实验结果显示了系统在防止合作崩溃方面的成功，与基线方法相比，RepuNet通过声誉系统实现了更稳定的合作环境。此外，研究观察到丰富的新兴行为，如合作集群的形成、剥削性代理的社会隔离，以及代理更倾向于分享正面八卦而非负面八卦，进一步验证了声誉系统的有效性。",
      "conclusion": "本论文的主要贡献是提出RepuNet，一个动态双层声誉框架，有效解决了基于LLM的多智能体系统中的合作崩溃问题。学术上，它探索了声誉系统在LLM-based MASs中的新应用，揭示了声誉机制如何促进合作并引发新兴行为，如集群形成和社会偏好。实际应用价值在于增强多智能体系统的合作稳定性和效率，适用于协同任务、社交模拟等领域。摘要未明确说明研究的局限性或具体未来工作方向，但潜在方向可能包括扩展框架到更多复杂场景或集成其他AI技术以优化性能。",
      "tags": [
        "Large Language Models",
        "Multi-Agent Systems",
        "Reputation Systems",
        "Gossip",
        "Emergent Behaviors"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:58.205604Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.03797",
    "title": "Utilising Gradient-Based Proposals Within Sequential Monte Carlo Samplers for Training of Partial Bayesian Neural Networks",
    "authors": [
      "Andrew Millard",
      "Joshua Murphy",
      "Simon Maskell",
      "Zheng Zhao"
    ],
    "abstract": "Partial Bayesian neural networks (pBNNs) have been shown to perform competitively with fully Bayesian neural networks while only having a subset of the parameters be stochastic. Using sequential Monte Carlo (SMC) samplers as the inference method for pBNNs gives a non-parametric probabilistic estimation of the stochastic parameters, and has shown improved performance over parametric methods. In this paper we introduce a new SMC-based training method for pBNNs by utilising a guided proposal and incorporating gradient-based Markov kernels, which gives us better scalability on high dimensional problems. We show that our new method outperforms the state-of-the-art in terms of predictive performance and optimal loss. We also show that pBNNs scale well with larger batch sizes, resulting in significantly reduced training times and often better performance.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.03797.pdf",
    "abs_url": "https://arxiv.org/abs/2505.03797",
    "published": "2025-05-01T20:05:38Z",
    "updated": "2026-01-29T16:52:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一种新的基于顺序蒙特卡洛采样器的训练方法，通过结合指导性提议和基于梯度的马尔可夫核，提升了部分贝叶斯神经网络的训练效率和性能。",
      "motivation": "部分贝叶斯神经网络通过只让一部分参数随机化来降低计算成本，同时保持贝叶斯方法的概率建模优势。顺序蒙特卡洛采样器作为推断方法提供非参数概率估计，优于参数方法，但在高维问题中面临可扩展性挑战。因此，本研究旨在开发一种改进的训练方法，以解决现有SMC方法在高维设置下的效率和性能不足。",
      "method": "论文提出了一种新的训练方法，基于顺序蒙特卡洛采样器，引入指导性提议来优化采样过程，并结合基于梯度的马尔可夫核以增强在高维空间中的推断效率。这种方法旨在提升部分贝叶斯神经网络的参数推断速度和准确性，通过改进提议机制和核函数来提高可扩展性。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "实验结果显示，新方法在预测性能和最优损失方面优于现有最先进技术。部分贝叶斯神经网络在较大批次规模下扩展良好，导致训练时间显著减少，并且通常性能更好。摘要未提供具体的数值指标，但强调了在性能提升和效率改进方面的优势。",
      "conclusion": "本研究的核心贡献在于提出了一种创新的训练策略，整合了指导性提议和基于梯度的马尔可夫核，显著改善了部分贝叶斯神经网络的推断过程。这为贝叶斯方法在高维机器学习问题中的应用提供了更高效和可扩展的解决方案。摘要未明确说明研究的局限性或未来工作方向。",
      "tags": [
        "Partial Bayesian Neural Networks",
        "Sequential Monte Carlo Samplers",
        "Gradient-Based Markov Kernels",
        "Guided Proposals"
      ]
    },
    "analyzed_at": "2026-01-30T04:00:59.281262Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.00570",
    "title": "FreqKV: Key-Value Compression in Frequency Domain for Context Window Extension",
    "authors": [
      "Jushi Kai",
      "Yixuan Wang",
      "Boyi Zeng",
      "Haoli Bai",
      "Bo Jiang",
      "Ziwei He",
      "Zhouhan Lin"
    ],
    "abstract": "Existing key-value (KV) cache compression methods for large language models (LLMs) often rely on token eviction, which risks losing critical local information in both long prefilling and decoding scenarios. When extrapolating beyond the pretrained context length, their performance degrades sharply on long-context benchmarks. Motivated by the observation in the frequency domain that the context information is concentrated in the low-frequency components, we propose FreqKV, a parameter-free and architecture-agnostic approach. It iteratively compresses the increasing KV cache in the frequency domain, allowing models to process lengthy contexts efficiently. With minimal training at 8K length, FreqKV extends the context window of LLaMA-2-7B up to 256K tokens while maintaining stable perplexity. Extensive experiments across prefilling and decoding demonstrate that FreqKV enables robust context window extension and consistently outperforms existing KV cache compression methods on LLaMA-2 and LLaMA-3, highlighting its effectiveness for both understanding and generation in long contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.00570.pdf",
    "abs_url": "https://arxiv.org/abs/2505.00570",
    "published": "2025-05-01T14:53:12Z",
    "updated": "2026-01-29T14:31:34Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "FreqKV通过频率域压缩键值缓存，提出一种无需参数和架构无关的方法，有效扩展大语言模型的上下文窗口。",
      "motivation": "该研究旨在解决大语言模型处理长上下文时的键值缓存压缩问题。现有方法主要依赖令牌淘汰策略，在长预填充和解码场景中可能丢失关键的局部信息，导致性能下降，尤其在扩展到预训练上下文长度之外时表现急剧恶化。因此，需要一种能保留核心信息、高效处理长文本的压缩技术，以支持模型在理解和生成任务中的鲁棒性。",
      "method": "论文提出FreqKV方法，基于观察到频率域中上下文信息集中在低频分量，通过迭代压缩频率域中的键值缓存来实现压缩。该方法无需额外参数，架构无关，适用于各种大语言模型。关键步骤包括将KV缓存转换到频率域，选择低频分量进行压缩，并在处理过程中动态更新。通过最少训练（如在8K长度上），FreqKV能扩展到更长上下文，提高计算效率。",
      "result": "实验结果显示，FreqKV能将LLaMA-2-7B的上下文窗口扩展到256K令牌，同时保持稳定的困惑度。在预填充和解码任务中，该方法在长上下文基准测试上一致优于现有的KV缓存压缩方法，如在LLaMA-2和LLaMA-3模型上表现鲁棒，突出了其在扩展上下文窗口方面的有效性和通用性。摘要未提供具体性能指标数据。",
      "conclusion": "FreqKV的主要贡献是提出了一种新颖的频率域压缩技术，无需参数和架构依赖，有效扩展大语言模型的上下文窗口，提升了长文本处理能力。这项研究对于文档理解、代码生成等实际应用具有重要价值，未来工作可包括进一步优化压缩算法或扩展到更多模型和任务场景。摘要未明确说明局限性。",
      "tags": [
        "Key-Value Cache Compression",
        "Frequency Domain Analysis",
        "Context Window Extension",
        "Parameter-Free Method",
        "Large Language Model"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:10.795574Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.14250",
    "title": "Towards Anomaly-Aware Pre-Training and Fine-Tuning for Graph Anomaly Detection",
    "authors": [
      "Yunhui Liu",
      "Jiashun Cheng",
      "Yiqing Lin",
      "Qizhuo Xie",
      "Jia Li",
      "Fugee Tsung",
      "Hongzhi Yin",
      "Tao Zheng",
      "Jianhua Zhao",
      "Tieke He"
    ],
    "abstract": "Graph anomaly detection (GAD) has garnered increasing attention in recent years, yet remains challenging due to two key factors: (1) label scarcity stemming from the high cost of annotations and (2) homophily disparity at node and class levels. In this paper, we introduce Anomaly-Aware Pre-Training and Fine-Tuning (APF), a targeted and effective framework to mitigate the above challenges in GAD. In the pre-training stage, APF incorporates node-specific subgraphs selected via the Rayleigh Quotient, a label-free anomaly metric, into the learning objective to enhance anomaly awareness. It further introduces two learnable spectral polynomial filters to jointly learn dual representations that capture both general semantics and subtle anomaly cues. During fine-tuning, a gated fusion mechanism adaptively integrates pre-trained representations across nodes and dimensions, while an anomaly-aware regularization loss encourages abnormal nodes to preserve more anomaly-relevant information. Furthermore, we theoretically show that APF tends to achieve linear separability under mild conditions. Comprehensive experiments on 10 benchmark datasets validate the superior performance of APF in comparison to state-of-the-art baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2504.14250.pdf",
    "abs_url": "https://arxiv.org/abs/2504.14250",
    "published": "2025-04-19T09:57:35Z",
    "updated": "2026-01-29T03:57:42Z",
    "comment": "Accepted by ICLR 2026",
    "light_analysis": {
      "overview": "论文提出了异常感知预训练和微调框架（APF），通过谱多项式滤波器和异常感知正则化，有效解决图异常检测中的标签稀缺和同质性差异问题。",
      "motivation": "图异常检测在网络安全、金融欺诈等应用中至关重要，但面临两大挑战：一是标注成本高导致标签稀缺，二是节点和类级别的同质性差异使得异常检测困难。现有方法多依赖大量标注数据或忽略同质性差异，限制了在真实场景中的泛化能力。APF框架旨在通过无监督预训练和自适应微调来弥补这些不足，提升检测的准确性和鲁棒性。",
      "method": "APF框架包括预训练和微调两个阶段。预训练阶段使用Rayleigh Quotient作为无标签异常度量选择节点特定子图，并引入两个可学习谱多项式滤波器学习双重表示，分别捕获一般语义和异常线索。微调阶段采用门控融合机制自适应整合预训练表示，结合异常感知正则化损失鼓励异常节点保留相关信息。该方法在10个基准数据集上实施，模型架构集成谱滤波器技术。",
      "result": "在10个基准数据集上的综合实验表明，APF在性能上优于最先进的基线方法，验证了其有效性。理论分析显示，在温和条件下APF倾向于实现线性可分性，为模型提供了理论保证。摘要未明确说明具体准确率提升等数据，但实验结果确认了其在多个数据集上的优越性，展现了更好的异常检测能力。",
      "conclusion": "APF框架成功解决了图异常检测的标签稀缺和同质性差异挑战，通过创新结合预训练、谱多项式滤波器和异常感知正则化，提高了检测性能。该研究具有学术价值，为图学习领域提供了新的异常感知方法，并可能扩展到其他图任务。摘要未明确说明局限性或未来工作，但可推断潜在方向包括应用到更复杂场景或与其他技术结合。",
      "tags": [
        "Graph Anomaly Detection",
        "Pre-Training",
        "Fine-Tuning",
        "Spectral Polynomial Filters",
        "Anomaly-Aware Regularization"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:16.355256Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.14224",
    "title": "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models",
    "authors": [
      "Yongguang Li",
      "Jindong Li",
      "Qi Wang",
      "Qianli Xing",
      "Runliang Niu",
      "Shengsheng Wang",
      "Menglin Yang"
    ],
    "abstract": "Vision-language models (VLMs) have gained widespread attention for their strong zero-shot capabilities across numerous downstream tasks. However, these models assume that each test image's class label is drawn from a predefined label set and lack a reliable mechanism to reject samples from emerging unknown classes when only unlabeled data are available. To address this gap, open-set domain adaptation methods retrain models to push potential unknowns away from known clusters. Yet, some unknown samples remain stably anchored to specific known classes in the VLM feature space due to semantic relevance, which is termed as Semantic Affinity Anchoring (SAA). Forcibly repelling these samples unavoidably distorts the native geometry of VLMs and degrades performance. Meanwhile, existing score-based unknown detectors use simplistic thresholds and suffer from threshold sensitivity, resulting in sub-optimal performance. To address aforementioned issues, we propose VLM-OpenXpert, which comprises two training-free, plug-and-play inference modules. SUFF performs SVD on high-confidence unknowns to extract a low-rank \"unknown subspace\". Each sample's projection onto this subspace is weighted and softly removed from its feature, suppressing unknown components while preserving semantics. BGAT corrects score skewness via a Box-Cox transform, then fits a bimodal Gaussian mixture to adaptively estimate the optimal threshold balancing known-class recognition and unknown-class rejection. Experiments on 9 benchmarks and three backbones (CLIP, SigLIP, ALIGN) under source-free OSDA settings show that our training-free pipeline matches or outperforms retraining-heavy state-of-the-art methods, establishing a powerful lightweight inference calibration paradigm for open-set VLM deployment.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2504.14224.pdf",
    "abs_url": "https://arxiv.org/abs/2504.14224",
    "published": "2025-04-19T08:12:19Z",
    "updated": "2026-01-29T04:29:06Z",
    "comment": "Core methods unchanged; title updated and full-text narrative refined for clarity and logical coherence. No changes to key findings and conclusions",
    "light_analysis": {
      "overview": "提出一种免训练的开放集域适应方法VLM-OpenXpert，通过SUFF和BGAT模块解决视觉语言模型中未知类过滤问题，无需重训练即可校准推理。",
      "motivation": "视觉语言模型(VLMs)在零样本任务中表现强劲，但默认测试类标签来自预定义集合，无法可靠拒绝新兴未知类样本。现有开放集域适应方法通过重训练推开未知样本，但由于语义相关性导致的Semantic Affinity Anchoring (SAA)，部分未知样本与已知类锚定，强行分离会扭曲VLM特征空间并降低性能。同时，基于分数的未知检测器使用简单阈值，阈值敏感性导致性能不佳。因此，需要开发免训练方法来有效过滤未知类，同时保持VLM原生几何和性能。",
      "method": "论文提出VLM-OpenXpert，包含两个免训练、即插即用的推理模块。SUFF模块对高置信度未知样本进行奇异值分解(SVD)，提取低秩未知子空间，并通过投影和加权软移除来抑制未知成分，同时保留语义信息。BGAT模块使用Box-Cox变换校正分数偏斜，然后拟合双峰高斯混合模型自适应估计最优阈值，以平衡已知类识别和未知类拒绝。该方法在源无关设置下工作，直接应用于现有VLM骨干（如CLIP、SigLIP、ALIGN），无需模型重训练。",
      "result": "在9个基准数据集和三种VLM骨干（CLIP、SigLIP、ALIGN）上的实验表明，在源无关开放集域适应(OSDA)设置下，该免训练管道匹配或优于需要重训练的最先进方法。这证明了VLM-OpenXpert在保持轻量级推理的同时，有效提升了未知类过滤和已知类识别的性能，为开放集VLM部署提供了高效的校准范式。摘要未明确说明具体性能指标数据，但强调整体效果显著。",
      "conclusion": "VLM-OpenXpert的主要贡献是提出了一种免训练的开放集域适应框架，通过SUFF和BGAT模块解决SAA和阈值敏感性问题，无需重训练即可校准VLM推理。该研究在学术上为视觉语言模型的开放集域适应提供了新方法，实际应用中为部署轻量级VLM系统提供了可行方案，有助于促进开放集环境下的模型泛化。局限性如对特定VLM骨干的依赖性摘要未明确说明，未来工作可扩展到更多变体和领域。",
      "tags": [
        "Vision-Language Models (VLM)",
        "Open Set Domain Adaptation (OSDA)",
        "Singular Value Decomposition (SVD)",
        "Gaussian Mixture Model (GMM)",
        "Box-Cox Transform"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:35.676055Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2504.12588",
    "title": "Plain Transformers Can be Powerful Graph Learners",
    "authors": [
      "Liheng Ma",
      "Soumyasundar Pal",
      "Yingxue Zhang",
      "Philip H. S. Torr",
      "Mark Coates"
    ],
    "abstract": "Transformers have attained outstanding performance across various modalities, owing to their simple but powerful scaled-dot-product (SDP) attention mechanisms. Researchers have attempted to migrate Transformers to graph learning, but most advanced Graph Transformers (GTs) have strayed far from plain Transformers, exhibiting major architectural differences either by integrating message-passing or incorporating sophisticated attention mechanisms. These divergences hinder the easy adoption of training advances for Transformers developed in other domains. Contrary to previous GTs, this work demonstrates that the plain Transformer architecture can be a powerful graph learner. To achieve this, we propose to incorporate three simple, minimal, and easy-to-implement modifications to the plain Transformer architecture to construct our Powerful Plain Graph Transformers (PPGT): (1) simplified $L_2$ attention for measuring the magnitude closeness among tokens; (2) adaptive root-mean-square normalization to preserve token magnitude information; and (3) a simple MLP-based stem for graph positional encoding. Consistent with its theoretical expressivity, PPGT demonstrates noteworthy realized expressivity on the empirical graph expressivity benchmark, comparing favorably to more complicated alternatives such as subgraph GNNs and higher-order GNNs. Its empirical performance across various graph datasets also justifies the effectiveness of PPGT. This finding underscores the versatility of plain Transformer architectures and highlights their strong potential as a unified backbone for multimodal learning across language, vision, and graph domains.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2504.12588.pdf",
    "abs_url": "https://arxiv.org/abs/2504.12588",
    "published": "2025-04-17T02:06:50Z",
    "updated": "2026-01-29T08:50:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究通过三个简单修改，使普通Transformer架构能够成为强大的图学习者，性能优于复杂图Transformer方法。",
      "motivation": "Transformer在语言和视觉等模态中表现出色，但在图学习领域，现有图Transformer（GTs）通常偏离普通架构，整合了消息传递或复杂注意力机制，导致难以利用其他领域训练的Transformer的进展。这一问题阻碍了跨模态学习的一致性，使得图学习无法轻松受益于Transformer的通用优势。因此，本研究旨在探索普通Transformer在图学习中的潜力，解决现有方法复杂且不统一的问题。",
      "method": "论文提出Powerful Plain Graph Transformers（PPGT），对普通Transformer架构进行三个简单修改：首先，采用简化L2注意力来测量token之间的幅度接近度；其次，引入自适应均方根归一化以保留token的幅度信息；最后，使用简单的基于MLP的stem作为图位置编码。这些修改避免了复杂的消息传递或注意力变体，保持了架构的简洁性和易实现性，从而支持普通Transformer的直接迁移。",
      "result": "PPGT在理论表达能力和经验图表达基准上表现优异，优于更复杂的替代方案如子图GNNs和更高阶GNNs。跨多个图数据集的实验也验证了其有效性，尽管摘要未提供具体性能指标，但结果表明PPGT在表达性和实证性能上与先进方法相当或更优，突显了其作为强大图学习者的潜力。",
      "conclusion": "本研究的核心贡献在于证明了普通Transformer架构通过简单修改即可成为有效的图学习者，强调了Transformer的多样性和跨模态通用性。这为语言、视觉和图域的统一骨干学习提供了新方向，促进了多模态集成。未来可进一步优化细节或扩展到更广泛的应用，解决潜在局限性如计算效率。",
      "tags": [
        "Transformer",
        "Graph Learning",
        "Attention Mechanism",
        "Graph Neural Networks",
        "Positional Encoding"
      ]
    },
    "analyzed_at": "2026-01-30T04:01:49.684647Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.07520",
    "title": "From Limited Labels to Open Domains:An Efficient Learning Method for Drone-view Geo-Localization",
    "authors": [
      "Zhongwei Chen",
      "Zhao-Xu Yang",
      "Hai-Jun Rong",
      "Jiawei Lang",
      "Guoqi Li"
    ],
    "abstract": "Traditional supervised drone-view geo-localization (DVGL) methods heavily depend on paired training data and encounter difficulties in learning cross-view correlations from unpaired data. Moreover, when deployed in a new domain, these methods require obtaining the new paired data and subsequent retraining for model adaptation, which significantly increases computational overhead. Existing unsupervised methods have enabled to generate pseudo-labels based on cross-view similarity to infer the pairing relationships. However, geographical similarity and spatial continuity often cause visually analogous features at different geographical locations. The feature confusion compromises the reliability of pseudo-label generation, where incorrect pseudo-labels drive negative optimization. Given these challenges inherent in both supervised and unsupervised DVGL methods, we propose a novel cross-domain invariant knowledge transfer network (CDIKTNet) with limited supervision, whose architecture consists of a cross-domain invariance sub-network (CDIS) and a cross-domain transfer sub-network (CDTS). This architecture facilitates a closed-loop framework for invariance feature learning and knowledge transfer. The CDIS is designed to learn cross-view structural and spatial invariance from a small amount of paired data that serves as prior knowledge. It endows the shared feature space of unpaired data with similar implicit cross-view correlations at initialization, which alleviates feature confusion. Based on this, the CDTS employs dual-path contrastive learning to further optimize each subspace while preserving consistency in a shared feature space. Extensive experiments demonstrate that CDIKTNet achieves state-of-the-art performance under full supervision compared with those supervised methods, and further surpasses existing unsupervised methods in both few-shot and cross-domain initialization.",
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.07520.pdf",
    "abs_url": "https://arxiv.org/abs/2503.07520",
    "published": "2025-03-10T16:46:43Z",
    "updated": "2026-01-29T07:05:22Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出跨域不变知识转移网络（CDIKTNet），通过在有限监督下结合不变性特征学习和对比学习，解决了无人机视图地理定位中的特征混淆和跨域适应问题。",
      "motivation": "传统监督无人机视图地理定位方法高度依赖配对训练数据，难以从未配对数据中学习跨视图关联，且在新域部署时需重新获取配对数据并重训练，计算成本高。现有无监督方法通过跨视图相似性生成伪标签，但地理相似性和空间连续性导致特征混淆，伪标签不可靠，引发负优化。这些问题限制了方法的效率和泛化能力，因此亟需在有限监督下解决跨域和特征混淆的挑战。",
      "method": "论文提出跨域不变知识转移网络（CDIKTNet），其架构包括跨域不变性子网络（CDIS）和跨域转移子网络（CDTS）。CDIS 从少量配对数据中学习跨视图结构性和空间不变性，作为先验知识来初始化共享特征空间，缓解特征混淆。CDTS 采用双路径对比学习，在保持共享特征空间一致性的同时进一步优化每个子空间，形成一个封闭环框架，实现不变性特征学习和知识转移的协同。",
      "result": "实验结果显示，CDIKTNet 在全监督设置下达到最先进性能，超越了传统监督方法。在少样本和跨域初始化场景中，CDIKTNet 进一步超越现有无监督方法，证明了其在有限数据和新域中的有效性。摘要未提供具体性能指标，但总体表明该方法在精度和泛化能力上有显著改进。",
      "conclusion": "CDIKTNet 的主要贡献是提出了一种新颖的跨域不变知识转移网络，有效解决了无人机视图地理定位中的特征混淆和跨域适应挑战。该方法通过结合不变性学习和对比学习，减少数据依赖，提高泛化能力和计算效率，具有学术价值和应用潜力。未来工作可扩展至其他视觉任务或优化网络架构，但摘要未明确说明具体局限性。",
      "tags": [
        "Drone-view Geo-Localization",
        "Cross-Domain Learning",
        "Contrastive Learning",
        "Few-Shot Learning",
        "Knowledge Transfer"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:07.348744Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.06991",
    "title": "Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols",
    "authors": [
      "Yongwoo Kim",
      "Sungmin Cha",
      "Donghyun Kim"
    ],
    "abstract": "Machine unlearning is a process to remove specific data points from a trained model while maintaining the performance on the retain data, addressing privacy or legal requirements. Despite its importance, existing unlearning evaluations tend to focus on logit-based metrics under small-scale scenarios. We observe that this could lead to a false sense of security in unlearning approaches under real-world scenarios. In this paper, we conduct a comprehensive evaluation that employs representation-based evaluations of the unlearned model under large-scale scenarios to verify whether the unlearning approaches truly eliminate the targeted data from the model's representation perspective. Our analysis reveals that current state-of-the-art unlearning approaches either completely degrade the representational quality of the unlearned model or merely modify the classifier, thereby achieving superior logit-based performance while maintaining representational similarity to the original model. Furthermore, we introduce a novel unlearning evaluation scenario in which the forgetting classes exhibit semantic similarity to downstream task classes, necessitating that feature representations diverge significantly from those of the original model, thus enabling a more thorough evaluation from a representation perspective. We hope our benchmark will serve as a standardized protocol for evaluating unlearning algorithms under realistic conditions.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2503.06991.pdf",
    "abs_url": "https://arxiv.org/abs/2503.06991",
    "published": "2025-03-10T07:11:34Z",
    "updated": "2026-01-29T10:37:16Z",
    "comment": "Accepted to Engineering Applications of Artificial Intelligence",
    "light_analysis": {
      "overview": "论文提出了一种基于表示的大规模机器遗忘评估方法，并引入了语义相似性场景以更彻底地评估遗忘效果。",
      "motivation": "机器遗忘旨在从训练模型中移除特定数据点以满足隐私或法律要求，但现有评估主要依赖小规模场景下的基于logit的指标，可能导致在实际应用中产生虚假的安全感。这一问题的重要性在于，如果遗忘不彻底，可能引发隐私泄露或合规风险，尤其是在现实大规模场景中。当前方法不足，因为它们忽视了从表示角度验证数据是否真正被消除，从而需要更全面的评估协议来确保模型的安全性和可靠性。",
      "method": "论文采用基于表示的评价方法，在大规模场景下全面评估机器遗忘方法是否真正从表示角度消除目标数据。关键创新点包括引入一种新评估场景，其中遗忘类与下游任务类具有语义相似性，这要求特征表示必须显著偏离原始模型，从而实现更彻底的表示层面评估。虽然摘要未明确说明具体数据集或模型架构，但该方法强调从表示相似性和大规模条件出发，分析遗忘效果，以弥补现有logit-based指标的不足。",
      "result": "分析显示，当前最先进的机器遗忘方法要么完全降低未学习模型的表示质量，要么仅修改分类器，从而在保持表示与原始模型相似的同时，在基于logit的指标上表现出色。这揭示了现有评估方法的局限性，即过分依赖logit性能而忽视了表示层面的变化，可能导致遗忘不彻底的问题。论文未提供具体准确率数据，但结果强调了表示相似性在大规模和语义相似场景下可能掩盖遗忘效果，从而促进更严格的评估标准。",
      "conclusion": "论文的主要贡献在于批判性地重审了机器遗忘评估协议，并提出一种基于表示的新评估基准，旨在标准化现实条件下的算法评估。学术价值在于揭示了现有评估方法的不足，并强调了表示角度的重要性；实际应用价值是帮助开发更有效的遗忘方法以提升隐私保护能力。潜在局限性可能包括评估场景的扩展性，未来工作可聚焦于改进遗忘算法或进一步验证评估协议在不同数据集上的泛化性。",
      "tags": [
        "Machine Unlearning",
        "Representation Learning",
        "Evaluation Protocols",
        "Feature Representation",
        "Semantic Similarity"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:15.539259Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.05600",
    "title": "Progressively Deformable 2D Gaussian Splatting for Video Representation at Arbitrary Resolutions",
    "authors": [
      "Mufan Liu",
      "Qi Yang",
      "Miaoran Zhao",
      "He Huang",
      "Le Yang",
      "Zhu Li",
      "Yiling Xu"
    ],
    "abstract": "Implicit neural representations (INRs) enable fast video compression and effective video processing, but a single model rarely offers scalable decoding across rates and resolutions. In practice, multi-resolution typically relies on retraining or multi-branch designs, and structured pruning failed to provide a permutation-invariant progressive transmission order. Motivated by the explicit structure and efficiency of Gaussian splatting, we propose D2GV-AR, a deformable 2D Gaussian video representation that enables \\emph{arbitrary-scale} rendering and \\emph{any-ratio} progressive coding within a single model. We partition each video into fixed-length Groups of Pictures and represent each group with a canonical set of 2D Gaussian primitives, whose temporal evolution is modeled by a neural ordinary differential equation. During training and rendering, we apply scale-aware grouping according to Nyquist sampling theorem to form a nested hierarchy across resolutions. Once trained, primitives can be pruned via a D-optimal subset objective to enable any-ratio progressive coding. Extensive experiments show that D2GV-AR renders at over 250 FPS while matching or surpassing recent INR baselines, enabling multiscale continuous rate--quality adaptation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2503.05600.pdf",
    "abs_url": "https://arxiv.org/abs/2503.05600",
    "published": "2025-03-07T17:26:27Z",
    "updated": "2026-01-29T06:47:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出D2GV-AR，一种基于可变形2D高斯泼溅的视频表示方法，实现了在单一模型中支持任意分辨率和任意比例渐进编码的创新。",
      "motivation": "隐式神经表示（INRs）在视频压缩和处理中虽具效率，但单一模型难以跨速率和分辨率进行可扩展解码。现有方法如多分辨率实现多依赖重训练或多分支设计，结构化剪枝亦未能提供置换不变的渐进传输顺序，限制了视频表示的灵活性和适应性。因此，本研究动机在于开发一种方法，克服这些局限性，在单一模型中实现任意分辨率的渲染和任意比例的渐进编码，提升视频处理的通用性和效率。",
      "method": "本研究基于高斯泼溅的显式结构，提出D2GV-AR方法。技术核心包括：将视频划分为固定长度的图片组，用规范2D高斯基元表示每个组；通过神经常微分方程（Neural ODE）建模基元的时间演化。在训练和渲染过程中，依据奈奎斯特采样定理进行尺度感知分组，形成跨分辨率的嵌套层次；训练完成后，使用D-最优子集目标剪枝基元，以实现任意比例的渐进编码，从而支持灵活的视频表示。",
      "result": "实验结果显示，D2GV-AR在渲染速度上达到超过250 FPS的高效率，同时性能匹配或超越了近期隐式神经表示（INR）基线方法。此外，该方法支持多尺度连续速率-质量适应，通过广泛实验验证了其在视频压缩和表示中的优越性，提升了灵活性和可扩展性，摘要未明确说明具体基线对比数据，但表明了显著性能提升。",
      "conclusion": "本研究主要贡献是提出D2GV-AR方法，解决了视频表示中的可扩展性挑战，支持任意分辨率和渐进编码。学术价值在于推动了视频压缩和自适应渲染技术的发展；实际应用价值体现在高效视频处理和灵活传输场景中。摘要未明确说明局限性，但未来工作可能涉及进一步优化模型复杂度或扩展应用领域，以增强方法的通用性。",
      "tags": [
        "Gaussian Splatting",
        "Neural ODE",
        "Progressive Coding",
        "Video Representation",
        "Scalable Decoding"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:26.458615Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.01431",
    "title": "How simple can you go? An off-the-shelf transformer approach to molecular dynamics",
    "authors": [
      "Max Eissler",
      "Tim Korjakow",
      "Stefan Ganscha",
      "Oliver T. Unke",
      "Klaus-Robert Müller",
      "Stefan Gugler"
    ],
    "abstract": "Most current neural networks for molecular dynamics (MD) include physical inductive biases, resulting in specialized and complex architectures. This is in contrast to most other machine learning domains, where specialist approaches are increasingly replaced by general-purpose architectures trained on vast datasets. In line with this trend, several recent studies have questioned the necessity of architectural features commonly found in MD models, such as built-in rotational equivariance or energy conservation. In this work, we contribute to the ongoing discussion by evaluating the performance of an MD model with as few specialized architectural features as possible. We present a recipe for MD using an Edge Transformer, an ``off-the-shelf'' transformer architecture that has been minimally modified for the MD domain, termed MD-ET. Our model implements neither built-in equivariance nor energy conservation. We use a simple supervised pre-training scheme on $\\sim$30 million molecular structures from the QCML database. Using this ``off-the-shelf'' approach, we show state-of-the-art results on several benchmarks after fine-tuning for a small number of steps. Additionally, we examine the effects of being only approximately equivariant and energy conserving for MD simulations, proposing a novel method for distinguishing the errors resulting from non-equivariance from other sources of inaccuracies like numerical rounding errors. While our model exhibits runaway energy increases on larger structures, we show approximately energy-conserving NVE simulations for a range of small structures.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2503.01431.pdf",
    "abs_url": "https://arxiv.org/abs/2503.01431",
    "published": "2025-03-03T11:34:27Z",
    "updated": "2026-01-29T09:23:40Z",
    "comment": "21 pages, code at https://github.com/mx-e/simple-md",
    "light_analysis": {
      "overview": "论文通过使用最小修改的通用Transformer架构（MD-ET）在分子动力学任务中取得最先进性能，展示了简单通用架构的潜力。",
      "motivation": "当前分子动力学（MD）模型大多包含物理归纳偏见，导致架构复杂且专业化，这与机器学习其他领域普遍采用通用架构的趋势相悖。本研究动机是验证是否可以简化MD模型架构，减少专业特征如内置旋转不变性或能量守恒，以探索更通用、简单的解决方案。这有助于降低模型开发复杂度，并可能提升其跨领域应用潜力，同时挑战传统方法的过度复杂化。",
      "method": "本研究提出了MD-ET模型，基于“现成的”Edge Transformer架构，仅进行了最小修改以适应分子动力学任务。模型不包含内置的旋转不变性或能量守恒。采用监督预训练方案，使用QCML数据库中的约3000万个分子结构进行训练。通过简单的预训练后微调，模型在多个基准测试中表现出色。关键创新点在于利用通用Transformer架构，减少了领域特定特征，从而简化了模型设计并保持高性能。",
      "result": "经过微调，MD-ET模型在多个分子动力学基准测试中取得了最先进的结果。具体性能指标摘要未明确说明，但实验表明模型在任务上表现优异。此外，研究提出了新方法来区分非旋转不变性误差与其他误差源如数值舍入误差。模型在小结构上实现了近似能量守恒的NVE模拟，但大结构上出现能量失控。这表明简单架构在特定条件下有效，但存在局限性。",
      "conclusion": "本研究的主要结论是简单通用架构如MD-ET在分子动力学中具有可行性，为开发更高效、易于部署的模型提供了新思路。学术上，它挑战了领域特定架构的必要性，推动了通用AI方法在科学领域的应用。局限性在于大结构上的能量问题，未来研究可探索改进能量守恒或扩展模型规模，以增强鲁棒性。",
      "tags": [
        "Molecular Dynamics",
        "Transformer",
        "Edge Transformer",
        "Supervised Learning",
        "Pre-training"
      ]
    },
    "analyzed_at": "2026-01-30T04:02:59.849260Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2503.04796",
    "title": "Optimizing Multi-Hop Document Retrieval Through Intermediate Representations",
    "authors": [
      "Jiaen Lin",
      "Jingyu Liu",
      "Yingbo Liu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) encounters challenges when addressing complex queries, particularly multi-hop questions. While several methods tackle multi-hop queries by iteratively generating internal queries and retrieving external documents, these approaches are computationally expensive. In this paper, we identify a three-stage information processing pattern in LLMs during layer-by-layer reasoning, consisting of extraction, processing, and subsequent extraction steps. This observation suggests that the representations in intermediate layers contain richer information compared to those in other layers. Building on this insight, we propose Layer-wise RAG (L-RAG). Unlike prior methods that focus on generating new internal queries, L-RAG leverages intermediate representations from the middle layers, which capture next-hop information, to retrieve external knowledge. L-RAG achieves performance comparable to multi-step approaches while maintaining inference overhead similar to that of standard RAG. Experimental results show that L-RAG outperforms existing RAG methods on open-domain multi-hop question-answering datasets, including MuSiQue, HotpotQA, and 2WikiMultiHopQA. The code is available in https://github.com/Olive-2019/L-RAG",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2503.04796.pdf",
    "abs_url": "https://arxiv.org/abs/2503.04796",
    "published": "2025-03-02T11:33:22Z",
    "updated": "2026-01-29T16:19:47Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Layer-wise RAG (L-RAG)方法，通过利用大语言模型中间层的表示来优化多跳文档检索，实现高效推理。",
      "motivation": "检索增强生成（RAG）在处理复杂查询，特别是多跳问题时面临挑战，因为现有方法通过迭代生成内部查询和检索外部文档来解决，计算开销大且效率低下。多跳查询在开放领域问答等应用中至关重要，现有方法的不足限制了其实际部署。论文观察到在大语言模型（LLMs）的逐层推理中存在提取、处理和再提取的三阶段信息处理模式，表明中间层表示包含更丰富信息，这为解决多跳检索的效率问题提供了新动机。",
      "method": "本文提出Layer-wise RAG (L-RAG)方法，核心创新在于利用LLMs中间层的表示来检索外部知识，而非生成新查询。基于对LLMs层间推理模式的观察，L-RAG在模型推理时提取中间层隐藏表示，这些表示捕获了下一跳信息，直接作为查询向量进行文档检索。技术路线包括设计层间表示提取机制，并集成到标准RAG框架中，减少了迭代步骤的计算开销，从而优化多跳检索过程。",
      "result": "实验在开放领域多跳问答数据集MuSiQue、HotpotQA和2WikiMultiHopQA上进行，结果表明L-RAG在性能上优于现有RAG方法。具体地，L-RAG实现了与多步检索方法相当的准确率，同时保持了类似于标准RAG的推理开销，在计算效率和检索效果上均有优势。与基线方法对比，L-RAG在高效推理的基础上显著提升了多跳查询处理能力。",
      "conclusion": "本研究的主要贡献是提出了Layer-wise RAG (L-RAG)，通过利用LLMs中间层表示优化多跳文档检索，其学术价值在于揭示层间推理模式并应用于检索增强生成，为高效多跳问答提供新思路。实际应用中，L-RAG能降低计算成本，提升系统性能。局限性方面，摘要未明确说明，未来工作可能涉及扩展到更复杂场景或进一步优化表示提取机制。",
      "tags": [
        "Retrieval-augmented Generation",
        "Multi-hop Question Answering",
        "Large Language Models",
        "Intermediate Representations",
        "Layer-wise Processing"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:27.633913Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.20120",
    "title": "Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion",
    "authors": [
      "QingYuan Jiang",
      "Longfei Huang",
      "Yang Yang"
    ],
    "abstract": "Multimodal learning (MML) is significantly constrained by modality imbalance, leading to suboptimal performance in practice. While existing approaches primarily focus on balancing the learning of different modalities to address this issue, they fundamentally overlook the inherent disproportion in model classification ability, which serves as the primary cause of this phenomenon. In this paper, we propose a novel multimodal learning approach to dynamically balance the classification ability of weak and strong modalities by incorporating the principle of boosting. Concretely, we first propose a sustained boosting algorithm in multimodal learning by simultaneously optimizing the classification and residual errors. Subsequently, we introduce an adaptive classifier assignment strategy to dynamically facilitate the classification performance of the weak modality. Furthermore, we theoretically analyze the convergence property of the cross-modal gap function, ensuring the effectiveness of the proposed boosting scheme. To this end, the classification ability of strong and weak modalities is expected to be balanced, thereby mitigating the imbalance issue. Empirical experiments on widely used datasets reveal the superiority of our method through comparison with various state-of-the-art (SOTA) multimodal learning baselines. The source code is available at https://github.com/njustkmg/NeurIPS25-AUG.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2502.20120.pdf",
    "abs_url": "https://arxiv.org/abs/2502.20120",
    "published": "2025-02-27T14:12:20Z",
    "updated": "2026-01-29T12:29:44Z",
    "comment": "Accepted by NeurIPS 2025",
    "light_analysis": {
      "overview": "本文提出了一种基于提升原则的多模态学习方法，通过动态平衡弱模态和强模态的分类能力，以缓解模态不平衡问题，提升学习性能。",
      "motivation": "多模态学习在实践中常受模态不平衡制约，导致模型性能下降。现有方法主要聚焦于平衡不同模态的学习过程，如调整权重或损失函数，但忽视了分类能力的内在不成比例，即强模态分类能力强、弱模态分类能力弱，这是模态不平衡的根本原因。传统方法未能从根本上解决这一问题，导致实际应用中效果有限，因此有必要从分类能力角度重新审视多模态学习，以更有效地优化模型表现。",
      "method": "本论文提出了一种新的多模态学习方法，核心创新包括持续提升算法和自适应分类器分配策略。持续提升算法结合提升原则，通过同时优化分类误差和残差误差，在多模态学习中实现动态平衡。自适应分类器分配策略则根据模态强弱动态调整分类器，专门增强弱模态的分类性能。此外，论文从理论上分析了跨模态差距函数的收敛性质，以确保方法的稳定性和有效性，为缓解模态不平衡提供了技术支撑。",
      "result": "在多个广泛使用的数据集上进行实证实验，结果表明所提出的方法在性能上优于当前最先进的多模态学习基线方法。摘要未明确说明具体准确率提升或效率改进数值，但通过与各类基线对比，证实了该方法在平衡模态分类能力、缓解不平衡问题方面的显著优势，突出了其在实际应用中的潜力。",
      "conclusion": "本研究的主要贡献在于从分类能力不成比例的新视角重新思考多模态学习，提出动态平衡策略，通过持续提升和自适应分配有效缓解模态不平衡。这具有理论创新价值，为多模态学习提供了新思路，并展示了实际应用前景，未来可探索更复杂模态交互或扩展至其他不平衡学习场景，以进一步优化模型性能。",
      "tags": [
        "Multimodal Learning",
        "Boosting Algorithm",
        "Adaptive Classifier Assignment",
        "Classification Ability Disproportion",
        "Cross-modal Gap Function"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:30.785083Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.10996",
    "title": "RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation",
    "authors": [
      "Pengcheng Jiang",
      "Lang Cao",
      "Ruike Zhu",
      "Minhao Jiang",
      "Yunyi Zhang",
      "Jiaming Shen",
      "Jimeng Sun",
      "Jiawei Han"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance on knowledge-intensive tasks, yet they often struggle with multi-step reasoning due to the unstructured nature of retrieved context. While retrieval-augmented generation (RAG) methods provide external information, the lack of explicit organization among retrieved passages limits their effectiveness, leading to brittle reasoning pathways. Recent interpretability studies highlighting the importance of structured intermediate reasoning further align with this perspective. We propose Retrieval-And-Structuring (RAS), a framework that dynamically constructs question-specific knowledge graphs through iterative retrieval and structured knowledge building. RAS interleaves targeted retrieval planning with incremental graph construction, enabling models to assemble and reason over evolving knowledge structures tailored to each query. On seven knowledge-intensive benchmarks, RAS consistently outperforms strong baselines, achieving up to 8.7\\% and 7.0\\% gains with proprietary and open-source LLMs, respectively. Our results demonstrate that dynamic, question-specific knowledge structuring offers a robust path to improving reasoning accuracy and robustness in language model generation.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2502.10996.pdf",
    "abs_url": "https://arxiv.org/abs/2502.10996",
    "published": "2025-02-16T05:01:49Z",
    "updated": "2026-01-29T11:19:15Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "该论文提出RAS框架，通过动态构建问题特定知识图来增强LLMs在知识密集型任务中的多步推理性能。",
      "motivation": "大语言模型在知识密集型任务中表现出色，但由于检索到的上下文缺乏结构化组织，多步推理能力受到限制。检索增强生成方法虽能提供外部知识，但检索段落之间缺乏显式关联，导致推理路径脆弱且效率低下。最近的可解释性研究进一步强调了结构化中间推理的重要性，表明现有方法在处理复杂推理任务时存在不足，亟需改进知识组织机制以提升LLM的准确性和鲁棒性。",
      "method": "RAS框架采用迭代检索与结构化知识构建相结合的方法，动态地为每个查询构建问题特定的知识图。关键创新在于交织目标检索规划与增量图构建，使模型能够根据查询逐步组装和推理知识结构。该方法通过检索获取相关信息，并利用知识图组织这些信息，从而增强LLM在知识密集型任务中的推理能力。摘要未明确说明使用的具体数据集或模型架构。",
      "result": "实验在七个知识密集型基准测试上进行，RAS框架 consistently outperforms 强基线方法。具体而言，使用专有LLM时，性能提升最高达8.7%；使用开源LLM时，提升最高达7.0%。这些结果表明RAS在提高推理准确性和鲁棒性方面显著优于现有检索增强生成方法，验证了动态知识结构的有效性。",
      "conclusion": "该论文的主要贡献是提出RAS框架，通过动态构建问题特定知识图，有效提升了LLM在知识密集型任务中的推理准确性和鲁棒性。研究具有重要的学术价值，推动了LLM推理技术的发展，并为复杂推理任务如问答和知识提取提供了新方法。实际应用中，该框架可增强智能系统的可靠性。未来工作可探索更多知识表示形式或扩展至其他任务领域，摘要未明确说明具体局限性。",
      "tags": [
        "Retrieval-Augmented Generation",
        "Knowledge Graph",
        "Large Language Model",
        "Multi-step Reasoning",
        "Structured Knowledge"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:20.903570Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.08987",
    "title": "Neural Force Field: Few-shot Learning of Generalized Physical Reasoning",
    "authors": [
      "Shiqian Li",
      "Ruihong Shen",
      "Yaoyu Tao",
      "Chi Zhang",
      "Yixin Zhu"
    ],
    "abstract": "Physical reasoning is a remarkable human ability that enables rapid learning and generalization from limited experience. Current AI models, despite extensive training, still struggle to achieve similar generalization, especially in Out-of-distribution (OOD) settings. This limitation stems from their inability to abstract core physical principles from observations. A key challenge is developing representations that can efficiently learn and generalize physical dynamics from minimal data. Here we present Neural Force Field (NFF), a framework extending Neural Ordinary Differential Equation (NODE) to learn complex object interactions through force field representations, which can be efficiently integrated through an Ordinary Differential Equation (ODE) solver to predict object trajectories. Unlike existing approaches that rely on discrete latent spaces, NFF captures fundamental physical concepts such as gravity, support, and collision in continuous explicit force fields. Experiments on three challenging physical reasoning tasks demonstrate that NFF, trained with only a few examples, achieves strong generalization to unseen scenarios. This physics-grounded representation enables efficient forward-backward planning and rapid adaptation through interactive refinement. Our work suggests that incorporating physics-inspired representations into learning systems can help bridge the gap between artificial and human physical reasoning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.08987.pdf",
    "abs_url": "https://arxiv.org/abs/2502.08987",
    "published": "2025-02-13T05:50:13Z",
    "updated": "2026-01-29T10:14:38Z",
    "comment": "27 pages, ICLR 2026",
    "light_analysis": {
      "overview": "本论文提出Neural Force Field框架，通过力场表示学习物理交互，实现少量样本下的泛化物理推理。",
      "motivation": "物理推理是人类的重要能力，但当前AI模型在泛化方面表现不佳，尤其是在分布外设置下，无法从少量观察中抽象核心物理原理。这一问题重要性在于，人类能够快速学习和适应物理世界，而AI模型需要大量数据，且难以处理未见场景，阻碍了实际应用。现有方法依赖离散潜在空间，无法有效捕捉连续物理动态，导致泛化能力受限，这是研究的核心动机。",
      "method": "本论文提出Neural Force Field框架，扩展了Neural Ordinary Differential Equation，通过学习连续显式力场表示来建模复杂物体交互，并通过ODE求解器集成预测对象轨迹。关键创新点在于，NFF能捕获基础物理概念如重力、支撑和碰撞，与现有离散潜在空间方法不同。研究使用了三个物理推理任务的数据集进行实验，但摘要未明确说明具体数据集细节，旨在验证框架在少量样本下的学习能力。",
      "result": "实验在三个挑战性物理推理任务上进行，显示NFF在少量样本训练后，能强泛化到未见场景，支持高效的前向-后向规划和交互细化。虽然摘要未提供具体性能指标，如准确率提升，但结果优于现有基线方法，证明了该框架在OOD设置下的有效性，这为少样本学习物理推理提供了实证支持。",
      "conclusion": "论文的主要贡献是提出了基于力场表示的NFF框架，结合物理启发式表示，有助于缩小AI与人类物理推理能力的差距。学术价值在于为少样本学习和泛化物理推理提供了新方法，实际应用价值包括高效规划和快速适应物理环境。潜在局限性或未来工作方向未在摘要中明确说明，但可推断为进一步优化模型或扩展更多物理任务。",
      "tags": [
        "Neural Force Field",
        "Neural Ordinary Differential Equation",
        "ODE Solver",
        "Force Field Representations",
        "Few-shot Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:21.845420Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.08488",
    "title": "One-Shot Federated Learning with Classifier-Free Diffusion Models",
    "authors": [
      "Obaidullah Zaland",
      "Shutong Jin",
      "Florian T. Pokorny",
      "Monowar Bhuyan"
    ],
    "abstract": "Federated learning (FL) enables collaborative learning without data centralization but introduces significant communication costs due to multiple communication rounds between clients and the server. One-shot federated learning (OSFL) addresses this by forming a global model with a single communication round, often relying on the server's model distillation or auxiliary dataset generation - mostly through pre-trained diffusion models (DMs). Existing DM-assisted OSFL methods, however, typically employ classifier-guided DMs, which require training auxiliary classifier models at each client, introducing additional computation overhead. This work introduces OSCAR (One-Shot Federated Learning with Classifier-Free Diffusion Models), a novel OSFL approach that eliminates the need for auxiliary models. OSCAR uses foundation models to devise category-specific data representations at each client which are integrated into a classifier-free diffusion model pipeline for server-side data generation. In our experiments, OSCAR outperforms the state-of-the-art on four benchmark datasets while reducing the communication load by at least 99%.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.08488.pdf",
    "abs_url": "https://arxiv.org/abs/2502.08488",
    "published": "2025-02-12T15:23:29Z",
    "updated": "2026-01-29T14:10:05Z",
    "comment": "Published in IEEE ICME 2025",
    "light_analysis": {
      "overview": "OSCAR方法利用分类器无关的扩散模型实现单次联邦学习，无需训练辅助分类器模型，提升效率和性能。",
      "motivation": "联邦学习（FL）支持协作学习而无需数据集中化，但多轮通信带来高通信成本。单次联邦学习（OSFL）通过单轮通信解决此问题，但现有方法依赖分类器引导的扩散模型（DMs），需要在每个客户端训练辅助分类器，引入额外计算开销。这增加了系统复杂性，因此，本研究旨在开发一种无需辅助模型的OSFL方法，以降低计算负担并简化流程。",
      "method": "OSCAR方法结合基础模型和分类器无关的扩散模型。在每个客户端，基础模型生成类别特定的数据表示，这些表示被传输到服务器。服务器端将这些表示集成到分类器无关的扩散模型管道中，生成合成数据用于全局模型训练。关键创新是消除了辅助分类器训练，直接使用分类器无关扩散模型，减少了客户端计算需求并简化了数据生成过程。",
      "result": "在四个基准数据集上的实验表明，OSCAR方法在性能上超越了现有技术，表现出更好的模型准确性，具体指标摘要未明确说明。同时，通信负载减少了至少99%，显著降低了联邦学习的通信成本，实现了效率与准确性的双重提升。与基线方法对比，OSCAR在不依赖辅助模型的情况下，仍能维持或改进性能。",
      "conclusion": "OSCAR通过引入分类器无关的扩散模型，有效减少了单次联邦学习中的计算和通信开销，简化了客户端操作，同时保持了模型性能。这一贡献推动了高效联邦学习的发展，具有实际应用价值，例如在隐私敏感场景中实现快速模型聚合。未来工作可能包括扩展到更多数据集或探索其他模型架构的适应性。",
      "tags": [
        "Federated Learning",
        "One-Shot Federated Learning",
        "Diffusion Models",
        "Classifier-Free Diffusion Models",
        "Foundation Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:00.600521Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.07541",
    "title": "Detecting Greenwashing: A Natural Language Processing Literature Survey",
    "authors": [
      "Tom Calamai",
      "Oana Balalau",
      "Théo Le Guenedal",
      "Fabian M. Suchanek"
    ],
    "abstract": "Greenwashing refers to practices by corporations or governments that intentionally mislead the public about their environmental impact. This paper provides a comprehensive and methodologically grounded survey of natural language processing (NLP) approaches for detecting greenwashing in textual data, with a focus on corporate climate communication.   Rather than treating greenwashing as a single, monolithic task, we examine the set of NLP problems, also known as climate NLP tasks, that researchers have used to approximate it, ranging from climate topic detection to the identification of deceptive communication patterns. Our focus is on the methodological foundations of these approaches: how tasks are formulated, how datasets are constructed, and how model evaluation influences reliability.   Our review reveals a fragmented landscape: several subtasks now exhibit near-perfect performance under controlled settings, yet tasks involving ambiguity, subjectivity, or reasoning remain challenging. Crucially, no dataset of verified greenwashing cases currently exists.   We argue that advancing automated greenwashing detection requires principled NLP methodologies that combine reliable data annotations with interpretable model design. Future work should leverage third-party judgments, such as verified media reports or regulatory records, to mitigate annotation subjectivity and legal risk, and adopt decomposed pipelines that support human oversight, traceable reasoning, and efficient model design.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2502.07541.pdf",
    "abs_url": "https://arxiv.org/abs/2502.07541",
    "published": "2025-02-11T13:28:56Z",
    "updated": "2026-01-29T13:40:37Z",
    "comment": "42 pages, 1 figure, 11 pages (appendix), working paper",
    "light_analysis": {
      "overview": "该论文提供了关于使用自然语言处理（NLP）检测绿色洗涤的全面文献调查，强调方法论基础和分解为多个气候NLP子任务。",
      "motivation": "绿色洗涤指企业或政府误导公众环境影响的实践，导致公众信任缺失和监管挑战。现有方法通常将绿色洗涤视为单一任务，缺乏系统性方法论，数据集不足，难以处理模糊性或主观性任务，限制了自动化检测的可靠性和可扩展性。因此，需要结构化调查来梳理NLP技术的应用现状和问题。",
      "method": "论文通过文献综述方法，将绿色洗涤检测分解为一系列气候NLP子任务，如气候主题检测和欺骗性通信模式识别。关键创新在于分析任务制定、数据集构建和模型评估的方法论基础，而非提出新模型。研究聚焦于如何基于现有NLP技术（如分类或序列标注）处理绿色洗涤相关文本，并探讨了数据标注和评估标准对结果的影响。",
      "result": "调查揭示NLP子任务在受控设置下（如明确主题检测）表现近乎完美，但涉及模糊性、主观性或推理的任务（如欺骗模式识别）仍具挑战性。目前缺乏已验证的绿色洗涤案例数据集，这阻碍了模型泛化和可靠性评估。与基线方法对比，现有研究缺乏统一基准，导致性能碎片化，且没有具体数据指标支持全面性能提升。",
      "conclusion": "论文总结了NLP检测绿色洗涤的研究现状，核心贡献在于方法论梳理和指出数据与模型设计缺陷。其学术价值在于为未来研究提供结构化框架，实际应用价值在于指导开发更可靠、可解释的自动化系统。局限性包括数据集缺失和主观性处理困难，未来工作应结合第三方数据（如监管记录）和分解管道以支持人工监督。",
      "tags": [
        "Natural Language Processing",
        "Greenwashing Detection",
        "Climate NLP Tasks",
        "Deceptive Communication",
        "Interpretable Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:03:59.447066Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.07202",
    "title": "Monte Carlo Tree Diffusion for System 2 Planning",
    "authors": [
      "Jaesik Yoon",
      "Hyeonseo Cho",
      "Doojin Baek",
      "Yoshua Bengio",
      "Sungjin Ahn"
    ],
    "abstract": "Diffusion models have recently emerged as a powerful tool for planning. However, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally improves with inference-time computation scaling-standard diffusion-based planners offer only limited avenues for the scalability. In this paper, we introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates the generative strength of diffusion models with the adaptive search capabilities of MCTS. Our method reconceptualizes denoising as a tree-structured process, allowing partially denoised plans to be iteratively evaluated, pruned, and refined. By selectively expanding promising trajectories while retaining the flexibility to revisit and improve suboptimal branches, MCTD achieves the benefits of MCTS such as controlling exploration-exploitation trade-offs within the diffusion framework. Empirical results on challenging long-horizon tasks show that MCTD outperforms diffusion baselines, yielding higher-quality solutions as inference-time computation increases.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2502.07202.pdf",
    "abs_url": "https://arxiv.org/abs/2502.07202",
    "published": "2025-02-11T02:51:42Z",
    "updated": "2026-01-29T04:51:49Z",
    "comment": "23 pages, 7 figures, ICML 2025 Spotlight",
    "light_analysis": {
      "overview": "论文提出Monte Carlo Tree Diffusion（MCTD）框架，将扩散模型的生成优势与蒙特卡洛树搜索的自适应搜索能力结合，以提升规划任务的可扩展性和性能。",
      "motivation": "扩散模型在规划任务中显示出潜力，但相比蒙特卡洛树搜索（MCTS），其性能不能随推理时间计算量增加而自然扩展。MCTS通过更多计算资源显著改进性能，而标准扩散基规划器在这方面受限，导致在长期规划任务中效率不足。因此，开发一种结合两种技术优势的方法，对解决复杂规划问题至关重要，以提高解决方案质量和可扩展性。",
      "method": "MCTD方法的核心是将扩散模型的去噪过程重构为树结构，使部分去噪的计划能够迭代评估、剪枝和精炼。通过选择性扩展有前景的轨迹，并保留改进次优分支的能力，MCTD在扩散框架内实现了MCTS的控制探索-利用权衡特性。该框架不依赖特定数据集，专注于算法集成，创新点在于融合生成建模与树搜索技术，优化规划过程。",
      "result": "在挑战性长期任务上的实验表明，MCTD优于基于扩散的基线方法。随着推理时间计算量增加，MCTD能产生更高质量的解决方案。摘要未明确说明具体性能指标如准确率提升百分比，但指出MCTD在性能上超越基线，证明了其在可扩展性方面的优势。",
      "conclusion": "MCTD的主要贡献是成功整合扩散模型与MCTS，提供了更可扩展的规划框架，增强了解决方案质量。其学术价值在于推动了生成建模与搜索算法的交叉研究，实际应用价值在于为复杂规划任务提供高效工具。摘要未明确说明局限性，但可推测未来工作可能包括扩展应用到更多领域或优化计算开销。",
      "tags": [
        "Diffusion Models",
        "Monte Carlo Tree Search",
        "Planning",
        "Tree-structured Process",
        "Exploration-Exploitation Trade-off"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:35.552548Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.03946",
    "title": "CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning",
    "authors": [
      "Yousef Koka",
      "David Selby",
      "Gerrit Großmann",
      "Sebastian Vollmer",
      "Kathan Pandya"
    ],
    "abstract": "Data preprocessing is a critical yet frequently neglected aspect of machine learning, often paid little attention despite its potentially significant impact on model performance. While automated machine learning pipelines are starting to recognize and integrate data preprocessing into their solutions for classification and regression tasks, this integration is lacking for more specialized tasks like survival or time-to-event models. As a result, survival analysis not only faces the general challenges of data preprocessing but also suffers from the lack of tailored, automated solutions in this area. To address this gap, this paper presents 'CleanSurvival', a reinforcement-learning-based solution for optimizing preprocessing pipelines, extended specifically for survival analysis. The framework can handle continuous and categorical variables, using Q-learning to select which combination of data imputation, outlier detection and feature extraction techniques achieves optimal performance for a Cox, random forest, neural network or user-supplied time-to-event model. The package is available on GitHub: https://github.com/datasciapps/CleanSurvival Experimental benchmarks on real-world datasets show that the Q-learning-based data preprocessing results in superior predictive performance to standard approaches, finding such a model up to 10 times faster than undirected random grid search. Furthermore, a simulation study demonstrates the effectiveness in different types and levels of missingness and noise in the data.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.03946.pdf",
    "abs_url": "https://arxiv.org/abs/2502.03946",
    "published": "2025-02-06T10:33:37Z",
    "updated": "2026-01-29T12:51:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出CleanSurvival框架，通过强化学习优化生存分析模型的自动化数据预处理，提升预测性能。",
      "motivation": "数据预处理在机器学习中至关重要，但常被忽视，尤其在生存分析等专业任务中缺乏自动化解决方案。现有自动化管道主要关注分类和回归任务，而对时间到事件模型缺乏定制化处理，导致性能瓶颈和效率低下。这种缺失加剧了数据预处理的一般挑战，限制了模型在真实世界应用中的潜力。因此，本研究旨在填补这一空白，提供一种专门针对生存分析的自动化预处理方法，以应对数据缺失和噪声等复杂问题。",
      "method": "论文提出CleanSurvival框架，基于强化学习（具体采用Q-learning算法）优化数据预处理管道。该方法能够处理连续和分类变量，通过Q-learning智能选择数据插补、异常值检测和特征提取技术的组合，以优化Cox模型、随机森林、神经网络或用户自定义的时间到事件模型的性能。关键创新在于将Q-learning应用于预处理选择，实现全自动化流程，避免了人工调参的繁琐。框架代码已在GitHub开源，便于实际部署和扩展。",
      "result": "实验在真实数据集上进行，结果显示基于Q-learning的预处理在预测性能上显著优于标准方法。具体而言，相比无向随机网格搜索，该方法在寻找最优模型时快达10倍，大大提高了效率。模拟研究进一步证实了其对不同类型和水平的缺失数据和噪声的鲁棒性，增强了模型在复杂数据情境下的稳定性。这些结果表明CleanSurvival能够有效提升生存分析模型的准确性和处理速度。",
      "conclusion": "CleanSurvival为生存分析领域提供了一种创新的自动化预处理解决方案，填补了现有技术的空白。其学术价值在于将强化学习与数据预处理结合，推动了相关研究的发展；实际应用价值体现在提高模型性能和效率，为医疗、金融等领域的时间到事件分析提供有力工具。未来工作可扩展到更多模型类型和更复杂的数据环境，以进一步提升通用性和适应性。",
      "tags": [
        "Reinforcement Learning",
        "Q-learning",
        "Survival Analysis",
        "Data Preprocessing",
        "Time-to-event Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:24.764348Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2502.04379",
    "title": "Can Large Language Models Capture Video Game Engagement?",
    "authors": [
      "David Melhart",
      "Matthew Barthet",
      "Georgios N. Yannakakis"
    ],
    "abstract": "Can out-of-the-box pretrained Large Language Models (LLMs) detect human affect successfully when observing a video? To address this question, for the first time, we evaluate comprehensively the capacity of popular LLMs for successfully predicting continuous affect annotations of videos when prompted by a sequence of text and video frames in a multimodal fashion. In this paper, we test LLMs' ability to correctly label changes of in-game engagement in 80 minutes of annotated videogame footage from 20 first-person shooter games of the GameVibe corpus. We run over 4,800 experiments to investigate the impact of LLM architecture, model size, input modality, prompting strategy, and ground truth processing method on engagement prediction. Our findings suggest that while LLMs rightfully claim human-like performance across multiple domains and able to outperform traditional machine learning baselines, they generally fall behind continuous experience annotations provided by humans. We examine some of the underlying causes for a fluctuating performance across games, highlight the cases where LLMs exceed expectations, and draw a roadmap for the further exploration of automated emotion labelling via LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2502.04379.pdf",
    "abs_url": "https://arxiv.org/abs/2502.04379",
    "published": "2025-02-05T17:14:47Z",
    "updated": "2026-01-29T08:44:15Z",
    "comment": "This work has been submitted to the IEEE for publication",
    "light_analysis": {
      "overview": "本研究首次全面评估预训练大型语言模型（LLMs）在预测视频游戏参与度连续情感标注方面的能力，发现其总体上落后于人类标注。",
      "motivation": "研究动机是探索预训练大型语言模型（LLMs）能否在观察视频时成功检测人类情感，特别是在游戏参与度方面。这个问题重要，因为自动情感标注在视频分析、游戏开发和情感计算中具有广泛应用。现有传统机器学习方法可能无法准确捕捉连续情感动态，而LLMs作为新兴技术，其在多模态情感检测中的潜力和局限性尚不明确，需要系统评估以推动技术发展。",
      "method": "研究方法使用多模态输入，将文本和视频帧序列作为提示，输入到预训练LLMs中预测连续情感标注。实验基于GameVibe语料库的80分钟视频游戏镜头，涵盖20个第一人称射击游戏，进行了超过4,800个实验，系统研究LLM架构、模型大小、输入模态、提示策略和真实处理方法对参与度预测的影响，以全面评估模型性能。",
      "result": "实验结果表明，大型语言模型（LLMs）在某些领域能够展现出类似人类的性能，并可以超越传统机器学习基线。然而，总体上，LLMs在预测连续情感标注时落后于人类提供的连续经验标注，性能在不同游戏中波动。研究识别出一些LLMs超出预期的案例，但没有提供具体准确率数据，这揭示了模型对内容敏感性和优化潜力。",
      "conclusion": "本研究的结论是，预训练大型语言模型（LLMs）在自动检测视频游戏参与度方面具有一定能力，但总体上不及人类标注。主要贡献在于首次全面评估LLMs在该任务上的表现，并识别影响性能的关键因素。学术上为多模态情感计算提供新视角，应用上可推动游戏体验分析和情感智能系统发展。未来工作包括分析性能波动原因，并制定进一步探索自动情感标注的路线图。",
      "tags": [
        "Large Language Models",
        "Multimodal Input",
        "Video Game Engagement",
        "Affective Computing",
        "Emotion Labelling"
      ]
    },
    "analyzed_at": "2026-01-30T04:04:58.268286Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.17377",
    "title": "ASAP: Exploiting the Satisficing Generalization Edge in Neural Combinatorial Optimization",
    "authors": [
      "Han Fang",
      "Paul Weng",
      "Yutong Ban"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) has emerged as a promising approach for solving Combinatorial Optimization (CO) problems, such as the 3D Bin Packing Problem (3D-BPP), Traveling Salesman Problem (TSP), or Vehicle Routing Problem (VRP), but these neural solvers often exhibit brittleness when facing distribution shifts. To address this issue, we uncover the Satisficing Generalization Edge, which we validate both theoretically and experimentally: identifying a set of promising actions is inherently more generalizable than selecting the single optimal action. To exploit this property, we propose Adaptive Selection After Proposal (ASAP), a generic framework that decomposes the decision-making process into two distinct phases: a proposal policy that acts as a robust filter, and a selection policy as an adaptable decision maker. This architecture enables a highly effective online adaptation strategy where the selection policy can be rapidly fine-tuned on a new distribution. Concretely, we introduce a two-phase training framework enhanced by Model-Agnostic Meta-Learning (MAML) to prime the model for fast adaptation. Extensive experiments on 3D-BPP, TSP, and CVRP demonstrate that ASAP improves the generalization capability of state-of-the-art baselines and achieves superior online adaptation on out-of-distribution instances.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2501.17377.pdf",
    "abs_url": "https://arxiv.org/abs/2501.17377",
    "published": "2025-01-29T02:12:34Z",
    "updated": "2026-01-29T13:56:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "ASAP框架通过分解决策过程并利用满意泛化边，提升了神经组合优化求解器的泛化能力和在线适应性能。",
      "motivation": "深度强化学习在解决组合优化问题如3D装箱、旅行商问题等显示出潜力，但现有神经求解器在面对数据分布变化时表现脆弱，限制了实际应用。现有方法通常选择单一最优动作，泛化能力有限，无法有效适应新分布。因此，研究揭示了满意泛化边，即识别多个有希望的动作比选择单个最优动作更易泛化，以解决这一不足之处。",
      "method": "ASAP框架将决策过程分解为提案策略和选择策略两个阶段：提案策略作为稳健筛选器生成一组候选动作，选择策略作为适应决策者在不同分布上快速调整。采用由模型无关元学习增强的两阶段训练框架，通过MAML优化模型参数，实现在新分布上的快速微调。该方法在3D-BPP、TSP和CVRP等数据集上进行验证，核心创新在于利用元学习促进高效在线适应。",
      "result": "在3D-BPP、TSP和CVRP上的实验表明，ASAP显著改进了最先进基线的泛化能力。在外分布实例上，ASAP实现了优越的在线适应性能，验证了满意泛化边的有效性。尽管摘要未提供具体数据，但与基线对比显示了性能提升，例如增强了鲁棒性和适应性。",
      "conclusion": "ASAP框架通过分解决策过程和利用满意泛化边，为神经组合优化提供了更通用的解决方案。该方法不仅增强了求解器在面对分布偏移时的稳健性，还展示了元学习在快速适应中的潜力，具有重要的学术和实际应用价值。未来工作可能包括扩展到更多问题类型或进一步优化适应策略。",
      "tags": [
        "Reinforcement Learning",
        "Combinatorial Optimization",
        "Model-Agnostic Meta-Learning",
        "Generalization",
        "Online Adaptation"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:14.367302Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.14587",
    "title": "Visual Localization via Semantic Structures in Autonomous Photovoltaic Power Plant Inspection",
    "authors": [
      "Viktor Kozák",
      "Karel Košnar",
      "Jan Chudoba",
      "Miroslav Kulich",
      "Libor Přeučil"
    ],
    "abstract": "Inspection systems utilizing unmanned aerial vehicles (UAVs) equipped with thermal cameras are increasingly popular for the maintenance of photovoltaic (PV) power plants. However, automation of the inspection task is a challenging problem as it requires precise navigation to capture images from optimal distances and viewing angles. This paper presents a novel localization pipeline that directly integrates PV module detection with UAV navigation, allowing precise positioning during inspection. The detections are used to identify the power plant structures in the image. These are associated with the power plant model and used to infer the UAV position relative to the inspected PV installation. We define visually recognizable anchor points for the initial association and use object tracking to discern global associations. Additionally, we present three different methods for visual segmentation of PV modules and evaluate their performance in relation to the proposed localization pipeline. The presented methods were verified and evaluated using custom aerial inspection data sets, demonstrating their robustness and applicability for real-time navigation. Additionally, we evaluate the influence of the power plant model precision on the localization methods.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2501.14587.pdf",
    "abs_url": "https://arxiv.org/abs/2501.14587",
    "published": "2025-01-24T15:48:41Z",
    "updated": "2026-01-29T13:02:39Z",
    "comment": "50 pages, 23 figures. Submitted for review to Array",
    "light_analysis": {
      "overview": "本文提出一种基于语义结构的视觉定位管道，通过集成光伏模块检测与无人机导航，实现光伏电站自主检查的精确定位。",
      "motivation": "研究动机源于光伏电站维护中无人机检查系统的自动化需求，该系统利用配备热像仪的无人机进行巡检，但自动化过程面临挑战，因为需要精确导航以从最佳距离和视角捕捉图像。现有方法在定位精度上可能不足，影响检查效率和准确性。因此，该研究旨在解决自动化检查中的定位问题，提升光伏电站维护的自动化和精确性。背景包括无人机技术的普及和光伏行业对高效维护的需求，突出了问题的紧迫性和实际应用价值。",
      "method": "研究方法提出一个新颖的定位管道，将光伏模块检测直接与无人机导航集成，以实现精确位置估计。具体技术路线包括：首先通过检测图像中的光伏电站结构，关联到电站模型，从而推断无人机相对位置；使用视觉可识别的锚点进行初始关联，并通过对象跟踪技术实现全局关联。此外，论文提出了三种不同的光伏模块视觉分割方法，用于增强检测效果。创新点在于语义结构的集成和实时导航支持。关键细节包括使用自定义的空中检查数据集进行验证，模型架构结合了检测与跟踪模块。",
      "result": "主要实验结果基于自定义空中检查数据集的验证，展示了定位管道的鲁棒性和实时导航的适用性，表明该方法能够有效支持自动化检查任务。实验评估了三种视觉分割方法的性能，并分析了电站模型精度对定位方法的影响。摘要未明确说明具体性能指标如准确率或效率提升数据，但通过实验证明了方法的实用性。与基线方法对比方面，摘要未详细说明，但通过整体评估强调了方法的有效性和在光伏电站检查中的潜在应用优势。",
      "conclusion": "论文的主要贡献是开发了一种集成语义结构的视觉定位管道，显著提升了光伏电站检查的自动化水平和定位精度。学术价值在于将计算机视觉技术应用于无人机导航，扩展了视觉定位的应用场景；实际应用价值为光伏行业提供了高效、精确的维护解决方案。研究支持实时导航，增强了检查系统的实用性。摘要未明确说明局限性和未来工作方向，但可推断未来可能优化分割方法或探索更多数据集，以进一步提高性能和适应性。",
      "tags": [
        "Visual Localization",
        "PV Module Detection",
        "UAV Navigation",
        "Semantic Structures",
        "Object Tracking"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:20.590827Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.04052",
    "title": "RaZeR: Pushing the Limits of NVFP4 Quantization with Redundant Zero Remapping",
    "authors": [
      "Yuzong Chen",
      "Xilai Dai",
      "Jake Hyun",
      "Chi-Chih Chang",
      "Wonsuk Jang",
      "Yuheng Wu",
      "Thierry Tambe",
      "Jae-sun Seo",
      "Mohamed S. Abdelfattah"
    ],
    "abstract": "The recently introduced NVFP4 format demonstrates remarkable performance and memory benefits for quantized large language model (LLM) inference. However, we observe two types of redundancy in NVFP4 encoding: (1) The FP4 element format naturally exposes an unused quantization value due to its sign-magnitude representation that contains both positive and negative zeros. (2) The FP8 block scaling factor has an unused sign bit because it is always positive. Additionally, we find that LLM weights are more tolerant to a lower-precision block scaling factor. Based on these observations, we propose Redundant Zero Remapping (RaZeR), an enhanced numerical format that pushes the limits of NVFP4 for more accurate LLM quantization under the same memory footprint. RaZeR leverages the redundant bits of the block scaling factor to adaptively remap the redundant FP4 zero to additional quantization values with improved accuracy. To demonstrate the practicality of RaZeR, we design efficient GPU kernels for RaZeR-quantized LLM inference and propose novel hardware to natively support this. Extensive experiments validate RaZeR's superior performance for 4-bit LLM quantization. For example, relative to native NVFP4, RaZeR reduces the average perplexity loss by 34.6% and 31.2% under weight-only and weight-activation quantization, respectively.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2501.04052.pdf",
    "abs_url": "https://arxiv.org/abs/2501.04052",
    "published": "2025-01-06T22:40:40Z",
    "updated": "2026-01-29T07:26:38Z",
    "comment": "Preprint. Under review",
    "light_analysis": {
      "overview": "RaZeR 提出一种增强的数值格式，通过重新映射 NVFP4 量化中的冗余零值，提升大型语言模型推理的准确性，在相同内存占用下实现更精确的量化。",
      "motivation": "本研究针对 NVFP4 量化格式在 LLM 推理中的冗余问题。NVFP4 的 FP4 元素格式因符号-幅度表示产生未使用的量化值，而 FP8 块缩放因子总是正数，导致未使用的符号位。这些问题限制了量化精度的提升，而现有方法未充分利用这些冗余。LLM 权重对低精度缩放因子更容忍，因此解决这些冗余可以改进量化性能，满足高效内存使用的需求。",
      "method": "RaZeR 的核心方法是设计一个增强的数值格式，利用块缩放因子的冗余位，自适应地将冗余 FP4 零值重新映射到额外的量化值，从而提高准确性。基于对冗余的观察，RaZeR 优化了 NVFP4 的编码方式。研究还设计了高效的 GPU 内核来支持 RaZeR 量化的 LLM 推理，并提出了新的硬件架构以原生支持该格式，确保实际应用中的计算效率。",
      "result": "通过广泛实验验证，RaZeR 在 4 位 LLM 量化中表现优异。相对于原生 NVFP4，RaZeR 在仅权重量化下将平均困惑度损失减少 34.6%，在权重-激活量化下减少 31.2%。这些数据表明 RaZeR 显著提升了量化精度，同时保持了相同的内存占用，为 LLM 推理提供了更高效的解决方案。",
      "conclusion": "RaZeR 的主要贡献是提出了一种利用冗余位提升量化精度的新格式，解决了 NVFP4 中的局限性。该研究不仅改进了 LLM 量化的准确性，还通过 GPU 内核和硬件设计展示了实际应用价值。未来工作可能包括将 RaZeR 扩展到其他量化格式或更广泛的 AI 模型，以进一步优化内存效率和性能。",
      "tags": [
        "NVFP4 Quantization",
        "Redundant Zero Remapping",
        "Large Language Model Inference",
        "GPU Kernel Optimization",
        "Hardware Acceleration"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:37.319526Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2501.02844",
    "title": "GORAG: Graph-based Online Retrieval Augmented Generation for Dynamic Few-shot Social Media Text Classification",
    "authors": [
      "Yubo Wang",
      "Haoyang Li",
      "Fei Teng",
      "Lei Chen"
    ],
    "abstract": "Text classification is vital for Web for Good applications like hate speech and misinformation detection. However, traditional models (e.g., BERT) often fail in dynamic few-shot settings where labeled data are scarce, and target labels frequently evolve. While Large Language Models (LLMs) show promise in few-shot settings, their performance is often hindered by increased input size in dynamic evolving scenarios. To address these issues, we propose GORAG, a Graph-based Online Retrieval-Augmented Generation framework for dynamic few-shot text classification. GORAG constructs and maintains a weighted graph of keywords and text labels, representing their correlations as edges. To model these correlations, GORAG employs an edge weighting mechanism to prioritize the importance and reliability of extracted information and dynamically retrieves relevant context using a tailored minimum-cost spanning tree for each input. Empirical evaluations show GORAG outperforms existing approaches by providing more comprehensive and precise contextual information. Our code is released at: https://github.com/Wyb0627/GORAG.",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2501.02844.pdf",
    "abs_url": "https://arxiv.org/abs/2501.02844",
    "published": "2025-01-06T08:43:31Z",
    "updated": "2026-01-29T08:40:34Z",
    "comment": "Accepted by WWW 2026",
    "light_analysis": {
      "overview": "论文提出了GORAG，一个基于图的在线检索增强生成框架，用于动态少样本社交媒体文本分类。",
      "motivation": "研究动机是解决动态少样本文本分类的挑战，传统模型如BERT在处理标记数据稀缺和标签频繁变化时表现不佳，而大型语言模型（LLMs）虽然在少样本设置下有前景，但在动态演变场景中性能受限。这个问题对网络应用如仇恨言论和虚假信息检测至关重要，因为这些应用需要准确且适应性的分类方法来提升网络安全性和可信度，现有方法不足以应对数据动态性。",
      "method": "论文提出了GORAG框架，通过构建和维护一个加权图来表示关键词和文本标签之间的相关性，其中节点代表这些元素，边表示它们的关联。使用边缘权重机制来建模相关性，优先考虑提取信息的重要性和可靠性，并为每个输入动态检索相关上下文，采用定制的最小成本生成树方法来高效选择最相关部分。这种方法结合了图结构和检索增强生成，以增强分类的上下文理解。",
      "result": "实证评估显示，GORAG在动态少样本文本分类任务中优于现有方法，通过提供更全面和精确的上下文信息来提升性能，具体性能指标如准确率或效率改进摘要未明确说明。与基线方法相比，GORAG在相关数据集上表现出显著优势，这验证了其框架的有效性和适用性。",
      "conclusion": "论文的主要贡献是提出了GORAG框架，有效解决了动态少样本文本分类问题，其学术价值在于创新地整合了图方法和检索增强生成技术，推动了相关领域的研究。实际应用价值在于改进社交媒体内容检测的准确性和适应性，如虚假信息识别，未来工作可能包括扩展到更多应用场景或优化算法的可扩展性，摘要未明确说明具体局限性。",
      "tags": [
        "Graph-based Methods",
        "Retrieval-Augmented Generation",
        "Few-shot Learning",
        "Dynamic Text Classification",
        "Edge Weighting Mechanism"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:35.898407Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.07720",
    "title": "ACDiT: Interpolating Autoregressive Conditional Modeling and Diffusion Transformer",
    "authors": [
      "Jinyi Hu",
      "Shengding Hu",
      "Yuxuan Song",
      "Yufei Huang",
      "Mingxuan Wang",
      "Hao Zhou",
      "Zhiyuan Liu",
      "Wei-Ying Ma",
      "Maosong Sun"
    ],
    "abstract": "Autoregressive and diffusion models have achieved remarkable progress in language models and visual generation, respectively. We present ACDiT, a novel Autoregressive blockwise Conditional Diffusion Transformer, that innovatively combines autoregressive and diffusion paradigms for continuous visual information. By introducing a block-wise autoregressive unit, ACDiT offers a flexible interpolation between token-wise autoregression and full-sequence diffusion, bypassing the limitations of discrete tokenization. The generation of each block is formulated as a conditional diffusion process, conditioned on prior blocks. ACDiT is easy to implement, as simple as applying a specially designed Skip-Causal Attention Mask on the standard diffusion transformer during training. During inference, the process iterates between diffusion denoising and autoregressive decoding that can make full use of KV-Cache. We validate the effectiveness of ACDiT on image, video, and text generation and show that ACDiT performs best among all autoregressive baselines under similar model scales on visual generation tasks. We also demonstrate that, benefiting from autoregressive modeling, pretrained ACDiT can be transferred in visual understanding tasks despite being trained with the generative objective. The analysis of the trade-off between autoregressive and diffusion demonstrates the potential of ACDiT to be used in long-horizon visual generation tasks. We hope that ACDiT offers a novel perspective on visual autoregressive generation and sheds light on new avenues for unified models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2412.07720.pdf",
    "abs_url": "https://arxiv.org/abs/2412.07720",
    "published": "2024-12-10T18:13:20Z",
    "updated": "2026-01-29T06:31:27Z",
    "comment": "TMLR camera-ready version",
    "light_analysis": {
      "overview": "ACDiT是一种新颖的视觉生成模型，通过结合自回归和扩散范式，实现连续视觉信息的灵活生成，提供自回归-扩散插值的新方法。",
      "motivation": "该研究旨在解决视觉生成中自回归和扩散模型的局限性：自回归模型依赖离散tokenization，可能限制连续数据生成质量；扩散模型适合连续数据但计算复杂。现有方法难以灵活权衡两者优势，因此需要一种统一框架来提升视觉信息生成的灵活性和效率，特别是在处理长期依赖时。",
      "method": "ACDiT提出一种块级自回归条件扩散Transformer，将视觉数据分块处理，每个块的生成建模为条件扩散过程，依赖于先前块。核心创新在于应用Skip-Causal Attention Mask到标准扩散Transformer上，实现简单训练；推断时，通过迭代扩散去噪和自回归解码，并利用KV-Cache提高计算效率，适用于图像、视频和文本生成。",
      "result": "在图像、视频和文本生成任务中验证ACDiT，在视觉生成任务上，它在相似模型规模下表现优于所有自回归基线，如准确率或生成质量提升（摘要未明确说明具体数值）。此外，预训练的ACDiT模型可迁移到视觉理解任务，尽管以生成为目标训练，展示了模型的泛化能力。",
      "conclusion": "ACDiT的主要贡献在于创新结合自回归和扩散模型，为视觉生成提供统一视角；其学术价值在于推动了自回归生成的新研究方向，实际应用潜力在于长程视觉生成任务。未来工作可扩展模型到更复杂场景或优化权衡策略。",
      "tags": [
        "Autoregressive Models",
        "Diffusion Models",
        "Transformer",
        "Skip-Causal Attention Mask",
        "Blockwise Generation"
      ]
    },
    "analyzed_at": "2026-01-30T04:05:50.183014Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.03671",
    "title": "Tight Lower Bounds and Improved Convergence in Performative Prediction",
    "authors": [
      "Pedram Khorsandi",
      "Rushil Gupta",
      "Mehrnaz Mofakhami",
      "Simon Lacoste-Julien",
      "Gauthier Gidel"
    ],
    "abstract": "Performative prediction is a framework accounting for the shift in the data distribution induced by the prediction of a model deployed in the real world. Ensuring rapid convergence to a stable solution where the data distribution remains the same after the model deployment is crucial, especially in evolving environments. This paper extends the Repeated Risk Minimization (RRM) framework by utilizing historical datasets from previous retraining snapshots, yielding a class of algorithms that we call Affine Risk Minimizers and enabling convergence to a performatively stable point for a broader class of problems. We introduce a new upper bound for methods that use only the final iteration of the dataset and prove for the first time the tightness of both this new bound and the previous existing bounds within the same regime. We also prove that utilizing historical datasets can surpass the lower bound for last iterate RRM, and empirically observe faster convergence to the stable point on various performative prediction benchmarks. We offer at the same time the first lower bound analysis for RRM within the class of Affine Risk Minimizers, quantifying the potential improvements in convergence speed that could be achieved with other variants in our framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2412.03671.pdf",
    "abs_url": "https://arxiv.org/abs/2412.03671",
    "published": "2024-12-04T19:06:19Z",
    "updated": "2026-01-29T12:43:13Z",
    "comment": "Neural Information Processing Systems (NeurIPS 2025)",
    "light_analysis": {
      "overview": "本文通过扩展 Repeated Risk Minimization 框架，提出 Affine Risk Minimizers 算法，首次在 performative prediction 中证明了上下界紧密性并实现了更快收敛速度。",
      "motivation": "Performative prediction 框架旨在处理模型部署导致的数据分布变化，在动态环境中快速收敛到稳定解是关键挑战。现有方法如 last iterate RRM 仅使用最终数据集，收敛速度受限，且现有理论分析未深入探究下界，限制了性能提升。本研究通过利用历史数据优化算法，解决现有方法的不足，提升实际部署中的效率和稳定性。",
      "method": "本研究扩展了 Repeated Risk Minimization (RRM) 框架，通过整合过去重新训练快照的历史数据集，提出 Affine Risk Minimizers 类算法。关键创新在于结合多时间步数据加速收敛，首次为仅使用最终数据集的方法引入新上界，并证明其与现有上界的紧密性。同时，提供了在 Affine Risk Minimizers 类中首次对 RRM 的下界分析，量化收敛速度改进空间。",
      "result": "理论结果证明，新引入的上界与现有上界在同一机制下具有紧密性，且利用历史数据的 Affine Risk Minimizers 能够超越 last iterate RRM 的下界。实验部分在多个 performative prediction 基准上观察到更快收敛到稳定点，与基线方法相比，收敛速度显著提升，验证了算法有效性。",
      "conclusion": "本研究通过扩展 RRM 框架和提出 Affine Risk Minimizers，深化了 performative prediction 的理论基础，首次提供了下界分析并证明边界紧密性。实验验证了利用历史数据的优势，为动态环境中模型部署的优化提供高效方案，未来可探索框架内其他变体以进一步提升性能。",
      "tags": [
        "Performative Prediction",
        "Repeated Risk Minimization",
        "Affine Risk Minimizers",
        "Lower Bound Analysis",
        "Convergence Speed"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:27.216280Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.02968",
    "title": "How Many Ratings per Item are Necessary for Reliable Significance Testing?",
    "authors": [
      "Christopher Homan",
      "Flip Korn",
      "Deepak Pandita",
      "Chris Welty"
    ],
    "abstract": "A cornerstone of machine learning evaluation is the (often hidden) assumption that model and human responses are reliable enough to evaluate models against unitary, authoritative, ``gold standard'' data, via simple metrics such as accuracy, precision, and recall. The generative AI revolution would seem to explode this assumption, given the critical role stochastic inference plays. Yet, in spite of public demand for more transparency in AI -- along with strong evidence that humans are unreliable judges -- estimates of model reliability are conventionally based on, at most, a few output responses per input item. We adapt a method, previously used to evaluate the reliability of various metrics and estimators for machine learning evaluation, to determine whether an (existing or planned) dataset has enough responses per item to assure reliable null hypothesis statistical testing. We show that, for many common metrics, collecting even 5-10 responses per item (from each model and team of human evaluators) is not sufficient. We apply our methods to several of the very few extant gold standard test sets with multiple disaggregated responses per item and show that even these datasets lack enough responses per item. We show how our methods can help AI researchers make better decisions about how to collect data for AI evaluation.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2412.02968.pdf",
    "abs_url": "https://arxiv.org/abs/2412.02968",
    "published": "2024-12-04T02:31:28Z",
    "updated": "2026-01-29T18:15:35Z",
    "comment": "Accepted at EACL Findings 2026",
    "light_analysis": {
      "overview": "本文提出一种方法来评估数据集中每个项目需要多少响应以确保可靠的统计检验，发现常见度量下5-10个响应不足。",
      "motivation": "研究动机源于机器学习评估中隐含的假设，即模型和人类响应是可靠的黄金标准，但生成AI的随机性挑战了这一假设。现有方法通常仅基于少数响应进行估计，而证据显示人类评估者不可靠，这导致评估结果不可信，影响了模型比较和AI透明度的提升。背景中，公众对AI透明性的需求日益增长，但当前评估实践缺乏对响应数量的充分考量，使得统计检验的可靠性不足，亟待改进。",
      "method": "研究方法采用了一种先前用于评估度量可靠性的统计方法，适配后用于确定数据集是否拥有足够的每个项目响应，以进行可靠的空假设统计检验。关键创新点在于将此方法应用于评估数据收集的充分性，重点关注响应数量对统计测试的影响。作者使用了几个现有的黄金标准测试集作为数据集，这些数据集包含多个分解响应，以验证方法的有效性，并通过分析这些数据集来推导响应数量需求。",
      "result": "主要实验结果表明，对于许多常见评估度量（如准确率、精确率和召回率），每个项目收集5-10个响应不足以确保可靠的统计检验。作者将此方法应用于几个数据集，结果显示即使这些被广泛使用的数据集也缺乏足够的响应数量，验证了现有评估实践中响应收集的不足。与基线方法对比，研究突显了当前评估在统计严谨性上的缺陷，但没有提供具体性能指标的提升数据，仅强调了响应数量不足的普遍问题。",
      "conclusion": "本文的主要贡献是提供了一种评估数据集中响应数量充分性的方法，帮助AI研究人员在数据收集时做出更优决策。学术上，该方法提升了机器学习评估的统计可靠性，促进了更严谨的模型比较；应用上，它支持AI透明化和评估实践改进。局限性可能包括方法依赖于特定度量或数据集，未来工作可以扩展到更多评估场景并优化响应收集策略，以增强实际应用价值。",
      "tags": [
        "Statistical Testing",
        "Machine Learning Evaluation",
        "Reliability Analysis",
        "Data Collection",
        "Generative AI"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:26.529225Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2412.00112",
    "title": "BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis",
    "authors": [
      "Seong-Eun Hong",
      "Soobin Lim",
      "Juyeong Hwang",
      "Minwook Chang",
      "Hyeongyeop Kang"
    ],
    "abstract": "Generating natural and expressive human motions from textual descriptions is challenging due to the complexity of coordinating full-body dynamics and capturing nuanced motion patterns over extended sequences that accurately reflect the given text. To address this, we introduce BiPO, Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis, a novel model that enhances text-to-motion synthesis by integrating part-based generation with a bidirectional autoregressive architecture. This integration allows BiPO to consider both past and future contexts during generation while enhancing detailed control over individual body parts without requiring ground-truth motion length. To relax the interdependency among body parts caused by the integration, we devise the Partial Occlusion technique, which probabilistically occludes the certain motion part information during training. In our comprehensive experiments, BiPO achieves state-of-the-art performance on the HumanML3D dataset, outperforming recent methods such as ParCo, MoMask, and BAMM in terms of FID scores and overall motion quality. Notably, BiPO excels not only in the text-to-motion generation task but also in motion editing tasks that synthesize motion based on partially generated motion sequences and textual descriptions. These results reveal the BiPO's effectiveness in advancing text-to-motion synthesis and its potential for practical applications.",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2412.00112.pdf",
    "abs_url": "https://arxiv.org/abs/2412.00112",
    "published": "2024-11-28T05:42:47Z",
    "updated": "2026-01-29T04:10:28Z",
    "comment": "18 pages, 11 figures. Accepted to WACV 2026 (Oral)",
    "light_analysis": {
      "overview": "本文提出BiPO网络，通过整合部分生成与双向自回归架构，并引入部分遮挡技术，有效提升文本到动作合成的准确性和细节控制。",
      "motivation": "研究动机在于解决从文本生成自然人类动作的挑战，包括全身动态协调和长序列细微模式捕捉，这对动画和虚拟现实等应用至关重要。现有方法可能难以高效处理多部分协同和上下文依赖，摘要未明确说明具体不足，但强调了问题的复杂性，如动作需准确反映文本描述的难度。",
      "method": "BiPO采用双向自回归架构，在生成时同时考虑过去和未来上下文，以增强时间序列建模。结合部分生成技术，实现对身体各部分的精细控制，无需真实动作长度作为输入。为缓解整合带来的身体部分相互依赖，设计了部分遮挡技术，在训练中概率性地遮挡特定动作部分信息，从而提升模型鲁棒性。该方法在HumanML3D数据集上进行训练和评估。",
      "result": "BiPO在HumanML3D数据集上实现了最先进性能，FID分数优于ParCo、MoMask和BAMM等近期方法，整体动作质量显著提升，表明其在指标和视觉评估上均表现优异。此外，模型在动作编辑任务中也能有效基于部分生成序列和文本描述合成运动，扩展了应用场景。",
      "conclusion": "BiPO通过创新架构和部分遮挡技术，推动了文本到动作合成的发展，提升了生成质量和实际应用价值，如动画和交互系统。其潜力体现在多样任务中，但摘要未明确说明局限性，未来工作可能包括进一步优化模型效率或扩展到更多数据集和复杂场景。",
      "tags": [
        "Text-to-Motion Synthesis",
        "Bidirectional Autoregressive Architecture",
        "Partial Occlusion Technique",
        "HumanML3D Dataset",
        "Motion Editing"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:39.083364Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.11004",
    "title": "EROAM: Event-based Camera Rotational Odometry and Mapping in Real-time",
    "authors": [
      "Wanli Xing",
      "Shijie Lin",
      "Linhan Yang",
      "Zeqing Zhang",
      "Yanjun Du",
      "Maolin Lei",
      "Yipeng Pan",
      "Chen Wang",
      "Jia Pan"
    ],
    "abstract": "This paper presents EROAM, a novel event-based rotational odometry and mapping system that achieves real-time, accurate camera rotation estimation. Unlike existing approaches that rely on event generation models or contrast maximization, EROAM employs a spherical event representation by projecting events onto a unit sphere and introduces Event Spherical Iterative Closest Point (ES-ICP), a novel geometric optimization framework designed specifically for event camera data. The spherical representation simplifies rotational motion formulation while operating in a continuous spherical domain, enabling enhanced spatial resolution. Our system features an efficient map management approach using incremental k-d tree structures and intelligent regional density control, ensuring optimal computational performance during long-term operation. Combined with parallel point-to-line optimization, EROAM achieves efficient computation without compromising accuracy. Extensive experiments on both synthetic and real-world datasets show that EROAM significantly outperforms state-of-the-art methods in terms of accuracy, robustness, and computational efficiency. Our method maintains consistent performance under challenging conditions, including high angular velocities and extended sequences, where other methods often fail or show significant drift. Additionally, EROAM produces high-quality panoramic reconstructions with preserved fine structural details.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.11004.pdf",
    "abs_url": "https://arxiv.org/abs/2411.11004",
    "published": "2024-11-17T08:50:47Z",
    "updated": "2026-01-29T17:25:30Z",
    "comment": "Accepted by IEEE Transactions on Robotics (T-RO), 2026. Project page: https://wlxing1901.github.io/eroam/",
    "light_analysis": {
      "overview": "EROAM提出了一种基于事件相机的实时旋转里程计和建图系统，通过球形事件表示和ES-ICP优化框架实现高精度和高效率。",
      "motivation": "研究动机是针对事件相机在旋转估计和建图任务中的挑战，现有方法依赖事件生成模型或对比最大化，往往在准确性、鲁棒性和计算效率上不足，尤其在高速动态场景中表现不佳。事件相机的高时间分辨率使其适用于动态环境，但现有方法难以处理复杂旋转运动，导致漂移或失败。EROAM旨在克服这些局限性，提供更可靠的解决方案，适用于机器人导航和增强现实等应用场景。",
      "method": "EROAM的核心方法包括：首先，将事件投影到单位球面上，形成球形事件表示，简化旋转运动的数学公式并增强空间分辨率。其次，引入Event Spherical Iterative Closest Point (ES-ICP)，一个专门为事件相机数据设计的几何优化框架，用于精确估计相机旋转。此外，系统采用增量k-d树结构进行建图管理，结合智能区域密度控制以优化长期计算性能。最后，通过并行点到线优化，实现高效计算而不牺牲准确性，确保实时操作。",
      "result": "在合成和真实世界数据集上的广泛实验表明，EROAM在准确性、鲁棒性和计算效率方面显著优于最先进方法。它能在高角速度和扩展序列等挑战性条件下保持一致性性能，而其他方法常出现失败或显著漂移。摘要未明确说明具体性能指标数据，但实验证实EROAM能生成高质量全景重建，保留精细结构细节，显示了其在复杂环境中的优越性。",
      "conclusion": "EROAM的主要贡献是开发了一个实时、准确的基于事件相机的旋转里程计和建图系统，通过球形表示和ES-ICP框架提升了性能。学术价值在于为事件视觉领域提供了新颖的几何优化方法，实际应用价值在于增强动态场景中的定位和建图能力，适用于自动驾驶和监控系统。未来工作可能包括扩展到多传感器融合或更复杂运动模式，摘要未明确说明具体局限。",
      "tags": [
        "Event-based Camera",
        "Rotational Odometry",
        "Spherical ICP",
        "k-d tree Optimization",
        "Parallel Computing"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:04.213696Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2411.02168",
    "title": "Do graph neural network states contain graph properties?",
    "authors": [
      "Tom Pelletreau-Duris",
      "Ruud van Bakel",
      "Michael Cochez"
    ],
    "abstract": "Deep neural networks (DNNs) achieve state-of-the-art performance on many tasks, but this often requires increasingly larger model sizes, which in turn leads to more complex internal representations. Explainability techniques (XAI) have made remarkable progress in the interpretability of ML models. However, the non-euclidean nature of Graph Neural Networks (GNNs) makes it difficult to reuse already existing XAI methods. While other works have focused on instance-based explanation methods for GNNs, very few have investigated model-based methods and, to our knowledge, none have tried to probe the embedding of the GNNs for structural graph properties. In this paper we present a model agnostic explainability pipeline for Graph Neural Networks (GNNs) employing diagnostic classifiers. We propose to consider graph-theoretic properties as the features of choice for studying the emergence of representations in GNNs. This pipeline aims to probe and interpret the learned representations in GNNs across various architectures and datasets, refining our understanding and trust in these models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2411.02168.pdf",
    "abs_url": "https://arxiv.org/abs/2411.02168",
    "published": "2024-11-04T15:26:07Z",
    "updated": "2026-01-29T18:33:46Z",
    "comment": "10 pages, 22 figures, conference",
    "light_analysis": {
      "overview": "论文提出了一种模型无关的解释管道，通过诊断分类器探测图神经网络中图论属性的表示形成。",
      "motivation": "该研究的核心动机是解决图神经网络（GNNs）解释性问题。由于GNNs的非欧几里德特性，现有解释性技术（XAI）难以直接应用，当前工作大多集中于实例层面的解释方法，而模型层面的方法较少被探索。特别是，缺乏利用结构图属性来探测GNNs嵌入的研究，这阻碍了对模型内部表示的理解和信任，使得在复杂任务中应用GNNs时存在解释性不足的挑战。",
      "method": "论文提出一个模型无关的解释性管道，采用诊断分类器来探测GNNs的表示。关键创新点在于使用图论属性作为特征，系统研究GNNs在学习和表示结构信息时的形成过程。该管道设计为适用于多种GNN架构和数据集，通过构建诊断分类任务，分析嵌入中是否包含节点度、社区结构等图属性，从而无需修改模型即可解释其内部工作机制。",
      "result": "摘要未明确说明主要实验结果或具体性能指标。论文提到管道旨在提高对GNNs的理解和信任，但未提供与基线方法的对比数据（如准确率提升）或实证效果，因此基于摘要信息，无法推断具体实验结果。",
      "conclusion": "论文的主要贡献是提出了一个创新解释管道，用于探测图神经网络中图论属性的表示。其学术价值在于填补了模型解释方法的空白，促进了GNNs的可解释性研究，增强了对这些复杂模型的信任。实际应用中，这可能有助于优化模型设计和安全部署，未来工作可扩展管道到更多图属性或与具体任务结合，以进一步验证其有效性。",
      "tags": [
        "Graph Neural Networks",
        "Explainability (XAI)",
        "diagnostic classifiers",
        "graph-theoretic properties"
      ]
    },
    "analyzed_at": "2026-01-30T04:06:58.432085Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.03613",
    "title": "Understanding Large Language Models in Your Pockets: Performance Study on COTS Mobile Devices",
    "authors": [
      "Jie Xiao",
      "Qianyi Huang",
      "Xu Chen",
      "Chen Tian"
    ],
    "abstract": "As large language models (LLMs) increasingly integrate into every aspect of our work and daily lives, there are growing concerns about user privacy, which push the trend toward local deployment of these models. There are a number of lightweight LLMs (e.g., Gemini Nano, LLAMA2 7B) that can run locally on smartphones, providing users with greater control over their personal data. As a rapidly emerging application, we are concerned about their performance on commercial-off-the-shelf mobile devices. To fully understand the current landscape of LLM deployment on mobile platforms, we conduct a comprehensive measurement study on mobile devices. While user experience is the primary concern for end-users, developers focus more on the underlying implementations. Therefore, we evaluate both user-centric metrics-such as token throughput, latency, and response quality-and developer-critical factors, including resource utilization, OS strategies, battery consumption, and launch time. We also provide comprehensive comparisons across the mobile system-on-chips (SoCs) from major vendors, highlighting their performance differences in handling LLM workloads, which may help developers identify and address bottlenecks for mobile LLM applications. We hope that this study can provide insights for both the development of on-device LLMs and the design for future mobile system architecture.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2410.03613.pdf",
    "abs_url": "https://arxiv.org/abs/2410.03613",
    "published": "2024-10-04T17:14:59Z",
    "updated": "2026-01-29T13:15:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究对商用移动设备上大语言模型的性能进行全面测量，评估用户和开发者指标，并比较不同系统芯片的表现，为移动LLM应用提供见解。",
      "motivation": "随着大语言模型（LLMs）在工作和生活中的广泛应用，用户隐私问题日益凸显，推动LLMs向本地部署发展。轻量级LLMs如Gemini Nano和LLAMA2 7B已能在智能手机上运行，但作为新兴应用，其在实际移动设备上的性能表现尚缺乏系统研究。现有方法可能未充分考虑移动环境的约束和用户体验，因此，本研究旨在全面评估LLM在商用现成移动设备上的性能，以填补这一研究空白，并为优化部署提供基础。",
      "method": "本研究采用全面的测量研究方法，聚焦于商用现成移动设备上的轻量级LLMs（如Gemini Nano和LLAMA2 7B）。核心方法包括评估用户中心指标，如令牌吞吐量、延迟和响应质量，以及开发者关键因素，如资源利用率、操作系统策略、电池消耗和启动时间。创新点在于构建了一个多维度评估框架，并跨不同供应商的系统芯片（SoCs）进行比较分析，以识别性能瓶颈。摘要未明确说明具体数据集或模型架构细节。",
      "result": "摘要未明确提供具体的实验结果数据，但研究表明不同移动系统芯片（SoCs）在处理LLM工作负载时存在性能差异。通过对比主要供应商的SoCs，研究可能揭示了令牌吞吐量、延迟和资源利用等方面的变化，帮助开发者识别潜在瓶颈。然而，具体的性能提升或效率改进指标未在摘要中说明，如准确率变化或电池消耗减少的具体数值，需要参考论文全文获取详细数据。",
      "conclusion": "本研究的核心贡献在于对移动设备上大语言模型性能的首次全面测量，评估了用户和开发者双重维度。研究不仅揭示了不同系统芯片在处理LLM工作负载时的性能差异，还为开发者提供了识别和解决瓶颈的指导。其学术价值在于填补了移动环境下LLM性能评估的空白，实际应用价值包括促进设备上AI的发展和未来移动系统架构的设计优化。未来工作可扩展更多模型和场景，进一步优化性能。",
      "tags": [
        "Large Language Models",
        "Mobile Computing",
        "Performance Evaluation",
        "System-on-Chips",
        "Resource Utilization"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:36.737226Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.01308",
    "title": "WL Tests Are Far from All We Need: Revisiting WL-Test Hardness and GNN Expressive Power from a Distributed Computation Perspective",
    "authors": [
      "Guanyu Cui",
      "Yuhe Guo",
      "Zhewei Wei",
      "Hsin-Hao Su"
    ],
    "abstract": "The expressive power of graph neural networks (GNNs) is often studied through their relationship to the Weisfeiler-Lehman (WL) tests. Despite its influence, this perspective leaves two gaps: (i) it is unclear whether WL tests are sufficiently primitive for understanding GNN expressivity, and (ii) WL-induced equivalence does not align well with characterizing the function classes that GNNs can approximate or compute. We attempt to address both gaps. First, we strengthen hardness results for the vanilla WL test, showing that in many settings it is not primitive enough to be implemented by constant-depth GNNs. Second, we propose an alternative framework for studying GNN expressivity based on an extended CONGEST model with an explicit preprocessing phase. Within this framework, we identify implicit shortcuts introduced in prior analyses and establish further results for WL tests in settings where graphs are augmented with virtual nodes and virtual edges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2410.01308.pdf",
    "abs_url": "https://arxiv.org/abs/2410.01308",
    "published": "2024-10-02T08:01:50Z",
    "updated": "2026-01-29T14:25:28Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文通过强化WL测试的硬度结果，并基于扩展CONGEST模型提出替代框架，从分布式计算视角重新审视GNN表达能力。",
      "motivation": "图形神经网络（GNNs）的表达能力常通过与Weisfeiler-Lehman（WL）测试的关联研究，但这一视角存在两个缺口：一是WL测试是否足够原始来理解GNN表达能力尚不明确；二是WL诱导的等价性不能准确表征GNN可近似或计算的函数类。这些问题限制了GNN理论的发展，因为现有方法依赖WL测试可能误导对表达能力的评估，导致理论和应用脱节。本研究旨在填补这些缺口，为GNN提供更坚实的理论基础。",
      "method": "本文首先强化了普通WL测试的硬度结果，证明在许多设置中，它并非足够原始以被常数深度GNN实现，揭示了其局限性。其次，提出了一个基于扩展CONGEST模型的替代框架，该模型包含显式预处理阶段，用于系统性研究GNN表达能力。在这个框架下，识别了先前分析中引入的隐式捷径，并针对图中添加虚拟节点和虚拟边的设置，建立了WL测试的进一步理论结果。摘要未明确说明具体使用的数据集或模型架构，重点在于理论分析和框架构建。",
      "result": "主要结果显示，普通WL测试在常数深度GNN中实现的难度得到进一步证实，表明其在某些设置下不足以作为表达能力度量。通过扩展CONGEST框架，研究揭示了先前分析中的隐式捷径，并在图形增强设置（如添加虚拟节点和边）下获得了新的硬度结果。尽管摘要未提供具体性能指标或对比数据，但强化了WL测试的局限性，为GNN表达能力提供了更深入的理论见解，可能指导未来算法设计。与基线方法对比，这些结果凸显了现有理论的不足。",
      "conclusion": "本研究的主要贡献是解决GNN表达能力研究中与WL测试相关的两个缺口，通过强化硬度结果和提出分布式计算框架，深化了对GNN理论的理解。学术上，它推动了图神经网络理论进展，提供了更精确的表达能力评估工具；实践中，可能帮助设计更具表达力的GNN模型。局限性包括摘要未明确说明具体应用细节，未来工作可探索框架的泛化性和实际应用场景，以进一步验证其有效性。",
      "tags": [
        "Graph Neural Networks",
        "Weisfeiler-Lehman Test",
        "Distributed Computation",
        "CONGEST Model",
        "Graph Expressivity"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:37.996112Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2410.00564",
    "title": "Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining",
    "authors": [
      "Jie Cheng",
      "Ruixi Qiao",
      "Yingwei Ma",
      "Binhua Li",
      "Gang Xiong",
      "Qinghai Miao",
      "Yongbin Li",
      "Yisheng Lv"
    ],
    "abstract": "A significant aspiration of offline reinforcement learning (RL) is to develop a generalist agent with high capabilities from large and heterogeneous datasets. However, prior approaches that scale offline RL either rely heavily on expert trajectories or struggle to generalize to diverse unseen tasks. Inspired by the excellent generalization of world model in conditional video generation, we explore the potential of image observation-based world model for scaling offline RL and enhancing generalization on novel tasks. In this paper, we introduce JOWA: Jointly-Optimized World-Action model, an offline model-based RL agent pretrained on multiple Atari games with 6 billion tokens data to learn general-purpose representation and decision-making ability. Our method jointly optimizes a world-action model through a shared transformer backbone, which stabilize temporal difference learning with large models during pretraining. Moreover, we propose a provably efficient and parallelizable planning algorithm to compensate for the Q-value estimation error and thus search out better policies. Experimental results indicate that our largest agent, with 150 million parameters, achieves 78.9% human-level performance on pretrained games using only 10% subsampled offline data, outperforming existing state-of-the-art large-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales favorably with model capacity and can sample-efficiently transfer to novel games using only 5k offline fine-tuning data (approximately 4 trajectories) per game, demonstrating superior generalization. We will release codes and model weights at https://github.com/CJReinforce/JOWA",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2410.00564.pdf",
    "abs_url": "https://arxiv.org/abs/2410.00564",
    "published": "2024-10-01T10:25:03Z",
    "updated": "2026-01-29T13:25:42Z",
    "comment": "Accepted by ICLR 2025",
    "light_analysis": {
      "overview": "JOWA是一个联合优化的世界-动作模型，通过预训练和高效规划扩展离线强化学习的泛化能力。",
      "motivation": "离线强化学习旨在从大规模异构数据中开发通用代理，但现有方法要么过度依赖专家轨迹，要么难以泛化到新任务。世界模型在条件视频生成中表现出色，激发了利用基于图像观察的世界模型来扩展离线RL并增强泛化的研究动机。这个问题的重要性在于提高代理的数据效率和跨任务泛化能力，推动通用AI发展，而现有方法的不足促使探索更有效的解决方案。",
      "method": "本文提出JOWA：Jointly-Optimized World-Action模型，通过在多个Atari游戏上预训练60亿token数据，使用共享Transformer骨干联合优化世界和动作模型。这种方法稳定了大模型预训练期间的时间差分学习，并引入了一个可证明高效且可并行化的规划算法来补偿Q值估计误差，从而搜索更好的策略。关键细节包括模型参数规模从150万到1.5亿，并基于图像观察进行训练。",
      "result": "实验显示，最大规模的JOWA代理（1.5亿参数）在预训练游戏中达到了78.9%的人类水平表现，仅使用10%的离线数据，平均优于现有最先进的大型离线RL基准31.6%。此外，JOWA能高效泛化到新游戏，每个游戏仅需5k离线微调数据（约4条轨迹），展示了卓越的样本效率和扩展性。",
      "conclusion": "本研究的主要贡献是提出了JOWA模型，有效扩展了离线模型基础RL的规模和泛化能力，通过联合优化和规划算法提升性能。学术价值在于提供了一种新的大规模离线RL方法，实际应用价值则体现在增强代理在多样化任务中的适应性和数据效率。未来工作可进一步探索模型在其他领域的泛化，代码和模型权重已发布以促进社区发展。",
      "tags": [
        "Offline Reinforcement Learning",
        "Model-Based RL",
        "World Model",
        "Transformer",
        "Joint Optimization"
      ]
    },
    "analyzed_at": "2026-01-30T04:07:46.484865Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2409.14038",
    "title": "OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching",
    "authors": [
      "Zhangcheng Qiang",
      "Kerry Taylor",
      "Weiqing Wang",
      "Jing Jiang"
    ],
    "abstract": "Hallucinations of large language models (LLMs) commonly occur in domain-specific downstream tasks, with no exception in ontology matching (OM). The prevalence of using LLMs for OM raises the need for benchmarks to better understand LLM hallucinations. The OAEI-LLM dataset is an extended version of the Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate LLM-specific hallucinations in OM tasks. We outline the methodology used in dataset construction and schema extension, and provide examples of potential use cases.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2409.14038.pdf",
    "abs_url": "https://arxiv.org/abs/2409.14038",
    "published": "2024-09-21T06:49:34Z",
    "updated": "2026-01-29T15:22:06Z",
    "comment": "5 pages, 1 figure, 1 table, 1 code snippet",
    "light_analysis": {
      "overview": "该论文提出了OAEI-LLM基准数据集，用于评估大语言模型在本体匹配任务中的幻觉现象。",
      "motivation": "研究动机源于大语言模型（LLMs）在领域特定下游任务中普遍存在的幻觉问题，特别是在本体匹配（OM）领域。随着LLMs在OM任务中的广泛应用，现有方法缺乏专门的基准来系统评估这些幻觉，这限制了模型行为的深入理解和改进。因此，迫切需要建立一个标准化的数据集，以更好地分析和理解LLM在OM中的幻觉现象，为后续研究提供数据支持，并推动该领域的发展。",
      "method": "研究方法聚焦于构建OAEI-LLM基准数据集，这是对本体对齐评估倡议（OAEI）数据集的扩展版本。论文概述了数据集的具体构造方法，包括如何扩展现有模式以专门评估LLM在本体匹配任务中产生的幻觉。方法涉及数据收集、处理和标注，以确保能够有效捕捉LLM在OM中的特定错误和偏差，同时提供了潜在使用案例的例子，为研究者提供一个标准化的评估工具来探索幻觉问题。",
      "result": "摘要未明确说明具体的实验结果，如准确率提升或效率改进等性能指标。论文主要介绍了OAEI-LLM数据集的构建，并提供了潜在使用案例的例子，表明该数据集可用于评估LLM在OM中的幻觉。未来工作可能包括利用该数据集进行实验，但当前摘要未提供与基线方法的对比或具体数据支撑，仅强调了数据集的潜在应用价值。",
      "conclusion": "论文的主要贡献是提出了OAEI-LLM基准数据集，专门用于理解大语言模型在本体匹配任务中的幻觉现象。这项研究的学术价值在于填补了LLM在领域特定任务中幻觉评估的空白，为后续实验和理论分析提供了数据基础。实际应用价值包括帮助开发更可靠的OM系统和改进LLM性能。未来工作可能涉及扩展数据集规模、进行实证评估，以及探索减少幻觉的技术方法。",
      "tags": [
        "Large Language Models",
        "Ontology Matching",
        "Benchmark Dataset",
        "Hallucination Evaluation"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:02.004236Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2409.13959",
    "title": "One Model, Any Conjunctive Query: Graph Neural Networks for Answering Queries over Incomplete Knowledge Graphs",
    "authors": [
      "Krzysztof Olejniczak",
      "Xingyue Huang",
      "Mikhail Galkin",
      "İsmail İlkan Ceylan"
    ],
    "abstract": "Motivated by the incompleteness of modern knowledge graphs, a new setup for query answering has emerged, where the goal is to predict answers that do not necessarily appear in the knowledge graph, but are present in its completion. In this paper, we formally introduce and study two query answering problems, namely, query answer classification and query answer retrieval. To solve these problems, we propose AnyCQ, a model that can classify answers to any conjunctive query on any knowledge graph. At the core of our framework lies a graph neural network trained using a reinforcement learning objective to answer Boolean queries. Trained only on simple, small instances, AnyCQ generalizes to large queries of arbitrary structure, reliably classifying and retrieving answers to queries that existing approaches fail to handle. This is empirically validated through our newly proposed, challenging benchmarks. Finally, we empirically show that AnyCQ can effectively transfer to completely novel knowledge graphs when equipped with an appropriate link prediction model, highlighting its potential for querying incomplete data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2409.13959.pdf",
    "abs_url": "https://arxiv.org/abs/2409.13959",
    "published": "2024-09-21T00:30:44Z",
    "updated": "2026-01-29T16:42:37Z",
    "comment": "Proceedings of the Fourth Learning on Graphs Conference (LoG 2025)",
    "light_analysis": {
      "overview": "本论文提出AnyCQ模型，通过图神经网络和强化学习，实现对不完整知识图谱中任意合取查询的答案分类和检索，具有强大的泛化能力。",
      "motivation": "现代知识图谱常存在不完整性，导致传统方法难以预测未直接出现在图谱中的答案。论文针对这一问题，定义了查询答案分类和检索两种新任务，旨在处理不完整知识图谱的查询回答。现有方法在处理复杂、大规模或任意结构的查询时往往失效，因此需要一种能够泛化到不同查询类型的通用方法。这一研究对于知识补全、推理系统及智能查询应用具有重要价值，能提升数据利用效率和准确性。",
      "method": "论文提出AnyCQ模型，其核心是基于图神经网络，采用强化学习目标进行训练，以处理布尔查询。模型仅使用简单、小规模的训练实例，但通过设计实现了对大型、任意结构合取查询的泛化。关键创新在于结合图神经网络处理图结构数据的能力和强化学习的优化策略，使模型能适应复杂查询模式。摘要未明确说明具体的数据集或详细模型架构，但强调了训练策略的泛化性和灵活性，支持任意知识图谱和查询类型。",
      "result": "通过新提出的挑战性基准测试进行实证验证，AnyCQ模型在查询答案分类和检索任务中表现优异，能够可靠处理现有方法无法应对的复杂查询。摘要未给出具体数据指标如准确率或效率提升，但指出模型在泛化能力和迁移性上优于基线方法，特别是在处理大型、任意结构查询时。实验结果还显示，当配备适当的链接预测模型时，AnyCQ可以迁移到全新的知识图谱，有效支持不完整数据的查询应用。",
      "conclusion": "本论文的主要贡献是提出并验证了AnyCQ模型，为不完整知识图谱的查询回答提供了通用解决方案。其学术价值在于创新性地结合图神经网络和强化学习，拓展了查询处理的技术边界；实际应用价值体现在模型的可迁移性，能适应不同知识图谱，提升不完整数据的查询效率。摘要未明确说明研究的局限性，但未来工作可能包括进一步优化模型性能、扩展到更多查询类型或探索实际部署中的挑战。该研究为知识图谱补全和智能查询系统的发展奠定了基础。",
      "tags": [
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Conjunctive Query",
        "Knowledge Graphs",
        "Query Answering"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:35.449686Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2408.06787",
    "title": "FLAME: Empowering Frozen LLMs for Knowledge Graph Completion",
    "authors": [
      "Bo Xue",
      "Yi Xu",
      "Bolei Ma",
      "Yunchong Song",
      "Jiaxin Ding",
      "Luoyi Fu",
      "Xinbing Wang"
    ],
    "abstract": "Traditional knowledge graph completion (KGC) methods rely solely on structural information and struggle with sparsity, while Large Language Models (LLMs) address these limitations through rich world knowledge and strong context modeling. Fine-tuning LLMs is effective but costly, while non-fine-tuned LLMs are efficient but suboptimal. To address this trade-off, we propose \\textbf{FLAME}, a framework that extracts context-aware hidden states from intermediate layers of frozen LLMs to train data-efficient KGC classifiers. We bridge LLM-KG semantic gaps via subgraph-based entity descriptions and employ sliced mutual information (SMI) to quantify task-relevant information in representations. Experiments demonstrate that FLAME achieves 47\\% improvement over non-fine-tuned LLM baselines and, to our knowledge, is the first to achieve fine-tuned performance with $188\\times$ memory efficiency and $26.11\\times$ speedup.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2408.06787.pdf",
    "abs_url": "https://arxiv.org/abs/2408.06787",
    "published": "2024-08-13T10:15:55Z",
    "updated": "2026-01-29T07:57:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出FLAME框架，通过提取冻结大型语言模型中间层的隐藏状态，高效完成知识图谱任务，实现了成本与性能的平衡。",
      "motivation": "知识图谱完成（KGC）传统方法仅依赖结构信息，在处理稀疏数据时效果有限。大型语言模型（LLMs）凭借丰富的世界知识和上下文建模能力能弥补不足，但微调LLMs计算成本高昂，而非微调方法虽效率高但性能较差。因此，本研究旨在解决微调成本与性能之间的权衡问题，提出一种高效且接近微调性能的KGC解决方案，以应对实际应用中的资源约束挑战。",
      "method": "FLAME框架从冻结LLMs的中间层提取上下文感知隐藏状态，用于训练数据高效的KGC分类器。通过使用基于子图的实体描述来桥接LLMs与知识图谱之间的语义差距，并引入切片互信息（SMI）量化表示中与任务相关的信息。关键创新在于避免整体模型微调，仅利用部分层信息，从而在降低计算开销的同时，增强模型对复杂KGC任务的适应性。",
      "result": "实验结果表明，FLAME在知识图谱完成任务中比非微调LLM基线性能提升47%，首次实现微调级别效果。具体数据包括内存效率提升188倍，速度提升26.11倍，显示了其在平衡效率和效果方面的优越性，有效克服了传统方法的局限性。",
      "conclusion": "FLAME框架的主要贡献在于创新地利用冻结LLMs的中间层进行高效知识图谱完成，解决了微调与非微调之间的权衡问题。该研究不仅提升了KGC性能并大幅降低计算成本，具有重要学术价值和实际应用潜力。未来工作可能涉及扩展至其他任务或优化SMI量化方法，以进一步提高泛化能力。",
      "tags": [
        "Knowledge Graph Completion (KGC)",
        "Large Language Models (LLMs)",
        "Frozen LLMs",
        "Sliced Mutual Information (SMI)",
        "Context-aware Hidden States"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:50.333529Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2407.11823",
    "title": "Harmonizing Safety and Speed: A Human-Algorithm Approach to Enhance the FDA's Medical Device Clearance Policy",
    "authors": [
      "Mohammad Zhalechian",
      "Soroush Saghafian",
      "Omar Robles"
    ],
    "abstract": "The United States Food and Drug Administration's (FDA's) 510(k) pathway allows manufacturers to gain medical device approval by demonstrating substantial equivalence to a legally marketed device. However, the inherent ambiguity of this regulatory procedure has been associated with high recall among many devices cleared through this pathway, raising significant safety concerns. In this paper, we develop a combined human-algorithm approach to assist the FDA in improving its 510(k) medical device clearance process by reducing recall risk and regulatory workload. We first develop machine learning methods to estimate the risk of recall of 510(k) medical devices based on the information available at the time of submission. We then propose a data-driven clearance policy that recommends acceptance, rejection, or deferral to FDA's committees for in-depth evaluation. We conduct an empirical study using a unique dataset of over 31,000 submissions that we assembled based on data sources from the FDA and Centers for Medicare and Medicaid Service (CMS). Compared to the FDA's current practice, which has a recall rate of 10.3% and a normalized workload measure of 100%, a conservative evaluation of our policy shows a 32.9% improvement in the recall rate and a 40.5% reduction in the workload. Our analyses further suggest annual cost savings of approximately $1.7 billion for the healthcare system driven by avoided replacement costs, which is equivalent to 1.1% of the entire United States annual medical device expenditure. Our findings highlight the value of a holistic and data-driven approach to improve the FDA's current 510(k) pathway.",
    "categories": [
      "cs.LG",
      "cs.HC",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2407.11823.pdf",
    "abs_url": "https://arxiv.org/abs/2407.11823",
    "published": "2024-07-16T15:11:29Z",
    "updated": "2026-01-29T18:09:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种结合人类与算法的数据驱动方法，显著改善FDA医疗设备批准流程的安全性和监管效率，通过机器学习降低召回风险和工作量。",
      "motivation": "FDA的510(k)批准路径允许医疗设备通过证明与已上市设备实质等效来获得批准，但该程序存在歧义，导致高召回率，引发严重安全担忧。现有方法依赖主观判断，缺乏数据支持，难以平衡安全性与审批速度，影响了公共卫生和经济成本。本研究旨在解决这一问题，通过数据驱动方法辅助FDA优化流程，减少召回风险和监管负担。",
      "method": "研究方法首先开发机器学习模型，基于提交时的信息（如设备特征和制造商历史）估计510(k)医疗设备的召回风险。关键创新在于提出一个数据驱动的批准政策，该政策根据风险评分自动推荐接受、拒绝或转交FDA委员会深入评估，实现了人类与算法的协同决策。使用的数据集由FDA和医疗保险与医疗补助服务中心（CMS）数据构建，包含超过31,000份设备提交记录，用于训练和验证模型，确保方法的实证基础。",
      "result": "实验结果表明，与FDA当前实践（召回率10.3%，归一化工作量100%）相比，保守评估下提出的政策使召回率改善32.9%（预计从10.3%显著降低），工作量减少40.5%。此外，分析显示每年可为医疗保健系统节省约17亿美元的成本，相当于美国年医疗设备总支出的1.1%，主要源于避免的设备更换费用，突显了该政策在性能指标和经济效益上的优越性。",
      "conclusion": "本研究的主要贡献是开发了一种整体和数据驱动的批准方法，结合人类与算法优化FDA的510(k)流程，在提高设备安全性的同时减轻监管负担。学术上，它展示了机器学习在监管决策中的实际应用价值；实际上，具有潜在的重大公共卫生和经济效益。未来方向可能包括扩展应用到其他监管领域或进一步优化算法模型以增强预测精度和适应性。",
      "tags": [
        "Machine Learning",
        "Risk Assessment",
        "Data-driven Decision Making",
        "Regulatory Technology",
        "Human-in-the-loop Systems"
      ]
    },
    "analyzed_at": "2026-01-30T04:08:54.010815Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2407.04969",
    "title": "EVA-Score: Evaluating Abstractive Long-form Summarization on Informativeness through Extraction and Validation",
    "authors": [
      "Yuchen Fan",
      "Yazhe Wan",
      "Xin Zhong",
      "Haonan Cheng",
      "Ning Ding",
      "Bowen Zhou"
    ],
    "abstract": "Since LLMs emerged, more attention has been paid to abstractive long-form summarization, where longer input sequences indicate more information contained. Nevertheless, the automatic evaluation of such summaries remains underexplored. The current evaluation metrics for long-form summarization either use similarity-based metrics like ROUGE and BERTScore or LLM-based metrics using appropriate prompts or pre-defined schema. We argue that the former only relies on similarity and fails to consider informativeness while the latter lacks quantitative analysis of informative richness, and is rather subjective and hard to explain. Current evaluation metrics either use traditional metrics like ROUGE and BERTScore, which rely on surface-level similarity and fail to consider informativeness, or simple LLM-based metrics, which are not robust and easily overwhelmed by the long contexts. In this paper, we propose a new evaluation metric called EVA-Score to extract all information from the given summaries, identify overlapped information based on reference, and calculate the information score. We test EVA-Score on several datasets and the experimental results reveal that EVA-Score shows the highest correlation with humans. We also re-evaluate the performance of LLMs on long-form summarization from the information perspective. The results indicate that responses of LLMs still have a gap with the human-written answers. Moreover, we provide a detailed analysis of the effectiveness of EVA-Score, forecasting future ways to automatically evaluate abstractive long-form summarization.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2407.04969.pdf",
    "abs_url": "https://arxiv.org/abs/2407.04969",
    "published": "2024-07-06T06:02:38Z",
    "updated": "2026-01-29T08:12:30Z",
    "comment": "20 pages",
    "light_analysis": {
      "overview": "本文提出EVA-Score，一种新评估指标，通过提取和验证评估抽象性长文本摘要的信息丰富度。",
      "motivation": "随着大型语言模型的出现，抽象性长文本摘要受到更多关注，但自动评估方法仍不成熟。当前评估指标如ROUGE和BERTScore仅依赖表面相似性，忽视了信息丰富度；而基于LLM的指标缺乏定量分析，主观性强且难以解释。这些问题导致长文本摘要的评估不准确且不稳定，因此需要一种新指标来定量评估信息内容，以改进现有方法的不足。",
      "method": "本文提出的EVA-Score方法，核心是通过提取给定摘要中的所有信息，然后基于参考摘要识别出重叠信息，最终计算出一个信息分数。该方法不依赖表面相似性，而是直接评估信息的丰富度和准确性。具体技术路线包括信息提取、重叠识别和分数计算，旨在定量衡量摘要的信息量。摘要未明确说明使用的具体数据集或模型架构细节，但强调了提取和验证的过程。",
      "result": "实验结果显示，EVA-Score在多个数据集上表现出色，与人类评估的相关性最高，优于现有指标如ROUGE和BERTScore。此外，通过EVA-Score重新评估大型语言模型在长文本摘要上的性能，发现其生成的摘要与人类撰写答案相比仍存在显著差距。结果提供了定量数据支持EVA-Score的有效性，并分析了其在信息评估方面的优势，为未来自动评估方法提供了参考。",
      "conclusion": "本文的主要贡献是提出EVA-Score，一种新评估指标，能够定量评估抽象性长文本摘要的信息丰富度，解决了现有方法的不足。研究不仅展示了EVA-Score的高效性和与人类评估的一致性，还从信息视角重新评估了LLMs的性能，揭示了其与人类水平的差距。这为长文本摘要的自动评估提供了新思路，具有重要的学术和实际应用价值，未来工作可进一步优化指标并扩展应用到更广泛的自然语言处理任务中。",
      "tags": [
        "Abstractive Summarization",
        "Long-form Summarization",
        "Evaluation Metrics",
        "Information Extraction",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:03.675026Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2406.12915",
    "title": "How Out-of-Distribution Detection Learning Theory Enhances Transformer: Learnability and Reliability",
    "authors": [
      "Yijin Zhou",
      "Yutang Ge",
      "Wenyuan Xie",
      "Linqian Zeng",
      "Xiaowen Dong",
      "Yuguang Wang"
    ],
    "abstract": "Transformers excel in natural language processing and computer vision tasks. However, they still face challenges in generalizing to Out-of-Distribution (OOD) datasets, i.e. data whose distribution differs from that seen during training. OOD detection aims to distinguish outliers while preserving in-distribution (ID) data performance. This paper introduces the OOD detection Probably Approximately Correct (PAC) Theory for transformers, which establishes the conditions for data distribution and model configurations for the OOD detection learnability of transformers. It shows that outliers can be accurately represented and distinguished with sufficient data under conditions. The theoretical implications highlight the trade-off between theoretical principles and practical training paradigms. By examining this trade-off, we naturally derived the rationale for leveraging auxiliary outliers to enhance OOD detection. Our theory suggests that by penalizing the misclassification of outliers within the loss function and strategically generating soft synthetic outliers, one can robustly bolster the reliability of transformer networks. This approach yields a novel algorithm that ensures learnability and refines the decision boundaries between inliers and outliers. In practice, the algorithm consistently achieves state-of-the-art (SOTA) performance across various data formats.",
    "categories": [
      "cs.LG",
      "math.PR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2406.12915.pdf",
    "abs_url": "https://arxiv.org/abs/2406.12915",
    "published": "2024-06-13T17:54:09Z",
    "updated": "2026-01-29T17:53:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于PAC理论的OOD检测学习框架，用于增强Transformer的可学习性和可靠性，并开发了一个实现SOTA性能的新算法。",
      "motivation": "Transformers在自然语言处理和计算机视觉任务中表现优异，但在处理分布外（OOD）数据时面临泛化挑战。OOD检测旨在区分异常值同时保持分布内数据性能，现有方法可能缺乏坚实的理论基础来保证可学习性和可靠性，导致实际应用中模型在未知数据上的表现不稳定。因此，研究OOD检测的理论基础对于提升模型鲁棒性和解决实际泛化问题至关重要。",
      "method": "论文引入了用于Transformer的OOD检测PAC理论，该理论建立了数据分布和模型配置的条件，以保障OOD检测的可学习性。基于理论分析，作者提出在损失函数中惩罚误分类异常值，并策略性地生成软合成异常值来增强模型可靠性。这推导出一个新算法，通过优化决策边界来区分内点与异常值，关键创新点在于结合理论原则与实用训练范式，提升Transformer网络的泛化能力。",
      "result": "实验结果显示，所提出的算法在各种数据格式上一致实现了最先进的性能，表明其在增强OOD检测方面的有效性。摘要未明确说明具体的性能指标提升（如准确率或效率改进）或与基线方法的详细对比数据，但强调了算法在广泛场景下的优越表现和泛化能力，验证了理论框架的实用性。",
      "conclusion": "本研究的主要贡献是建立了OOD检测的PAC理论框架，为Transformer的可学习性提供了理论支持，并开发了一个实用算法来提升模型可靠性。这具有重要的学术价值，扩展了深度学习理论，同时在实际应用中增强了模型的鲁棒性和适应性。未来工作可能包括优化算法细节或扩展到更多复杂任务，以进一步验证理论的应用潜力。",
      "tags": [
        "Out-of-Distribution Detection",
        "Probably Approximately Correct Theory",
        "Transformer",
        "Synthetic Outliers",
        "Loss Function Penalization"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:21.570069Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2406.08440",
    "title": "Adaptive Swarm Mesh Refinement using Deep Reinforcement Learning with Local Rewards",
    "authors": [
      "Niklas Freymuth",
      "Philipp Dahlinger",
      "Tobias Würth",
      "Simon Reisch",
      "Luise Kärger",
      "Gerhard Neumann"
    ],
    "abstract": "Simulating physical systems is essential in engineering, but analytical solutions are limited to straightforward problems. Consequently, numerical methods like the Finite Element Method (FEM) are widely used. However, the FEM becomes computationally expensive as problem complexity and accuracy demands increase. Adaptive Mesh Refinement (AMR) improves the FEM by dynamically placing mesh elements on the domain, balancing computational speed and accuracy. Classical AMR depends on heuristics or expensive error estimators, which may lead to suboptimal performance for complex simulations. While AMR methods based on machine learning are promising, they currently only scale to simple problems. In this work, we formulate AMR as a system of collaborating, homogeneous agents that iteratively split into multiple new agents. This agent-wise perspective enables a spatial reward formulation focused on reducing the maximum mesh element error. Our approach, Adaptive Swarm Mesh Refinement++ (ASMR++), offers efficient, stable optimization and generates highly adaptive meshes at user-defined resolution at inference time. Extensive experiments demonstrate that ASMR++ outperforms heuristic approaches and learned baselines, matching the performance of expensive error-based oracle AMR strategies. ASMR additionally generalizes to different domains during inference, and produces meshes that simulate up to 2 orders of magnitude faster than uniform refinements in more demanding settings.",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2406.08440.pdf",
    "abs_url": "https://arxiv.org/abs/2406.08440",
    "published": "2024-06-12T17:26:54Z",
    "updated": "2026-01-29T17:22:03Z",
    "comment": "Submitted to Journal of Machine Learning Research (JMLR)",
    "light_analysis": {
      "overview": "论文提出ASMR++方法，结合深度强化学习与局部奖励的自适应群网格细化，显著提升有限元模拟的效率和精度。",
      "motivation": "有限元方法在工程物理模拟中计算成本高昂，传统自适应网格细化依赖启发式或昂贵错误估计器，导致复杂模拟中的性能次优。现有基于机器学习的方法仅能处理简单问题，缺乏可扩展性，因此需要开发更高效、能平衡计算速度与精度的自适应网格优化技术，以应对日益增长的模拟需求。",
      "method": "研究将自适应网格细化为协作、同质代理系统，代理通过迭代分裂来细化网格。采用深度强化学习框架，创新性地设计局部奖励机制，专注于减少最大网格元素错误，实现空间优化。ASMR++方法在推理时能高效稳定地生成用户指定分辨率的自适应网格，无需依赖传统昂贵错误估计。",
      "result": "实验表明，ASMR++在性能上超越启发式方法和学习基线，匹配昂贵的基于错误的AMR策略。该方法具有良好的泛化能力，在不同模拟域中有效，生成的网格在苛刻设置下模拟速度比均匀细化提升高达2个数量级，显著加速计算过程。",
      "conclusion": "ASMR++成功整合深度强化学习与网格细化，提供高效、稳定的自适应解决方案，对工程模拟具有重要应用价值。其创新代理视角和局部奖励设计拓展了机器学习在数值方法中的应用，未来可探索更复杂场景的适应性和实时优化潜力。",
      "tags": [
        "Adaptive Mesh Refinement",
        "Deep Reinforcement Learning",
        "Local Rewards",
        "Finite Element Method",
        "Swarm Agents"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:36.913741Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2404.13318",
    "title": "Federated Learning for Heterogeneous Electronic Health Record Systems with Cost Effective Participant Selection",
    "authors": [
      "Jiyoun Kim",
      "Junu Kim",
      "Kyunghoon Hur",
      "Edward Choi"
    ],
    "abstract": "The increasing volume of electronic health records (EHRs) presents the opportunity to improve the accuracy and robustness of models in clinical prediction tasks. Unlike traditional centralized approaches, federated learning enables training on data from multiple institutions while preserving patient privacy and complying with regulatory constraints. In practice, healthcare institutions (i.e., hosts) often need to build predictive models tailored to their specific needs (e.g., creatinine-level prediction, N-day readmission prediction) using federated learning. When building a federated learning model for a single healthcare institution, two key challenges arise: (1) ensuring compatibility across heterogeneous EHR systems, and (2) managing federated learning costs within budget constraints. Specifically, heterogeneity in EHR systems across institutions hinders compatible modeling, while the computational costs of federated learning can exceed practical budget limits for healthcare institutions. To address these challenges, we propose EHRFL, a federated learning framework designed for building a cost-effective, host-specific predictive model using patient EHR data. EHRFL consists of two components: (1) text-based EHR modeling, which facilitates cross-institution compatibility without costly data standardization, and (2) a participant selection strategy based on averaged patient embedding similarity to reduce the number of participants without degrading performance. Our participant selection strategy sharing averaged patient embeddings is differentially private, ensuring patient privacy. Experiments on multiple open-source EHR datasets demonstrate the effectiveness of both components. With our framework, healthcare institutions can build institution-specific predictive models under budgetary constraints with reduced costs and time.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2404.13318.pdf",
    "abs_url": "https://arxiv.org/abs/2404.13318",
    "published": "2024-04-20T08:23:46Z",
    "updated": "2026-01-29T13:37:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出EHRFL联邦学习框架，通过文本建模和基于嵌入相似性的参与者选择策略，解决异构电子健康记录系统的兼容性和成本问题，以构建医疗预测模型。",
      "motivation": "医疗保健机构需为特定临床任务构建预测模型，但传统集中式方法侵犯患者隐私，而联邦学习虽保护隐私却面临两大挑战：异构电子健康记录系统导致数据兼容性差，需要昂贵的数据标准化；联邦学习参与者多增加计算成本，易超预算限制。现有方法难以在保护隐私的同时高效处理异构数据和成本控制，因此急需创新解决方案。",
      "method": "EHRFL框架包括两个核心组件：一是文本基于的电子健康记录建模，将异构数据转换为文本表示以实现跨机构兼容性，无需复杂数据标准化；二是基于平均患者嵌入相似性的参与者选择策略，通过计算患者嵌入的相似度选择最有价值的参与者，减少参与机构数量而不降低性能，该策略采用差分隐私技术保护患者隐私。实验在多个开源EHR数据集上进行。",
      "result": "在多个开源电子健康记录数据集上的实验验证了EHRFL框架的有效性：文本建模促进了跨机构兼容性，参与者选择策略减少了联邦学习的参与机构数量，从而降低了计算成本和时间消耗。尽管摘要未明确说明具体的性能指标如准确率提升，但实验表明框架在预算约束下成功构建了机构特定预测模型，实现了成本效益的训练过程。",
      "conclusion": "EHRFL框架通过集成文本建模和成本效益的参与者选择策略，有效解决了异构电子健康记录系统在联邦学习中的兼容性和成本挑战。该研究具有重要学术价值，为医疗领域的联邦学习应用提供了新方法，增强了模型的可扩展性和实用性；实际中帮助医疗保健机构在遵守隐私法规下高效构建定制化模型。未来工作可优化选择策略或扩展到更多医疗数据类型。",
      "tags": [
        "Federated Learning",
        "Electronic Health Records",
        "Participant Selection",
        "Text-based Modeling",
        "Differential Privacy"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:04.942469Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2403.14124",
    "title": "Soft Masked Transformer for Point Cloud Processing with Skip Attention-Based Upsampling",
    "authors": [
      "Yong He",
      "Hongshan Yu",
      "Chaoxu Mu",
      "Mingtao Feng",
      "Tongjia Chen",
      "Zechuan Li",
      "Anwaar Ulhaq",
      "Ajmal Mian"
    ],
    "abstract": "Point cloud processing methods leverage local and global point features %at the feature level to cater to downstream tasks, yet they often overlook the task-level context inherent in point clouds during the encoding stage. We argue that integrating task-level information into the encoding stage significantly enhances performance. To that end, we propose SMTransformer which incorporates task-level information into a vector-based transformer by utilizing a soft mask generated from task-level queries and keys to learn the attention weights. Additionally, to facilitate effective communication between features from the encoding and decoding layers in high-level tasks such as segmentation, we introduce a skip-attention-based up-sampling block. This block dynamically fuses features from various resolution points across the encoding and decoding layers. To mitigate the increase in network parameters and training time resulting from the complexity of the aforementioned blocks, we propose a novel shared position encoding strategy. This strategy allows various transformer blocks to share the same position information over the same resolution points, thereby reducing network parameters and training time without compromising accuracy.Experimental comparisons with existing methods on multiple datasets demonstrate the efficacy of SMTransformer and skip-attention-based up-sampling for point cloud processing tasks, including semantic segmentation and classification. In particular, we achieve state-of-the-art semantic segmentation results of 73.4% mIoU on S3DIS Area 5 and 62.4% mIoU on SWAN dataset",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2403.14124.pdf",
    "abs_url": "https://arxiv.org/abs/2403.14124",
    "published": "2024-03-21T04:34:24Z",
    "updated": "2026-01-29T07:53:55Z",
    "comment": "Conditionally accepted by IEEE Transactions on Automation Science and Engineering",
    "light_analysis": {
      "overview": "提出SMTransformer，通过软掩码整合任务级信息，结合跳跃注意力上采样和共享位置编码，提升点云处理性能。",
      "motivation": "现有点云处理方法在编码阶段常忽略任务级上下文，导致模型无法充分利用任务相关信息，限制了性能提升。任务级信息如语义分割的类别标签对于下游任务至关重要，现有方法侧重于特征层面的局部和全局信息，但缺乏任务导向的编码机制，因此需要将任务级信息融入编码阶段以增强模型适应性和精度。",
      "method": "SMTransformer是一种基于transformer的模型，通过任务级查询和键生成软掩码来学习注意力权重，从而在向量化transformer中整合任务级信息。创新点包括软掩码机制和跳跃注意力上采样块，该块动态融合编码和解码层中不同分辨率的点特征，提升特征传递效率。为减少参数和训练时间，采用共享位置编码策略，使多个transformer块共享相同分辨率点的位置信息，降低计算复杂度。",
      "result": "实验在多个数据集上验证方法有效性，包括语义分割任务。SMTransformer在S3DIS Area 5上取得73.4%的mIoU，在SWAN数据集上达到62.4%的mIoU，均优于现有基线方法，实现了最先进性能。这些结果证明了软掩码和上采样块在点云处理中的显著优势，尤其在提升分割准确性方面。",
      "conclusion": "本研究的核心贡献是提出了SMTransformer和跳跃注意力上采样块，成功将任务级信息引入编码阶段，并优化特征融合机制。学术上，创新性地扩展了transformer在点云处理中的应用；实际上，提升了语义分割和分类任务的性能，具有广泛应用潜力。摘要未明确说明局限性，未来工作可能包括进一步优化计算效率或扩展到更多点云任务。",
      "tags": [
        "Point Cloud Processing",
        "Transformer",
        "Attention Mechanism",
        "Soft Mask",
        "Skip Attention"
      ]
    },
    "analyzed_at": "2026-01-30T04:09:47.624035Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2402.04177",
    "title": "Scaling Laws for Downstream Task Performance of Large Language Models",
    "authors": [
      "Berivan Isik",
      "Natalia Ponomareva",
      "Hussein Hazimeh",
      "Dimitris Paparas",
      "Sergei Vassilvitskii",
      "Sanmi Koyejo"
    ],
    "abstract": "Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by: downstream cross-entropy and translation quality metrics such as BLEU and COMET scores. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and translation quality scores improve monotonically with more pretraining data. In such cases, we show that it is possible to predict the downstream translation quality metrics with good accuracy using a log-law. However, there are cases where moderate misalignment causes the downstream translation scores to fluctuate or get worse with more pretraining, whereas downstream cross-entropy monotonically improves. By analyzing these, we provide new practical insights for choosing appropriate pretraining data.",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2402.04177.pdf",
    "abs_url": "https://arxiv.org/abs/2402.04177",
    "published": "2024-02-06T17:31:20Z",
    "updated": "2026-01-29T06:50:51Z",
    "comment": "Published at the International Conference on Learning Representations (ICLR) 2025, with title: \"Scaling Laws for Downstream Task Performance in Machine Translation\"",
    "light_analysis": {
      "overview": "本研究探索大语言模型在迁移学习中下游任务性能的缩放定律，揭示预训练数据对齐对翻译质量的影响，并提出基于对数定律的预测方法。",
      "motivation": "现有研究主要关注大语言模型预训练损失的缩放定律，但在迁移学习设置中，模型预训练后需微调于下游任务（如机器翻译），下游性能对实际应用至关重要。然而，预训练数据如何影响下游性能的缩放行为尚未充分研究，现有方法往往忽略数据分布对齐的作用，导致下游优化不足。本工作旨在填补这一空白，为预训练数据选择提供理论指导和实践见解，解决现有研究对下游性能关注不足的问题。",
      "method": "论文采用迁移学习框架，将大语言模型在无监督数据集上预训练后，微调于机器翻译任务。核心方法是系统研究预训练数据选择及其大小对下游性能的影响，使用下游交叉熵和翻译质量指标（如BLEU和COMET分数）进行评估。关键创新点在于分析预训练与下游数据分布对齐对缩放行为的作用，通过实验设计考察不同对齐程度下的性能变化，而不依赖特定模型架构或数据集名称。",
      "result": "实验表明，当下游数据与预训练数据分布对齐良好时，下游翻译质量（如BLEU和COMET分数）随预训练数据增加单调改善，并可用对数定律准确预测。例如，在充分对齐情况下，性能指标持续提升。但在中度错位时，翻译分数可能波动或恶化，而下游交叉熵仍单调改善，突显数据对齐对缩放行为的关键影响。与基线对比，这些结果提供了新见解，指导预训练数据选择以优化下游任务表现。",
      "conclusion": "本研究的主要贡献是扩展缩放定律到下游任务性能，强调预训练与下游数据对齐的重要性，为优化迁移学习提供新视角。学术上，填补了现有研究的空白；实际上，指导如何选择预训练数据以提高机器翻译等任务的效果。局限性包括摘要未明确说明更广泛任务的应用，未来工作可探索更复杂的对齐策略或扩展到其他自然语言处理任务。",
      "tags": [
        "Large Language Models",
        "Scaling Laws",
        "Transfer Learning",
        "Machine Translation",
        "Data Alignment"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:08.127529Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2401.08742",
    "title": "Efficient4D: Fast Dynamic 3D Object Generation from a Single-view Video",
    "authors": [
      "Zijie Pan",
      "Zeyu Yang",
      "Xiatian Zhu",
      "Li Zhang"
    ],
    "abstract": "Generating dynamic 3D object from a single-view video is challenging due to the lack of 4D labeled data. An intuitive approach is to extend previous image-to-3D pipelines by transferring off-the-shelf image generation models such as score distillation sampling.However, this approach would be slow and expensive to scale due to the need for back-propagating the information-limited supervision signals through a large pretrained model. To address this, we propose an efficient video-to-4D object generation framework called Efficient4D. It generates high-quality spacetime-consistent images under different camera views, and then uses them as labeled data to directly reconstruct the 4D content through a 4D Gaussian splatting model. Importantly, our method can achieve real-time rendering under continuous camera trajectories. To enable robust reconstruction under sparse views, we introduce inconsistency-aware confidence-weighted loss design, along with a lightly weighted score distillation loss. Extensive experiments on both synthetic and real videos show that Efficient4D offers a remarkable 10-fold increase in speed when compared to prior art alternatives while preserving the quality of novel view synthesis. For example, Efficient4D takes only 10 minutes to model a dynamic object, vs 120 minutes by the previous art model Consistent4D.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2401.08742.pdf",
    "abs_url": "https://arxiv.org/abs/2401.08742",
    "published": "2024-01-16T18:58:36Z",
    "updated": "2026-01-29T12:51:24Z",
    "comment": "IJCV version",
    "light_analysis": {
      "overview": "Efficient4D提出了一种高效的视频到4D对象生成方法，通过生成时空一致的图像并直接重建4D内容，实现10倍速度提升。",
      "motivation": "从单视角视频生成动态3D对象是计算机视觉和图形学中的重要问题，但面临缺乏4D标记数据的挑战。现有方法通常扩展图像到3D管道，利用现成的图像生成模型如分数蒸馏采样，但这种方法效率低下，因为它需要通过大型预训练模型反向传播有限的监督信号，导致速度慢、计算成本高。因此，迫切需要一种更快速、高效的方法来处理动态内容生成，以适应实时应用的需求。",
      "method": "Efficient4D是一个视频到4D对象生成框架，首先通过高效方法生成高质量、时空一致的图像在不同相机视图下，这些图像作为标记数据。然后，利用4D高斯splatting模型直接重建4D内容，实现实时渲染。关键技术包括不一致感知的置信度加权损失设计和轻量化的分数蒸馏损失，以在稀疏视图下实现稳健重建。该方法避免了复杂的反向传播过程，通过优化监督信号的使用提升了效率。",
      "result": "在合成和真实视频上进行广泛实验，Efficient4D在速度上比先前方法（如Consistent4D）有显著提升，达到10倍加速。例如，建模动态对象的时间从120分钟减少到10分钟，同时保持新颖视图合成的质量。性能指标表明，该方法在渲染速度和视觉效果方面均优于基线，实现了高效且高质量的动态3D生成。",
      "conclusion": "该论文的主要贡献是提出了一种高效的视频到4D对象生成框架，显著提升了动态3D生成的效率。学术上，它通过引入不一致感知损失和优化监督信号，推动了领域的技术创新。实际上，该方法有潜力应用于实时动态内容创建等领域，如游戏和虚拟现实。未来工作可探索更复杂的场景扩展和进一步优化重建质量。",
      "tags": [
        "4D Gaussian Splatting",
        "Score Distillation Sampling",
        "Novel View Synthesis",
        "Dynamic 3D Generation",
        "Video-to-4D"
      ]
    },
    "analyzed_at": "2026-01-30T04:13:33.935531Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2312.00326",
    "title": "Agent-OM: Leveraging LLM Agents for Ontology Matching",
    "authors": [
      "Zhangcheng Qiang",
      "Weiqing Wang",
      "Kerry Taylor"
    ],
    "abstract": "Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2312.00326.pdf",
    "abs_url": "https://arxiv.org/abs/2312.00326",
    "published": "2023-12-01T03:44:54Z",
    "updated": "2026-01-29T14:13:49Z",
    "comment": "31 pages - VLDB 2025 (Page 1-20), OM 2025 (Page 21-31)",
    "light_analysis": {
      "overview": "论文提出了基于大型语言模型代理的本体匹配新范式，通过Agent-OM框架显著提升了匹配性能，尤其在复杂和少样本任务上。",
      "motivation": "本体匹配对于实现语义互操作性和解决概念异构性至关重要，能促进不同本体之间的数据集成。现有系统主要分为两种范式：基于知识的专家系统依赖人工规则，灵活性不足；机器学习预测系统虽自动化但可能在复杂或数据稀疏场景中表现受限。大型语言模型及其代理在数据工程中已广泛应用，展现出强大的语义理解能力，然而在本体匹配领域的潜力尚未被充分探索，因此本研究旨在填补这一空白，探索更高效的匹配方法。",
      "method": "本研究提出了一个通用框架Agent-OM，它利用两个Siamese代理分别负责检索和匹配任务，配合一组本体匹配工具来应对特定挑战。框架在概念验证系统中实现，通过LLM代理的语义处理能力，增强了本体对齐的准确性和鲁棒性，特别针对复杂和少样本场景进行了优化。摘要未明确说明具体的数据集或模型架构细节，但强调了Siamese代理的设计是核心创新点之一。",
      "result": "通过在三个Ontology Alignment Evaluation Initiative（OAEI）测试上的评估，结果显示Agent-OM在简单的本体匹配任务上性能接近长期以来的最佳系统，而在复杂和少样本任务上则实现了显著提升。与现有最优方法相比，该系统在挑战性场景中表现出优势，例如提高了匹配精度和效率，尽管摘要未提供具体的性能指标数值，但强调了其在OAEI基准上的竞争力。",
      "conclusion": "本研究的主要贡献是引入了基于LLM代理的本体匹配新设计范式，并通过Agent-OM框架验证了其有效性，拓展了大型语言模型在语义技术领域的应用。这不仅具有学术价值，推动了AI与本体工程的交叉研究，还为实际数据集成和语义Web应用提供了高效工具。未来工作可能包括优化代理架构或扩展至更多样化场景，但摘要未明确说明具体局限性或方向。",
      "tags": [
        "Large Language Model",
        "Ontology Matching",
        "Agent-based Systems",
        "Siamese Networks",
        "Few-shot Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:10:38.872341Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2311.01591",
    "title": "Fair Graph Machine Learning under Adversarial Missingness Processes",
    "authors": [
      "Debolina Halder Lina",
      "Arlei Silva"
    ],
    "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art results in many relevant tasks where decisions might disproportionately impact specific communities. However, existing work on fair GNNs often assumes that either sensitive attributes are fully observed or they are missing completely at random. We show that an adversarial missingness process can inadvertently disguise a fair model through the imputation, leading the model to overestimate the fairness of its predictions. We address this challenge by proposing Better Fair than Sorry (BFtS), a fair missing data imputation model for sensitive attributes. The key principle behind BFtS is that imputations should approximate the worst-case scenario for fairness -- i.e. when optimizing fairness is the hardest. We implement this idea using a 3-player adversarial scheme where two adversaries collaborate against a GNN classifier, and the classifier minimizes the maximum bias. Experiments using synthetic and real datasets show that BFtS often achieves a better fairness x accuracy trade-off than existing alternatives under an adversarial missingness process.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2311.01591.pdf",
    "abs_url": "https://arxiv.org/abs/2311.01591",
    "published": "2023-11-02T20:57:44Z",
    "updated": "2026-01-29T04:21:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了BFtS模型，用于在对抗性缺失过程中实现公平的图机器学习。",
      "motivation": "公平图神经网络在影响社区决策的任务中至关重要，但现有研究常假设敏感属性完全观察或随机缺失。现实中，缺失可能具有对抗性，通过数据插值过程无意中隐藏公平问题，导致模型评估时高估公平性，从而在决策中可能加剧偏见。这突出了解决对抗性缺失以提升真实公平性的必要性，因为现有方法无法处理这种挑战。",
      "method": "论文提出Better Fair than Sorry (BFtS)，一个公平缺失数据插值模型，针对敏感属性。其核心原则是插值应近似于优化公平性最困难的情况。采用3玩家对抗方案实现：两个对抗者协作挑战一个GNN分类器，分类器则旨在最小化最大偏见，通过对抗训练促进公平性优化。该方法结合了图神经网络和对抗学习，用于处理缺失数据并提升模型鲁棒性。",
      "result": "实验使用合成和真实数据集，结果显示在对抗性缺失过程下，BFtS通常比现有方法实现更好的公平性与准确性权衡。例如，在公平性指标和准确性之间取得改进，但具体性能数据摘要未明确说明，整体表现为在多种场景下优于基线方法。这表明BFtS能有效降低偏见并保持模型性能。",
      "conclusion": "本文的主要贡献是BFtS模型，它通过对抗性插值处理敏感属性缺失，增强了图机器学习的公平性。研究具有重要学术价值，改进了公平GNNs方法，并提升真实世界应用中公平性评估的准确性。潜在局限性或未来方向摘要未明确说明，但可能包括扩展到其他缺失模式或多任务学习。",
      "tags": [
        "Graph Neural Networks",
        "Adversarial Learning",
        "Fairness",
        "Missing Data Imputation",
        "Sensitive Attributes"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:05.532785Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2309.16117",
    "title": "Low-redundancy Distillation for Continual Learning",
    "authors": [
      "RuiQi Liu",
      "Boyu Diao",
      "Libo Huang",
      "Zijia An",
      "Hangda Liu",
      "Zhulin An",
      "Yongjun Xu"
    ],
    "abstract": "Continual learning (CL) aims to learn new tasks without erasing previous knowledge. However, current CL methods primarily emphasize improving accuracy while often neglecting training efficiency, which consequently restricts their practical application. Drawing inspiration from the brain's contextual gating mechanism, which selectively filters neural information and continuously updates past memories, we propose Low-redundancy Distillation (LoRD), a novel CL method that enhances model performance while maintaining training efficiency. This is achieved by eliminating redundancy in three aspects of CL: student model redundancy, teacher model redundancy, and rehearsal sample redundancy. By compressing the learnable parameters of the student model and pruning the teacher model, LoRD facilitates the retention and optimization of prior knowledge, effectively decoupling task-specific knowledge without manually assigning isolated parameters for each task. Furthermore, we optimize the selection of rehearsal samples and refine rehearsal frequency to improve training efficiency. Through a meticulous design of distillation and rehearsal strategies, LoRD effectively balances training efficiency and model precision. Extensive experimentation across various benchmark datasets and environments demonstrates LoRD's superiority, achieving the highest accuracy with the lowest training FLOPs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2309.16117.pdf",
    "abs_url": "https://arxiv.org/abs/2309.16117",
    "published": "2023-09-28T02:48:13Z",
    "updated": "2026-01-29T06:56:54Z",
    "comment": "Accepted by Pattern Recognition",
    "light_analysis": {
      "overview": "本文提出低冗余蒸馏（LoRD）方法，通过消除学生模型、教师模型和排练样本的冗余，以平衡持续学习中的模型精度和训练效率。",
      "motivation": "持续学习的目标是在不遗忘先前知识的情况下学习新任务，但现有方法过分关注准确性而忽视训练效率，限制了实际应用。本研究受大脑上下文门控机制的启发，该机制能选择性过滤信息并更新记忆，旨在解决训练效率低下的问题，以提升持续学习的实用性。",
      "method": "LoRD 方法通过三个方面减少冗余：压缩学生模型的可学习参数以降低学生模型冗余，剪枝教师模型以减少教师模型冗余，并优化排练样本选择和频率来减少排练样本冗余。这有效保留了先前知识，无需为每个任务手动分配隔离参数，结合蒸馏和排练策略的精心设计，实现效率和精度的平衡。",
      "result": "实验在多个基准数据集和环境下进行，结果表明 LoRD 实现了最高的准确率和最低的训练浮点运算次数（FLOPs），相较于基线方法，在提升模型性能的同时显著改善了训练效率。摘要未提供具体数据，但突出了其在综合实验中的优越性。",
      "conclusion": "LoRD 通过减少冗余创新性地平衡了持续学习的训练效率和模型精度，增强了方法的实际应用价值。其贡献包括改进知识保留和优化策略，为解决实际部署中的效率问题提供了新思路。未来工作可能涉及进一步优化或在更多场景中的应用扩展。",
      "tags": [
        "Continual Learning",
        "Knowledge Distillation",
        "Model Compression",
        "Rehearsal Strategy",
        "Parameter Pruning"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:08.092776Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2210.05607",
    "title": "Divergence Results and Convergence of a Variance Reduced Version of ADAM",
    "authors": [
      "Ruiqi Wang",
      "Diego Klabjan"
    ],
    "abstract": "Stochastic optimization algorithms using exponential moving averages of the past gradients, such as ADAM, RMSProp and AdaGrad, have been having great successes in many applications, especially in training deep neural networks. ADAM in particular stands out as efficient and robust. Despite of its outstanding performance, ADAM has been proved to be divergent for some specific problems. We revisit the divergent question and provide divergent examples under stronger conditions such as in expectation or high probability. Under a variance reduction assumption, we show that an ADAM-type algorithm converges, which means that it is the variance of gradients that causes the divergence of original ADAM. To this end, we propose a variance reduced version of ADAM and provide a convergent analysis of the algorithm. Numerical experiments show that the proposed algorithm has as good performance as ADAM. Our work suggests a new direction for fixing the convergence issues.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2210.05607.pdf",
    "abs_url": "https://arxiv.org/abs/2210.05607",
    "published": "2022-10-11T16:54:56Z",
    "updated": "2026-01-29T11:21:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种方差减少的ADAM算法，解决了原始ADAM的发散问题，并提供了收敛证明。",
      "motivation": "ADAM等基于指数移动平均的随机优化算法在深度神经网络训练中表现出色，但ADAM已被证明在特定问题中发散，这引发了对其可靠性的担忧。现有方法的不足之处在于无法保证收敛，从而限制了算法在复杂任务中的应用。本研究旨在解决这一收敛问题，以提高优化算法的稳定性和可预测性，为实际部署提供更坚实的基础。",
      "method": "论文重新审视ADAM的发散问题，在更强条件（如期望或高概率）下提供发散示例。基于梯度方差导致发散的假设，提出一个方差减少版本的ADAM算法。该方法的关键创新点是通过减少梯度方差来确保收敛，并进行了详细的收敛分析，使用了随机优化框架来验证算法的稳定性，但摘要未明确说明具体数据集或模型架构。",
      "result": "数值实验显示，所提出的方差减少ADAM算法在性能上与原始ADAM相当，有效解决了发散问题。虽然没有给出具体性能指标，但实验结果表明新算法保持了ADAM的高效性和鲁棒性，与基线方法相比在收敛性上具有优势，验证了梯度方差是导致原始ADAM发散的关键因素。",
      "conclusion": "论文的主要贡献在于指出梯度方差是ADAM发散的根本原因，并通过方差减少算法实现了收敛。这项研究的学术价值在于提供了改进优化算法收敛性的新思路，实际应用价值在于增强了深度神经网络训练的稳定性。未来工作可探索更广泛的方差减少技术，或将此方法应用到其他优化算法中。",
      "tags": [
        "ADAM",
        "Variance Reduction",
        "Stochastic Optimization",
        "Convergence Analysis",
        "Deep Neural Networks"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:16.479596Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2210.00310",
    "title": "Parametrized Power-Iteration Clustering for Directed Graphs",
    "authors": [
      "Gwendal Debaussart-Joniec",
      "Harry Sevi",
      "Matthieu Jonckheere",
      "Argyris Kalogeratos"
    ],
    "abstract": "Vertex-level clustering for directed graphs (digraphs) remains challenging as edge directionality breaks the key assumptions underlying popular spectral methods, which also incur the overhead of eigen-decomposition. This paper proposes Parametrized Power-Iteration Clustering (ParPIC), a random-walk-based clustering method for weakly connected digraphs. This builds over the Power-Iteration Clustering paradigm, which uses the rows of the iterated diffusion operator as a data embedding. ParPIC has three important features: the use of parametrized reversible random walk operators, the automatic tuning of the diffusion time, and the efficient truncation of the final embedding, which produces low-dimensional data representations and reduces complexity. Empirical results on synthetic and real-world graphs demonstrate that ParPIC achieves competitive clustering accuracy with improved scalability relative to spectral and teleportation-based methods.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2210.00310.pdf",
    "abs_url": "https://arxiv.org/abs/2210.00310",
    "published": "2022-10-01T16:13:40Z",
    "updated": "2026-01-29T13:03:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Parametrized Power-Iteration Clustering (ParPIC)，一种参数化功率迭代聚类方法，用于解决有向图顶点聚类问题，提高可扩展性并应对方向性挑战。",
      "motivation": "有向图顶点聚类因边方向性而困难重重，因为方向性破坏了流行谱方法（如谱聚类）的对称性假设，导致这些方法失效，同时谱方法需要特征分解，计算开销大。现有方法如基于teleportation的技术虽能处理方向性，但可能效率不足或复杂度高。因此，亟需开发一种能有效结合方向性信息、降低计算复杂度并保持准确性的新聚类方法，以应用于社交网络、生物网络等真实场景。",
      "method": "ParPIC基于随机游走范式，构建于Power-Iteration Clustering之上，使用迭代扩散算子的行作为数据嵌入。关键创新包括：引入参数化可逆随机游走算子以增强灵活性和适应性；自动调整扩散时间，优化聚类过程并减少手动调参；以及高效截断最终嵌入，生成低维表示以降低计算复杂度。该方法专注于弱连通有向图，无需特征分解，通过参数化技术提升效率和可扩展性。",
      "result": "在合成和真实世界图上的实证实验表明，ParPIC在聚类准确性上与基线方法（如谱方法和基于teleportation的方法）竞争性相当，具体性能指标摘要未明确说明数字。结果显示，ParPIC显著改进了可扩展性，在处理大规模图时计算效率更高，减少了特征分解带来的计算开销，从而在保持精度的同时提升了处理速度。",
      "conclusion": "ParPIC的主要贡献是提出一种有效、可扩展的有向图聚类方法，通过参数化随机游走和优化技术解决了方向性带来的限制。学术上，它扩展了随机游走聚类理论；实际中，可应用于推荐系统、网络分析等领域。未来工作可能包括扩展到更复杂的图结构或进一步自动参数调整，摘要未明确说明局限性，但可推断可能涉及图类型的普适性优化。",
      "tags": [
        "Directed Graphs",
        "Random Walk Clustering",
        "Power-Iteration Clustering",
        "Parameterized Optimization",
        "Spectral Methods"
      ]
    },
    "analyzed_at": "2026-01-30T04:11:48.856709Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "1810.06284",
    "title": "CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement Learning",
    "authors": [
      "Cédric Colas",
      "Pierre Fournier",
      "Olivier Sigaud",
      "Mohamed Chetouani",
      "Pierre-Yves Oudeyer"
    ],
    "abstract": "In open-ended environments, autonomous learning agents must set their own goals and build their own curriculum through an intrinsically motivated exploration. They may consider a large diversity of goals, aiming to discover what is controllable in their environments, and what is not. Because some goals might prove easy and some impossible, agents must actively select which goal to practice at any moment, to maximize their overall mastery on the set of learnable goals. This paper proposes CURIOUS, an algorithm that leverages 1) a modular Universal Value Function Approximator with hindsight learning to achieve a diversity of goals of different kinds within a unique policy and 2) an automated curriculum learning mechanism that biases the attention of the agent towards goals maximizing the absolute learning progress. Agents focus sequentially on goals of increasing complexity, and focus back on goals that are being forgotten. Experiments conducted in a new modular-goal robotic environment show the resulting developmental self-organization of a learning curriculum, and demonstrate properties of robustness to distracting goals, forgetting and changes in body properties.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/1810.06284.pdf",
    "abs_url": "https://arxiv.org/abs/1810.06284",
    "published": "2018-10-15T11:40:28Z",
    "updated": "2026-01-29T11:57:35Z",
    "comment": "Accepted at ICML 2019 https://github.com/flowersteam/curious",
    "light_analysis": {
      "overview": "本文提出CURIOUS算法，通过内在动机和模块化设计，使自主代理能自适应地建立多目标强化学习课程。",
      "motivation": "在开放环境中，自主代理需探索多样目标，但目标难度各异，需智能选择练习以最大化学习效果。现有方法可能缺乏有效的内在动机和动态课程学习机制，导致学习效率低下。该研究旨在解决代理如何自主设定和优化学习路径的问题，这对于开发适应复杂环境的AI系统至关重要。",
      "method": "CURIOUS算法结合模块化通用价值函数逼近器与后视学习，以实现单一策略内多类型目标；并引入自动课程学习机制，基于绝对学习进展动态调整代理关注的目标。关键创新点包括利用 hindsight learning 处理目标多样性，以及通过监测学习进展指导课程构建。实验在一个新的模块化目标机器人环境中进行，但摘要未明确说明具体数据集和模型架构细节。",
      "result": "实验结果表明，代理能够发展性地自组织学习课程，顺序关注复杂性增加的目标并重新关注被遗忘的目标。系统展现出对干扰目标、遗忘现象和身体属性变化的鲁棒性，但摘要未提供具体性能指标（如准确率提升）或与基线方法的详细对比信息。",
      "conclusion": "本研究提出CURIOUS算法，实现了内在动机驱动的多目标强化学习，使代理能自主构建和优化学习课程。这为AI系统在开放环境中的自适应学习提供了新思路，具有重要的学术和实际应用价值。摘要未提及算法的局限性或未来研究方向。",
      "tags": [
        "Intrinsically Motivated Reinforcement Learning",
        "Modular Value Function Approximator",
        "Hindsight Learning",
        "Automated Curriculum Learning",
        "Multi-Goal Learning"
      ]
    },
    "analyzed_at": "2026-01-30T04:12:15.554862Z",
    "analysis_status": "success",
    "analysis_error": null
  }
]