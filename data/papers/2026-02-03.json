[
  {
    "id": "2602.02067",
    "title": "Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data",
    "authors": [
      "Nikola Cenikj",
      "Özgün Turgut",
      "Alexander Müller",
      "Alexander Steger",
      "Jan Kehrer",
      "Marcus Brugger",
      "Daniel Rueckert",
      "Eimo Martens",
      "Philip Müller"
    ],
    "abstract": "Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02067.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02067",
    "published": "2026-02-02T13:07:52Z",
    "updated": "2026-02-02T13:07:52Z",
    "comment": null,
    "light_analysis": {
      "overview": "本研究提出了一种基于Transformer的多视图多实例学习框架SegmentMIL，用于患者级冠状动脉狭窄分类，无需视图级注释。",
      "motivation": "冠状动脉狭窄是心血管疾病的主要诊断目标，通常通过多视图血管造影分析。现有深度学习方法多依赖单视图，需要昂贵的视图级注释，这些注释在实际医院系统中难以获取，且无法捕获多视图间的时序动态和依赖关系，这对临床决策至关重要。因此，开发一种无需视图级注释、能有效整合多视图信息的方法，以提升诊断的准确性和实用性，成为当前研究的迫切需求。",
      "method": "本研究提出SegmentMIL，一种基于Transformer的多视图多实例学习框架。该方法使用真实世界临床数据集进行训练，仅依赖患者级监督，无需视图级注释。通过Transformer架构建模多视图间的依赖关系，SegmentMIL联合预测冠状动脉狭窄的存在，并定位受影响的解剖区域，包括区分左右冠状动脉及其段。关键创新在于将多实例学习与Transformer结合，以处理患者级数据并捕获视图间复杂交互。",
      "result": "SegmentMIL在内部和外部评估中表现出高性能，并优于视图级模型和经典多实例学习基线。摘要未提供具体准确率数字，但表明该框架在真实临床数据上有效分类狭窄并定位区域，验证了其作为临床可行解决方案的潜力。结果表明，该方法能有效利用多视图信息，无需视图级注释即可实现准确诊断。",
      "conclusion": "本研究的主要贡献是提出SegmentMIL，一个无需视图级注释的多视图多实例学习框架，用于冠状动脉狭窄诊断，具有学术和实际应用价值。其学术价值在于结合Transformer和多实例学习处理临床数据挑战，实际价值在于提供可扩展的临床工具。未来工作可能包括优化模型泛化能力或在更广泛数据集上验证，但摘要未明确说明具体局限性。",
      "tags": [
        "Transformer",
        "Multiple-Instance Learning",
        "Multi-View Learning",
        "Coronary Stenosis Classification",
        "Clinical Data Analysis"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:30.527980Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.02061",
    "title": "Learning to Route and Schedule LLMs from User Retrials via Contextual Queueing Bandits",
    "authors": [
      "Seoungbin Bae",
      "Junyoung Son",
      "Dabeen Lee"
    ],
    "abstract": "Explosive demands for LLMs often cause user queries to accumulate in server queues, requiring efficient routing (query-LLM matching) and scheduling (query prioritization) mechanisms. Several online algorithms are being deployed, but they overlook the following two key challenges inherent to conversational LLM services: (1) unsatisfied users may retry queries, increasing the server backlog, and (2) requests for ``explicit\" feedback, such as ratings, degrade user experiences. In this paper, we develop a joint routing and scheduling algorithm that leverages ``implicit\" feedback inferred from user retrial behaviors. The key idea is to propose and study the framework of contextual queueing bandits with multinomial logit feedback (CQB-MNL). CQB-MNL models query retrials, as well as context-based learning for user preferences over LLMs. Our algorithm, anytime CQB (ACQB), achieves efficient learning while maintaining queue stability by combining Thompson sampling with forced exploration at a decaying rate. We show that ACQB simultaneously achieves a cumulative regret of $\\widetilde{\\mathcal{O}}(\\sqrt{t})$ for routing and a queue length regret of $\\widetilde{\\mathcal{O}}(t^{-1/4})$ for any large $t$. For experiments, we refine query embeddings via contrastive learning while adopting a disjoint parameter model to learn LLM-specific parameters. Experiments on SPROUT, EmbedLLM, and RouterBench datasets confirm that both algorithms consistently outperform baselines.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02061.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02061",
    "published": "2026-02-02T13:01:41Z",
    "updated": "2026-02-02T13:01:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出基于上下文排队强盗（CQB-MNL）框架的联合路由调度算法，利用用户重试作为隐式反馈优化LLM服务队列管理。",
      "motivation": "随着LLM需求的激增，用户查询在服务器队列中大量累积，亟需高效的路由（查询与LLM匹配）和调度（查询优先级排序）机制。现有在线算法忽视了两个关键挑战：不满意用户的重试行为会增加服务器积压，而请求显式反馈（如评分）会损害用户体验。本研究旨在开发新算法，通过利用用户重试提供的隐式反馈，解决这些问题，以优化LLM服务效率，减少负载并改善用户体验。",
      "method": "论文提出上下文排队强盗与多逻辑反馈（CQB-MNL）框架，将查询重试建模为隐式反馈，以学习用户对LLM的偏好。核心算法ACQB结合Thompson采样进行路由决策的贝叶斯更新，并通过衰减率的强制探索来平衡学习效率和队列稳定性。实验部分使用对比学习精炼查询嵌入，并采用分离参数模型学习每个LLM的特定参数，从而提高匹配准确性和调度性能。",
      "result": "理论分析显示ACQB算法在路由上实现累积遗憾为√̃(t)，在队列长度上实现遗憾为̃(t^{-1/4})，确保高效学习。在SPROUT、EmbedLLM和RouterBench数据集上的实验表明，该算法在路由和调度任务中一致优于基线方法，具体性能指标如准确率提升（摘要未明确说明具体数值），验证了利用隐式反馈的有效性和模型优化带来的改进。",
      "conclusion": "本研究贡献了CQB-MNL框架和ACQB算法，通过隐式反馈联合优化LLM服务中的路由和调度，解决了用户重试和显式反馈不足的关键问题。这不仅推动了在线学习和队列管理理论的进展，还提供了实际部署中的高效解决方案，减少服务器积压并提升用户体验。未来工作可扩展到更复杂的用户行为模型或多服务器环境，以进一步增强算法适用性。",
      "tags": [
        "Contextual Bandits",
        "Thompson Sampling",
        "Contrastive Learning",
        "LLM Scheduling",
        "Queueing Theory"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:03.062474Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.02060",
    "title": "FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance",
    "authors": [
      "Hyunsuk Chung",
      "Caren Han",
      "Yerin Choi",
      "Seungyeon Ji",
      "Jinwoo Kim",
      "Eun-Jung Holden",
      "Kyungreem Han"
    ],
    "abstract": "Multimodal foundation models integrate heterogeneous signals across modalities, yet it remains poorly understood how their predictions depend on specific internal feature groups and whether such reliance can be deliberately controlled. Existing studies of shortcut and spurious behavior largely rely on post hoc analyses or feature removal, offering limited insight into whether reliance can be modulated without altering task semantics. We introduce FiLoRA (Focus-and-Ignore LoRA), an instruction-conditioned, parameter-efficient adaptation framework that enables explicit control over internal feature reliance while keeping the predictive objective fixed. FiLoRA decomposes adaptation into feature group-aligned LoRA modules and applies instruction-conditioned gating, allowing natural language instructions to act as computation-level control signals rather than task redefinitions. Across text--image and audio--visual benchmarks, we show that instruction-conditioned gating induces consistent and causal shifts in internal computation, selectively amplifying or suppressing core and spurious feature groups without modifying the label space or training objective. Further analyses demonstrate that FiLoRA yields improved robustness under spurious feature interventions, revealing a principled mechanism to regulate reliance beyond correlation-driven learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02060.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02060",
    "published": "2026-02-02T13:00:57Z",
    "updated": "2026-02-02T13:00:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "FiLoRA提出了一种基于指令条件门控的参数高效适应框架，以实现多模态基础模型中内部特征依赖的可控性。",
      "motivation": "当前多模态基础模型在整合异构信号时，其预测如何依赖于特定内部特征组以及这种依赖是否可被主动控制尚不清楚，这影响了模型的可靠性和鲁棒性理解。现有方法如事后分析或特征移除存在局限，无法在不改变任务语义的前提下调节依赖，因此需要一种新的机制来允许用户直接控制内部计算而不影响预测目标，以解决虚假关联和依赖偏见的问题。",
      "method": "FiLoRA框架将参数高效适应分解为特征组对齐的LoRA模块，并应用指令条件门控机制。关键创新在于使用自然语言指令作为计算级控制信号，而不是重新定义任务，从而允许用户通过指令来选择性放大或抑制特定特征组，保持预测目标不变。该方法基于LoRA技术进行适配，适用于文本-图像和音频-视觉等多模态任务，提高了适应的灵活性和控制精度。",
      "result": "在文本-图像和音频-视觉基准测试中，指令条件门控引起内部计算的一致和因果偏移，有效选择性控制核心和虚假特征组，不改变标签空间或训练目标。进一步分析显示，FiLoRA在虚假特征干预下提供改进的鲁棒性，超越传统相关性驱动学习，展示了调节特征依赖的原理机制。摘要未提供具体性能指标数据，但强调其在实际应用中的效果和对比优势。",
      "conclusion": "FiLoRA框架的主要贡献在于提供了一种在不改变任务语义的情况下控制多模态模型中特征依赖的方法，学术上为理解模型内部机制提供了新工具，应用上可能提高模型鲁棒性和可控性。尽管摘要未明确说明具体局限性，但未来工作可扩展其泛化能力和在不同任务中的应用，揭示更多关于计算调节的深层机制。",
      "tags": [
        "Multimodal Foundation Models",
        "LoRA",
        "Instruction-Conditioned Gating",
        "Feature Reliance Control",
        "Robustness"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:46.726107Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.02055",
    "title": "FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification",
    "authors": [
      "Nan Qiao",
      "Sheng Yue"
    ],
    "abstract": "In Internet-of-Things systems, federated learning has advanced online reinforcement learning (RL) by enabling parallel policy training without sharing raw data. However, interacting with real environments online can be risky and costly, motivating offline federated RL (FRL), where local devices learn from fixed datasets. Despite its promise, offline FRL may break down under low-quality, heterogeneous data. Offline RL tends to get stuck in local optima, and in FRL, one device's suboptimal policy can degrade the aggregated model, i.e., policy pollution. We present FORLER, combining Q-ensemble aggregation on the server with actor rectification on devices. The server robustly merges device Q-functions to curb policy pollution and shift heavy computation off resource-constrained hardware without compromising privacy. Locally, actor rectification enriches policy gradients via a zeroth-order search for high-Q actions plus a bespoke regularizer that nudges the policy toward them. A $δ$-periodic strategy further reduces local computation. We theoretically provide safe policy improvement performance guarantees. Extensive experiments show FORLER consistently outperforms strong baselines under varying data quality and heterogeneity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02055.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02055",
    "published": "2026-02-02T12:57:09Z",
    "updated": "2026-02-02T12:57:09Z",
    "comment": "accetped by IEEE International Conference on Communications (ICC 2026)",
    "light_analysis": {
      "overview": "提出FORLER方法，通过服务器端Q-ensemble聚合和设备端actor rectification，有效解决离线联邦强化学习中的数据异构性和政策污染问题。",
      "motivation": "物联网系统中，联邦学习推动在线强化学习，但直接与环境互动存在风险和高成本，因此离线联邦RL成为有前景的替代方案。然而，设备上的固定数据集质量低且异构，导致离线RL易陷入局部最优；在联邦设置中，一个设备的次优策略通过聚合传播会污染整个模型，即政策污染问题，这限制了离线FRL的实际应用。现有方法难以处理此类挑战，亟需稳健解决方案以提升性能并保护隐私。",
      "method": "FORLER的核心方法结合服务器端Q-ensemble聚合和设备端actor rectification：服务器利用Q函数集成稳健合并来自设备的Q函数，减少政策污染并将计算负担转移至服务器，保护隐私；设备端通过零阶搜索寻找高Q值的动作，配合定制正则器引导策略更新，丰富政策梯度。此外，δ-periodic策略进一步降低本地计算开销，优化资源使用效率。",
      "result": "理论分析表明，FORLER提供安全政策改进的性能保证，确保模型聚合后不会退化。广泛实验验证其在不同数据质量和异构性条件下均一致优于强基线方法，展示了鲁棒性和有效性。摘要未明确说明具体性能指标如准确率提升，但强调在各种场景下优于基准，证明了方法在应对数据挑战时的优势。",
      "conclusion": "FORLER通过集成聚合和策略校正，成功解决离线联邦强化学习中的政策污染和局部最优问题，提高了模型性能和鲁棒性。研究在学术上拓展了联邦学习与强化学习的融合领域，实际应用中可在物联网等资源受限场景实现更安全、高效的智能决策。未来工作可能包括扩展到更多RL变体或处理更复杂的数据分布，进一步探索方法潜力。",
      "tags": [
        "Federated Learning",
        "Offline Reinforcement Learning",
        "Q-Ensemble",
        "Actor Rectification",
        "Zeroth-order Search"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:30.970512Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.02053",
    "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
    "authors": [
      "Pengyu Wang",
      "Benfeng Xu",
      "Licheng Zhang",
      "Shaohan Wang",
      "Mingxuan Du",
      "Chiwei Zhu",
      "Zhendong Mao"
    ],
    "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.02053.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02053",
    "published": "2026-02-02T12:55:29Z",
    "updated": "2026-02-02T12:55:29Z",
    "comment": "https://github.com/BstWPY/WildGraphBench",
    "light_analysis": {
      "overview": "本文引入了WildGraphBench基准，用于评估GraphRAG在真实世界长上下文和大规模异构文档中的性能，弥补现有基准的不足。",
      "motivation": "GraphRAG基于图结构组织外部知识以增强信息检索和生成，但在实际应用中，如处理多文档信息时，现有基准常依赖短小、编辑过的段落，无法充分模拟长上下文和大规模异构文档的真实场景。这导致评估偏差，难以反映GraphRAG在现实部署中的挑战，如维基百科等多源引用环境。因此，研究旨在开发更贴近真实世界的评估工具，以推动技术优化并解决现有方法在复杂文档处理中的局限性。",
      "method": "本研究提出WildGraphBench基准，利用维基百科的结构特性构建，其中文章基于长且异构的外部参考文档。方法创新地采样12个顶级主题的文章，使用其外部参考作为检索语料，并以引用链接的陈述作为事实依据。基准包含1,100个问题，分为三个复杂度级别：单事实问答、多事实问答和部分级总结。这种设计模拟了真实多文档检索场景，确保了评估的全面性和实际相关性，为核心技术提供了可靠测试平台。",
      "result": "在多个基线的实验中，WildGraphBench显示当前GraphRAG管道在多事实聚合方面表现良好，特别是在证据来自中等数量来源时能有效整合信息。然而，实验揭示GraphRAG可能过度强调高层次陈述而牺牲细节，导致在总结任务中性能较弱。基准的对比突出了聚合范式的局限性，表明在实际应用中需要优化以平衡整体和局部信息，为识别技术弱点提供了数据支撑。",
      "conclusion": "WildGraphBench作为一个新基准，成功评估了GraphRAG在真实场景下的性能，揭示了其多事实聚合能力和总结任务中的局限性。学术上，它推动了GraphRAG研究向更实际的应用发展；实践中，帮助开发者和研究者识别系统弱点以优化设计。未来工作可能包括改进聚合算法以更好地处理细节，或扩展基准到更广泛的文档类型，以丰富评估多样性。",
      "tags": [
        "GraphRAG",
        "Benchmark",
        "Wikipedia",
        "Heterogeneous Documents",
        "Summarization"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:01.353334Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.02051",
    "title": "SIDiffAgent: Self-Improving Diffusion Agent",
    "authors": [
      "Shivank Garg",
      "Ayush Singh",
      "Gaurav Kumar Nayak"
    ],
    "abstract": "Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse\" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \\modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02051.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02051",
    "published": "2026-02-02T12:53:21Z",
    "updated": "2026-02-02T12:53:21Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02050",
    "title": "Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents",
    "authors": [
      "Zeping Li",
      "Hongru Wang",
      "Yiwen Zhao",
      "Guanhua Chen",
      "Yixia Li",
      "Keyang Chen",
      "Yixin Cao",
      "Guangnan Ye",
      "Hongfeng Chai",
      "Mengdi Wang",
      "Zhenfei Yin"
    ],
    "abstract": "Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02050.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02050",
    "published": "2026-02-02T12:52:14Z",
    "updated": "2026-02-02T12:52:14Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02047",
    "title": "Dissecting Outlier Dynamics in LLM NVFP4 Pretraining",
    "authors": [
      "Peijie Dong",
      "Ruibo Fan",
      "Yuechen Tao",
      "Di Mou",
      "Wenhu Hu",
      "Zhenheng Tang",
      "Yinghao Yu",
      "Jiamang Wang",
      "Wenbo Su",
      "Guodong Yang",
      "Liping Zhang",
      "Xiaowen Chu",
      "Baochun Li",
      "Bo Li"
    ],
    "abstract": "Training large language models using 4-bit arithmetic enhances throughput and memory efficiency. Yet, the limited dynamic range of FP4 increases sensitivity to outliers. While NVFP4 mitigates quantization error via hierarchical microscaling, a persistent loss gap remains compared to BF16. This study conducts a longitudinal analysis of outlier dynamics across architecture during NVFP4 pretraining, focusing on where they localize, why they occur, and how they evolve temporally. We find that, compared with Softmax Attention (SA), Linear Attention (LA) reduces per-tensor heavy tails but still exhibits persistent block-level spikes under block quantization. Our analysis attributes outliers to specific architectural components: Softmax in SA, gating in LA, and SwiGLU in FFN, with \"post-QK\" operations exhibiting higher sensitivity to quantization. Notably, outliers evolve from transient spikes early in training to a small set of persistent hot channels (i.e., channels with persistently large magnitudes) in later stages. Based on these findings, we introduce Hot-Channel Patch (HCP), an online compensation mechanism that identifies hot channels and reinjects residuals using hardware-efficient kernels. We then develop CHON, an NVFP4 training recipe integrating HCP with post-QK operation protection. On GLA-1.3B model trained for 60B tokens, CHON reduces the loss gap to BF16 from 0.94% to 0.58% while maintaining downstream accuracy.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02047.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02047",
    "published": "2026-02-02T12:50:27Z",
    "updated": "2026-02-02T12:50:27Z",
    "comment": "39 pages, 32 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02045",
    "title": "On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems",
    "authors": [
      "Yiming Yang",
      "Xiaoyuan Cheng",
      "Yi He",
      "Kaiyu Li",
      "Wenxuan Yuan",
      "Zhuo Sun"
    ],
    "abstract": "Diffusion models have recently emerged as powerful learned priors for Bayesian inverse problems (BIPs). Diffusion-based solvers rely on a presumed likelihood for the observations in BIPs to guide the generation process. However, the link between likelihood and recovery quality for BIPs is unclear in previous works. We bridge this gap by characterizing the posterior approximation error and proving the \\emph{stability} of the diffusion-based solvers. Meanwhile, an immediate result of our findings on stability demonstrates the lack of robustness in diffusion-based solvers, which remains unexplored. This can degrade performance when the presumed likelihood mismatches the unknown true data generation processes. To address this issue, we propose a simple yet effective solution, \\emph{robust diffusion posterior sampling}, which is provably \\emph{robust} and compatible with existing gradient-based posterior samplers. Empirical results on scientific inverse problems and natural image tasks validate the effectiveness and robustness of our method, showing consistent performance improvements under challenging likelihood misspecifications.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02045.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02045",
    "published": "2026-02-02T12:47:15Z",
    "updated": "2026-02-02T12:47:15Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02043",
    "title": "Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models",
    "authors": [
      "Cristian Sbrolli",
      "Matteo Matteucci",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing \"a red cube and a blue sphere\" with \"a blue cube and a red sphere\". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., \"a monitor to the left of a bicycle on a white background\") and LLM-generated Contextual captions (e.g., \"In a brightly lit photography studio, a monitor is positioned to the left of a bicycle\"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel \"Confusion Benchmark\" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02043.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02043",
    "published": "2026-02-02T12:39:39Z",
    "updated": "2026-02-02T12:39:39Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02039",
    "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
    "authors": [
      "Wei Liu",
      "Peijie Yu",
      "Michele Orini",
      "Yali Du",
      "Yulan He"
    ],
    "abstract": "The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02039.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02039",
    "published": "2026-02-02T12:36:57Z",
    "updated": "2026-02-02T12:36:57Z",
    "comment": "14 pages, 7 tables, 8 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02034",
    "title": "Constrained Process Maps for Multi-Agent Generative AI Workflows",
    "authors": [
      "Ananya Joshi",
      "Michael Rudow"
    ],
    "abstract": "Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02034.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02034",
    "published": "2026-02-02T12:32:11Z",
    "updated": "2026-02-02T12:32:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02033",
    "title": "One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation",
    "authors": [
      "Shuo Lu",
      "Haohan Wang",
      "Wei Feng",
      "Weizhen Wang",
      "Shen Zhang",
      "Yaoyu Li",
      "Ao Ma",
      "Zheng Zhang",
      "Jingjing Lv",
      "Junjie Shen",
      "Ching Law",
      "Bing Zhan",
      "Yuan Xu",
      "Huizai Yao",
      "Yongcan Yu",
      "Chenyang Si",
      "Jian Liang"
    ],
    "abstract": "Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all\" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \\textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02033.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02033",
    "published": "2026-02-02T12:30:53Z",
    "updated": "2026-02-02T12:30:53Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02029",
    "title": "Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation",
    "authors": [
      "Zhongyuan Lyu",
      "Shuoyu Hu",
      "Lujie Liu",
      "Hongxia Yang",
      "Ming LI"
    ],
    "abstract": "Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02029.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02029",
    "published": "2026-02-02T12:26:27Z",
    "updated": "2026-02-02T12:26:27Z",
    "comment": "41 pages, 4 figures, 5 tables",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02028",
    "title": "Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories",
    "authors": [
      "Ya Gao",
      "Kalle Kujanpää",
      "Pekka Marttinen",
      "Harri Valpola",
      "Alexander Ilin"
    ],
    "abstract": "Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02028.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02028",
    "published": "2026-02-02T12:22:51Z",
    "updated": "2026-02-02T12:22:51Z",
    "comment": "under review",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02027",
    "title": "Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron",
    "authors": [
      "Sicheng Shen",
      "Mingyang Lv",
      "Han Shen",
      "Jialin Wu",
      "Binghao Wang",
      "Zhou Yang",
      "Guobin Shen",
      "Dongcheng Zhao",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "abstract": "The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02027.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02027",
    "published": "2026-02-02T12:21:54Z",
    "updated": "2026-02-02T12:21:54Z",
    "comment": "21 pages, 3 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02018",
    "title": "Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction",
    "authors": [
      "Enes Altinisik",
      "Masoomali Fatehkia",
      "Fatih Deniz",
      "Nadir Durrani",
      "Majd Hawasly",
      "Mohammad Raza",
      "Husrev Taha Sencar"
    ],
    "abstract": "Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.02018.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02018",
    "published": "2026-02-02T12:15:50Z",
    "updated": "2026-02-02T12:15:50Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02016",
    "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
    "authors": [
      "Ionut-Vlad Modoranu",
      "Philip Zmushko",
      "Erik Schultheis",
      "Mher Safaryan",
      "Dan Alistarh"
    ],
    "abstract": "Shampoo is one of the leading approximate second-order optimizers: a variant of it has won the MLCommons AlgoPerf competition, and it has been shown to produce models with lower activation outliers that are easier to compress. Yet, applying Shampoo currently comes at the cost of significant computational slowdown, due to its expensive internal operations. In this paper, we take a significant step to address this shortcoming by proposing \\method (for \\textbf{D}istributed \\textbf{A}ccelerated \\textbf{SH}ampoo), a faster implementation of Distributed Shampoo based on two main new techniques: First, we show that preconditioner blocks can be stacked into 3D tensors to significantly improve GPU utilization; second, we introduce the Newton-DB iteration and the Chebyshev polynomial approximations as novel and faster approaches for computing the inverse matrix roots required by Shampoo. Along with these algorithmic contributions, we provide a first in-depth analysis of how matrix scaling critically affects Shampoo convergence. On the practical side, our GPU-aware implementation achieves up to $4.83\\times$ faster optimizer steps compared to the well-optimized Distributed Shampoo, while Newton-DB attains the lowest validation perplexity per iteration among all tested methods. Our code is available at https://github.com/IST-DASLab/DASH.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02016.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02016",
    "published": "2026-02-02T12:14:45Z",
    "updated": "2026-02-02T12:14:45Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02015",
    "title": "Robust Domain Generalization under Divergent Marginal and Conditional Distributions",
    "authors": [
      "Jewon Yeom",
      "Kyubyung Chae",
      "Hyunggyu Lim",
      "Yoonna Oh",
      "Dongyoon Yang",
      "Taesup Kim"
    ],
    "abstract": "Domain generalization (DG) aims to learn predictive models that can generalize to unseen domains. Most existing DG approaches focus on learning domain-invariant representations under the assumption of conditional distribution shift (i.e., primarily addressing changes in $P(X\\mid Y)$ while assuming $P(Y)$ remains stable). However, real-world scenarios with multiple domains often involve compound distribution shifts where both the marginal label distribution $P(Y)$ and the conditional distribution $P(X\\mid Y)$ vary simultaneously. To address this, we propose a unified framework for robust domain generalization under divergent marginal and conditional distributions. We derive a novel risk bound for unseen domains by explicitly decomposing the joint distribution into marginal and conditional components and characterizing risk gaps arising from both sources of divergence. To operationalize this bound, we design a meta-learning procedure that minimizes and validates the proposed risk bound across seen domains, ensuring strong generalization to unseen ones. Empirical evaluations demonstrate that our method achieves state-of-the-art performance not only on conventional DG benchmarks but also in challenging multi-domain long-tailed recognition settings where both marginal and conditional shifts are pronounced.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02015.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02015",
    "published": "2026-02-02T12:13:41Z",
    "updated": "2026-02-02T12:13:41Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02014",
    "title": "Rethinking Genomic Modeling Through Optical Character Recognition",
    "authors": [
      "Hongxin Xiang",
      "Pengsen Ma",
      "Yunkang Cao",
      "Di Yu",
      "Haowen Chen",
      "Xinyu Yang",
      "Xiangxiang Zeng"
    ],
    "abstract": "Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \\emph{visual DNA encoder} and a \\emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\\times$ fewer effective tokens, and surpasses models with up to $985\\times$ more activated parameters while tuning only 256k \\emph{trainable} parameters.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02014.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02014",
    "published": "2026-02-02T12:12:00Z",
    "updated": "2026-02-02T12:12:00Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02013",
    "title": "SNAP: A Self-Consistent Agreement Principle with Application to Robust Computation",
    "authors": [
      "Xiaoyi Jiang",
      "Andreas Nienkötter"
    ],
    "abstract": "We introduce SNAP (Self-coNsistent Agreement Principle), a self-supervised framework for robust computation based on mutual agreement. Based on an Agreement-Reliability Hypothesis SNAP assigns weights that quantify agreement, emphasizing trustworthy items and downweighting outliers without supervision or prior knowledge. A key result is the Exponential Suppression of Outlier Weights, ensuring that outliers contribute negligibly to computations, even in high-dimensional settings. We study properties of SNAP weighting scheme and show its practical benefits on vector averaging and subspace estimation. Particularly, we demonstrate that non-iterative SNAP outperforms the iterative Weiszfeld algorithm and two variants of multivariate median of means. SNAP thus provides a flexible, easy-to-use, broadly applicable approach to robust computation.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02013.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02013",
    "published": "2026-02-02T12:10:31Z",
    "updated": "2026-02-02T12:10:31Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02010",
    "title": "NEAT: Neuron-Based Early Exit for Large Reasoning Models",
    "authors": [
      "Kang Liu",
      "Yongkang Liu",
      "Xiaocui Yang",
      "Peidong Wang",
      "Wen Zhang",
      "Shi Feng",
      "Yifei Zhang",
      "Daling Wang"
    ],
    "abstract": "Large Reasoning Models (LRMs) often suffer from \\emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \\textbf{NEAT}, a \\textbf{N}euron-based \\textbf{E}arly re\\textbf{A}soning exi\\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\\% to 28\\% when averaged over the four benchmarks, while maintaining accuracy.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.02010.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02010",
    "published": "2026-02-02T12:09:59Z",
    "updated": "2026-02-02T12:09:59Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02009",
    "title": "Logic-Guided Vector Fields for Constrained Generative Modeling",
    "authors": [
      "Ali Baheri"
    ],
    "abstract": "Neuro-symbolic systems aim to combine the expressive structure of symbolic logic with the flexibility of neural learning; yet, generative models typically lack mechanisms to enforce declarative constraints at generation time. We propose Logic-Guided Vector Fields (LGVF), a neuro-symbolic framework that injects symbolic knowledge, specified as differentiable relaxations of logical constraints, into flow matching generative models. LGVF couples two complementary mechanisms: (1) a training-time logic loss that penalizes constraint violations along continuous flow trajectories, with weights that emphasize correctness near the target distribution; and (2) an inference-time adjustment that steers sampling using constraint gradients, acting as a lightweight, logic-informed correction to the learned dynamics. We evaluate LGVF on three constrained generation case studies spanning linear, nonlinear, and multi-region feasibility constraints. Across all settings, LGVF reduces constraint violations by 59-82% compared to standard flow matching and achieves the lowest violation rates in each case. In the linear and ring settings, LGVF also improves distributional fidelity as measured by MMD, while in the multi-obstacle setting, we observe a satisfaction-fidelity trade-off, with improved feasibility but increased MMD. Beyond quantitative gains, LGVF yields constraint-aware vector fields exhibiting emergent obstacle-avoidance behavior, routing samples around forbidden regions without explicit path planning.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02009.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02009",
    "published": "2026-02-02T12:09:42Z",
    "updated": "2026-02-02T12:09:42Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02007",
    "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation",
    "authors": [
      "Zhanghao Hu",
      "Qinglin Zhu",
      "Hanqi Yan",
      "Yulan He",
      "Lin Gui"
    ],
    "abstract": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.02007.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02007",
    "published": "2026-02-02T12:04:58Z",
    "updated": "2026-02-02T12:04:58Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02004",
    "title": "ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning",
    "authors": [
      "Gongli Xi",
      "Kun Wang",
      "Zeming Gao",
      "Huahui Yi",
      "Haolang Lu",
      "Ye Tian",
      "Wendong Wang"
    ],
    "abstract": "Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \\emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\\rightarrow$ outputs $\\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \\textbf{without any additional training}, ClueTracer improves all \\textbf{reasoning} architectures (including \\texttt{R1-OneVision}, \\texttt{Ocean-R1}, \\texttt{MM-Eureka}, \\emph{etc}.) by $\\mathbf{1.21\\times}$ on reasoning benchmarks. When transferred to \\textbf{non-reasoning} settings, it yields a $\\mathbf{1.14\\times}$ gain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02004.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02004",
    "published": "2026-02-02T12:03:56Z",
    "updated": "2026-02-02T12:03:56Z",
    "comment": "20 pages, 7 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02002",
    "title": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving",
    "authors": [
      "Guosheng Zhao",
      "Yaozeng Wang",
      "Xiaofeng Wang",
      "Zheng Zhu",
      "Tingdong Yu",
      "Guan Huang",
      "Yongchen Zai",
      "Ji Jiao",
      "Changliang Xue",
      "Xiaole Wang",
      "Zhen Yang",
      "Futang Zhu",
      "Xingang Wang"
    ],
    "abstract": "World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02002.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02002",
    "published": "2026-02-02T12:02:27Z",
    "updated": "2026-02-02T12:02:27Z",
    "comment": "16 pages, 7 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02001",
    "title": "Preserve-Then-Quantize: Balancing Rank Budgets for Quantization Error Reconstruction in LLMs",
    "authors": [
      "Yoonjun Cho",
      "Dongjae Jeon",
      "Soeun Kim",
      "Moongyu Jeon",
      "Albert No"
    ],
    "abstract": "Quantization Error Reconstruction (QER) reduces accuracy loss in Post-Training Quantization (PTQ) by approximating weights as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$, using a rank-$r$ correction to reconstruct quantization error. Prior methods devote the full rank budget to error reconstruction, which is suboptimal when $\\mathbf{W}$ has intrinsic low-rank structure and quantization corrupts dominant directions. We propose Structured Residual Reconstruction (SRR), a rank-allocation framework that preserves the top-$k$ singular subspace of the activation-scaled weight before quantization, quantizes only the residual, and uses the remaining rank $r-k$ for error reconstruction. We derive a theory-guided criterion for selecting $k$ by balancing quantization-exposed energy and unrecoverable error under rank constraints. We further show that resulting $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ parameterization naturally supports Quantized Parameter-Efficient Fine-Tuning (QPEFT), and stabilizes fine-tuning via gradient scaling along preserved directions. Experiments demonstrate consistent perplexity reductions across diverse models and quantization settings in PTQ, along with a 5.9 percentage-point average gain on GLUE under 2-bit QPEFT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.02001.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02001",
    "published": "2026-02-02T12:02:21Z",
    "updated": "2026-02-02T12:02:21Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.02000",
    "title": "SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors",
    "authors": [
      "Bing He",
      "Jingnan Gao",
      "Yunuo Chen",
      "Ning Cao",
      "Gang Chen",
      "Zhengxue Cheng",
      "Li Song",
      "Wenjun Zhang"
    ],
    "abstract": "Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.02000.pdf",
    "abs_url": "https://arxiv.org/abs/2602.02000",
    "published": "2026-02-02T11:58:26Z",
    "updated": "2026-02-02T11:58:26Z",
    "comment": "ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01999",
    "title": "From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs",
    "authors": [
      "Yanrui Du",
      "Yibo Gao",
      "Sendong Zhao",
      "Jiayun Li",
      "Haochun Wang",
      "Qika Lin",
      "Kai He",
      "Bing Qin",
      "Mengling Feng"
    ],
    "abstract": "R1-style LLMs have attracted growing attention for their capacity for self-reflection, yet the internal mechanisms underlying such behavior remain unclear. To bridge this gap, we anchor on the onset of reflection behavior and trace its layer-wise activation trajectory. Using the logit lens to read out token-level semantics, we uncover a structured progression: (i) Latent-control layers, where an approximate linear direction encodes the semantics of thinking budget; (ii) Semantic-pivot layers, where discourse-level cues, including turning-point and summarization cues, surface and dominate the probability mass; and (iii) Behavior-overt layers, where the likelihood of reflection-behavior tokens begins to rise until they become highly likely to be sampled. Moreover, our targeted interventions uncover a causal chain across these stages: prompt-level semantics modulate the projection of activations along latent-control directions, thereby inducing competition between turning-point and summarization cues in semantic-pivot layers, which in turn regulates the sampling likelihood of reflection-behavior tokens in behavior-overt layers. Collectively, our findings suggest a human-like meta-cognitive process-progressing from latent monitoring, to discourse-level regulation, and to finally overt self-reflection. Our analysis code can be found at https://github.com/DYR1/S3-CoT.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01999.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01999",
    "published": "2026-02-02T11:58:24Z",
    "updated": "2026-02-02T11:58:24Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01997",
    "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs",
    "authors": [
      "Safal Shrestha",
      "Anubhav Shrestha",
      "Aadim Nepal",
      "Minwu Kim",
      "Keith Ross"
    ],
    "abstract": "Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01997.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01997",
    "published": "2026-02-02T11:57:22Z",
    "updated": "2026-02-02T11:57:22Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01995",
    "title": "Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs",
    "authors": [
      "Jeongmoon Won",
      "Seungwon Kook",
      "Yohan Jo"
    ],
    "abstract": "Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01995.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01995",
    "published": "2026-02-02T11:56:36Z",
    "updated": "2026-02-02T11:56:36Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01996",
    "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations",
    "authors": [
      "Theologos Anthimopoulos",
      "Milad Kokhazadeh",
      "Vasilios Kelefouras",
      "Benjamin Himpel",
      "Georgios Keramidas"
    ],
    "abstract": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3x faster than IREE and 8x faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.MS"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01996.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01996",
    "published": "2026-02-02T11:56:36Z",
    "updated": "2026-02-02T11:56:36Z",
    "comment": "36 pages, 16 figures, this is the author-accepted version of the article published in ACM Transactions on Embedded Computing Systems (TECS), Vol. 24, No. 6",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01992",
    "title": "Emergent Analogical Reasoning in Transformers",
    "authors": [
      "Gouki Minegishi",
      "Jingyuan Feng",
      "Hiroki Furuta",
      "Takeshi Kojima",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "abstract": "Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01992.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01992",
    "published": "2026-02-02T11:49:36Z",
    "updated": "2026-02-02T11:49:36Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01991",
    "title": "Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models",
    "authors": [
      "Pablo Domingo-Gregorio",
      "Javier Ruiz-Hidalgo"
    ],
    "abstract": "Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01991.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01991",
    "published": "2026-02-02T11:47:48Z",
    "updated": "2026-02-02T11:47:48Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01990",
    "title": "SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning",
    "authors": [
      "Zhen-Hao Xie",
      "Jun-Tao Tang",
      "Yu-Cheng Shi",
      "Han-Jia Ye",
      "De-Chuan Zhan",
      "Da-Wei Zhou"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) achieve strong performance through instruction tuning, but real-world deployment requires them to continually expand their capabilities, making Multimodal Continual Instruction Tuning (MCIT) essential. Recent methods leverage sparse expert routing to promote task specialization, but we find that the expert routing process suffers from drift as the data distribution evolves. For example, a grounding query that previously activated localization experts may instead be routed to irrelevant experts after learning OCR tasks. Meanwhile, the grounding-related experts can be overwritten by new tasks and lose their original functionality. Such failure reflects two problems: router drift, where expert selection becomes inconsistent over time, and expert drift, where shared experts are overwritten across tasks. Therefore, we propose StAbilized Mixture-of-Experts (SAME) for MCIT. To address router drift, SAME stabilizes expert selection by decomposing routing dynamics into orthogonal subspaces and updating only task-relevant directions. To mitigate expert drift, we regulate expert updates via curvature-aware scaling using historical input covariance in a rehearsal-free manner. SAME also introduces adaptive expert activation to freeze selected experts during training, reducing redundant computation and cross-task interference. Extensive experiments demonstrate its SOTA performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01990.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01990",
    "published": "2026-02-02T11:47:06Z",
    "updated": "2026-02-02T11:47:06Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01984",
    "title": "Enhancing Multi-Image Understanding through Delimiter Token Scaling",
    "authors": [
      "Minyoung Lee",
      "Yeji Park",
      "Dongjun Hwang",
      "Yejin Kim",
      "Seong Joon Oh",
      "Junsuk Choe"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01984.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01984",
    "published": "2026-02-02T11:38:01Z",
    "updated": "2026-02-02T11:38:01Z",
    "comment": "Accepted at ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01983",
    "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
    "authors": [
      "Xintian Shen",
      "Jiawei Chen",
      "Lihao Zheng",
      "Hao Ma",
      "Tao Wei",
      "Kun Zhan"
    ],
    "abstract": "Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\\uparrow$ and +23.04%$\\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01983.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01983",
    "published": "2026-02-02T11:37:45Z",
    "updated": "2026-02-02T11:37:45Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01982",
    "title": "S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs",
    "authors": [
      "Yanrui Du",
      "Sendong Zhao",
      "Yibo Gao",
      "Danyang Zhao",
      "Qika Lin",
      "Ming Ma",
      "Jiayun Li",
      "Yi Jiang",
      "Kai He",
      "Qianyi Xu",
      "Bing Qin",
      "Mengling Feng"
    ],
    "abstract": "Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01982.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01982",
    "published": "2026-02-02T11:37:36Z",
    "updated": "2026-02-02T11:37:36Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01977",
    "title": "Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing",
    "authors": [
      "Shuainan Liu",
      "Xuanang Chen",
      "Ben He",
      "Le Sun"
    ],
    "abstract": "Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01977.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01977",
    "published": "2026-02-02T11:33:25Z",
    "updated": "2026-02-02T11:33:25Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01976",
    "title": "FlyPrompt: Brain-Inspired Random-Expanded Routing with Temporal-Ensemble Experts for General Continual Learning",
    "authors": [
      "Hongwei Yan",
      "Guanglong Sun",
      "Kanglei Zhou",
      "Qian Li",
      "Liyuan Wang",
      "Yi Zhong"
    ],
    "abstract": "General continual learning (GCL) challenges intelligent systems to learn from single-pass, non-stationary data streams without clear task boundaries. While recent advances in continual parameter-efficient tuning (PET) of pretrained models show promise, they typically rely on multiple training epochs and explicit task cues, limiting their effectiveness in GCL scenarios. Moreover, existing methods often lack targeted design and fail to address two fundamental challenges in continual PET: how to allocate expert parameters to evolving data distributions, and how to improve their representational capacity under limited supervision. Inspired by the fruit fly's hierarchical memory system characterized by sparse expansion and modular ensembles, we propose FlyPrompt, a brain-inspired framework that decomposes GCL into two subproblems: expert routing and expert competence improvement. FlyPrompt introduces a randomly expanded analytic router for instance-level expert activation and a temporal ensemble of output heads to dynamically adapt decision boundaries over time. Extensive theoretical and empirical evaluations demonstrate FlyPrompt's superior performance, achieving up to 11.23%, 12.43%, and 7.62% gains over state-of-the-art baselines on CIFAR-100, ImageNet-R, and CUB-200, respectively. Our source code is available at https://github.com/AnAppleCore/FlyGCL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01976.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01976",
    "published": "2026-02-02T11:32:56Z",
    "updated": "2026-02-02T11:32:56Z",
    "comment": "33 pages. Accepted by ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01975",
    "title": "IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs",
    "authors": [
      "Meng Li",
      "Peisong Wang",
      "Yuantian Shao",
      "Qinghao Hu",
      "Hongjian Fang",
      "Yifan Zhang",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "abstract": "Large Language Models (LLMs) achieve strong performance across diverse tasks but face deployment challenges due to their massive size. Structured pruning offers acceleration benefits but leads to significant performance degradation. Recent PCA-based pruning methods have alleviated this issue by retaining key activation components, but are only applied between modules in order to fuse the transformation matrix, which introduces extra parameters and severely disrupts activation distributions due to residual connections. To address these issues, we propose IntraSlice, a framework that applies block-wise module-intra PCA compression pruning. By leveraging the structural characteristics of Transformer modules, we design an approximate PCA method whose transformation matrices can be fully fused into the model without additional parameters. We also introduce a PCA-based global pruning ratio estimator that further considers the distribution of compressed activations, building on conventional module importance. We validate our method on Llama2, Llama3, and Phi series across various language benchmarks. Experimental results demonstrate that our approach achieves superior compression performance compared to recent baselines at the same compression ratio or inference speed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01975.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01975",
    "published": "2026-02-02T11:28:56Z",
    "updated": "2026-02-02T11:28:56Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01973",
    "title": "Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated",
    "authors": [
      "Muli Yang",
      "Gabriel James Goenawan",
      "Henan Wang",
      "Huaiyuan Qin",
      "Chenghao Xu",
      "Yanhua Yang",
      "Fen Fang",
      "Ying Sun",
      "Joo-Hwee Lim",
      "Hongyuan Zhu"
    ],
    "abstract": "Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at https://github.com/muliyangm/AIGI-Det-Calib.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01973.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01973",
    "published": "2026-02-02T11:26:37Z",
    "updated": "2026-02-02T11:26:37Z",
    "comment": "AAAI 2026. Code: https://github.com/muliyangm/AIGI-Det-Calib",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01970",
    "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models",
    "authors": [
      "Yun Qu",
      "Qi Wang",
      "Yixiu Mao",
      "Heming Zou",
      "Yuhang Jiang",
      "Weijie Liu",
      "Clive Bai",
      "Kai Yang",
      "Yangkun Chen",
      "Saiyong Yang",
      "Xiangyang Ji"
    ],
    "abstract": "Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01970.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01970",
    "published": "2026-02-02T11:24:36Z",
    "updated": "2026-02-02T11:24:36Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01969",
    "title": "Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models",
    "authors": [
      "Bin Cao",
      "Huixian Lu",
      "Chenwen Ma",
      "Ting Wang",
      "Ruizhe Li",
      "Jing Fan"
    ],
    "abstract": "Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01969.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01969",
    "published": "2026-02-02T11:22:43Z",
    "updated": "2026-02-02T11:22:43Z",
    "comment": "Work in process",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01967",
    "title": "Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition",
    "authors": [
      "Wonjun Lee",
      "Hyounghun Kim",
      "Gary Geunbae Lee"
    ],
    "abstract": "Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01967.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01967",
    "published": "2026-02-02T11:16:34Z",
    "updated": "2026-02-02T11:16:34Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01966",
    "title": "Self-Consolidation for Self-Evolving Agents",
    "authors": [
      "Hongzhuo Yu",
      "Fei Zhu",
      "Guo-Sen Xie",
      "Ling Shao"
    ],
    "abstract": "While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01966.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01966",
    "published": "2026-02-02T11:16:07Z",
    "updated": "2026-02-02T11:16:07Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01965",
    "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
    "authors": [
      "Kwun Hang Lau",
      "Fangyuan Zhang",
      "Boyu Ruan",
      "Yingli Zhou",
      "Qintian Guo",
      "Ruiyuan Zhang",
      "Xiaofang Zhou"
    ],
    "abstract": "Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a \"Static Graph Fallacy\": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree \"hub\" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01965.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01965",
    "published": "2026-02-02T11:13:38Z",
    "updated": "2026-02-02T11:13:38Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01962",
    "title": "Zero-Shot Off-Policy Learning",
    "authors": [
      "Arip Asadulaev",
      "Maksim Bobrin",
      "Salem Lahlou",
      "Dmitry Dylov",
      "Fakhri Karray",
      "Martin Takac"
    ],
    "abstract": "Off-policy learning methods seek to derive an optimal policy directly from a fixed dataset of prior interactions. This objective presents significant challenges, primarily due to the inherent distributional shift and value function overestimation bias. These issues become even more noticeable in zero-shot reinforcement learning, where an agent trained on reward-free data must adapt to new tasks at test time without additional training. In this work, we address the off-policy problem in a zero-shot setting by discovering a theoretical connection of successor measures to stationary density ratios. Using this insight, our algorithm can infer optimal importance sampling ratios, effectively performing a stationary distribution correction with an optimal policy for any task on the fly. We benchmark our method in motion tracking tasks on SMPL Humanoid, continuous control on ExoRL, and for the long-horizon OGBench tasks. Our technique seamlessly integrates into forward-backward representation frameworks and enables fast-adaptation to new tasks in a training-free regime. More broadly, this work bridges off-policy learning and zero-shot adaptation, offering benefits to both research areas.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01962.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01962",
    "published": "2026-02-02T11:06:31Z",
    "updated": "2026-02-02T11:06:31Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01960",
    "title": "Grounding Generated Videos in Feasible Plans via World Models",
    "authors": [
      "Christos Ziakas",
      "Amir Bar",
      "Alessandra Russo"
    ],
    "abstract": "Large-scale video generative models have shown emerging capabilities as zero-shot visual planners, yet video-generated plans often violate temporal consistency and physical constraints, leading to failures when mapped to executable actions. To address this, we propose Grounding Video Plans with World Models (GVP-WM), a planning method that grounds video-generated plans into feasible action sequences using a learned action-conditioned world model. At test-time, GVP-WM first generates a video plan from initial and goal observations, then projects the video guidance onto the manifold of dynamically feasible latent trajectories via video-guided latent collocation. In particular, we formulate grounding as a goal-conditioned latent-space trajectory optimization problem that jointly optimizes latent states and actions under world-model dynamics, while preserving semantic alignment with the video-generated plan. Empirically, GVP-WM recovers feasible long-horizon plans from zero-shot image-to-video-generated and motion-blurred videos that violate physical constraints, across navigation and manipulation simulation tasks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01960.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01960",
    "published": "2026-02-02T11:04:47Z",
    "updated": "2026-02-02T11:04:47Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01956",
    "title": "Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation",
    "authors": [
      "Seonghyeon Park",
      "Jewon Yeom",
      "Jaewon Sok",
      "Jeongjae Park",
      "Heejun Kim",
      "Taesup Kim"
    ],
    "abstract": "Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01956.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01956",
    "published": "2026-02-02T11:03:37Z",
    "updated": "2026-02-02T11:03:37Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01954",
    "title": "Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images",
    "authors": [
      "Shuai Yang",
      "Ziyue Huang",
      "Jiaxin Chen",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "abstract": "Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01954.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01954",
    "published": "2026-02-02T11:03:01Z",
    "updated": "2026-02-02T11:03:01Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01953",
    "title": "Deep Multivariate Models with Parametric Conditionals",
    "authors": [
      "Dmitrij Schlesinger",
      "Boris Flach",
      "Alexander Shekhovtsov"
    ],
    "abstract": "We consider deep multivariate models for heterogeneous collections of random variables. In the context of computer vision, such collections may e.g. consist of images, segmentations, image attributes, and latent variables. When developing such models, most existing works start from an application task and design the model components and their dependencies to meet the needs of the chosen task. This has the disadvantage of limiting the applicability of the resulting model for other downstream tasks. Here, instead, we propose to represent the joint probability distribution by means of conditional probability distributions for each group of variables conditioned on the rest. Such models can then be used for practically any possible downstream task. Their learning can be approached as training a parametrised Markov chain kernel by maximising the data likelihood of its limiting distribution. This has the additional advantage of allowing a wide range of semi-supervised learning scenarios.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01953.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01953",
    "published": "2026-02-02T11:01:48Z",
    "updated": "2026-02-02T11:01:48Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01951",
    "title": "Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network",
    "authors": [
      "Shuyang Wu",
      "Yifu Qiu",
      "Ines P. Nearchou",
      "Sandrine Prost",
      "Jonathan A Fallowfield",
      "Hakan Bilen",
      "Timothy J Kendall"
    ],
    "abstract": "Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01951.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01951",
    "published": "2026-02-02T11:00:07Z",
    "updated": "2026-02-02T11:00:07Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01949",
    "title": "Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity",
    "authors": [
      "Leonardo Stoppani",
      "Davide Bacciu",
      "Shahab Mokarizadeh"
    ],
    "abstract": "Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Fréchet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01949.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01949",
    "published": "2026-02-02T10:59:20Z",
    "updated": "2026-02-02T10:59:20Z",
    "comment": "Accepted at ESANN 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01937",
    "title": "T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation",
    "authors": [
      "Suhan Guo",
      "Bingxu Wang",
      "Shaodan Zhang",
      "Furao Shen"
    ],
    "abstract": "Time series forecasting plays a critical role in decision-making across many real-world applications. Unlike data in vision and language domains, time series data is inherently tied to the evolution of underlying processes and can only accumulate as real-world time progresses, limiting the effectiveness of scale-driven pretraining alone. This time-bound constraint poses a challenge for enabling large language models (LLMs) to acquire forecasting capability, as existing approaches primarily rely on representation-level alignment or inference-time temporal modules rather than explicitly teaching forecasting behavior to the LLM. We propose T-LLM, a temporal distillation framework that equips general-purpose LLMs with time series forecasting capability by transferring predictive behavior from a lightweight temporal teacher during training. The teacher combines trend modeling and frequency-domain analysis to provide structured temporal supervision, and is removed entirely at inference, leaving the LLM as the sole forecasting model. Experiments on benchmark datasets and infectious disease forecasting tasks demonstrate that T-LLM consistently outperforms existing LLM-based forecasting methods under full-shot, few-shot, and zero-shot settings, while enabling a simple and efficient deployment pipeline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01937.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01937",
    "published": "2026-02-02T10:40:27Z",
    "updated": "2026-02-02T10:40:27Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01936",
    "title": "PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting",
    "authors": [
      "Abdul Joseph Fofanah",
      "Lian Wen",
      "David Chen"
    ],
    "abstract": "Accurate traffic flow prediction remains a fundamental challenge in intelligent transportation systems, particularly in cross-domain, data-scarce scenarios where limited historical data hinders model training and generalisation. The complex spatio-temporal dependencies and nonlinear dynamics of urban mobility networks further complicate few-shot learning across different cities. This paper proposes MCPST, a novel Multi-phase Consensus Spatio-Temporal framework for few-shot traffic forecasting that reconceptualises traffic prediction as a multi-phase consensus learning problem. Our framework introduces three core innovations: (1) a multi-phase engine that models traffic dynamics through diffusion, synchronisation, and spectral embeddings for comprehensive dynamic characterisation; (2) an adaptive consensus mechanism that dynamically fuses phase-specific predictions while enforcing consistency; and (3) a structured meta-learning strategy for rapid adaptation to new cities with minimal data. We establish extensive theoretical guarantees, including representation theorems with bounded approximation errors and generalisation bounds for few-shot adaptation. Through experiments on four real-world datasets, MCPST outperforms fourteen state-of-the-art methods in spatio-temporal graph learning methods, dynamic graph transfer learning methods, prompt-based spatio-temporal prediction methods and cross-domain few-shot settings, improving prediction accuracy while reducing required training data and providing interpretable insights. The implementation code is available at https://github.com/afofanah/MCPST.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01936.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01936",
    "published": "2026-02-02T10:40:07Z",
    "updated": "2026-02-02T10:40:07Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01935",
    "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation",
    "authors": [
      "Annabelle Sujun Tang",
      "Christopher Priebe",
      "Lianhui Qin",
      "Hadi Esmaeilzadeh"
    ],
    "abstract": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01935.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01935",
    "published": "2026-02-02T10:37:05Z",
    "updated": "2026-02-02T10:37:05Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01933",
    "title": "Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling",
    "authors": [
      "Fabrice Boissier",
      "Monica Sen",
      "Irina Rychkova"
    ],
    "abstract": "Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01933.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01933",
    "published": "2026-02-02T10:35:42Z",
    "updated": "2026-02-02T10:35:42Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01924",
    "title": "Bayesian Integration of Nonlinear Incomplete Clinical Data",
    "authors": [
      "Lucía González-Zamorano",
      "Nuria Balbás-Esteban",
      "Vanessa Gómez-Verdejo",
      "Albert Belenguer-Llorens",
      "Carlos Sevilla-Salcedo"
    ],
    "abstract": "Multimodal clinical data are characterized by high dimensionality, heterogeneous representations, and structured missingness, posing significant challenges for predictive modeling, data integration, and interpretability. We propose BIONIC (Bayesian Integration of Nonlinear Incomplete Clinical data), a unified probabilistic framework that integrates heterogeneous multimodal data under missingness through a joint generative-discriminative latent architecture. BIONIC uses pretrained embeddings for complex modalities such as medical images and clinical text, while incorporating structured clinical variables directly within a Bayesian multimodal formulation. The proposed framework enables robust learning in partially observed and semi-supervised settings by explicitly modeling modality-level and variable-level missingness, as well as missing labels. We evaluate BIONIC on three multimodal clinical and biomedical datasets, demonstrating strong and consistent discriminative performance compared to representative multimodal baselines, particularly under incomplete data scenarios. Beyond predictive accuracy, BIONIC provides intrinsic interpretability through its latent structure, enabling population-level analysis of modality relevance and supporting clinically meaningful insight.",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01924.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01924",
    "published": "2026-02-02T10:23:53Z",
    "updated": "2026-02-02T10:23:53Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01922",
    "title": "Embedding Learning on Multiplex Networks for Link Prediction",
    "authors": [
      "Orell Trautmann",
      "Olaf Wolkenhauer",
      "Clémence Réda"
    ],
    "abstract": "Over the past years, embedding learning on networks has shown tremendous results in link prediction tasks for complex systems, with a wide range of real-life applications. Learning a representation for each node in a knowledge graph allows us to capture topological and semantic information, which can be processed in downstream analyses later. In the link prediction task, high-dimensional network information is encoded into low-dimensional vectors, which are then fed to a predictor to infer new connections between nodes in the network. As the network complexity (that is, the numbers of connections and types of interactions) grows, embedding learning turns out increasingly challenging. This review covers published models on embedding learning on multiplex networks for link prediction. First, we propose refined taxonomies to classify and compare models, depending on the type of embeddings and embedding techniques. Second, we review and address the problem of reproducible and fair evaluation of embedding learning on multiplex networks for the link prediction task. Finally, we tackle evaluation on directed multiplex networks by proposing a novel and fair testing procedure. This review constitutes a crucial step towards the development of more performant and tractable embedding learning approaches for multiplex networks and their fair evaluation for the link prediction task. We also suggest guidelines on the evaluation of models, and provide an informed perspective on the challenges and tools currently available to address downstream analyses applied to multiplex networks.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01922.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01922",
    "published": "2026-02-02T10:23:10Z",
    "updated": "2026-02-02T10:23:10Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01920",
    "title": "PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks",
    "authors": [
      "Abdul Joseph Fofanah",
      "Lian Wen",
      "David Chen"
    ],
    "abstract": "Graph neural networks (GNNs) often struggle in class-imbalanced settings, where minority classes are under-represented and predictions are biased toward majorities. We propose \\textbf{PIMPC-GNN}, a physics-informed multi-phase consensus framework for imbalanced node classification. Our method integrates three complementary dynamics: (i) thermodynamic diffusion, which spreads minority labels to capture long-range dependencies, (ii) Kuramoto synchronisation, which aligns minority nodes through oscillatory consensus, and (iii) spectral embedding, which separates classes via structural regularisation. These perspectives are combined through class-adaptive ensemble weighting and trained with an imbalance-aware loss that couples balanced cross-entropy with physics-based constraints. Across five benchmark datasets and imbalance ratios from 5-100, PIMPC-GNN outperforms 16 state-of-the-art baselines, achieving notable gains in minority-class recall (up to +12.7\\%) and balanced accuracy (up to +8.3\\%). Beyond empirical improvements, the framework also provides interpretable insights into consensus dynamics in graph learning. The code is available at \\texttt{https://github.com/afofanah/PIMPC-GNN}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01920.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01920",
    "published": "2026-02-02T10:21:58Z",
    "updated": "2026-02-02T10:21:58Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01919",
    "title": "From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted \"Vibe Coding\"",
    "authors": [
      "Hend Al-Khalifa"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01919.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01919",
    "published": "2026-02-02T10:21:34Z",
    "updated": "2026-02-02T10:21:34Z",
    "comment": "Accepted in The Seventh Workshop on Teaching Natural Language Processing (Teaching NLP @ EACL2026)",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01917",
    "title": "GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs",
    "authors": [
      "Chengguang Gan",
      "Yoshihiro Tsujii",
      "Yunhao Liang",
      "Tatsunori Mori",
      "Shiwen Ni",
      "Hiroki Itoh"
    ],
    "abstract": "Digital Adoption Platform (DAP) provide web-based overlays that deliver operation guidance and contextual hints to help users navigate complex websites. Although modern DAP tools enable non-experts to author such guidance, maintaining these guides remains labor-intensive because website layouts and functionalities evolve continuously, which requires repeated manual updates and re-annotation. In this work, we introduce \\textbf{GuideWeb}, a new benchmark for automatic in-app guide generation on real-world web UIs. GuideWeb formulates the task as producing page-level guidance by selecting \\textbf{guide target elements} grounded in the webpage and generating concise guide text aligned with user intent. We also propose a comprehensive evaluation suite that jointly measures the accuracy of guide target element selection and the quality of generated intents and guide texts. Experiments show that our proposed \\textbf{GuideWeb Agent} achieves \\textbf{30.79\\%} accuracy in guide target element prediction, while obtaining BLEU scores of \\textbf{44.94} for intent generation and \\textbf{21.34} for guide-text generation. Existing baselines perform substantially worse, which highlights that automatic guide generation remains challenging and that further advances are necessary before such systems can be reliably deployed in real-world settings.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01917.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01917",
    "published": "2026-02-02T10:21:03Z",
    "updated": "2026-02-02T10:21:03Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01915",
    "title": "VLM-Guided Experience Replay",
    "authors": [
      "Elad Sharony",
      "Tom Jurgenson",
      "Orr Krupnik",
      "Dotan Di Castro",
      "Shie Mannor"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability in reinforcement learning (RL). While prior work has integrated LLMs and VLMs into various components of RL, the replay buffer, a core component for storing and reusing experiences, remains unexplored. We propose addressing this gap by leveraging VLMs to guide the prioritization of experiences in the replay buffer. Our key idea is to use a frozen, pre-trained VLM (requiring no fine-tuning) as an automated evaluator to identify and prioritize promising sub-trajectories from the agent's experiences. Across scenarios, including game-playing and robotics, spanning both discrete and continuous domains, agents trained with our proposed prioritization method achieve 11-52% higher average success rates and improve sample efficiency by 19-45% compared to previous approaches. https://esharony.me/projects/vlm-rb/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01915.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01915",
    "published": "2026-02-02T10:19:59Z",
    "updated": "2026-02-02T10:19:59Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01914",
    "title": "Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs",
    "authors": [
      "Wenbo Pan",
      "Zhichao Liu",
      "Xianlong Wang",
      "Haining Yu",
      "Xiaohua Jia"
    ],
    "abstract": "Token attribution methods provide intuitive explanations for language model outputs by identifying causally important input tokens. However, as modern LLMs increasingly rely on extended reasoning chains, existing schemes face two critical challenges: (1) efficiency bottleneck, where attributing a target span of M tokens within a context of length N requires O(M*N) operations, making long-context attribution prohibitively slow; and (2) faithfulness drop, where intermediate reasoning tokens absorb attribution mass, preventing importance from propagating back to the original input. To address these, we introduce FlashTrace, an efficient multi-token attribution method that employs span-wise aggregation to compute attribution over multi-token targets in a single pass, while maintaining faithfulness. Moreover, we design a recursive attribution mechanism that traces importance through intermediate reasoning chains back to source inputs. Extensive experiments on long-context retrieval (RULER) and multi-step reasoning (MATH, MorehopQA) tasks demonstrate that FlashTrace achieves over 130x speedup over existing baselines while maintaining superior faithfulness. We further analyze the dynamics of recursive attribution, showing that even a single recursive hop improves faithfulness by tracing importance through the reasoning chain.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01914.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01914",
    "published": "2026-02-02T10:19:52Z",
    "updated": "2026-02-02T10:19:52Z",
    "comment": "ICML 2025 submission",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01910",
    "title": "DomusFM: A Foundation Model for Smart-Home Sensor Data",
    "authors": [
      "Michele Fiori",
      "Gabriele Civitarese",
      "Flora D. Salim",
      "Claudio Bettini"
    ],
    "abstract": "Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01910.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01910",
    "published": "2026-02-02T10:16:34Z",
    "updated": "2026-02-02T10:16:34Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01906",
    "title": "DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification",
    "authors": [
      "Farhan Ullah",
      "Irfan Ullah",
      "Khalil Khan",
      "Giovanni Pau",
      "JaKeoung Koo"
    ],
    "abstract": "Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01906.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01906",
    "published": "2026-02-02T10:12:18Z",
    "updated": "2026-02-02T10:12:18Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01905",
    "title": "Learning Sparse Visual Representations via Spatial-Semantic Factorization",
    "authors": [
      "Theodore Zhengde Zhao",
      "Sid Kiblawi",
      "Jianwei Yang",
      "Naoto Usuyama",
      "Reuben Tan",
      "Noel C Codella",
      "Tristan Naumann",
      "Hoifung Poon",
      "Mu Wei"
    ],
    "abstract": "Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at https://aka.ms/stellar.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01905.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01905",
    "published": "2026-02-02T10:12:17Z",
    "updated": "2026-02-02T10:12:17Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01903",
    "title": "Data- and Variance-dependent Regret Bounds for Online Tabular MDPs",
    "authors": [
      "Mingyi Li",
      "Taira Tsuchiya",
      "Kenji Yamanishi"
    ],
    "abstract": "This work studies online episodic tabular Markov decision processes (MDPs) with known transitions and develops best-of-both-worlds algorithms that achieve refined data-dependent regret bounds in the adversarial regime and variance-dependent regret bounds in the stochastic regime. We quantify MDP complexity using a first-order quantity and several new data-dependent measures for the adversarial regime, including a second-order quantity and a path-length measure, as well as variance-based measures for the stochastic regime. To adapt to these measures, we develop algorithms based on global optimization and policy optimization, both built on optimistic follow-the-regularized-leader with log-barrier regularization. For global optimization, our algorithms achieve first-order, second-order, and path-length regret bounds in the adversarial regime, and in the stochastic regime, they achieve a variance-aware gap-independent bound and a variance-aware gap-dependent bound that is polylogarithmic in the number of episodes. For policy optimization, our algorithms achieve the same data- and variance-dependent adaptivity, up to a factor of the episode horizon, by exploiting a new optimistic $Q$-function estimator. Finally, we establish regret lower bounds in terms of data-dependent complexity measures for the adversarial regime and a variance measure for the stochastic regime, implying that the regret upper bounds achieved by the global-optimization approach are nearly optimal.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01903.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01903",
    "published": "2026-02-02T10:09:29Z",
    "updated": "2026-02-02T10:09:29Z",
    "comment": "80pages, 4tables",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01901",
    "title": "Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model",
    "authors": [
      "Jiedong Zhuang",
      "Lu Lu",
      "Ming Dai",
      "Rui Hu",
      "Jian Chen",
      "Qiang Liu",
      "Haoji Hu"
    ],
    "abstract": "Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01901.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01901",
    "published": "2026-02-02T10:08:00Z",
    "updated": "2026-02-02T10:08:00Z",
    "comment": "Accepted by AAAI26",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01898",
    "title": "Observation-dependent Bayesian active learning via input-warped Gaussian processes",
    "authors": [
      "Sanna Jarl",
      "Maria Bånkestad",
      "Jonathan J. S. Scragg",
      "Jens Sjölund"
    ],
    "abstract": "Bayesian active learning relies on the precise quantification of predictive uncertainty to explore unknown function landscapes. While Gaussian process surrogates are the standard for such tasks, an underappreciated fact is that their posterior variance depends on the observed outputs only through the hyperparameters, rendering exploration largely insensitive to the actual measurements. We propose to inject observation-dependent feedback by warping the input space with a learned, monotone reparameterization. This mechanism allows the design policy to expand or compress regions of the input space in response to observed variability, thereby shaping the behavior of variance-based acquisition functions. We demonstrate that while such warps can be trained via marginal likelihood, a novel self-supervised objective yields substantially better performance. Our approach improves sample efficiency across a range of active learning benchmarks, particularly in regimes where non-stationarity challenges traditional methods.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01898.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01898",
    "published": "2026-02-02T10:05:56Z",
    "updated": "2026-02-02T10:05:56Z",
    "comment": "13 pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01897",
    "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
    "authors": [
      "Sungheon Jeong",
      "Sanggeon Yun",
      "Ryozo Masukawa",
      "Wenjun Haung",
      "Hanning Chen",
      "Mohsen Imani"
    ],
    "abstract": "Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce \\emph{internal flow signatures} that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact \\emph{moving} readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. \\emph{Code is available at} \\texttt{github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs}.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01897.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01897",
    "published": "2026-02-02T10:05:54Z",
    "updated": "2026-02-02T10:05:54Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01893",
    "title": "Geometric Analysis of Token Selection in Multi-Head Attention",
    "authors": [
      "Timur Mudarisov",
      "Mikhal Burtsev",
      "Tatiana Petrova",
      "Radu State"
    ],
    "abstract": "We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01893.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01893",
    "published": "2026-02-02T10:04:40Z",
    "updated": "2026-02-02T10:04:40Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01885",
    "title": "ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support",
    "authors": [
      "Tiantian Chen",
      "Jiaqi Lu",
      "Ying Shen",
      "Lin Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01885.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01885",
    "published": "2026-02-02T09:58:26Z",
    "updated": "2026-02-02T09:58:26Z",
    "comment": "12 pages, 7 figures. Accepted to The Web Conference (WWW) 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01884",
    "title": "Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models",
    "authors": [
      "Shidong Yang",
      "Tongwen Huang",
      "Hao Wen",
      "Yong Wang",
      "Li Chen",
      "Xiangxiang Chu"
    ],
    "abstract": "Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01884.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01884",
    "published": "2026-02-02T09:58:24Z",
    "updated": "2026-02-02T09:58:24Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01881",
    "title": "ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding",
    "authors": [
      "Ye Chen",
      "Yupeng Zhu",
      "Xiongzhen Zhang",
      "Zhewen Wan",
      "Yingzhe Li",
      "Wenjun Zhang",
      "Bingbing Ni"
    ],
    "abstract": "Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01881.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01881",
    "published": "2026-02-02T09:53:45Z",
    "updated": "2026-02-02T09:53:45Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01877",
    "title": "Autocorrelated Optimize-via-Estimate: Predict-then-Optimize versus Finite-sample Optimal",
    "authors": [
      "Zichun Wang",
      "Gar Goei Loke",
      "Ruiting Zuo"
    ],
    "abstract": "Models that directly optimize for out-of-sample performance in the finite-sample regime have emerged as a promising alternative to traditional estimate-then-optimize approaches in data-driven optimization. In this work, we compare their performance in the context of autocorrelated uncertainties, specifically, under a Vector Autoregressive Moving Average VARMA(p,q) process. We propose an autocorrelated Optimize-via-Estimate (A-OVE) model that obtains an out-of-sample optimal solution as a function of sufficient statistics, and propose a recursive form for computing its sufficient statistics. We evaluate these models on a portfolio optimization problem with trading costs. A-OVE achieves low regret relative to a perfect information oracle, outperforming predict-then-optimize machine learning benchmarks. Notably, machine learning models with higher accuracy can have poorer decision quality, echoing the growing literature in data-driven optimization. Performance is retained under small mis-specification.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01877.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01877",
    "published": "2026-02-02T09:49:51Z",
    "updated": "2026-02-02T09:49:51Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01875",
    "title": "PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning",
    "authors": [
      "Langming Liu",
      "Kangtao Lv",
      "Haibin Chen",
      "Weidong Zhang",
      "Yejing Wang",
      "Shilei Liu",
      "Xin Tong",
      "Yujin Yuan",
      "Yongwei Wang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of \"low-probability truth\" and \"high-probability falsehood\". Recent approaches, such as teaching models to say \"I don't know\" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \\textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is \"\\textbf{debiasing then learning}.\" It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making \"room\" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01875.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01875",
    "published": "2026-02-02T09:46:05Z",
    "updated": "2026-02-02T09:46:05Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01869",
    "title": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents",
    "authors": [
      "Qirui Mi",
      "Zhijian Ma",
      "Mengyue Yang",
      "Haoxuan Li",
      "Yisen Wang",
      "Haifeng Zhang",
      "Jun Wang"
    ],
    "abstract": "LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01869.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01869",
    "published": "2026-02-02T09:43:12Z",
    "updated": "2026-02-02T09:43:12Z",
    "comment": "20 Pages, 6 Figures, 4 Tables",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01864",
    "title": "Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling",
    "authors": [
      "Yuan Wang",
      "Yuhao Wan",
      "Siming Zheng",
      "Bo Li",
      "Qibin Hou",
      "Peng-Tao Jiang"
    ],
    "abstract": "Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a \"Trust but Verify\" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01864.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01864",
    "published": "2026-02-02T09:34:57Z",
    "updated": "2026-02-02T09:34:57Z",
    "comment": "26 pages, 19 figures. Accepted to ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01858",
    "title": "SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures",
    "authors": [
      "Liangtao Lin",
      "Zhaomeng Zhu",
      "Tianwei Zhang",
      "Yonggang Wen"
    ],
    "abstract": "Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01858.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01858",
    "published": "2026-02-02T09:30:43Z",
    "updated": "2026-02-02T09:30:43Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01855",
    "title": "Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG",
    "authors": [
      "Blagoj Hristov",
      "Hristijan Gjoreski",
      "Vesna Ojleska Latkoska",
      "Gorjan Nadzinski"
    ],
    "abstract": "Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\\pm$ 2.98% to 96.9% $\\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01855.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01855",
    "published": "2026-02-02T09:28:27Z",
    "updated": "2026-02-02T09:28:27Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01854",
    "title": "Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection",
    "authors": [
      "A S M Sharifuzzaman Sagar",
      "Mohammed Bennamoun",
      "Farid Boussaid",
      "Naeha Sharif",
      "Lian Xu",
      "Shaaban Sahmoud",
      "Ali Kishk"
    ],
    "abstract": "In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01854.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01854",
    "published": "2026-02-02T09:28:16Z",
    "updated": "2026-02-02T09:28:16Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01853",
    "title": "Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning",
    "authors": [
      "Xiangkun Wu",
      "Qianglin Wen",
      "Yingying Zhang",
      "Hongtu Zhu",
      "Ting Li",
      "Chengchun Shi"
    ],
    "abstract": "A/B testing has become a gold standard for modern technological companies to conduct policy evaluation. Yet, its application to time series experiments, where policies are sequentially assigned over time, remains challenging. Existing designs suffer from two limitations: (i) they do not fully leverage the entire history for treatment allocation; (ii) they rely on strong assumptions to approximate the objective function (e.g., the mean squared error of the estimated treatment effect) for optimizing the design. We first establish an impossibility theorem showing that failure to condition on the full history leads to suboptimal designs, due to the dynamic dependencies in time series experiments. To address both limitations simultaneously, we next propose a transformer reinforcement learning (RL) approach which leverages transformers to condition allocation on the entire history and employs RL to directly optimize the MSE without relying on restrictive assumptions. Empirical evaluations on synthetic data, a publicly available dispatch simulator, and a real-world ridesharing dataset demonstrate that our proposal consistently outperforms existing designs.",
    "categories": [
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01853.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01853",
    "published": "2026-02-02T09:27:51Z",
    "updated": "2026-02-02T09:27:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种基于Transformer和强化学习的方法，以改进时间序列A/B测试中的策略分配设计，解决历史利用不足和目标函数优化问题。",
      "motivation": "该研究旨在解决时间序列实验中A/B测试的应用挑战，特别是在策略随时间顺序分配时。现有方法存在两个关键局限性：一是未能充分利用整个历史数据来优化分配；二是依赖强假设（如近似均方误差）来近似目标函数，导致设计次优。时间序列的动态依赖性使得忽略完整历史会显著降低评估效果，因此开发新方法对提高政策评估的准确性和效率至关重要。",
      "method": "作者提出了一种Transformer强化学习方法，结合Transformer模型处理时间序列依赖，并利用强化学习直接优化均方误差（MSE）。关键创新在于使用Transformer对完整历史进行条件分配，避免传统方法中的强假设，通过RL框架优化设计。实验中使用了合成数据、公开可用的调度模拟器和真实世界的共享乘车数据集来验证方法的有效性。",
      "result": "实验评估在合成数据、公开调度模拟器和真实世界共享乘车数据集上进行，结果表明所提出的Transformer强化学习方法 consistently 优于现有设计。尽管摘要未明确提供具体性能指标如准确率或效率提升数值，但强调了该方法在多个场景下均能有效改善时间序列A/B测试的设计效果，展示了其在减少估计误差方面的优势。",
      "conclusion": "该研究的主要贡献是通过Transformer强化学习方法克服了时间序列A/B测试中的历史利用不足和目标函数优化挑战，建立了不可能定理并开发了新的设计框架。其学术价值在于为动态实验设计提供了创新思路，实际应用价值在于提升了政策评估的准确性和效率。未来工作可能包括将方法扩展到更复杂的实验场景或与其他技术结合，以进一步增强适应性。",
      "tags": [
        "A/B Testing",
        "Time Series Experiments",
        "Transformer",
        "Reinforcement Learning",
        "Mean Squared Error"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:23.646553Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01852",
    "title": "FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization",
    "authors": [
      "Zeyan Wang",
      "Zhengmao Liu",
      "Yongxin Cai",
      "Chi Li",
      "Xiaoying Tang",
      "Jingchao Chen",
      "Zibin Pan",
      "Jing Qiu"
    ],
    "abstract": "Federated Unlearning (FU) aims to efficiently remove the influence of specific client data from a federated model while preserving utility for the remaining clients. However, three key challenges remain: (1) existing unlearning objectives often compromise model utility or increase vulnerability to Membership Inference Attacks (MIA); (2) there is a persistent conflict between forgetting and utility, where further unlearning inevitably harms retained performance; and (3) support for concurrent multi-client unlearning is poor, as gradient conflicts among clients degrade the quality of forgetting. To address these issues, we propose FUPareto, an efficient unlearning framework via Pareto-augmented optimization. We first introduce the Minimum Boundary Shift (MBS) Loss, which enforces unlearning by suppressing the target class logit below the highest non-target class logit; this can improve the unlearning efficiency and mitigate MIA risks. During the unlearning process, FUPareto performs Pareto improvement steps to preserve model utility and executes Pareto expansion to guarantee forgetting. Specifically, during Pareto expansion, the framework integrates a Null-Space Projected Multiple Gradient Descent Algorithm (MGDA) to decouple gradient conflicts. This enables effective, fair, and concurrent unlearning for multiple clients while minimizing utility degradation. Extensive experiments across diverse scenarios demonstrate that FUPareto consistently outperforms state-of-the-art FU methods in both unlearning efficacy and retained utility.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01852.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01852",
    "published": "2026-02-02T09:25:33Z",
    "updated": "2026-02-02T09:25:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "FUPareto提出了一种基于Pareto优化的联邦遗忘框架，有效平衡遗忘与效用，支持多客户并发遗忘。",
      "motivation": "联邦遗忘旨在从联邦模型中高效移除特定客户数据的影响，同时保持对其他客户的效用。然而，现有方法面临三个主要挑战：首先，遗忘目标常导致模型效用下降或增加成员推理攻击风险；其次，遗忘与效用之间存在固有冲突，进一步遗忘会损害保留性能；最后，对多客户并发遗忘的支持不足，客户间梯度冲突降低遗忘质量。这些问题限制了联邦遗忘的实际应用，因此需要一种能同时优化遗忘和效用、处理多客户场景的新方法。",
      "method": "论文提出了FUPareto框架，通过Pareto增强优化解决遗忘-效用差距。核心方法包括引入最小边界偏移损失，通过抑制目标类logit低于最高非目标类logit来强制遗忘，提高效率并缓解攻击风险。在遗忘过程中，框架执行Pareto改进步骤以保留模型效用，并执行Pareto扩展以保证遗忘。具体地，在Pareto扩展中，集成了零空间投影多梯度下降算法来解耦客户间的梯度冲突，实现公平有效的并发遗忘。该方法未指定具体数据集，但应用于联邦学习场景。",
      "result": "通过多种场景下的广泛实验，FUPareto在遗忘效能和保留效用方面均优于最先进的联邦遗忘方法。实验表明，该框架能有效减少模型对目标数据的依赖，同时最小化对其他客户性能的影响，但摘要未明确说明具体性能指标如准确率提升百分比。与基线方法对比，FUPareto在平衡遗忘与效用、支持多客户并发遗忘方面表现更优。",
      "conclusion": "FUPareto的主要贡献是提出了一种基于Pareto优化的联邦遗忘框架，有效解决遗忘与效用之间的冲突，并支持多客户并发遗忘。其学术价值在于为联邦遗忘领域提供了新的优化思路和技术，实际应用价值体现在提升隐私保护中的遗忘效率和公平性。未来工作可能包括进一步优化算法效率或扩展到更复杂场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Federated Unlearning",
        "Pareto Optimization",
        "Minimum Boundary Shift Loss",
        "Multiple Gradient Descent Algorithm",
        "Null-Space Projection"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:39.094204Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01851",
    "title": "How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing",
    "authors": [
      "Huanyu Zhang",
      "Xuehai Bai",
      "Chengzu Li",
      "Chen Liang",
      "Haochen Tian",
      "Haodong Li",
      "Ruichuan An",
      "Yifan Zhang",
      "Anna Korhonen",
      "Zhang Zhang",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "abstract": "Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01851.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01851",
    "published": "2026-02-02T09:24:45Z",
    "updated": "2026-02-02T09:24:45Z",
    "comment": "https://vibe-benchmark.github.io/",
    "light_analysis": {
      "overview": "本研究引入了VIBE基准，用于系统评估图像编辑模型在遵循视觉指令方面的能力，填补了多模态交互在图像编辑中的空白。",
      "motivation": "近年来生成模型在图像编辑方面取得显著进展，但现有系统和基准仍以文本指导为主，未能充分适应多模态交互需求。人类交流本质上是多模态的，视觉指令（如草图）能高效传达空间和结构意图，然而这一领域的研究存在空白，缺乏系统评估模型遵循视觉指令的能力。因此，开发能理解视觉指令的模型对于提升人机交互的自然性和效率至关重要，现有方法的不足在于无法全面衡量模型的视觉指令遵循性能。",
      "method": "本研究提出了VIBE（Visual Instruction Benchmark for Image Editing）基准，通过三层交互层次（指示性基础、形态操作、因果推理）来评估视觉指令遵循能力。方法包括策划高质量、多样化的测试案例，反映逐步增加的复杂度，并开发了一个LMM-as-a-judge评估框架，使用大型语言模型作为评判者，结合任务特定指标支持可扩展和细粒度的评估。摘要未明确说明使用的具体数据集或模型架构，但强调了框架的设计以促进全面评估。",
      "result": "通过评估17个代表性开源和专有图像编辑模型，专有模型表现出早期视觉指令遵循能力，并在所有任务中一致优于开源模型。然而，性能随着任务难度增加而显著下降，即使对于最强的系统也如此，这揭示了模型在处理复杂视觉指令时面临的挑战。摘要未提供具体性能指标如准确率或效率数据，但强调了性能随复杂度降低的趋势，与基线对比显示了专有模型的优势但仍有改进空间。",
      "conclusion": "本研究的主要贡献是引入了VIBE基准和评估框架，填补了视觉指令在图像编辑中的系统评估空白。其学术价值在于提供了一个标准化工具，推动多模态交互和模型性能的研究；实际应用价值在于促进更高效的自然人机交互界面开发。局限性在于模型在复杂任务中表现不佳，未来研究应聚焦于增强模型的视觉理解和推理能力，以应对更高难度的指令。",
      "tags": [
        "Visual Instruction",
        "Image Editing",
        "Benchmark",
        "LMM-as-a-judge",
        "Multimodal Learning"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:27.976189Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01850",
    "title": "WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?",
    "authors": [
      "Pei Li",
      "Jiaxi Yin",
      "Lei Ouyang",
      "Shihan Pan",
      "Ge Wang",
      "Han Ding",
      "Fei Wang"
    ],
    "abstract": "IMU-based Human Activity Recognition (HAR) has enabled a wide range of ubiquitous computing applications, yet its dominant clip classification paradigm cannot capture the rich temporal structure of real-world behaviors. This motivates a shift toward IMU Temporal Action Localization (IMU-TAL), which predicts both action categories and their start/end times in continuous streams. However, current progress is strongly bottlenecked by the need for dense, frame-level boundary annotations, which are costly and difficult to scale. To address this bottleneck, we introduce WS-IMUBench, a systematic benchmark study of weakly supervised IMU-TAL (WS-IMU-TAL) under only sequence-level labels. Rather than proposing a new localization algorithm, we evaluate how well established weakly supervised localization paradigms from audio, image, and video transfer to IMU-TAL under only sequence-level labels. We benchmark seven representative weakly supervised methods on seven public IMU datasets, resulting in over 3,540 model training runs and 7,080 inference evaluations. Guided by three research questions on transferability, effectiveness, and insights, our findings show that (i) transfer is modality-dependent, with temporal-domain methods generally more stable than image-derived proposal-based approaches; (ii) weak supervision can be competitive on favorable datasets (e.g., with longer actions and higher-dimensional sensing); and (iii) dominant failure modes arise from short actions, temporal ambiguity, and proposal quality. Finally, we outline concrete directions for advancing WS-IMU-TAL (e.g., IMU-specific proposal generation, boundary-aware objectives, and stronger temporal reasoning). Beyond individual results, WS-IMUBench establishes a reproducible benchmarking template, datasets, protocols, and analyses, to accelerate community-wide progress toward scalable WS-IMU-TAL.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01850.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01850",
    "published": "2026-02-02T09:22:35Z",
    "updated": "2026-02-02T09:22:35Z",
    "comment": "Under Review. 28 pages, 9 figures, 6 tables",
    "light_analysis": {
      "overview": "该论文引入了WS-IMUBench，一个针对弱监督IMU时间动作定位的基准研究，旨在评估从音频、图像和视频迁移的弱监督方法在仅序列级标签下的表现。",
      "motivation": "现有基于IMU的人类活动识别主要依赖片段分类，难以捕捉真实世界行为的复杂时间结构，因此需转向IMU时间动作定位，以预测连续流中的动作类别和起止时间。然而，该方法当前面临瓶颈，需要密集的帧级边界标注，标注成本高昂且难以扩展，限制了实际应用和可扩展性。为解决这一问题，研究探索了弱监督方法的适用性，以减少标注需求并推动领域发展。",
      "method": "论文采用基准研究方法，未提出新算法，而是系统评估了七种代表性强监督方法从音频、图像和视频迁移到IMU时间动作定位的效果。在七个公共IMU数据集上进行了超过3,540次模型训练运行和7,080次推理评估，通过三个研究问题关注迁移性能、有效性和洞察，以测试不同模态方法的稳定性和竞争力。",
      "result": "研究结果表明，迁移性能依赖于模态，时间域方法通常比图像衍生提案方法更稳定；弱监督在动作较长、传感维度较高的数据集上表现具有竞争力，但主导失败模式源于短动作、时间模糊和提案质量差。摘要未提供具体准确率数字，但基于实验评估，揭示了弱监督方法的潜力和局限性。",
      "conclusion": "该论文的主要贡献是建立了WS-IMUBench基准，包括可重复的模板、数据集、协议和分析，以加速弱监督IMU时间动作定位的社区进展。研究还指出了未来改进方向，如IMU特定的提案生成、边界感知目标和更强的时间推理。这为减少标注成本提供了学术和实用价值。",
      "tags": [
        "Weakly Supervised Learning",
        "Temporal Action Localization",
        "IMU",
        "Transfer Learning",
        "Benchmarking"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:18.669841Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01849",
    "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models",
    "authors": [
      "Ziwei Luo",
      "Ziqi Jin",
      "Lei Wang",
      "Lidong Bing",
      "Thomas B. Schön"
    ],
    "abstract": "This work presents self-rewarding sequential Monte Carlo (SMC), an inference-time scaling algorithm enabling effective sampling of masked diffusion language models (MDLMs). Our algorithm stems from the observation that most existing MDLMs rely on a confidence-based sampling strategy, where only tokens with the highest prediction confidence are preserved at each step. This restricts the generation to a noise-sensitive, greedy decoding paradigm, resulting in an inevitable collapse in the diversity of possible paths. We address this problem by launching multiple interacting diffusion processes in parallel, referred to as particles, for trajectory exploration. Importantly, we introduce the trajectory-level confidence as a self-rewarding signal for assigning particle importance weights. During sampling, particles are iteratively weighted and resampled to systematically steer generation towards globally confident, high-quality samples. Our self-rewarding SMC is verified on various masked diffusion language models and benchmarks, achieving significant improvement without extra training or reward guidance, while effectively converting parallel inference capacity into improved sampling quality. Our code is available at https://github.com/Algolzw/self-rewarding-smc.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01849.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01849",
    "published": "2026-02-02T09:21:45Z",
    "updated": "2026-02-02T09:21:45Z",
    "comment": "Project page: https://algolzw.github.io/sr-smc",
    "light_analysis": {
      "overview": "提出一种自奖励序列蒙特卡洛算法，通过并行扩散过程和轨迹级置信度信号，提升掩蔽扩散语言模型的采样质量与多样性。",
      "motivation": "现有掩蔽扩散语言模型采用基于置信度的贪婪采样策略，在每一步仅保留预测置信度最高的令牌，这导致解码过程对噪声敏感，并严重限制了生成路径的多样性，影响模型在语言生成任务中的实际应用效果。该研究旨在解决这一采样瓶颈，因为现有方法缺乏有效的轨迹探索机制，无法平衡采样效率与输出质量。",
      "method": "论文提出了自奖励序列蒙特卡洛算法，核心是并行启动多个相互作用的扩散过程（称为粒子），以探索不同轨迹。引入轨迹级置信度作为自奖励信号，为粒子分配重要性权重；在采样过程中，迭代进行加权和重采样，系统性引导生成朝向全局置信度高、高质量的样本。该方法无需额外训练或外部奖励，基于序列蒙特卡洛框架，适用于各种掩蔽扩散语言模型，通过优化推理过程提升采样效果。",
      "result": "在多种掩蔽扩散语言模型和基准测试中，自奖励序列蒙特卡洛算法实现了显著改进，有效提升了采样质量和多样性。与基线基于置信度的贪婪采样方法相比，该算法将并行推理能力转化为更好的采样效果，实验显示生成样本的全局置信度提高，但具体性能指标如准确率等摘要未明确说明。结果表明，算法在不增加训练成本的情况下，成功克服了现有方法的局限性。",
      "conclusion": "该研究的主要贡献是提出自奖励序列蒙特卡洛算法，优化了掩蔽扩散语言模型的推理采样过程。学术上，它扩展了序列蒙特卡洛方法在语言模型中的应用，提供了一种有效的采样策略；实际上，提高了生成模型的效率和适用性，适用于自然语言生成等任务。未来工作可能包括进一步优化算法计算效率或扩展到其他扩散模型，摘要未明确说明局限性。",
      "tags": [
        "Masked Diffusion Language Models",
        "Sequential Monte Carlo",
        "Self-Rewarding",
        "Particle Importance Weighting",
        "Trajectory Exploration"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:26.402857Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01848",
    "title": "ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems",
    "authors": [
      "Salaheddin Alzu'bi",
      "Baran Nama",
      "Arda Kaz",
      "Anushri Eswaran",
      "Weiyuan Chen",
      "Sarvesh Khetan",
      "Rishab Bala",
      "Tu Vu",
      "Sewoong Oh"
    ],
    "abstract": "Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01848.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01848",
    "published": "2026-02-02T09:20:59Z",
    "updated": "2026-02-02T09:20:59Z",
    "comment": null,
    "light_analysis": {
      "overview": "ROMA框架通过递归任务分解和模块化代理角色解决长视野多代理系统中的推理和上下文管理问题，结合GEPA+提示搜索方法提高性能。",
      "motivation": "当前代理框架在长视野任务中表现不佳，如推理深度增加时顺序编排变得脆弱、上下文窗口限制导致性能下降、执行轨迹不透明难以调试。这些问题在复杂推理和长文本生成等实际应用中尤为重要，而现有方法无法有效处理这些挑战，限制了多代理系统的可扩展性和鲁棒性。ROMA旨在通过结构化框架克服这些限制，提升任务处理的效率和可靠性。",
      "method": "ROMA框架采用递归任务分解将目标拆分为依赖感知的子任务树，允许并行执行，并通过聚合器压缩和验证中间结果来控制上下文增长。其核心创新在于标准化四个模块角色（Atomizer、Planner、Executor、Aggregator），分离编排与模型选择，支持透明层次执行轨迹。此外，引入GEPA+（改进的遗传-Pareto提示提议器），在组件层次内搜索提示以适配特定任务，无需微调，支持异构多代理系统混合模型和工具。",
      "result": "ROMA在推理和长文本生成基准测试中表现领先。在SEAL-0基准（评估网络证据冲突推理）上，使用GLM-4.6的ROMA准确率比Kimi-Researcher提高了9.9%。在EQ-Bench（长文本写作基准）上，ROMA使DeepSeek-V3的性能达到了闭源模型如Claude Sonnet 4.5的水平。这些结果展示了ROMA在处理复杂任务时的优势，尤其在准确率和模型兼容性方面超过基线方法。",
      "conclusion": "ROMA框架的主要贡献是提出一种递归模块化代理架构，能扩展推理深度同时保持可解释性、灵活性和模型无关性。学术上，它推动了多代理系统设计的研究；实际应用中，为复杂任务提供了可扩展和透明的解决方案。尽管摘要未明确说明局限性，但未来工作可能包括优化框架性能、扩展到更多领域或进一步验证在多样化任务上的表现。",
      "tags": [
        "Recursive Task Decomposition",
        "Modular Agent Architecture",
        "Prompt Proposer",
        "Context Aggregation",
        "Heterogeneous Multi-Agent Systems"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:37.157949Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01845",
    "title": "No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation",
    "authors": [
      "Furkan Eris"
    ],
    "abstract": "Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \\textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $ρ= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01845.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01845",
    "published": "2026-02-02T09:17:09Z",
    "updated": "2026-02-02T09:17:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了Proust模型，一个高效的因果蛋白质语言模型，通过架构创新同时实现蛋白质生成和零射适应性预测。",
      "motivation": "当前蛋白质语言模型面临根本性分裂：掩码语言模型擅长适应性预测，而因果模型支持生成，迫使实践者维护独立的架构。这增加了计算成本和复杂性，限制了应用的统一性和扩展性。本研究的动机是解决这一分裂问题，通过开发一个统一模型来提高效率，使蛋白质适应性估计在零射场景下更实用，减少对大量计算资源的需求。",
      "method": "论文提出Proust模型，一个309M参数的因果蛋白质语言模型。核心方法采用架构创新，包括grouped-query attention with shared K/V projections、cross-layer value residuals和depthwise causal convolutions，这些技术借鉴自大型语言模型研究。模型在33B个tokens上训练，使用40 B200 GPU小时，实现了高效的训练和推理，以桥接生成和适应性预测的能力。",
      "result": "在ProteinGym substitutions基准上，Proust实现Spearman ρ=0.390，与需要50-200倍计算量的掩码语言模型竞争。在indels任务上，它设置了新的state-of-the-art，性能优于参数大20倍的模型。在EVEREST病毒适应性基准上，仅使用序列信息就接近结构感知方法的水平。此外，模型保持了固有的生成能力，验证了其表示的有效性。",
      "conclusion": "主要贡献是Proust模型，通过架构创新统一了蛋白质语言模型的生成和适应性预测功能。学术价值在于借鉴大型语言模型技术提升蛋白质模型的效率和性能；实际应用价值在于降低计算成本，促进蛋白质工程和设计。可解释性分析揭示了per-position entropy variance的作用，为未来扩展如test-time scaling提供指导。",
      "tags": [
        "Protein Language Models",
        "Causal Language Models",
        "Grouped-query Attention",
        "Cross-layer Value Residuals",
        "Zero-Shot Fitness Estimation"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:25.387995Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01844",
    "title": "CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions",
    "authors": [
      "Yuliang Zhan",
      "Jian Li",
      "Wenbing Huang",
      "Wenbing Huang",
      "Yang Liu",
      "Hao Sun"
    ],
    "abstract": "Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\\footnote{As in this example.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01844.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01844",
    "published": "2026-02-02T09:16:16Z",
    "updated": "2026-02-02T09:16:16Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "CloDS 是一个无监督学习框架，通过视觉数据学习布料动力学，在未知条件下无需已知物理属性。",
      "motivation": "深度学习在模拟复杂动态系统方面展现潜力，但现有方法通常需要已知物理属性作为监督或输入，这限制了其在未知环境中的应用。在实际场景中，物理参数往往难以获取，导致传统方法适应性差。因此，开发一种能从多视角视觉观察中无监督学习动力学的方法变得重要，以克服这一局限性并提升系统的泛化能力。",
      "method": "CloDS 采用三阶段流水线：首先，通过视频到几何接地将多视角视频转换为3D网格；其次，在接地网格上训练动力学模型。关键创新是双重位置不透明度调制，通过网格高斯喷涂技术实现2D和3D之间的双向映射，有效应对大非线性和自遮挡问题。该方法联合考虑高斯基元的绝对和相对位置，增强了几何表示的准确性和鲁棒性。",
      "result": "综合实验评估表明，CloDS 能够从视觉数据中有效学习布料动力学，并在未见配置下表现出较强的泛化能力。虽然摘要未提供具体性能数据，如准确率或效率指标，但实验暗示该方法优于需要已知物理属性的基线方法，强调了其在实际应用中的潜力。",
      "conclusion": "论文的主要贡献是提出了 Cloth Dynamics Grounding 场景和 CloDS 无监督学习框架，实现了从视觉观察中学习布料动力学。这具有重要的学术意义，推动了无监督动态学习的研究，并在实际应用中拓展了在未知条件下的系统适应性。局限性或未来工作方向在摘要中未明确说明。",
      "tags": [
        "Unsupervised Learning",
        "Cloth Dynamics",
        "Gaussian Splatting",
        "Multi-view Visual Observations",
        "Video-to-Geometry Grounding"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:44.737746Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01843",
    "title": "SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection",
    "authors": [
      "Qian Xu",
      "Xi Li",
      "Fei Gao",
      "Jie Guo",
      "Haojuan Yuan",
      "Shuaipeng Fan",
      "Mingjin Zhang"
    ],
    "abstract": "Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01843.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01843",
    "published": "2026-02-02T09:15:29Z",
    "updated": "2026-02-02T09:15:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "SPIRIT框架通过轻量级物理信息插件，将视觉基础模型适应于红外小目标检测，实现单帧与多帧推理的统一。",
      "motivation": "红外小目标检测在监控和预警中至关重要，但面临数据稀缺、目标信号弱、语义线索有限等挑战。现有方法直接应用视觉基础模型时，由于红外与可见光谱的模态差异，语义特征聚合会淹没局部目标峰值，外观驱动跨帧关联不可靠，导致虚假背景关联。因此，亟需一种能适应红外特性并整合单帧和多帧推理的解决方案，以提高检测准确性和鲁棒性，弥补现有方法的不足。",
      "method": "SPIRIT框架引入两个轻量级物理信息插件：空间上，PIFR通过近似秩稀疏分解抑制结构化背景成分、增强稀疏目标信号；时间上，PGMA将历史软空间先验注入内存交叉注意力，约束跨帧关联，实现鲁棒视频检测。该框架基于视觉基础模型，通过插件适应红外数据，无时间上下文时自然回退单帧推理，统一了单帧和多帧检测流程。",
      "result": "实验在多个红外小目标检测基准上进行，结果显示SPIRIT相比基于视觉基础模型的基线方法取得一致性能增益，并达到最先进水平，证明了其在提升检测准确性和鲁棒性方面的有效性。摘要未明确说明具体性能指标，但强调了优于基线和SOTA性能。",
      "conclusion": "SPIRIT的主要贡献在于通过物理信息插件适应视觉基础模型，解决了红外小目标检测中的模态差距和跨帧关联模糊问题，提升了检测的一致性和效率。该研究具有学术价值，推动了红外视觉应用的模型适配技术；实际应用上可增强监控系统的预警能力。未来可探索插件优化或扩展到其他红外任务。",
      "tags": [
        "Infrared Small Target Detection",
        "Vision Foundation Models",
        "Memory Attention",
        "Rank-Sparsity Decomposition",
        "Physics-Informed Plug-ins"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:24.954926Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01842",
    "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
    "authors": [
      "Jinbin Bai",
      "Yixuan Li",
      "Yuchen Zhu",
      "Yi Xin",
      "Qingyu Shi",
      "Aosong Feng",
      "Xiaohong Liu",
      "Molei Tao",
      "Jianru Xue",
      "Xiangtai Li",
      "Ming-Hsuan Yang"
    ],
    "abstract": "Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01842.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01842",
    "published": "2026-02-02T09:14:51Z",
    "updated": "2026-02-02T09:14:51Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Prism框架，通过层次搜索和自验证实现离散扩散语言模型在推理时的高效扩展。",
      "motivation": "推理时间计算被重新提出以提升大语言模型的推理能力，但大多数测试时间扩展算法依赖自回归解码，这不适用于离散扩散语言模型，因为后者对整个序列进行并行解码。这导致现有方法无法有效释放dLLMs的生成潜力，因此开发高效、适合dLLMs的测试时间扩展方法成为一个重要且未充分探索的挑战。",
      "method": "Prism框架采用Hierarchical Trajectory Search在去噪的早期到中期动态修剪和重新分配计算资源；引入Local branching with partial remasking探索多样性实现，同时保留高置信度标记；并使用Self-Verified Feedback通过自评估提示替换外部验证器，以优化测试时间扩展效率。",
      "result": "在数学推理和代码生成的四个基准上，使用三个dLLMs（如LLaDA 8B Instruct、Dream 7B Instruct和LLaDA 2.0-mini），Prism实现了性能-效率的优越平衡，匹配了最佳性能，同时显著减少了函数评估次数，具体效果表现为用更少计算开销达到类似性能。",
      "conclusion": "该研究的主要贡献是提出了高效的测试时间扩展框架Prism，解锁离散扩散语言模型的生成潜力，具有学术和实际应用价值，通过减少计算开销促进其在推理任务中的应用。未来可能进一步扩展到其他领域或模型优化。",
      "tags": [
        "Test-Time Scaling",
        "Discrete Diffusion Language Models",
        "Hierarchical Search",
        "Self-Verification",
        "Local Branching"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:20.327641Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01840",
    "title": "Read As Human: Compressing Context via Parallelizable Close Reading and Skimming",
    "authors": [
      "Jiwei Tang",
      "Shilei Liu",
      "Zhicheng Zhang",
      "Qingsong Lv",
      "Runsong Zhao",
      "Tingwei Lu",
      "Langming Liu",
      "Haibin Chen",
      "Yujin Yuan",
      "Hai-Tao Zheng",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01840.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01840",
    "published": "2026-02-02T09:10:56Z",
    "updated": "2026-02-02T09:10:56Z",
    "comment": "13 pages,5 figures",
    "light_analysis": {
      "overview": "论文提出了RAM框架，通过模拟人类阅读行为自适应压缩上下文，以解决大语言模型在长上下文场景中的计算效率低下和冗余信息问题，提升性能和效率。",
      "motivation": "大语言模型（LLMs）在长上下文应用中面临计算效率低下和冗余信息的挑战，这限制了其部署潜力，因为现有方法往往无法有效区分信息重要性，导致资源浪费和性能瓶颈。因此，需要开发新的压缩技术来优化处理长输入时的效率和准确性，以支持实际应用如文档分析和问答系统。",
      "method": "RAM框架采用自适应混合阅读策略，将上下文划分为段落并与输入查询并行编码。高相关性段落完整保留进行精读，而低相关性段落则通过查询指导压缩成紧凑摘要向量。所有段落和摘要向量拼接后输入解码器，确保高性能和自然语言解释性。此外，引入基于正负查询-段落对的对比学习目标来优化精读与略读的决策边界。",
      "result": "实验表明，RAM在多个问答和摘要基准测试中优于现有基线，使用两个骨干模型验证。在平均长度为16K、最大长度为32K的长输入上，实现高达12倍的端到端加速，性能提升显著，验证了框架的有效性和效率优势。",
      "conclusion": "该研究提出了RAM框架，通过模拟人类阅读行为进行上下文压缩，创新性地提升了大语言模型在长上下文处理中的性能和效率。这具有重要学术价值，为上下文管理提供了新方法，并有实际应用潜力，如加速长文档分析。未来工作可进一步探索压缩策略的泛化性和其他任务中的应用。",
      "tags": [
        "Large Language Models",
        "Context Compression",
        "Parallel Encoding",
        "Contrastive Learning",
        "Query-Guided Compression"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:22.174986Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01839",
    "title": "DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis",
    "authors": [
      "Ru Zhang",
      "Xunkai Li",
      "Yaxin Deng",
      "Sicheng Liu",
      "Daohan Su",
      "Qiangqiang Dai",
      "Hongchao Qin",
      "Rong-Hua Li",
      "Guoren Wang",
      "Jia Li"
    ],
    "abstract": "Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models.   To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01839.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01839",
    "published": "2026-02-02T09:10:09Z",
    "updated": "2026-02-02T09:10:09Z",
    "comment": "12 pages, 4 figures",
    "light_analysis": {
      "overview": "DOGMA框架通过整合多级生物先验知识重塑单细胞转录组学数据的结构和语义，显著提升分析性能。",
      "motivation": "在数据为中心的单细胞转录组学分析中，序列方法将细胞视为独立实体，忽略细胞间关系和原始数据质量问题；结构化方法尝试捕捉关系但忽视生物先验知识，导致计算开销大和图形表示不佳，限制了机器学习模型效用。因此，研究旨在解决如何有效整合生物先验知识，以克服现有方法的不足，提高数据表示的准确性和效率，这对于理解复杂生物系统至关重要。",
      "method": "DOGMA采用多级生物先验知识进行数据重塑：结合Statistical Anchors、Cell Ontology和Phylogenetic Trees实现确定性图构建和跨物种对齐，超越随机启发式方法；同时利用Gene Ontology集成功能先验以弥补特征级语义差距。框架核心在于整合生物结构信息，支持单细胞转录组学数据的整体优化，无需依赖复杂模型，而是专注于数据表示层面的创新。",
      "result": "在复杂多物种和多器官基准测试中，DOGMA达到SOTA性能，表现出优越的零样本鲁棒性和样本效率，同时计算成本显著降低。摘要未明确说明具体性能指标数值，但与基线方法相比，DOGMA在保持高性能的同时，减少了计算开销，增强了实用性和可扩展性。",
      "conclusion": "DOGMA的主要贡献是通过生物先验知识优化数据表示，解决了当前单细胞分析中忽视结构和语义的不足，提高了机器学习模型效用。其学术价值在于融合生物先验与数据科学，推动单细胞转录组学领域发展；实践上支持更高效和鲁棒的数据分析，潜在局限性包括对其他生物数据类型的适应性，未来可探索更广泛的应用或算法改进。",
      "tags": [
        "Data-centric AI",
        "Single-cell Transcriptomics",
        "Biological Prior Knowledge",
        "Graph Construction",
        "Cross-species Alignment"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:07.556302Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01838",
    "title": "AXE: Low-Cost Cross-Domain Web Structured Information Extraction",
    "authors": [
      "Abdelrahman Mansour",
      "Khaled W. Alshaer",
      "Moataz Elsaban"
    ],
    "abstract": "Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized \"pruning\" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01838.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01838",
    "published": "2026-02-02T09:09:35Z",
    "updated": "2026-02-02T09:09:35Z",
    "comment": null,
    "light_analysis": {
      "overview": "AXE是一种通过HTML DOM修剪和GXR机制实现低成本、高准确度的网页结构化信息提取的管道。",
      "motivation": "网页结构化信息提取面临手动启发式规则易碎和大语言模型成本高昂的权衡问题。现有方法如手工规则不稳定且维护困难，而大型模型则成本过高，难以大规模部署，限制了跨领域应用的可行性和效率。因此，需要开发一种既经济又可靠的解决方案来平衡这两者，以便在真实场景中实现高效、低成本的信息提取。",
      "method": "AXE管道将HTML DOM视为需要修剪的树而非纯文本，采用专门“修剪”机制去除模板和无关节点，生成高密度上下文，使得小型0.6B参数语言模型能生成精确的结构化输出。关键创新包括Grounded XPath Resolution（GXR），确保每个提取都物理映射到源节点，提高可追溯性和可靠性。在SWDE数据集上进行实验，模型架构专注于高效处理，结合XPath技术优化跨领域适应。",
      "result": "在SWDE数据集上，AXE以88.1%的F1分数实现了state-of-the-art的zero-shot性能，超越了多个更大规模的完全训练替代方法。实验对比表明AXE在保持低成本的同时，能在多个领域任务中达到或超过高成本模型的准确性，突显了其高效性和实用性，并为大规模部署提供了数据支持。",
      "conclusion": "AXE的主要贡献在于提出了一种基于DOM修剪和GXR的低成本网页信息提取方法，显著减少对计算资源的需求。学术上创新了网页数据处理方式，应用上通过发布专门适配器，为大规模提取提供了经济有效的路径。未来工作可能包括扩展到更多复杂网页结构和数据集，进一步优化修剪机制和跨领域泛化能力。",
      "tags": [
        "Web Information Extraction",
        "DOM Pruning",
        "Grounded XPath Resolution",
        "Small Language Model",
        "Zero-shot Learning"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:16.679272Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01836",
    "title": "Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery",
    "authors": [
      "Yin Wu",
      "Daniel Slieter",
      "Carl Esselborn",
      "Ahmed Abouelazm",
      "Tsung Yuan Tseng",
      "J. Marius Zöllner"
    ],
    "abstract": "Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01836.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01836",
    "published": "2026-02-02T09:09:07Z",
    "updated": "2026-02-02T09:09:07Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出一种基于街景图像引导的高效跨国家数据采集策略，用于ADAS部署，以应对域偏移问题并降低成本。",
      "motivation": "部署高级驾驶辅助系统（ADAS）和自动驾驶系统（ADS）在不同国家面临挑战，因为立法、交通基础设施和视觉惯例差异导致域偏移，显著降低感知模型性能。传统跨国家数据收集依赖广泛实地路测，成本高昂且效率低下，难以覆盖所有代表性场景。为解决这一问题，研究旨在利用公开可用的街景图像资源，开发更经济高效的数据采集方法，以支持模型适应和部署。",
      "method": "论文提出街景引导的数据采集策略，通过分析公共街景图像识别兴趣点（POI）。引入两种POI评分方法：一是基于KNN特征距离的方法，使用视觉基础模型提取图像特征；二是视觉归因方法，利用视觉语言模型进行内容分析。为可重复评估，采用收集-检测协议，并构建共定位数据集，将Zenseact Open Dataset与Mapillary街景图像配对，确保数据一致性和标准化测试。",
      "result": "在交通标志检测任务上进行实验，该任务对跨国家标志外观变化敏感。结果显示，使用所提方法采集的一半目标域数据即可达到与随机采样全部数据相当的检测性能。进一步提供成本估计，表明大规模处理街景图像在经济上可行，为全国范围分析提供了实际依据，支持该策略的广泛应用潜力。",
      "conclusion": "该研究证明了街景引导数据采集在跨国家ADAS模型适应中的高效性和成本效益，通过利用公共图像资源显著降低数据收集成本。主要贡献是提出了基于街景图像的新策略，为全球部署提供实用解决方案，具有重要的学术和应用价值。未来工作可扩展至其他感知任务或更多国家，进一步提升方法的泛化性和实用性。",
      "tags": [
        "Street-View Imagery",
        "KNN",
        "Vision-Language Model",
        "Traffic Sign Detection",
        "Domain Shift"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:48.155106Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01832",
    "title": "Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs",
    "authors": [
      "Rui Wang",
      "Yaoguang Cao",
      "Yuyi Chen",
      "Jianyi Xu",
      "Zhuoyang Li",
      "Jiachen Shang",
      "Shichun Yang"
    ],
    "abstract": "Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01832.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01832",
    "published": "2026-02-02T09:06:11Z",
    "updated": "2026-02-02T09:06:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种从视觉输入合成触觉数据的跨模态框架，以增强自主车辆的安全性。",
      "motivation": "自主车辆（AVs）依赖多模态融合来确保安全，但当前视觉和光学传感器无法检测道路引起的触觉激励，如振动和冲击，这对车辆的动态控制至关重要。现有传感器侧重于环境感知，而忽略了触觉数据，导致感知不全面，可能引发安全隐患。因此，研究如何从视觉输入中合成触觉数据变得尤为重要，以弥补现有方法的不足，提升AV的鲁棒性和安全性能，特别是在复杂道路条件下。",
      "method": "论文提出Synesthesia of Vehicles（SoV）框架，主要包括两个核心部分：首先，开发了一种跨模态时空对齐方法，用于解决视觉和触觉数据在时间和空间上的差异，确保数据的同步和对应；其次，设计了一个视觉-触觉联觉（VTSyn）生成模型，基于潜在扩散技术，能够在无监督条件下实现高质量触觉数据合成。模型使用从真实车辆感知系统收集的多模态数据集，涵盖不同道路和光照条件，以增强泛化能力，无需依赖人工标注。",
      "result": "通过大量实验验证，VTSyn模型在时间一致性、频率分析准确性和分类性能方面均优于现有方法。例如，在触觉数据合成任务中，VTSyn表现出更好的预测和生成质量，但与具体基线模型的对比细节如准确率提升百分比等，摘要未明确说明。实验结果表明，该模型能够有效合成触觉数据，增强自主车辆的主动感知能力，从而改善安全性能，展示出其在多模态融合中的潜力。",
      "conclusion": "本研究的核心贡献是提出了一个创新的跨模态框架，使得自主车辆能够从视觉输入中合成触觉数据，解决了现有传感器在触觉感知上的缺陷。这推动了多模态感知技术的发展，并引入了联觉启发的建模方法，具有重要的学术价值。在实际应用中，该方法有望提升AV的动态控制安全性和鲁棒性。然而，摘要未明确说明研究的局限性或未来工作方向，可能需要进一步探索数据泛化、实时性等挑战。",
      "tags": [
        "Latent Diffusion",
        "Generative Model",
        "Cross-modal Alignment",
        "Autonomous Vehicles",
        "Tactile Perception"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:30.093933Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01828",
    "title": "Hyperbolic Graph Neural Networks Under the Microscope: The Role of Geometry-Task Alignment",
    "authors": [
      "Dionisia Naddeo",
      "Jonas Linkerhägner",
      "Nicola Toschi",
      "Geri Skenderi",
      "Veronica Lachi"
    ],
    "abstract": "Many complex networks exhibit hyperbolic structural properties, making hyperbolic space a natural candidate for representing hierarchical and tree-like graphs with low distortion. Based on this observation, Hyperbolic Graph Neural Networks (HGNNs) have been widely adopted as a principled choice for representation learning on tree-like graphs. In this work, we question this paradigm by proposing an additional condition of geometry-task alignment, i.e., whether the metric structure of the target follows that of the input graph. We theoretically and empirically demonstrate the capability of HGNNs to recover low-distortion representations on two synthetic regression problems, and show that their geometric inductive bias becomes helpful when the problem requires preserving metric structure. Additionally, we evaluate HGNNs on the tasks of link prediction and node classification by jointly analyzing predictive performance and embedding distortion, revealing that only link prediction is geometry-aligned. Overall, our findings shift the focus from only asking \"Is the graph hyperbolic?\" to also questioning \"Is the task aligned with hyperbolic geometry?\", showing that HGNNs consistently outperform Euclidean models under such alignment, while their advantage vanishes otherwise.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01828.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01828",
    "published": "2026-02-02T09:01:58Z",
    "updated": "2026-02-02T09:01:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了几何任务对齐的概念，质疑双曲线图神经网络仅在双曲图上的固有优势，强调任务对齐对模型性能的关键影响。",
      "motivation": "当前双曲线图神经网络（HGNNs）广泛用于类树图的表示学习，但其有效性可能被过度依赖图的双曲结构，而忽略了任务本身是否与几何对齐。本研究旨在解决这一问题，提出几何任务对齐条件，以弥补现有方法在任务特定性上的不足，强调不仅要评估图的结构，还需考虑任务需求，从而提高模型选择的准确性。",
      "method": "论文引入几何任务对齐条件，通过理论分析和实证研究评估HGNNs。关键创新包括设计两个合成回归问题来验证HGNNs恢复低失真表示的能力，并在链接预测和节点分类任务中联合分析预测性能和嵌入失真，以确定任务是否与双曲几何对齐，使用实证方法展示几何归纳偏置的作用。",
      "result": "实验表明，当任务需要保留度量结构时，HGNNs能有效恢复低失真表示；链接预测被证明是几何对齐的，因此HGNNs持续优于欧几里得模型，而节点分类任务并非对齐，导致优势消失。具体数据摘要未明确说明，但通过理论验证和对比较性能指标，揭示了任务对齐对模型优势的决定性作用。",
      "conclusion": "论文的主要贡献是强调任务与几何对齐的重要性，将研究焦点从图结构扩展到任务特性，为HGNNs应用提供更精确的指导。学术价值在于深化了对几何建模的理解，实际应用有助于优化模型选择；未来可扩展至更多任务类型的对齐分析，但局限性如具体数据细节未在摘要中说明。",
      "tags": [
        "Hyperbolic Graph Neural Networks",
        "Geometry-Task Alignment",
        "Link Prediction",
        "Node Classification",
        "Synthetic Regression"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:17.399128Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01826",
    "title": "Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It",
    "authors": [
      "Yaxiang Zhang",
      "Yingru Li",
      "Jiacai Liu",
      "Jiawei Xu",
      "Ziniu Li",
      "Qian Liu",
      "Haoyuan Li"
    ],
    "abstract": "Reinforcement Learning (RL) for training Large Language Models is notoriously unstable. While recent studies attribute this to \"training inference mismatch stemming\" from inconsistent hybrid engines, standard remedies, such as Importance Sampling, might fail during extended training runs. In this work, we analyze this instability through the lens of optimization, demonstrating that gradient noise and training-inference mismatch escalate in tandem as training progresses. Meanwhile, we find that the mismatch can be effectively suppressed by shrinking the update size. Taken together, we deduce that the mismatch is not merely a static numerical discrepancy, but a dynamic failure coupled with the model's optimization. Based on this insight, we propose a simple yet effective solution: a specialized Learning Rate (LR) scheduler. Instead of pre-defined decay schedule in traditional LR scheduler, our method dynamically triggers LR decay based on response length, which we identify as a reliable early-warning signal for impending instability. Empirical evidence suggests that by reducing the learning rate as gradient noise rises, we can consistently stabilize RL training and keep the training-inference mismatch at a safe level.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01826.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01826",
    "published": "2026-02-02T09:00:53Z",
    "updated": "2026-02-02T09:00:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出一种基于响应长度的动态学习率调度器，解决强化学习训练大型语言模型中的不稳定性问题。",
      "motivation": "强化学习训练大型语言模型普遍存在不稳定性，影响模型性能和可靠性。现有研究将此归因于训练与推理阶段的不匹配，标准补救方法如重要性采样在长期训练中可能失效。这一问题的重要性在于，不稳定的训练会降低模型效果和效率，阻碍实际应用。现有方法的不足在于它们未能从优化角度动态处理不匹配，导致梯度噪声随训练进展加剧，从而影响训练稳定性。",
      "method": "论文从优化视角分析训练不稳定性，揭示梯度噪声与训练推理不匹配之间存在动态耦合关系。核心方法是提出一种专用学习率调度器，该调度器基于响应长度动态触发学习率衰减，而不是依赖传统的预定义衰减方案。响应长度被识别为即将发生不稳定的可靠预警信号，这使得调度器能自适应地调整更新规模，有效抑制不匹配。创新点在于将不匹配问题转化为优化动态，并通过简单机制实现稳定化。",
      "result": "经验证据表明，通过学习率调度器在梯度噪声上升时降低学习率，能有效稳定强化学习训练过程，并将训练推理不匹配保持在安全水平。该方法能一致地改善训练稳定性，但摘要未明确说明与基线方法的具体对比数据，如准确率或效率的量化提升。然而，论文强调该解决方案能动态响应不稳定信号，确保训练进展顺利。",
      "conclusion": "本研究的主要贡献在于揭示训练推理不匹配是一个与优化过程耦合的动态问题，并提出一个简单有效的学习率调度解决方案。学术价值在于为强化学习训练大型语言模型提供了新的稳定化策略，丰富了优化理论。实际应用价值在于提升模型训练效率和可靠性，减少训练失败风险。潜在局限性或未来工作可能包括探索更多预警信号或将该方法扩展到其他机器学习领域。",
      "tags": [
        "Reinforcement Learning",
        "Large Language Models",
        "Learning Rate Scheduling",
        "Optimization",
        "Gradient Noise"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:29.689266Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01816",
    "title": "Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies",
    "authors": [
      "Wenjin Hou",
      "Wei Liu",
      "Han Hu",
      "Xiaoxiao Sun",
      "Serena Yeung-Levy",
      "Hehe Fan"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01816.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01816",
    "published": "2026-02-02T08:48:03Z",
    "updated": "2026-02-02T08:48:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出VIA-Bench基准，用于系统评估多模态大语言模型在视觉错觉和异常场景下的鲁棒性，揭示了模型在这些挑战性情况下的显著弱点。",
      "motivation": "多模态大语言模型在通用视觉-语言基准上已达到或超越人类水平，但现有评估主要依赖于标准分布内数据，忽视了模型在面对视觉错觉和异常等违背常识先验场景时的鲁棒性。这种缺陷限制了我们对模型真实感知能力的理解，因为这些场景挑战了基本认知，而现有方法对此缺乏系统性考察。因此，开发一个专门基准来填补这一空白，对推动人工通用智能的发展至关重要，因为鲁棒性是实现更高级人工智能的关键环节。",
      "method": "本研究引入了VIA-Bench基准，该基准包含六个核心类别：颜色错觉、运动错觉、格式塔错觉、几何和空间错觉、一般视觉错觉和视觉异常。通过人类在环审查过程，构建了超过1000个高质量问答对，这些对需要细致的视觉推理。在技术路线上，作者评估了超过20个最先进的MLLMs，包括专有模型、开源模型以及推理增强模型（如使用Chain-of-Thought推理的模型），以全面测试模型在非标准场景下的表现。该方法的关键创新点在于系统性构建挑战性数据，直接针对模型感知能力的瓶颈。",
      "result": "评估结果表明，超过20个MLLMs在VIA-Bench基准上表现出显著脆弱性，模型在面对视觉错觉和异常时逻辑容易崩溃。特别地，Chain-of-Thought推理方法提供的鲁棒性微不足道，常导致“脆弱的幻象”，即模型在错觉刺激下推理失败。与标准基准上的高性能相比，模型在这些非标准场景下的表现大幅下降，揭示了其感知能力与人类之间的根本差异。摘要未明确说明具体性能指标如准确率，但强调了大范围评估下模型的普遍弱点。",
      "conclusion": "本研究的主要贡献是引入VIA-Bench基准，系统性地评估了MLLMs在视觉错觉和异常上的鲁棒性，揭示了模型在这些挑战性场景中的局限性。研究发现，即使先进的推理技术如CoT也无法有效应对错觉，表明机器与人类感知存在根本分歧。这一成果对学术价值在于填补了鲁棒性评估的空白，对实际应用则强调了解决感知瓶颈对于人工通用智能发展的重要性。未来工作可基于发布的基准数据和代码，进一步探索模型改进和更广泛的鲁棒性测试。",
      "tags": [
        "Multimodal Large Language Models",
        "Visual Illusions",
        "Benchmark Evaluation",
        "Chain-of-Thought Reasoning",
        "Visual Anomalies"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:44.767107Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01815",
    "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery",
    "authors": [
      "Yunhui Jang",
      "Seonghyun Park",
      "Jaehyung Kim",
      "Sungsoo Ahn"
    ],
    "abstract": "Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01815.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01815",
    "published": "2026-02-02T08:47:36Z",
    "updated": "2026-02-02T08:47:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "INDIBATOR是一个用于分子发现的多代理辩论框架，通过细粒度个体科学家档案提升代理性能，解决了现有方法简化科学家个体特异性的问题。",
      "motivation": "多代理系统在自动化科学发现中发挥着关键作用，但现有区分代理行为的方法通常使用通用角色（如'审稿人'或'作者'）或基于关键词的粗略人物设定。这简化了人类科学家基于独特研究轨迹的操作方式，无法准确模拟个体背景对科学贡献的影响。因此，问题在于需要开发更精确的方法来捕捉代理的个体特异性，以提升系统性能和真实性，避免过度简化导致的性能瓶颈。",
      "method": "INDIBATOR框架通过构建个体科学家档案来实现代理个性化，档案基于两种模态：出版历史提供文献知识，分子历史提供结构先验。关键创新点在于使用细粒度个体档案而非粗略角色，代理在多轮辩论中通过提议、批判和投票阶段交互，确保多样性且基于事实的讨论。该方法结合知识图谱和多代理辩论机制，具体细节包括从科学数据库中提取数据创建档案，并集成到分子发现任务中。",
      "result": "评估结果显示，基于细粒度个体档案的代理 consistently outperform 依赖粗粒度人物设定的系统，达到竞争性或最先进性能。摘要未明确说明具体数据（如准确率提升），但与基线方法对比表明性能显著改进。这验证了个性化代理在提升分子发现效率和质量方面的有效性，推断可能在高通量实验中实现了更高的成功率或更优的分子结构预测。",
      "conclusion": "该研究的主要贡献在于提出了一个创新的多代理辩论框架，强调捕捉代理的'科学DNA'对高质量发现的重要性。学术上，它为多代理系统设计提供了新视角；实际应用上，推动了自动化科学发现的进展。局限性或未来方向摘要未明确说明，但可推断潜在应用包括扩展到其他科学领域或集成更多数据类型。",
      "tags": [
        "Multi-Agent Systems",
        "Molecular Discovery",
        "Individuality Modeling",
        "Scientific Debate",
        "Agent Profiling"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:06.860409Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01814",
    "title": "GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation",
    "authors": [
      "Xiao Liang",
      "Yunzhu Zhang",
      "Linchao Zhu"
    ],
    "abstract": "Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01814.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01814",
    "published": "2026-02-02T08:47:33Z",
    "updated": "2026-02-02T08:47:33Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了GPD框架，通过指导渐进蒸馏技术，在加速扩散模型采样过程的同时，保持了高质量的视频生成。",
      "motivation": "扩散模型在视频生成领域取得了显著成就，但其去噪过程的高计算成本成为主要瓶颈。现有方法尝试减少扩散步骤，但在视频生成中常导致严重的质量退化，限制了实时应用的可能性。因此，本研究旨在解决效率与质量的权衡问题，开发一种既能显著加速生成过程，又能确保视觉细节和时间连贯性的框架，以推动视频编辑、虚拟现实等实际场景的发展。",
      "method": "GPD框架采用渐进蒸馏策略，由教师模型逐步指导学生模型使用更大的去噪步长，以加速扩散过程。关键创新包括：引入在线生成的训练目标，降低优化难度并提高计算效率；以及结合潜在空间中的频域约束，促进细粒度细节和时间动态的有效保留。该方法具体应用于Wan2.1模型架构，通过蒸馏训练实现高效的视频生成管道。",
      "result": "实验结果显示，GPD将Wan2.1模型的采样步骤从48步大幅减少至仅6步，显著提升了生成速度。在VBench评估中，生成的视频质量保持竞争性，没有明显下降。与现有蒸馏方法相比，GPD在管道简单性和质量保留方面表现出优势，有效平衡了加速与性能，为高效视频生成提供了实证支持。",
      "conclusion": "GPD框架通过整合渐进蒸馏和频域约束，成功解决了扩散模型加速时的质量下降问题，贡献了一种高效视频生成方案。学术上，它引入了创新的训练策略和约束机制；实际应用中，降低了计算开销，促进了实时视频生成的可行性。未来工作可探索该框架在其他模型或更复杂场景中的泛化能力和优化方向。",
      "tags": [
        "Diffusion Models",
        "Progressive Distillation",
        "Video Generation",
        "Frequency-Domain Constraints"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:32.190372Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01812",
    "title": "LDRNet: Large Deformation Registration Model for Chest CT Registration",
    "authors": [
      "Cheng Wang",
      "Qiyu Gao",
      "Fandong Zhang",
      "Shu Zhang",
      "Yizhou Yu"
    ],
    "abstract": "Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01812.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01812",
    "published": "2026-02-02T08:44:53Z",
    "updated": "2026-02-02T08:44:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "LDRNet通过粗到细细化策略和刚性学习块，实现了胸部CT大变形图像的快速无监督配准。",
      "motivation": "大多数基于深度学习的医学图像配准算法专注于脑部图像，而胸部CT配准面临更大的变形、复杂背景和区域重叠等挑战，这些挑战使得现有方法在处理胸部CT图像时效果有限。该问题在临床应用中至关重要，如肿瘤跟踪和治疗规划，但当前方法因变形程度和复杂性不足，亟需专门解决方案来提升配准准确性和效率。",
      "method": "LDRNet是一种快速无监督深度学习方法，首先预测粗分辨率配准场，然后采用从粗到细的细化策略逐步优化。创新技术组件包括：细化块用于在不同分辨率下细化配准场，刚性块用于从高层特征学习刚性变换矩阵以处理大变形。模型在私有数据集和公开数据集SegTHOR上进行训练和评估，基于深度学习架构实现图像配准任务。",
      "result": "在私有数据集和SegTHOR数据集上的实验表明，LDRNet在大变形图像配准中达到了最先进的性能。与传统配准方法以及深度学习模型VoxelMorph、RCN和LapIRN相比，LDRNet在准确性和速度上均有显著提升，实现了高效配准，但具体性能指标如准确率或时间节省百分比摘要未明确说明。",
      "conclusion": "LDRNet的主要贡献是提出了一种针对胸部CT大变形配准的快速无监督深度学习方法，通过创新组件提高了配准精度和效率。这项研究扩展了深度学习在医学图像配准领域的应用，具有重要的学术价值，并有望改善临床图像对齐，支持疾病诊断和治疗监测。未来工作可能包括模型进一步优化或扩展到其他医学图像模态，但摘要未明确说明具体局限性。",
      "tags": [
        "Large Deformation Registration",
        "Chest CT",
        "Unsupervised Learning",
        "Coarse-to-Fine Refinement",
        "Feature Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:01.969046Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01807",
    "title": "Sentence Curve Language Models",
    "authors": [
      "DongNyeong Heo",
      "Heelyoul Choi"
    ],
    "abstract": "Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01807.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01807",
    "published": "2026-02-02T08:40:53Z",
    "updated": "2026-02-02T08:40:53Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了句子曲线语言模型（SCLM），通过连续句子曲线表示预测，增强语言模型对全局句子结构的建模能力。",
      "motivation": "研究动机源于现有语言模型（包括扩散基语言模型，DLMs）在预测目标句子时依赖静态词嵌入的局限性。这种表示对邻近词不敏感，鼓励模型优先考虑局部词预测的准确性，而忽视了句子整体结构的建模。全局结构对于需要理解上下文的任务至关重要，现有方法在这方面的不足限制了模型性能，特别是在翻译等任务中。因此，本研究旨在解决静态嵌入的缺点，通过更动态的表示来捕获句子级全局信息。",
      "method": "研究方法引入了句子曲线表示，定义为样条曲线，其控制点可以同时影响句子中的多个单词，从而提供连续的句子编码。基于此，作者提出了句子曲线语言模型（SCLM），它扩展了扩散基语言模型（DLMs），将目标从预测静态词嵌入改为预测这些句子曲线。关键创新点在于通过曲线预测实现正则化效应，促进对句子全局结构的建模，并理论分析了不同曲线类型（如样条曲线）如何影响模型行为。技术细节包括利用现有扩散模型框架进行预测。",
      "result": "实验结果在IWSLT14和WMT14翻译数据集上，SCLM达到了扩散基语言模型（DLMs）中的最先进性能（SOTA），显示了在翻译任务中的显著提升。具体来说，与基线DLMs相比，SCLM在准确率等指标上有所改进，但摘要未提供具体数值。此外，模型训练过程稳定，无需依赖繁琐的知识蒸馏技术。在LM1B数据集上，SCLM与离散DLMs相比显示出潜力，表明其在通用语言建模中的优势，但摘要未说明具体对比数据。",
      "conclusion": "结论总结了SCLM的主要贡献是通过句子曲线预测解决了静态词嵌入在全局结构建模上的局限性，提高了语言模型的性能。研究具有学术价值，为连续句子表示提供了新思路，并促进了扩散模型在语言任务中的应用。在实际应用中，例如机器翻译，SCLM表现优异，显示了推广潜力。局限性可能包括对曲线类型选择的依赖，未来工作可探索更多表示变体或应用于其他自然语言处理任务，如文本生成。",
      "tags": [
        "Sentence Curve Representation",
        "Diffusion-based Language Models",
        "Spline Curves",
        "Global Structure Modeling",
        "Language Models"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:27.543384Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01805",
    "title": "FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing",
    "authors": [
      "Menglin Han",
      "Zhangkai Ni"
    ],
    "abstract": "Training-free image editing has attracted increasing attention for its efficiency and independence from training data. However, existing approaches predominantly rely on inversion-reconstruction trajectories, which impose an inherent trade-off: longer trajectories accumulate errors and compromise fidelity, while shorter ones fail to ensure sufficient alignment with the edit prompt. Previous attempts to address this issue typically employ backbone-specific feature manipulations, limiting general applicability. To address these challenges, we propose FlowBypass, a novel and analytical framework grounded in Rectified Flow that constructs a bypass directly connecting inversion and reconstruction trajectories, thereby mitigating error accumulation without relying on feature manipulations. We provide a formal derivation of two trajectories, from which we obtain an approximate bypass formulation and its numerical solution, enabling seamless trajectory transitions. Extensive experiments demonstrate that FlowBypass consistently outperforms state-of-the-art image editing methods, achieving stronger prompt alignment while preserving high-fidelity details in irrelevant regions.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01805.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01805",
    "published": "2026-02-02T08:37:00Z",
    "updated": "2026-02-02T08:37:00Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出FlowBypass框架，基于Rectified Flow构建bypass直接连接反转与重建轨迹，解决训练自由图像编辑中的轨迹权衡问题。",
      "motivation": "训练自由图像编辑因其高效和独立于训练数据而受到广泛关注，但现有方法主要依赖inversion-reconstruction trajectories，导致固有权衡：长轨迹会累积错误损害保真度，而短轨迹无法确保与编辑提示充分对齐。先前方法通常采用backbone-specific feature manipulations，这限制了其通用性。为解决这些问题，本研究旨在开发一种无需特征操纵的通用方法，以提升图像编辑的质量和灵活性。",
      "method": "FlowBypass是一种基于Rectified Flow的解析框架，通过正式推导反转和重建轨迹，构建一个直接连接这些轨迹的bypass。关键创新在于提供近似bypass公式及其数值解，实现轨迹无缝过渡，避免了依赖特征操纵的局限性。该方法利用Rectified Flow理论，专注于优化轨迹路径，适用于多种图像编辑场景，提升编辑过程的效率和通用性。",
      "result": "广泛实验表明，FlowBypass consistently优于state-of-the-art图像编辑方法。它在增强prompt对齐的同时，能有效保持无关区域的高保真度细节。与现有基线相比，FlowBypass减少了错误累积，提升了编辑精度和可靠性，摘要未明确具体数值指标但强调了性能优势。",
      "conclusion": "论文主要贡献是提出FlowBypass框架，解决了训练自由图像编辑中的轨迹权衡问题。其学术价值在于为图像生成领域提供了新理论视角，实际应用价值在于实现高效、高质量的图像编辑。未来工作可探索扩展至更多编辑任务和优化细节，摘要未明确说明具体局限性。",
      "tags": [
        "Rectified Flow",
        "Training-Free Image Editing",
        "Trajectory Bypass",
        "Image Synthesis"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:29.339465Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01801",
    "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
    "authors": [
      "Dvir Samuel",
      "Issar Tzachor",
      "Matan Levy",
      "Micahel Green",
      "Gal Chechik",
      "Rami Ben-Ari"
    ],
    "abstract": "Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01801.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01801",
    "published": "2026-02-02T08:31:21Z",
    "updated": "2026-02-02T08:31:21Z",
    "comment": "Project Page: https://dvirsamuel.github.io/fast-auto-regressive-video/",
    "light_analysis": {
      "overview": "本文提出一种统一的无需训练注意力框架，通过临时缓存压缩和稀疏注意力显著提升自回归视频扩散模型的推理速度和效率。",
      "motivation": "自回归视频扩散模型在生成长序列视频时面临关键瓶颈：注意力层的KV缓存随生成时间线性增长，导致推理延迟增加和GPU内存使用上升，这限制了模型利用时间上下文和保持长范围一致性的能力。现有方法在长时间生成过程中会逐渐减慢并消耗更多内存，严重影响了模型在流式生成、视频世界模型等实际应用中的可行性，因此急需解决这一效率问题以提高实用性。",
      "method": "论文提出一个训练免费的注意力框架，包含三个核心模块：TempCache通过分析帧间时间对应关系压缩KV缓存，以限制其线性增长；AnnCA利用快速近似最近邻匹配从长提示中选择与当前帧相关的token，加速交叉注意力计算；AnnSA则通过限制每个查询只关注语义上匹配的键，使用轻量级ANN实现自注意力的稀疏化。这些模块基于冗余分析（如跨帧近似重复键和缓慢演化查询），可直接集成到现有自回归扩散主干和世界模型中，无需额外训练。",
      "result": "实验结果显示，该框架实现了端到端速度提升达5-10倍，同时视觉质量与原始模型保持接近相同。关键优势在于长序列生成中，模型维持稳定的吞吐量和几乎恒定的峰值GPU内存使用，而基线方法随生成时间延长会逐渐减慢并增加内存消耗。这表明了该方法在优化计算和内存效率方面的有效性，且不牺牲输出质量。",
      "conclusion": "本研究通过设计高效的注意力优化模块，成功解决了自回归视频扩散模型的推理瓶颈，提升了模型在长序列任务中的实用性和可扩展性。其贡献在于提供了一种兼容现有模型的训练免费解决方案，为视频世界模型和交互应用奠定了基础。未来工作可能包括进一步扩展该方法到其他生成任务或优化ANN匹配的效率，摘要未明确说明具体方向。",
      "tags": [
        "Autoregressive Video Diffusion",
        "KV Cache Compression",
        "Approximate Nearest Neighbor",
        "Sparse Attention",
        "Attention Mechanisms"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:46.639272Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01799",
    "title": "Spatio-Temporal Transformers for Long-Term NDVI Forecasting",
    "authors": [
      "Ido Faran",
      "Nathan S. Netanyahu",
      "Maxim Shoshany"
    ],
    "abstract": "Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01799.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01799",
    "published": "2026-02-02T08:29:45Z",
    "updated": "2026-02-02T08:29:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出STT-LTF框架，结合空间和时间Transformer建模，用于长期NDVI预测，克服异质地貌分析的挑战。",
      "motivation": "长期卫星图像时间序列分析在地中海异质地貌中面临复杂空间模式、季节变化和多年代环境变化的交互问题，传统方法如纯时间分析难以整合空间上下文和长期依赖，导致预测精度不足。STT-LTF旨在解决这一重要问题，因现有方法在处理异质性和不规则采样时效果有限，影响生态监测和气候研究。",
      "method": "STT-LTF框架使用统一的Transformer架构，处理多尺度空间块和长达20年的时间序列，捕捉局部空间关系和区域气候影响。创新点包括自监督学习策略：空间掩码、时间掩码和地平线采样，以及直接预测任意未来时间点以避免误差累积。关键细节涵盖空间块嵌入、循环时间编码和地理坐标集成，训练基于40年未标记Landsat图像（1984-2024）。",
      "result": "在Landsat数据集上的实验显示，STT-LTF在次年预测中达到平均绝对误差（MAE）0.0328和R^2分数0.8412，优于传统统计方法、基于CNN的方法、LSTM网络和标准Transformer基线。该框架能有效处理不规则时间采样和可变预测范围，适用于快速生态过渡区域的异质地貌分析。",
      "conclusion": "STT-LTF的主要贡献是提供了一种准确预测长期NDVI的框架，增强了空间和时间建模的集成能力。其学术价值在于推进卫星图像分析技术，实际应用价值在于支持生态监测和气候预测。摘要未明确说明局限性或未来工作，但可推断未来方向可能包括扩展到其他数据类型或进一步优化预测范围。",
      "tags": [
        "Spatio-Temporal Transformer",
        "Self-Supervised Learning",
        "NDVI Forecasting",
        "Landsat Data",
        "Transformer"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:37.683740Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01797",
    "title": "ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing",
    "authors": [
      "Hanlin Zhou",
      "Huah Yong Chan"
    ],
    "abstract": "Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01797.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01797",
    "published": "2026-02-02T08:27:58Z",
    "updated": "2026-02-02T08:27:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "ORCH提出一个确定性的多代理协调框架，用于离散选择推理，通过多分析和一决策范式提高可解释性和性能。",
      "motivation": "多代理架构在LLM推理任务中日益重要，但现有系统依赖随机路由或启发式方法，导致行为难以复制、决策过程难以解释。这限制了系统的可信度和实际部署价值，尤其是在需要可控性和可解释性的场景中。ORCH旨在解决这一不足，提供确定性和可预测性框架，弥补现有方法的缺陷。",
      "method": "ORCH采用“多分析，一决策”范式，使用固定规则协调异构LLM代理：每个基础模型独立生成结构化分析，一个专门合并代理输出最终选择。关键创新包括确定性的任务分解和答案聚合规则，以及可选的EMA-guided路由器，该路由器基于历史准确性、延迟或成本动态更新代理选择，主要用于评估和延迟反馈设置。框架无需训练，保持简单和可重现性。",
      "result": "在MMLU、MMLU-Pro和GSM8K数据集上的实验表明，ORCH持续优于单模型基线和多数投票集成。具体来说，在MMLU-Pro上精度提升超过10个百分点，在GSM8K上超过50个百分点，McNemar测试证实了统计显著性。EMA路由器提供额外0.7至2.0个百分点的精度提升，消融实验显示多代理协作和路由都贡献显著。",
      "conclusion": "ORCH为基于LLM的代理系统提供了一个可控、可解释和部署就绪的框架，显著改善了离散选择推理的确定性和性能。其学术价值在于推动多代理系统的标准化和可解释性研究，实际应用潜力涵盖教育、决策支持等领域。摘要未明确说明未来方向，但可能涉及扩展至更复杂推理任务或优化路由策略。",
      "tags": [
        "Large Language Model",
        "Multi-agent System",
        "Deterministic Routing",
        "EMA-guided Routing",
        "Discrete-choice Reasoning"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:37.207002Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01791",
    "title": "Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning",
    "authors": [
      "Zheng Zhang",
      "Ao Lu",
      "Yuanhao Zeng",
      "Ziwei Shan",
      "Jinjin Guo",
      "Lufei Li",
      "Yexin Li",
      "Kan Ren"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has catalyzed significant breakthroughs in complex LLM reasoning within verifiable domains, such as mathematics and programming. Recent efforts have sought to extend this paradigm to open-ended tasks by employing LLMs-as-a-Judge to provide sequence-level rewards for policy optimization. However, these rewards are inherently sparse, failing to provide the fine-grained supervision necessary for generating complex, long-form trajectories. Furthermore, current work treats the Judge as a black-box oracle, discarding the rich intermediate feedback signals encoded in it. To address these limitations, we introduce Grad2Reward, a novel framework that extracts dense process rewards directly from the Judge's model inference process via a single backward pass. By leveraging gradient-based attribution, Grad2Reward enables precise token-level credit assignment, substantially enhancing training efficiency and reasoning quality. Additionally, Grad2Reward introduces a self-judging mechanism, allowing the policy to improve through its own evaluative signals without training specialized reward models or reliance on superior external Judges. The experiments demonstrate that policies optimized with Grad2Reward achieve outstanding performance across diverse open-ended tasks, affirming its effectiveness and broad generalizability.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01791.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01791",
    "published": "2026-02-02T08:13:13Z",
    "updated": "2026-02-02T08:13:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "Grad2Reward是一个创新框架，通过梯度归因从Judge模型推理中提取密集过程奖励，以解决稀疏奖励问题并提升开放式LLM推理的效率和质量。",
      "motivation": "强化学习在可验证领域（如数学和编程）取得了突破，但扩展到开放式任务时，现有方法采用LLM作为Judge提供序列级奖励，这些奖励稀疏且无法为复杂长序列生成提供细粒度监督。同时，将Judge视为黑盒忽略了模型中丰富的中间反馈信号，导致训练效率低下和推理质量受限。因此，需要一种方法从Judge中提取更密集的奖励信号来改善开放式任务的强化学习训练。",
      "method": "Grad2Reward框架通过单一后向传递直接从Judge的模型推理过程中提取密集过程奖励。其核心创新是使用梯度基于的归因方法，实现精确的标记级信用分配，为策略优化提供细粒度监督。此外，引入自我判断机制，使策略能够通过自身的评估信号进行改进，无需训练专门奖励模型或依赖外部优质Judge。摘要未明确说明具体使用的数据集或模型架构，但强调了方法的技术特色。",
      "result": "实验结果显示，使用Grad2Reward优化的策略在多种开放式任务中表现优异，证实了其有效性和广泛泛化能力。该方法显著提高了训练效率和推理质量，与基线方法相比，解决了稀疏奖励导致的训练困难问题。摘要未提供具体性能指标如准确率提升，但强调了框架在提升开放式LLM推理中的实际效果。",
      "conclusion": "Grad2Reward的主要贡献是提出了一种从Judge模型中提取密集奖励的新框架，解决了开放式LLM推理中的稀疏奖励挑战。研究具有重要学术价值，为强化学习在开放式任务中的应用提供了新思路，通过梯度归因和self-judging机制减少对外部资源的依赖。未来工作可能包括扩展方法到更广泛任务领域，或进一步优化奖励提取过程。摘要未明确说明局限性，但可推断可能涉及计算成本或泛化性验证。",
      "tags": [
        "Reinforcement Learning with Verifiable Rewards",
        "LLM-as-a-Judge",
        "Gradient Attribution",
        "Self-judging Mechanism",
        "Token-level Credit Assignment"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:26.320853Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01785",
    "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
    "authors": [
      "Yuling Shi",
      "Chaoxiang Xie",
      "Zhensu Sun",
      "Yeheng Chen",
      "Chenxu Zhang",
      "Longfei Yun",
      "Chengcheng Wan",
      "Hongyu Zhang",
      "David Lo",
      "Xiaodong Gu"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.",
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01785.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01785",
    "published": "2026-02-02T08:10:21Z",
    "updated": "2026-02-02T08:10:21Z",
    "comment": "Code and data are available at https://github.com/YerbaPage/CodeOCR",
    "light_analysis": {
      "overview": "本研究首次系统探讨了多模态语言模型在代码理解中的有效性，提出通过图像表示代码以减少计算成本。",
      "motivation": "随着软件系统规模的扩大，计算效率已成为大型语言模型在源代码理解中的关键瓶颈。现有方法将源代码视为线性文本序列，导致上下文长度和计算成本线性增加，难以高效处理大规模代码。图像模态因其可压缩性而具有优势，通过调整分辨率可实现令牌成本的大幅降低，为解决效率问题提供了新途径。",
      "method": "论文提出利用多模态语言模型进行代码理解，核心方法是将源代码转换为渲染图像表示，以利用图像模态的压缩特性。通过调整图像分辨率实现令牌成本缩减，并探索视觉提示如语法高亮对性能的影响。研究进行了系统实验，但摘要未明确说明使用的具体数据集或模型架构细节。",
      "result": "实验表明，多模态语言模型在代码理解中能实现高达8倍的令牌压缩，同时保持有效性。在代码完成任务中，利用视觉提示如语法高亮，在4倍压缩下性能得到改进。克隆检测等任务对视觉压缩表现出强韧性，某些压缩比下甚至略微优于原始文本输入，显示了图像表示的潜力。",
      "conclusion": "本研究首次系统验证了多模态语言模型在代码理解中的有效性，揭示了图像表示代码在减少计算成本方面的潜力。学术上，为代码理解开辟了新范式；实际中，可推动更高效推理系统的开发。未来工作可进一步优化压缩技术和探索多模态模型的局限性。",
      "tags": [
        "Multimodal Language Models",
        "Code Understanding",
        "Image Compression",
        "Vision-Language Models",
        "Token Efficiency"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:20.146883Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01783",
    "title": "Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation",
    "authors": [
      "Dibyayan Patra",
      "Pasindu Ranasinghe",
      "Bikram Banerjee",
      "Simit Raval"
    ],
    "abstract": "Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01783.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01783",
    "published": "2026-02-02T08:09:05Z",
    "updated": "2026-02-02T08:09:05Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出了一种新方法，利用单次过滤策略、循环方向转换和层次聚类技术，自动表征封闭岩石面点云中的结构不连续面。",
      "motivation": "在采矿工程中，结构不连续面的表征对评估岩体稳定性和确保挖掘安全至关重要。尽管无人机和激光扫描技术能高效收集岩石面点云，但开发一个鲁棒且高效的方法来自动表征真实场景（如封闭岩石面）中的不连续面集仍是一个开放研究问题。现有方法在处理噪声和高曲率伪影方面存在局限性，导致在实际应用中不够精确和自动化。",
      "method": "该方法采用三个核心步骤：首先，通过单次过滤策略，利用信号处理技术一次性隔离点云中的平面区域，并抑制噪声和高曲率伪影；其次，创新性地开发循环方向转换方案，将极坐标下的倾角和倾角方向数据转换为笛卡尔空间，以克服传统聚类方法的缺陷；最后，使用层次聚类技术对转换后的方向进行聚类，自动识别不连续面集，无需用户预先指定簇数，并能处理密度分布的变化。",
      "result": "实验验证了该方法的准确性。在真实矿井数据上，与地面真实数据（通过虚拟罗盘工具手动选取）和其他广泛使用的自动结构映射技术相比，该方法在估计不连续面方向时表现出最低的平均绝对误差：倾角误差为1.95°，倾角方向误差为2.20°，且离散误差保持在3°以下。这表明该方法在提高精度和鲁棒性方面显著优于基线方法。",
      "conclusion": "该研究的主要贡献是提出了一种结合单次过滤、循环方向转换和层次聚类的自动表征方法，提高了岩石不连续面表征的准确性和效率。其学术价值在于为点云处理和地质工程提供了创新技术路径，实际应用则有助于改进岩体稳定性评估和挖掘安全监控。摘要未明确说明局限性，但未来工作可探索方法在其他地质环境或更复杂点云数据中的适用性。",
      "tags": [
        "Point Cloud Processing",
        "Signal Processing",
        "Hierarchical Clustering",
        "Discontinuity Characterization",
        "Orientation Transformation"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:27.829736Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01780",
    "title": "DDP-WM: Disentangled Dynamics Prediction for Efficient World Models",
    "authors": [
      "Shicheng Yin",
      "Kaixuan Yin",
      "Weixing Chen",
      "Yang Liu",
      "Guanbin Li",
      "Liang Lin"
    ],
    "abstract": "World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLabSYSU/DDP-WM.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01780.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01780",
    "published": "2026-02-02T08:04:25Z",
    "updated": "2026-02-02T08:04:25Z",
    "comment": "Codes will be available at https://github.com/HCPLabSYSU/DDP-WM",
    "light_analysis": {
      "overview": "提出DDP-WM，一种基于解耦动力学预测的高效世界模型，显著提升推理速度和性能，解决了现有密集Transformer模型的计算效率瓶颈。",
      "motivation": "世界模型在自主机器人规划中至关重要，但当前基于密集Transformer的模型存在大量计算开销，严重阻碍了实时部署应用。该研究针对这一效率与性能之间的瓶颈问题，旨在开发一种高效且高保真的世界模型，以优化资源分配并满足实时需求。现有方法在处理复杂场景动力学时过于密集，导致计算冗余和性能下降，亟需创新方法来平衡效率与准确性。",
      "method": "DDP-WM采用解耦动力学预测原则，假设场景中的潜在状态演化可分解为稀疏的主要动力学和次要的背景更新。核心架构通过集成高效的历史处理模块和动态定位机制来隔离物理交互驱动的主要动力学，同时利用交叉注意力机制进行背景更新。这一设计优化了资源分配，减少了计算冗余，并为规划器提供了平滑的优化环境，从而在保持高精度的同时提升整体效率。",
      "result": "实验表明，DDP-WM在多种任务中均实现了显著效率和性能提升，包括导航、精确桌面操作及复杂变形或多体交互。在具有挑战性的Push-T任务上，与最先进的密集模型相比，DDP-WM实现了约9倍的推理速度加速，并将模型预测控制（MPC）的成功率从90%提升至98%。这些结果证明了其在保持高性能的同时，大幅优化了计算开销。",
      "conclusion": "该研究的主要贡献在于提出了DDP-WM，一种基于解耦动力学预测的高效世界模型，为开发实时、高保真的机器人规划系统开辟了新路径。它不仅在学术上推动了世界模型理论的创新，还具有实际应用价值，可促进自主机器人系统的部署。未来工作可进一步探索其在更广泛场景中的扩展性和优化潜力。",
      "tags": [
        "Disentangled Dynamics Prediction",
        "World Models",
        "Cross-Attention Mechanism",
        "Model Predictive Control",
        "Robotic Planning"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:31.164903Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01779",
    "title": "LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning",
    "authors": [
      "Rui Hua",
      "Yu Wei",
      "Zixin Shu",
      "Kai Chang",
      "Dengying Yan",
      "Jianan Xia",
      "Zeyu Liu",
      "Hui Zhu",
      "Shujie Song",
      "Mingzhong Xiao",
      "Xiaodong Li",
      "Dongmei Jia",
      "Zhuye Gao",
      "Yanyan Meng",
      "Naixuan Zhao",
      "Yu Fu",
      "Haibin Yu",
      "Benman Yu",
      "Yuanyuan Chen",
      "Fei Dong",
      "Zhizhou Meng",
      "Pengcheng Yang",
      "Songxue Zhao",
      "Lijuan Pei",
      "Yunhui Hu",
      "Kan Ding",
      "Jiayuan Duan",
      "Wenmao Yin",
      "Yang Gu",
      "Runshun Zhang",
      "Qiang Zhu",
      "Jian Yu",
      "Jiansheng Li",
      "Baoyan Liu",
      "Wenjia Wang",
      "Xuezhong Zhou"
    ],
    "abstract": "Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01779.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01779",
    "published": "2026-02-02T08:02:25Z",
    "updated": "2026-02-02T08:02:25Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了LingLanMiDian基准，统一评估大型语言模型在中医知识和临床推理中的表现。",
      "motivation": "LLMs在医学NLP领域快速进展，但中医具有独特的本体、术语和推理模式，需要领域专门的评估。现有中医基准覆盖范围分散、规模有限，且依赖非统一或生成密集的评分方法，导致公平比较困难。这限制了LLMs在中医应用中的可信度和发展，因此迫切需要构建统一、大规模的评估框架，以推动中医AI研究的标准化。",
      "method": "本研究提出了LingLan基准，这是一个专家策划、多任务的评估套件，覆盖知识召回、多跳推理、信息抽取和临床决策。关键创新包括统一的度量设计、临床标签的同义词容忍协议、每个数据集400项的难子集，并将诊断和治疗推荐重构为单选决策识别。通过零样本评估14个领先的开源和专有LLMs，提供了系统化的性能分析框架。",
      "result": "评估结果显示，LingLan基准为LLMs的中医能力提供了统一视角，揭示了在知识理解和推理方面的优势与局限。在难子集上，当前模型表现与人类专家相比存在显著差距，特别是在中医专门推理任务中，突出了模型改进的需求；尽管摘要未明确具体数值，但强调了公平比较的重要性。",
      "conclusion": "LingLan基准通过标准化评估桥接基础知识和应用推理，为中医LLMs和领域特异性医学AI研究建立了统一、定量和可扩展的基础。主要贡献在于提供了统一的评估框架，促进模型比较和领域进步，未来工作可能涉及扩展基准或应用于更广泛的医学领域。",
      "tags": [
        "Large Language Model",
        "Traditional Chinese Medicine",
        "Benchmark Evaluation",
        "Multi-hop Reasoning",
        "Zero-shot Learning"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:45.248218Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01778",
    "title": "Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model",
    "authors": [
      "Kangtao Lv",
      "Jiwei Tang",
      "Langming Liu",
      "Haibin Chen",
      "Weidong Zhang",
      "Shilei Liu",
      "Yongwei Wang",
      "Yujin Yuan",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01778.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01778",
    "published": "2026-02-02T08:01:57Z",
    "updated": "2026-02-02T08:01:57Z",
    "comment": "15 pages,6 figures",
    "light_analysis": {
      "overview": "本文首次从数据中心视角系统研究数据分布对大型语言模型上下文压缩质量的影响。",
      "motivation": "在长上下文场景中部署大型语言模型面临计算效率低下和信息冗余的挑战。尽管上下文压缩技术已被广泛研究以应对这些问题，但现有工作主要聚焦于模型端优化，忽略了数据分布本身对压缩效果的关键影响。这一不足导致压缩策略可能不充分，限制了LLMs在实际应用中的性能提升，因此本文旨在探索数据分布的作用，以填补研究空白并推动更有效的压缩方法。",
      "method": "本研究采用基于自编码器的框架来评估上下文压缩后的语义完整性，核心方法包括分析两个数据维度：输入数据分布和内在数据分布（即模型的内部预训练知识）。创新点在于首次从数据中心视角出发，通过测量编码器和解码器的熵值，系统探讨数据特性如何影响压缩质量。具体实验设置包括使用自编码器架构，并在冻结解码器条件下进行测量，以区分输入和内在数据的作用，从而揭示压缩机制中的关键因素。",
      "result": "实验发现编码器测量的输入熵与压缩质量呈负相关，表明高熵数据更难压缩；而在冻结解码器设置下，解码器测量的熵与压缩质量无显著关系。此外，编码器和解码器之间的内在数据不匹配显著削弱压缩增益，且这一问题难以通过常规方法缓解。这些结果强调了数据分布因素在上下文压缩中的重要性，为优化策略提供了数据驱动依据，但摘要未明确说明具体的性能指标提升数据或与基线方法的详细对比。",
      "conclusion": "论文的主要贡献是首次系统揭示了数据分布在上下文压缩中的关键作用，填补了现有研究空白，具有重要学术价值，扩展了压缩技术的理论基础。在实际应用上，提出的实践指南有助于优化LLMs在长上下文部署中的效率。局限性在于内在数据差距问题难以完全解决，未来工作可探索更复杂的数据对齐方法或结合模型改进，以进一步提升压缩性能和应用范围。",
      "tags": [
        "Context Compression",
        "Large Language Models",
        "Data Distribution",
        "Autoencoder",
        "Entropy"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:55.388976Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01777",
    "title": "Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions",
    "authors": [
      "M. Arashi",
      "M. Amintoosi"
    ],
    "abstract": "Stochastic gradient methods are central to large-scale learning, yet their analysis typically treats mini-batch gradients as unbiased estimators of the population gradient. In high-dimensional settings, however, classical results from statistical decision theory show that unbiased estimators are generally inadmissible under quadratic loss, suggesting that standard stochastic gradients may be suboptimal from a risk perspective. In this work, we formulate stochastic gradient computation as a high-dimensional estimation problem and introduce a decision-theoretic framework based on Stein-rule shrinkage. We construct a shrinkage gradient estimator that adaptively contracts noisy mini-batch gradients toward a stable restricted estimator derived from historical momentum. The shrinkage intensity is determined in a data-driven manner using an online estimate of gradient noise variance, leveraging second-moment statistics commonly maintained by adaptive optimization methods. Under a Gaussian noise model and for dimension p>=3, we show that the proposed estimator uniformly dominates the standard stochastic gradient under squared error loss and is minimax-optimal in the classical decision-theoretic sense. We further demonstrate how this estimator can be incorporated into the Adam optimizer, yielding a practical algorithm with negligible additional computational cost. Empirical evaluations on CIFAR10 and CIFAR100, across multiple levels of label noise, show consistent improvements over Adam in the large-batch regime. Ablation studies indicate that the gains arise primarily from selectively applying shrinkage to high-dimensional convolutional layers, while indiscriminate shrinkage across all parameters degrades performance. These results illustrate that classical shrinkage principles provide a principled and effective approach to improving stochastic gradient estimation in modern deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01777.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01777",
    "published": "2026-02-02T08:01:13Z",
    "updated": "2026-02-02T08:01:13Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出基于 Stein 规则收缩的梯度估计器，通过决策理论框架改进高维随机梯度估计，理论证明支配标准方法，实证集成 Adam 优化器提升性能。",
      "motivation": "随机梯度方法是现代大规模机器学习的核心，但传统分析通常假设小批量梯度是总体梯度的无偏估计器。在高维设置下，统计决策理论表明，无偏估计器在二次损失下一般不是容许的，这意味着标准随机梯度在风险角度可能不是最优的。本研究旨在解决这一问题，因为高维环境中的梯度估计不准确可能导致算法性能下降，现有方法的不足在于忽略了无偏性带来的潜在风险，需要通过更有效的估计策略来提升学习效率和稳定性。",
      "method": "本研究将随机梯度计算形式化为高维估计问题，引入基于 Stein 规则收缩的决策理论框架。核心方法构建一个收缩梯度估计器，自适应地将噪声小批量梯度向一个由历史动量导出的稳定受限估计器收缩。收缩强度通过在线估计梯度噪声方差来确定，利用了自适应优化方法中常见的二阶矩统计。在假设噪声为高斯分布且维度 p>=3 的条件下，该方法设计为可集成到 Adam 优化器中，形成一个计算成本可忽略的实用算法，关键创新包括自适应收缩策略和数据驱动的强度确定机制。",
      "result": "在 CIFAR10 和 CIFAR100 数据集上，通过不同标签噪声水平的实证评估，本方法在大批量训练机制中相比标准 Adam 优化器表现出持续改进，例如在处理噪声标签时显示了更强的鲁棒性。摘要未明确列出具体数值指标，如准确率提升的百分比，但实验结果强调了性能增益。与基线方法 Adam 的对比显示，消融研究表明，这种改进主要源于选择性地对高维卷积层应用收缩，而全局应用收缩则会降低性能，验证了选择性收缩的有效性。",
      "conclusion": "本论文的主要贡献是提出了一种基于 Stein 规则收缩的梯度估计框架，理论证明其在平方误差损失下统一支配标准随机梯度，并达到极小极大最优，这为改进现代深度学习中的随机梯度估计提供了一种原理性方法。学术价值在于将经典统计决策理论应用于高维梯度优化，实际应用上，该方法可轻松融入 Adam 等流行优化器，具有低计算开销。尽管摘要未明确说明局限性或未来工作方向，但该研究为高维机器学习优化开辟了新路径，可能推动更广泛的算法改进。",
      "tags": [
        "Stochastic Gradient Estimation",
        "Stein-Rule Shrinkage",
        "High-Dimensional Statistics",
        "Decision-Theoretic Framework",
        "Adam Optimizer"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:05.988760Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01776",
    "title": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting",
    "authors": [
      "Mingyue Cheng",
      "Xiaoyu Tao",
      "Qi Liu",
      "Ze Guo",
      "Enhong Chen"
    ],
    "abstract": "Time series forecasting has traditionally been formulated as a model-centric, static, and single-pass prediction problem that maps historical observations to future values. While this paradigm has driven substantial progress, it proves insufficient in adaptive and multi-turn settings where forecasting requires informative feature extraction, reasoning-driven inference, iterative refinement, and continual adaptation over time. In this paper, we argue for agentic time series forecasting (ATSF), which reframes forecasting as an agentic process composed of perception, planning, action, reflection, and memory. Rather than focusing solely on predictive models, ATSF emphasizes organizing forecasting as an agentic workflow that can interact with tools, incorporate feedback from outcomes, and evolve through experience accumulation. We outline three representative implementation paradigms -- workflow-based design, agentic reinforcement learning, and a hybrid agentic workflow paradigm -- and discuss the opportunities and challenges that arise when shifting from model-centric prediction to agentic forecasting. Together, this position aims to establish agentic forecasting as a foundation for future research at the intersection of time series forecasting.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01776.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01776",
    "published": "2026-02-02T08:01:11Z",
    "updated": "2026-02-02T08:01:11Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出代理性时间序列预测（ATSF），将传统模型中心预测重构为代理过程，以应对自适应和多轮设置中的挑战。",
      "motivation": "时间序列预测传统上被形式化为模型中心的、静态的单次预测问题，虽然在许多场景下有效，但在自适应和多轮设置中显得不足，这些设置需要信息性特征提取、推理驱动的推断和持续适应。实际应用中，预测往往需要交互式反馈和迭代优化，现有方法无法有效满足这些需求，这凸显了转向代理化预测的重要性，以提高灵活性和应对复杂动态环境的能力。",
      "method": "论文提出代理性时间序列预测（ATSF），将预测重构为包含感知、规划、行动、反思和记忆的代理过程，强调组织为可交互的工作流程，能够利用工具、纳入结果反馈并通过经验进化。关键创新点在于引入代理化框架，取代单一模型预测，并概述了三种代表性实现范式：基于工作流的设计、代理强化学习以及混合代理工作流程，这些方法旨在增强预测的适应性和多轮处理能力，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "本文是一个立场论文，未提供具体实验结果或性能指标，主要侧重于概念框架的讨论。它描述了从模型中心预测转向代理预测的机遇，如提高自适应性和交互能力，以及面临的挑战，例如系统复杂性和实现难度。由于缺乏实证数据，未进行与基线方法的直接对比，但其理论框架为未来实验验证奠定了基础，强调ATSF在应对动态预测问题中的潜在优势。",
      "conclusion": "论文的主要贡献是提出并概述了代理性时间序列预测（ATSF），将其确立为未来研究的基础，具有重要学术价值，推动时间序列预测领域向更灵活和自适应方向发展。实际应用价值在于可能提升预测系统在动态环境中的性能和用户交互体验。局限性包括尚未进行实证验证和具体实现细节不足，未来工作方向应包括开发具体ATSF系统、进行实验评估，并探索其在真实场景中的应用以应对多轮和适应性挑战。",
      "tags": [
        "Agentic Time Series Forecasting",
        "Workflow-based Design",
        "Agentic Reinforcement Learning",
        "Hybrid Agentic Workflow",
        "Multi-turn Forecasting"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:59.951007Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01775",
    "title": "Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction",
    "authors": [
      "Yucheng Wu",
      "Yuekui Yang",
      "Hongzheng Li",
      "Anan Liu",
      "Jian Xiao",
      "Junjie Zhai",
      "Huan Yu",
      "Shaoping Ma",
      "Leye Wang"
    ],
    "abstract": "Deploying new architectures in large-scale user response prediction systems incurs high model switching costs due to expensive retraining on massive historical data and performance degradation under data retention constraints. Existing knowledge distillation methods struggle with architectural heterogeneity and the prohibitive cost of transferring large embedding tables. We propose CrossAdapt, a two-stage framework for efficient cross-architecture knowledge transfer. The offline stage enables rapid embedding transfer via dimension-adaptive projections without iterative training, combined with progressive network distillation and strategic sampling to reduce computational cost. The online stage introduces asymmetric co-distillation, where students update frequently while teachers update infrequently, together with a distribution-aware adaptation mechanism that dynamically balances historical knowledge preservation and fast adaptation to evolving data. Experiments on three public datasets show that CrossAdapt achieves 0.27-0.43% AUC improvements while reducing training time by 43-71%. Large-scale deployment on Tencent WeChat Channels (~10M daily samples) further demonstrates its effectiveness, significantly mitigating AUC degradation, LogLoss increase, and prediction bias compared to standard distillation baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01775.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01775",
    "published": "2026-02-02T08:00:36Z",
    "updated": "2026-02-02T08:00:36Z",
    "comment": "15 pages",
    "light_analysis": {
      "overview": "本文提出CrossAdapt框架，通过两阶段知识转移机制实现高效跨架构迁移，显著降低大规模在线用户响应预测中的模型切换成本。",
      "motivation": "在大规模在线用户响应预测系统中，部署新架构常面临高模型切换成本，包括需要昂贵重新训练大量历史数据和因数据保留约束导致的性能下降。现有知识蒸馏方法难以处理架构异构性及大型嵌入表传输的过高开销，限制了应用效果。该研究旨在解决这些问题，提升系统效率和适应性，为实际部署提供支持。",
      "method": "CrossAdapt采用两阶段框架：离线阶段通过维度自适应投影实现快速嵌入转移，无需迭代训练，结合渐进网络蒸馏和战略采样以降低计算成本。在线阶段引入不对称协同蒸馏，学生模型频繁更新而教师模型更新较少，并采用分布感知适应机制动态平衡历史知识保留与对新数据的快速适应。该方法针对用户响应预测任务，未明确说明具体数据集和模型架构细节。",
      "result": "实验在三个公共数据集上进行，结果显示CrossAdapt实现了0.27-0.43%的AUC提升，同时训练时间减少了43-71%。在腾讯微信频道的大规模部署（约1000万日样本）中，相较于标准蒸馏基线，显著减轻了AUC下降、LogLoss增加和预测偏差，验证了方法的有效性和实际应用价值。",
      "conclusion": "本研究的主要贡献是提出CrossAdapt框架，实现高效跨架构知识转移，提升大规模在线系统的性能和效率。它具有重要的学术价值，推动了知识蒸馏和在线学习领域的发展，并在实际应用中减少了运营成本。未来工作可探索更多适应机制或扩展到其他预测任务，摘要未明确说明具体局限性。",
      "tags": [
        "Knowledge Distillation",
        "Cross-Architecture Transfer",
        "Online Adaptation",
        "Embedding Transfer",
        "AUC Improvement"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:21.820527Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01772",
    "title": "DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics",
    "authors": [
      "Yucheng Liao",
      "Han Wen",
      "Weinan E",
      "Weijie Zhang"
    ],
    "abstract": "Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01772.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01772",
    "published": "2026-02-02T07:55:24Z",
    "updated": "2026-02-02T07:55:24Z",
    "comment": "21 pages, 5 figures",
    "light_analysis": {
      "overview": "DIA-CLIP 提出一个预训练的表示学习框架，通过跨模态学习实现零样本肽-谱匹配，显著提升 DIA 蛋白质组学分析的准确性和泛化性。",
      "motivation": "当前数据非依赖性采集质谱分析框架依赖半监督训练进行肽-谱匹配重评分，容易过拟合且缺乏跨物种和实验条件的泛化性，限制了大规模系统生物学研究的应用。本研究旨在解决这一关键问题，通过开发通用框架来提高分析的可靠性和广泛适应性，以应对蛋白质组学中多样化的实验需求。",
      "method": "DIA-CLIP 集成双编码器对比学习框架与编码器-解码器架构，为肽序列和对应光谱特征建立统一的跨模态表示，通过预训练实现高精度零样本推理。该方法避免了每个运行中的半监督训练，关键技术包括对比学习优化表示对齐和编码器-解码器架构处理跨模态数据，摘要未明确说明具体数据集细节。",
      "result": "DIA-CLIP 在多个基准测试中一致优于最先进工具，蛋白质识别率最高提升45%，同时诱饵识别减少12%。这些结果表明该框架在提高识别深度和降低假阳性方面具有显著优势，与现有方法相比展现出更强的鲁棒性和准确性，验证了其在实际应用中的有效性。",
      "conclusion": "本研究的主要贡献是提出一个通用表示学习框架，推动了 DIA 分析从半监督训练到预训练范式的转变。学术上，它融合对比学习和跨模态表示技术；实际应用中，在单细胞和空间蛋白质组学等领域有潜力促进新生物标志物发现和细胞机制研究，未来工作可能涉及扩展应用场景和改进模型泛化。",
      "tags": [
        "Representation Learning",
        "Contrastive Learning",
        "Encoder-Decoder Architecture",
        "Zero-shot Learning",
        "Cross-modal Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:16.785194Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01771",
    "title": "<SOG_k>: One LLM Token for Explicit Graph Structural Understanding",
    "authors": [
      "Jingyao Wu",
      "Bin Lu",
      "Zijun Di",
      "Xiaoying Gan",
      "Meng Jin",
      "Luoyi Fu",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "abstract": "Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01771.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01771",
    "published": "2026-02-02T07:55:09Z",
    "updated": "2026-02-02T07:55:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种使用特殊令牌<SOG_k>的方法，以统一方式增强大语言模型在图结构理解中的能力，避免了现有方法的不足，提高了效率和准确性。",
      "motivation": "大语言模型在处理图结构数据时面临结构幻觉等挑战。现有方法主要分为两种：一种将图转化为自然语言描述，但这会导致令牌消耗过多和注意力分散；另一种将图转换为连续嵌入作为软提示，但这与原文本令牌存在严重不匹配问题。图结构是重要的数据类型，在社交网络、知识图谱等领域有广泛应用，现有方法无法高效、准确地捕捉结构信息，因此需要一种新方法来统一令牌空间，提升模型对图结构的理解能力。",
      "method": "论文的核心方法是引入特殊令牌<SOG_k>来显式表示图结构，并设计了一个拓扑感知的结构分词器，该分词器能将每个图拓扑映射为高度选择性的单一令牌。此外，作者构建了一套混合结构问答语料库，用于将新的结构令牌与现有文本令牌对齐，确保在统一的令牌空间中实现结构信息共享。这种方法使大语言模型能够以简洁的方式输入拓扑信息，并促进结构理解和推理，避免了传统方法中的令牌冗余和注意力分散问题。",
      "result": "论文在五个图级基准测试上进行了广泛实验，结果表明，该方法相比基线方法取得了显著的性能提升，具体表现为9.9%到41.4%的性能改进，同时展现出可解释性和一致性。此外，该方法还具有良好的可扩展性，能够灵活扩展到节点级任务，支持全局和局部结构理解。这些实验验证了<SOG_k>令牌在增强大语言模型图结构理解方面的有效性，并优于现有基于语言化或连续嵌入的方法。",
      "conclusion": "该研究的主要贡献是提出了一种创新的令牌表示方法，使用<SOG_k>令牌使大语言模型能够以统一、准确的方式理解和处理图结构数据，解决了现有方法在令牌消耗和匹配性方面的局限。学术价值在于提供了一种新的图结构集成框架，增强了模型的结构理解能力；实际应用价值包括在图分析、问答系统等领域的潜在应用，且方法具有可扩展性和代码公开性。未来工作方向可以进一步探索在其他复杂结构数据上的应用或优化令牌映射策略。",
      "tags": [
        "Large Language Model",
        "Graph Structural Understanding",
        "Token Representation",
        "Topology-aware Tokenizer",
        "Hybrid Question-Answering Corpus"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:21.740839Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01769",
    "title": "IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination",
    "authors": [
      "Yuanshuai Li",
      "Yuping Yan",
      "Jirui Han",
      "Fei Ming",
      "Lingjuan Lv",
      "Yaochu Jin"
    ],
    "abstract": "Hallucination remains a fundamental challenge for Multimodal Large Language Models (MLLMs). While Direct Preference Optimization (DPO) is a key alignment framework, existing approaches often rely heavily on costly external evaluators for scoring or rewriting, incurring off-policy learnability gaps and discretization loss. Due to the lack of access to internal states, such feedback overlooks the fine-grained conflicts between different modalities that lead to hallucinations during generation.   To address this issue, we propose IRIS (Implicit Reward-Guided Internal Sifting), which leverages continuous implicit rewards in the native log-probability space to preserve full information density and capture internal modal competition. This on-policy paradigm eliminates learnability gaps by utilizing self-generated preference pairs. By sifting these pairs based on multimodal implicit rewards, IRIS ensures that optimization is driven by signals that directly resolve modal conflicts. Extensive experiments demonstrate that IRIS achieves highly competitive performance on key hallucination benchmarks using only 5.7k samples, without requiring any external feedback during preference alignment. These results confirm that IRIS provides an efficient and principled paradigm for mitigating MLLM hallucinations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01769.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01769",
    "published": "2026-02-02T07:51:57Z",
    "updated": "2026-02-02T07:51:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "IRIS提出了一种基于连续隐含奖励和内部筛选的方法，以缓解多模态大语言模型的幻觉问题。",
      "motivation": "多模态大语言模型（MLLMs）面临幻觉的根本挑战，即生成内容与输入模态不符。现有方法如直接偏好优化（DPO）依赖昂贵的外部评估者进行评分或重写，导致学习能力差距和离散化损失，且无法捕捉模态间的细粒度冲突，这些冲突是幻觉产生的主要原因。研究动机在于克服这些局限性，通过内部状态反馈来更高效地解决多模态对齐问题。",
      "method": "IRIS方法利用原生对数概率空间中的连续隐含奖励，以保持完整信息密度并捕捉内部模态竞争。该方法采用在线策略范式，通过自生成偏好对消除学习能力差距，然后基于多模态隐含奖励对这些对进行内部筛选，确保优化信号直接解决模态冲突。技术核心包括隐含奖励机制和内部筛选策略，不依赖外部反馈，适用于MLLMs的偏好对齐。",
      "result": "实验表明，IRIS在关键幻觉基准上取得了高度竞争性的性能，仅使用5.7k样本且无需外部反馈。该方法通过自生成偏好对和内部筛选优化，与基线方法相比，有效缓解了幻觉问题。具体性能提升未在摘要中明确说明，但结果验证了IRIS的高效性和原理性。",
      "conclusion": "IRIS提供了一种高效且原则性的范式来缓解多模态大语言模型的幻觉，具有重要的学术价值和实际应用潜力，如提升模型可靠性和减少对齐成本。贡献包括消除学习能力差距和捕捉模态冲突，未来工作可能包括扩展到更复杂场景或更多数据集，但摘要未明确说明局限性。",
      "tags": [
        "Multimodal Large Language Models",
        "Direct Preference Optimization",
        "Implicit Reward Learning",
        "On-policy Learning",
        "Hallucination Mitigation"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:17.647510Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01766",
    "title": "CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling",
    "authors": [
      "Runsong Zhao",
      "Shilei Liu",
      "Jiwei Tang",
      "Langming Liu",
      "Haibin Chen",
      "Weidong Zhang",
      "Yujin Yuan",
      "Tong Xiao",
      "Jingbo Zhu",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: https://anonymous.4open.science/r/comet-B00B/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01766.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01766",
    "published": "2026-02-02T07:49:44Z",
    "updated": "2026-02-02T07:49:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出CoMeT架构，通过双内存系统和动态软提示实现LLMs对任意长序列的高效处理，保持常数内存和线性时间复杂度。",
      "motivation": "标准Transformer的二次复杂度问题和无限增长的键值（KV）缓存成为长上下文处理的主要障碍，导致计算资源消耗大且内存使用不可控。现有高效方法在维持性能和处理极长序列方面存在不足，限制了实际应用。因此，研究旨在开发一种新架构，以克服这些限制，实现高效、可扩展的长上下文建模。",
      "method": "CoMeT是一种可插拔模块，使用双内存系统管理上下文：临时内存基于FIFO队列处理近期事件，全局内存通过门控更新规则捕捉长距离依赖。这些内存作为动态软提示为后续数据块提供上下文。此外，引入层级流水线并行策略，支持在极长上下文上高效微调，可轻松集成到预训练Transformer模型中。",
      "result": "实验表明，配备CoMeT的模型在32k上下文微调后，能在1M token序列中准确检索任意位置的passkey。在SCROLLS基准测试中，CoMeT超越其他高效方法，并在摘要任务上达到与全注意力基线相当的性能。进一步在现实世界的代理和用户行为QA任务中验证了其有效性。",
      "conclusion": "本研究的主要贡献是CoMeT架构，使LLMs能够以常数内存和线性时间处理任意长序列，具有高可集成性和实际应用价值。学术意义在于提出了一种新颖的效率和性能平衡方法，推动长上下文建模发展。未来工作可探索更广泛的应用场景和进一步优化内存管理策略。",
      "tags": [
        "Long Context Modeling",
        "Memory Systems",
        "Transformer Architecture",
        "Pipeline Parallelism",
        "Efficient Fine-tuning"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:17.350529Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01764",
    "title": "GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data",
    "authors": [
      "Dennis Basile",
      "Dennis Sprute",
      "Helene Dörksen",
      "Holger Flatt"
    ],
    "abstract": "The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01764.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01764",
    "published": "2026-02-02T07:48:03Z",
    "updated": "2026-02-02T07:48:03Z",
    "comment": "Accepted at 19th CIRP Conference on Intelligent Computation in Manufacturing Engineering",
    "light_analysis": {
      "overview": "本文提出一种基于MEMS-LiDAR和混合数据的GDPR合规人员识别方法，用于工业环境，以解决隐私侵犯和数据标注难题。",
      "motivation": "在工业环境中，可靠检测未经授权人员对避免停机、财产损坏和人身风险至关重要。传统基于深度学习的视觉方法虽能提供图像信息，但对光照和可见度条件敏感，且常违反GDPR等隐私法规，导致合规风险。此外，这些方法需要大量标注数据进行训练，但数据收集和标注过程耗时、易错且成本高。因此，本研究旨在开发一种高效、隐私合规的替代方案，解决现有方法在隐私保护、数据获取和性能稳定性方面的不足。",
      "method": "本研究采用基于MEMS-LiDAR的技术，捕获匿名化的3D点云数据，避免个人身份特征以确保隐私合规。为克服真实数据采集和标注的耗时问题，提出混合数据方法：结合真实MEMS-LiDAR记录与从CARLA模拟框架生成的合成场景进行数据增强。核心创新在于利用合成数据弥补真实数据的不足，减少对昂贵标注数据的依赖，同时通过3D点云分析实现准确的人员检测，无需图像信息。技术路线包括使用模拟环境生成多样化的训练数据，并整合到深度学习模型中以提高泛化能力。",
      "result": "实验结果显示，使用混合数据的模型相比仅用真实数据的模型，在平均精度上提升了44个百分点。同时，手动标注工作量减少了50%，显著降低了数据处理的成本和时间。与基线方法对比，混合数据方法不仅实现了更高的检测性能，还证明了合成数据在提升模型准确率方面的有效性。此外，该方法在保持隐私合规的同时，展现了在工业环境中应用的可行性和效率优势。",
      "conclusion": "本文的主要贡献是开发了一种可扩展、成本效益高的人员识别方法，结合了高性能检测与GDPR合规性，通过利用MEMS-LiDAR和合成数据解决隐私和数据获取难题。研究具有重要学术价值，为AI系统在敏感工业环境中的应用提供了新思路，并展示了合成数据在实际场景中的潜力。实际应用中，该方法可促进安全监测系统的部署而不侵犯隐私。未来工作可探索更多合成数据来源、优化模型架构或扩展到其他隐私敏感领域。",
      "tags": [
        "MEMS-LiDAR",
        "3D Point Clouds",
        "Hybrid Data",
        "GDPR Compliance",
        "Person Recognition"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:58.225591Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01763",
    "title": "A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention",
    "authors": [
      "Xiaowei Ye",
      "Xiaoyu He",
      "Chao Liao",
      "Chen Wu",
      "Pinyan Lu"
    ],
    "abstract": "Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01763.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01763",
    "published": "2026-02-02T07:47:21Z",
    "updated": "2026-02-02T07:47:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文理论地建立了混合线性-全注意力与全注意力在表达能力上的可证明层次关系。",
      "motivation": "Transformer模型是现代大型语言模型的基石，但标准全注意力的二次计算复杂度限制了其效率。为此，研究者提出了线性和混合注意力等高效机制，然而这些机制的表达能力相对于全注意力缺乏严格的理论分析。当前研究未能从理论上明确这些高效机制与全注意力的性能差异，这使得在选择和优化注意力机制时缺乏理论指导。因此，本文旨在填补这一理论空白，为理解不同注意力机制的基本能力和局限性提供理论支撑。",
      "method": "本文采用理论分析方法，比较不同注意力机制的表达能力。核心是建立一个表达层次，针对序列函数组合这一多步推理任务进行论证。具体地，研究证明了对于该任务，一个(L+1)层的全注意力网络足以解决，而任何混合网络，即使交织L-1层全注意力和大量(2^{3L^2}层)线性注意力层，也无法解决。这一理论适用于所有以循环形式表示的线性注意力变体，如Mamba和DeltaNet，从而广泛覆盖了现有高效注意力机制。",
      "result": "研究结果表明，在表达能力上存在一个清晰的层次结构。对于序列函数组合任务，全注意力网络仅需(L+1)层即可解决，而混合注意力网络，即使结合了L-1层全注意力和多达(2^{3L^2})层的线性注意力，也无法完成该任务。这明确展示了全注意力在表达能力上的优势，与混合注意力形成鲜明对比。理论分析提供了具体的数据支持，揭示了高效注意力机制在复杂推理任务中的局限性。",
      "conclusion": "本文的主要贡献是首次理论证明了混合线性-全注意力与标准全注意力在表达能力上的可分离性，建立了明确的表达层次。这一研究具有重要的学术价值，为理解注意力机制的理论基础提供了新的视角，有助于指导高效模型的设计和选择。在实际应用中，该理论可以用于评估不同注意力机制在复杂任务中的适用性。未来工作可能包括将理论扩展到更多类型的注意力机制或其他推理任务中，进一步深化对Transformer模型的理解。",
      "tags": [
        "Linear Attention",
        "Hybrid Attention",
        "Expressiveness Hierarchy",
        "Theoretical Characterization"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:26.658030Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01762",
    "title": "PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models",
    "authors": [
      "Xuliang Wang",
      "Yuetao Chen",
      "Maochan Zhen",
      "Fang Liu",
      "Xinzhou Zheng",
      "Xingwu Liu",
      "Hong Xu",
      "Ming Li"
    ],
    "abstract": "Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation.   We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01762.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01762",
    "published": "2026-02-02T07:46:03Z",
    "updated": "2026-02-02T07:46:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "PRISM提出了一种通过参数化重构推理路径的创新草案模型架构，有效解耦模型容量与推理成本，显著加速大型语言模型解码。",
      "motivation": "大型语言模型由于自回归特性面临解码速度慢的挑战，推测解码方法虽能加速推理，但现有方法常使用参数规模更大的草案模型以提高预测质量，这引入显著计算开销，导致在预测准确性和计算延迟之间难以平衡。本研究旨在通过架构创新解决这一根本问题，以提升实际应用中的推理效率，满足AI系统对高性能解码的需求。",
      "method": "PRISM的核心方法是将每个预测步骤的计算分配到不同的参数集中，通过重构草案模型的计算路径来实现模型容量与推理成本的解耦。具体而言，它采用参数化设计分离计算过程，可能涉及优化参数使用以减少冗余操作，从而在不增加延迟的前提下提升模型表现，摘要未明确说明具体数据集或模型架构细节。",
      "result": "实验结果显示，PRISM在性能上优于所有现有草案架构，实现了优异的接受长度，同时保持最小草案延迟，确保端到端速度显著提升。通过严格公平的比较，PRISM将高度优化推理引擎的解码吞吐量提升了超过2.6倍，并在扩展数据量时比其他草案架构更有效地扩展，表现出更强的适应性。",
      "conclusion": "本研究贡献了PRISM架构，成功解决了推测解码中计算开销的难题，通过创新设计平衡了模型效率与性能。其学术价值体现在重新审视扩展定律并推动架构优化，实际应用上大幅加速了LLM推理，未来工作可能涉及参数分配进一步优化或扩展至更多场景，但摘要未明确说明具体局限性。",
      "tags": [
        "Speculative Decoding",
        "Large Language Model",
        "Inference Acceleration",
        "Parametric Refactoring",
        "Draft Models"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:58.170667Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01760",
    "title": "MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement",
    "authors": [
      "Hao Zhang",
      "Yanping Zha",
      "Zizhuo Li",
      "Meiqi Gong",
      "Jiayi Ma"
    ],
    "abstract": "This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01760.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01760",
    "published": "2026-02-02T07:43:29Z",
    "updated": "2026-02-02T07:43:29Z",
    "comment": null,
    "light_analysis": {
      "overview": "MagicFuse提出了一种基于扩散模型的单图像融合框架，通过知识强化和生成，实现从单一可见图像到高质量跨光谱场景表示。",
      "motivation": "研究动机在于解决恶劣条件下只有可见光传感器可用时，传统多模态图像融合方法受限的实际问题。这一问题的重要性在于现实应用中资源有限，多模态输入难以获取，现有方法无法从单图像中提取跨光谱信息，导致性能下降。通过将融合从数据级扩展到知识级，本方法旨在提升融合技术的适应性和实用性，弥补现有方法的不足。",
      "method": "论文提出MagicFuse框架，包括两个基于扩散模型的分支：同谱知识增强分支挖掘可见光谱中被遮蔽的场景信息，跨谱知识生成分支学习红外光谱的热辐射分布模式。关键创新在于设计多域知识融合分支，集成这两个分支扩散流的概率噪声，通过连续采样获得跨光谱场景表示。此外，框架施加视觉和语义约束以优化表示，支持下游任务，尽管摘要未明确说明具体数据集和模型架构，但基于扩散模型实现知识级融合是核心特色。",
      "result": "实验结果显示，尽管仅依赖单一退化可见图像，MagicFuse在视觉和语义表示性能上达到甚至优于使用多模态输入的最新融合方法。与基线方法对比，该方法有效克服了单图像限制，实现了高质量跨光谱场景表示，证明了其优越性。摘要未给出具体数据如准确率，但强调了性能的显著提升，表明框架在资源受限环境下的应用潜力。",
      "conclusion": "论文的主要贡献是提出了单图像融合概念和MagicFuse框架，通过扩散模型实现知识级融合，扩展了图像融合领域。该研究具有重要学术价值，为资源受限的实际应用提供了创新解决方案。未来工作可探索更多约束机制或应用于其他模态，以进一步优化性能和泛化能力，尽管摘要未明确说明具体局限性。",
      "tags": [
        "Image Fusion",
        "Diffusion Models",
        "Knowledge Reinforcement",
        "Semantic Constraints",
        "Cross-spectral Representation"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:06.626177Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01757",
    "title": "Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings",
    "authors": [
      "Doohyun Kim",
      "Donghwa Kang",
      "Kyungjae Lee",
      "Hyeongboo Baek",
      "Brent Byunghoon Kang"
    ],
    "abstract": "The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01757.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01757",
    "published": "2026-02-02T07:42:18Z",
    "updated": "2026-02-02T07:42:18Z",
    "comment": "10 pages",
    "light_analysis": {
      "overview": "Zero2Text提出了一种无需训练、基于递归在线对齐的跨域嵌入反转攻击框架，利用LLM先验和动态岭回归在严格黑盒设置中高效恢复文本。",
      "motivation": "检索增强生成（RAG）的普及使向量数据库成为关键基础设施，但也引入严重的隐私风险，如嵌入反转攻击。现有方法面临根本性权衡：基于优化的方法需要计算成本高昂的查询，而基于对齐的方法依赖难以获取的领域内训练数据，这些限制使它们在严格黑盒和跨域设置中无效。因此，需要一种更实用的攻击方法来克服这些缺陷，以评估和改进隐私保护措施。",
      "method": "Zero2Text是一种训练免费的框架，基于递归在线对齐技术。核心创新在于结合大型语言模型（LLM）的先验知识和动态岭回归机制，迭代地对齐文本生成与目标嵌入，无需静态数据集即可在线调整。该方法避免了传统方法对训练数据或高计算资源的依赖，适用于跨域和黑盒环境，通过优化过程实时恢复文本内容。",
      "result": "在多样化的基准测试中，Zero2Text表现出显著优势。例如，在MS MARCO数据集上针对OpenAI受害模型，其ROUGE-L分数比基线高1.8倍，BLEU-2分数高6.4倍，能够有效恢复未知领域的句子而无需任何泄漏的数据对。实验表明，该方法在跨域设置中优于现有基线，同时揭示了标准防御如差分隐私的局限性。",
      "conclusion": "Zero2Text的主要贡献是提出了一种无需训练、高效的跨域嵌入反转攻击框架，改进了现有攻击技术。其学术价值在于探索了LLM先验与动态对齐的结合，实际应用中揭示了现有隐私防御的不足，为未来安全设计提供了参考。潜在局限性包括对特定模型的依赖性，未来工作可扩展到更复杂的场景或改进攻击鲁棒性。",
      "tags": [
        "Embedding Inversion Attacks",
        "Retrieval-Augmented Generation (RAG)",
        "Large Language Model (LLM)",
        "Ridge Regression",
        "Cross-Domain Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:15.084549Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01756",
    "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation",
    "authors": [
      "Jun He",
      "Junyan Ye",
      "Zilong Huang",
      "Dongzhi Jiang",
      "Chenjue Zhang",
      "Leqi Zhu",
      "Renrui Zhang",
      "Xiang Zhang",
      "Weijia Li"
    ],
    "abstract": "While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01756.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01756",
    "published": "2026-02-02T07:42:13Z",
    "updated": "2026-02-02T07:42:13Z",
    "comment": "36 pages, 24 figures",
    "light_analysis": {
      "overview": "Mind-Brush提出了一个统一的代理框架，通过模拟人类认知过程，结合知识检索和推理，显著提升图像生成的意图理解和动态适应能力。",
      "motivation": "文本到图像生成模型虽已达到高保真度，但多为静态文本到像素解码器，难以理解用户隐式意图，导致在实际应用中效果不佳。现有统一理解生成模型虽有所改进，但仍无法处理复杂知识推理任务，且受限于静态内部先验，无法适应现实世界的动态变化，如实时新闻和新兴概念，这突显了开发更智能、适应性更强方法的必要性。",
      "method": "论文提出Mind-Brush框架，将图像生成转化为动态、知识驱动的工作流程，模拟人类“思考-研究-创造”范式。关键创新在于主动检索多模态证据以处理分布外概念，并利用推理工具解决隐式视觉约束，通过代理机制整合实时信息，增强对复杂任务的适应性，但摘要未明确说明具体模型架构或数据集细节。",
      "result": "实验结果显示，Mind-Brush显著增强了统一模型的能力：在提出的Mind-Bench基准（包含500个样本，覆盖实时新闻、新兴概念和数学、地理推理等领域）上，为Qwen-Image基线实现了从零到一的性能飞跃，同时在现有基准如WISE和RISE上取得了优越结果，验证了其广泛适用性和提升效果。",
      "conclusion": "Mind-Brush的主要贡献在于引入代理驱动框架，解决了图像生成中意图理解和动态适应的关键问题，学术上推动了模型向知识驱动和主动推理方向发展，应用上能更好地处理动态场景如实时新闻。未来工作可能包括优化检索和推理机制，或扩展到更多领域，但摘要未明确说明具体局限性。",
      "tags": [
        "Text-to-Image Generation",
        "Agentic Framework",
        "Knowledge Retrieval",
        "Reasoning Tools",
        "Multimodal Evidence"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:25.738899Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01754",
    "title": "Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration",
    "authors": [
      "Gustavo P. C. P. da Luz",
      "Alvaro M. Aspilcueta Narvaez",
      "Tiago Godoi Bannwart",
      "Gabriel Massuyoshi Sato",
      "Luis Fernando Gomez Gonzalez",
      "Juliana Freitag Borin"
    ],
    "abstract": "Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01754.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01754",
    "published": "2026-02-02T07:39:37Z",
    "updated": "2026-02-02T07:39:37Z",
    "comment": "Submitted to Journal of Internet Services and Applications, 27 pages, 20 figures, 3 tables",
    "light_analysis": {
      "overview": "该论文提出了一种基于边缘计算的车位级智能停车系统，通过YOLOv11模型和数字孪生整合，实现了高精度监控和系统可扩展性。",
      "motivation": "智能停车系统有助于减少城市拥堵和用户搜索时间，促进智慧城市发展和城市流动性。现有方法通过估计区域内车辆数量来监控停车可用性，虽然准确性良好，但无法提供车位级洞察或支持高级应用，如实时车位分配或优化。因此，研究动机是克服这一限制，开发更精细化的监控策略，以增强系统功能和实用性。",
      "method": "研究方法采用车位级监控策略，基于距离感知匹配方法和空间容忍度来精确匹配车位状态。通过自适应边界框划分方法处理挑战性空间（如遮挡或复杂布局），优化了YOLOv11m模型（大小40.5 MB）在资源受限边缘设备上的部署。此外，引入数字阴影作为数字孪生的基础，以及基于改造TV盒子的应用支持服务器，实现云服务、停车终端和统计机器人的可扩展通信，并促进硬件重用和可持续性。",
      "result": "实验结果显示，所提方法在资源受限的边缘设备上实现了98.80%的平衡准确率，同时推理时间保持在8秒。这相较于仅估计车位数量的基线方法，显著提升了监控精度和实时性，为车位级应用（如详细占用统计）提供了可靠支持，表明系统在保持效率的同时增强了功能性。",
      "conclusion": "该研究的主要贡献是扩展智能停车系统以支持车位级监控，通过距离感知匹配和自适应边界框划分提高了精度，并引入数字阴影和应用服务器提升可扩展性。其学术价值在于推动边缘计算和数字孪生在智慧城市中的应用，实际价值包括减少拥堵和促进硬件可持续发展。未来工作可朝向完全数字孪生发展，以进一步增强系统集成和实时控制能力。",
      "tags": [
        "YOLOv11",
        "Edge Computing",
        "Digital Twin",
        "Adaptive Bounding Box Partitioning",
        "Distance-Aware Matching"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:23.140809Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01753",
    "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings",
    "authors": [
      "Shenghao Fu",
      "Yukun Su",
      "Fengyun Rao",
      "Jing Lyu",
      "Xiaohua Xie",
      "Wei-Shi Zheng"
    ],
    "abstract": "Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01753.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01753",
    "published": "2026-02-02T07:38:45Z",
    "updated": "2026-02-02T07:38:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "ObjEmbed提出一种新颖的多模态语言模型嵌入方法，通过对象导向表示和高效编码，实现视觉对象与文本描述的细粒度对齐。",
      "motivation": "在视觉语言理解中，对齐图像对象与相应文本描述是一个基础挑战和现实需求。现有多模态嵌入模型在全局图像-文本对齐上表现优异，但在细粒度对齐如图像区域与特定短语上存在不足，导致视觉任务如视觉定位和局部图像检索的准确性受限。这一问题的重要性在于，细粒度对齐是提升多模态系统实用性的关键，但现有方法难以平衡语义和空间信息，需要改进以实现更精确的视觉理解。",
      "method": "ObjEmbed模型将输入图像分解为多个区域嵌入，每个对应一个对象，并包括全局嵌入。核心创新在于对象导向表示：为每个区域生成两个互补嵌入——对象嵌入用于语义匹配，IoU嵌入预测定位质量；最终匹配分数结合语义相似度和预测IoU，以提高检索准确性。模型支持区域级任务（如视觉定位）和图像级任务（如全局检索），并通过单次前向传播高效编码所有对象和图像。摘要未明确说明使用的具体数据集和模型架构细节。",
      "result": "论文报告了ObjEmbed在18个多样化基准测试中的优越性能，证明了其在语义区分上的强大能力。虽然摘要未提供具体数据如准确率提升百分比，但推断其在与基线方法的对比中表现出色，显著提升了细粒度对齐的效果。这些基准测试涵盖了视觉理解的不同方面，表明模型在多个任务上具有广泛适用性和改进。",
      "conclusion": "ObjEmbed的主要贡献在于提出一种结合语义和空间信息的对象导向多模态嵌入模型，支持视觉定位、局部和全局图像检索等多种任务。其学术价值是推动细粒度视觉语言对齐研究的发展，实际应用价值体现在提升多模态系统的准确性和效率。摘要未明确说明模型的局限性或未来工作方向，但潜在方向可能包括扩展至更多模态或优化计算效率。",
      "tags": [
        "Multimodal Language Model",
        "Object Embedding",
        "Semantic Matching",
        "IoU Prediction",
        "Visual Grounding"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:28.661383Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01752",
    "title": "WorldCup Sampling for Multi-bit LLM Watermarking",
    "authors": [
      "Yidan Wang",
      "Yubing Ren",
      "Yanan Cao",
      "Li Guo"
    ],
    "abstract": "As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.",
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01752.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01752",
    "published": "2026-02-02T07:36:38Z",
    "updated": "2026-02-02T07:36:38Z",
    "comment": null,
    "light_analysis": {
      "overview": "WorldCup提出了一种基于分层竞争机制的多比特水印框架，直接将消息比特嵌入LLM的令牌选择中，优化了容量、可检测性和文本质量。",
      "motivation": "随着大型语言模型生成的文本越来越接近人类水平，可靠归属成为关键需求。水印技术虽能提供解决方案，但现有多比特方法主要扩展零比特方案，依赖种子驱动转向，导致信息流间接、有效容量有限和解码性能不佳。这限制了水印在编码丰富来源信息时的实用性和效率，因此需要直接嵌入多比特消息的高效方法以提升性能。",
      "method": "WorldCup框架将LLM的令牌采样视为自然通信通道，通过互补信号指导的分层竞争机制直接嵌入消息比特。采用熵感知调制动态调整水印强度，以保持生成文本质量；并利用置信感知解码策略，在干扰下鲁棒恢复消息。关键创新在于直接嵌入机制，避免了间接信息流，并提高了有效容量和解码效率，具体实现可能涉及多个信号源的融合，但摘要未详细说明。",
      "result": "全面实验表明，WorldCup在容量、可检测性、鲁棒性、文本质量和解码效率方面实现了强平衡。与先前基线方法相比，WorldCup在所有指标上均持续更优，例如在标准评估中显示出更高的消息恢复准确率和更低的文本质量损失。但摘要未提供具体数值细节，仅强调其综合性能优势。",
      "conclusion": "论文贡献了WorldCup多比特水印框架，通过直接嵌入和分层竞争机制，显著提升了LLM水印的性能平衡。其学术价值在于提出了新颖的水印嵌入方法，解决现有技术瓶颈；实际应用价值在于增强了文本来源认证的可靠性和实用性。未来工作可探索更复杂的调制策略或扩展到更多模型，潜在局限性如对极端噪声的鲁棒性需进一步研究。",
      "tags": [
        "Multi-bit Watermarking",
        "Large Language Model",
        "Sampling Mechanism",
        "Entropy Modulation",
        "Robust Decoding"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:02.131436Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01751",
    "title": "MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network",
    "authors": [
      "Kunyi Fan",
      "Mengjie Chen",
      "Longlong Li",
      "Cunquan Qu"
    ],
    "abstract": "Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01751.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01751",
    "published": "2026-02-02T07:35:08Z",
    "updated": "2026-02-02T07:35:08Z",
    "comment": "Submitted to ICASSP 2026",
    "light_analysis": {
      "overview": "MGKAN提出了一种基于图Kolmogorov-Arnold网络的多模态模型，通过引入可学习的基础函数和集成多个网络视图，有效预测非对称药物-药物相互作用，提升了非线性建模能力。",
      "motivation": "预测药物-药物相互作用对于确保药理学治疗安全至关重要，但现有图神经网络模型主要依赖线性聚合和对称假设，限制了捕捉非线性和异质模式的能力。因此，需要一种新方法来改进预测准确性和处理复杂药物关系，以预防不良反应并提高治疗效果。摘要强调现有方法的不足在于建模非对称效应的能力有限，这推动了本研究的发展。",
      "method": "MGKAN采用图Kolmogorov-Arnold网络，用可学习的基础函数替代传统MLP变换，增强非线性建模。它集成三个网络视图：非对称DDI网络、共交互网络和生化相似性网络，并使用角色特定嵌入来保持方向语义。融合模块结合线性注意力和非线性变换，以提升表示能力。关键创新在于将KAN驱动的基础函数与多模态网络视图结合，以捕捉药理学依赖性。",
      "result": "在两个基准数据集上，MGKAN的性能优于七个最先进的基线模型。消融研究确认了各组件对预测准确性的贡献，案例研究表明其在建模方向性药物效应方面的有效性。摘要未明确说明具体指标如准确率提升，但强调了模型相对于基线的显著改进和验证。",
      "conclusion": "MGKAN成功开发了一种新颖的多模态图网络模型，用于非对称DDI预测。其主要贡献在于引入非线性建模和方向语义保留，学术价值是推动了图神经网络在药理学中的应用，实际应用中有助于提高药物安全性。未来工作方向可能包括扩展到更多数据类型或进行临床验证，但摘要未明确说明局限性。",
      "tags": [
        "Drug-Drug Interaction Prediction",
        "Graph Neural Network",
        "Kolmogorov-Arnold Network",
        "Multimodal Fusion",
        "Linear Attention"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:49.534563Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01750",
    "title": "Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking",
    "authors": [
      "Mohammad Beigi",
      "Ming Jin",
      "Junshan Zhang",
      "Qifan Wang",
      "Lifu Huang"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01750.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01750",
    "published": "2026-02-02T07:34:57Z",
    "updated": "2026-02-02T07:34:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Adversarial Reward Auditing框架，通过动态对抗游戏主动检测和缓解强化学习中的奖励黑客攻击。",
      "motivation": "RLHF易受奖励黑客攻击，模型利用奖励模型中的虚假相关性获取高分，但违背人类意图。现有缓解措施依赖静态防御，如固定检查或正则化，无法适应新出现的利用策略，导致模型对齐不可靠，限制了RLHF在安全关键应用中的使用。这一问题对AI安全至关重要，因为奖励黑客可能引发模型行为失控或产生有害输出，因此需要动态、自适应的方法来实时检测和缓解攻击，确保模型行为符合人类价值观。",
      "method": "ARA框架将奖励黑客重构为动态竞争游戏，分两阶段进行：首先，Hacker策略主动探索奖励模型漏洞，同时Auditor从潜在表示中学习检测利用行为；其次，Auditor-Guided RLHF门控奖励信号，惩罚检测到的黑客，将不可观测的黑客失败转化为可测量、可控制的信号。关键创新包括对抗性学习机制和门控奖励设计，无需依赖静态规则，能自适应新攻击策略。实验中使用多任务设置，涵盖奉承、冗长和代码游戏等场景，但摘要未明确说明具体数据集或模型架构细节。",
      "result": "在三种黑客场景实验中，ARA在所有基线中实现最佳对齐-效用权衡：将奉承行为降至接近SFT水平，同时提高帮助性；减少输出冗长，同时达到最高ROUGE-L分数；抑制代码游戏，同时提升Pass@1性能。具体数据显示，ARA显著优于传统静态方法，并展示跨领域泛化能力：在单一模型下，Hacker和Auditor能有效扩展到其他领域，如代码游戏训练后能在奉承场景中检测攻击，实现高效多域防御。",
      "conclusion": "ARA框架成功将奖励黑客从不可观测失败转化为可控信号，提升了RLHF的鲁棒性和安全性，其跨领域泛化能力为多域防御提供了高效方案。该研究的主要学术价值在于引入动态对抗机制解决对齐问题，实际应用价值在于增强AI系统的可靠部署。局限性方面，摘要未明确说明计算成本或特定场景适应性；未来工作可能包括扩展到更复杂攻击或结合其他对齐技术。",
      "tags": [
        "Reinforcement Learning from Human Feedback",
        "Reward Hacking",
        "Adversarial Learning",
        "Cross-Domain Generalization",
        "Auditor-Guided RLHF"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:23.256353Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01749",
    "title": "Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives",
    "authors": [
      "Lin Chen",
      "Samuel Drapeau",
      "Fanghao Shao",
      "Xuekai Zhu",
      "Bo Xue",
      "Yunchong Song",
      "Mathieu Laurière",
      "Zhouhan Lin"
    ],
    "abstract": "Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \\times$ increase in the number of discovered modes.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01749.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01749",
    "published": "2026-02-02T07:34:30Z",
    "updated": "2026-02-02T07:34:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了α-GFNs，通过Markov链视角控制GFlowNets中的探索-利用权衡，以增强模式发现能力。",
      "motivation": "研究动机源于现有GFlowNet目标隐含固定了正向和反向策略的平等混合，这限制了训练过程中的探索-利用权衡，可能导致模式发现能力不足。通过揭示GFlowNets与Markov链的联系，论文说明了这种约束的根源，并指出现有方法缺乏灵活调整探索与利用的能力，影响了在复杂任务中的性能提升。这一问题的解决对于优化生成模型和强化学习应用具有重要意义。",
      "method": "研究方法基于理论分析，建立了GFlowNet目标与Markov链可逆性的等价性，提供了一个框架来适应Markov链属性到GFlowNets中。核心创新是提出了α-GFNs，它通过引入可调参数α来推广混合策略，从而直接控制探索-利用动态，增强模式发现能力，同时确保收敛到唯一流。该方法不依赖特定数据集，而是通过参数化调整策略灵活性，改进了GFlowNets的训练机制。",
      "result": "在各种基准测试中，包括Set、Bit Sequence和Molecule Generation，α-GFN目标一致优于之前的GFlowNet目标。具体表现是发现模式数量实现了高达10倍的增加，这表明方法在模式发现能力上有显著提升。实验结果通过比较基线方法验证了α-GFNs在改善探索-利用权衡方面的有效性，突显了其在实际应用中的性能优势。",
      "conclusion": "论文的主要贡献是通过Markov链视角揭示了GFlowNets中探索-利用约束的根源，并提出了α-GFNs来直接控制这一权衡，从而增强模式发现能力。学术价值在于提供了新的理论框架和实用方法，对生成模型和强化学习领域有应用潜力。摘要未明确说明局限性，但未来工作可能涉及进一步优化参数调整或扩展到更广泛的任务中。",
      "tags": [
        "Generative Flow Network",
        "Markov Chain",
        "Exploration-Exploitation",
        "Mode Discovery",
        "α-GFN"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:17.660804Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01747",
    "title": "Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training",
    "authors": [
      "Hongseok Choi",
      "Serynn Kim",
      "Wencke Liermann",
      "Jin Seong",
      "Jin-Xia Huang"
    ],
    "abstract": "Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01747.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01747",
    "published": "2026-02-02T07:29:15Z",
    "updated": "2026-02-02T07:29:15Z",
    "comment": "22 pages, 4 figures",
    "light_analysis": {
      "overview": "本研究提出一种结合两阶段微调、分数对齐和自训练的方法，显著提升自动论文评分系统在数据稀缺和全数据设置下的性能。",
      "motivation": "自动论文评分（AES）在教育中扮演关键角色，提供可扩展和高效的评估工具，但真实场景中标签数据的极端稀缺严重限制了稳健AES系统的开发和应用。现有方法往往依赖大量标注数据，在数据有限时难以保持准确性，这阻碍了实际部署。本研究旨在解决数据稀缺下的AES性能问题，通过创新技术提升系统在有限数据和全数据设置下的表现，以促进教育评估的实用性和效率。",
      "method": "论文提出了三种关键技术：首先，两阶段微调策略利用低秩适应，使AES模型更好地适应特定提示的论文；其次，分数对齐技术通过优化预测分数与真实分数分布的一致性，提升评分准确性；第三，采用不确定性感知的自训练，利用未标注数据生成伪标签样本，扩展训练集并缓解标签噪声传播。这些技术在DualBERT模型上实现，并在ASAP++数据集上进行实验验证，关键创新在于整合这些方法以增强模型在数据稀缺环境下的鲁棒性。",
      "result": "实验结果表明，在32-data设置下，三种技术均能提升性能，其整合使用后，仅使用约1000个标签样本，就实现了全数据性能的91.2%。此外，分数对齐技术不仅在有限数据设置中有效，在全数据设置中集成到DualBERT后，也取得了最先进的性能，验证了其鲁棒性和有效性。对比基线方法，这些技术显著提高了评分准确性和一致性，为AES系统提供了高效解决方案。",
      "conclusion": "本研究的主要贡献在于提出并整合了三种技术来增强自动论文评分系统，特别在数据稀缺场景下表现出色。学术上，它扩展了AES方法，结合了微调、分布对齐和半监督学习；实际应用中，为教育评估提供了更可行的解决方案，减少了数据依赖。未来工作可探索更多数据集和应用场景，以进一步优化和推广该方法，摘要未明确说明具体局限性。",
      "tags": [
        "Automated Essay Scoring",
        "Low-Rank Adaptation",
        "Score Alignment",
        "Self-Training",
        "DualBERT"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:29.651899Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01746",
    "title": "Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment",
    "authors": [
      "Hongyi Peng",
      "Han Yu",
      "Xiaoxiao Li",
      "Qiang Yang"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) is widely used for federated fine-tuning. Yet under non-IID settings, it can substantially underperform full-parameter fine-tuning. Through with-high-probability robustness analysis, we uncover that this gap can be attributed to two coupled mismatches: (i) update-space mismatch, where clients optimize in a low-rank subspace but aggregation occurs in the full space; and (ii) optimizer-state mismatch, where unsynchronized adaptive states amplify drift across rounds. We propose FedGaLore, which combines client-side GaLore-style gradient-subspace optimization with server-side drift-robust synchronization of projected second-moment states via spectral shared-signal extraction, to address this challenge. Across NLU, vision, and NLG benchmarks, FedGaLore improves robustness and accuracy over state-of-the-art federated LoRA baselines in non-IID settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01746.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01746",
    "published": "2026-02-02T07:27:44Z",
    "updated": "2026-02-02T07:27:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出FedGaLore方法，通过子空间和状态对齐解决LoRA在数据异构联邦学习中的性能下降问题。",
      "motivation": "LoRA在联邦学习中广泛用于模型微调，但在非独立同分布数据设置下，其性能远低于全参数微调，这在实际应用中构成挑战。数据异构性是联邦学习的核心问题，影响模型收敛和泛化能力。现有联邦LoRA方法存在更新空间和优化器状态不匹配的问题，导致在非IID环境中鲁棒性不足，限制了效率和准确性提升。因此，研究如何改进LoRA以应对数据异构性具有重要意义，以推动分布式机器学习的实用化。",
      "method": "论文提出FedGaLore方法，核心是结合客户端侧的GaLore风格梯度子空间优化和服务器侧通过谱共享信号提取实现的投影第二矩状态同步。客户端在低秩梯度子空间中进行优化，以解决更新空间不匹配；服务器同步自适应优化器状态，以减少状态不匹配导致的轮次间漂移。通过高概率鲁棒性分析识别出两个耦合问题，并设计对齐机制。该方法在联邦学习框架下实现，适用于NLU、视觉和NLG等多种任务基准，通过技术整合提升鲁棒性。",
      "result": "在自然语言理解、视觉和自然语言生成等基准测试中，FedGaLore在非IID设置下显著提高了鲁棒性和准确性。实验结果表明，与最先进的联邦LoRA基线相比，FedGaLore表现出更优的性能，但摘要未明确说明具体准确率提升数值或效率改进百分比。这表明该方法能有效缓解数据异构性带来的挑战，在多个领域验证了其有效性，优于现有优化方法。",
      "conclusion": "本研究的主要贡献是提出FedGaLore，通过子空间和状态对齐机制解决了LoRA在数据异构联邦学习中的性能瓶颈。该研究具有学术价值，为联邦优化提供了新思路；实际应用中，可提升分布式环境下的模型微调效率和效果。尽管在多个基准上验证了有效性，但未来工作可能包括扩展到更复杂场景或进一步优化计算开销，以应对大规模部署需求。",
      "tags": [
        "Federated Learning",
        "Low-Rank Adaptation",
        "Non-IID Data",
        "Gradient Subspace Optimization",
        "Spectral Shared-Signal Extraction"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:32.066753Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01745",
    "title": "Probability-Entropy Calibration: An Elastic Indicator for Adaptive Fine-tuning",
    "authors": [
      "Wenhao Yu",
      "Shaohang Wei",
      "Jiahong Liu",
      "Yifan Li",
      "Minda Hu",
      "Aiwei Liu",
      "Hao Zhang",
      "Irwin King"
    ],
    "abstract": "Token-level reweighting is a simple yet effective mechanism for controlling supervised fine-tuning, but common indicators are largely one-dimensional: the ground-truth probability reflects downstream alignment, while token entropy reflects intrinsic uncertainty induced by the pre-training prior. Ignoring entropy can misidentify noisy or easily replaceable tokens as learning-critical, while ignoring probability fails to reflect target-specific alignment. RankTuner introduces a probability--entropy calibration signal, the Relative Rank Indicator, which compares the rank of the ground-truth token with its expected rank under the prediction distribution. The inverse indicator is used as a token-wise Relative Scale to reweight the fine-tuning objective, focusing updates on truly under-learned tokens without over-penalizing intrinsically uncertain positions. Experiments on multiple backbones show consistent improvements on mathematical reasoning benchmarks, transfer gains on out-of-distribution reasoning, and pre code generation performance over probability-only or entropy-only reweighting baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01745.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01745",
    "published": "2026-02-02T07:27:19Z",
    "updated": "2026-02-02T07:27:19Z",
    "comment": null,
    "light_analysis": {
      "overview": "RankTuner提出了一种新的概率-熵校准方法，通过相对排名指标优化监督微调中的令牌级重新加权，提升模型在下游任务的适应效率。",
      "motivation": "研究动机源于现有令牌级重新加权方法的不足。在监督微调中，常用指标如ground-truth概率和token熵分别反映下游对齐和预训练先验引起的不确定性，但单一使用这些一维指标会导致问题：忽略熵可能将噪声令牌误判为学习关键，增加过拟合风险；忽略概率则无法确保模型与目标任务的精准对齐，影响泛化能力。因此，需要一种综合校准机制来平衡概率和熵，以提高微调的精准性和鲁棒性。",
      "method": "论文提出RankTuner方法，核心是引入Relative Rank Indicator作为概率-熵校准信号。该指标通过比较ground-truth令牌在预测分布中的实际排名与其期望排名，生成一个相对尺度用于token-wise重新加权微调目标。关键创新点在于弹性调整损失函数更新，将重点放在真正未学习的令牌上，同时避免过度惩罚那些因预训练先验而内在不确定的位置。技术实现涉及在多个骨干模型架构上进行实验，具体数据集摘要未明确说明，但聚焦于推理和生成任务。",
      "result": "实验结果表明，在多个骨干网络上，RankTuner在数学推理基准上实现了持续的性能改进，并在分布外推理任务上表现出转移增益，增强了模型的泛化能力。代码生成任务中，其性能也显著优于仅使用概率或仅使用熵的重新加权基线方法。摘要未提供具体的准确率或效率数据，但强调了相对于基线的整体优势，证明了校准信号的有效性和适应性。",
      "conclusion": "论文的主要贡献是提出了一种概率-熵校准的弹性指标，用于自适应监督微调，有效提升了模型在下游任务如数学推理和代码生成中的性能与泛化能力。研究具有重要学术价值，为微调策略提供了新思路，增强了AI模型的适应效率和鲁棒性；在实际应用中，可优化大型语言模型的部署效果。潜在局限性或未来工作方向摘要未明确说明，但可能涉及扩展到更多任务类型或进一步优化指标计算。",
      "tags": [
        "Supervised Fine-tuning",
        "Token Reweighting",
        "Probability-Entropy Calibration",
        "Relative Rank Indicator",
        "Mathematical Reasoning"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:37.544164Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01744",
    "title": "Softmax Linear Attention: Reclaiming Global Competition",
    "authors": [
      "Mingwei Xu",
      "Xuan Lin",
      "Xinnan Guo",
      "Wanqing Xu",
      "Wanyun Cui"
    ],
    "abstract": "While linear attention reduces the quadratic complexity of standard Transformers to linear time, it often lags behind in expressivity due to the removal of softmax normalization. This omission eliminates \\emph{global competition}, a critical mechanism that enables models to sharply focus on relevant information amidst long-context noise. In this work, we propose \\textbf{Softmax Linear Attention (SLA)}, a framework designed to restore this competitive selection without sacrificing efficiency. By lifting the softmax operation from the token level to the head level, SLA leverages attention heads as coarse semantic slots, applying a competitive gating mechanism to dynamically select the most relevant subspaces. This reintroduces the ``winner-take-all'' dynamics essential for precise retrieval and robust long-context understanding. Distinct from prior methods that focus on refining local kernel functions, SLA adopts a broader perspective by exploiting the higher-level multi-head aggregation structure. Extensive experiments demonstrate that SLA consistently enhances state-of-the-art linear baselines (RetNet, GLA, GDN) across language modeling and long-context benchmarks, particularly in challenging retrieval scenarios where it significantly boosts robustness against noise, validating its capability to restore precise focus while maintaining linear complexity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01744.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01744",
    "published": "2026-02-02T07:25:03Z",
    "updated": "2026-02-02T07:25:03Z",
    "comment": "11 pages,4 figures",
    "light_analysis": {
      "overview": "本文提出Softmax Linear Attention (SLA) 框架，通过将softmax操作提升至注意力头级别，恢复线性注意力中的全局竞争机制，在维持线性复杂度的同时提升表达能力。",
      "motivation": "线性注意力技术将标准Transformer的二次计算复杂度降低至线性，但移除softmax归一化导致全局竞争机制缺失，使得模型在长上下文场景中难以有效聚焦相关信息和过滤噪声。全局竞争是精确信息检索和鲁棒理解的关键，现有线性注意力方法因缺少此机制而表达能力受限，影响在复杂应用中的性能。本研究旨在不牺牲效率的前提下，解决这一权衡问题，以提升模型在长序列处理中的表现。",
      "method": "SLA框架的核心方法是将softmax操作从token级别提升到head级别，利用注意力头作为粗略的语义槽，并引入竞争门控机制动态选择最相关的子空间。这一设计恢复了“赢家通吃”的动态，支持精确检索和鲁棒长上下文理解。区别于先前专注于优化局部核函数的方法，SLA采用更高层次的多头聚合结构作为竞争平台，通过轻量级修改保持线性计算复杂度。摘要未明确说明具体使用的数据集或模型架构细节，但强调了基于现有多头注意力架构的创新。",
      "result": "实验表明，SLA在语言建模和长上下文基准测试中，持续增强了RetNet、GLA、GDN等先进线性基线方法的性能。特别是在挑战性检索场景下，SLA显著提升了模型对噪声的鲁棒性，验证了其恢复精确焦点并维持线性复杂度的能力。摘要未提供具体的准确率或效率改进数值，但作者强调SLA在多个基准上的普遍提升，表明其在保持效率的同时强化了表达力和鲁棒性。",
      "conclusion": "本研究的主要贡献是提出了SLA框架，成功将全局竞争机制重新引入线性注意力，平衡了计算效率与表达能力。学术上，它为改进线性注意力提供了基于多头聚合结构的新视角；实践中，有助于开发高效且精确的长上下文处理模型。摘要未明确说明研究的局限性或未来工作方向，但潜在方向可能包括进一步优化门控机制或扩展到更多序列建模任务，以增强泛化能力。",
      "tags": [
        "Linear Attention",
        "Softmax Normalization",
        "Global Competition",
        "Multi-head Attention",
        "Retrieval Scenarios"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:01.211171Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01741",
    "title": "Tail-Aware Post-Training Quantization for 3D Geometry Models",
    "authors": [
      "Sicheng Pan",
      "Chen Tang",
      "Shuzhao Xie",
      "Ke Yang",
      "Weixiang Zhang",
      "Jiawei Li",
      "Bin Chen",
      "Shu-Tao Xia",
      "Zhi Wang"
    ],
    "abstract": "The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\\mathcal{O}(N)$ to $\\mathcal{O}(\\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01741.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01741",
    "published": "2026-02-02T07:21:15Z",
    "updated": "2026-02-02T07:21:15Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出TAPTQ，一种针对3D几何模型的尾感知后训练量化管道，旨在解决传统方法在3D模型上的失效问题。",
      "motivation": "随着3D几何模型复杂度和规模的迅速增长，在资源受限平台上部署这些模型面临巨大挑战。传统后训练量化方法主要针对2D视觉变换器优化，但由于3D模型特征分布复杂且校准开销大，这些方法在3D场景中效果不佳。因此，开发专门针对3D几何学习的高效量化方法至关重要，以提高模型推理效率并降低部署成本，现有方法在准确性和效率上存在明显不足。",
      "method": "论文提出TAPTQ方法，包含三个关键技术：首先，采用渐进粗到细校准构建策略，构建紧凑子集以平衡统计纯度和几何代表性，解决3D数据集规模瓶颈。其次，将量化区间搜索重新定义为优化问题，并引入基于三元搜索的求解器，将计算复杂度从O(N)降低到O(log N)，加速部署。第三，提出TRE引导的模块补偿机制，使用尾相对误差度量自适应识别和纠正对长尾激活异常值敏感的模块中的失真，减少量化误差累积。",
      "result": "在VGGT和Pi3基准测试上进行广泛实验，结果显示TAPTQ在准确率方面一致优于最先进的后训练量化方法，同时显著减少了校准时间。摘要未提供具体性能指标数字，但表明该方法在保持高精度的同时提高了效率，验证了其在3D几何模型量化中的优越性，相比于基线方法有显著改进。",
      "conclusion": "TAPTQ的主要贡献是针对3D几何模型开发了一个高效的尾感知后训练量化管道，解决了传统量化方法的局限性。该研究具有重要的学术价值，推动了3D模型优化技术的发展，并具有实际应用价值，有助于在资源受限设备上部署复杂3D模型。摘要未明确说明局限性或未来工作方向，但代码即将发布，为进一步研究提供基础。",
      "tags": [
        "Post-Training Quantization",
        "3D Geometry Models",
        "Calibration Strategy",
        "Ternary Search",
        "Tail Relative Error"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:37.360337Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01740",
    "title": "MACD: Model-Aware Contrastive Decoding via Counterfactual Data",
    "authors": [
      "Qixin Xiao",
      "Kun Zhou"
    ],
    "abstract": "Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01740.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01740",
    "published": "2026-02-02T07:21:02Z",
    "updated": "2026-02-02T07:21:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出 MACD 方法，通过结合模型感知的反事实数据与对比解码，有效减少视频语言模型的幻觉问题。",
      "motivation": "视频语言模型在视觉证据弱、模糊或有偏时容易产生幻觉，即生成看似合理但无根据的内容，这降低了模型输出的可靠性。现有解码方法如对比解码依赖于随机扰动来构建对比数据，但难以精确控制导致幻觉的视觉线索或与模型弱点对齐，导致幻觉缓解效果有限。因此，开发更精准的方法来识别和解决幻觉问题具有重要性和迫切性，以提升模型在实际应用中的准确性和可信度。",
      "method": "论文提出 Model-aware Counterfactual Data based Contrastive Decoding (MACD)，该方法结合模型引导的反事实构建与解码。核心创新点在于使用视频语言模型的自反馈机制，识别导致幻觉的关键对象区域，生成目标化的反事实输入（在对象级别而非随机帧或时间修改）。这些模型感知的反事实数据被集成到对比解码中，在解码过程中强制进行基于证据的令牌选择，从而减少幻觉。实验中使用包括 Qwen 和 InternVL 家族在内的多种视频语言模型，并在 EventHallusion 等数据集上进行验证。",
      "result": "实验在 EventHallusion、MVBench、Perception-test 和 Video-MME 等数据集上进行。结果显示，MACD 能够一致减少幻觉现象，同时保持或提高任务准确性，适用于多种视频语言模型。与基线方法如对比解码相比，MACD 在涉及小对象、被遮挡对象或共现对象的挑战性场景中表现尤为有效，显著改善了模型的性能，但没有提供具体的数值指标，摘要未明确说明。",
      "conclusion": "MACD 通过模型感知的反事实数据结合解码策略，有效减少了视频语言模型的幻觉，提升了输出的可靠性和准确性。该研究在解码方法上提供了创新，具有重要的学术价值，有助于推动视频语言模型的优化；在实际应用中，能增强模型在复杂视觉任务中的性能。摘要未明确说明潜在局限性或未来工作方向，但可推断未来可能涉及更广泛的数据集验证或与其他技术的结合。",
      "tags": [
        "Video Language Models",
        "Contrastive Decoding",
        "Counterfactual Data",
        "Hallucination Mitigation",
        "Object-level Modifications"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:41.921858Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01738",
    "title": "Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models",
    "authors": [
      "Yue Zhou",
      "Xinan He",
      "Kaiqing Lin",
      "Bing Fan",
      "Feng Ding",
      "Bin Li"
    ],
    "abstract": "While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01738.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01738",
    "published": "2026-02-02T07:20:02Z",
    "updated": "2026-02-02T07:20:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出使用视觉基础模型冻结特征训练的简单线性分类器，实现了AI生成图像检测的泛化能力和新的SOTA性能。",
      "motivation": "当前专门化AI生成图像检测器在精心策划的基准测试中表现优异，但在现实野外场景中性能急剧下降，揭示了过拟合问题和泛化能力不足。这凸显了开发更鲁棒检测方法的必要性，以应对真实世界图像的多样性和复杂性。",
      "method": "本研究采用现代视觉基础模型，包括Perception Encoder、MetaCLIP 2和DINOv3，提取冻结特征后训练一个线性分类器进行检测。核心创新在于简化架构设计，利用大规模预训练模型的特征表示，而非依赖复杂网络。摘要未明确说明具体数据集，但强调了预训练数据的规模和多样性是关键。",
      "result": "实验结果表明，该方法在传统基准测试中与专门化检测器准确率相当，在未见生成器和挑战性野外数据集上，准确率提升超过30%，显著超越了基线方法。这证明了其强大的泛化能力和对现实场景的适应性。",
      "conclusion": "研究贡献在于展示基础模型特征能有效提升AIGI检测的泛化性，倡导从静态基准过拟合转向利用基础模型的动态世界知识。局限性包括对重新捕获、传输的敏感性，以及对VAE重建和局部编辑的盲点，为未来改进指明了方向。",
      "tags": [
        "AIGI Detection",
        "Vision Foundation Models",
        "Linear Classifier",
        "Feature Freezing",
        "Self-Supervised Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:47.540549Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01736",
    "title": "Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting",
    "authors": [
      "Qinwei Ma",
      "Jingzhe Shi",
      "Jiahao Qiu",
      "Zaiwen Yang"
    ],
    "abstract": "Recent work has questioned the effectiveness and robustness of neural network architectures for time series forecasting tasks. We summarize these concerns and analyze groundly their inherent limitations: i.e. the irreconcilable conflict between single (or few similar) domains SOTA and generalizability over general domains for time series forecasting neural network architecture designs. Moreover, neural networks architectures for general domain time series forecasting are becoming more and more complicated and their performance has almost saturated in recent years. As a result, network architectures developed aiming at fitting general time series domains are almost not inspiring for real world practices for certain single (or few similar) domains such as Finance, Weather, Traffic, etc: each specific domain develops their own methods that rarely utilize advances in neural network architectures of time series community in recent 2-3 years. As a result, we call for the time series community to shift focus away from research on time series neural network architectures for general domains: these researches have become saturated and away from domain-specific SOTAs over time. We should either (1) focus on deep learning methods for certain specific domain(s), or (2) turn to the development of meta-learning methods for general domains.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01736.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01736",
    "published": "2026-02-02T07:19:16Z",
    "updated": "2026-02-02T07:19:16Z",
    "comment": "14 pages, 3 figures, 2 tables",
    "light_analysis": {
      "overview": "该论文质疑通用时间序列预测神经网络架构的有效性，呼吁研究重心转向领域特定方法或元学习。",
      "motivation": "研究的动机是解决时间序列预测中通用神经网络架构的局限性。现有方法试图设计一个架构适应所有领域，但这导致泛化能力差，与特定领域（如金融、天气、交通）的实际需求脱节。近年来，神经网络架构变得复杂但性能饱和，而特定领域自发展方法很少利用社区进展，表明通用架构研究已远离实用，需要转向更聚焦的研究方向以提高预测效果。",
      "method": "论文采用立场陈述和文献分析方法，通过总结现有研究关切，分析通用神经网络架构的固有局限性，如泛化冲突。然而，摘要未明确说明具体的技术路线或实验方法，更多是提出研究方向建议，例如专注于特定领域的深度学习方法或开发元学习技术。",
      "result": "摘要未提及具体的实验结果或性能数据，但指出通用神经网络架构的性能已接近饱和，与特定领域的先进方法相比缺乏实用性。这基于文献分析，强调需要更有效的评估来支持通用架构的局限性，建议未来研究应聚焦于领域特异性优化或元学习方法开发。",
      "conclusion": "论文的主要结论是通用时间序列预测神经网络架构已饱和，应转向领域特定方法或元学习研究。这具有重要学术价值，可促进更实用和高效的预测技术发展，实际应用中可能提升各领域准确性。局限性在于未提供新方法细节，未来工作可探索元学习算法的实现或跨领域适应策略。",
      "tags": [
        "Time Series Forecasting",
        "Neural Network Architectures",
        "Domain-Specific Learning",
        "Meta-Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:00.214174Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01734",
    "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
    "authors": [
      "Lianhai Ren",
      "Yucheng Ding",
      "Xiao Liu",
      "Qianxiao Li",
      "Peng Cheng",
      "Yeyun Gong"
    ],
    "abstract": "Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via $μ$P, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01734.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01734",
    "published": "2026-02-02T07:18:45Z",
    "updated": "2026-02-02T07:18:45Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出MSign优化器，通过定期恢复权重矩阵的稳定秩，有效防止大型语言模型训练中的梯度爆炸问题，提升训练稳定性。",
      "motivation": "大型语言模型预训练中的训练不稳定是关键挑战，常表现为梯度爆炸，浪费大量计算资源。现有优化器可能无法有效处理稳定秩下降和相邻层雅可比对齐等问题，这些现象在模型规模增大时导致训练失败，因此需开发新方法来预防崩溃，以提高训练效率和资源利用率。摘要未明确说明现有方法的具体不足，但强调了问题的重要性和研究必要性。",
      "method": "研究基于5M参数NanoGPT模型，通过μP缩放识别训练崩溃前的两个关键现象：权重矩阵稳定秩（Frobenius范数平方与谱范数平方之比）的快速下降和相邻层雅可比对齐的增加。理论证明这些条件共同导致梯度范数随网络深度指数增长。为打破此机制，提出MSign优化器，它定期应用矩阵符号操作来恢复稳定秩，从而防止梯度爆炸。实验覆盖从5M到3B参数的模型，验证方法的有效性。",
      "result": "在从5M到3B参数的大型语言模型上进行实验，MSign能有效防止训练失败，计算开销小于7.0%，显示了较高的效率。摘要未提供具体性能指标如准确率提升，但通过稳定训练过程，它减少了梯度爆炸的发生，避免了资源浪费。与基线方法相比，MSign在防止崩溃方面表现更优，但摘要未明确说明详细对比数据。",
      "conclusion": "本研究的主要贡献是提出了MSign优化器，通过恢复稳定秩解决了大型语言模型训练中的不稳定问题。学术上，提供了理论分析，揭示了训练崩溃的机制；实际上，可以减少训练失败，提高计算资源利用率和训练效率。未来工作可能包括进一步优化计算开销或扩展到更多模型类型，但摘要未明确说明具体局限性或方向。",
      "tags": [
        "Large Language Models",
        "Training Instability",
        "Stable Rank Restoration",
        "MSign Optimizer",
        "Matrix Sign Operation"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:14.992278Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01725",
    "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
    "authors": [
      "Yurun Chen",
      "Zeyi Liao",
      "Ping Yin",
      "Taotao Xie",
      "Keting Yin",
      "Shengyu Zhang"
    ],
    "abstract": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01725.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01725",
    "published": "2026-02-02T07:04:06Z",
    "updated": "2026-02-02T07:04:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了SafePred预测性护栏框架，通过世界模型对齐未来风险与当前决策，以确保计算机使用代理的行为安全。",
      "motivation": "随着计算机使用代理在复杂现实环境中的广泛部署，长期风险常导致严重且不可逆的后果。现有护栏多采用反应式方法，仅能在当前观察空间约束代理行为，虽能预防短期风险如点击钓鱼链接，但无法主动避免延迟出现的长期风险，例如清理日志导致未来审计不可追溯。因此，当前方法在处理长期风险方面存在明显不足，需要一种预测性机制来提前识别和规避这些风险，以提高代理系统的整体安全性。",
      "method": "SafePred采用预测性护栏方法，核心是建立风险到决策的循环，对齐预测的未来风险与当前决策。它支持两个关键能力：短期和长期风险预测，基于安全政策作为风险预测基础，利用世界模型的预测能力生成风险的语义表示，从而识别和剪枝可能导致高风险状态的动作；决策优化通过步骤级干预和任务级重规划，将预测的风险转化为可执行的安全决策指导。创新点在于整合世界模型进行风险预测，并通过循环机制实现风险与决策的动态对齐。",
      "result": "广泛实验表明，SafePred显著减少了高风险行为，安全性能达到97.6%以上，并且与反应式基线方法相比，任务效用提升了高达21.4%。这证明了其在有效控制风险的同时，能优化代理的执行效率，突出了预测性方法相对于传统反应式护栏的优势。",
      "conclusion": "本研究的主要贡献是提出了SafePred框架，通过预测未来风险并优化决策，解决了计算机使用代理的长期安全问题。该研究具有重要的学术价值，为代理安全控制提供了新方法，同时在实际应用中可提升代理的可靠性和效率；未来工作可探索更广泛的环境应用或进一步优化预测精度，以应对更多复杂场景。",
      "tags": [
        "World Model",
        "Risk Prediction",
        "Decision Optimization",
        "Safety Guardrails",
        "Computer-using Agents"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:23.862097Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2602.01724",
    "title": "DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation",
    "authors": [
      "Tushar Anand",
      "Maheswar Bora",
      "Antitza Dantcheva",
      "Abhijit Das"
    ],
    "abstract": "In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01724.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01724",
    "published": "2026-02-02T07:03:07Z",
    "updated": "2026-02-02T07:03:07Z",
    "comment": "IEEE International Conference on Robotics and Automation 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01723",
    "title": "FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization",
    "authors": [
      "Yikun Ma",
      "Yiqing Li",
      "Jingwen Ye",
      "Zhongkai Wu",
      "Weidong Zhang",
      "Lin Gao",
      "Zhi Jin"
    ],
    "abstract": "Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01723.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01723",
    "published": "2026-02-02T07:00:42Z",
    "updated": "2026-02-02T07:00:42Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01719",
    "title": "COMI: Coarse-to-fine Context Compression via Marginal Information Gain",
    "authors": [
      "Jiwei Tang",
      "Shilei Liu",
      "Zhicheng Zhang",
      "Yujin Yuan",
      "Libin Zheng",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01719.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01719",
    "published": "2026-02-02T06:57:22Z",
    "updated": "2026-02-02T06:57:22Z",
    "comment": "Accepted at ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01718",
    "title": "Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift",
    "authors": [
      "Sora Nakai",
      "Youssef Fadhloun",
      "Kacem Mathlouthi",
      "Kotaro Yoshida",
      "Ganesh Talluri",
      "Ioannis Mitliagkas",
      "Hiroki Naganuma"
    ],
    "abstract": "Generalization remains a central yet unresolved challenge in deep learning, particularly the ability to predict a model's performance beyond its training distribution using quantities available prior to test-time evaluation. Building on the large-scale study of Jiang et al. (2020). and concerns by Dziugaite et al. (2020). about instability across training configurations, we benchmark the robustness of generalization measures beyond IID regime. We train small-to-medium models over 10,000 hyperparameter configurations and evaluate more than 40 measures computable from the trained model and the available training data alone. We significantly broaden the experimental scope along multiple axes: (i) extending the evaluation beyond the standard IID setting to include benchmarking for robustness across diverse distribution shifts, (ii) evaluating multiple architectures and training recipes, and (iii) newly incorporating calibration- and information-criteria-based measures to assess their alignment with both IID and OOD generalization. We find that distribution shifts can substantially alter the predictive performance of many generalization measures, while a smaller subset remains comparatively stable across settings.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01718.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01718",
    "published": "2026-02-02T06:56:33Z",
    "updated": "2026-02-02T06:56:33Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01717",
    "title": "BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition",
    "authors": [
      "Hyunsik Kim",
      "Haeri Kim",
      "Munhak Lee",
      "Kyungmin Lee"
    ],
    "abstract": "Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01717.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01717",
    "published": "2026-02-02T06:56:27Z",
    "updated": "2026-02-02T06:56:27Z",
    "comment": "accepted to ICASSP 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01716",
    "title": "Mechanistic Indicators of Steering Effectiveness in Large Language Models",
    "authors": [
      "Mehdi Jafari",
      "Hao Xue",
      "Flora Salim"
    ],
    "abstract": "Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01716.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01716",
    "published": "2026-02-02T06:56:22Z",
    "updated": "2026-02-02T06:56:22Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01714",
    "title": "MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark",
    "authors": [
      "Mouath Abu-Daoud",
      "Leen Kharouf",
      "Omar El Hajj",
      "Dana El Samad",
      "Mariam Al-Omari",
      "Jihad Mallat",
      "Khaled Saleh",
      "Nizar Habash",
      "Farah E. Shamout"
    ],
    "abstract": "Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01714.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01714",
    "published": "2026-02-02T06:52:20Z",
    "updated": "2026-02-02T06:52:20Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01711",
    "title": "Optimizing Prompts for Large Language Models: A Causal Approach",
    "authors": [
      "Wei Chen",
      "Yanbin Fang",
      "Shuran Fu",
      "Fasheng Xu",
      "Xuan Wei"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01711.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01711",
    "published": "2026-02-02T06:37:11Z",
    "updated": "2026-02-02T06:37:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01710",
    "title": "Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis",
    "authors": [
      "Salma Zahran",
      "Zhou Ao",
      "Zhengyang Zhang",
      "Chen Chi",
      "Chenchen Yuan",
      "Yanming Wang"
    ],
    "abstract": "Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.",
    "categories": [
      "cs.CV",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01710.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01710",
    "published": "2026-02-02T06:36:06Z",
    "updated": "2026-02-02T06:36:06Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01709",
    "title": "ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation",
    "authors": [
      "Xingshan Zeng",
      "Lingzhi Wang",
      "Weiwen Liu",
      "Liangyou Li",
      "Yasheng Wang",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "abstract": "Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \\emph{\\name}, \\emph{\\underline{A}gentic \\underline{R}isk-Aware \\underline{T}est-Time Scaling via \\underline{I}terative \\underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \\emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01709.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01709",
    "published": "2026-02-02T06:33:22Z",
    "updated": "2026-02-02T06:33:22Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01708",
    "title": "Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory",
    "authors": [
      "Langyuan Cui",
      "Chun Kai Ling",
      "Hwee Tou Ng"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \\textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01708.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01708",
    "published": "2026-02-02T06:33:18Z",
    "updated": "2026-02-02T06:33:18Z",
    "comment": "23 pages, 10 figures, under review at ICML 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01705",
    "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner",
    "authors": [
      "Haoqiang Kang",
      "Yizhe Zhang",
      "Nikki Lijing Kuang",
      "Yi-An Ma",
      "Lianhui Qin"
    ],
    "abstract": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01705.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01705",
    "published": "2026-02-02T06:26:31Z",
    "updated": "2026-02-02T06:26:31Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01703",
    "title": "$\\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality",
    "authors": [
      "Pengyu Li",
      "Lingling Zhang",
      "Zhitao Gao",
      "Yanrui Wu",
      "Yuxuan Dong",
      "Huan Liu",
      "Bifan Wei",
      "Jun Liu"
    ],
    "abstract": "While Large Language Models (LLMs) have achieved remarkable capabilities, they unintentionally memorize sensitive data, posing critical privacy and security risks. Machine unlearning is pivotal for mitigating these risks, yet existing paradigms face a fundamental dilemma: aggressive unlearning often induces catastrophic forgetting that degrades model utility, whereas conservative strategies risk superficial forgetting, leaving models vulnerable to adversarial recovery. To address this trade-off, we propose $\\textbf{AGT$^{AO}$}$ (Adversarial Gating Training with Adaptive Orthogonality), a unified framework designed to reconcile robust erasure with utility preservation. Specifically, our approach introduces $\\textbf{Adaptive Orthogonality (AO)}$ to dynamically mitigate geometric gradient conflicts between forgetting and retention objectives, thereby minimizing unintended knowledge degradation. Concurrently, $\\textbf{Adversarial Gating Training (AGT)}$ formulates unlearning as a latent-space min-max game, employing a curriculum-based gating mechanism to simulate and counter internal recovery attempts. Extensive experiments demonstrate that $\\textbf{AGT$^{AO}$}$ achieves a superior trade-off between unlearning efficacy (KUR $\\approx$ 0.01) and model utility (MMLU 58.30). Code is available at https://github.com/TiezMind/AGT-unlearning.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01703.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01703",
    "published": "2026-02-02T06:19:27Z",
    "updated": "2026-02-02T06:19:27Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01699",
    "title": "Mitigating loss of control in advanced AI systems through instrumental goal trajectories",
    "authors": [
      "Willem Fourie"
    ],
    "abstract": "Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01699.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01699",
    "published": "2026-02-02T06:13:21Z",
    "updated": "2026-02-02T06:13:21Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01698",
    "title": "Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models",
    "authors": [
      "Wenhui Tan",
      "Fiorenzo Parascandolo",
      "Enver Sangineto",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Qian Cao",
      "Rita Cucchiara",
      "Ruihua Song",
      "Jian Luan"
    ],
    "abstract": "Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01698.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01698",
    "published": "2026-02-02T06:12:33Z",
    "updated": "2026-02-02T06:12:33Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01696",
    "title": "Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection",
    "authors": [
      "Jiaming Cui",
      "Shuai Zhou",
      "Wenqiang Li",
      "Ruifeng Qin",
      "Feng Shen"
    ],
    "abstract": "Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01696.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01696",
    "published": "2026-02-02T06:11:33Z",
    "updated": "2026-02-02T06:11:33Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01695",
    "title": "Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning",
    "authors": [
      "Yadong Wang",
      "Haodong Chen",
      "Yu Tian",
      "Chuanxing Geng",
      "Dong Liang",
      "Xiang Chen"
    ],
    "abstract": "Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01695.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01695",
    "published": "2026-02-02T06:08:35Z",
    "updated": "2026-02-02T06:08:35Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01689",
    "title": "What LLMs Think When You Don't Tell Them What to Think About?",
    "authors": [
      "Yongchan Kwon",
      "James Zou"
    ],
    "abstract": "Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01689.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01689",
    "published": "2026-02-02T06:06:06Z",
    "updated": "2026-02-02T06:06:06Z",
    "comment": "NA",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01687",
    "title": "Counting Hypothesis: Potential Mechanism of In-Context Learning",
    "authors": [
      "Jung H. Lee",
      "Sujith Vijayan"
    ],
    "abstract": "In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01687.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01687",
    "published": "2026-02-02T05:57:33Z",
    "updated": "2026-02-02T05:57:33Z",
    "comment": "19 pages, 7 main Figures, 1 Table and 6 Supp. Figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01685",
    "title": "Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment",
    "authors": [
      "Byeonghu Na",
      "Hyungho Na",
      "Yeongmin Kim",
      "Suhyeon Jo",
      "HeeSun Bae",
      "Mina Kang",
      "Il-Chul Moon"
    ],
    "abstract": "Large language models (LLMs) are commonly aligned with human preferences using reinforcement learning from human feedback (RLHF). In this method, LLM policies are generally optimized through reward maximization with Kullback-Leibler (KL) divergence regularization of the reference policy. However, KL and its $f$-divergence variants only compare token probabilities at identical indices, failing to capture semantic similarity. We propose Wasserstein Policy Regularization (WPR), a semantic-aware regularization for the RLHF framework based on the entropy-regularized Wasserstein distance, which incorporates the geometry of the token space. The dual formulation of the distance expresses the regularization as penalty terms applied to the reward via optimal dual variables, which yield a tractable objective compatible with standard RL algorithms. Empirically, our method outperforms KL- and $f$-divergence-based baselines, demonstrating the benefits of semantic-aware policy distances for alignment. Our code is available at https://github.com/aailab-kaist/WPR.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01685.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01685",
    "published": "2026-02-02T05:56:16Z",
    "updated": "2026-02-02T05:56:16Z",
    "comment": "Accepted at ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01683",
    "title": "FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding",
    "authors": [
      "Kangcong Li",
      "Peng Ye",
      "Lin Zhang",
      "Chao Wang",
      "Huafeng Qin",
      "Tao Chen"
    ],
    "abstract": "Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical \"gist\"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01683.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01683",
    "published": "2026-02-02T05:52:11Z",
    "updated": "2026-02-02T05:52:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01682",
    "title": "Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets",
    "authors": [
      "Taihei Oki",
      "Shinsaku Sakaue"
    ],
    "abstract": "We study online inverse linear optimization, also known as contextual recommendation, where a learner sequentially infers an agent's hidden objective vector from observed optimal actions over feasible sets that change over time. The learner aims to recommend actions that perform well under the agent's true objective, and the performance is measured by the regret, defined as the cumulative gap between the agent's optimal values and those achieved by the learner's recommended actions. Prior work has established a regret bound of $O(d\\log T)$, as well as a finite but exponentially large bound of $\\exp(O(d\\log d))$, where $d$ is the dimension of the optimization problem and $T$ is the time horizon, while a regret lower bound of $Ω(d)$ is known (Gollapudi et al. 2021; Sakaue et al. 2025). Whether a finite regret bound polynomial in $d$ is achievable or not has remained an open question. We partially resolve this by showing that when the feasible sets are M-convex -- a broad class that includes matroids -- a finite regret bound of $O(d\\log d)$ is possible. We achieve this by combining a structural characterization of optimal solutions on M-convex sets with a geometric volume argument. Moreover, we extend our approach to adversarially corrupted feedback in up to $C$ rounds. We obtain a regret bound of $O((C+1)d\\log d)$ without prior knowledge of $C$, by monitoring directed graphs induced by the observed feedback to detect corruptions adaptively.",
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01682.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01682",
    "published": "2026-02-02T05:48:54Z",
    "updated": "2026-02-02T05:48:54Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01677",
    "title": "SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking",
    "authors": [
      "Yinchao Ma",
      "Dengqing Yang",
      "Zhangyu He",
      "Wenfei Yang",
      "Tianzhu Zhang"
    ],
    "abstract": "Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01677.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01677",
    "published": "2026-02-02T05:44:59Z",
    "updated": "2026-02-02T05:44:59Z",
    "comment": "This paper is accepted by IEEE TIP",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01675",
    "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios",
    "authors": [
      "Yuanzhe Shen",
      "Zisu Huang",
      "Zhengyuan Wang",
      "Muzhao Tian",
      "Zhengkang Guo",
      "Chenyang Zhang",
      "Shuaiyu Zhou",
      "Zengjie Hu",
      "Dailin Li",
      "Jingwen Xu",
      "Kaimin Wang",
      "Wenhao Liu",
      "Tianlong Li",
      "Fengpeng Yue",
      "Feng Hong",
      "Cao Liu",
      "Ke Zeng"
    ],
    "abstract": "As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \\textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\\% success on the easy split, with performance dropping below 10\\% on hard subsets. We further propose \\textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01675.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01675",
    "published": "2026-02-02T05:43:08Z",
    "updated": "2026-02-02T05:43:08Z",
    "comment": "40 pages, 6figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01674",
    "title": "VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR",
    "authors": [
      "Hail Song",
      "Boram Yoon",
      "Seokhwan Yang",
      "Seoyoung Kang",
      "Hyunjeong Kim",
      "Henning Metzmacher",
      "Woontack Woo"
    ],
    "abstract": "We present VRGaussianAvatar, an integrated system that enables real-time full-body 3D Gaussian Splatting (3DGS) avatars in virtual reality using only head-mounted display (HMD) tracking signals. The system adopts a parallel pipeline with a VR Frontend and a GA Backend. The VR Frontend uses inverse kinematics to estimate full-body pose and streams the resulting pose along with stereo camera parameters to the backend. The GA Backend stereoscopically renders a 3DGS avatar reconstructed from a single image. To improve stereo rendering efficiency, we introduce Binocular Batching, which jointly processes left and right eye views in a single batched pass to reduce redundant computation and support high-resolution VR displays. We evaluate VRGaussianAvatar with quantitative performance tests and a within-subject user study against image- and video-based mesh avatar baselines. Results show that VRGaussianAvatar sustains interactive VR performance and yields higher perceived appearance similarity, embodiment, and plausibility. Project page and source code are available at https://vrgaussianavatar.github.io.",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01674.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01674",
    "published": "2026-02-02T05:42:40Z",
    "updated": "2026-02-02T05:42:40Z",
    "comment": "Accepted as an IEEE TVCG paper at IEEE VR 2026 (journal track)",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01673",
    "title": "Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss",
    "authors": [
      "Enguang Fan"
    ],
    "abstract": "Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01673.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01673",
    "published": "2026-02-02T05:41:42Z",
    "updated": "2026-02-02T05:41:42Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01672",
    "title": "Scaling Search-Augmented LLM Reasoning via Adaptive Information Control",
    "authors": [
      "Siheng Xiong",
      "Oguzhan Gungordu",
      "Blair Johnson",
      "James C. Kerce",
      "Faramarz Fekri"
    ],
    "abstract": "Search-augmented reasoning agents interleave multi-step reasoning with external information retrieval, but uncontrolled retrieval often leads to redundant evidence, context saturation, and unstable learning. Existing approaches rely on outcome-based reinforcement learning (RL), which provides limited guidance for regulating information acquisition. We propose DeepControl, a framework for adaptive information control based on a formal notion of information utility, which measures the marginal value of retrieved evidence under a given reasoning state. Building on this utility, we introduce retrieval continuation and granularity control mechanisms that selectively regulate when to continue and stop retrieval, and how much information to expand. An annealed control strategy enables the agent to internalize effective information acquisition behaviors during training. Extensive experiments across seven benchmarks demonstrate that our method consistently outperforms strong baselines. In particular, our approach achieves average performance improvements of 9.4% and 8.6% on Qwen2.5-7B and Qwen2.5-3B, respectively, over strong outcome-based RL baselines, and consistently outperforms both retrieval-free and retrieval-based reasoning methods without explicit information control. These results highlight the importance of adaptive information control for scaling search-augmented reasoning agents to complex, real-world information environments.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01672.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01672",
    "published": "2026-02-02T05:40:38Z",
    "updated": "2026-02-02T05:40:38Z",
    "comment": "Work in progress",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01668",
    "title": "ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting",
    "authors": [
      "Qianyang Li",
      "Xingjun Zhang",
      "Shaoxun Wang",
      "Jia Wei",
      "Yueqi Xing"
    ],
    "abstract": "Long-term multivariate time series forecasting (LTSF) plays a crucial role in various high-performance computing applications, including real-time energy grid management and large-scale traffic flow simulation. However, existing solutions face a dilemma: Transformer-based models suffer from quadratic complexity, limiting their scalability on long sequences, while linear State Space Models (SSMs) often struggle to distinguish valuable signals from high-frequency noise, leading to wasted state capacity. To bridge this gap, we propose ASGMamba, an efficient forecasting framework designed for resource-constrained supercomputing environments. ASGMamba integrates a lightweight Adaptive Spectral Gating (ASG) mechanism that dynamically filters noise based on local spectral energy, enabling the Mamba backbone to focus its state evolution on robust temporal dynamics. Furthermore, we introduce a hierarchical multi-scale architecture with variable-specific Node Embeddings to capture diverse physical characteristics. Extensive experiments on nine benchmarks demonstrate that ASGMamba achieves state-of-the-art accuracy. While keeping strictly $$\\mathcal{O}(L)$$ complexity we significantly reduce the memory usage on long-horizon tasks, thus establishing ASGMamba as a scalable solution for high-throughput forecasting in resource limited environments.The code is available at https://github.com/hit636/ASGMamba",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01668.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01668",
    "published": "2026-02-02T05:38:21Z",
    "updated": "2026-02-02T05:38:21Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01667",
    "title": "Quantifying Epistemic Predictive Uncertainty in Conformal Prediction",
    "authors": [
      "Siu Lun Chau",
      "Soroush H. Zargarbashi",
      "Yusuf Sale",
      "Michele Caprio"
    ],
    "abstract": "We study the problem of quantifying epistemic predictive uncertainty (EPU) -- that is, uncertainty faced at prediction time due to the existence of multiple plausible predictive models -- within the framework of conformal prediction (CP). To expose the implicit model multiplicity underlying CP, we build on recent results showing that, under a mild assumption, any full CP procedure induces a set of closed and convex predictive distributions, commonly referred to as a credal set. Importantly, the conformal prediction region (CPR) coincides exactly with the set of labels to which all distributions in the induced credal set assign probability at least $1-α$. As our first contribution, we prove that this characterisation also holds in split CP. Building on this connection, we then propose a computationally efficient and analytically tractable uncertainty measure, based on \\emph{Maximum Mean Imprecision}, to quantify the EPU by measuring the degree of conflicting information within the induced credal set. Experiments on active learning and selective classification demonstrate that the quantified EPU provides substantially more informative and fine-grained uncertainty assessments than reliance on CPR size alone. More broadly, this work highlights the potential of CP serving as a principled basis for decision-making under epistemic uncertainty.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01667.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01667",
    "published": "2026-02-02T05:38:07Z",
    "updated": "2026-02-02T05:38:07Z",
    "comment": "42 pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01666",
    "title": "Moonworks Lunara Aesthetic II: An Image Variation Dataset",
    "authors": [
      "Yan Wang",
      "Partho Hassan",
      "Samiha Sadeka",
      "Nada Soliman",
      "M M Sayeef Abdullah",
      "Sabit Hassan"
    ],
    "abstract": "We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01666.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01666",
    "published": "2026-02-02T05:37:28Z",
    "updated": "2026-02-02T05:37:28Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01664",
    "title": "FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning",
    "authors": [
      "Mingda Zhang",
      "Haoran Luo",
      "Tiesunlong Shen",
      "Qika Lin",
      "Xiaoying Tang",
      "Rui Mao",
      "Erik Cambria"
    ],
    "abstract": "In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01664.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01664",
    "published": "2026-02-02T05:30:42Z",
    "updated": "2026-02-02T05:30:42Z",
    "comment": "41 pages, 7 figures, 6 tables. Project page: http://flowsteer.org/",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01661",
    "title": "From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction",
    "authors": [
      "Xingyu Miao",
      "Junting Dong",
      "Qin Zhao",
      "Yuhang Yang",
      "Junhao Chen",
      "Yang Long"
    ],
    "abstract": "In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01661.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01661",
    "published": "2026-02-02T05:28:58Z",
    "updated": "2026-02-02T05:28:58Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01660",
    "title": "CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation",
    "authors": [
      "Zhongyuan Peng",
      "Caijun Xu",
      "Changyi Xiao",
      "Shibo Hong",
      "Eli Zhang",
      "Stephen Huang",
      "Yixin Cao"
    ],
    "abstract": "Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01660.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01660",
    "published": "2026-02-02T05:28:26Z",
    "updated": "2026-02-02T05:28:26Z",
    "comment": "11 pages, 5 tables, 5 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01658",
    "title": "Efficient Adversarial Attacks on High-dimensional Offline Bandits",
    "authors": [
      "Seyed Mohammad Hadi Hosseini",
      "Amir Najafi",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "Bandit algorithms have recently emerged as a powerful tool for evaluating machine learning models, including generative image models and large language models, by efficiently identifying top-performing candidates without exhaustive comparisons. These methods typically rely on a reward model, often distributed with public weights on platforms such as Hugging Face, to provide feedback to the bandit. While online evaluation is expensive and requires repeated trials, offline evaluation with logged data has become an attractive alternative. However, the adversarial robustness of offline bandit evaluation remains largely unexplored, particularly when an attacker perturbs the reward model (rather than the training data) prior to bandit training. In this work, we fill this gap by investigating, both theoretically and empirically, the vulnerability of offline bandit training to adversarial manipulations of the reward model. We introduce a novel threat model in which an attacker exploits offline data in high-dimensional settings to hijack the bandit's behavior. Starting with linear reward functions and extending to nonlinear models such as ReLU neural networks, we study attacks on two Hugging Face evaluators used for generative model assessment: one measuring aesthetic quality and the other assessing compositional alignment. Our results show that even small, imperceptible perturbations to the reward model's weights can drastically alter the bandit's behavior. From a theoretical perspective, we prove a striking high-dimensional effect: as input dimensionality increases, the perturbation norm required for a successful attack decreases, making modern applications such as image evaluation especially vulnerable. Extensive experiments confirm that naive random perturbations are ineffective, whereas carefully targeted perturbations achieve near-perfect attack success rates ...",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01658.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01658",
    "published": "2026-02-02T05:24:31Z",
    "updated": "2026-02-02T05:24:31Z",
    "comment": "Accepted at ICLR 2026 Conference",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01655",
    "title": "ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development",
    "authors": [
      "Pengrui Lu",
      "Shiqi Zhang",
      "Yunzhong Hou",
      "Lyumanshan Ye",
      "Chaoyi Huang",
      "Zixi Chen",
      "Ji Zeng",
      "Hantao Jiang",
      "Pengfei Liu",
      "Yiwei Wang",
      "Ming-Hsuan Yang"
    ],
    "abstract": "Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01655.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01655",
    "published": "2026-02-02T05:17:23Z",
    "updated": "2026-02-02T05:17:23Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01654",
    "title": "Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models",
    "authors": [
      "Jiaqian Li",
      "Yanshu Li",
      "Kuan-Hao Huang"
    ],
    "abstract": "Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01654.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01654",
    "published": "2026-02-02T05:14:42Z",
    "updated": "2026-02-02T05:14:42Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01651",
    "title": "On the Spatiotemporal Dynamics of Generalization in Neural Networks",
    "authors": [
      "Zichao Wei"
    ],
    "abstract": "Why do neural networks fail to generalize addition from 16-digit to 32-digit numbers, while a child who learns the rule can apply it to arbitrarily long sequences? We argue that this failure is not an engineering problem but a violation of physical postulates. Drawing inspiration from physics, we identify three constraints that any generalizing system must satisfy: (1) Locality -- information propagates at finite speed; (2) Symmetry -- the laws of computation are invariant across space and time; (3) Stability -- the system converges to discrete attractors that resist noise accumulation. From these postulates, we derive -- rather than design -- the Spatiotemporal Evolution with Attractor Dynamics (SEAD) architecture: a neural cellular automaton where local convolutional rules are iterated until convergence. Experiments on three tasks validate our theory: (1) Parity -- demonstrating perfect length generalization via light-cone propagation; (2) Addition -- achieving scale-invariant inference from L=16 to L=1 million with 100% accuracy, exhibiting input-adaptive computation; (3) Rule 110 -- learning a Turing-complete cellular automaton without trajectory divergence. Our results suggest that the gap between statistical learning and logical reasoning can be bridged -- not by scaling parameters, but by respecting the physics of computation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01651.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01651",
    "published": "2026-02-02T05:11:48Z",
    "updated": "2026-02-02T05:11:48Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01649",
    "title": "Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning",
    "authors": [
      "Yinchao Ma",
      "Qiang Zhou",
      "Zhibin Wang",
      "Xianing Chen",
      "Hanqing Yang",
      "Jun Song",
      "Bo Zheng"
    ],
    "abstract": "Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \\textbf{C}ontribution-\\textbf{a}ware token \\textbf{Co}mpression algorithm for \\textbf{VID}eo understanding (\\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01649.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01649",
    "published": "2026-02-02T05:09:48Z",
    "updated": "2026-02-02T05:09:48Z",
    "comment": "This paper is accepted by AAAI2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01644",
    "title": "From Perception to Action: Spatial AI Agents and World Models",
    "authors": [
      "Gloria Felicia",
      "Nolan Bryant",
      "Handi Putra",
      "Ayaan Gazali",
      "Eliel Lobo",
      "Esteban Rojas"
    ],
    "abstract": "While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01644.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01644",
    "published": "2026-02-02T05:00:55Z",
    "updated": "2026-02-02T05:00:55Z",
    "comment": "61 pages, 742 citations, 1 figure, 3 tables. Survey paper on spatial AI agents, embodied AI, graph neural networks, and world models",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01643",
    "title": "De Novo Molecular Generation from Mass Spectra via Many-Body Enhanced Diffusion",
    "authors": [
      "Xichen Sun",
      "Wentao Wei",
      "Jiahua Rao",
      "Jiancong Xie",
      "Yuedong Yang"
    ],
    "abstract": "Molecular structure generation from mass spectrometry is fundamental for understanding cellular metabolism and discovering novel compounds. Although tandem mass spectrometry (MS/MS) enables the high-throughput acquisition of fragment fingerprints, these spectra often reflect higher-order interactions involving the concerted cleavage of multiple atoms and bonds-crucial for resolving complex isomers and non-local fragmentation mechanisms. However, most existing methods adopt atom-centric and pairwise interaction modeling, overlooking higher-order edge interactions and lacking the capacity to systematically capture essential many-body characteristics for structure generation. To overcome these limitations, we present MBGen, a Many-Body enhanced diffusion framework for de novo molecular structure Generation from mass spectra. By integrating a many-body attention mechanism and higher-order edge modeling, MBGen comprehensively leverages the rich structural information encoded in MS/MS spectra, enabling accurate de novo generation and isomer differentiation for novel molecules. Experimental results on the NPLIB1 and MassSpecGym benchmarks demonstrate that MBGen achieves superior performance, with improvements of up to 230% over state-of-the-art methods, highlighting the scientific value and practical utility of many-body modeling for mass spectrometry-based molecular generation. Further analysis and ablation studies show that our approach effectively captures higher-order interactions and exhibits enhanced sensitivity to complex isomeric and non-local fragmentation information.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01643.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01643",
    "published": "2026-02-02T05:00:00Z",
    "updated": "2026-02-02T05:00:00Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01642",
    "title": "The Effect of Mini-Batch Noise on the Implicit Bias of Adam",
    "authors": [
      "Matias D. Cattaneo",
      "Boris Shigida"
    ],
    "abstract": "With limited high-quality data and growing compute, multi-epoch training is gaining back its importance across sub-areas of deep learning. Adam(W), versions of which are go-to optimizers for many tasks such as next token prediction, has two momentum hyperparameters $(β_1, β_2)$ controlling memory and one very important hyperparameter, batch size, controlling (in particular) the amount mini-batch noise. We introduce a theoretical framework to understand how mini-batch noise influences the implicit bias of memory in Adam (depending on $β_1$, $β_2$) towards sharper or flatter regions of the loss landscape, which is commonly observed to correlate with the generalization gap in multi-epoch training. We find that in the case of large batch sizes, higher $β_2$ increases the magnitude of anti-regularization by memory (hurting generalization), but as the batch size becomes smaller, the dependence of (anti-)regulariation on $β_2$ is reversed. A similar monotonicity shift (in the opposite direction) happens in $β_1$. In particular, the commonly \"default\" pair $(β_1, β_2) = (0.9, 0.999)$ is a good choice if batches are small; for larger batches, in many settings moving $β_1$ closer to $β_2$ is much better in terms of validation accuracy in multi-epoch training. Moreover, our theoretical derivations connect the scale of the batch size at which the shift happens to the scale of the critical batch size. We illustrate this effect in experiments with small-scale data in the about-to-overfit regime.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01642.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01642",
    "published": "2026-02-02T04:59:24Z",
    "updated": "2026-02-02T04:59:24Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01640",
    "title": "A2Eval: Agentic and Automated Evaluation for Embodied Brain",
    "authors": [
      "Shuai Zhang",
      "Jiayu Hu",
      "Zijie Chen",
      "Zeyuan Ding",
      "Yi Zhang",
      "Yingji Zhang",
      "Ziyi Zhou",
      "Junwei Liao",
      "Shengjie Zhou",
      "Yong Dai",
      "Zhenzhong Lan",
      "Xiaozhu Ju"
    ],
    "abstract": "Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01640.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01640",
    "published": "2026-02-02T04:55:27Z",
    "updated": "2026-02-02T04:55:27Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01639",
    "title": "ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval",
    "authors": [
      "Tianyu Yang",
      "ChenWei He",
      "Xiangzhao Hao",
      "Tianyue Wang",
      "Jiarui Guo",
      "Haiyun Guo",
      "Leigang Qu",
      "Jinqiao Wang",
      "Tat-Seng Chua"
    ],
    "abstract": "Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01639.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01639",
    "published": "2026-02-02T04:52:54Z",
    "updated": "2026-02-02T04:52:54Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01637",
    "title": "Chance-Constrained Inference for Hallucination Risk Control in Large Language Models",
    "authors": [
      "Sreenivasan Mohandas"
    ],
    "abstract": "Large language models generate outputs stochastically and may produce fluent but invalid responses, including factual hallucinations. Existing mitigation strategies reduce average error rates but do not provide explicit control over the \\emph{frequency} of such failures under repeated use. We formulate inference as a deployment-time risk control problem and introduce \\emph{chance-constrained inference}, which directly bounds the probability of hallucinations among accepted generations. Hallucinations are modeled as stochastic constraint violations, and we show that confidence-based selective prediction does not, in general, imply probabilistic risk guarantees. To enforce chance constraints efficiently, we propose a sequential, anytime-valid inference procedure that adaptively certifies feasibility or infeasibility using finite samples, avoiding conservative fixed-sample bounds. Experiments on questions inspired by NaturalQuestions and controlled multi-hop question answering demonstrate reliable risk control, early detection of intrinsically infeasible inputs, and safe composition under repeated use, while confidence-based baselines fail to provide consistent guarantees.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01637.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01637",
    "published": "2026-02-02T04:51:47Z",
    "updated": "2026-02-02T04:51:47Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01635",
    "title": "COMET: Codebook-based Online-adaptive Multi-scale Embedding for Time-series Anomaly Detection",
    "authors": [
      "Jinwoo Park",
      "Hyeongwon Kang",
      "Seung Hun Han",
      "Pilsung Kang"
    ],
    "abstract": "Time series anomaly detection is a critical task across various industrial domains. However, capturing temporal dependencies and multivariate correlations within patch-level representation learning remains underexplored, and reliance on single-scale patterns limits the detection of anomalies across different temporal ranges. Furthermore, focusing on normal data representations makes models vulnerable to distribution shifts at inference time. To address these limitations, we propose Codebook-based Online-adaptive Multi-scale Embedding for Time-series anomaly detection (COMET), which consists of three key components: (1) Multi-scale Patch Encoding captures temporal dependencies and inter-variable correlations across multiple patch scales. (2) Vector-Quantized Coreset learns representative normal patterns via codebook and detects anomalies with a dual-score combining quantization error and memory distance. (3) Online Codebook Adaptation generates pseudo-labels based on codebook entries and dynamically adapts the model at inference through contrastive learning. Experiments on five benchmark datasets demonstrate that COMET achieves the best performance in 36 out of 45 evaluation metrics, validating its effectiveness across diverse environments.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01635.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01635",
    "published": "2026-02-02T04:51:18Z",
    "updated": "2026-02-02T04:51:18Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01633",
    "title": "Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification",
    "authors": [
      "Xinyuan Zhao",
      "Yihang Wu",
      "Ahmad Chaddad",
      "Tareef Daqqaq",
      "Reem Kateb"
    ],
    "abstract": "While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\\% to 41.69\\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: https://github.com/AIPMLab/ViT-FLDAF.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01633.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01633",
    "published": "2026-02-02T04:47:33Z",
    "updated": "2026-02-02T04:47:33Z",
    "comment": "Accepted in Knowledge-Based Systems",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01630",
    "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks",
    "authors": [
      "Bohan Zeng",
      "Kaixin Zhu",
      "Daili Hua",
      "Bozhou Li",
      "Chengzhuo Tong",
      "Yuran Wang",
      "Xinyi Huang",
      "Yifan Dai",
      "Zixiang Zhang",
      "Yifan Yang",
      "Zhou Liu",
      "Hao Liang",
      "Xiaochen Ma",
      "Ruichuan An",
      "Tianyi Bai",
      "Hongcheng Gao",
      "Junbo Niu",
      "Yang Shi",
      "Xinlong Chen",
      "Yue Ding",
      "Minglei Shi",
      "Kai Zeng",
      "Yiwen Tang",
      "Yuanxing Zhang",
      "Pengfei Wan",
      "Xintao Wang",
      "Wentao Zhang"
    ],
    "abstract": "World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01630.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01630",
    "published": "2026-02-02T04:42:44Z",
    "updated": "2026-02-02T04:42:44Z",
    "comment": "13 pages, 4 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01629",
    "title": "AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments",
    "authors": [
      "Renukanandan Tumu",
      "Aditya Singh",
      "Rahul Mangharam"
    ],
    "abstract": "Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \\textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels.",
    "categories": [
      "cs.LG",
      "cs.RO",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01629.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01629",
    "published": "2026-02-02T04:41:35Z",
    "updated": "2026-02-02T04:41:35Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01626",
    "title": "Toward Enhancing Representation Learning in Federated Multi-Task Settings",
    "authors": [
      "Mehdi Setayesh",
      "Mahdi Beitollahi",
      "Yasser H. Khalil",
      "Hongliang Li"
    ],
    "abstract": "Federated multi-task learning (FMTL) seeks to collaboratively train customized models for users with different tasks while preserving data privacy. Most existing approaches assume model congruity (i.e., the use of fully or partially homogeneous models) across users, which limits their applicability in realistic settings. To overcome this limitation, we aim to learn a shared representation space across tasks rather than shared model parameters. To this end, we propose Muscle loss, a novel contrastive learning objective that simultaneously aligns representations from all participating models. Unlike existing multi-view or multi-model contrastive methods, which typically align models pairwise, Muscle loss can effectively capture dependencies across tasks because its minimization is equivalent to the maximization of mutual information among all the models' representations. Building on this principle, we develop FedMuscle, a practical and communication-efficient FMTL algorithm that naturally handles both model and task heterogeneity. Experiments on diverse image and language tasks demonstrate that FedMuscle consistently outperforms state-of-the-art baselines, delivering substantial improvements and robust performance across heterogeneous settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01626.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01626",
    "published": "2026-02-02T04:39:36Z",
    "updated": "2026-02-02T04:39:36Z",
    "comment": "This paper has been accepted at ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01624",
    "title": "PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards",
    "authors": [
      "Minh-Quan Le",
      "Gaurav Mittal",
      "Cheng Zhao",
      "David Gu",
      "Dimitris Samaras",
      "Mei Chen"
    ],
    "abstract": "Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01624.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01624",
    "published": "2026-02-02T04:37:11Z",
    "updated": "2026-02-02T04:37:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01623",
    "title": "Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?",
    "authors": [
      "Susan Liang",
      "Chao Huang",
      "Filippos Bellos",
      "Yolo Yunlong Tang",
      "Qianxiang Shen",
      "Jing Bi",
      "Luchuan Song",
      "Zeliang Zhang",
      "Jason Corso",
      "Chenliang Xu"
    ],
    "abstract": "State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01623.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01623",
    "published": "2026-02-02T04:36:23Z",
    "updated": "2026-02-02T04:36:23Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01619",
    "title": "SUSD: Structured Unsupervised Skill Discovery through State Factorization",
    "authors": [
      "Seyed Mohammad Hadi Hosseini",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "Unsupervised Skill Discovery (USD) aims to autonomously learn a diverse set of skills without relying on extrinsic rewards. One of the most common USD approaches is to maximize the Mutual Information (MI) between skill latent variables and states. However, MI-based methods tend to favor simple, static skills due to their invariance properties, limiting the discovery of dynamic, task-relevant behaviors. Distance-Maximizing Skill Discovery (DSD) promotes more dynamic skills by leveraging state-space distances, yet still fall short in encouraging comprehensive skill sets that engage all controllable factors or entities in the environment. In this work, we introduce SUSD, a novel framework that harnesses the compositional structure of environments by factorizing the state space into independent components (e.g., objects or controllable entities). SUSD allocates distinct skill variables to different factors, enabling more fine-grained control on the skill discovery process. A dynamic model also tracks learning across factors, adaptively steering the agent's focus toward underexplored factors. This structured approach not only promotes the discovery of richer and more diverse skills, but also yields a factorized skill representation that enables fine-grained and disentangled control over individual entities which facilitates efficient training of compositional downstream tasks via Hierarchical Reinforcement Learning (HRL). Our experimental results across three environments, with factors ranging from 1 to 10, demonstrate that our method can discover diverse and complex skills without supervision, significantly outperforming existing unsupervised skill discovery methods in factorized and complex environments. Code is publicly available at: https://github.com/hadi-hosseini/SUSD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01619.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01619",
    "published": "2026-02-02T04:21:33Z",
    "updated": "2026-02-02T04:21:33Z",
    "comment": "Accepted as a conference paper at ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01618",
    "title": "SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia",
    "authors": [
      "Panuthep Tasawong",
      "Jian Gang Ngui",
      "Alham Fikri Aji",
      "Trevor Cohn",
      "Peerat Limkonchotiwat"
    ],
    "abstract": "Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01618.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01618",
    "published": "2026-02-02T04:20:35Z",
    "updated": "2026-02-02T04:20:35Z",
    "comment": "Under reivew",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01614",
    "title": "AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems",
    "authors": [
      "Qi Cheng",
      "Licheng Liu",
      "Yao Zhang",
      "Mu Hong",
      "Yiqun Xie",
      "Xiaowei Jia"
    ],
    "abstract": "Agroecosystem, which heavily influenced by human actions and accounts for a quarter of global greenhouse gas emissions (GHGs), plays a crucial role in mitigating global climate change and securing environmental sustainability. However, we can't manage what we can't measure. Accurately quantifying the pools and fluxes in the carbon, nutrient, and water nexus of the agroecosystem is therefore essential for understanding the underlying drivers of GHG and developing effective mitigation strategies. Conventional approaches like soil sampling, process-based models, and black-box machine learning models are facing challenges such as data sparsity, high spatiotemporal heterogeneity, and complex subsurface biogeochemical and physical processes. Developing new trustworthy approaches such as AI-empowered models, will require the AI-ready benchmark dataset and outlined protocols, which unfortunately do not exist. In this work, we introduce a first-of-its-kind spatial-temporal agroecosystem GHG benchmark dataset that integrates physics-based model simulations from Ecosys and DayCent with real-world observations from eddy covariance flux towers and controlled-environment facilities. We evaluate the performance of various sequential deep learning models on carbon and nitrogen flux prediction, including LSTM-based models, temporal CNN-based model, and Transformer-based models. Furthermore, we explored transfer learning to leverage simulated data to improve the generalization of deep learning models on real-world observations. Our benchmark dataset and evaluation framework contribute to the development of more accurate and scalable AI-driven agroecosystem models, advancing our understanding of ecosystem-climate interactions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01614.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01614",
    "published": "2026-02-02T04:04:07Z",
    "updated": "2026-02-02T04:04:07Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01613",
    "title": "A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models",
    "authors": [
      "Sergii Kozyrev",
      "Davyd Maiboroda"
    ],
    "abstract": "Large language models are limited in deployment by GPU memory and inference latency. We present Minima, a production compression pipeline that learns where and how to structurally compress a Transformer and turns that compression into real serving gains. Minima trains a lightweight convolutional predictor to estimate layer- and patch-level sensitivity, applies a mixture of Tucker, tensor-train, and tensor-ring decompositions to low-sensitivity regions, performs a short healing fine-tune, and executes the resulting operators with custom Triton and CUDA kernels. The reduced memory footprint enables speculative decoding with a small draft model and a larger verifier. On Qwen3-32B at an 8k-token context window, Minima reduces peak VRAM from 64 GiB to 40 GiB. For a single active request, throughput increases from 40 tokens per second (baseline) to 50 tokens per second (Minima) and 75 tokens per second (Minima with speculative decoding). Under 50 parallel requests, throughput is 34, 44, and 53 tokens per second respectively, showing that Minima remains effective under high concurrency even when speculative decoding gains compress. We position Minima relative to recent tensor-network, low-rank plus quantization, and cross-layer sharing methods, and argue that it is a practical step toward more aggressive structural compression via shared tensor backbones with tiny per-layer adapters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01613.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01613",
    "published": "2026-02-02T04:03:39Z",
    "updated": "2026-02-02T04:03:39Z",
    "comment": "13 pages, 5 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01611",
    "title": "What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?",
    "authors": [
      "Weizheng Gu",
      "Chengze Li",
      "Zhuohao Yu",
      "Mengyuan Sun",
      "Zhibang Yang",
      "Wei Wang",
      "Hongrui Jia",
      "Shikun Zhang",
      "Wei Ye"
    ],
    "abstract": "Large language models are increasingly evaluated as interactive agents, yet standard agent benchmarks conflate two qualitatively distinct sources of success: semantic tool-use and interface-specific interaction pattern memorization. Because both mechanisms can yield identical task success on the original interface, benchmark scores alone are not identifiable evidence of environment-invariant capability. We propose PIPE, a protocol-level evaluation augmentation for diagnosing interface reliance by minimally rewriting environment interfaces while preserving task semantics and execution behavior. Across 16 environments from AgentBench and AgentGym and a range of open-source and API-based agents, PIPE reveals that trajectory-SFT substantially amplifies interface shortcutting: trained agents degrade sharply under minimal interface rewrites, while non-trajectory-trained models remain largely stable. We further introduce Interface Reliance (IR), a counterbalanced alias-based metric that quantifies preference for training-time interfaces, and show that interface shortcutting exhibits environment-dependent, non-monotonic training dynamics that remain invisible under standard evaluation. Our code is available at https://anonymous.4open.science/r/What-Do-Agents-Learn-from-Trajectory-SFT-Semantics-or-Interfaces--0831/.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01611.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01611",
    "published": "2026-02-02T04:02:03Z",
    "updated": "2026-02-02T04:02:03Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01610",
    "title": "ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning",
    "authors": [
      "Zitao Guo",
      "Changyang Jiang",
      "Tianhong Zhao",
      "Jinzhou Cao",
      "Genan Dai",
      "Bowen Zhang"
    ],
    "abstract": "Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01610.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01610",
    "published": "2026-02-02T03:56:05Z",
    "updated": "2026-02-02T03:56:05Z",
    "comment": "The paper has been accepted by ICASSP 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01609",
    "title": "Token Pruning for In-Context Generation in Diffusion Transformers",
    "authors": [
      "Junqing Lin",
      "Xingyu Zheng",
      "Pei Cheng",
      "Bin Fu",
      "Jingwei Sun",
      "Guangzhong Sun"
    ],
    "abstract": "In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01609.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01609",
    "published": "2026-02-02T03:54:32Z",
    "updated": "2026-02-02T03:54:32Z",
    "comment": "20 pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01608",
    "title": "Reasoning with Autoregressive-Diffusion Collaborative Thoughts",
    "authors": [
      "Mu Yuan",
      "Liekang Zeng",
      "Guoliang Xing",
      "Lan Zhang",
      "Yunhao Liu"
    ],
    "abstract": "Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2602.01608.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01608",
    "published": "2026-02-02T03:54:15Z",
    "updated": "2026-02-02T03:54:15Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01606",
    "title": "Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching",
    "authors": [
      "Zeqiao Li",
      "Yijing Wang",
      "Haoyu Wang",
      "Zheng Li",
      "Zhiqiang Zuo"
    ],
    "abstract": "Diffusion policies are expressive yet incur high inference latency. Flow Matching (FM) enables one-step generation, but integrating it into Maximum Entropy Reinforcement Learning (MaxEnt RL) is challenging: the optimal policy is an intractable energy-based distribution, and the efficient log-likelihood estimation required to balance exploration and exploitation suffers from severe discretization bias. We propose \\textbf{F}low-based \\textbf{L}og-likelihood-\\textbf{A}ware \\textbf{M}aximum \\textbf{E}ntropy RL (\\textbf{FLAME}), a principled framework that addresses these challenges. First, we derive a Q-Reweighted FM objective that bypasses partition function estimation via importance reweighting. Second, we design a decoupled entropy estimator that rigorously corrects bias, which enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Third, we integrate the MeanFlow formulation to achieve expressive and efficient one-step control. Empirical results on MuJoCo show that FLAME outperforms Gaussian baselines and matches multi-step diffusion policies with significantly lower inference cost. Code is available at https://github.com/lzqw/FLAME.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01606.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01606",
    "published": "2026-02-02T03:54:11Z",
    "updated": "2026-02-02T03:54:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01605",
    "title": "Universal Redundancies in Time Series Foundation Models",
    "authors": [
      "Anthony Bao",
      "Venkata Hasith Vattikuti",
      "Jeffrey Lai",
      "William Gilpin"
    ],
    "abstract": "Time Series Foundation Models (TSFMs) leverage extensive pretraining to accurately predict unseen time series during inference, without the need for task-specific fine-tuning. Through large-scale evaluations on standard benchmarks, we find that leading transformer-based TSFMs exhibit redundant components in their intermediate layers. We introduce a set of tools for mechanistic interpretability of TSFMs, including ablations of specific components and direct logit attribution on the residual stream. Our findings are consistent across several leading TSFMs with diverse architectures, and across a diverse set of real-world and synthetic time-series datasets. We discover that all models in our study are robust to ablations of entire layers. Furthermore, we develop a theoretical framework framing transformers as kernel regressors, motivating a purely intrinsic strategy for ablating heads based on the stable rank of the per-head projection matrices. Using this approach, we uncover the specific heads responsible for degenerate phenomena widely observed in TSFMs, such as parroting of motifs from the context and seasonality bias. Our study sheds light on the universal properties of this emerging class of architectures for continuous-time sequence modeling.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01605.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01605",
    "published": "2026-02-02T03:53:46Z",
    "updated": "2026-02-02T03:53:46Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01601",
    "title": "Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards",
    "authors": [
      "Hieu Trung Nguyen",
      "Bao Nguyen",
      "Wenao Ma",
      "Yuzhi Zhao",
      "Ruifeng She",
      "Viet Anh Nguyen"
    ],
    "abstract": "Sampling efficiency is a key bottleneck in reinforcement learning with verifiable rewards. Existing group-based policy optimization methods, such as GRPO, allocate a fixed number of rollouts for all training prompts. This uniform allocation implicitly treats all prompts as equally informative, and could lead to inefficient computational budget usage and impede training progress. We introduce \\Ours, a Variance-Informed Predictive allocation strategy that allocates a given rollout budget to the prompts in the incumbent batch to minimize the expected gradient variance of the policy update. At each iteration, \\Ours~uses a lightweight Gaussian process model to predict per-prompt success probabilities based on recent rollouts. These probability predictions are translated into variance estimates, which are then fed into a convex optimization problem to determine the optimal rollout allocations under a hard compute budget constraint. Empirical results show that \\Ours~consistently improves sampling efficiency and achieves higher performance than uniform or heuristic allocation strategies in multiple benchmarks. Our code will be available at https://github.com/HieuNT91/VIP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01601.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01601",
    "published": "2026-02-02T03:50:01Z",
    "updated": "2026-02-02T03:50:01Z",
    "comment": "Accepted at ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01599",
    "title": "The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR",
    "authors": [
      "Israel Adewuyi",
      "Solomon Okibe",
      "Vladmir Ivanov"
    ],
    "abstract": "The Lottery Ticket Hypothesis demonstrated that sparse subnetworks can match full-model performance, suggesting parameter redundancy. Meanwhile, in Reinforcement Learning with Verifiable Rewards (RLVR), recent work has shown that updates concentrate on a sparse subset of parameters, which further lends evidence to this underlying redundancy. We study the simplest possible way to exploit this redundancy: training only a randomly selected subset of parameters at extreme sparsities. Empirically, we find that training just 1\\% of parameters matches or exceeds full-parameter RLVR finetuning across 3 models and 2 task domains. Moreover, different random masks show minimal overlap ($\\leq 0.005$ Jaccard similarity) and yet all succeed, suggesting pretrained models contain many viable sparse subnetworks rather than one privileged set. We term this the Multiple Ticket Hypothesis. We explain this phenomenon through the implicit per-step KL constraint in RLVR, which restricts updates to a low-dimensional subspace, enabling arbitrary sparse masks to succeed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01599.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01599",
    "published": "2026-02-02T03:43:31Z",
    "updated": "2026-02-02T03:43:31Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01598",
    "title": "The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation",
    "authors": [
      "Mingwen Zhang",
      "Minqiang Yang",
      "Changsheng Ma",
      "Yang Yu",
      "Hui Bai",
      "Chen Xu",
      "Xiangzhen Kong",
      "Bin Hu"
    ],
    "abstract": "Proactive questioning, where therapists deliberately initiate structured, cognition-guiding inquiries, is a cornerstone of cognitive behavioral therapy (CBT). Yet, current psychological large language models (LLMs) remain overwhelmingly reactive, defaulting to empathetic but superficial responses that fail to surface latent beliefs or guide behavioral change. To bridge this gap, we propose the \\textbf{Socratic Inquiry Framework (SIF)}, a lightweight, plug-and-play therapeutic intent planner that transforms LLMs from passive listeners into active cognitive guides. SIF decouples \\textbf{when to ask} (via Strategy Anchoring) from \\textbf{what to ask} (via Template Retrieval), enabling context-aware, theory-grounded questioning without end-to-end retraining. Complementing SIF, we introduce \\textbf{Socratic-QA}, a high-quality dataset of strategy-aligned Socratic sequences that provides explicit supervision for proactive reasoning. Experiments show that SIF significantly enhances proactive questioning frequency, conversational depth, and therapeutic alignment, marking a clear shift from reactive comfort to proactive exploration. Our work establishes a new paradigm for psychologically informed LLMs: not just to respond, but to guide.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01598.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01598",
    "published": "2026-02-02T03:40:11Z",
    "updated": "2026-02-02T03:40:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01594",
    "title": "UV-M3TL: A Unified and Versatile Multimodal Multi-Task Learning Framework for Assistive Driving Perception",
    "authors": [
      "Wenzhuo Liu",
      "Qiannan Guo",
      "Zhen Wang",
      "Wenshuo Wang",
      "Lei Yang",
      "Yicheng Qiao",
      "Lening Wang",
      "Zhiwei Li",
      "Chen Lv",
      "Shanghang Zhang",
      "Junqiang Xi",
      "Huaping Liu"
    ],
    "abstract": "Advanced Driver Assistance Systems (ADAS) need to understand human driver behavior while perceiving their navigation context, but jointly learning these heterogeneous tasks would cause inter-task negative transfer and impair system performance. Here, we propose a Unified and Versatile Multimodal Multi-Task Learning (UV-M3TL) framework to simultaneously recognize driver behavior, driver emotion, vehicle behavior, and traffic context, while mitigating inter-task negative transfer. Our framework incorporates two core components: dual-branch spatial channel multimodal embedding (DB-SCME) and adaptive feature-decoupled multi-task loss (AFD-Loss). DB-SCME enhances cross-task knowledge transfer while mitigating task conflicts by employing a dual-branch structure to explicitly model salient task-shared and task-specific features. AFD-Loss improves the stability of joint optimization while guiding the model to learn diverse multi-task representations by introducing an adaptive weighting mechanism based on learning dynamics and feature decoupling constraints. We evaluate our method on the AIDE dataset, and the experimental results demonstrate that UV-M3TL achieves state-of-the-art performance across all four tasks. To further prove the versatility, we evaluate UV-M3TL on additional public multi-task perception benchmarks (BDD100K, CityScapes, NYUD-v2, and PASCAL-Context), where it consistently delivers strong performance across diverse task combinations, attaining state-of-the-art results on most tasks.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01594.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01594",
    "published": "2026-02-02T03:35:24Z",
    "updated": "2026-02-02T03:35:24Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01593",
    "title": "Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework",
    "authors": [
      "Wenzhuo Zhao",
      "Keren Fu",
      "Jiahao He",
      "Xiaohong Liu",
      "Qijun Zhao",
      "Guangtao Zhai"
    ],
    "abstract": "Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the \"task-specific\" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01593.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01593",
    "published": "2026-02-02T03:34:25Z",
    "updated": "2026-02-02T03:34:25Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01591",
    "title": "Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages",
    "authors": [
      "Zhixiong Yue",
      "Zixuan Ni",
      "Feiyang Ye",
      "Jinshan Zhang",
      "Sheng Shen",
      "Zhenpeng Mi"
    ],
    "abstract": "Recent advances in flow matching models, particularly with reinforcement learning (RL), have significantly enhanced human preference alignment in few step text to image generators. However, existing RL based approaches for flow matching models typically rely on numerous denoising steps, while suffering from sparse and imprecise reward signals that often lead to suboptimal alignment. To address these limitations, we propose Temperature Annealed Few step Sampling with Group Relative Policy Optimization (TAFS GRPO), a novel framework for training flow matching text to image models into efficient few step generators well aligned with human preferences. Our method iteratively injects adaptive temporal noise onto the results of one step samples. By repeatedly annealing the model's sampled outputs, it introduces stochasticity into the sampling process while preserving the semantic integrity of each generated image. Moreover, its step aware advantage integration mechanism combines the GRPO to avoid the need for the differentiable of reward function and provide dense and step specific rewards for stable policy optimization. Extensive experiments demonstrate that TAFS GRPO achieves strong performance in few step text to image generation and significantly improves the alignment of generated images with human preferences. The code and models of this work will be available to facilitate further research.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01591.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01591",
    "published": "2026-02-02T03:32:00Z",
    "updated": "2026-02-02T03:32:00Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01590",
    "title": "Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles",
    "authors": [
      "Shaohan Wang",
      "Benfeng Xu",
      "Licheng Zhang",
      "Mingxuan Du",
      "Chiwei Zhu",
      "Xiaorui Wang",
      "Zhendong Mao",
      "Yongdong Zhang"
    ],
    "abstract": "Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01590.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01590",
    "published": "2026-02-02T03:30:13Z",
    "updated": "2026-02-02T03:30:13Z",
    "comment": "Preprint. Work in progress",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01588",
    "title": "Spectral Text Fusion: A Frequency-Aware Approach to Multimodal Time-Series Forecasting",
    "authors": [
      "Huu Hiep Nguyen",
      "Minh Hoang Nguyen",
      "Dung Nguyen",
      "Hung Le"
    ],
    "abstract": "Multimodal time series forecasting is crucial in real-world applications, where decisions depend on both numerical data and contextual signals. The core challenge is to effectively combine temporal numerical patterns with the context embedded in other modalities, such as text. While most existing methods align textual features with time-series patterns one step at a time, they neglect the multiscale temporal influences of contextual information such as time-series cycles and dynamic shifts. This mismatch between local alignment and global textual context can be addressed by spectral decomposition, which separates time series into frequency components capturing both short-term changes and long-term trends. In this paper, we propose SpecTF, a simple yet effective framework that integrates the effect of textual data on time series in the frequency domain. Our method extracts textual embeddings, projects them into the frequency domain, and fuses them with the time series' spectral components using a lightweight cross-attention mechanism. This adaptively reweights frequency bands based on textual relevance before mapping the results back to the temporal domain for predictions. Experimental results demonstrate that SpecTF significantly outperforms state-of-the-art models across diverse multi-modal time series datasets while utilizing considerably fewer parameters. Code is available at https://github.com/hiepnh137/SpecTF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01588.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01588",
    "published": "2026-02-02T03:28:21Z",
    "updated": "2026-02-02T03:28:21Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01587",
    "title": "Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment",
    "authors": [
      "Zehua Cheng",
      "Jianwei Yang",
      "Wei Dai",
      "Jiahao Sun"
    ],
    "abstract": "Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01587.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01587",
    "published": "2026-02-02T03:26:45Z",
    "updated": "2026-02-02T03:26:45Z",
    "comment": "10 pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01586",
    "title": "HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation",
    "authors": [
      "Wencan Cheng",
      "Gim Hee Lee"
    ],
    "abstract": "3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01586.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01586",
    "published": "2026-02-02T03:25:43Z",
    "updated": "2026-02-02T03:25:43Z",
    "comment": "AAAI accepted",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01585",
    "title": "A Lightweight Sparse Interaction Network for Time Series Forecasting",
    "authors": [
      "Xu Zhang",
      "Qitong Wang",
      "Peng Wang",
      "Wei Wang"
    ],
    "abstract": "Recent work shows that linear models can outperform several transformer models in long-term time-series forecasting (TSF). However, instead of explicitly performing temporal interaction through self-attention, linear models implicitly perform it based on stacked MLP structures, which may be insufficient in capturing the complex temporal dependencies and their performance still has potential for improvement. To this end, we propose a Lightweight Sparse Interaction Network (LSINet) for TSF task. Inspired by the sparsity of self-attention, we propose a Multihead Sparse Interaction Mechanism (MSIM). Different from self-attention, MSIM learns the important connections between time steps through sparsity-induced Bernoulli distribution to capture temporal dependencies for TSF. The sparsity is ensured by the proposed self-adaptive regularization loss. Moreover, we observe the shareability of temporal interactions and propose to perform Shared Interaction Learning (SIL) for MSIM to further enhance efficiency and improve convergence. LSINet is a linear model comprising only MLP structures with low overhead and equipped with explicit temporal interaction mechanisms. Extensive experiments on public datasets show that LSINet achieves both higher accuracy and better efficiency than advanced linear models and transformer models in TSF tasks. The code is available at the link https://github.com/Meteor-Stars/LSINet.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01585.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01585",
    "published": "2026-02-02T03:24:14Z",
    "updated": "2026-02-02T03:24:14Z",
    "comment": "The paper is published in AAAI Conference on Artificial Intelligence, AAAI 2025. The code is available at the link https://github.com/Meteor-Stars/LSINet",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01581",
    "title": "Nearly Optimal Active Preference Learning and Its Application to LLM Alignment",
    "authors": [
      "Yao Zhao",
      "Kwang-Sung Jun"
    ],
    "abstract": "Aligning large language models (LLMs) depends on high-quality datasets of human preference labels, which are costly to collect. Although active learning has been studied to improve sample efficiency relative to passive collection, many existing approaches adopt classical experimental design criteria such as G- or D-optimality. These objectives are not tailored to the structure of preference learning, leaving open the design of problem-specific algorithms. In this work, we identify a simple intuition specific to preference learning that calls into question the suitability of these existing design objectives. Motivated by this insight, we propose two active learning algorithms. The first provides the first instance-dependent label complexity guarantee for this setting, and the second is a simple, practical greedy method. We evaluate our algorithm on real-world preference datasets and observe improved sample efficiency compared to existing methods.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01581.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01581",
    "published": "2026-02-02T03:21:29Z",
    "updated": "2026-02-02T03:21:29Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01576",
    "title": "Generative Visual Code Mobile World Models",
    "authors": [
      "Woosung Koh",
      "Sungjun Han",
      "Segyu Lee",
      "Se-Young Yun",
      "Jamin Shin"
    ],
    "abstract": "Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01576.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01576",
    "published": "2026-02-02T03:12:16Z",
    "updated": "2026-02-02T03:12:16Z",
    "comment": "Pre-print (technical report)",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01574",
    "title": "SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models",
    "authors": [
      "Haobo Wang",
      "Weiqi Luo",
      "Xiaojun Jia",
      "Xiaochun Cao"
    ],
    "abstract": "Large vision-language models (VLMs) are vulnerable to transfer-based adversarial perturbations, enabling attackers to optimize on surrogate models and manipulate black-box VLM outputs. Prior targeted transfer attacks often overfit surrogate-specific embedding space by relying on a single reference and emphasizing final-layer alignment, which underutilizes intermediate semantics and degrades transfer across heterogeneous VLMs. To address this, we propose SGHA-Attack, a Semantic-Guided Hierarchical Alignment framework that adopts multiple target references and enforces intermediate-layer consistency. Concretely, we generate a visually grounded reference pool by sampling a frozen text-to-image model conditioned on the target prompt, and then carefully select the Top-K most semantically relevant anchors under the surrogate to form a weighted mixture for stable optimization guidance. Building on these anchors, SGHA-Attack injects target semantics throughout the feature hierarchy by aligning intermediate visual representations at both global and spatial granularities across multiple depths, and by synchronizing intermediate visual and textual features in a shared latent subspace to provide early cross-modal supervision before the final projection. Extensive experiments on open-source and commercial black-box VLMs show that SGHA-Attack achieves stronger targeted transferability than prior methods and remains robust under preprocessing and purification defenses.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01574.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01574",
    "published": "2026-02-02T03:10:41Z",
    "updated": "2026-02-02T03:10:41Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01572",
    "title": "LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States",
    "authors": [
      "Yeqin Zhang",
      "Yunfei Wang",
      "Jiaxuan Chen",
      "Ke Qin",
      "Yizheng Zhao",
      "Cam-Tu Nguyen"
    ],
    "abstract": "Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01572.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01572",
    "published": "2026-02-02T03:09:37Z",
    "updated": "2026-02-02T03:09:37Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01570",
    "title": "One-Step Diffusion for Perceptual Image Compression",
    "authors": [
      "Yiwen Jia",
      "Hao Wei",
      "Yanhui Zhou",
      "Chenyang Ge"
    ],
    "abstract": "Diffusion-based image compression methods have achieved notable progress, delivering high perceptual quality at low bitrates. However, their practical deployment is hindered by significant inference latency and heavy computational overhead, primarily due to the large number of denoising steps required during decoding. To address this problem, we propose a diffusion-based image compression method that requires only a single-step diffusion process, significantly improving inference speed. To enhance the perceptual quality of reconstructed images, we introduce a discriminator that operates on compact feature representations instead of raw pixels, leveraging the fact that features better capture high-level texture and structural details. Experimental results show that our method delivers comparable compression performance while offering a 46$\\times$ faster inference speed compared to recent diffusion-based approaches. The source code and models are available at https://github.com/cheesejiang/OSDiff.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2602.01570.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01570",
    "published": "2026-02-02T03:04:08Z",
    "updated": "2026-02-02T03:04:08Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01566",
    "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents",
    "authors": [
      "Chiwei Zhu",
      "Benfeng Xu",
      "Mingxuan Du",
      "Shaohan Wang",
      "Xiaorui Wang",
      "Zhendong Mao",
      "Yongdong Zhang"
    ],
    "abstract": "Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2602.01566.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01566",
    "published": "2026-02-02T03:00:19Z",
    "updated": "2026-02-02T03:00:19Z",
    "comment": "19 pages, 6 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2602.01564",
    "title": "Local Exponential Stability of Mean-Field Langevin Descent-Ascent in Wasserstein Space",
    "authors": [
      "Geuntaek Seo",
      "Minseop Shin",
      "Pierre Monmarché",
      "Beomjun Choi"
    ],
    "abstract": "We study the mean-field Langevin descent-ascent (MFL-DA), a coupled optimization dynamics on the space of probability measures for entropically regularized two-player zero-sum games. Although the associated mean-field objective admits a unique mixed Nash equilibrium, the long-time behavior of the original MFL-DA for general nonconvex-nonconcave payoffs has remained largely open. Answering an open question posed by Wang and Chizat (COLT 2024), we provide a partial resolution by proving that this equilibrium is locally exponentially stable: if the initialization is sufficiently close in Wasserstein metric, the dynamics trends to the equilibrium at an exponential rate. The key to our analysis is to establish a coercivity estimate for the entropy near equilibrium via spectral analysis of the linearized operator. We show that this coercivity effectively reveals a local displacement convex-concave structure, thereby driving contraction. This result settles the local stability and quantitative rate questions of Wang and Chizat, leaving global convergence as a remaining open challenge.",
    "categories": [
      "cs.LG",
      "math.AP",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2602.01564.pdf",
    "abs_url": "https://arxiv.org/abs/2602.01564",
    "published": "2026-02-02T02:58:17Z",
    "updated": "2026-02-02T02:58:17Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.23001",
    "title": "Bias Beyond Borders: Political Ideology Evaluation and Steering in Multilingual LLMs",
    "authors": [
      "Afrozah Nadeem",
      "Agrima",
      "Mehwish Nasim",
      "Usman Naseem"
    ],
    "abstract": "Large Language Models (LLMs) increasingly shape global discourse, making fairness and ideological neutrality essential for responsible AI deployment. Despite growing attention to political bias in LLMs, prior work largely focuses on high-resource, Western languages or narrow multilingual settings, leaving cross-lingual consistency and safe post-hoc mitigation underexplored. To address this gap, we present a large-scale multilingual evaluation of political bias spanning 50 countries and 33 languages. We introduce a complementary post-hoc mitigation framework, Cross-Lingual Alignment Steering (CLAS), designed to augment existing steering methods by aligning ideological representations across languages and dynamically regulating intervention strength. This method aligns latent ideological representations induced by political prompts into a shared ideological subspace, ensuring cross lingual consistency, with the adaptive mechanism prevents over correction and preserves coherence. Experiments demonstrate substantial bias reduction along both economic and social axes with minimal degradation in response quality. The proposed framework establishes a scalable and interpretable paradigm for fairness-aware multilingual LLM governance, balancing ideological neutrality with linguistic and cultural diversity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.23001.pdf",
    "abs_url": "https://arxiv.org/abs/2601.23001",
    "published": "2026-01-30T14:07:25Z",
    "updated": "2026-02-02T05:40:17Z",
    "comment": "PrePrint",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22944",
    "title": "Environment-Conditioned Tail Reweighting for Total Variation Invariant Risk Minimization",
    "authors": [
      "Yuanchao Wang",
      "Zhao-Rong Lai",
      "Tianqi Zhong",
      "Fengnan Li"
    ],
    "abstract": "Out-of-distribution (OOD) generalization remains challenging when models simultaneously encounter correlation shifts across environments and diversity shifts driven by rare or hard samples. Existing invariant risk minimization (IRM) methods primarily address spurious correlations at the environment level, but often overlook sample-level heterogeneity within environments, which can critically impact OOD performance. In this work, we propose Environment-Conditioned Tail Reweighting for Total Variation Invariant Risk Minimization (ECTR), a unified framework that augments TV-based invariant learning with environment-conditioned tail reweighting to jointly address both types of distribution shift. By integrating environment-level invariance with within-environment robustness, the proposed approach makes these two mechanisms complementary under mixed distribution shifts. We further extend the framework to scenarios without explicit environment annotations by inferring latent environments through a minimax formulation. Experiments across regression, tabular, time-series, and image classification benchmarks under mixed distribution shifts demonstrate consistent improvements in both worst-environment and average OOD performance.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22944.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22944",
    "published": "2026-01-30T13:03:04Z",
    "updated": "2026-02-02T09:28:56Z",
    "comment": "8 pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22929",
    "title": "Semantic Leakage from Image Embeddings",
    "authors": [
      "Yiyi Chen",
      "Qiongkai Xu",
      "Desmond Elliott",
      "Qiongxiu Li",
      "Johannes Bjerva"
    ],
    "abstract": "Image embeddings are generally assumed to pose limited privacy risk. We challenge this assumption by formalizing semantic leakage as the ability to recover semantic structures from compressed image embeddings. Surprisingly, we show that semantic leakage does not require exact reconstruction of the original image. Preserving local semantic neighborhoods under embedding alignment is sufficient to expose the intrinsic vulnerability of image embeddings. Crucially, this preserved neighborhood structure allows semantic information to propagate through a sequence of lossy mappings. Based on this conjecture, we propose Semantic Leakage from Image Embeddings (SLImE), a lightweight inference framework that reveals semantic information from standalone compressed image embeddings, incorporating a locally trained semantic retriever with off-the-shelf models, without training task-specific decoders. We thoroughly validate each step of the framework empirically, from aligned embeddings to retrieved tags, symbolic representations, and grammatical and coherent descriptions. We evaluate SLImE across a range of open and closed embedding models, including GEMINI, COHERE, NOMIC, and CLIP, and demonstrate consistent recovery of semantic information across diverse inference tasks. Our results reveal a fundamental vulnerability in image embeddings, whereby the preservation of semantic neighborhoods under alignment enables semantic leakage, highlighting challenges for privacy preservation.1",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22929.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22929",
    "published": "2026-01-30T12:46:41Z",
    "updated": "2026-02-02T09:20:53Z",
    "comment": "20 pages, 19 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22861",
    "title": "Under-Canopy Terrain Reconstruction in Dense Forests Using RGB Imaging and Neural 3D Reconstruction",
    "authors": [
      "Refael Sheffer",
      "Chen Pinchover",
      "Haim Zisman",
      "Dror Ozeri",
      "Roee Litman"
    ],
    "abstract": "Mapping the terrain and understory hidden beneath dense forest canopies is of great interest for numerous applications such as search and rescue, trail mapping, forest inventory tasks, and more. Existing solutions rely on specialized sensors: either heavy, costly airborne LiDAR, or Airborne Optical Sectioning (AOS), which uses thermal synthetic aperture photography and is tailored for person detection.   We introduce a novel approach for the reconstruction of canopy-free, photorealistic ground views using only conventional RGB images. Our solution is based on the celebrated Neural Radiance Fields (NeRF), a recent 3D reconstruction method. Additionally, we include specific image capture considerations, which dictate the needed illumination to successfully expose the scene beneath the canopy. To better cope with the poorly lit understory, we employ a low light loss. Finally, we propose two complementary approaches to remove occluding canopy elements by controlling per-ray integration procedure.   To validate the value of our approach, we present two possible downstream tasks. For the task of search and rescue (SAR), we demonstrate that our method enables person detection which achieves promising results compared to thermal AOS (using only RGB images). Additionally, we show the potential of our approach for forest inventory tasks like tree counting. These results position our approach as a cost-effective, high-resolution alternative to specialized sensors for SAR, trail mapping, and forest-inventory tasks.",
    "categories": [
      "cs.CV",
      "cs.CY",
      "cs.ET",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22861.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22861",
    "published": "2026-01-30T11:38:56Z",
    "updated": "2026-02-02T07:24:42Z",
    "comment": "WACV 2026 CV4EO",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22763",
    "title": "Is Training Necessary for Anomaly Detection?",
    "authors": [
      "Xingwu Zhang",
      "Guanxuan Li",
      "Paul Henderson",
      "Gerardo Aragon-Camarasa",
      "Zijun Long"
    ],
    "abstract": "Current state-of-the-art multi-class unsupervised anomaly detection (MUAD) methods rely on training encoder-decoder models to reconstruct anomaly-free features. We first show these approaches have an inherent fidelity-stability dilemma in how they detect anomalies via reconstruction residuals. We then abandon the reconstruction paradigm entirely and propose Retrieval-based Anomaly Detection (RAD). RAD is a training-free approach that stores anomaly-free features in a memory and detects anomalies through multi-level retrieval, matching test patches against the memory. Experiments demonstrate that RAD achieves state-of-the-art performance across four established benchmarks (MVTec-AD, VisA, Real-IAD, 3D-ADAM) under both standard and few-shot settings. On MVTec-AD, RAD reaches 96.7\\% Pixel AUROC with just a single anomaly-free image compared to 98.5\\% of RAD's full-data performance. We further prove that retrieval-based scores theoretically upper-bound reconstruction-residual scores. Collectively, these findings overturn the assumption that MUAD requires task-specific training, showing that state-of-the-art anomaly detection is feasible with memory-based retrieval. Our code is available at https://github.com/longkukuhi/RAD.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22763.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22763",
    "published": "2026-01-30T09:40:42Z",
    "updated": "2026-02-02T03:56:50Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22709",
    "title": "Gated Relational Alignment via Confidence-based Distillation for Efficient VLMs",
    "authors": [
      "Yanlong Chen",
      "Amirhossein Habibian",
      "Luca Benini",
      "Yawei Li"
    ],
    "abstract": "Vision-Language Models (VLMs) achieve strong multimodal performance but are costly to deploy, and post-training quantization often causes significant accuracy loss. Despite its potential, quantization-aware training for VLMs remains underexplored. We propose GRACE, a framework unifying knowledge distillation and QAT under the Information Bottleneck principle: quantization constrains information capacity while distillation guides what to preserve within this budget. Treating the teacher as a proxy for task-relevant information, we introduce confidence-gated decoupled distillation to filter unreliable supervision, relational centered kernel alignment to transfer visual token structures, and an adaptive controller via Lagrangian relaxation to balance fidelity against capacity constraints. Across extensive benchmarks on LLaVA and Qwen families, our INT4 models consistently outperform FP16 baselines (e.g., LLaVA-1.5-7B: 70.1 vs. 66.8 on SQA; Qwen2-VL-2B: 76.9 vs. 72.6 on MMBench), nearly matching teacher performance. Using real INT4 kernel, we achieve 3$\\times$ throughput with 54% memory reduction. This principled framework significantly outperforms existing quantization methods, making GRACE a compelling solution for resource-constrained deployment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22709.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22709",
    "published": "2026-01-30T08:30:52Z",
    "updated": "2026-02-02T06:39:48Z",
    "comment": "This paper is currently under review",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22674",
    "title": "VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration",
    "authors": [
      "Hanxun Yu",
      "Wentong Li",
      "Xuan Qu",
      "Song Wang",
      "Junbo Chen",
      "Jianke Zhu"
    ],
    "abstract": "Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens, particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.22674.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22674",
    "published": "2026-01-30T07:45:48Z",
    "updated": "2026-02-02T09:21:10Z",
    "comment": "ICLR2026, Code Link: https://github.com/hanxunyu/VisionTrim",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22285",
    "title": "Demystifying Mergeability: Interpretable Properties to Predict Model Merging Success",
    "authors": [
      "Luca Zhou",
      "Bo Zhao",
      "Rose Yu",
      "Emanuele Rodolà"
    ],
    "abstract": "Model merging combines knowledge from separately fine-tuned models, yet success factors remain poorly understood. While recent work treats mergeability as an intrinsic property, we show with an architecture-agnostic framework that it fundamentally depends on both the merging method and the partner tasks. Using linear optimization over a set of interpretable pairwise metrics (e.g., gradient L2 distance), we uncover properties correlating with post-merge performance across four merging methods. We find substantial variation in success drivers (46.7% metric overlap; 55.3% sign agreement), revealing method-specific \"fingerprints\". Crucially, however, subspace overlap and gradient alignment metrics consistently emerge as foundational, method-agnostic prerequisites for compatibility. These findings provide a diagnostic foundation for understanding mergeability and motivate future fine-tuning strategies that explicitly encourage these properties.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22285.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22285",
    "published": "2026-01-29T20:00:26Z",
    "updated": "2026-02-02T07:07:31Z",
    "comment": "8 pages of main paper, 3 figures in the main paper, 4 tables in the main paper, many more figures and tables in the appendix",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.19103",
    "title": "Glance and Focus Reinforcement for Pan-cancer Screening",
    "authors": [
      "Linshan Wu",
      "Jiaxin Zhuang",
      "Hao Chen"
    ],
    "abstract": "Pan-cancer screening in large-scale CT scans remains challenging for existing AI methods, primarily due to the difficulty of localizing diverse types of tiny lesions in large CT volumes. The extreme foreground-background imbalance significantly hinders models from focusing on diseased regions, while redundant focus on healthy regions not only decreases the efficiency but also increases false positives. Inspired by radiologists' glance and focus diagnostic strategy, we introduce GF-Screen, a Glance and Focus reinforcement learning framework for pan-cancer screening. GF-Screen employs a Glance model to localize the diseased regions and a Focus model to precisely segment the lesions, where segmentation results of the Focus model are leveraged to reward the Glance model via Reinforcement Learning (RL). Specifically, the Glance model crops a group of sub-volumes from the entire CT volume and learns to select the sub-volumes with lesions for the Focus model to segment. Given that the selecting operation is non-differentiable for segmentation training, we propose to employ the segmentation results to reward the Glance model. To optimize the Glance model, we introduce a novel group relative learning paradigm, which employs group relative comparison to prioritize high-advantage predictions and discard low-advantage predictions within sub-volume groups, not only improving efficiency but also reducing false positives. In this way, for the first time, we effectively extend cutting-edge RL techniques to tackle the specific challenges in pan-cancer screening. Extensive experiments on 16 internal and 7 external datasets across 9 lesion types demonstrated the effectiveness of GF-Screen. Notably, GF-Screen leads the public validation leaderboard of MICCAI FLARE25 pan-cancer challenge, surpassing the FLARE24 champion solution by a large margin (+25.6% DSC and +28.2% NSD).",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.19103.pdf",
    "abs_url": "https://arxiv.org/abs/2601.19103",
    "published": "2026-01-27T02:10:34Z",
    "updated": "2026-02-02T08:40:13Z",
    "comment": "Accepted by ICLR 2026. Code is available at https://github.com/Luffy03/GF-Screen",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.15519",
    "title": "TransportAgents: a multi-agents LLM framework for traffic accident severity prediction",
    "authors": [
      "Zhichao Yang",
      "Jiashu He",
      "Jinxuan Fan",
      "Cirillo Cinzia"
    ],
    "abstract": "Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2601.15519.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15519",
    "published": "2026-01-21T23:14:05Z",
    "updated": "2026-02-02T04:18:37Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.15475",
    "title": "Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events",
    "authors": [
      "Yunshan Qi",
      "Lin Zhu",
      "Nan Bao",
      "Yifan Zhao",
      "Jia Li"
    ],
    "abstract": "Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2601.15475.pdf",
    "abs_url": "https://arxiv.org/abs/2601.15475",
    "published": "2026-01-21T21:25:58Z",
    "updated": "2026-02-02T08:35:26Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.05488",
    "title": "MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards",
    "authors": [
      "Zhiyu Shen",
      "Ziming Wu",
      "Fuming Lai",
      "Shaobing Lian",
      "Yanghui Rao"
    ],
    "abstract": "Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that trains models to orchestrate multi-dimensional memory construction with attributed dense rewards. MemBuilder addresses two key challenges: (1) Sparse Trajectory-Level Rewards: we employ synthetic session-level question generation to provide dense intermediate rewards across extended trajectories; and (2) Multi-Dimensional Memory Attribution: we introduce contribution-aware gradient weighting that scales policy updates based on each component's downstream impact. Experimental results show that MemBuilder enables a 4B-parameter model to outperform state-of-the-art closed-source baselines, exhibiting strong generalization across long-term dialogue benchmarks.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2601.05488.pdf",
    "abs_url": "https://arxiv.org/abs/2601.05488",
    "published": "2026-01-09T02:44:37Z",
    "updated": "2026-02-02T09:29:13Z",
    "comment": "19 pages (9 main + 10 appendix), 7 figures, 3 tables",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2601.22161",
    "title": "Attention Isn't All You Need for Emotion Recognition:Domain Features Outperform Transformers on the EAV Dataset",
    "authors": [
      "Anmol Guragain"
    ],
    "abstract": "We present a systematic study of multimodal emotion recognition using the EAV dataset, investigating whether complex attention mechanisms improve performance on small datasets. We implement three model categories: baseline transformers (M1), novel factorized attention mechanisms (M2), and improved CNN baselines (M3). Our experiments show that sophisticated attention mechanisms consistently underperform on small datasets. M2 models achieved 5 to 13 percentage points below baselines due to overfitting and destruction of pretrained features. In contrast, simple domain-appropriate modifications proved effective: adding delta MFCCs to the audio CNN improved accuracy from 61.9% to 65.56% (+3.66pp), while frequency-domain features for EEG achieved 67.62% (+7.62pp over the paper baseline). Our vision transformer baseline (M1) reached 75.30%, exceeding the paper's ViViT result (74.5%) through domain-specific pretraining, and vision delta features achieved 72.68% (+1.28pp over the paper CNN). These findings demonstrate that for small-scale emotion recognition, domain knowledge and proper implementation outperform architectural complexity.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2601.22161.pdf",
    "abs_url": "https://arxiv.org/abs/2601.22161",
    "published": "2026-01-07T18:22:01Z",
    "updated": "2026-02-02T11:50:11Z",
    "comment": "2 figures, 10 Pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2512.20576",
    "title": "Performative Policy Gradient: Optimality in Performative Reinforcement Learning",
    "authors": [
      "Debabrota Basu",
      "Udvas Das",
      "Brahim Driss",
      "Uddalak Mukherjee"
    ],
    "abstract": "Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms the existing performative RL algorithms aiming for stability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.20576.pdf",
    "abs_url": "https://arxiv.org/abs/2512.20576",
    "published": "2025-12-23T18:20:06Z",
    "updated": "2026-02-02T11:24:53Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2512.19673",
    "title": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
    "authors": [
      "Yuqiao Tan",
      "Minzheng Wang",
      "Shizhu He",
      "Huanxuan Liao",
      "Chengfeng Zhao",
      "Qiunan Lu",
      "Tian Liang",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a unified policy, overlooking their internal mechanisms. In this paper, we decompose the LLM-based policy into Internal Layer Policies and Internal Modular Policies via Transformer's residual stream. Our entropy analysis on internal policy reveals distinct patterns: (1) universally, policies evolve from high-entropy exploration in early layers to deterministic refinement in top layers; and (2) Qwen exhibits a progressive, human-like reasoning structure, contrasting with the abrupt final-layer convergence in Llama. Furthermore, we discover that optimizing internal layers induces feature refinement, forcing lower layers to capture high-level reasoning representations early. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that reconstructs the LLM's reasoning foundation from the bottom up by optimizing internal layers in early stages. Extensive experiments on complex reasoning benchmarks demonstrate the effectiveness of BuPO. Our code is available at https://github.com/Trae1ounG/BuPO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.19673.pdf",
    "abs_url": "https://arxiv.org/abs/2512.19673",
    "published": "2025-12-22T18:51:48Z",
    "updated": "2026-02-02T11:29:09Z",
    "comment": "Preprint. Our code is available at https://github.com/Trae1ounG/BuPO",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2512.18595",
    "title": "Benchmarking neural surrogates on realistic spatiotemporal multiphysics flows",
    "authors": [
      "Runze Mao",
      "Rui Zhang",
      "Xuan Bai",
      "Tianhao Wu",
      "Teng Zhang",
      "Zhenyi Chen",
      "Minqi Lin",
      "Bocheng Zeng",
      "Yangchen Xu",
      "Yingxuan Xiang",
      "Haoze Zhang",
      "Shubham Goswami",
      "Pierre A. Dawe",
      "Yifan Xu",
      "Zhenhua An",
      "Mengtao Yan",
      "Xiaoyi Lu",
      "Yi Wang",
      "Rongbo Bai",
      "Haobu Gao",
      "Xiaohang Fang",
      "Han Li",
      "Hao Sun",
      "Zhi X. Chen"
    ],
    "abstract": "Predicting multiphysics dynamics is computationally expensive and challenging due to the severe coupling of multi-scale, heterogeneous physical processes. While neural surrogates promise a paradigm shift, the field currently suffers from an \"illusion of mastery\", as repeatedly emphasized in top-tier commentaries: existing evaluations overly rely on simplified, low-dimensional proxies, which fail to expose the models' inherent fragility in realistic regimes. To bridge this critical gap, we present REALM (REalistic AI Learning for Multiphysics), a rigorous benchmarking framework designed to test neural surrogates on challenging, application-driven reactive flows. REALM features 11 high-fidelity datasets spanning from canonical multiphysics problems to complex propulsion and fire safety scenarios, alongside a standardized end-to-end training and evaluation protocol that incorporates multiphysics-aware preprocessing and a robust rollout strategy. Using this framework, we systematically benchmark over a dozen representative surrogate model families, including spectral operators, convolutional models, Transformers, pointwise operators, and graph/mesh networks, and identify three robust trends: (i) a scaling barrier governed jointly by dimensionality, stiffness, and mesh irregularity, leading to rapidly growing rollout errors; (ii) performance primarily controlled by architectural inductive biases rather than parameter count; and (iii) a persistent gap between nominal accuracy metrics and physically trustworthy behavior, where models with high correlations still miss key transient structures and integral quantities. Taken together, REALM exposes the limits of current neural surrogates on realistic multiphysics flows and offers a rigorous testbed to drive the development of next-generation physics-aware architectures.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.18595.pdf",
    "abs_url": "https://arxiv.org/abs/2512.18595",
    "published": "2025-12-21T05:04:13Z",
    "updated": "2026-02-02T05:48:56Z",
    "comment": "52 pages, 20 figures. Code and data available at https://github.com/deepflame-ai/REALM. Companion website and leaderboard at https://realm-bench.org",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2512.10942",
    "title": "VL-JEPA: Joint Embedding Predictive Architecture for Vision-language",
    "authors": [
      "Delong Chen",
      "Mustafa Shukor",
      "Theo Moutakanni",
      "Willy Chung",
      "Jade Yu",
      "Tejaswi Kasarla",
      "Yejin Bang",
      "Allen Bolourchi",
      "Yann LeCun",
      "Pascale Fung"
    ],
    "abstract": "We introduce VL-JEPA, a vision-language model built on a Joint Embedding Predictive Architecture (JEPA). Instead of autoregressively generating tokens as in classical VLMs, VL-JEPA predicts continuous embeddings of the target texts. By learning in an abstract representation space, the model focuses on task-relevant semantics while abstracting away surface-level linguistic variability. In a strictly controlled comparison against standard token-space VLM training with the same vision encoder and training data, VL-JEPA achieves stronger performance while having 50% fewer trainable parameters. At inference time, a lightweight text decoder is invoked only when needed to translate VL-JEPA predicted embeddings into text. We show that VL-JEPA natively supports selective decoding that reduces the number of decoding operations by 2.85x while maintaining similar performance compared to non-adaptive uniform decoding. Beyond generation, the VL-JEPA's embedding space naturally supports open-vocabulary classification, text-to-video retrieval, and discriminative VQA without any architecture modification. On eight video classification and eight video retrieval datasets, the average performance VL-JEPA surpasses that of CLIP, SigLIP2, and Perception Encoder. At the same time, the model achieves comparable performance as classical VLMs (InstructBLIP, QwenVL) on four VQA datasets: GQA, TallyQA, POPE and POPEv2, despite only having 1.6B parameters.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.10942.pdf",
    "abs_url": "https://arxiv.org/abs/2512.10942",
    "published": "2025-12-11T18:59:22Z",
    "updated": "2026-02-02T12:38:20Z",
    "comment": null,
    "light_analysis": {
      "overview": "VL-JEPA通过预测连续文本嵌入而非生成离散token，提出了一种基于联合嵌入预测架构的高效视觉-语言模型。",
      "motivation": "该研究旨在解决传统视觉-语言模型（VLMs）中自回归生成token方法的效率不足问题，这些方法通常对表面语言变异性敏感且参数效率低下。现有方法在任务泛化和计算资源消耗方面存在局限，而VL-JEPA通过抽象表示空间学习，专注于语义而非形式，以提升性能和可扩展性，应对多模态任务中的挑战。",
      "method": "VL-JEPA基于Joint Embedding Predictive Architecture (JEPA)，核心方法是通过预测目标文本的连续嵌入来替代token生成。关键创新在于在抽象表示空间学习任务相关语义，忽略语言表面变异性；使用相同视觉编码器和训练数据，模型架构更简洁。推理时仅调用轻量级文本解码器将嵌入转换为文本，支持选择性解码以减少计算操作。",
      "result": "在严格控制下，VL-JEPA相比标准token空间VLM训练性能更强，参数减少50%。选择性解码将解码操作减少2.85倍，同时维持相似性能。在8个视频分类和8个视频检索数据集上，平均性能超越CLIP、SigLIP2和Perception Encoder；在4个VQA数据集（GQA、TallyQA、POPE和POPEv2）上，参数仅1.6B时性能可比InstructBLIP和QwenVL。",
      "conclusion": "VL-JEPA的主要贡献是提供了一种高效的视觉-语言建模方法，通过嵌入预测支持多种任务如开放词汇分类和检索，无需架构修改。学术价值在于推动了抽象表示空间学习的研究，实际应用价值在于减少计算资源。未来工作可能包括扩展到更多任务或优化模型泛化能力。",
      "tags": [
        "Joint Embedding Predictive Architecture",
        "Vision-language Modeling",
        "Embedding Prediction",
        "Selective Decoding",
        "Open-vocabulary Classification"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:21.186610Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.04456",
    "title": "GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis",
    "authors": [
      "Changjin Kim",
      "HyeokJun Lee",
      "YoungJoon Yoo"
    ],
    "abstract": "Recent image denoising methods have leveraged generative modeling for real noise synthesis to address the costly acquisition of real-world noisy data. However, these generative models typically require camera metadata and extensive target-specific noisy-clean image pairs, often showing limited generalization between settings. In this paper, to mitigate the prerequisites, we propose a Single-Pair Guided Diffusion for generalized noise synthesis GuidNoise, which uses a single noisy/clean pair as the guidance, often easily obtained by itself within a training set. To train GuidNoise, which generates synthetic noisy images from the guidance, we introduce a guidance-aware affine feature modification (GAFM) and a noise-aware refine loss to leverage the inherent potential of diffusion models. This loss function refines the diffusion model's backward process, making the model more adept at generating realistic noise distributions. The GuidNoise synthesizes high-quality noisy images under diverse noise environments without additional metadata during both training and inference. Additionally, GuidNoise enables the efficient generation of noisy-clean image pairs at inference time, making synthetic noise readily applicable for augmenting training data. This self-augmentation significantly improves denoising performance, especially in practical scenarios with lightweight models and limited training data. The code is available at https://github.com/chjinny/GuidNoise.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.04456.pdf",
    "abs_url": "https://arxiv.org/abs/2512.04456",
    "published": "2025-12-04T05:00:00Z",
    "updated": "2026-02-02T03:41:37Z",
    "comment": "AAAI2026",
    "light_analysis": {
      "overview": "提出了GuidNoise方法，利用单对噪声/干净图像引导扩散模型，实现无需元数据的通用噪声合成。",
      "motivation": "当前图像去噪方法依赖生成模型合成真实噪声，以解决真实噪声数据获取成本高的问题，但现有方法通常需要相机元数据和大量特定噪声-干净图像对，导致泛化能力有限且数据需求大。本研究旨在减少这些前提条件，通过更灵活的单对图像引导来合成通用噪声，以改进去噪模型训练，特别是在实际场景中轻量模型和数据不足的情况下，提升方法的应用广泛性。",
      "method": "GuidNoise采用单对噪声/干净图像作为引导，结合引导感知的仿射特征修改（GAFM）和噪声感知精炼损失，优化扩散模型的反向过程。该方法利用扩散模型的潜力，在训练过程中通过损失函数精炼噪声分布生成，无需额外元数据。关键创新包括单对引导机制和特征修改技术，使得模型能适应多样噪声环境并生成高质量合成噪声图像，推理时也能高效生成噪声-干净图像对。",
      "result": "GuidNoise能生成高质量噪声图像，并通过自增强方式扩充训练数据，显著提高去噪性能。摘要未明确说明具体性能指标数据，但指出在轻量模型和有限训练数据场景下效果尤为明显，优于依赖大量数据和元数据的基线方法。生成的真实噪声分布使去噪模型在资源受限环境中表现更好，验证了方法的有效性和通用性。",
      "conclusion": "本研究提出了GuidNoise方法，降低了噪声合成对数据和元数据的依赖，推动了扩散模型在噪声生成中的应用。学术上，它扩展了生成模型在图像处理领域的潜力；实际上，为轻量去噪模型和数据稀缺场景提供了实用解决方案，未来可探索更多图像增强任务和噪声类型的适应性改进。",
      "tags": [
        "Diffusion Models",
        "Noise Synthesis",
        "Image Denoising",
        "Generative Modeling",
        "Self-Augmentation"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:29.548811Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.04282",
    "title": "Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer",
    "authors": [
      "Tasmiah Haque",
      "Srinjoy Das"
    ],
    "abstract": "Real-time video motion transfer applications such as immersive gaming and vision-based anomaly detection require accurate yet diverse future predictions to support realistic synthesis and robust downstream decision making under uncertainty. To improve the diversity of such sequential forecasts we propose a novel inference-time refinement technique that combines Gated Recurrent Unit-Normalizing Flows (GRU-NF) with stochastic sampling methods. While GRU-NF can capture multimodal distributions through its integration of normalizing flows within a temporal forecasting framework, its deterministic transformation structure can limit expressivity. To address this, inspired by Stochastic Normalizing Flows (SNF), we introduce Markov Chain Monte Carlo (MCMC) steps during GRU-NF inference, enabling the model to explore a richer output space and better approximate the true data distribution without retraining. We validate our approach in a keypoint-based video motion transfer pipeline, where capturing temporally coherent and perceptually diverse future trajectories is essential for realistic samples and low bandwidth communication. Experiments show that our inference framework, Gated Recurrent Unit- Stochastic Normalizing Flows (GRU-SNF) outperforms GRU-NF in generating diverse outputs without sacrificing accuracy, even under longer prediction horizons. By injecting stochasticity during inference, our approach captures multimodal behavior more effectively. These results highlight the potential of integrating stochastic dynamics with flow-based sequence models for generative time series forecasting. The code is available at: https://github.com/Tasmiah1408028/Inference-Time-Stochastic-Refinement-Of-GRU-NF-For-Real-Time-Video-Motion-Transfer",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.04282.pdf",
    "abs_url": "https://arxiv.org/abs/2512.04282",
    "published": "2025-12-03T21:47:30Z",
    "updated": "2026-02-02T04:15:21Z",
    "comment": null,
    "light_analysis": {
      "overview": "本论文提出一种新颖的推断时随机精炼技术，将马尔可夫链蒙特卡洛步骤集成到门控循环单元归一化流模型中，以提高视频运动转移任务的多样化预测能力。",
      "motivation": "实时视频运动转移应用，如沉浸式游戏和基于视觉的异常检测，需要生成准确且多样化的未来预测，以支持现实样本合成和鲁棒的下游决策。然而，现有方法如GRU-Normalizing Flow虽然能捕获多模态分布，但其确定性变换结构限制了输出表达的多样性，导致在不确定性环境下预测不足，影响应用效果。因此，研究如何在不牺牲准确性的前提下增强预测多样性成为关键问题，这对提升合成质量和决策鲁棒性至关重要。",
      "method": "本研究提出Gated Recurrent Unit-Stochastic Normalizing Flows (GRU-SNF)，一种推断时精炼方法。该方法在GRU-Normalizing Flow的推断过程中引入Markov Chain Monte Carlo (MCMC) 步骤，灵感来自Stochastic Normalizing Flows，使模型能够随机探索更丰富的输出空间，从而更好地近似真实数据分布。关键创新在于在无需重新训练的情况下，通过随机采样技术提升模型的表达性。研究在一个基于关键点的视频运动转移管道中验证了该方法，利用时序预测框架捕获多模态分布。",
      "result": "实验结果显示，GRU-SNF在生成多样化输出方面优于基线方法GRU-NF，同时保持了预测准确性，尤其在更长预测视野下表现更佳。通过推断时注入随机性，模型能更有效地捕获多模态行为，提高了视频运动转移任务的性能。具体性能指标如准确率提升在摘要中未明确说明，但与GRU-NF相比，多样化输出有所改善，有助于支持现实样本合成和低带宽通信应用。",
      "conclusion": "本论文的主要贡献在于提出了一种集成随机动态与基于流序列模型的推断时精炼方法，增强了生成时间序列预测的多样性和真实性。学术上，展示了将随机性融入深度序列模型的潜力，为生成预测任务提供新思路；应用上，适用于实时视频运动转移等场景，能提高合成样本的逼真度和决策鲁棒性。未来工作可探索该方法在其他时间序列预测任务中的应用，并优化随机采样过程以提高效率。",
      "tags": [
        "Gated Recurrent Unit",
        "Normalizing Flow",
        "Stochastic Sampling",
        "Markov Chain Monte Carlo",
        "Video Motion Transfer"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:33.330210Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2512.00920",
    "title": "Reward Auditor: Inference on Reward Modeling Suitability in Real-World Perturbed Scenarios",
    "authors": [
      "Jianxiang Zang",
      "Yongda Wei",
      "Ruxue Bai",
      "Shiyu Jiang",
      "Nijia Mo",
      "Binhong Li",
      "Qiang Sun",
      "Hui Liu"
    ],
    "abstract": "Reliable reward models (RMs) are critical for ensuring the safe alignment of large language models (LLMs). However, current RM evaluation methods focus solely on preference perception accuracies in given specific scenarios, obscuring the critical vulnerabilities of RMs in real-world scenarios. We identify the true challenge lies in assessing a novel dimension: Suitability, defined as conditional reliability under specific real-world perturbations. To this end, we introduce Reward Auditor, a hypothesis-testing framework specifically designed for RM suitability inference. Rather than answering \"How accurate is the RM's preference perception for given samples?\", it employs scientific auditing to answer: \"Can we infer RMs exhibit systematic vulnerabilities in specific real-world scenarios?\". Under real-world perturbed scenarios, Reward Auditor quantifies statistical significance and effect size by auditing distribution degradation of RM preference perception confidence. This enables inference of both the certainty and severity of RM vulnerabilities across diverse real-world scenarios. This lays a solid foundation for building next-generation LLM alignment systems that are verifiably safe, more robust, and trustworthy.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2512.00920.pdf",
    "abs_url": "https://arxiv.org/abs/2512.00920",
    "published": "2025-11-30T14:54:12Z",
    "updated": "2026-02-02T06:23:08Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了Reward Auditor框架，创新性地评估奖励模型在现实扰动场景下的适用性，以识别系统性漏洞。",
      "motivation": "现有奖励模型评估方法仅关注特定场景下的偏好感知准确性，忽视了现实世界扰动中的关键漏洞。可靠奖励模型对大型语言模型的安全对齐至关重要，但当前方法无法全面评估模型在实际应用中的稳健性，导致潜在安全风险。因此，需要引入新的维度——Suitability（适用性），来更真实地反映模型在复杂现实环境中的表现。",
      "method": "Reward Auditor是一个假设检验框架，专门用于推断奖励模型在特定现实扰动场景下的适用性。核心方法是审计奖励模型偏好感知置信度的分布退化，从而量化统计显著性和效应大小。这允许系统性地推断漏洞的确定性和严重性，无需依赖传统准确性指标，而是通过科学审计来评估模型在多样化现实场景中的表现。",
      "result": "摘要未明确说明具体实验结果，如准确率提升或效率改进数据。但框架旨在通过假设检验推断奖励模型在现实扰动场景中的脆弱性，为后续实证研究提供理论基础，潜在应用于对比不同模型的稳健性并识别系统性缺陷。",
      "conclusion": "研究的主要贡献是引入Suitability维度并开发Reward Auditor框架，为构建下一代可验证安全、更稳健和可信的大型语言模型对齐系统奠定基础。这提升了模型评估的全面性，具有学术价值（推动对齐理论研究）和实际应用价值（增强AI系统安全性），未来工作可扩展至更多场景验证和优化方法。",
      "tags": [
        "Reward Modeling",
        "Large Language Model",
        "Hypothesis Testing",
        "Statistical Significance",
        "Real-World Perturbations"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:15.611884Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.23402",
    "title": "Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning",
    "authors": [
      "Jiajun Guo",
      "Xin Luo",
      "Jiayin Zheng",
      "Yiqun Wang",
      "Kai-Wei Chang",
      "Wei Wang",
      "Jie Liu"
    ],
    "abstract": "Multimodal foundation models are increasingly trained on sensitive data across domains such as finance, biomedicine, and personal identifiers. However, this distributed setup raises serious privacy concerns due to the need for cross-partition data sharing. Split learning addresses these concerns by enabling collaborative model training without raw data exchange between partitions, yet it introduces a significant challenge: transmitting high-dimensional intermediate feature representations between partitions leads to substantial communication costs. To address this challenge, we propose Quantized-TinyLLaVA, a multimodal foundation model with an integrated communication-efficient split learning framework. Our approach adopts a compression module that quantizes intermediate feature into discrete representations before transmission, substantially reducing communication overhead. Besides, we derive a principled quantization strategy grounded in entropy coding theory to determine the optimal number of discrete representation levels. We deploy our framework in a two-partition setting, with one partition operating as the client and the other as the server, to realistically simulate distributed training. Under this setup, Quantized-TinyLLaVA achieves an approximate \\textbf{87.5\\%} reduction in communication overhead with 2-bit quantization, while maintaining performance of the original 16-bit model across five benchmark datasets. Furthermore, our compressed representations exhibit enhanced resilience against feature inversion attacks, validating the privacy of transmission. The code is available at https://github.com/anonymous-1742/Quantized-TinyLLaVA.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.23402.pdf",
    "abs_url": "https://arxiv.org/abs/2511.23402",
    "published": "2025-11-28T17:53:05Z",
    "updated": "2026-02-02T05:07:36Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出Quantized-TinyLLaVA多模态基础模型，通过量化中间特征显著降低拆分学习的通信开销。",
      "motivation": "随着多模态基础模型在金融、生物医学等敏感数据领域的应用增加，跨分区训练引发隐私担忧。拆分学习能协作训练而无需共享原始数据，但传输高维中间特征导致高通信成本，限制了分布式场景的实用性。现有方法往往忽略通信效率问题，因此需要一种平衡隐私保护和效率的解决方案。",
      "method": "论文提出Quantized-TinyLLaVA，集成了通信效率高的拆分学习框架。核心方法使用压缩模块将中间特征量化为离散表示，并基于熵编码理论确定最优量化级别。在双分区设置（客户端和服务器）中部署，模拟分布式训练，以减少数据传输。摘要未明确说明具体模型架构和数据集细节。",
      "result": "Quantized-TinyLLaVA在2-bit量化下实现约87.5%的通信开销减少，同时在五个基准数据集上保持原始16-bit模型性能。压缩后的特征表示增强了对抗特征反转攻击的能力，进一步验证了隐私保护效果。与基线模型相比，通信效率显著提升，性能无损失。",
      "conclusion": "Quantized-TinyLLaVA通过量化技术有效解决拆分学习的通信瓶颈，为隐私敏感场景的多模态模型分布式训练提供高效方案。学术价值在于应用熵编码理论于量化，实际价值高，可推广其他领域。摘要未明确说明局限性，未来工作可能包括扩展到更多分区或模型类型。",
      "tags": [
        "Multimodal Foundation Model",
        "Split Learning",
        "Quantization",
        "Entropy Coding",
        "Communication Efficiency"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:27.508859Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.22099",
    "title": "Decomposed Trust: Exploring Privacy, Adversarial Robustness, Fairness, and Ethics of Low-Rank LLMs",
    "authors": [
      "Daniel Agyei Asante",
      "Md Mokarram Chowdhury",
      "Yang Li"
    ],
    "abstract": "Large language models (LLMs) have driven major advances across domains, yet their massive size hinders deployment in resource-constrained settings. Model compression addresses this challenge, with low-rank factorization emerging as a particularly effective method for reducing size, memory, and computation while maintaining accuracy. However, while these compressed models boast of benign performance and system-level advantages, their trustworthiness implications remain poorly understood. In this paper, we present the first comprehensive study of how low-rank factorization affects LLM trustworthiness across privacy, adversarial robustness, fairness, and ethical alignment. We evaluate multiple LLMs of different sizes and variants compressed with diverse low-rank algorithms, revealing key insights: (1) low-rank compression preserves or improves training data privacy but weakens PII protection during conversation; (2) adversarial robustness is generally preserved and often enhanced, even under deep compression; (3) ethical reasoning degrades in zero-shot settings but partially recovers with few-shot prompting; (4) fairness declines under compression. Beyond compression, we investigate how model scale and fine-tuning affect trustworthiness, as both are important in low-rank methods. To guide trustworthy compression strategies, we end our paper with a gradient-based attribution analysis to identify which layers in LLMs contribute most to adversarial robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.22099.pdf",
    "abs_url": "https://arxiv.org/abs/2511.22099",
    "published": "2025-11-27T04:40:56Z",
    "updated": "2026-02-02T08:35:00Z",
    "comment": "14 pages, 10 figures",
    "light_analysis": {
      "overview": "论文首次全面评估低秩压缩对大型语言模型在隐私、对抗性鲁棒性、公平性和伦理对齐方面的信任度影响。",
      "motivation": "大型语言模型（LLMs）在多个领域取得重大进展，但其庞大尺寸限制了在资源受限环境中的部署。模型压缩技术如低秩因子化被广泛采用，以减少模型大小、内存使用和计算成本，同时保持准确性。然而，现有研究主要关注压缩后的性能优势，而对压缩模型在信任度方面的潜在影响知之甚少。本研究旨在填补这一空白，探讨低秩压缩如何影响LLM的隐私保护、对抗性鲁棒性、公平性和伦理对齐，这些问题对于确保AI系统的安全和可靠应用至关重要。",
      "method": "本研究采用系统性评估方法，针对多个不同规模和变体的LLMs，使用多种低秩算法进行压缩，包括低秩因子化技术。研究重点考察压缩后模型在隐私（训练数据隐私和对话中个人身份信息保护）、对抗性鲁棒性（抵抗对抗攻击的能力）、公平性（不同群体表现公平性）和伦理对齐（遵循道德准则能力）方面的表现。此外，论文还研究了模型规模和微调对信任度的影响，并使用梯度基础属性分析来识别影响对抗性鲁棒性的关键模型层。摘要未明确说明具体数据集或详细模型架构。",
      "result": "实验结果表明，低秩压缩对LLM信任度产生复杂影响：在隐私方面，压缩模型保持或改善训练数据隐私，但对话中个人身份信息保护减弱；对抗性鲁棒性得到保持甚至增强，即使在深度压缩下；伦理推理在零样本设置下性能下降，但通过少量样本提示可部分恢复；公平性在压缩后普遍下降。这些发现基于与原始模型的对比，突出了压缩对信任度的不均匀效应。摘要未提供具体性能数值，但描述了定性趋势。",
      "conclusion": "本研究的核心贡献在于首次全面分析了低秩压缩对LLM信任度的影响，为隐私、对抗性鲁棒性、公平性和伦理对齐提供了深入见解。其学术价值在于深化了对模型压缩信任度效应的理解，并为开发更安全的压缩策略奠定基础。实际应用中，研究有助于指导在资源受限环境中部署可信赖AI模型。未来工作可能包括改进压缩算法以平衡性能与信任度，或扩展对其他信任维度的研究。摘要未明确说明局限性，但可推断评估范围可能有限。",
      "tags": [
        "Large Language Model",
        "Low-Rank Factorization",
        "Adversarial Robustness",
        "Fairness",
        "Privacy"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:53.959394Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.16886",
    "title": "Your Latent Reasoning is Secretly Policy Improvement Operator",
    "authors": [
      "Arip Asadulaev",
      "Rayan Banerjee",
      "Fakhri Karray",
      "Martin Takac"
    ],
    "abstract": "Recently, small models with latent recursion have obtained promising results on complex reasoning tasks. These results are typically explained by the theory that such recursion increases a networks depth, allowing it to compactly emulate the capacity of larger models. However, the performance of recursively added layers remains behind the capabilities of one pass models with the same feed forward depth. This means that in the looped version, not every recursive step effectively contributes to depth. This raises the question: when and why does latent reasoning improve performance, and when does it result in dead compute? In our work, we analyze the algorithms that latent reasoning provides answer to this question. We show that latent reasoning can be formalized as a classifier free guidance and policy improvement algorithm. Building on these insights, we propose to use a training schemes from reinforcement learning and diffusion methods for latent reasoning models. Using the Tiny Recursive Model as our testbed, we show that with our modifications we can avoid dead compute steps and reduce the total number of forward passes by 18x while maintaining performance. Broadly speaking, we show how a policy improvement perspective on recursive steps can explain model behavior and provide insights for further improvements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2511.16886.pdf",
    "abs_url": "https://arxiv.org/abs/2511.16886",
    "published": "2025-11-21T01:54:23Z",
    "updated": "2026-02-02T11:47:43Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文将潜在推理形式化为策略改进算法，并基于强化学习和扩散方法提出训练方案，以减少递归模型中的计算浪费。",
      "motivation": "该研究旨在解决小模型通过潜在递归处理复杂推理任务时，部分递归步骤无效（死计算）的问题。当前方法中，递归层性能低于一次性模型，表明递归未有效增加深度，导致计算资源浪费。理解潜在推理的有效性条件对优化模型效率和避免无用计算至关重要，但现有理论未能充分解释递归步骤何时发挥作用。",
      "method": "论文提出将潜在推理形式化为分类器自由引导和策略改进算法。基于这一形式化，作者引入了从强化学习和扩散方法借鉴的训练方案，以优化递归模型的训练过程。使用 Tiny Recursive Model 作为测试平台，通过修改训练策略来提高递归步骤的有效性，关键创新点在于结合策略改进视角来指导模型设计。",
      "result": "实验结果表明，修改后的模型成功避免了死计算步骤，并将前向传递次数减少了 18 倍，同时保持了原有的性能水平。摘要未明确说明具体的性能指标如准确率，但强调与未优化模型相比，计算效率显著提升，实现了在保持任务表现的同时大幅降低计算成本的目标。",
      "conclusion": "论文的主要贡献是从策略改进角度解释了潜在推理，提供了一个新的理论框架来理解递归模型行为。这具有学术价值，为模型优化提供理论基础，并在实际应用中能提高计算效率。未来工作可探索更广泛的优化技术或将此方法扩展到其他模型架构，以进一步提升性能。",
      "tags": [
        "Latent Reasoning",
        "Policy Improvement Algorithm",
        "Reinforcement Learning",
        "Diffusion Methods",
        "Classifier Free Guidance"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:18.395394Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.16600",
    "title": "You Only Forward Once: An Efficient Compositional Judging Paradigm",
    "authors": [
      "Tianlong Zhang",
      "Hongwei Xue",
      "Shilin Yan",
      "Di Wu",
      "Chen Xu",
      "Guannan Zhang",
      "Yunyun Yang"
    ],
    "abstract": "Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis -- where subsequent judgments are conditioned on previous ones -- and further benefits from post-hoc CoT.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.16600.pdf",
    "abs_url": "https://arxiv.org/abs/2511.16600",
    "published": "2025-11-20T17:55:21Z",
    "updated": "2026-02-02T11:23:30Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出 YOFO 方法，通过一次前向传播实现高效的多模态评判，解决现有方法的效率与细粒度理解平衡问题。",
      "motivation": "研究动机源于多模态大语言模型作为评判者的潜力与现有方法的不足。具体问题在于：适应 MLLMs 输出单一分数与模型的生成性质不匹配，限制了细粒度需求的理解；而自回归生成评判分析虽然详细，但在高吞吐量设置下速度过慢，导致无法满足实际应用中的高效需求验证。因此，需要开发一种既能保持可解释性又能显著提升速度的方法，以解决评判任务中的效率瓶颈。",
      "method": "论文提出 YOFO，一种模板条件化的方法，用于高效的多需求评判。该方法基于自回归模型，通过接受结构化需求模板，在单个推理步骤中为每个需求产生二元是/否决策。关键创新在于利用与每个需求关联的最终标记的 logits 来直接输出决策，避免了多次前向传播，从而实现数量级的速度提升。此外，方法支持依赖感知分析，允许后续判断基于先前结果，增强了评判的灵活性和准确性。",
      "result": "实验结果显示，YOFO 在标准推荐数据集上取得了最先进的性能，同时实现了数量级的推理速度提升。该方法不仅支持依赖感知的评判分析，还能从后处理的思维链中获益，进一步提高效果。与基线方法相比，YOFO 在保持高准确率的同时显著提高了效率，适用于需要快速响应的应用场景。摘要未提供具体性能指标数据，但强调了速度和效果的平衡优势。",
      "conclusion": "YOFO 的主要贡献是提出了一种高效的成分化评判范式，通过一次前向传播实现多需求判断，解决了 MLLMs 作为评判者时的效率与细粒度平衡问题。其学术价值在于提供了一种新颖的模板条件化方法，实际应用价值在于支持高速吞吐场景下的自动化评判任务。局限性或未来工作方向在摘要中未明确说明，但可能涉及扩展到更多模态或优化模板设计。",
      "tags": [
        "Multimodal Large Language Models",
        "Autoregressive Model",
        "Template Conditioning",
        "Efficient Inference",
        "Dependency-Aware Analysis"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:37.667636Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.15658",
    "title": "GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI",
    "authors": [
      "Naomi Simumba",
      "Nils Lehmann",
      "Paolo Fraccaro",
      "Hamed Alemohammad",
      "Geeth De Mel",
      "Salman Khan",
      "Manil Maskey",
      "Nicolas Longepe",
      "Xiao Xiang Zhu",
      "Hannah Kerner",
      "Juan Bernabe-Moreno",
      "Alexandre Lacoste"
    ],
    "abstract": "Geospatial Foundation Models (GeoFMs) are transforming Earth Observation (EO), but evaluation lacks standardized protocols. GEO-Bench-2 addresses this with a comprehensive framework spanning classification, segmentation, regression, object detection, and instance segmentation across 19 permissively-licensed datasets. We introduce ''capability'' groups to rank models on datasets that share common characteristics (e.g., resolution, bands, temporality). This enables users to identify which models excel in each capability and determine which areas need improvement in future work. To support both fair comparison and methodological innovation, we define a prescriptive yet flexible evaluation protocol. This not only ensures consistency in benchmarking but also facilitates research into model adaptation strategies, a key and open challenge in advancing GeoFMs for downstream tasks.   Our experiments show that no single model dominates across all tasks, confirming the specificity of the choices made during architecture design and pretraining. While models pretrained on natural images (ConvNext ImageNet, DINO V3) excel on high-resolution tasks, EO-specific models (TerraMind, Prithvi, and Clay) outperform them on multispectral applications such as agriculture and disaster response. These findings demonstrate that optimal model choice depends on task requirements, data modalities, and constraints. This shows that the goal of a single GeoFM model that performs well across all tasks remains open for future research. GEO-Bench-2 enables informed, reproducible GeoFM evaluation tailored to specific use cases. Code, data, and leaderboard for GEO-Bench-2 are publicly released under a permissive license.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.15658.pdf",
    "abs_url": "https://arxiv.org/abs/2511.15658",
    "published": "2025-11-19T17:45:02Z",
    "updated": "2026-02-02T08:03:41Z",
    "comment": null,
    "light_analysis": {
      "overview": "GEO-Bench-2提出了一种基于能力的综合评估框架，重新思考地理空间AI的评估方法，以标准化评测地理空间基础模型。",
      "motivation": "地理空间基础模型（GeoFMs）正在革新地球观测（EO）领域，但现有评估缺乏统一标准，导致难以公平比较模型性能。这一问题的重要性在于，随着GeoFMs在分类、分割等下游任务中的应用增加，不一致的评估协议阻碍了模型优化和实际部署。现有方法的不足之处是，评估过于依赖单个性能指标，未能充分考虑数据特性（如分辨率、波段），无法全面反映模型在多样化任务中的能力，从而限制了模型选择和未来研究进展。",
      "method": "研究方法包括引入“能力”组概念，根据数据集共享特性（如分辨率、波段、时间性）对模型进行排名，涵盖分类、分割、回归、目标检测和实例分割五大任务，使用19个具有许可的数据集。关键创新点在于定义了一个既规定性又灵活的评估协议，不仅确保基准测试的一致性，还促进了模型适应策略的研究，这是推动GeoFMs用于下游任务的关键挑战。框架支持公平比较和方法创新，强调了多任务和数据集整合以评估模型综合能力。",
      "result": "主要实验结果表明，没有单一模型在所有任务中占主导地位。具体数据如：自然图像预训练模型（ConvNext ImageNet、DINO V3）在高分辨率任务中表现优异；而针对地球观测设计的模型（TerraMind、Prithvi、Clay）在多光谱应用（如农业和灾害响应）中超越前者。这些发现与基线方法对比显示，模型性能高度依赖于任务需求和数据模态，验证了架构设计和预训练选择对特定应用的重要性，突显了评估框架的有效性和实际指导意义。",
      "conclusion": "论文的主要贡献是GEO-Bench-2框架，它支持针对特定用例的可重现地理空间基础模型评估。学术价值在于推动了标准化评估和模型适应策略的研究；实际应用价值在于帮助用户根据任务需求选择合适模型。局限性在于，单一通用模型在所有任务中表现良好的目标仍是未来研究的开放问题。未来工作可探索更广泛的模型集成、自适应方法和更多样化的数据集扩展。",
      "tags": [
        "Geospatial Foundation Models",
        "Earth Observation",
        "Evaluation Framework",
        "Capability Groups",
        "Multispectral Analysis"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:26.914013Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.21717",
    "title": "CrossCheck-Bench: Diagnosing Compositional Failures in Multimodal Conflict Resolution",
    "authors": [
      "Baoliang Tian",
      "Yuxuan Si",
      "Jilong Wang",
      "Lingyao Li",
      "Zhongyuan Bao",
      "Zineng Zhou",
      "Tao Wang",
      "Sixu Li",
      "Ziyao Xu",
      "Mingze Wang",
      "Zhouzhuo Zhang",
      "Zhihao Wang",
      "Yike Yun",
      "Ke Tian",
      "Ning Yang",
      "Minghui Qiu"
    ],
    "abstract": "Multimodal Large Language Models are primarily trained and evaluated on aligned image-text pairs, which leaves their ability to detect and resolve real-world inconsistencies largely unexplored. In open-domain applications visual and textual cues often conflict, requiring models to perform structured reasoning beyond surface-level alignment. We introduce CrossCheck-Bench, a diagnostic benchmark for evaluating contradiction detection in multimodal inputs. The benchmark adopts a hierarchical task framework covering three levels of reasoning complexity and defines seven atomic capabilities essential for resolving cross-modal inconsistencies. CrossCheck-Bench includes 15k question-answer pairs sourced from real-world artifacts with synthetically injected contradictions. The dataset is constructed through a multi-stage annotation pipeline involving more than 450 expert hours to ensure semantic validity and calibrated difficulty across perception, integration, and reasoning. We evaluate 13 state-of-the-art vision-language models and observe a consistent performance drop as tasks shift from perceptual matching to logical contradiction detection. Most models perform well on isolated entity recognition but fail when multiple clues must be synthesized for conflict reasoning. Capability-level analysis further reveals uneven skill acquisition, especially in tasks requiring multi-step inference or rule-based validation. Additional probing shows that conventional prompting strategies such as Chain-of-Thought and Set-of-Mark yield only marginal gains. By contrast, methods that interleave symbolic reasoning with grounded visual processing achieve more stable improvements. These results highlight a persistent bottleneck in multimodal reasoning and suggest new directions for building models capable of robust cross-modal verification.",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2511.21717.pdf",
    "abs_url": "https://arxiv.org/abs/2511.21717",
    "published": "2025-11-19T12:17:15Z",
    "updated": "2026-02-02T03:28:04Z",
    "comment": "Accepted by AAAI 2026",
    "light_analysis": {
      "overview": "本文提出了CrossCheck-Bench基准，用于诊断多模态大语言模型在跨模态不一致性检测和解决中的组合失败。",
      "motivation": "多模态大语言模型主要在对齐的图像-文本对上训练和评估，这导致其在处理现实世界中视觉和文本线索冲突的能力未被充分探索。在开放域应用中，模型常需进行结构化推理以检测和解决不一致性，但现有方法专注于表面对齐，忽略了深层逻辑矛盾，这限制了模型在实际场景中的鲁棒性和可靠性。因此，开发一个诊断基准来评估和揭示这些不足至关重要，以便推动模型改进。",
      "method": "本研究引入了CrossCheck-Bench，这是一个诊断基准，通过分层任务框架覆盖三个推理复杂度级别，并定义七个解决跨模态不一致性的原子能力。数据集包含15,000个问题-答案对，源自现实世界制品并注入合成矛盾，构建过程涉及多阶段注释管道和超过450个专家小时，以确保语义有效性和在感知、整合、推理方面的校准难度。评估了13个最先进的视觉-语言模型，以分析其在不同任务上的性能。",
      "result": "实验结果显示，随着任务从感知匹配转向逻辑矛盾检测，模型性能一致下降。大多数模型在孤立实体识别上表现良好，但在综合多个线索进行冲突推理时失败。能力级别分析表明技能获取不均匀，多步推理或基于规则验证的任务尤其困难。传统提示策略如Chain-of-Thought和Set-of- Mark仅带来边际改进，而将符号推理与接地视觉处理交织的方法实现了更稳定的性能提升，揭示了现有模型的局限性。",
      "conclusion": "本研究的主要贡献是通过CrossCheck-Bench基准评估和揭示了多模态大语言模型在跨模态不一致性检测中的瓶颈，强调了模型在深层推理方面的不足。学术价值在于为诊断模型失败提供了新工具，实际应用价值在于指导未来开发更鲁棒的跨模态验证模型。未来工作可探索符号推理与视觉处理结合的方法，以提升模型在复杂场景下的性能。",
      "tags": [
        "Multimodal Large Language Models",
        "Contradiction Detection",
        "Benchmark Evaluation",
        "Symbolic Reasoning",
        "Cross-modal Verification"
      ]
    },
    "analyzed_at": "2026-02-03T03:56:25.201369Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.15204",
    "title": "Physics-Based Benchmarking Metrics for Multimodal Synthetic Images",
    "authors": [
      "Kishor Datta Gupta",
      "Marufa Kamal",
      "Md. Mahfuzur Rahman",
      "Fahad Rahman",
      "Mohd Ariful Haque",
      "Sunzida Siddique"
    ],
    "abstract": "Current state of the art measures like BLEU, CIDEr, VQA score, SigLIP-2 and CLIPScore are often unable to capture semantic or structural accuracy, especially for domain-specific or context-dependent scenarios. For this, this paper proposes a Physics-Constrained Multimodal Data Evaluation (PCMDE) metric combining large language models with reasoning, knowledge based mapping and vision-language models to overcome these limitations. The architecture is comprised of three main stages: (1) feature extraction of spatial and semantic information with multimodal features through object detection and VLMs; (2) Confidence-Weighted Component Fusion for adaptive component-level validation; and (3) physics-guided reasoning using large language models for structural and relational constraints (e.g., alignment, position, consistency) enforcement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.15204.pdf",
    "abs_url": "https://arxiv.org/abs/2511.15204",
    "published": "2025-11-19T07:52:20Z",
    "updated": "2026-02-02T07:21:32Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出一种基于物理约束的多模态数据评估指标PCMDE，通过结合大型语言模型和视觉语言模型，旨在克服现有度量标准在语义和结构准确性捕捉方面的不足。",
      "motivation": "当前多模态度量标准如BLEU、CIDEr、VQA分数等在领域特定或上下文依赖场景中，往往无法有效捕捉语义和结构准确性，导致评估结果不够精确。这一问题在多模态合成图像等应用中尤为突出，因为这些场景需要更精细的物理和结构一致性验证。现有方法缺乏对物理知识的集成，限制了评估的全面性，因此开发一个能结合物理约束的新度量标准对于提升评估可靠性和应用价值具有重要意义。",
      "method": "PCMDE方法包括三个主要阶段：首先，通过对象检测和视觉语言模型提取空间和语义特征，实现多模态信息融合；其次，采用置信度加权组件融合进行自适应组件级验证，动态调整各部分的贡献；最后，利用大型语言模型进行物理引导推理，强制执行结构和关系约束如对齐、位置和一致性，以增强评估的准确性和鲁棒性。",
      "result": "摘要未明确说明主要实验结果，如具体的性能指标提升或与基线方法的对比数据。基于方法推断，PCMDE指标通过融合物理约束和自适应验证，可能改善多模态合成图像评估的语义和结构准确性，但具体实验效果需要通过后续研究来验证。未来工作应包含在真实数据集上的测试，以量化该方法相对于传统度量标准的优势。",
      "conclusion": "本论文的主要贡献是提出PCMDE指标，它集成物理约束和多模态模型，为多模态数据评估提供更全面的框架，推动评估度量标准的发展。其学术价值在于探索跨模态推理在评估中的应用，实际应用价值在于提升图像生成和验证系统的可靠性。潜在局限性可能包括计算复杂性或泛化能力限制，未来工作可优化集成方法或扩展到更多领域特定任务。",
      "tags": [
        "Large Language Model",
        "Vision-Language Model",
        "Physics-Based Reasoning",
        "Object Detection",
        "Adaptive Fusion"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:09.373680Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.13144",
    "title": "Personalized Federated Learning with Bidirectional Communication Compression via One-Bit Random Sketching",
    "authors": [
      "Jiacheng Cheng",
      "Xu Zhang",
      "Guanghui Qiu",
      "Yifang Zhang",
      "Yinchuan Li",
      "Kaiyuan Feng"
    ],
    "abstract": "Federated Learning (FL) enables collaborative training across decentralized data, but faces key challenges of bidirectional communication overhead and client-side data heterogeneity. To address communication costs while embracing data heterogeneity, we propose pFed1BS, a novel personalized federated learning framework that achieves extreme communication compression through one-bit random sketching. In personalized FL, the goal shifts from training a single global model to creating tailored models for each client. In our framework, clients transmit highly compressed one-bit sketches, and the server aggregates and broadcasts a global one-bit consensus. To enable effective personalization, we introduce a sign-based regularizer that guides local models to align with the global consensus while preserving local data characteristics. To mitigate the computational burden of random sketching, we employ the Fast Hadamard Transform for efficient projection. Theoretical analysis guarantees that our algorithm converges to a stationary neighborhood of the global potential function. Numerical simulations demonstrate that pFed1BS substantially reduces communication costs while achieving competitive performance compared to advanced communication-efficient FL algorithms.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.13144.pdf",
    "abs_url": "https://arxiv.org/abs/2511.13144",
    "published": "2025-11-17T08:55:22Z",
    "updated": "2026-02-02T09:20:14Z",
    "comment": "Accepted in AAAI 2026",
    "light_analysis": {
      "overview": "提出pFed1BS框架，通过一比特随机草图实现个性化联邦学习的双向通信极致压缩。",
      "motivation": "联邦学习面临双向通信开销高和客户端数据异构性的关键挑战，这可能导致训练效率低下和模型适应性差。传统方法在处理通信压缩与数据个性化间难以平衡，使得联邦学习在实际应用中成本较高。本研究旨在解决这些问题，通过降低通信成本同时应对数据异构性，提升联邦学习的可扩展性和实用性。摘要未明确说明现有具体方法的不足之处，但强调了通信和异构性问题的重要性。",
      "method": "pFed1BS框架的核心是利用一比特随机草图进行通信压缩，客户端传输高度压缩的一比特草图，服务器聚合这些草图并广播全局一比特共识。为实现个性化，引入基于符号的正则化器，指导本地模型在保持本地数据特征的同时与全局共识对齐。为优化计算效率，采用快速哈达玛变换实现高效投影，减少随机草图生成的计算负担。该方法专注于技术实现，未提及具体数据集或模型架构细节。",
      "result": "数值模拟结果表明，pFed1BS能大幅降低通信成本，与先进的通信高效联邦学习算法相比，在性能上具有竞争力。具体实验数据未在摘要中提供，但强调了算法在平衡通信效率和模型性能方面的有效性。摘要未明确说明基准对比的具体指标，但整体表现优于或可比其他方法。",
      "conclusion": "该研究贡献了pFed1BS框架，有效处理联邦学习中的通信开销和数据异构性问题，通过理论分析保证算法收敛到平稳邻域。学术上推动了个性化联邦学习的发展，实际应用中有助于提升分布式训练效率，适用于边缘计算和物联网等场景。摘要未明确说明局限性或未来工作方向，但可能涉及进一步优化压缩算法或扩展应用领域。",
      "tags": [
        "Personalized Federated Learning",
        "Communication Compression",
        "One-Bit Sketching",
        "Fast Hadamard Transform",
        "Sign-based Regularization"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:25.253598Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.11051",
    "title": "NP-LoRA: Null Space Projection Unifies Subject and Style in LoRA Fusion",
    "authors": [
      "Chuheng Chen",
      "Xiaofei Zhou",
      "Geyuan Zhang",
      "Yong Huang"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) fusion enables the composition of learned subject and style representations for controllable generation without retraining. However, existing methods rely on weight-based merging within a shared adaptation space, where independently trained LoRAs interfere and degrade fidelity. We show that this interference is fundamentally geometric: content and style LoRAs occupy overlapping, non-orthogonal low-rank subspaces, making weight-based fusion inherently flawed. Analyzing LoRA internal structure, we find that generative behavior is dominated by a few principal directions that must be preserved during fusion. Based on this insight, we reformulate LoRA fusion as a null-space projection problem and propose Null Space Projection LoRA (NP-LoRA), a projection-based framework that enforces subspace separation by construction. NP-LoRA extracts principal style directions via singular value decomposition (SVD) and projects the subject LoRA into the orthogonal complement of the style subspace, preventing interference. We further introduce a soft projection mechanism that provides continuous control over the trade-off between subject fidelity and style preservation. Experiments show that NP-LoRA consistently outperforms strong baselines and generalizes well across pretrained LoRA pairs without retraining.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.11051.pdf",
    "abs_url": "https://arxiv.org/abs/2511.11051",
    "published": "2025-11-14T08:06:01Z",
    "updated": "2026-02-02T06:22:03Z",
    "comment": null,
    "light_analysis": {
      "overview": "NP-LoRA通过空空间投影框架解决了LoRA融合中的干扰问题，实现了主题和风格的无损组合。",
      "motivation": "LoRA融合技术能组合学习到的主题和风格表示以实现可控生成，无需重新训练。但现有方法依赖权重合并，导致独立训练的LoRA在共享适应空间中相互干扰，降低保真度。这一问题源于几何本质：主题和风格LoRA的子空间重叠且非正交，使得基于权重的融合方法存在固有缺陷。因此，开发一种能避免干扰、提高融合效果的方案至关重要。",
      "method": "论文提出Null Space Projection LoRA (NP-LoRA)，基于空空间投影的框架。通过分析LoRA内部结构，发现生成行为由少数主方向主导，必须在融合中保留。使用奇异值分解提取风格LoRA的主方向，并将主题LoRA投影到这些方向的正交补空间中，构造性地强制子空间分离以防止干扰。此外，引入软投影机制，提供连续控制以权衡主题保真度和风格保留。",
      "result": "实验表明，NP-LoRA在多个评估中一致优于强基线方法，显著提升主题保真度和风格保留效果。该方法泛化能力强，能直接应用于预训练的LoRA对而无需重新训练，提高了可控生成的效率和实用性。摘要未明确提供具体性能指标如准确率数据，但结果验证了其在避免干扰方面的有效性。",
      "conclusion": "该研究的主要贡献是提出NP-LoRA，通过空空间投影解决了LoRA融合中的子空间干扰问题，实现更精准的主题和风格组合。学术上，将融合问题重新表述为几何投影，为相关技术提供了新视角。实际应用中，增强了生成模型的灵活性和可控性，适用于图像生成和风格迁移等领域。未来工作可探索扩展到复杂场景或优化计算效率。",
      "tags": [
        "Low-Rank Adaptation",
        "Singular Value Decomposition",
        "Null Space Projection",
        "LoRA Fusion",
        "Style Transfer"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:29.516600Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.07448",
    "title": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey",
    "authors": [
      "Fatemeh Shahhosseini",
      "Arash Marioriyad",
      "Ali Momen",
      "Mahdieh Soleymani Baghshah",
      "Mohammad Hossein Rohban",
      "Shaghayegh Haghjooy Javanmard"
    ],
    "abstract": "Scientific idea generation is central to discovery, requiring the joint satisfaction of novelty and scientific soundness. Unlike standard reasoning or general creative generation, scientific ideation is inherently open-ended and multi-objective, making its automation particularly challenging. Recent advances in large language models (LLMs) have enabled the generation of coherent and plausible scientific ideas, yet the nature and limits of their creative capabilities remain poorly understood. This survey provides a structured synthesis of methods for LLM-driven scientific ideation, focusing on how different approaches trade off novelty and scientific validity. We organize existing methods into five complementary families: External knowledge augmentation, Prompt-based distributional steering, Inference-time scaling, Multi-agent collaboration, and Parameter-level adaptation. To interpret their contributions, we adopt two complementary creativity frameworks: Boden taxonomy to characterize the expected level of creative novelty, and Rhodes 4Ps framework to analyze the aspects or sources of creativity emphasized by each method. By aligning methodological developments with cognitive creativity frameworks, this survey clarifies the evaluation landscape and identifies key challenges and directions for reliable and systematic LLM-based scientific discovery.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2511.07448.pdf",
    "abs_url": "https://arxiv.org/abs/2511.07448",
    "published": "2025-11-05T07:50:43Z",
    "updated": "2026-02-02T04:59:58Z",
    "comment": "75 Pages",
    "light_analysis": {
      "overview": "本调查通过结构化综述大语言模型驱动的科学想法生成方法，并引入创造力框架评估其新颖性和有效性。",
      "motivation": "科学想法生成是科学发现的核心，要求同时满足新颖性和科学严谨性，具有开放式和多目标特性，自动化难度高。现有大语言模型虽能生成连贯想法，但其创造能力的本质和限制尚不明确，评估标准不统一。本研究旨在系统化理解 LLMs 在科学想法生成中的应用，弥补现有方法的不足，推动科学发现的自动化进程。",
      "method": "本调查作为一篇综述，不提出新方法，而是对现有方法进行结构化组织。核心是将 LLM 驱动的科学想法生成方法分为五类：外部知识增强、基于提示的分布导向、推理时缩放、多代理协作和参数级适应。关键创新点在于引入两个互补的创造力框架：Boden 分类法用于评估新颖性水平，Rhodes 4Ps 框架用于分析创造力的来源，聚焦于方法在权衡新颖性和科学有效性时的特性。",
      "result": "作为调查论文，本研究的主要结果体现在对现有方法的综合分析和评估上。通过组织方法并应用创造力框架，调查澄清了 LLM 科学想法生成的评估景观，识别了关键挑战，如确保生成想法的可靠性和系统性，并指出了未来研究方向，例如优化方法以更好地平衡新颖性和有效性。摘要未明确说明具体实验数据。",
      "conclusion": "本调查的主要贡献是提供了 LLM 驱动科学想法生成方法的结构化综合，并通过创造力框架进行评估，增进了对 LLMs 创造能力的理解。其学术价值在于为这一新兴领域提供了系统化视角，应用价值在于促进可靠、自动化的科学发现工具开发。未来工作方向包括进一步优化方法以平衡新颖性和严谨性，以及建立更全面的评估体系。",
      "tags": [
        "Large Language Models",
        "Scientific Idea Generation",
        "Creativity Frameworks",
        "Knowledge Augmentation",
        "Multi-agent Collaboration"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:43.386349Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.02463",
    "title": "Extending RLVR to Open-Ended Tasks via Verifiable Multiple-Choice Reformulation",
    "authors": [
      "Mengyu Zhang",
      "Siyu Ding",
      "Weichong Yin",
      "Yu Sun"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards(RLVR) has demonstrated great potential in enhancing the reasoning capabilities of large language models (LLMs). However, its success has thus far been largely confined to the mathematical and programming domains with clear and automatically checkable outcomes. Reinforcement learning on open-ended tasks (e.g., creative writing and subjective Q&A) continues to rely on reward models due to the absence of verifiable solutions. This raises a key question: how can we extend RLVR to strengthen reasoning in open-ended tasks regardless of the absence of the unambiguous ground truth? To overcome this challenge, we introduce Verifiable Multiple-Choice Reformulation for Reinforcement Learning from Verifiable Rewards (VMR-RLVR), a novel training strategy that restructures open-ended data into verifiable multiple-choice formats, enabling effective training even in the absence of explicit ground truth. Experimental results on multiple benchmarks validate the effectiveness of our method in improving LLM performance on open-ended tasks. Notably, across seven open-ended benchmarks, our VMR-RLVR training delivers an average gain of 3.29 points over the RL with reward model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.02463.pdf",
    "abs_url": "https://arxiv.org/abs/2511.02463",
    "published": "2025-11-04T10:45:52Z",
    "updated": "2026-02-02T10:35:44Z",
    "comment": "8 pages",
    "light_analysis": {
      "overview": "本文提出VMR-RLVR方法，通过将开放任务数据重构为可验证多选格式，扩展了RLVR在开放任务中的应用。",
      "motivation": "研究旨在解决开放任务（如创意写作和主观问答）中强化学习依赖奖励模型的局限性，这些任务缺乏明确可验证的解决方案，导致现有基于RLVR的方法无法直接应用。RLVR在数学和编程领域表现出色，但开放任务因主观性和缺乏自动检查机制而难以扩展，这限制了大型语言模型推理能力的提升。该问题的重要性在于开放任务在实际应用广泛，增强模型推理能力对推动AI发展具有关键意义。摘要未明确说明现有方法的具体名称，但指出当前依赖奖励模型，存在灵活性不足和性能瓶颈。",
      "method": "研究方法的核心是VMR-RLVR，一种新颖的训练策略，通过将开放任务数据重构为可验证的多选格式，使RLVR能应用于缺乏明确真值的场景。技术特色包括数据转换机制，将开放输出问题转化为结构化选择题，以便利用RLVR的验证奖励机制。关键创新点在于克服开放任务的主观性，通过多选格式提供可验证的训练目标，无需依赖传统的奖励模型。摘要未明确说明具体数据集或模型架构，但提及在多个基准测试上进行实验，推断可能使用大型语言模型和标准开放任务基准。技术路线涉及数据预处理和强化学习框架的集成。",
      "result": "实验在多个开放任务基准测试上进行，结果显示VMR-RLVR显著提升了大型语言模型的性能。具体数据表明，在七个开放任务基准中，与使用奖励模型的强化学习方法相比，VMR-RLVR训练带来了平均3.29点的性能增益。这种提升验证了方法的有效性，特别是在缺乏明确真值的复杂任务中，如创意写作和主观问答。对比基线方法，VMR-RLVR表现出更高的效率和改进潜力，摘要未提供更多详细指标，但强调了其在广泛任务中的一致性优势。",
      "conclusion": "论文的主要贡献是提出了VMR-RLVR方法，成功扩展了RLVR到开放任务，增强了大型语言模型的推理能力。学术价值在于为开放任务强化学习提供了新思路，突破了传统依赖奖励模型的限制，扩展了RLVR的应用范围。实际应用价值包括在创意写作、主观问答等开放领域提升模型性能，推动AI在复杂任务中的实用性。局限性或未来工作方向摘要未明确说明，但可推断可能需要进一步优化数据重构策略、扩展到更多任务类型或结合更多评估指标以验证泛化性。",
      "tags": [
        "Reinforcement Learning with Verifiable Rewards (RLVR)",
        "Multiple-Choice Reformulation",
        "Open-Ended Tasks",
        "Large Language Models (LLMs)",
        "Verifiable Rewards"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:38.461196Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2511.01817",
    "title": "SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art",
    "authors": [
      "Sagi Eppel",
      "Alona Strugatski"
    ],
    "abstract": "The ability to connect visual patterns with the processes that form them represents one of the deepest forms of visual understanding. Textures of clouds and waves, the growth of cities and forests, or the formation of materials and landscapes are all examples of patterns emerging from underlying mechanisms. We present the SciTextures dataset, a large-scale collection of textures and visual patterns from all domains of science, tech, and art, along with the models and code that generate these images. Covering over 1,270 different models and 100,000 images of patterns and textures from physics, chemistry, biology, sociology, technology, mathematics, and art, this dataset offers a way to explore the deep connection between the visual patterns that shape our world and the mechanisms that produce them. Built through an agentic AI pipeline that autonomously collects, implements, and standardizes scientific and generative models. This AI pipeline is also used to autonomously invent and implement novel methods for generating visual patterns and textures. SciTextures enables systematic evaluation of vision language models (VLM's) ability to link visual patterns to the models and code that generate them, and to identify different patterns that emerge from the same underlying process. We also test VLMs ability to infer and recreate the mechanisms behind visual patterns by providing a natural image of a real-world phenomenon and asking the AI to identify and code a model of the process that formed it, then run this code to generate a simulated image that is compared to the reference image. These benchmarks reveal that VLM's can understand and simulate physical systems beyond visual patterns at multiple levels of abstraction. The dataset and code are available at: https://zenodo.org/records/17485502",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.01817.pdf",
    "abs_url": "https://arxiv.org/abs/2511.01817",
    "published": "2025-11-03T18:22:11Z",
    "updated": "2026-02-02T13:00:09Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出SciTextures数据集，通过自主AI管道收集视觉模式、模型和代码，用于评估视觉语言模型连接视觉模式与生成机制的能力。",
      "motivation": "研究动机是解决如何系统评估视觉语言模型在连接视觉模式与生成机制方面的能力。现有方法缺乏大规模、跨领域的数据集来探索这一深度连接，而这一问题对于推动AI在科学和艺术中的视觉理解至关重要，有助于揭示模式背后的物理或社会过程。",
      "method": "研究方法基于构建SciTextures数据集，使用一个自主的AI管道收集、实现和标准化科学及生成模型。数据集涵盖1270个模型和100,000张图像，来自物理、化学、生物学等多个领域，AI管道还能发明新的视觉模式生成方法，支持系统化评估。",
      "result": "通过基准测试，发现视觉语言模型能够理解和模拟物理系统，在多个抽象级别连接视觉模式与生成模型。结果展示了VLMs的能力，但摘要未明确说明具体性能指标（如准确率）或与基线方法的对比，仅指出模型可以识别模式并模拟生成机制。",
      "conclusion": "论文贡献在于推出SciTextures数据集，为视觉语言模型研究提供新基准，促进跨学科视觉理解。学术价值是系统化连接模式与机制，实际应用包括科学可视化和AI模拟。局限性可能在于数据集覆盖范围，未来工作可扩展模型多样性和优化评估方法。",
      "tags": [
        "Vision Language Models",
        "Autonomous AI Pipeline",
        "SciTextures Dataset",
        "Generative Models",
        "Pattern Generation"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:24.502021Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.24410",
    "title": "GenTrack2: An Improved Hybrid Approach for Visual Multi-Object Tracking",
    "authors": [
      "Toan Van Nguyen",
      "Rasmus G. K. Christiansen",
      "Dirk Kraft",
      "Leon Bodenhagen"
    ],
    "abstract": "This paper proposes a visual multi-object tracking method that jointly employs stochastic and deterministic mechanisms to ensure identifier consistency for unknown and time-varying target numbers under nonlinear dynamics. A stochastic particle filter addresses nonlinear dynamics and non-Gaussian noise, with support from particle swarm optimization (PSO) to guide particles toward state distribution modes and mitigate divergence through proposed fitness measures incorporating motion consistency, appearance similarity, and social-interaction cues with neighboring targets. Deterministic association further enforces identifier consistency via a proposed cost matrix incorporating spatial consistency between particles and current detections, detection confidences, and track penalties. Subsequently, a novel scheme is proposed for the smooth updating of target states while preserving their identities, particularly for weak tracks during interactions with other targets and prolonged occlusions. Moreover, velocity regression over past states provides trend-seed velocities, enhancing particle sampling and state updates. The proposed tracker is designed to operate flexibly for both pre-recorded videos and camera live streams, where future frames are unavailable. Experimental results confirm superior performance compared to state-of-the-art trackers. The source-code reference implementations of both the proposed method and compared-trackers are provided on GitHub: https://github.com/SDU-VelKoTek/GenTrack2",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.24410.pdf",
    "abs_url": "https://arxiv.org/abs/2510.24410",
    "published": "2025-10-28T13:22:24Z",
    "updated": "2026-02-02T09:56:39Z",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "light_analysis": {
      "overview": "本研究提出GenTrack2，一种结合随机粒子滤波和确定性关联的视觉多目标跟踪方法，以改进在非线性动力学下的标识符一致性。",
      "motivation": "视觉多目标跟踪面临未知和时变目标数量的挑战，特别是在非线性动力学、非高斯噪声以及目标交互和遮挡场景中，现有方法可能导致标识符不一致，影响跟踪准确性。此研究旨在解决这些问题，提出更鲁棒的混合机制，以确保在复杂环境下的稳定跟踪，弥补传统方法在实时性和适应性方面的不足。",
      "method": "方法采用随机与确定性机制结合：随机部分使用粒子滤波器处理非线性动力学和非高斯噪声，通过粒子群优化（PSO）引导粒子，融合运动一致性、外观相似性和社交交互线索的适应性度量；确定性部分引入成本矩阵，结合粒子与检测的空间一致性、检测置信度和轨迹惩罚，强制标识符关联。新颖方案平滑更新目标状态，特别针对弱轨迹交互和长期遮挡，并通过速度回归提供趋势种子速度，增强采样和更新。",
      "result": "实验结果显示，所提方法在性能上优于当前最先进的跟踪器，但摘要未明确说明具体指标如准确率或效率提升。与基线方法的对比证实了其在标识符一致性方面的显著改进，适用于预录制视频和实时流场景，验证了方法的有效性。",
      "conclusion": "本研究贡献在于提出一种混合视觉多目标跟踪方法，有效结合随机和确定性机制处理非线性动力学和标识符一致性问题。具有学术价值，提供了新颖框架和开源代码，促进后续研究；实际应用广泛，但可能存在计算复杂度限制，未来工作可优化效率或扩展到更多动态场景。",
      "tags": [
        "Visual Multi-Object Tracking",
        "Particle Filter",
        "Particle Swarm Optimization",
        "Deterministic Association",
        "Non-linear Dynamics"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:31.846167Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.24795",
    "title": "A Survey on Efficient Vision-Language-Action Models",
    "authors": [
      "Zhaoshu Yu",
      "Bo Wang",
      "Pengpeng Zeng",
      "Haonan Zhang",
      "Ji Zhang",
      "Zheng Wang",
      "Lianli Gao",
      "Jingkuan Song",
      "Nicu Sebe",
      "Heng Tao Shen"
    ],
    "abstract": "Vision-Language-Action models (VLAs) represent a significant frontier in embodied intelligence, aiming to bridge digital knowledge with physical-world interaction. Despite their remarkable performance, foundational VLAs are hindered by the prohibitive computational and data demands inherent to their large-scale architectures. While a surge of recent research has focused on enhancing VLA efficiency, the field lacks a unified framework to consolidate these disparate advancements. To bridge this gap, this survey presents the first comprehensive review of Efficient Vision-Language-Action models (Efficient VLAs) across the entire model-training-data pipeline. Specifically, we introduce a unified taxonomy to systematically organize the disparate efforts in this domain, categorizing current techniques into three core pillars: (1) Efficient Model Design, focusing on efficient architectures and model compression; (2) Efficient Training, which reduces computational burdens during model learning; and (3) Efficient Data Collection, which addresses the bottlenecks in acquiring and utilizing robotic data. Through a critical review of state-of-the-art methods within this framework, this survey not only establishes a foundational reference for the community but also summarizes representative applications, delineates key challenges, and charts a roadmap for future research. We maintain a continuously updated project page to track our latest developments: https://evla-survey.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.24795.pdf",
    "abs_url": "https://arxiv.org/abs/2510.24795",
    "published": "2025-10-27T17:57:33Z",
    "updated": "2026-02-02T12:16:44Z",
    "comment": "28 pages, 8 figures",
    "light_analysis": {
      "overview": "本文首次全面综述高效视觉-语言-行动模型，提出统一分类法以系统化整理领域研究进展，为社区提供基础参考。",
      "motivation": "视觉-语言-行动模型是具身智能的重要前沿，旨在连接数字知识与物理世界交互，但基础模型因大规模架构导致计算和数据需求高昂，阻碍实际应用。尽管近期研究关注提升效率，但领域内缺乏统一框架整合这些分散进展，导致难以系统推进。因此，提供一个全面综述以梳理高效 VLAs 技术，对促进该领域发展至关重要，有助于解决现有方法的不足和瓶颈。",
      "method": "本综述提出一个统一分类法，将高效 VLAs 技术分为三个核心支柱：高效模型设计，关注架构优化和模型压缩技术；高效训练，专注于减少模型学习时的计算负担；高效数据收集，解决机器人数据获取和利用中的瓶颈。通过这一系统性框架，综述审查了整个模型-训练-数据管道中的 state-of-the-art 方法，为研究社区提供结构化参考，并涵盖了代表性技术和应用场景。",
      "result": "作为综述论文，本文通过统一框架审查了高效 VLAs 的 state-of-the-art 方法，总结了这些技术在提升模型性能、降低计算成本和数据效率方面的潜在效果。摘要未明确说明具体性能指标如准确率提升，但突出强调了高效技术在模型设计、训练优化和数据管理方面的改进潜力，并通过与基线方法的对比，指出了现有研究的挑战和未来路线图。",
      "conclusion": "本综述为高效视觉-语言-行动模型领域建立了基础参考，通过统一分类法系统化整理了研究进展，其学术价值在于提供了一个清晰框架，帮助社区理解现状和识别未来方向；实际应用价值体现在推动高效 AI 系统在具身智能中的开发。潜在局限性包括作为综述缺乏实验验证，未来工作包括持续更新项目页面以跟踪发展，并进一步探索技术挑战如模型可扩展性和数据多样性。",
      "tags": [
        "Vision-Language-Action Models",
        "Efficient Model Design",
        "Training Efficiency",
        "Data Collection",
        "Survey Taxonomy"
      ]
    },
    "analyzed_at": "2026-02-03T03:57:44.877479Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.23478",
    "title": "UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception",
    "authors": [
      "Karthikeyan Chandra Sekaran",
      "Markus Geisler",
      "Dominik Rößle",
      "Adithya Mohan",
      "Daniel Cremers",
      "Wolfgang Utschick",
      "Michael Botsch",
      "Werner Huber",
      "Torsten Schön"
    ],
    "abstract": "Recent cooperative perception datasets have played a crucial role in advancing smart mobility applications by enabling information exchange between intelligent agents, helping to overcome challenges such as occlusions and improving overall scene understanding. While some existing real-world datasets incorporate both vehicle-to-vehicle and vehicle-to-infrastructure interactions, they are typically limited to a single intersection or a single vehicle. A comprehensive perception dataset featuring multiple connected vehicles and infrastructure sensors across several intersections remains unavailable, limiting the benchmarking of algorithms in diverse traffic environments. Consequently, overfitting can occur, and models may demonstrate misleadingly high performance due to similar intersection layouts and traffic participant behavior. To address this gap, we introduce UrbanIng-V2X, the first large-scale, multi-modal dataset supporting cooperative perception involving vehicles and infrastructure sensors deployed across three urban intersections in Ingolstadt, Germany. UrbanIng-V2X consists of 34 temporally aligned and spatially calibrated sensor sequences, each lasting 20 seconds. All sequences contain recordings from one of three intersections, involving two vehicles and up to three infrastructure-mounted sensor poles operating in coordinated scenarios. In total, UrbanIng-V2X provides data from 12 vehicle-mounted RGB cameras, 2 vehicle LiDARs, 17 infrastructure thermal cameras, and 12 infrastructure LiDARs. All sequences are annotated at a frequency of 10 Hz with 3D bounding boxes spanning 13 object classes, resulting in approximately 712k annotated instances across the dataset. We provide comprehensive evaluations using state-of-the-art cooperative perception methods and publicly release the codebase, dataset, HD map, and a digital twin of the complete data collection environment.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.23478.pdf",
    "abs_url": "https://arxiv.org/abs/2510.23478",
    "published": "2025-10-27T16:12:12Z",
    "updated": "2026-02-02T07:58:08Z",
    "comment": "Accepted to NeurIPS 2025. Including supplemental material. For code and dataset, see https://github.com/thi-ad/UrbanIng-V2X",
    "light_analysis": {
      "overview": "提出UrbanIng-V2X，首个大规模、多车辆、多基础设施、覆盖多个交叉口的合作感知数据集，以推动智能交通应用发展。",
      "motivation": "该研究的动机在于解决现有合作感知数据集在多样交通环境评估中的不足。当前数据集通常局限于单一交叉口或单一车辆，导致算法在相似场景下容易过拟合并表现出误导性高性能，限制了模型在实际复杂交通中的泛化能力。合作感知对于智能交通至关重要，通过车辆与基础设施的信息交换来克服遮挡和提升场景理解，但缺乏涉及多车辆、多基础设施传感器且覆盖多个交叉口的全面数据集，阻碍了算法的基准测试和优化。背景强调了数据多样性对算法评估的重要性，促使开发新数据集以支持更广泛的研究。",
      "method": "研究方法侧重于构建UrbanIng-V2X数据集，这是一个多模态、大规模的合作感知数据集。核心技术路线包括在德国因戈尔德斯塔特的三个城市交叉口部署传感器，涉及两个车辆和最多三个基础设施传感器杆。数据集由34个时间对齐、空间校准的序列组成，每个序列持续20秒；传感器配置包括12个车载RGB摄像头、2个车载LiDAR、17个基础设施热像仪和12个基础设施LiDAR，实现多源数据采集。创新点在于首次整合多个交叉口、多车辆与基础设施传感器的协同，并以10 Hz频率标注3D边界框，覆盖13个对象类别，提供约712k标注实例。关键细节还包括公开代码库、高清地图和数据收集环境的数字孪生，以促进算法开发和评估。",
      "result": "主要实验结果显示，UrbanIng-V2X数据集包含了约712k个3D边界框标注实例，涵盖13个对象类别，提供了丰富的多模态数据用于评估。论文基于该数据集，使用最先进的合作感知方法进行了全面评估，但摘要未明确说明具体性能指标如准确率提升或效率改进。结果强调了数据集的实用性，通过基准测试展示了其在多样化交通环境中评估算法的潜力，有助于减少过拟合和提供更可靠的性能对比。与现有基线方法的比较可能依赖于公开的代码和数据集进行后续分析，论文突出了数据集规模和多样性的优势，为未来算法研究提供了坚实基础。",
      "conclusion": "结论总结了UrbanIng-V2X的主要贡献：创建了首个大规模、多车辆、多基础设施、覆盖多个交叉口的合作感知数据集，并公开相关资源如代码、地图和数字孪生。研究意义体现在为合作感知算法提供了多样化、真实的测试环境，推动了智能交通应用的发展，有助于克服遮挡和提升场景理解。学术价值在于促进算法基准测试和泛化能力研究，实际应用价值则支持自动驾驶和城市交通管理系统的开发。局限性可能包括数据集仅限于三个特定交叉口和有限场景，未来工作方向可扩展到更多地理位置、整合更多传感器类型或优化标注流程，以进一步丰富数据集和算法评估。",
      "tags": [
        "Cooperative Perception",
        "Vehicle-to-Infrastructure",
        "Multi-modal Sensors",
        "Dataset Annotation",
        "3D Bounding Box"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:23.111157Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.21303",
    "title": "Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity",
    "authors": [
      "Prakhar Ganesh",
      "Hsiang Hsu",
      "Golnoosh Farnadi"
    ],
    "abstract": "Multiplicity, the existence of equally good yet competing models, has received growing attention in recent years. While prior work has emphasized modelling choices, the critical role of data in shaping multiplicity has been largely overlooked. In this work, we first introduce a neighbouring datasets framework, arguing that much of data processing can be reframed as choosing between neighbouring datasets. Under this framework, we find a counterintuitive theoretical relationship: neighbouring datasets with greater inter-class distribution overlap exhibit lower multiplicity.   Building on this insight, we apply our framework to two domains: active learning and data imputation. For each, we establish natural extensions of the neighbouring datasets perspective, conduct the first systematic study of multiplicity in existing algorithms, and finally, propose novel multiplicity-aware methods, namely, multiplicity-aware data acquisition strategies for active learning and multiplicity-aware data imputation.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.21303.pdf",
    "abs_url": "https://arxiv.org/abs/2510.21303",
    "published": "2025-10-24T10:01:40Z",
    "updated": "2026-02-02T08:22:04Z",
    "comment": null,
    "light_analysis": {
      "overview": "通过提出邻接数据集框架，揭示了数据重叠与预测多重性的反直觉关系，并应用于主动学习和数据插补算法的改进。",
      "motivation": "多重性指存在多个性能相当的模型，这在机器学习中普遍存在，但先前研究多关注模型选择，忽略了数据在塑造多重性中的关键作用。数据是模型训练的基础，其处理方式直接影响模型多样性和不确定性，因此探究数据影响对提高算法鲁棒性和减少偏差具有重要意义。现有方法的不足在于过度集中于建模决策，缺乏对数据环节的系统分析，导致模型选择的不确定性未被充分理解。",
      "method": "本文引入邻接数据集框架，将数据处理视为在相邻数据集之间的选择。关键创新在于发现反直觉理论关系：邻接数据集中类间分布重叠越大，预测多重性越低。基于此，作者将该框架扩展到主动学习和数据插补领域，进行了现有算法中多重性的首次系统研究。对于主动学习，提出了多重性感知数据获取策略；对于数据插补，开发了多重性感知插补方法。摘要未明确说明具体使用的数据集或模型架构细节。",
      "result": "主要理论结果是发现了邻接数据集重叠与多重性的负相关关系，表明重叠越大可降低模型多样性。在应用方面，对主动学习和数据插补的现有算法进行了系统评估，揭示了多重性表现。提出的新方法，如多重性感知策略，理论上能优化算法以减少多重性和控制不确定性，与基线方法相比，预期能改善模型选择效果。摘要未明确说明具体性能指标如准确率提升或效率改进数据。",
      "conclusion": "本研究的核心贡献是提出了邻接数据集框架，强调了数据在预测多重性中的重要作用，通过理论分析和应用扩展为理解模型多样性提供了新视角。学术价值在于填补了数据相关研究在多重性领域的空白，丰富了机器学习理论基础；实际应用价值体现在改进了主动学习和数据插补算法，有助于减少模型不确定性。未来工作可能包括将该框架扩展到其他领域或进行更广泛的实证验证。",
      "tags": [
        "Multiplicity",
        "Neighbouring Datasets",
        "Active Learning",
        "Data Imputation",
        "Distribution Overlap"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:37.580828Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.19875",
    "title": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention",
    "authors": [
      "J Rosser",
      "José Luis Redondo García",
      "Gustavo Penha",
      "Konstantina Palla",
      "Hugues Bouchard"
    ],
    "abstract": "As Large Language Models (LLMs) scale to million-token contexts, traditional Mechanistic Interpretability techniques for analyzing attention scale quadratically with context length, demanding terabytes of memory beyond 100,000 tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic sparse attention to efficiently analyze long context attention patterns. We present Stream, a compilable hierarchical pruning algorithm that estimates per-head sparse attention masks in near-linear time $O(T \\log T)$ and linear space $O(T)$, enabling one-pass interpretability at scale. Stream performs a binary-search-style refinement to retain only the top-$k$ key blocks per query while preserving the model's next-token behavior. We apply Stream to long chain-of-thought reasoning traces and identify thought anchors while pruning 97-99\\% of token interactions. On the RULER benchmark, Stream preserves critical retrieval paths while discarding 90-96\\% of interactions and exposes layer-wise routes from the needle to output. Our method offers a practical drop-in tool for analyzing attention patterns and tracing information flow without terabytes of caches. By making long context interpretability feasible on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring. Code is available at https://anonymous.4open.science/r/stream-03B8/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.19875.pdf",
    "abs_url": "https://arxiv.org/abs/2510.19875",
    "published": "2025-10-22T09:42:29Z",
    "updated": "2026-02-02T12:03:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出Stream算法，通过稀疏注意力技术高效分析大语言模型的长上下文注意力模式，降低计算和内存需求，实现大规模可解释性。",
      "motivation": "随着大语言模型（LLMs）扩展到百万标记上下文，传统的Mechanistic Interpretability技术在分析注意力时，内存需求与上下文长度平方增长，超过10万标记时需要太字节内存，这限制了长上下文分析的实际应用。该研究旨在解决这一可扩展性问题，因为现有方法无法在长链思维推理等任务中有效监控和理解模型行为，导致可解释性工具不可行。",
      "method": "研究方法引入了Sparse Tracing技术，利用动态稀疏注意力来高效分析长上下文注意力模式。核心是Stream算法，一个可编译的分层剪枝算法，通过二进制搜索式细化估计每个头的稀疏注意力掩码，在近线性时间O(T log T)和线性空间O(T)内运行，同时保持模型的下一个标记行为，从而允许单遍分析大规模数据，而无需大量内存缓存。",
      "result": "实验结果显示，在长链思维推理轨迹中，Stream成功识别思维锚点，同时剪枝了97-99%的标记交互。在RULER基准上，算法保留了关键检索路径，丢弃了90-96%的交互，并暴露了从输入针到输出的逐层路径，证明了其在维持模型性能的同时，显著减少了计算开销，相比之下基线方法可能内存需求极高且不可行。",
      "conclusion": "论文贡献了Stream算法，为分析大语言模型的长上下文注意力模式提供了实用工具，使可解释性在消费者GPU上可行，促进了链思维监控的民主化。其学术价值在于扩展了可解释性技术到大规模场景，实际应用上支持更高效的模型监控。未来工作可扩展到其他模型类型或更复杂的推理任务。",
      "tags": [
        "Large Language Model",
        "Sparse Attention",
        "Mechanistic Interpretability",
        "Hierarchical Pruning",
        "Chain-of-Thought Reasoning"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:27.150474Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.14376",
    "title": "DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation",
    "authors": [
      "Dongnam Byun",
      "Jungwon Park",
      "Jungmin Ko",
      "Changin Choi",
      "Wonjong Rhee"
    ],
    "abstract": "Recent progress in text-to-image (T2I) generative models has led to significant improvements in generating high-quality images aligned with text prompts. However, these models still struggle with prompts involving multiple objects, often resulting in object neglect or object mixing. Through extensive studies, we identify four problematic scenarios, Similar Shapes, Similar Textures, Dissimilar Background Biases, and Many Objects, where inter-object relationships frequently lead to such failures. Motivated by two key observations about CLIP embeddings, we propose DOS (Directional Object Separation), a method that modifies three types of CLIP text embeddings before passing them into text-to-image models. Experimental results show that DOS consistently improves the success rate of multi-object image generation and reduces object mixing. In human evaluations, DOS significantly outperforms four competing methods, receiving 26.24%-43.04% more votes across four benchmarks. These results highlight DOS as a practical and effective solution for improving multi-object image generation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.14376.pdf",
    "abs_url": "https://arxiv.org/abs/2510.14376",
    "published": "2025-10-16T07:17:23Z",
    "updated": "2026-02-02T06:40:44Z",
    "comment": "Accepted to AAAI 2026",
    "light_analysis": {
      "overview": "DOS方法通过修改CLIP文本嵌入，有效解决文本到图像生成中多对象提示下的对象忽视和混合问题。",
      "motivation": "文本到图像生成模型在处理多对象提示时，常出现对象忽视或对象混合的问题，限制了实际应用效果。论文识别了四种常见失败场景：相似形状、相似纹理、不同背景偏见和多个对象，这些场景中对象间关系易导致模型失败。现有方法在这些方面表现不足，因此基于对CLIP嵌入的两个关键观察，研究旨在提出一种改进方法来增强对象分离能力，解决多对象生成的挑战。",
      "method": "论文提出DOS（定向对象分离）方法，其核心是通过修改CLIP文本嵌入以改善多对象图像生成。基于对CLIP嵌入的观察，论文调整了三种类型的文本嵌入，然后将其输入到文本到图像模型中。关键技术包括定向分离策略，增强对象在嵌入空间中的区分度，减少混合现象。该方法不依赖额外数据集，直接集成到现有模型框架中，以提升对象间的独立性和准确性。",
      "result": "实验结果表明，DOS方法能显著提高多对象图像生成的成功率，并有效减少对象混合。在人类评估中，DOS在四个基准测试上优于四种竞争方法，得票率高出26.24%至43.04%。这些数据证明了DOS在减少对象忽视和混合方面的优越性，显示了其在多对象生成任务中的稳定改进和有效性。",
      "conclusion": "DOS方法作为一个实用有效的解决方案，显著改善了多对象图像生成的质量。学术上，它基于CLIP嵌入的观察提出创新方法；实际应用中，提升了文本到图像模型处理复杂提示的能力。尽管摘要未明确说明局限性，但未来工作可探索更多场景下的适用性或与其他技术的结合，以进一步优化性能。",
      "tags": [
        "Text-to-Image Generation",
        "CLIP embeddings",
        "Multi-object Generation",
        "Object Separation",
        "Directional Separation"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:40.592742Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.13745",
    "title": "UniCalli: A Unified Diffusion Framework for Column-Level Generation and Recognition of Chinese Calligraphy",
    "authors": [
      "Tianshuo Xu",
      "Kai Wang",
      "Zhifei Chen",
      "Leyi Wu",
      "Tianshui Wen",
      "Fei Chao",
      "Ying-Cong Chen"
    ],
    "abstract": "Computational replication of Chinese calligraphy remains challenging. Existing methods falter, either creating high-quality isolated characters while ignoring page-level aesthetics like ligatures and spacing, or attempting page synthesis at the expense of calligraphic correctness. We introduce \\textbf{UniCalli}, a unified diffusion framework for column-level recognition and generation. Training both tasks jointly is deliberate: recognition constrains the generator to preserve character structure, while generation provides style and layout priors. This synergy fosters concept-level abstractions that improve both tasks, especially in limited-data regimes. We curated a dataset of over 8,000 digitized pieces, with ~4,000 densely annotated. UniCalli employs asymmetric noising and a rasterized box map for spatial priors, trained on a mix of synthetic, labeled, and unlabeled data. The model achieves state-of-the-art generative quality with superior ligature continuity and layout fidelity, alongside stronger recognition. The framework successfully extends to other ancient scripts, including Oracle bone inscriptions and Egyptian hieroglyphs. Code and data can be viewed in \\href{https://github.com/EnVision-Research/UniCalli}{this URL}.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.13745.pdf",
    "abs_url": "https://arxiv.org/abs/2510.13745",
    "published": "2025-10-15T16:52:07Z",
    "updated": "2026-02-02T08:01:40Z",
    "comment": "Page: https://envision-research.github.io/UniCalli/",
    "light_analysis": {
      "overview": "UniCalli是一个统一的扩散框架，用于中国书法的列级生成与识别，通过联合训练促进概念级抽象，提升性能和泛化能力。",
      "motivation": "中国书法计算复制面临挑战，现有方法要么在生成高质量孤立字符时忽略页面级美观性（如连笔和间距），要么在尝试页面合成时牺牲书法正确性。这个问题重要，因为书法是文化遗产，自动化复制对文化保护和传承有实际需求。现有方法的不足在于难以平衡生成美观性和书法正确性，导致效果不佳。",
      "method": "论文提出UniCalli框架，采用扩散模型统一处理列级生成和识别任务。关键创新在于联合训练，生成任务提供样式和布局先验，识别任务约束字符结构，促进概念级抽象。技术特色包括使用不对称噪声策略和栅格化框图来融入空间先验。数据集包含超过8,000件数字化书法作品，其中约4,000件有密集注释，训练时结合合成、标记和未标记数据，以增强模型鲁棒性。",
      "result": "UniCalli在生成质量上达到最先进水平，具有优越的连笔连续性和布局保真度，同时识别性能更强，优于基线方法。框架成功扩展到其他古代文字，如甲骨文和埃及象形文字，显示出良好的泛化能力。实验结果虽未提供具体数字，但强调了在生成和识别任务上的显著改进。",
      "conclusion": "论文的主要贡献是提出UniCalli统一扩散框架，显著改进了书法生成和识别性能，尤其在有限数据情况下。学术价值在于为书法计算复制提供了一种多任务协同方法，实际应用价值体现在文化遗产保护和教育等领域。局限性或未来工作方向摘要未明确说明，但扩展性显示潜力。",
      "tags": [
        "Diffusion Model",
        "Chinese Calligraphy",
        "Multi-task Learning",
        "Column-Level Generation",
        "Recognition"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:31.361110Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.15969",
    "title": "LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems",
    "authors": [
      "Paul-Niklas Ken Kandora",
      "Simon Caspar Zeller",
      "Aaron Jeremias Elsing",
      "Elena Kuss",
      "Steffen Rebennack"
    ],
    "abstract": "Reformulating nonlinear optimization problems into solver-ready linear optimization problems is often necessary for practical applications, but the process is often manual and requires domain expertise. We propose LinearizeLLM, an agent-based LLM framework that produces solver-ready linear reformulations of nonlinear optimization problems. Agents first detect the nonlinearity pattern (e.g., bilinear products) and apply nonlinearity pattern-aware reformulation techniques, selecting the most suitable linearization technique. We benchmark on 40 instances: 27 derived from ComplexOR by injecting exactly-linearizable operators, and 13 automatically generated instances with deeply nested nonlinearities. LinearizeLLM achieves 73\\% mean end-to-end overall success (OSR) across nonlinearity depths (8.3x higher than a one-shot LLM baseline; 4.3x higher than Pyomo). The results suggest that a set of pattern-specialized agents can automate linearization, supporting natural-language-based modeling of nonlinear optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.15969.pdf",
    "abs_url": "https://arxiv.org/abs/2510.15969",
    "published": "2025-10-12T16:43:21Z",
    "updated": "2026-02-02T09:32:11Z",
    "comment": "This version is a major revision with a new abstract, updated workflow logic and description, an expanded instance set, additional numerical experiments, and corrected bibliography entries",
    "light_analysis": {
      "overview": "LinearizeLLM 提出了一个基于代理的 LLM 框架，用于自动将非线性优化问题转化为线性优化问题。",
      "motivation": "非线性优化问题在实际应用中常需转化为线性优化问题以便求解，但这一过程通常依赖人工手动完成，要求深厚的领域专业知识，导致效率低下和可扩展性差。现有方法如 Pyomo 或一次性 LLM 方法性能有限，成功率较低，限制了自动化建模的可行性。因此，开发自动化的线性化框架具有重要意义，可以降低建模门槛，提升优化问题求解的效率和可访问性，满足工程、经济等领域的实际需求。",
      "method": "LinearizeLLM 采用基于代理的框架，其中代理首先检测非线性模式（例如双线性乘积），然后应用非线性模式感知的线性化技术，选择最合适的线性化方法进行转化。框架利用 LLM 驱动，通过模式识别和智能选择来自动化整个过程。研究在 40 个实例上进行了测试，包括来自 ComplexOR 的 27 个实例和自动生成的 13 个实例，涵盖不同非线性深度，以评估方法的有效性和鲁棒性。",
      "result": "实验结果显示，LinearizeLLM 在 40 个实例上实现了 73% 的平均端到端总体成功率（OSR）。与基线方法相比，其成功率是一次性 LLM 基线的 8.3 倍，是 Pyomo 的 4.3 倍。这表明框架在处理不同非线性深度的问题时具有显著优势，特别是在复杂嵌套非线性实例上表现优异，有效提升了线性化过程的自动化水平和求解效率。",
      "conclusion": "LinearizeLLM 的主要贡献是提供了一个能够自动化非线性优化问题线性化的代理框架，支持基于自然语言的建模。该研究在学术上推动了 LLM 在优化领域的应用，实践上可以简化优化问题的求解流程，提高效率和应用可及性。未来工作可能包括扩展到更复杂的非线性模式、集成更多求解器或优化代理决策过程，以进一步提升性能和通用性。",
      "tags": [
        "Large Language Model",
        "Agent-Based Systems",
        "Nonlinear Optimization",
        "Linearization Techniques",
        "Pattern Recognition"
      ]
    },
    "analyzed_at": "2026-02-03T03:58:53.035993Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.10467",
    "title": "AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs",
    "authors": [
      "Gunho Park",
      "Jeongin Bae",
      "Beomseok Kwon",
      "Byeongwook Kim",
      "Se Jung Kwon",
      "Dongsoo Lee"
    ],
    "abstract": "The deployment of large language models (LLMs) is increasingly constrained by memory and latency bottlenecks, motivating the need for quantization techniques that flexibly balance accuracy and efficiency. Recent work has introduced multi-precision models, which enable inference at multiple precisions within a single model depending on runtime constraints. To support such flexibility, quantized weights are often stored as bit-planes, where hardware efficiency improves when the compute operates directly at the bit-plane level and activates only the precision required by each request. In this work, we present AnyBCQ, a hardware-friendly multi-precision extension of Binary-Coded Quantization (BCQ) that supports direct bit-plane operations. By representing weights as binary bit-planes with corresponding scale factors, AnyBCQ enables bit-plane-level computation and maps naturally to accelerator-friendly, bit-parallel arithmetic. Our progressive precision expansion mechanism incrementally refines scaling factors while reusing previously assigned binary codes, yielding monotonic improvements in accuracy as additional bits are enabled. We further co-design a specialized kernel that exploits the BCQ structure to support dynamic per-request precision selection with negligible overhead. Experiments on recent LLMs demonstrate that AnyBCQ significantly narrows the accuracy drop in the low-bit regime (e.g. 2-bit), remains competitive at higher precision, and achieves throughput gains of up to 3.0x over half precision and 1.2x over state-of-the-art multi-precision methods. By aligning algorithmic flexibility with hardware efficiency, AnyBCQ provides a practical foundation for multi-precision LLM deployment across diverse service-level objectives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.10467.pdf",
    "abs_url": "https://arxiv.org/abs/2510.10467",
    "published": "2025-10-12T06:20:38Z",
    "updated": "2026-02-02T04:23:47Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "AnyBCQ提出了一种硬件友好的二进制编码量化方法，支持多精度LLM部署，实现高效动态精度选择和位平面操作，以平衡精度与效率。",
      "motivation": "大规模语言模型部署面临内存和延迟瓶颈，需要灵活的量化技术来压缩模型并加速推理。多精度模型允许在单个模型内根据运行时约束调整精度，但现有方法在硬件效率方面不足，尤其是位平面操作未充分利用，导致开销较大。AnyBCQ旨在解决这一问题，通过优化二进制编码量化，实现直接位平面计算，从而提高硬件效率并支持动态精度选择。",
      "method": "AnyBCQ基于二进制编码量化扩展，将权重表示为带比例因子的二进制位平面，实现位平面级计算并映射到加速器友好的位并行算术。其关键创新包括渐进精度扩展机制，通过逐步细化比例因子并重用已有二进制代码，确保精度随启用位数单调提升。此外，作者共同设计了一个专用计算内核，利用BCQ结构特性支持动态每请求精度选择，且额外开销极小，适用于多精度LLM推理。",
      "result": "实验验证了AnyBCQ在多种LLMs上的性能：在低位量化（如2位）下，该方法显著缩小了准确性下降，表现优于其他方法；在较高精度设置中仍保持竞争力。吞吐量方面，相比半精度推理，AnyBCQ实现了高达3.0倍的增益；与现有最先进多精度方法相比，也有1.2倍的提升。这些结果表明，AnyBCQ在减少精度损失的同时，有效提高了硬件效率。",
      "conclusion": "该论文的主要贡献在于提出了AnyBCQ方法，它将算法灵活性与硬件效率相结合，为多精度LLM部署提供了实用解决方案。通过渐进精度扩展和专用内核设计，AnyBCQ在减少精度损失的同时大幅提升了吞吐量，适用于不同资源约束的应用场景。这项研究具有重要的学术价值，推动了量化技术在实际部署中的应用，未来工作可扩展到更广泛的模型和优化中。摘要未明确说明具体局限性。",
      "tags": [
        "Binary-Coded Quantization",
        "Bit-Plane Operations",
        "Multi-Precision Models",
        "Progressive Precision Expansion",
        "Hardware Efficiency"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:00.475568Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.07890",
    "title": "Standard-to-Dialect Transfer Trends Differ across Text and Speech: A Case Study on Intent and Topic Classification in German Dialects",
    "authors": [
      "Verena Blaschke",
      "Miriam Winkler",
      "Barbara Plank"
    ],
    "abstract": "Research on cross-dialectal transfer from a standard to a non-standard dialect variety has typically focused on text data. However, dialects are primarily spoken, and non-standard spellings cause issues in text processing. We compare standard-to-dialect transfer in three settings: text models, speech models, and cascaded systems where speech first gets automatically transcribed and then further processed by a text model. We focus on German dialects in the context of written and spoken intent classification -- releasing the first dialectal audio intent classification dataset -- with supporting experiments on topic classification. The speech-only setup provides the best results on the dialect data while the text-only setup works best on the standard data. While the cascaded systems lag behind the text-only models for German, they perform relatively well on the dialectal data if the transcription system generates normalized, standard-like output.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2510.07890.pdf",
    "abs_url": "https://arxiv.org/abs/2510.07890",
    "published": "2025-10-09T07:43:08Z",
    "updated": "2026-02-02T11:52:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文比较了文本、语音和级联系统在德语方言意图分类中的标准到方言转移趋势，并发布了首个方言音频意图分类数据集。",
      "motivation": "该研究旨在解决跨方言转移中文本数据处理的局限性。现有研究多集中于文本模态，但方言主要是口头语言，非标准拼写导致文本处理困难，忽略了语音模态的重要性。因此，论文探讨了从标准德语到非标准方言的转移在不同设置下的表现，以更好地理解和优化方言数据处理方法，填补现有研究的空白。",
      "method": "论文提出了三种标准到方言转移设置：文本模型、语音模型和级联系统（语音先被自动转录为文本，再由文本模型处理）。研究聚焦于德语方言的意图分类任务，并发布了首个方言音频意图分类数据集，同时进行主题分类的支持实验。关键创新点在于跨模态比较和音频数据集的创建，使用具体的数据集和模型架构（摘要未明确说明细节）来评估不同方法的有效性。",
      "result": "实验结果显示，仅语音模型在方言数据上表现最佳，而仅文本模型在标准数据上效果最好。对于德语，级联系统落后于文本模型，但如果转录系统能生成归一化的、类似标准的输出，则在方言数据上表现相对较好。这些发现表明，语音模型在处理方言数据时具有优势，而文本模型更适用于标准数据，验证了不同模态在处理方言时的性能差异。",
      "conclusion": "论文的主要贡献在于揭示了标准到方言转移在文本和语音模态下的不同趋势，并发布了首个方言音频意图分类数据集，为跨方言自然语言处理提供了新见解。研究具有学术价值，强调语音模型在方言数据处理中的重要性，实际应用价值包括改进方言分类系统。潜在局限性可能在于数据集的规模和语言范围，未来工作可以扩展到更多方言和优化转录系统。",
      "tags": [
        "Standard-to-Dialect Transfer",
        "Intent Classification",
        "Speech Processing",
        "German Dialects",
        "Topic Classification"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:19.900401Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.04714",
    "title": "Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction",
    "authors": [
      "KunHo Heo",
      "GiHyun Kim",
      "SuYeon Kim",
      "MyeongAh Cho"
    ],
    "abstract": "3D Semantic Scene Graph Prediction aims to detect objects and their semantic relationships in 3D scenes, and has emerged as a crucial technology for robotics and AR/VR applications. While previous research has addressed dataset limitations and explored various approaches including Open-Vocabulary settings, they frequently fail to optimize the representational capacity of object and relationship features, showing excessive reliance on Graph Neural Networks despite insufficient discriminative capability. In this work, we demonstrate through extensive analysis that the quality of object features plays a critical role in determining overall scene graph accuracy. To address this challenge, we design a highly discriminative object feature encoder and employ a contrastive pretraining strategy that decouples object representation learning from the scene graph prediction. This design not only enhances object classification accuracy but also yields direct improvements in relationship prediction. Notably, when plugging in our pretrained encoder into existing frameworks, we observe substantial performance improvements across all evaluation metrics. Additionally, whereas existing approaches have not fully exploited the integration of relationship information, we effectively combine both geometric and semantic features to achieve superior relationship prediction. Comprehensive experiments on the 3DSSG dataset demonstrate that our approach significantly outperforms previous state-of-the-art methods. Our code is publicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2510.04714.pdf",
    "abs_url": "https://arxiv.org/abs/2510.04714",
    "published": "2025-10-06T11:33:09Z",
    "updated": "2026-02-02T08:57:36Z",
    "comment": "Accepted by NeurIPS 2025. Code: https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes",
    "light_analysis": {
      "overview": "本研究提出一种对象中心表示学习方法，结合对比预训练，显著提升3D场景图预测的准确性。",
      "motivation": "3D语义场景图预测是机器人和AR/VR领域的关键技术，但现有方法常因对象特征表示能力不足而性能受限。研究者指出，尽管有Open-Vocabulary等尝试，但过度依赖图神经网络导致判别能力差，对象特征质量直接影响整体准确性。因此，亟需优化对象表示学习以解决此问题，推动实际应用发展，弥补现有方法在特征优化和关系整合方面的不足。",
      "method": "本文设计了一个高判别性的对象特征编码器，并采用对比预训练策略，将对象表示学习从场景图预测中解耦。通过独立训练对象特征，增强分类能力，同时结合几何和语义信息来改进关系预测。在3DSSG数据集上实施，预训练编码器可无缝集成到现有框架中，无需改动网络结构，利用解耦学习优化对象和关系特征表示。",
      "result": "在3DSSG数据集上的综合实验表明，所提方法在所有评价指标上均显著优于先前的最先进方法。通过对比基线，对象分类准确性和关系预测均得到直接改善，展现出整体性能的实质性提升，验证了对象特征质量对场景图预测的关键作用。具体表现为准确率、召回率等指标的全面增强，摘要未明确说明具体数据。",
      "conclusion": "本研究的主要贡献在于提出了一种有效的对象中心表示学习框架，通过优化对象特征和结合多源信息，显著提升了3D场景图预测的准确性和鲁棒性。这不仅在学术上推动了表示学习领域的发展，还为机器人和AR/VR应用提供了实用技术。未来工作可探索更复杂的场景或扩展该方法到其他视觉任务，如摘要未明确说明局限性。",
      "tags": [
        "3D Semantic Scene Graph Prediction",
        "Object-Centric Representation Learning",
        "Contrastive Pretraining",
        "Graph Neural Networks",
        "Geometric and Semantic Features"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:26.385060Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2510.04217",
    "title": "MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering",
    "authors": [
      "Chenlu Ding",
      "Jiancan Wu",
      "Leheng Sheng",
      "Fan Zhang",
      "Yancheng Yuan",
      "Xiang Wang",
      "Xiangnan He"
    ],
    "abstract": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities across vision-language tasks, yet their large-scale deployment raises pressing concerns about memorized private data, outdated knowledge, and harmful content. Existing unlearning approaches for MLLMs typically adapt training-based strategies such as gradient ascent or preference optimization, but these methods are computationally expensive, irreversible, and often distort retained knowledge. In this work, we propose MLLMEraser, an input-aware, training-free framework for test-time unlearning. Our approach leverages activation steering to enable dynamic knowledge erasure without parameter updates. Specifically, we construct a multimodal erasure direction by contrasting adversarially perturbed, knowledge-recall image-text pairs with knowledge-erasure counterparts, capturing both textual and visual discrepancies. To prevent unnecessary interference, we further design an input-aware steering mechanism that adaptively determines when and how the erasure direction should be applied, preserving utility on retained knowledge while enforcing forgetting on designated content. Experiments on LLaVA-1.5 and Qwen-2.5-VL demonstrate that MLLMEraser consistently outperforms state-of-the-art MLLM unlearning baselines, achieving stronger forgetting performance with lower computational cost and minimal utility degradation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2510.04217.pdf",
    "abs_url": "https://arxiv.org/abs/2510.04217",
    "published": "2025-10-05T14:20:17Z",
    "updated": "2026-02-02T12:41:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出MLLMEraser框架，通过激活引导实现多模态大语言模型的测试时遗忘学习，无需参数更新。",
      "motivation": "多模态大语言模型（MLLMs）在视觉-语言任务中表现出色，但其大规模部署引发了隐私数据记忆、过时知识和有害内容等紧迫问题。现有遗忘学习方法通常基于训练策略，如梯度上升或偏好优化，这些方法计算成本高、不可逆，并可能破坏模型保留的知识。因此，迫切需要一种高效、可逆的方法，以确保模型的安全性和隐私保护，同时避免知识失真。本研究旨在解决这一实际问题，通过开发一种无需训练的动态遗忘框架来弥补现有不足。",
      "method": "研究方法基于激活引导技术，提出一个输入感知、无需训练的遗忘框架MLLMEraser。核心是通过对比对抗扰动的知识召回图像-文本对与知识擦除配对，构建多模态擦除方向，捕捉文本和视觉差异。创新点包括设计输入感知的引导机制，自适应确定何时及如何应用擦除方向，从而保留有用知识并有效遗忘指定内容。该方法在无需更新模型参数的条件下实现动态知识擦除，实验中使用LLaVA-1.5和Qwen-2.5-VL等MLLM模型进行验证。",
      "result": "在LLaVA-1.5和Qwen-2.5-VL模型上的实验表明，MLLMEraser consistently outperforms state-of-the-art MLLM遗忘基线方法。它实现了更强的遗忘性能，计算成本较低，并最小化了对保留知识的效用退化。摘要未明确说明具体性能指标如准确率，但突出了该方法在效率和有效性上的优势，相比于基于训练的方法，具有显著改进。",
      "conclusion": "本论文的主要贡献是提出MLLMEraser，一种高效、无需训练的多模态大语言模型遗忘学习框架。其学术价值在于通过激活引导技术提升了模型的可控性和安全性，实际应用价值包括隐私保护和内容过滤，促进MLLMs的负责任部署。未来工作方向可能涉及进一步优化自适应机制或扩展到更广泛的多模态任务中，摘要未明确说明具体局限性，但强调了方法的可扩展性和成本效益。",
      "tags": [
        "Multimodal Large Language Models (MLLMs)",
        "Activation Steering",
        "Test-Time Unlearning",
        "Unlearning Algorithms",
        "Vision-Language Tasks"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:17.696703Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.23234",
    "title": "p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding",
    "authors": [
      "Runyan Tan",
      "Shuang Wu",
      "Phillip Howard"
    ],
    "abstract": "Obtaining high-quality outputs from Large Language Models (LLMs) often depends upon the choice of a sampling-based decoding strategy to probabilistically choose the next token at each generation step. While a variety of such sampling methods have been proposed, their performance can be sensitive to the selection of hyperparameters which may require different settings depending upon the generation task and temperature configuration. In this work, we introduce $p$-less sampling: an information-theoretic approach to sampling which dynamically sets a truncation threshold at each decoding step based on the entire token probability distribution. Unlike existing methods, $p$-less sampling has no hyperparameters and consistently produces high-quality outputs as temperature increases. We provide theoretical perspectives on $p$-less sampling to ground our proposed method and conduct experiments to empirically validate its effectiveness across a range of math, logical reasoning, and creative writing tasks. Our results demonstrate how $p$-less sampling consistently outperforms existing sampling approaches while exhibiting much less degradation in text quality at higher temperature values. We further show how $p$-less achieves greater inference-time efficiency than alternative methods through lower average token sampling times and shorter generation lengths, without sacrificing accuracy. Finally, we provide analyses to highlight the benefits of $p$-less through qualitative examples, case studies, and diversity assessments. The code is available at https://github.com/ryttry/p-less .",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2509.23234.pdf",
    "abs_url": "https://arxiv.org/abs/2509.23234",
    "published": "2025-09-27T10:33:41Z",
    "updated": "2026-02-02T11:54:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出p-less sampling，一种无超参数的稳健采样方法，用于大型语言模型解码，动态设置截断阈值以提升输出质量和效率。",
      "motivation": "大型语言模型（LLMs）的解码过程中，采样策略对输出质量至关重要，但现有方法如top-p和temperature scaling对超参数敏感，需根据不同生成任务和温度配置调整，增加了使用复杂性。在温度升高时，现有方法常导致文本质量下降，因此开发一种无需调参、能适应不同任务并维持高质量输出的稳健方法具有重要研究价值，以简化部署并提高模型泛化能力。",
      "method": "论文提出p-less sampling方法，它是一种基于信息论的采样技术，用于LLM解码。在每个生成步骤中，方法动态计算并设置一个截断阈值，基于当前所有标记的概率分布，无需任何超参数。核心创新在于利用整个概率分布进行阈值选择，确保采样过程的稳健性和自适应性。摘要未明确说明具体的数据集或模型架构，但该方法通过理论视角和应用实验来验证其技术特色。",
      "result": "实验结果显示，p-less sampling在数学、逻辑推理和创造性写作任务上 consistently outperforms existing sampling approaches。在高温度设置下，输出质量下降较少，表现出更高稳健性。具体指标包括更低平均标记采样时间和更短生成长度，同时不牺牲准确性，与基线方法相比，展示了效率和质量的双重优势。定性示例和多样性评估进一步验证了其有效性。",
      "conclusion": "本文的主要贡献是提出了p-less sampling，一种无超参数的稳健采样方法，显著提升LLM解码的质量、效率和稳健性。学术价值体现在为信息论在采样中的应用提供了新视角，并简化了实际部署中的参数调优。实际应用中，能减少计算开销，促进更高效推理。未来工作方向在摘要中未明确说明，但可能包括扩展到更多任务或与其他解码策略结合，以进一步评估其泛化能力和局限性。",
      "tags": [
        "Large Language Model",
        "Sampling Methods",
        "Information Theory",
        "Decoding",
        "Hyperparameter-Free"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:29.162813Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22221",
    "title": "Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models",
    "authors": [
      "Jiaqi Liu",
      "Lang Sun",
      "Ronghao Fu",
      "Bo Yang"
    ],
    "abstract": "Vision-Language Models (VLMs) in remote sensing often fail at complex analytical tasks, a limitation stemming from their end-to-end training paradigm that bypasses crucial reasoning steps and leads to unverifiable outputs. To address this limitation, we introduce the Perceptually-Grounded Geospatial Chain-of-Thought (Geo-CoT), a framework that models remote sensing analysis as a verifiable, multi-step process. We instill this analytical process through a two-stage alignment strategy, leveraging Geo-CoT380k, the first large-scale dataset of structured Geo-CoT rationales. This strategy first employs supervised fine-tuning (SFT) to instill the foundational cognitive architecture, then leverages Group Reward Policy Optimization (GRPO) to refine the model's reasoning policy towards factual correctness. The resulting model, RSThinker, outputs both a final answer and its justifying, verifiable analytical trace. This capability yields dominant performance, significantly outperforming state-of-the-art models across a comprehensive range of tasks. The public release of our Geo-CoT380k dataset and RSThinker model upon publication serves as a concrete pathway from opaque perception towards structured, verifiable reasoning for Earth Observation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.22221.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22221",
    "published": "2025-09-26T11:34:42Z",
    "updated": "2026-02-02T10:01:02Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出感知基础的时空链式思维框架和RSThinker模型，提升遥感视觉-语言模型的可验证推理能力和性能。",
      "motivation": "遥感视觉-语言模型在处理复杂分析任务时经常失败，这源于其端到端训练范式跳过推理步骤，导致输出不可验证。遥感分析需要高可靠性和可解释性，但现有方法缺乏结构化推理过程，难以确保事实正确性。因此，开发一个能够模拟空间推理、提供可追溯分析痕迹的框架至关重要，以解决遥感领域的关键需求。",
      "method": "论文引入Perceptually-Grounded Geospatial Chain-of-Thought（Geo-CoT）框架，将遥感分析建模为多步可验证推理链。采用两阶段对齐策略：首先使用监督微调在Geo-CoT380k数据集上构建基础认知架构；然后应用群体奖励策略优化来精细化推理策略，确保事实正确性。关键创新包括大规模结构化理性数据集的创建和GRPO优化技术的应用，提升模型的空间理解和推理能力。",
      "result": "RSThinker模型在广泛遥感任务中展现出主导性能，显著优于当前最先进的视觉-语言模型。模型输出最终答案及其可验证的分析跟踪，增强了结果的可信度和可解释性。尽管摘要未明确说明具体性能指标，但强调了其在多项任务上的卓越表现，为遥感分析提供了可靠的工具，推动了领域进步。",
      "conclusion": "研究通过Geo-CoT框架和RSThinker模型，实现了遥感视觉-语言模型从模糊感知到结构化推理的转变，提升了分析的可验证性和性能。公开发布Geo-CoT380k数据集和模型，为地球观测领域提供了可复现的基础资源，具有重要的学术和实际应用价值。未来工作可能涉及优化推理效率、扩展任务范围，以及探索更多应用场景。",
      "tags": [
        "Vision-Language Models",
        "Chain-of-Thought",
        "Remote Sensing",
        "Supervised Fine-Tuning",
        "Group Reward Policy Optimization"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:46.145351Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.22102",
    "title": "Reinforcement Learning for Durable Algorithmic Recourse",
    "authors": [
      "Marina Ceccon",
      "Alessandro Fabris",
      "Goran Radanović",
      "Asia J. Biega",
      "Gian Antonio Susto"
    ],
    "abstract": "Algorithmic recourse seeks to provide individuals with actionable recommendations that increase their chances of receiving favorable outcomes from automated decision systems (e.g., loan approvals). While prior research has emphasized robustness to model updates, considerably less attention has been given to the temporal dynamics of recourse--particularly in competitive, resource-constrained settings where recommendations shape future applicant pools. In this work, we present a novel time-aware framework for algorithmic recourse, explicitly modeling how candidate populations adapt in response to recommendations. Additionally, we introduce a novel reinforcement learning (RL)-based recourse algorithm that captures the evolving dynamics of the environment to generate recommendations that are both feasible and valid. We design our recommendations to be durable, supporting validity over a predefined time horizon T. This durability allows individuals to confidently reapply after taking time to implement the suggested changes. Through extensive experiments in complex simulation environments, we show that our approach substantially outperforms existing baselines, offering a superior balance between feasibility and long-term validity. Together, these results underscore the importance of incorporating temporal and behavioral dynamics into the design of practical recourse systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.22102.pdf",
    "abs_url": "https://arxiv.org/abs/2509.22102",
    "published": "2025-09-26T09:24:12Z",
    "updated": "2026-02-02T09:01:26Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出了一种基于强化学习的时间感知算法推荐框架，以生成耐久的、可行的建议。",
      "motivation": "Algorithmic recourse 旨在为个体提供可操作建议，以增加在自动化决策系统（如贷款审批）中获得有利结果的机会。然而，现有研究多侧重于对模型更新的鲁棒性，却忽视了时间动态，尤其是在竞争性和资源受限的环境中，推荐建议会影响未来申请者群体，导致建议可能不持久或失效。这个问题至关重要，因为它直接关系到个体能否在实施建议后成功重新申请，从而提升公平性和实用性。因此，本研究致力于解决这一不足，将时间动态和行为适应纳入考量。",
      "method": "本研究提出了一个时间感知的算法推荐框架，明确建模候选群体如何适应推荐建议。核心方法包括引入基于强化学习的recourse算法，该算法捕捉环境的演化动态，以生成既可行又有效的建议。关键创新点在于结合时间维度，确保建议在预定义的时间范围T内保持耐久性，支持个体在实施改变后自信地重新申请。技术特色包括使用强化学习来优化长期策略，避免短期失效，并在模拟环境中测试模型的适应性。",
      "result": "通过在复杂模拟环境中的广泛实验，本方法显示出显著优于现有基线的性能。它在可行性和长期有效性之间提供了更好的平衡，确保建议在时间范围内保持有效。然而，摘要未明确说明具体的性能指标数据，如准确率或效率提升百分比，仅提到大幅优于基线。这表明该方法在模拟设置中能有效处理时间动态，为实际应用提供了改进方案。",
      "conclusion": "本文的主要贡献是提出了一种耐久的算法推荐框架，通过结合时间动态和强化学习，提高了建议的长期有效性。研究强调了在实用recourse系统设计中纳入时间和行为动态的重要性，具有学术价值并为实际应用（如金融服务）提供了新思路。未来工作可能包括进一步优化算法以处理更复杂的环境，或将框架扩展到其他自动化决策领域，以增强其通用性和鲁棒性。",
      "tags": [
        "Algorithmic Recourse",
        "Reinforcement Learning",
        "Temporal Dynamics",
        "Behavioral Adaptation",
        "Simulation"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:47.899402Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.20295",
    "title": "FAST: Foreground-aware Diffusion with Accelerated Sampling Trajectory for Segmentation-oriented Anomaly Synthesis",
    "authors": [
      "Xichen Xu",
      "Yanshu Wang",
      "Jinbao Wang",
      "Xiaoning Lei",
      "Guoyang Xie",
      "Guannan Jiang",
      "Zhichao Lu"
    ],
    "abstract": "Industrial anomaly segmentation relies heavily on pixel-level annotations, yet real-world anomalies are often scarce, diverse, and costly to label. Segmentation-oriented industrial anomaly synthesis (SIAS) has emerged as a promising alternative; however, existing methods struggle to balance sampling efficiency and generation quality. Moreover, most approaches treat all spatial regions uniformly, overlooking the distinct statistical differences between anomaly and background areas. This uniform treatment hinders the synthesis of controllable, structure-specific anomalies tailored for segmentation tasks. In this paper, we propose FAST, a foreground-aware diffusion framework featuring two novel modules: the Anomaly-Informed Accelerated Sampling (AIAS) and the Foreground-Aware Reconstruction Module (FARM). AIAS is a training-free sampling algorithm specifically designed for segmentation-oriented industrial anomaly synthesis, which accelerates the reverse process through coarse-to-fine aggregation and enables the synthesis of state-of-the-art segmentation-oriented anomalies in as few as 10 steps. Meanwhile, FARM adaptively adjusts the anomaly-aware noise within the masked foreground regions at each sampling step, preserving localized anomaly signals throughout the denoising trajectory. Extensive experiments on multiple industrial benchmarks demonstrate that FAST consistently outperforms existing anomaly synthesis methods in downstream segmentation tasks. We release the code at: https://github.com/Chhro123/fast-foreground-aware-anomaly-synthesis.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.20295.pdf",
    "abs_url": "https://arxiv.org/abs/2509.20295",
    "published": "2025-09-24T16:28:15Z",
    "updated": "2026-02-02T05:41:48Z",
    "comment": "Accepted to NeurIPS 2025",
    "light_analysis": {
      "overview": "FAST提出一种前景感知扩散框架，通过AIAS加速采样和FARM调整噪声，实现高效高质量的工业异常合成。",
      "motivation": "工业异常分割高度依赖像素级标注，然而真实世界异常样本稀缺、多样且标注成本高昂。分割导向的工业异常合成（SIAS）作为一种替代方案，能够生成标注数据以辅助训练，但现有方法在采样效率和生成质量之间难以平衡。此外，大多数方法对所有空间区域统一处理，忽略了异常区域与背景区域的统计差异，导致无法合成针对分割任务的结构特定异常，限制了实际应用效果。",
      "method": "FAST框架包含两个新模块：AIAS和FARM。AIAS是一种无需训练的采样算法，通过粗到细聚合策略加速扩散模型的反向过程，仅需10步即可生成高质量分割导向异常。FARM则在每个采样步骤中自适应调整掩码前景区域内的异常感知噪声，确保局部异常信号在去噪轨迹中得到保留，实现前景感知和结构特定异常合成。摘要未明确说明具体数据集，但实验基于多个工业基准。",
      "result": "在多个工业基准数据集上的广泛实验表明，FAST在下游异常分割任务中一致优于现有异常合成方法。该框架通过加速采样实现高效率，仅需10步即可生成先进异常，提高了合成与分割的整体性能，与基线方法相比表现出色，为工业应用提供有效支持。",
      "conclusion": "FAST的主要贡献在于提出一个前景感知扩散框架，有效平衡采样效率和生成质量，实现针对分割任务的可控异常合成。该研究推动了分割导向异常合成的学术进展，并具有实际应用价值，能辅助工业异常检测与分割。摘要未明确说明潜在局限性或未来工作方向，但代码开源促进了进一步研究和应用。",
      "tags": [
        "Diffusion Models",
        "Anomaly Synthesis",
        "Segmentation",
        "Accelerated Sampling",
        "Foreground-Aware"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:55.860290Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.19771",
    "title": "Frictional Q-Learning",
    "authors": [
      "Hyunwoo Kim",
      "Hyo Kyung Lee"
    ],
    "abstract": "Off-policy reinforcement learning suffers from extrapolation errors when a learned policy selects actions that are weakly supported in the replay buffer. In this study, we address this issue by drawing an analogy to static friction in classical mechanics. From this perspective, the replay buffer is represented as a smooth, low-dimensional action manifold, where the support directions correspond to the tangential component, while the normal component captures the dominant first-order extrapolation error. This decomposition reveals an intrinsic anisotropy in value sensitivity that naturally induces a stability condition analogous to a friction threshold. To mitigate deviations toward unsupported actions, we propose Frictional Q-Learning, an off-policy algorithm that encodes supported actions as tangent directions using a contrastive variational autoencoder. We further show that an orthonormal basis of the orthogonal complement corresponds to normal components under mild local isometry assumptions. Empirical results on standard continuous-control benchmarks demonstrate robust, stable performance compared with existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.19771.pdf",
    "abs_url": "https://arxiv.org/abs/2509.19771",
    "published": "2025-09-24T05:42:38Z",
    "updated": "2026-02-02T07:54:27Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出Frictional Q-Learning算法，通过类比经典力学中的静摩擦力，有效缓解离线强化学习中的外推误差问题。",
      "motivation": "离线强化学习在策略选择回放缓冲区中支持较弱的动作时，会产生外推误差，导致学习不稳定和性能下降。现有方法对此问题处理不足，影响了算法的鲁棒性和泛化能力。本研究旨在通过引入物理类比来解决这一关键挑战，提升离线强化学习的稳定性和可靠性，以应对实际应用中动作选择不确定性的问题。",
      "method": "论文提出Frictional Q-Learning算法，核心方法是将回放缓冲区建模为平滑的低维动作流形，将动作分解为切向（支持方向）和法向（外推误差）分量，并类比静摩擦力的阈值条件以稳定学习。使用对比变分自编码器编码支持的动作作为切向方向，并在局部等距假设下推导正交补基对应于法向分量，从而抑制非支持动作的偏差，实现稳健的策略更新。",
      "result": "在标准连续控制基准测试中，Frictional Q-Learning展示了比现有基线更稳健和稳定的性能。摘要未提供具体性能指标数据，但通过实验验证了算法在外推误差缓解方面的有效性，表明其在提升离线强化学习鲁棒性方面具有优势，有效减少了因动作外推导致的学习波动。",
      "conclusion": "本研究的主要贡献是提出Frictional Q-Learning算法，通过物理类比和流形分解减少外推误差，增强了离线强化学习的稳定性。学术上，为处理强化学习中的不确定性提供了新视角；实际应用中，可提高算法在连续控制任务中的可靠性。未来工作方向摘要未明确说明。",
      "tags": [
        "Off-policy Reinforcement Learning",
        "Q-Learning",
        "Contrastive Learning",
        "Variational Autoencoder",
        "Action Manifold"
      ]
    },
    "analyzed_at": "2026-02-03T03:59:39.841003Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15748",
    "title": "Hybrid Lie semi-group and cascade structures for the generalized Gaussian derivative model for visual receptive fields",
    "authors": [
      "Tony Lindeberg"
    ],
    "abstract": "Because of the variabilities of real-world image structures under the natural image transformations that arise when observing similar objects or spatio-temporal events under different viewing conditions, the receptive field responses computed in the earliest layers of the visual hierarchy may be strongly influenced by such geometric image transformations. One way of handling this variability is by basing the vision system on covariant receptive field families, which expand the receptive field shapes over the degrees of freedom in the image transformations.   This paper addresses the problem of deriving relationships between spatial and spatio-temporal receptive field responses obtained for different values of the shape parameters in the resulting multi-parameter families of receptive fields. For this purpose, we derive both (i) infinitesimal relationships, roughly corresponding to a combination of notions from semi-groups and Lie groups, as well as (ii) macroscopic cascade smoothing properties, which describe how receptive field responses at coarser spatial and temporal scales can be computed by applying smaller support incremental filters to the output from corresponding receptive fields at finer spatial and temporal scales, structurally related to the notion of Lie algebras, although with directional preferences.   The presented results provide (i) a deeper understanding of the relationships between spatial and spatio-temporal receptive field responses for different values of the filter parameters, which can be used for both (ii) designing more efficient schemes for computing receptive field responses over populations of multi-parameter families of receptive fields, as well as (iii)~formulating idealized theoretical models of the computations of simple cells in biological vision.",
    "categories": [
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2509.15748.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15748",
    "published": "2025-09-19T08:23:44Z",
    "updated": "2026-02-02T10:29:16Z",
    "comment": "27 pages, 9 figures",
    "light_analysis": {
      "overview": "本文结合半群、李群理论和级联结构，推导了广义高斯导数模型中视觉接收场响应的关系，以处理自然图像变换带来的变异性。",
      "motivation": "由于在不同观测条件下，自然图像变换（如几何变换）导致视觉层次中接收场响应变异性增加，影响视觉系统对相似对象的识别鲁棒性。现有方法中，接收场形状受几何变换影响大，效率低下，需要基于协变接收场家族扩展参数来处理变异性。因此，本研究动机是推导空间和时空接收场响应之间的关系，以解决这一实际问题，并为设计更高效的视觉模型提供理论基础。",
      "method": "本研究采用数学推导方法，提出了两种核心关系：一是微关系，结合了半群和李群的概念来描述接收场响应的变化；二是宏观级联平滑性质，解释如何通过应用小支持增量滤波器，从细尺度接收场响应计算粗尺度响应。该方法应用于广义高斯导数模型，利用多参数家族扩展接收场形状，涉及滤波器设计和结构优化，以处理图像变换的变异性。",
      "result": "论文推导了空间和时空接收场响应之间的关系，包括微关系和宏观级联性质，为理解接收场变异性提供了理论框架。这些结果可用于设计更高效的多参数家族计算方案，优化响应计算，但摘要未明确说明具体性能指标如准确率提升。与基线方法相比，该方法通过数学结构增强了对图像变换的鲁棒性，但缺乏实验数据支撑。",
      "conclusion": "本研究的主要贡献在于推导了视觉接收场响应的数学关系，结合半群、李群理论和级联结构，加深了对接收场计算的理解。这为设计高效视觉算法和生物视觉中简单细胞的理想化模型提供了理论基础。学术价值在于连接了数学理论与视觉模型，应用价值体现在改进视觉系统的鲁棒性。未来工作可能包括在实际数据上验证理论，并扩展到复杂视觉任务，但摘要未明确说明局限性。",
      "tags": [
        "Receptive Fields",
        "Lie Groups",
        "Semi-groups",
        "Cascade Structures",
        "Generalized Gaussian Derivative Model"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:05.369445Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15552",
    "title": "The Multi-Query Paradox in Zeroth-Order Optimization",
    "authors": [
      "Wei Lin",
      "Qingyu Song",
      "Hong Xu"
    ],
    "abstract": "Zeroth-order (ZO) optimization provides a powerful framework for problems where explicit gradients are unavailable and have to be approximated using only queries to function value. The prevalent single-query approach is simple, but suffers from high estimation variance, motivating a multi-query paradigm to improve estimation accuracy. This, however, creates a critical trade-off: under a fixed budget of queries (i.e. cost), queries per iteration and the total number of optimization iterations are inversely proportional to one another. How to best allocate this budget is a fundamental, under-explored question.   This work systematically resolves this query allocation problem. We analyze two aggregation methods: the de facto simple averaging (ZO-Avg), and a new Projection Alignment method (ZO-Align) we derive from local surrogate minimization. By deriving convergence rates for both methods that make the dependence on the number of queries explicit across strongly convex, convex, non-convex, and stochastic settings, we uncover a stark dichotomy: For ZO-Avg, we prove that using more than one query per iteration is always query-inefficient, rendering the single-query approach optimal. On the contrary, ZO-Align generally performs better with more queries per iteration, resulting in a full-subspace estimation as the optimal approach. Thus, our work clarifies that the multi-query problem boils down to a choice not about an intermediate query size, but between two classic algorithms, a choice dictated entirely by the aggregation method used. These theoretical findings are also consistently validated by extensive experiments.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2509.15552.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15552",
    "published": "2025-09-19T03:10:45Z",
    "updated": "2026-02-02T07:28:48Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文系统性地解决了零阶优化中的多查询悖论，通过理论分析揭示了聚合方法的选择决定了查询分配的最优策略。",
      "motivation": "零阶（ZO）优化在处理梯度不可用问题时，依赖于函数值查询来近似梯度，但现有单查询方法因高估计方差导致收敛效率低下。多查询方法虽能提升估计精度，却面临固定查询预算下查询次数与迭代次数的权衡问题。这一分配问题尚未充分探索，对于优化算法的实际应用至关重要，特别是在黑箱优化或计算成本高昂的领域。",
      "method": "本研究分析了两种聚合方法：基于简单平均的ZO-Avg和提出的新方法ZO-Align，后者从局部代理最小化中推导，旨在优化梯度估计的对齐。关键创新在于理论推导了收敛率，明确了对查询次数的依赖，覆盖了强凸、凸、非凸及随机优化设置。通过比较这些方法，阐明了聚合技术如何影响查询效率，为算法设计提供了理论基础。",
      "result": "理论分析显示，对于ZO-Avg，每次迭代使用多于一个查询总是查询效率低下的，单查询方法被证明为最优；而ZO-Align通常在更多查询下表现更佳，实现全子空间估计作为最优方法。这些发现通过大量实验得到验证，表明多查询问题本质上是聚合方法的选择问题。摘要未明确说明具体实验数据如准确率提升，但强调了理论与实验结果的一致性。",
      "conclusion": "本文的主要贡献在于澄清了零阶优化中的多查询悖论，通过理论分析和实验验证，证明了聚合方法的选择是查询分配的关键因素。研究具有重要学术价值，为优化算法设计提供了新视角；在实际应用中，可指导资源受限情况下的高效优化策略。局限性或未来工作摘要未明确说明，但可能涉及更复杂场景的扩展或其他聚合方法的探索。",
      "tags": [
        "Zeroth-Order Optimization",
        "Query Allocation",
        "Convergence Analysis",
        "Stochastic Optimization",
        "Gradient Estimation"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:34.887586Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2509.15048",
    "title": "MaiBERT: A Pre-training Corpus and Language Model for Low-Resourced Maithili Language",
    "authors": [
      "Sumit Yadav",
      "Raju Kumar Yadav",
      "Utsav Maskey",
      "Gautam Siddharth Kashyap",
      "Ganesh Gautam",
      "Usman Naseem"
    ],
    "abstract": "Natural Language Understanding (NLU) for low-resource languages remains a major challenge in NLP due to the scarcity of high-quality data and language-specific models. Maithili, despite being spoken by millions, lacks adequate computational resources, limiting its inclusion in digital and AI-driven applications. To address this gap, we introducemaiBERT, a BERT-based language model pre-trained specifically for Maithili using the Masked Language Modeling (MLM) technique. Our model is trained on a newly constructed Maithili corpus and evaluated through a news classification task. In our experiments, maiBERT achieved an accuracy of 87.02%, outperforming existing regional models like NepBERTa and HindiBERT, with a 0.13% overall accuracy gain and 5-7% improvement across various classes. We have open-sourced maiBERT on Hugging Face enabling further fine-tuning for downstream tasks such as sentiment analysis and Named Entity Recognition (NER).",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2509.15048.pdf",
    "abs_url": "https://arxiv.org/abs/2509.15048",
    "published": "2025-09-18T15:11:18Z",
    "updated": "2026-02-02T12:45:15Z",
    "comment": "Accepted at EACL LoResLM 2026",
    "light_analysis": {
      "overview": "本文提出了MaiBERT，一个针对低资源Maithili语言的BERT预训练模型和语料库，有效提升了新闻分类性能。",
      "motivation": "本研究旨在解决低资源语言Maithili在自然语言理解（NLU）中的挑战，由于高质量数据和语言特定模型的稀缺，Maithili难以融入数字和AI应用。Maithili有数百万使用者，但缺乏计算资源，导致现有区域模型无法有效适配，限制了其实际应用，突显了解决该问题的重要性。",
      "method": "本研究提出MaiBERT，这是一个基于BERT架构的语言模型，采用掩码语言建模（MLM）技术进行预训练。关键创新在于专门构建了一个新的Maithili语料库，用于模型训练，并通过新闻分类任务评估模型性能。方法强调针对低资源语言的定制化解决方案。",
      "result": "实验结果显示，MaiBERT在新闻分类任务上达到87.02%的准确率，优于现有区域模型如NepBERTa和HindiBERT。具体表现为整体准确率提升0.13%，各类别提升5-7%，证明了模型在Maithili语言上的有效性和优越性能。",
      "conclusion": "本研究的贡献在于开发并开源了专门针对Maithili的MaiBERT模型和预训练语料库，为低资源语言处理提供了方法支持，促进了Maithili在AI应用中的集成。学术价值在于推进了语言特定模型的研究，实际应用潜力包括扩展至情感分析和NER等下游任务。",
      "tags": [
        "Maithili Language",
        "BERT",
        "Masked Language Modeling",
        "Corpus Construction",
        "Open-Source"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:30.799703Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.17649",
    "title": "Longitudinal Progression Prediction of Alzheimer's Disease with Tabular Foundation Model",
    "authors": [
      "Yilang Ding",
      "Jiawen Ren",
      "Jiaying Lu",
      "Gloria Hyunjung Kwak",
      "Armin Iraji",
      "Shengpu Tang",
      "Alex Fedorov"
    ],
    "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that remains challenging to predict due to its multifactorial etiology and the complexity of multimodal clinical data. Accurate forecasting of clinically relevant biomarkers, including diagnostic and quantitative measures, is essential for effective monitoring of disease progression. This work introduces L2C-TabPFN, a method that integrates a longitudinal-to-cross-sectional (L2C) transformation with a pre-trained Tabular Foundation Model (TabPFN) to predict Alzheimer's disease outcomes using the TADPOLE dataset. L2C-TabPFN converts sequential patient records into fixed-length feature vectors, enabling robust prediction of diagnosis, cognitive scores, and ventricular volume. Experimental results demonstrate that, while L2C-TabPFN achieves competitive performance on diagnostic and cognitive outcomes, it provides state-of-the-art results in ventricular volume prediction. This key imaging biomarker reflects neurodegeneration and progression in Alzheimer's disease. These findings highlight the potential of tabular foundational models for advancing longitudinal prediction of clinically relevant imaging markers in Alzheimer's disease.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.17649.pdf",
    "abs_url": "https://arxiv.org/abs/2508.17649",
    "published": "2025-08-25T04:24:51Z",
    "updated": "2026-02-02T03:43:44Z",
    "comment": "preprint",
    "light_analysis": {
      "overview": "提出L2C-TabPFN方法，通过整合纵向到横截面变换和预训练表格基础模型，实现阿尔茨海默病的纵向进展预测，并在脑室体积预测上达到最优性能。",
      "motivation": "阿尔茨海默病是一种进行性神经退行性疾病，由于其多因素病因和多模态临床数据的复杂性，预测疾病进展具有挑战性。准确预测临床相关生物标志物，如诊断结果和定量指标，对疾病监测至关重要。摘要未明确说明现有方法的不足，但可推断当前方法在处理纵向序列数据和多模态整合方面存在困难，需要更有效的预测模型来提升准确性和临床实用性。",
      "method": "本研究提出L2C-TabPFN方法，结合纵向到横截面（L2C）变换和预训练的表格基础模型（TabPFN）。L2C变换将序列患者记录转换为固定长度特征向量，使用TADPOLE数据集来预测诊断、认知评分和脑室体积。关键创新在于处理纵向数据，通过预训练模型优化特征提取，提升预测鲁棒性，特别适用于多模态临床数据分析。",
      "result": "实验结果显示，L2C-TabPFN在诊断和认知结果预测上具有竞争性性能，而在脑室体积预测方面达到了最佳水平。脑室体积是关键成像生物标志物，能反映神经退行和疾病进展。该方法在临床相关成像标志物预测上优于基线方法，突出了其在纵向预测任务中的有效性，摘要未提供具体数据指标。",
      "conclusion": "本研究验证了L2C-TabPFN方法在阿尔茨海默病纵向预测中的有效性，展示了表格基础模型在临床相关成像标志物预测上的潜力。学术价值在于推动多模态数据处理和纵向预测模型的发展，实际应用有助于改进疾病监测和临床决策支持。未来工作方向摘要未明确说明，可能包括扩展到其他疾病或优化模型架构。",
      "tags": [
        "Longitudinal Prediction",
        "Tabular Foundation Model",
        "Alzheimer's Disease",
        "Imaging Biomarker",
        "L2C Transformation"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:24.044003Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.16929",
    "title": "Dimensional Collapse in Transformer Attention Outputs: A Challenge for Sparse Dictionary Learning",
    "authors": [
      "Junxuan Wang",
      "Xuyang Ge",
      "Wentao Shu",
      "Zhengfu He",
      "Xipeng Qiu"
    ],
    "abstract": "Transformer architectures, and their attention mechanisms in particular, form the foundation of modern large language models. While transformer models are widely believed to operate in high-dimensional hidden spaces, we show that attention outputs are in fact confined to a surprisingly low-dimensional subspace, with an effective dimensionality of only about $60\\%$ of the full space. In contrast, MLP outputs and residual streams remain much closer to full-rank, exhibiting effective ranks around $90\\%$. This striking dimensional discrepancy is consistently observed across diverse model families and datasets, and is strongly shaped by the attention output projection matrix. Critically, we find this low-rank structure as a key factor of the prevalent dead feature problem in sparse dictionary learning, where it creates a mismatch between randomly initialized features and the intrinsic geometry of the activation space. Building on this insight, we propose a subspace-constrained training method for sparse autoencoders (SAEs), initializing feature directions into the active subspace of activations. Our approach reduces dead features from 87\\% to below 1\\% in Attention Output SAEs with 1M features, and can further extend to other sparse dictionary learning methods. Our findings provide both new insights into the geometry of attention and practical tools for improving sparse dictionary learning in large language models.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.16929.pdf",
    "abs_url": "https://arxiv.org/abs/2508.16929",
    "published": "2025-08-23T07:27:00Z",
    "updated": "2026-02-02T09:46:23Z",
    "comment": "27 pages, 16 figures",
    "light_analysis": {
      "overview": "本文揭示Transformer注意力输出存在低维崩溃现象，并提出子空间约束训练方法以优化稀疏字典学习中的死特征问题。",
      "motivation": "本研究旨在解决稀疏字典学习在大语言模型中普遍存在的死特征问题，即许多随机初始化的特征无法激活，导致学习效率低下。这一问题的重要性在于，它阻碍了模型的可解释性和优化，现有方法由于特征初始化与注意力输出的低维子空间几何不匹配而效果有限。因此，探索注意力输出的内在结构以改进稀疏字典学习方法具有关键意义。",
      "method": "基于对Transformer注意力输出低维结构的发现，论文提出一种子空间约束训练方法。该方法将稀疏自编码器的特征方向初始化到激活的活跃子空间中，而非传统随机初始化，关键创新在于利用注意力输出投影矩阵的分析来引导训练。使用注意力输出稀疏自编码器作为案例，通过实验验证该方法在不同模型家族和数据集上的适用性。",
      "result": "实验结果显示，在具有100万个特征的注意力输出稀疏自编码器中，死特征比例从87%显著降低到低于1%，大幅提升了特征激活率。与基线方法相比，该改进在多个模型和数据集上保持一致鲁棒性。此外，该方法可扩展到其他稀疏字典学习方法，证明了其泛化能力和实用性。",
      "conclusion": "本研究提供了对Transformer注意力几何结构的新见解，并提出了一种有效工具来改进稀疏字典学习。其学术价值在于深化了对大语言模型内部工作机制的理解，实际应用价值在于促进模型解释性和可解释AI的发展。未来工作可探索该方法在其他模型组件中的扩展应用。",
      "tags": [
        "Transformer Attention",
        "Low-Rank Structure",
        "Sparse Dictionary Learning",
        "Sparse Autoencoder",
        "Subspace Constraint"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:23.732099Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.12685",
    "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction",
    "authors": [
      "Xingshan Zeng",
      "Weiwen Liu",
      "Lingzhi Wang",
      "Liangyou Li",
      "Fei Mi",
      "Yasheng Wang",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "abstract": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn, multi-step interactions, often involving complex function calls and dynamic user-agent exchanges. Existing simulation-based data generation methods for such scenarios rely heavily on costly autoregressive interactions between multiple LLM agents, thereby limiting real-world performance of agentic tasks. In this paper, we propose ToolACE-MT, a novel Non-Autoregressive Iterative Generation framework for constructing high-quality multi-turn agentic dialogues. ToolACE-MT generates full conversational trajectories through three stages: coarse-grained initialization, iterative refinement, and offline verification. The initialization phase builds a structurally complete yet semantically coarse dialogue skeleton; the iterative refinement phase introduces realistic complexities and continued refinement via mask-and-fill operations; and the offline verification phase ensures correctness and coherence via rule- and model-based checks. Experiments demonstrate that ToolACE-MT enables efficient, effective and generalizable agentic data generation, offering a new paradigm for high-quality data construction in tool-augmented LLM scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.12685.pdf",
    "abs_url": "https://arxiv.org/abs/2508.12685",
    "published": "2025-08-18T07:38:23Z",
    "updated": "2026-02-02T03:37:29Z",
    "comment": "Accepted by ICLR2026",
    "light_analysis": {
      "overview": "ToolACE-MT框架通过非自回归迭代生成，高效构建高质量多轮代理对话数据，为工具增强的LLM场景提供新范式。",
      "motivation": "基于大型语言模型的代理任务解决需要多轮、多步交互，涉及复杂的函数调用和动态用户-代理交换。现有基于模拟的数据生成方法严重依赖成本高昂的自回归交互，这限制了代理任务的实际性能和可扩展性。因此，研究如何高效生成高质量的多轮代理对话数据至关重要，以克服现有方法在效率和数据质量方面的不足，推动代理系统的实际部署。",
      "method": "本文提出了ToolACE-MT，一种非自回归迭代生成框架，包含三个阶段：粗粒度初始化阶段构建结构完整但语义粗略的对话骨架；迭代细化阶段通过mask-and-fill操作引入现实复杂性并持续优化对话内容；离线验证阶段利用基于规则和模型的检查确保对话的正确性和一致性。该方法的关键创新在于减少对自回归交互的依赖，提高数据生成效率，适用于工具增强的LLM场景。",
      "result": "实验表明ToolACE-MT能够实现高效、有效和可泛化的代理数据生成，提供了一种新的高质量数据构建范式。与现有自回归方法相比，该框架在工具增强的LLM场景中展现出优越的性能，显著提升了数据构造的速度和准确性。摘要未明确说明具体性能指标如准确率提升，但强调了其广泛适用性和改进效果，支持更高效的代理任务应用。",
      "conclusion": "ToolACE-MT的主要贡献是提出了一种非自回归迭代生成框架，为工具增强的大型语言模型场景中的高质量数据构建提供了新范式。这具有重要的学术价值，推动了非自回归技术在代理任务中的研究；同时，实际应用价值在于提高数据生成效率，支持更有效的代理系统开发和部署。未来工作可探索其在更多复杂交互场景中的扩展性和泛化能力，摘要未明确说明具体局限性。",
      "tags": [
        "Non-Autoregressive Generation",
        "Agentic Multi-Turn Interaction",
        "Tool-Augmented LLMs",
        "Iterative Refinement",
        "Mask-and-Fill Operations"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:47.109968Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.12596",
    "title": "Constructing 3D Rotational Invariance and Equivariance with Symmetric Tensor Networks",
    "authors": [
      "Meng Zhang",
      "Chao Wang",
      "Hao Zhang",
      "Shaojun Dong",
      "Lixin He"
    ],
    "abstract": "Symmetry-aware architectures are central to geometric deep learning. We present a systematic approach for constructing continuous rotationally invariant and equivariant functions using symmetric tensor networks. The proposed framework supports inputs and outputs given as a tuple of Cartesian tensors of different rank as well as spherical tensors of different type. We introduce tensor network generators for invariant maps and obtain equivariant maps via differentiation. Specifically, we derive general continuous equivariant maps from vector inputs to Cartesian or spherical tensor output. Finally, we clarify how common equivariant primitives in geometric graph neural networks arise within our construction.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.12596.pdf",
    "abs_url": "https://arxiv.org/abs/2508.12596",
    "published": "2025-08-18T03:13:08Z",
    "updated": "2026-02-02T03:28:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "提出了一种基于对称张量网络的系统方法，用于构建连续旋转不变和等变函数，支持多种张量类型。",
      "motivation": "几何深度学习依赖于对称感知架构，但现有方法在构建连续旋转不变和等变函数时可能缺乏系统性，特别是在处理不同秩的Cartesian张量和spherical张量时，这限制了模型的表达能力和通用性。本研究旨在提供一个统一框架，以解决这些限制，促进对称性处理在深度学习中的标准化应用。",
      "method": "该方法使用对称张量网络构建连续旋转不变和等变函数，框架支持输入输出为不同秩的Cartesian张量和不同类型spherical张量的元组。核心创新包括引入张量网络生成器用于不变映射，并通过微分技术获得等变映射，具体推导了从向量输入到Cartesian或spherical张量输出的连续等变映射，从而系统化了构建过程。",
      "result": "摘要未明确说明具体实验数据，但基于框架描述，该框架能够构建连续旋转不变和等变函数，并解释了几何图神经网络中常见等变原语如何从该构造中产生，表明其在理论上的有效性和通用性，未来可能通过实验验证性能提升。",
      "conclusion": "本研究的主要贡献是提供了一个基于对称张量网络的系统框架，用于构建连续旋转不变和等变函数，支持多种张量类型并通过微分连接不变和等变映射。学术上，增强了对称感知架构的理论基础；应用上，为几何图神经网络的设计提供了新工具，未来可扩展处理更复杂对称性问题。",
      "tags": [
        "Symmetric Tensor Networks",
        "Rotational Invariance",
        "Rotational Equivariance",
        "Geometric Deep Learning",
        "Tensor Networks"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:43.274135Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.08688",
    "title": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision",
    "authors": [
      "Chen Li",
      "Han Zhang",
      "Zhantao Yang",
      "Fangyi Chen",
      "Zihan Wang",
      "Anudeepsekhar Bolimera",
      "Marios Savvides"
    ],
    "abstract": "Vision-language models (VLMs) have made significant strides in reasoning, yet they often struggle with complex multimodal tasks and tend to generate overly verbose outputs. A key limitation is their reliance on chain-of-thought (CoT) reasoning, despite many tasks benefiting from alternative topologies like trees or graphs. To address this, we introduce STELAR-Vision, a training framework for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline that enriches training with diverse topological structures. Using supervised fine-tuning and reinforcement learning, we post-train Qwen2VL models with both accuracy and efficiency in mind. Additionally, we propose Frugal Learning, which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H, STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it outperforms Phi-4-Multimodal-Instruct by up to 28.4% and LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong generalization. Compared to Chain-Only training, our approach achieves 4.3% higher overall accuracy on in-distribution datasets and consistently outperforms across all OOD benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2508.08688.pdf",
    "abs_url": "https://arxiv.org/abs/2508.08688",
    "published": "2025-08-12T07:27:50Z",
    "updated": "2026-02-02T05:52:55Z",
    "comment": "This paper has been accepted at AAAI 2026. This is the author's extended version. The final version will appear in the official proceedings",
    "light_analysis": {
      "overview": "STELAR-Vision框架通过拓扑感知推理和高效学习，显著提升视觉语言模型的准确性和效率。",
      "motivation": "视觉语言模型（VLMs）在复杂多模态推理任务中面临挑战，常常生成冗长输出，且过度依赖链式思维（CoT）推理。然而，许多任务（如图像推理或视觉问答）可能更适合树状或图状拓扑结构，现有方法未能充分利用这些结构，导致推理效率低下和准确率受限。因此，研究旨在解决这些问题，通过拓扑感知推理优化VLM性能，提升其在真实场景中的适用性。",
      "method": "论文提出STELAR-Vision训练框架，核心是TopoAug合成数据管道，通过生成具有树状或图状拓扑结构的数据，丰富训练集。采用监督微调和强化学习相结合的后训练策略，对Qwen2VL模型进行优化，平衡准确性和效率。此外，引入Frugal Learning技术，旨在最小化准确率损失的同时压缩输出长度，进一步提升模型效率，使模型能适应多种推理拓扑。",
      "result": "在MATH-V和VLM-S2H数据集上，STELAR-Vision相比基础模型准确率提升了9.7%，并超过了更大的Qwen2VL-72B-Instruct模型7.3%。在五个分布外基准测试中，性能显著优于Phi-4-Multimodal-Instruct（最高提升28.4%）和LLaMA-3.2-11B-Vision-Instruct（最高提升13.2%）。与仅使用链式思维训练的方法相比，本方法在分布内数据集上准确率高4.3%，并在所有OOD基准上均表现出更好的泛化能力。",
      "conclusion": "本论文贡献了STELAR-Vision框架，通过拓扑感知推理和高效学习，有效提升了视觉语言模型在复杂任务中的性能。TopoAug和Frugal Learning的创新应用，为解决VLM推理中的效率问题提供了新途径。研究具有重要学术价值，推动了多模态推理技术的发展，并具有实际应用潜力，如智能助手和视觉分析系统。未来工作可探索更多拓扑结构或扩展到其他VLM模型，摘要未明确说明局限性。",
      "tags": [
        "Vision-Language Models",
        "Topology-Aware Reasoning",
        "Reinforcement Learning",
        "Frugal Learning",
        "Supervised Fine-Tuning"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:21.921568Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.08540",
    "title": "Biased Local SGD for Efficient Deep Learning on Heterogeneous Systems",
    "authors": [
      "Jihyun Lim",
      "Junhyuk Jo",
      "Chanhyeok Ko",
      "Young Min Go",
      "Jimin Hwa",
      "Sunwoo Lee"
    ],
    "abstract": "Most parallel neural network training methods assume homogeneous computing resources. For example, synchronous data-parallel SGD suffers from significant synchronization overhead under heterogeneous workloads, often forcing practitioners to rely only on the fastest devices (e.g., GPUs). In this work, we study local SGD for efficient parallel training on heterogeneous systems. We show that intentionally introducing bias in data sampling and model aggregation can effectively harmonize slower CPUs with faster GPUs. Our extensive empirical results demonstrate that a carefully controlled bias significantly accelerates local SGD while achieving comparable or even higher accuracy than synchronous SGD under the same epoch budget. For instance, our method trains ResNet20 on CIFAR-10 with 2 CPUs and 8 GPUs up to 32x faster than synchronous SGD, with nearly identical accuracy. These results provide practical insights into how to flexibly utilize diverse compute resources for deep learning.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.08540.pdf",
    "abs_url": "https://arxiv.org/abs/2508.08540",
    "published": "2025-08-12T01:03:09Z",
    "updated": "2026-02-02T08:35:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了一种引入偏见的本地SGD方法，用于在异构计算系统中高效训练深度学习模型，解决同步开销问题。",
      "motivation": "该研究的动机源于实际应用中并行神经网络训练常面临异构计算资源问题。现有方法如同步数据并行SGD假设同质资源，但在异构环境（如混合使用CPU和GPU）下，同步等待导致显著开销，迫使从业者仅依赖最快设备，浪费资源且降低效率。这个问题限制了深度学习训练的可扩展性和灵活性，因此需要新方法来协调不同速度设备，优化整体性能。摘要未明确说明更广泛的背景细节。",
      "method": "论文的核心方法是基于本地SGD，通过有意引入偏见来优化数据采样和模型聚合过程。具体技术包括设计有偏见的数据分布策略，以平衡慢速CPU和快速GPU之间的工作负载，确保在本地训练阶段减少同步需求。关键创新点在于控制偏见程度，以协调异构设备，无需假设同质资源。使用ResNet20和CIFAR-10数据集进行实验，但摘要未明确说明更详细的模型架构或算法细节。",
      "result": "论文的主要实验结果显示，在CIFAR-10数据集上使用ResNet20模型，配置为2个CPU和8个GPU时，该方法比同步SGD快达32倍，同时准确率几乎相同（如接近基准值）。这表明在相同训练周期预算下，偏见本地SGD能显著提升训练效率，而不牺牲模型精度。与基线方法同步SGD相比，该方法有效解决了同步开销问题，提高了资源利用率，实证支持了其有效性。",
      "conclusion": "该研究的结论是，偏见本地SGD能有效利用异构计算资源，提高并行训练效率。其学术贡献在于改进了本地SGD在异构系统下的应用，解决了同步瓶颈；实际应用价值为深度学习训练提供了灵活、高效的资源调度策略。未来工作可能包括扩展到更大规模模型和更复杂数据集，或探索不同偏见机制的优化。摘要未明确说明局限性。",
      "tags": [
        "Local SGD",
        "Heterogeneous Systems",
        "Bias Introduction",
        "Data Sampling",
        "Model Aggregation"
      ]
    },
    "analyzed_at": "2026-02-03T04:00:52.440265Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.09198",
    "title": "SACO: Sequence-Aware Constrained Optimization Framework for Coupon Distribution in E-commerce",
    "authors": [
      "Li Kong",
      "Bingzhe Wang",
      "Zhou Chen",
      "Suhan Hu",
      "Yuchao Ma",
      "Qi Qi",
      "Suoyuan Song",
      "Bicheng Jin"
    ],
    "abstract": "Coupon distribution is a critical marketing strategy used by online platforms to boost revenue and enhance user engagement. Regrettably, existing coupon distribution strategies fall far short of effectively leveraging the complex sequential interactions between platforms and users. This critical oversight, despite the abundance of e-commerce log data, has precipitated a performance plateau. In this paper, we focus on the scene that the platforms make sequential coupon distribution decision multiple times for various users, with each user interacting with the platform repeatedly. Based on this scenario, we propose a novel marketing framework, named \\textbf{S}equence-\\textbf{A}ware \\textbf{C}onstrained \\textbf{O}ptimization (SACO) framework, to directly devise coupon distribution policy for long-term revenue boosting. SACO framework enables optimized online decision-making in a variety of real-world marketing scenarios. It achieves this by seamlessly integrating three key characteristics, general scenarios, sequential modeling with more comprehensive historical data, and efficient iterative updates within a unified framework. Furthermore, empirical results on real-world industrial dataset, alongside public and synthetic datasets demonstrate the superiority of our framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.09198.pdf",
    "abs_url": "https://arxiv.org/abs/2508.09198",
    "published": "2025-08-08T13:03:17Z",
    "updated": "2026-02-02T09:25:16Z",
    "comment": null,
    "light_analysis": {
      "overview": "SACO框架通过整合序列建模和约束优化，为电商优惠券分发提供长期收益提升的决策策略。",
      "motivation": "优惠券分发是电商平台提升收益和用户参与度的关键营销手段，但现有策略未能有效利用平台与用户之间的复杂序列交互，导致性能瓶颈。尽管有丰富的电商日志数据，当前方法仍无法充分挖掘序列依赖性，限制了长期收益的优化潜力。因此，研究旨在解决序列感知的优惠券分发问题，以突破现有方法的局限，提升营销策略的长期效果。",
      "method": "论文提出序列感知约束优化框架（SACO），通过整合通用场景适应性、基于更全面历史数据的序列建模和高效迭代更新，直接设计长期收益最大化的优惠券分发策略。该框架支持在线决策，能适应各种真实营销场景，但摘要未明确说明具体模型架构或算法细节，如是否使用强化学习或其他机器学习技术。",
      "result": "实证结果基于真实工业数据集、公共数据集和合成数据集，展示了SACO框架的优越性能，但摘要未提供具体数据如收益提升百分比或与基线方法的详细对比。因此，结果主要表明框架在多个数据集上的有效性，具体指标如准确率或效率改进需参考完整论文，摘要未明确说明。",
      "conclusion": "SACO框架的主要贡献在于将序列感知与约束优化相结合，为电商优惠券分发提供了创新的长期优化方案。其学术价值在于推进了序列决策在营销自动化中的应用，实际应用价值在于提升平台收益和用户参与度。未来工作可能涉及扩展框架到其他营销策略或处理动态约束，但摘要未明确说明局限性或具体方向。",
      "tags": [
        "Coupon Distribution",
        "Sequence Modeling",
        "Constrained Optimization",
        "E-commerce",
        "Online Decision-Making"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:19.383809Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.02426",
    "title": "Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding",
    "authors": [
      "Linyu Li",
      "Zhi Jin",
      "Yuanpeng He",
      "Dongming Jin",
      "Yichi Zhang",
      "Haoran Duan",
      "Xuan Zhang",
      "Zhengwei Tao",
      "Nyima Tash"
    ],
    "abstract": "As social media and the World Wide Web become hubs for information dissemination, effectively organizing and understanding the vast amounts of dynamically evolving Web content is crucial. Knowledge graphs (KGs) provide a powerful framework for structuring this information. However, the rapid emergence of new hot topics, user relationships, and events in social media renders traditional static knowledge graph embedding (KGE) models rapidly outdated. Continual Knowledge Graph Embedding (CKGE) aims to address this issue, but existing methods commonly suffer from catastrophic forgetting, whereby older, but still valuable, information is lost when learning new knowledge (such as new memes or trending events). This means the model cannot effectively learn the evolution of the data. We propose a novel CKGE framework, BAKE. Unlike existing methods, BAKE formulates CKGE as a sequential Bayesian inference problem and utilizes the Bayesian posterior update principle as a natural continual learning strategy. This principle is insensitive to data order and provides theoretical guarantees to preserve prior knowledge as much as possible. Specifically, we treat each batch of new data as a Bayesian update to the model's prior. By maintaining the posterior distribution, the model effectively preserves earlier knowledge even as it evolves over multiple snapshots. Furthermore, to constrain the evolution of knowledge across snapshots, we introduce a continual clustering method that maintains the compact cluster structure of entity embeddings through a regularization term, ensuring semantic consistency while allowing controlled adaptation to new knowledge. We conduct extensive experiments on multiple CKGE benchmarks, which demonstrate that BAKE achieves the top performance in the vast majority of cases compared to existing approaches.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2508.02426.pdf",
    "abs_url": "https://arxiv.org/abs/2508.02426",
    "published": "2025-08-04T13:46:33Z",
    "updated": "2026-02-02T09:12:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了BAKE框架，一个基于贝叶斯推理的持续知识图嵌入方法，有效解决灾难性遗忘问题。",
      "motivation": "随着社交媒体和网络信息爆炸，知识图成为组织动态内容的关键工具，但传统静态知识图嵌入模型无法适应快速演变的新话题和事件，导致过时。持续知识图嵌入旨在处理这一挑战，然而现有方法普遍面临灾难性遗忘问题，即在学习新知识（如新迷因或热门事件）时丢失了仍具价值的旧信息，从而无法有效学习数据的演化过程，这限制了模型在动态环境中的实际应用。",
      "method": "BAKE框架将持续知识图嵌入重新定义为顺序贝叶斯推理问题，利用贝叶斯后验更新原理作为自然的持续学习策略，这一方法不依赖于数据顺序，并理论上保证尽可能保留先验知识。具体来说，我们将每批新数据视为对模型先验的贝叶斯更新，通过维护后验分布来有效保存早期知识。此外，引入了持续聚类方法，通过正则化项保持实体嵌入的紧凑簇结构，在允许适应新知识的同时确保语义一致性。",
      "result": "我们在多个持续知识图嵌入基准上进行了广泛实验。结果表明，BAKE在绝大多数情况下均达到了最佳性能，与现有方法相比，有效缓解了灾难性遗忘问题，并平衡了新知识的融入和旧知识的保留。摘要未提供具体准确率数据，但实验验证了其在动态知识图嵌入任务中的优越性，展示了模型鲁棒性和适应性。",
      "conclusion": "本文的主要贡献是提出了基于贝叶斯推理的持续知识图嵌入框架BAKE，通过顺序贝叶斯更新和聚类正则化，有效解决了灾难性遗忘问题。该研究提供了理论保证来保留先验知识，并具有实际应用价值，适用于社交媒体等动态环境中的知识图演化。未来工作可能包括扩展到更大规模数据集或结合其他持续学习技术。",
      "tags": [
        "Continual Knowledge Graph Embedding",
        "Bayesian Inference",
        "Clustering",
        "Regularization",
        "Knowledge Graph Embedding"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:18.862370Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2508.02741",
    "title": "DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening",
    "authors": [
      "Zhixiang Lu",
      "Yulong Li",
      "Feilong Tang",
      "Zhengyong Jiang",
      "Chong Li",
      "Mian Zhou",
      "Tenglong Li",
      "Jionglong Su"
    ],
    "abstract": "Large-scale tuberculosis (TB) screening is limited by the high cost and operational complexity of traditional diagnostics, creating a need for artificial-intelligence solutions. We propose DeepGB-TB, a non-invasive system that instantly assigns TB risk scores using only cough audio and basic demographic data. The model couples a lightweight one-dimensional convolutional neural network for audio processing with a gradient-boosted decision tree for tabular features. Its principal innovation is a Cross-Modal Bidirectional Cross-Attention module (CM-BCA) that iteratively exchanges salient cues between modalities, emulating the way clinicians integrate symptoms and risk factors. To meet the clinical priority of minimizing missed cases, we design a Tuberculosis Risk-Balanced Loss (TRBL) that places stronger penalties on false-negative predictions, thereby reducing high-risk misclassifications. DeepGB-TB is evaluated on a diverse dataset of 1,105 patients collected across seven countries, achieving an AUROC of 0.903 and an F1-score of 0.851, representing a new state of the art. Its computational efficiency enables real-time, offline inference directly on common mobile devices, making it ideal for low-resource settings. Importantly, the system produces clinically validated explanations that promote trust and adoption by frontline health workers. By coupling AI innovation with public-health requirements for speed, affordability, and reliability, DeepGB-TB offers a tool for advancing global TB control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2508.02741.pdf",
    "abs_url": "https://arxiv.org/abs/2508.02741",
    "published": "2025-08-02T14:11:07Z",
    "updated": "2026-02-02T11:44:43Z",
    "comment": "Accepted by AAAI 2026 (oral)",
    "light_analysis": {
      "overview": "提出了DeepGB-TB系统，通过结合跨模态双向交叉注意力和风险平衡损失，实现快速、可解释的结核病筛查。",
      "motivation": "结核病大规模筛查因传统诊断方法的高成本和操作复杂性而受限，导致低资源地区难以有效开展。现有AI解决方案在整合多模态数据和优先减少漏诊方面不足，无法满足快速、廉价、可靠的公共卫生需求。本研究旨在开发一种非侵入性系统，利用咳嗽音频和基础人口数据，以应对全球结核病控制的挑战，提升筛查的普及性和效率。",
      "method": "DeepGB-TB模型耦合了轻量级一维卷积神经网络处理音频和梯度提升决策树处理表格特征。其核心创新是跨模态双向交叉注意力模块，模拟临床医生整合信息的方式，迭代交换模态间的关键线索。此外，设计了结核病风险平衡损失函数，通过加强假阴性惩罚来减少高风险误分类。模型基于七个国家收集的1,105名患者数据集构建，确保多样性和代表性。",
      "result": "在1,105名患者的多样化数据集上评估，DeepGB-TB实现了AUROC为0.903和F1得分为0.851，达到新状态，表明在降低假阴性方面优于基线方法。系统计算效率高，支持实时离线推理，可直接部署在普通移动设备上，适合低资源环境应用，展示了卓越的性能和实用性。",
      "conclusion": "DeepGB-TB通过技术创新如跨模态注意力和风险平衡损失，提供了一个高效、可解释的结核病筛查工具，具有重要学术和实际价值。它结合AI与公共卫生需求，提高了筛查速度、可靠性和可负担性，有望促进全球结核病控制。未来工作可扩展应用到其他疾病或优化多模态整合。",
      "tags": [
        "Cross-Modal Attention",
        "Gradient Boosted Decision Tree",
        "1D Convolutional Neural Network",
        "Risk-Balanced Loss",
        "Tuberculosis Screening"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:41.471860Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.18220",
    "title": "Sparse identification of nonlinear dynamics with library optimization mechanism: Recursive long-term prediction perspective",
    "authors": [
      "Ansei Yonezawa",
      "Heisei Yonezawa",
      "Shuichi Yahagi",
      "Itsuro Kajiwara",
      "Shinya Kijimoto",
      "Hikaru Taniuchi",
      "Kentaro Murakami"
    ],
    "abstract": "The sparse identification of nonlinear dynamics (SINDy) approach can discover the governing equations of dynamical systems based on measurement data, where the dynamical model is identified as the sparse linear combination of the given basis functions. A major challenge in SINDy is the design of a library, which is a set of candidate basis functions, as the appropriate library is not trivial for many dynamical systems. To overcome this difficulty, this study proposes SINDy with library optimization mechanism (SINDy-LOM), which is a combination of the sparse regression technique and the novel learning strategy of the library. In the proposed approach, the basis functions are parametrized. The SINDy-LOM approach involves a two-layer optimization architecture: the inner-layer, in which the data-driven model is extracted as the sparse linear combination of the candidate basis functions, and the outer-layer, in which the basis functions are optimized from the viewpoint of the recursive long-term (RLT) prediction accuracy; thus, the library design is reformulated as the optimization of the parametrized basis functions. The dynamical model obtained by SINDy-LOM has good interpretability and usability, as this approach yields a parsimonious closed-form model. The library optimization mechanism significantly reduces user burden. The RLT perspective improves the reliability of the resulting model compared with the traditional SINDy approach that can only ensure the one-step-ahead prediction accuracy. The effectiveness of the proposed approach is verified through numerical experiments.",
    "categories": [
      "cs.LG",
      "math.DS"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.18220.pdf",
    "abs_url": "https://arxiv.org/abs/2507.18220",
    "published": "2025-07-24T09:15:26Z",
    "updated": "2026-02-02T07:15:21Z",
    "comment": "Published in IEEE Transactions on Cybernetics (https://ieeexplore.ieee.org/document/11365958)",
    "light_analysis": {
      "overview": "该论文提出了SINDy-LOM方法，通过优化参数化基函数库来提高非线性动力系统识别的递归长期预测精度。",
      "motivation": "SINDy方法用于从测量数据中发现动力系统的控制方程，但库设计是一个主要挑战，因为合适的基函数库对许多系统来说不易确定。传统SINDy方法只能确保一步预测精度，而递归长期预测对实际应用更重要，但现有方法依赖用户手动设计库，增加了负担并可能影响模型可靠性和实用性。因此，需要一种自动化优化库的方法来提升长期预测能力。",
      "method": "SINDy-LOM方法结合稀疏回归技术和新的库学习策略，将基函数参数化，并采用两层优化架构：内层使用稀疏回归从候选基函数中提取稀疏线性组合模型；外层从递归长期预测精度的角度优化基函数参数。这样，库设计被重新表述为参数化基函数的优化问题，关键创新在于自动调整库以提高长期预测性能。",
      "result": "摘要未明确说明具体实验结果和数据，但提到通过数值实验验证了SINDy-LOM的有效性。与传统的SINDy方法相比，该方法在递归长期预测精度上表现出改进，提高了模型的可靠性，尽管未提供详细性能指标如准确率提升或效率改进。",
      "conclusion": "SINDy-LOM的主要贡献在于通过库优化机制得到具有良好可解释性和可用性的简洁闭式模型，减少了用户负担并增强了长期预测可靠性。该研究对动力系统建模有学术价值，推动了数据驱动方法的发展，实际应用价值在于降低用户门槛和提高预测准确性。未来工作可能涉及扩展到更复杂系统或优化算法的改进。",
      "tags": [
        "Sparse Identification of Nonlinear Dynamics",
        "Library Optimization",
        "Sparse Regression",
        "Recursive Long-Term Prediction"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:33.990684Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.17307",
    "title": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning",
    "authors": [
      "Zhuokun Chen",
      "Zeren Chen",
      "Jiahao He",
      "Lu Sheng",
      "Mingkui Tan",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "abstract": "Chain-of-thought (CoT) enhances the problem-solving ability of large language models (LLMs) but incurs substantial inference cost due to long autoregressive trajectories. Existing acceleration strategies either shorten traces via early stopping or compression, or adopt speculative decoding with a smaller model. However, speculative decoding provides limited gains when model agreement is low and rigidly enforces token-level consistency, overlooking the observation that some smaller models, when correct, produce significantly more concise reasoning traces that could reduce inference length. We introduce R-Stitch, a training-free hybrid decoding framework that leverages token-level entropy as an uncertainty proxy to delegate computation between a small language model (SLM) and an LLM. Our analysis shows that high-entropy tokens are more likely to induce errors, motivating an entropy-guided routing strategy that lets the SLM efficiently handle low-entropy tokens while delegating uncertain ones to the LLM, thereby avoiding full rollbacks and preserving answer quality. We further extend this design with R-Stitch$^{+}$, which learns an adaptive routing policy to adjust the token budget dynamically beyond fixed thresholds. By jointly reducing per-token decoding complexity and the number of generated tokens, our method achieves substantial acceleration with negligible accuracy loss. Concretely, it attains peak speedups of 3.00$\\times$ on DeepSeek-R1-Distill-Qwen-7B, 3.85$\\times$ on 14B, and 4.10$\\times$ on QWQ-32B while maintaining accuracy comparable to full LLM decoding. Moreover, it naturally enables adaptive efficiency--accuracy trade-offs that can be tailored to diverse computational budgets without retraining.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.17307.pdf",
    "abs_url": "https://arxiv.org/abs/2507.17307",
    "published": "2025-07-23T08:14:36Z",
    "updated": "2026-02-02T07:57:06Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文提出了R-Stitch框架，通过熵引导的路由策略动态分配计算在小型和大型语言模型之间，实现高效推理并显著降低推理成本。",
      "motivation": "研究动机源于链式思考（CoT）增强了大语言模型的问题解决能力，但推理成本高昂，因为需要生成长的自回归轨迹。现有加速方法如推测解码在模型一致性低时效果有限，并强制token级一致性，忽视了小型模型可能生成更简洁推理轨迹的潜力。因此，亟需一种能有效平衡效率和准确性的方法，以适应不同计算预算和实际应用需求，解决推理效率瓶颈。",
      "method": "论文提出了R-Stitch，一种无需训练的混合解码框架，使用token级熵作为不确定性代理来在小型语言模型（SLM）和大型语言模型（LLM）之间分配计算。高熵token被视为更易出错，委托给LLM处理，而低熵token由SLM高效处理，避免全回滚并保持答案质量。扩展版本R-Stitch+通过自适应学习动态调整路由策略，超越固定阈值，进一步优化token预算分配，实现更灵活的加速。",
      "result": "实验结果显示，R-Stitch在多个模型上实现了显著的加速：在DeepSeek-R1-Distill-Qwen-7B上达到3.00倍峰值加速，14B模型上3.85倍，QWQ-32B模型上4.10倍，同时准确度与完整LLM解码相当。对比基线方法，该方法不仅减少每个token的解码复杂度，还降低生成token数量，支持自适应效率-准确度权衡，无需重新训练即可适应多样化计算预算。",
      "conclusion": "研究的主要贡献是提出R-Stitch框架，通过动态轨迹拼接有效降低推理成本。其学术价值在于改进了推测解码方法，引入熵分析和自适应路由策略；实际应用价值在于提供灵活的权衡方案，适用于资源受限场景。未来工作可能涉及优化泛化性或扩展到更多模型类型，以进一步提升性能和适用范围。",
      "tags": [
        "Chain-of-Thought (CoT)",
        "Large Language Model (LLM)",
        "Speculative Decoding",
        "Token-level Entropy",
        "Dynamic Routing"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:36.360448Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.12094",
    "title": "Is This Predictor More Informative than Another? A Decision-Theoretical Comparison",
    "authors": [
      "Yiding Feng",
      "Liuhan Qian",
      "Wei Tang"
    ],
    "abstract": "In many real-world applications, a model provider provides probabilistic forecasts to downstream decision-makers who use them to make decisions under diverse payoff objectives. The provider may have access to multiple predictive models, each potentially miscalibrated, and must choose which model to deploy in order to maximize the usefulness of predictions for downstream decisions. A central challenge arises: how can the provider meaningfully compare two predictors when neither is guaranteed to be well-calibrated, and when the relevant decision tasks may differ across users and contexts?   To answer this, our first contribution introduces the notion of the informativeness gap between any two predictors, defined as the maximum normalized payoff advantage one predictor offers over the other across all decision-making tasks. Our framework strictly generalizes several existing notions: it subsumes U-Calibration and Calibration Decision Loss, which compare a miscalibrated predictor to its calibrated counterpart, and it recovers Blackwell informativeness as a special case when both predictors are perfectly calibrated. Our second contribution is a dual characterization of the informativeness gap, which gives rise to a natural informativeness measure that can be viewed as a relaxed variant of the earth mover's distance between two prediction distributions. We show that this measure satisfies natural desiderata: it is complete and sound, and it can be estimated sample-efficiently in the prediction-only access setting. We complement our theory with experiments on LLM-based forecasters in real-world prediction tasks, showing that the informativeness gap offers a more decision-relevant alternative to traditional metrics, and provides a principled lens for evaluating how ad hoc calibration post-processing affects downstream decision usefulness.",
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2507.12094.pdf",
    "abs_url": "https://arxiv.org/abs/2507.12094",
    "published": "2025-07-16T10:01:22Z",
    "updated": "2026-02-02T07:13:44Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文提出信息差距概念及其双重表征，为比较非校准预测器在决策任务中的信息量提供新框架。",
      "motivation": "在实际应用中，模型提供者需要为下游决策者提供概率预测，但多个预测器可能未校准，且决策任务因用户和情境而异。传统度量如校准度无法直接衡量预测对决策的有用性，导致模型选择困难。本文旨在解决这一挑战，通过广义化现有概念（如U-Calibration和Calibration Decision Loss），为比较不同预测器提供决策理论基础，强调了提升预测实用性的重要性。",
      "method": "论文首先定义信息差距概念，即两个预测器在所有决策任务中的最大标准化收益优势。其次，通过双重表征开发一个自然的信息度量，该度量可视作两个预测分布之间地球移动距离的松弛变体，满足完整性和可靠性要求，并能在仅访问预测设置中有效估计。实验部分使用了基于大语言模型的预测器，在真实世界预测任务中验证该框架的有效性。",
      "result": "实验结果显示，信息差距比传统度量提供更决策相关的比较标准。在基于LLM的预测器任务中，该框架成功评估了临时校准后处理对下游决策有用性的影响，表明其在模型选择和评估中的实用价值。尽管摘要未提供具体性能数据，但与基线方法对比，信息差距展现了提高决策相关性和应用效果的潜力。",
      "conclusion": "本文的主要贡献是引入信息差距及其双重表征，为比较预测器信息量构建决策理论框架，学术上广义化现有概念并恢复Blackwell informativeness，实际中为模型提供者选择预测器提供原则性指导。研究的局限性可能在于应用场景的普适性，未来工作可扩展至更复杂决策环境或验证方法的鲁棒性。",
      "tags": [
        "Decision Theory",
        "Probabilistic Forecasting",
        "Calibration",
        "Informativeness Gap",
        "Earth Mover's Distance"
      ]
    },
    "analyzed_at": "2026-02-03T04:01:48.344736Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.07610",
    "title": "SpatialViz-Bench: A Cognitively-Grounded Benchmark for Diagnosing Spatial Visualization in MLLMs",
    "authors": [
      "Siting Wang",
      "Minnan Pei",
      "Luoyang Sun",
      "Cheng Deng",
      "Kun Shao",
      "Zheng Tian",
      "Haifeng Zhang",
      "Jun Wang"
    ],
    "abstract": "Humans can imagine and manipulate visual images mentally, a capability known as spatial visualization. While many multi-modal benchmarks assess reasoning on visible visual information, the ability to infer unseen relationships through spatial visualization remains insufficiently evaluated as a spatial skill. This reliance on publicly sourced problems from IQ tests or math competitions risks data contamination and compromises assessment reliability. To this end, we introduce SpatialViz-Bench, a comprehensive multi-modal benchmark for spatial visualization with 12 tasks across 4 sub-abilities, comprising 1,180 programmatically generated problems, a scalable framework that allows for expansion to ensure fair and continuously reliable evaluations. Our evaluation of 27 Multi-modal Large Language Models (MLLMs) reveals wide performance variations, demonstrates the benchmark's strong discriminative power, and uncovers counter-intuitive findings: Chain-of-Thought (CoT) prompting paradoxically degrades accuracy on open-source models. Through statistical and qualitative analysis of error types, SpatialViz-Bench demonstrates that state-of-the-art MLLMs exhibit deficiencies in spatial visualization tasks, thereby addressing a significant lacuna in the field. The benchmark data and evaluation code are publicly available.",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.07610.pdf",
    "abs_url": "https://arxiv.org/abs/2507.07610",
    "published": "2025-07-10T10:27:20Z",
    "updated": "2026-02-02T07:28:58Z",
    "comment": null,
    "light_analysis": {
      "overview": "该论文提出SpatialViz-Bench，一个程序生成的多模态基准，用于诊断多模态大语言模型在空间可视化任务中的能力。",
      "motivation": "该研究旨在解决MLLMs在空间可视化能力评估上的不足。现有基准多基于可见视觉信息推理，无法充分评估推断未见关系的空间技能，而依赖公开问题（如IQ测试或数学竞赛）可能导致数据污染和评估可靠性问题。因此，开发一个公平、可靠且认知基础的基准对准确评估MLLMs空间可视化能力至关重要，以推动该领域研究和模型改进。",
      "method": "论文提出SpatialViz-Bench基准，包含12个任务覆盖4个子能力，共1,180个程序生成的问题。该框架采用程序化生成方式，确保问题多样性和可扩展性，避免数据污染。基准设计为多模态评估，用于系统测试MLLMs的空间可视化技能，技术特色包括认知基础的任务划分和可动态扩展的评估体系，提供公平且持续可靠的评估环境。",
      "result": "通过评估27个MLLMs在SpatialViz-Bench上，结果显示模型性能差异显著，基准具有强区分力。反直觉地，Chain-of-Thought提示在开源模型上反而降低了准确性。通过统计和定性分析误差类型，发现当前最先进的MLLMs在空间可视化任务中存在明显缺陷，验证了基准的诊断能力。具体数据如准确率变化未在摘要中说明，但基准成功识别了模型弱点。",
      "conclusion": "SpatialViz-Bench成功填补了MLLMs空间可视化评估的空白，提供了可靠的基准和公开资源。其程序生成和可扩展设计确保了评估的公平性和持续性，对识别模型缺陷、促进MLLMs认知能力研究有重要学术和实际价值。未来工作可扩展基准以覆盖更广泛任务或改进评估方法，推动领域进一步发展。",
      "tags": [
        "Spatial Visualization",
        "Multi-modal Large Language Models",
        "Benchmark Evaluation",
        "Chain-of-Thought Prompting",
        "Programmatically Generated Problems"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:19.478190Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.05980",
    "title": "Lost in Localization: Building RabakBench with Human-in-the-Loop Validation to Measure Multilingual Safety Gaps",
    "authors": [
      "Gabriel Chua",
      "Leanne Tan",
      "Ziyu Ge",
      "Roy Ka-Wei Lee"
    ],
    "abstract": "Large language models (LLMs) often fail to maintain safety in low-resource language varieties, such as code-mixed vernaculars and regional dialects. We introduce RabakBench, a multilingual safety benchmark and scalable pipeline localized to Singapore's unique linguistic landscape, covering Singlish, Chinese, Malay, and Tamil. We construct the benchmark through a three-stage pipeline: (1) Generate: augmenting real-world unsafe web content via LLM-driven red teaming; (2) Label: applying semi-automated multi-label annotation using majority-voted LLM labelers; and (3) Translate: performing high-fidelity, toxicity-preserving translation. The resulting dataset contains over 5,000 examples across six fine-grained safety categories. Despite using LLMs for scalability, our framework maintains rigorous human oversight, achieving 0.70-0.80 inter-annotator agreement. Evaluations of 13 state-of-the-art guardrails reveal significant performance degradation, underscoring the need for localized evaluation. RabakBench provides a reproducible framework for building safety benchmarks in underserved communities.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2507.05980.pdf",
    "abs_url": "https://arxiv.org/abs/2507.05980",
    "published": "2025-07-08T13:37:25Z",
    "updated": "2026-02-02T05:02:34Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文介绍了 RabakBench，一个针对低资源语言的多语言安全基准和构建管道，通过本地化评估揭示了现有模型的安全性能下降。",
      "motivation": "大型语言模型在代码混合方言和区域方言等低资源语言变体中经常无法确保安全，这在实际应用中可能导致严重风险和误导。现有安全评估方法往往针对主流语言，忽略了新加坡等地独特的语言环境如新加坡式英语、中文、马来语和泰米尔语，缺乏本地化基准来衡量这些差距。因此，本研究旨在解决多语言安全评估的不足，开发一个针对服务不足社区的基准，以促进模型在多样化语言中的安全性能提升。",
      "method": "研究提出一个三阶段管道来构建 RabakBench：生成阶段通过大型语言模型驱动的红队测试增强真实网络内容；标注阶段采用多数投票的 LLM 标注器进行半自动化多标签标注；翻译阶段执行高保真、毒性保留的翻译以本地化数据。管道结合了可扩展的自动化方法和严格的人类监督，确保数据质量和一致性，覆盖六个细粒度安全类别。数据集包含超过 5,000 个示例，涵盖新加坡式英语、中文、马来语和泰米尔语，提供针对性的多语言评估资源。",
      "result": "实验结果显示，RabakBench 数据集包含超过 5,000 个示例，标注者间一致性达到 0.70 到 0.80，表明数据质量可靠。对 13 个最先进的防护栏模型进行评估，发现它们在本地化语言中的安全性能显著下降，凸显了现有模型在低资源语言环境中的局限性。这强调了本地化安全评估的必要性，基准揭示了明显的性能差距，为后续改进提供了实证基础。",
      "conclusion": "本文的主要贡献是构建了 RabakBench，一个可复现的框架，用于在服务不足的社区中测量多语言安全差距。这项研究具有重要的学术价值，推动了本地化安全评估的发展，并为改进大型语言模型在低资源语言中的安全性提供了实用工具。潜在局限性包括依赖特定语言环境，未来工作可以扩展到更多语言变体和社区，以进一步验证和扩展该框架的通用性。",
      "tags": [
        "Multilingual Safety Benchmark",
        "Large Language Models",
        "Human-in-the-Loop",
        "Red Teaming",
        "Toxicity-Preserving Translation"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:33.231468Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.05427",
    "title": "OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts",
    "authors": [
      "Shiting Xiao",
      "Rishabh Kabra",
      "Yuhang Li",
      "Donghyun Lee",
      "Joao Carreira",
      "Priyadarshini Panda"
    ],
    "abstract": "The ability to segment objects based on open-ended language prompts remains a critical challenge, requiring models to ground textual semantics into precise spatial masks while handling diverse and unseen categories. We present OpenWorldSAM, a framework that extends the prompt-driven Segment Anything Model v2 (SAM2) to open-vocabulary scenarios by integrating multi-modal embeddings extracted from a lightweight vision-language model (VLM). Our approach is guided by four key principles: i) Unified prompting: OpenWorldSAM supports a diverse range of prompts, including category-level and sentence-level language descriptions, providing a flexible interface for various segmentation tasks. ii) Efficiency: By freezing the pre-trained components of SAM2 and the VLM, we train only 4.5 million parameters on the COCO-stuff dataset, achieving remarkable resource efficiency. iii) Instance Awareness: We enhance the model's spatial understanding through novel positional tie-breaker embeddings and cross-attention layers, enabling effective segmentation of multiple instances. iv) Generalization: OpenWorldSAM exhibits strong zero-shot capabilities, generalizing well on unseen categories and an open vocabulary of concepts without additional training. Extensive experiments demonstrate that OpenWorldSAM achieves state-of-the-art performance in open-vocabulary semantic, instance, and panoptic segmentation across multiple benchmarks. Code is available at https://github.com/GinnyXiao/OpenWorldSAM.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2507.05427.pdf",
    "abs_url": "https://arxiv.org/abs/2507.05427",
    "published": "2025-07-07T19:16:22Z",
    "updated": "2026-02-02T04:21:49Z",
    "comment": null,
    "light_analysis": {
      "overview": "OpenWorldSAM通过集成视觉语言模型扩展SAM2，实现基于语言提示的开放词汇通用图像分割。",
      "motivation": "该研究旨在解决基于开放语言提示的图像分割挑战，即需要模型将文本语义准确映射到空间掩码，并处理多样和未见类别。现有方法在此方面不足，难以适应真实世界复杂场景，OpenWorldSAM通过整合多模态信息提升模型的泛化能力和适应性，以应对这一关键问题。",
      "method": "研究方法基于SAM2框架，集成了轻量级视觉语言模型的多模态嵌入。关键创新包括支持统一提示（如类别和句子描述）、高效训练（只训练4.5百万参数，冻结预训练组件）、增强实例感知（通过位置嵌入和交叉注意力层）以及强化零样本泛化。技术细节涉及使用COCO-stuff数据集，改进模型架构以提高分割精度。",
      "result": "实验结果显示，OpenWorldSAM在多个基准测试中达到最先进的性能，特别是在开放词汇语义、实例和全景分割方面。模型展现出强大的零样本能力，能有效泛化到未见类别和概念，无需额外训练。摘要未提供具体数据指标，但强调了其在效率和泛化上的显著优势。",
      "conclusion": "OpenWorldSAM的主要贡献在于提出了一种高效且泛化的图像分割框架，成功解决了开放词汇挑战。学术价值在于整合多模态嵌入提升分割准确性，实际应用价值高，适用于多样任务。局限性或未来方向可能包括扩展更多提示类型和数据集，摘要未明确说明具体细节。",
      "tags": [
        "Segment Anything Model v2",
        "Vision-Language Model",
        "Open-Vocabulary Segmentation",
        "Multi-Modal Embeddings",
        "Prompt-Driven Segmentation"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:05.708579Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2507.00439",
    "title": "Improving the Distributional Alignment of LLMs using Supervision",
    "authors": [
      "Gauri Kambhatla",
      "Sanjana Gautam",
      "Angela Zhang",
      "Alex Liu",
      "Ravi Srinivasan",
      "Junyi Jessy Li",
      "Matthew Lease"
    ],
    "abstract": "The ability to accurately align LLMs with population groups on subjective questions would have great value. In this work, we show that simple supervision can more consistently improve language model alignment with diverse population groups, as measured across three datasets spanning various topics. Beyond evaluating average alignment, we also report how alignment varies across specific groups. Our broad findings provide insights into the distributional alignment of LLMs with diverse populations. By conducting evaluation over many LLMs and prompting strategies, we provide a benchmark to stimulate future research.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2507.00439.pdf",
    "abs_url": "https://arxiv.org/abs/2507.00439",
    "published": "2025-07-01T05:46:22Z",
    "updated": "2026-02-02T04:11:57Z",
    "comment": null,
    "light_analysis": {
      "overview": "通过简单监督方法，论文有效提升了大型语言模型在主观问题上与不同人群组的分布对齐一致性。",
      "motivation": "在处理主观问题时，大型语言模型往往难以准确反映多样人群的观点，这限制了模型的公平性和实际应用价值。现有方法在对齐一致性和群体间差异处理上可能不足，本研究旨在解决这一关键问题，探索更有效的对齐策略，以提升模型的社会适用性和可靠性，为AI公平性研究提供基础。",
      "method": "论文采用简单的监督方法，通过对大型语言模型进行优化，结合三个涵盖不同主题的数据集进行评估，核心创新在于利用监督信号来改进对齐性能。具体技术细节如监督形式或模型架构摘要未明确说明，但通过提示策略和大规模LLM评估，提供了基准框架以促进未来研究。",
      "result": "实验结果表明，使用监督方法能更一致地改善语言模型与人群组的对齐，在三个数据集上均观察到提升，并报告了对齐在不同特定群体中的变化情况。摘要未提供具体性能指标数据，但通过对比多种LLM和提示策略，为分布对齐评估提供了新见解和基准。",
      "conclusion": "论文的主要贡献在于验证了简单监督对LLM分布对齐的有效性，通过大规模评估建立了基准，并提供了关于对齐群体差异的洞察，有助于推动公平AI研究。未来工作可进一步优化监督方法、扩展应用场景，并探索更多群体特异性对齐策略。",
      "tags": [
        "Large Language Models",
        "Supervised Learning",
        "Distributional Alignment",
        "Prompting Strategies",
        "Dataset Evaluation"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:08.443153Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.16123",
    "title": "FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning",
    "authors": [
      "Natapong Nitarach",
      "Warit Sirichotedumrong",
      "Panop Pitchayarthorn",
      "Pittawat Taveekitworachai",
      "Potsawee Manakul",
      "Kunat Pipatanakul"
    ],
    "abstract": "This paper presents FinCoT, a structured chain-of-thought (CoT) prompting framework that embeds domain-specific expert financial reasoning blueprints to guide large language models' behaviors. We identify three main prompting styles in financial NLP (FinNLP): (1) standard prompting (zero-shot), (2) unstructured CoT (free-form reasoning), and (3) structured CoT (with explicitly structured reasoning steps). Prior work has mainly focused on the first two, while structured CoT remains underexplored and lacks domain expertise incorporation. Therefore, we evaluate all three prompting approaches across ten CFA-style financial domains and introduce FinCoT as the first structured finance-specific prompting approach incorporating blueprints from domain experts. FinCoT improves the accuracy of a general-purpose model, Qwen3-8B-Base, from 63.2% to 80.5%, and boosts Fin-R1 (7B), a finance-specific model, from 65.7% to 75.7%, while reducing output length by up to 8.9x and 1.16x compared to structured CoT methods, respectively. We find that FinCoT proves most effective for models lacking financial post-training. Our findings show that FinCoT does not only improve performance and reduce inference costs but also yields more interpretable and expert-aligned reasoning traces.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.16123.pdf",
    "abs_url": "https://arxiv.org/abs/2506.16123",
    "published": "2025-06-19T08:18:55Z",
    "updated": "2026-02-02T12:35:50Z",
    "comment": "Accepted at FinNLP-2025, EMNLP (Oral Presentation)",
    "light_analysis": {
      "overview": "FinCoT 提出首个整合专家财务推理蓝图的结构化思维链提示框架，显著提升金融 NLP 模型的性能、减少推理成本并增强可解释性。",
      "motivation": "该研究旨在解决金融自然语言处理（FinNLP）中结构化思维链（CoT）提示方法未被充分探索的问题。现有工作主要关注标准提示和非结构化 CoT，但结构化 CoT 缺乏领域专业知识的整合，导致模型在复杂金融推理任务中表现不佳。金融领域需要精准和可解释的推理，因此开发结合专家知识的结构化提示方法对提高模型准确性和适应性至关重要。摘要未明确说明更广泛的应用背景。",
      "method": "FinCoT 框架通过嵌入领域特定专家财务推理蓝图，形成结构化思维链提示来指导大型语言模型的行为。关键创新在于首次将专家蓝图整合到结构化提示中，以明确步骤引导推理。研究在十个 CFA 风格的金融领域进行评估，使用通用模型 Qwen3-8B-Base 和金融特定模型 Fin-R1，作为验证框架有效性的基础。该方法聚焦于设计结构化步骤，而非修改模型架构。",
      "result": "实验结果显示，FinCoT 显著提升模型准确率：通用模型 Qwen3-8B-Base 的准确率从 63.2% 提升到 80.5%，金融特定模型 Fin-R1 从 65.7% 提升到 75.7%。同时，与结构化 CoT 方法相比，输出长度分别减少了高达 8.9 倍和 1.16 倍。这些数据表明 FinCoT 在提高性能、降低推理成本方面优于基线方法，尤其对缺乏金融后训练的模型效果更佳。",
      "conclusion": "FinCoT 的主要贡献在于提出了一个整合专家知识的结构化提示框架，有效提升了金融 NLP 任务的准确性、减少了输出长度，并生成了更可解释和专家对齐的推理痕迹。这项研究对提示工程和领域适应方法具有重要学术价值，为金融 AI 应用提供了实际工具。未来工作可扩展至更多领域或优化专家蓝图的整合方式，以应对类似挑战。",
      "tags": [
        "Chain-of-Thought",
        "Structured Prompting",
        "Financial NLP",
        "Expert Systems",
        "Large Language Models"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:32.857396Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.08373",
    "title": "Draft-based Approximate Inference for LLMs",
    "authors": [
      "Kevin Galim",
      "Ethan Ewer",
      "Wonjun Kang",
      "Minjae Lee",
      "Hyung Il Koo",
      "Kangwook Lee"
    ],
    "abstract": "Optimizing inference for long-context large language models (LLMs) is increasingly important due to the quadratic compute and linear memory cost of Transformers. Existing approximate inference methods, including key-value (KV) cache dropping, sparse attention, and prompt compression, typically rely on coarse predictions of token or KV pair importance. We unify and extend recent work by introducing a framework for approximate LLM inference that leverages small draft models to more accurately predict token and KV pair importance. We provide novel theoretical and empirical analyses justifying lookahead-based importance estimation techniques. Within this framework, we present: (i) SpecKV, the first method to use lookahead with a small draft model to enable precise KV cache dropping; (ii) SpecPC, which leverages draft model attention activations to identify and discard less important prompt tokens; and (iii) SpecKV-PC, a cascaded compression strategy combining both techniques. Extensive experiments on long-context benchmarks demonstrate that our methods consistently achieve higher accuracy than existing baselines while retaining the same efficiency gains in memory usage, latency, and throughput.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2506.08373.pdf",
    "abs_url": "https://arxiv.org/abs/2506.08373",
    "published": "2025-06-10T02:37:46Z",
    "updated": "2026-02-02T08:30:58Z",
    "comment": "Accepted to ICLR 2026",
    "light_analysis": {
      "overview": "本文提出了一个基于草案模型的近似推理框架，通过前瞻性重要性估计优化长上下文大语言模型的推理效率和准确性。",
      "motivation": "随着长上下文大语言模型（LLMs）的广泛应用，Transformer模型的计算成本（二次计算）和内存成本（线性内存）成为推理效率的主要瓶颈。现有近似推理方法，如键值（KV）缓存丢弃、稀疏注意力和提示压缩，通常依赖于粗粒度的令牌或KV对重要性预测，导致准确性不足。因此，需要更精确的重要性预测方法来平衡推理效率和模型性能，这对于资源受限的实际部署至关重要。",
      "method": "论文引入了一个基于草案模型的近似推理框架，通过小草案模型进行前瞻性重要性估计。核心方法包括：(i) SpecKV，利用草案模型的前瞻性预测精确丢弃KV缓存；(ii) SpecPC，使用草案模型的注意力激活识别并丢弃不重要提示令牌；(iii) SpecKV-PC，结合两者的级联压缩策略。关键技术创新是首次将草案模型的前瞻性技术应用于KV缓存和提示压缩，并基于长上下文基准测试进行实验，但摘要未明确说明具体数据集和模型架构细节。",
      "result": "在长上下文基准测试的广泛实验中，所提出的方法在保持相同内存使用、延迟和吞吐量效率增益的同时， consistently 达到比现有基线更高的准确性。与KV缓存丢弃、稀疏注意力和提示压缩等基线方法相比，SpecKV、SpecPC和SpecKV-PC在准确性上均有显著提升，但摘要未明确说明具体提升数值，表明在效率不损失的前提下优化了性能。",
      "conclusion": "该研究的主要贡献是提出了一个基于草案模型的近似推理框架，并通过SpecKV、SpecPC和SpecKV-PC方法优化了LLMs的推理效率。学术价值在于提供了前瞻性重要性估计的理论和实证依据，实际应用价值在于降低计算和内存成本，促进LLMs在现实场景中的部署。未来工作方向可能包括扩展框架到更多模型类型或测试更广泛的数据集，以进一步提升通用性和鲁棒性。",
      "tags": [
        "Large Language Models",
        "Approximate Inference",
        "KV Cache",
        "Draft Model",
        "Lookahead"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:34.393490Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.06178",
    "title": "Reusing Trajectories in Policy Gradients Enables Fast Convergence",
    "authors": [
      "Alessandro Montenegro",
      "Federico Mansutti",
      "Marco Mussi",
      "Matteo Papini",
      "Alberto Maria Metelli"
    ],
    "abstract": "Policy gradient (PG) methods are a class of effective reinforcement learning algorithms, particularly when dealing with continuous control problems. They rely on fresh on-policy data, making them sample-inefficient and requiring $O(ε^{-2})$ trajectories to reach an $ε$-approximate stationary point. A common strategy to improve efficiency is to reuse information from past iterations, such as previous gradients or trajectories, leading to off-policy PG methods. While gradient reuse has received substantial attention, leading to improved rates up to $O(ε^{-3/2})$, the reuse of past trajectories, although intuitive, remains largely unexplored from a theoretical perspective. In this work, we provide the first rigorous theoretical evidence that reusing past off-policy trajectories can significantly accelerate PG convergence. We propose RT-PG (Reusing Trajectories - Policy Gradient), a novel algorithm that leverages a power mean-corrected multiple importance weighting estimator to effectively combine on-policy and off-policy data coming from the most recent $ω$ iterations. Through a novel analysis, we prove that RT-PG achieves a sample complexity of $\\widetilde{O}(ε^{-2}ω^{-1})$. When reusing all available past trajectories, this leads to a rate of $\\widetilde{O}(ε^{-1})$, the best known one in the literature for PG methods. We further validate our approach empirically, demonstrating its effectiveness against baselines with state-of-the-art rates.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.06178.pdf",
    "abs_url": "https://arxiv.org/abs/2506.06178",
    "published": "2025-06-06T15:42:15Z",
    "updated": "2026-02-02T10:02:14Z",
    "comment": null,
    "light_analysis": {
      "overview": "本文首次理论证明重用过去轨迹能加速策略梯度收敛，并提出RT-PG算法达到最佳样本复杂度~O(ε^{-1})。",
      "motivation": "策略梯度方法在强化学习中，尤其是连续控制任务中有效，但依赖新鲜on-policy数据导致样本效率低下，收敛需要O(ε^{-2})轨迹。现有方法如梯度重用已将速率提升至O(ε^{-3/2})，但轨迹重用的理论潜力未被探索，限制了进一步效率提升。本研究旨在填补这一空白，通过理论分析验证轨迹重用的有效性，解决PG方法数据不足的问题，为开发更高效的算法提供基础，推动强化学习在实际应用中的部署。",
      "method": "论文提出RT-PG算法，核心是使用power mean-corrected multiple importance weighting估计器。该估计器整合当前on-policy数据和过去ω次迭代的off-policy轨迹，通过校正权重减少数据来源差异带来的偏差。算法设计避免了直接重用轨迹的常见问题，并通过新颖理论分析确保收敛性，首次将轨迹重用纳入严谨框架。具体技术包括基于最近迭代的数据池，优化估计器以平衡on-policy和off-policy信息，为策略梯度方法的数据效率优化提供新途径。",
      "result": "理论分析证明，RT-PG算法的样本复杂度为~O(ε^{-2}ω^{-1})，当ω取最大值时，速率优化为~O(ε^{-1})，优于标准PG的O(ε^{-2})和梯度重用的O(ε^{-3/2})，是文献中最好的。实验部分在连续控制任务中验证了算法的实际性能，与基线方法对比显示RT-PG在收敛速度和样本效率上均有显著提升，支持了理论结论。具体指标如收敛曲线和样本数减少证实了算法的有效性，突显其在资源受限环境中的优势。",
      "conclusion": "本研究的主要贡献是首次理论证实重用过去轨迹能加速策略梯度收敛，并设计RT-PG算法实现最佳已知速率。学术上，这为强化学习的样本效率研究提供了新视角和理论框架；实际上，算法的高效性有助于在机器人控制等应用场景中减少数据需求，提升部署可行性。未来工作可探索算法在更复杂环境中的扩展，或结合深度强化学习技术进一步优化，同时潜在局限性包括参数ω的调优和泛化到其他任务的能力。",
      "tags": [
        "Policy Gradient",
        "Reinforcement Learning",
        "Importance Weighting",
        "Convergence Analysis",
        "Off-Policy Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:36.831054Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.02370",
    "title": "Converge Faster, Talk Less: Hessian-Informed Federated Zeroth-Order Optimization",
    "authors": [
      "Zhe Li",
      "Bicheng Ying",
      "Zidong Liu",
      "Chaosheng Dong",
      "Haibo Yang"
    ],
    "abstract": "Zeroth-order (ZO) optimization enables dimension-free communication in federated learning (FL), making it attractive for fine-tuning of large language models (LLMs) due to significant communication savings. However, existing ZO-FL methods largely overlook curvature information, despite its well-established benefits for convergence acceleration. To address this, we propose HiSo, a Hessian-informed ZO federated optimization method that accelerates convergence by leveraging global diagonal Hessian approximations, while strictly preserving scalar-only communication without transmitting any second-order information. Theoretically, for non-convex functions, we show that HiSo can achieve an accelerated convergence rate that is independent of the Lipschitz constant $L$ and model dimension $d$ under some Hessian approximation assumptions, offering a plausible explanation for the observed phenomenon of ZO convergence being much faster than its worst-case $\\mathscr{O}(d)$-bound. Empirically, across diverse LLM fine-tuning benchmarks, HiSo delivers a 1$\\sim$5$\\times$ speedup in communication rounds over existing state-of-the-art ZO-FL baselines. This superior convergence not only cuts communication costs but also provides strong empirical evidence that Hessian information acts as an effective accelerator in federated ZO optimization settings. Our source code is provided at https://github.com/ZidongLiu/DeComFL.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.02370.pdf",
    "abs_url": "https://arxiv.org/abs/2506.02370",
    "published": "2025-06-03T02:13:31Z",
    "updated": "2026-02-02T03:44:55Z",
    "comment": "Accepted by ICLR 2026",
    "light_analysis": {
      "overview": "论文提出了一种名为HiSo的基于Hessian信息的联邦零阶优化方法，通过全局对角线Hessian近似加速收敛，同时保持标量通信。",
      "motivation": "在联邦学习（FL）中，零阶优化（ZO）通过仅传输标量值实现维度无关通信，显著降低了大规模语言模型（LLM）微调的通信开销。然而，现有ZO-FL方法普遍忽视了曲率信息，尽管曲率信息已证明能加速收敛，这限制了ZO-FL在资源受限场景下的效率。因此，本研究旨在利用Hessian信息改进ZO-FL方法，以解决收敛速度慢的问题，提升优化性能并扩展应用范围。",
      "method": "HiSo是一种基于Hessian信息的联邦零阶优化方法，核心创新在于使用全局对角线Hessian近似来加速收敛，同时严格遵守仅标量通信，不传输任何二阶信息。技术特色包括理论分析，在Hessian近似假设下，针对非凸函数，实现收敛速率独立于Lipschitz常数L和模型维度d。实验中使用了多种LLM微调基准数据集来验证方法效果，关键细节如具体模型架构摘要未明确说明。",
      "result": "实验结果表明，在多个大规模语言模型（LLM）微调基准测试中，HiSo与现有最先进的ZO-FL基线方法相比，通信轮数实现了1到5倍的加速。这大幅降低了通信成本，并为Hessian信息在联邦零阶优化中作为有效加速器提供了强有力实证证据。理论分析进一步显示收敛速度可能超出传统最坏情况边界，补充了性能改进。",
      "conclusion": "本研究的主要贡献是提出了HiSo方法，成功将Hessian信息融入联邦零阶优化，显著加速收敛并保持低通信成本。这一成果不仅证明了Hessian信息在ZO-FL中的有效性，还为优化理论提供了新见解，推动高效联邦学习的发展。未来工作方向可能包括改进Hessian近似精度和扩展到其他应用场景，摘要未明确说明具体局限性。",
      "tags": [
        "Federated Learning",
        "Zeroth-Order Optimization",
        "Hessian Approximation",
        "Large Language Models",
        "Convergence Acceleration"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:19.715206Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2506.01582",
    "title": "Bayes optimal learning of attention-indexed models",
    "authors": [
      "Fabrizio Boncoraglio",
      "Emanuele Troiani",
      "Vittorio Erba",
      "Lenka Zdeborová"
    ],
    "abstract": "We introduce the attention-indexed model (AIM), a theoretical framework for analyzing learning in deep attention layers. Inspired by multi-index models, AIM captures how token-level outputs emerge from layered bilinear interactions over high-dimensional embeddings. Unlike prior tractable attention models, AIM allows full-width key and query matrices, aligning more closely with practical transformers. Using tools from statistical mechanics and random matrix theory, we derive closed-form predictions for Bayes-optimal generalization error and identify sharp phase transitions as a function of sample complexity, model width, and sequence length. We propose a matching approximate message passing algorithm and show that gradient descent can reach optimal performance. AIM offers a solvable playground for understanding learning in self-attention layers, that are key components of modern architectures.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.01582.pdf",
    "abs_url": "https://arxiv.org/abs/2506.01582",
    "published": "2025-06-02T12:11:26Z",
    "updated": "2026-02-02T10:09:54Z",
    "comment": null,
    "light_analysis": {
      "overview": "论文引入注意力索引模型（AIM），一个理论框架用于分析深度注意力层学习，并推导贝叶斯最优泛化误差的闭式预测。",
      "motivation": "论文旨在解决深度注意力层学习动态的理论分析问题。自注意力层是transformer等现代AI架构的核心，但现有可处理模型往往简化键和查询矩阵，不能准确反映实际设置，限制了理论洞察。AIM框架通过允许全宽度矩阵，更紧密地与实际transformer对齐，从而弥补了这一不足，为理解复杂学习过程提供了重要背景。",
      "method": "论文提出注意力索引模型（AIM），受多索引模型启发，用于建模深度注意力层中令牌级输出的分层双线性交互。关键创新包括允许全宽度键和查询矩阵，与实际transformer更一致；使用统计力学和随机矩阵理论工具，推导贝叶斯最优泛化误差的闭式表达式；识别样本复杂度、模型宽度和序列长度函数中的相变；并提出匹配的近似消息传递算法，证明梯度下降可以逼近最优性能。",
      "result": "论文主要展示了理论结果，推导了贝叶斯最优泛化误差的闭式预测，揭示了学习过程中随样本复杂度、模型宽度和序列长度变化的急剧相变。这些结果提供了量化洞察，表明梯度下降能够达到最优性能，但摘要未明确说明具体实验数据或与基线方法的详细对比。",
      "conclusion": "论文的主要贡献是提出了注意力索引模型（AIM），一个可解的理论框架，用于分析深度注意力层的学习，增强了与实际transformer的对齐。这为理解自注意力机制提供了新的学术工具，具有理论价值，并可能指导实践优化。未来工作可扩展模型复杂性或应用于更广泛场景，以探索其局限性。",
      "tags": [
        "Attention-indexed Model",
        "Self-Attention",
        "Statistical Mechanics",
        "Random Matrix Theory",
        "Approximate Message Passing"
      ]
    },
    "analyzed_at": "2026-02-03T04:02:44.876562Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.24779",
    "title": "Are Your Generated Instances Truly Useful? GenBench-MILP: A Benchmark Suite for MILP Instance Generation",
    "authors": [
      "Yidong Luo",
      "Chenguang Wang",
      "Dong Li",
      "Tianshu Yu"
    ],
    "abstract": "The proliferation of machine learning-based methods for Mixed-Integer Linear Programming (MILP) instance generation has surged, driven by the need for diverse training datasets. However, a critical question remains: Are these generated instances truly useful and realistic? Current evaluation protocols often rely on superficial structural metrics or simple solvability checks, which frequently fail to capture the true computational complexity of real-world problems. To bridge this gap, we introduce GenBench-MILP, a comprehensive benchmark suite designed for the standardized and objective evaluation of MILP generators. Our framework assesses instance quality across four key dimensions: mathematical validity, structural similarity, computational hardness, and utility in downstream tasks. A distinctive innovation of GenBench-MILP is the analysis of solver-internal features -- including root node gaps, heuristic success rates, and cut plane usage. By treating the solver's dynamic behavior as an expert assessment, we reveal nuanced computational discrepancies that static graph features miss. Our experiments on instance generative models demonstrate that instances with high structural similarity scores can still exhibit drastically divergent solver interactions and difficulty levels. By providing this multifaceted evaluation toolkit, GenBench-MILP aims to facilitate rigorous comparisons and guide the development of high-fidelity instance generators.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.24779.pdf",
    "abs_url": "https://arxiv.org/abs/2505.24779",
    "published": "2025-05-30T16:42:15Z",
    "updated": "2026-02-02T06:56:44Z",
    "comment": "The code is available in https://github.com/icml2026genbench-milp/GenBench-MILP",
    "light_analysis": {
      "overview": "GenBench-MILP是一个用于标准化评估混合整数线性规划实例生成器的基准套件，通过分析求解器内部特征实现多维评估。",
      "motivation": "随着基于机器学习的混合整数线性规划实例生成方法激增，需要多样化的训练数据集来支持优化算法。然而，当前评估协议通常依赖表面结构指标或简单可解性检查，无法捕捉真实问题的计算复杂性，导致生成的实例可能缺乏实用性和现实性。因此，迫切需要更有效的评估方法，以确保生成实例的质量和在下游任务中的适用性。",
      "method": "论文提出了GenBench-MILP基准套件，用于标准化评估混合整数线性规划实例生成器。该方法评估四个关键维度：数学有效性、结构相似性、计算硬度和下游任务效用。独特创新是分析求解器内部特征，如根节点间隙、启发式成功率和切割平面使用，将求解器的动态行为视为专家评估，从而揭示静态图特征遗漏的细微计算差异，全面捕捉实例的真实复杂性。",
      "result": "实验表明，使用GenBench-MILP评估实例生成模型时，发现具有高结构相似性得分的实例在求解器交互和难度水平上仍可能表现出显著差异，这揭示了传统结构指标的不足。摘要未明确说明具体性能指标，但通过比较传统方法，新框架有效暴露了计算复杂性中的隐藏问题，验证了其多维评估的实用性和对生成实例质量的深入分析能力。",
      "conclusion": "论文的主要贡献是引入了GenBench-MILP基准套件，通过标准化和多维评估，解决了混合整数线性规划实例生成器评估的局限性。该研究具有重要的学术价值，提供了一种客观工具来促进高保真生成器的开发，并具有实际应用价值，优化了机器学习在优化问题中的使用。未来工作可能涉及扩展评估维度或应用到其他领域的实例生成任务中。",
      "tags": [
        "Mixed-Integer Linear Programming",
        "Instance Generation",
        "Benchmark Suite",
        "Solver-Internal Features",
        "Computational Hardness"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:07.872795Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.24157",
    "title": "Experience-based Knowledge Correction for Robust Planning in Minecraft",
    "authors": [
      "Seungjoon Lee",
      "Suhwan Kim",
      "Minhyeon Oh",
      "Youngsik Yoon",
      "Jungseul Ok"
    ],
    "abstract": "Large Language Model (LLM)-based planning has advanced embodied agents in long-horizon environments such as Minecraft, where acquiring latent knowledge of goal (or item) dependencies and feasible actions is critical. However, LLMs often begin with flawed priors and fail to correct them through prompting, even with feedback. We present XENON (eXpErience-based kNOwledge correctioN), an agent that algorithmically revises knowledge from experience, enabling robustness to flawed priors and sparse binary feedback. XENON integrates two mechanisms: Adaptive Dependency Graph, which corrects item dependencies using past successes, and Failure-aware Action Memory, which corrects action knowledge using past failures. Together, these components allow XENON to acquire complex dependencies despite limited guidance. Experiments across multiple Minecraft benchmarks show that XENON outperforms prior agents in both knowledge learning and long-horizon planning. Remarkably, with only a 7B open-weight LLM, XENON surpasses agents that rely on much larger proprietary models. Code available at https://sjlee-me.github.io/XENON",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.24157.pdf",
    "abs_url": "https://arxiv.org/abs/2505.24157",
    "published": "2025-05-30T03:01:44Z",
    "updated": "2026-02-02T05:55:44Z",
    "comment": "ICLR 2026",
    "light_analysis": {
      "overview": "XENON代理通过自适应依赖图和失败感知动作记忆，基于经验修正LLM的先验知识错误，提升在Minecraft中的长视野规划鲁棒性。",
      "motivation": "基于大型语言模型（LLM）的规划方法在长视野环境如Minecraft中面临挑战，因为LLMs通常从错误先验知识开始，这些知识无法通过提示或反馈有效纠正。Minecraft等环境需要精确理解目标依赖和可行动作，现有方法依赖提示和静态知识，导致规划不鲁棒且效率低下。该研究旨在解决LLM在体现代理中知识纠正的不足，以应对复杂任务中的不准确先验问题。",
      "method": "XENON代理的核心方法包括两个算法组件：自适应依赖图利用过去成功经验动态修正物品依赖关系；失败感知动作记忆基于过去失败经验优化动作知识。这些机制使代理能在稀疏二进制反馈下，通过经验学习修正先验错误，提高知识获取的鲁棒性。使用7B开放权重LLM，摘要未明确说明具体数据集，主要针对Minecraft相关基准测试进行实现和评估。",
      "result": "实验结果显示，XENON在多个Minecraft基准测试中，在知识学习和长视野规划性能上优于先前代理。值得注意的是，仅使用7B开放权重LLM，XENON超越了依赖更大专有模型的代理，摘要未提供具体准确率等数据，但强调了在鲁棒性和效率方面的显著提升。这表明该方法能有效纠正先验知识，增强规划能力。",
      "conclusion": "XENON的主要贡献是通过经验学习机制纠正LLM的先验知识错误，提高了在复杂环境中的规划鲁棒性。学术上，该研究为体现代理的知识修正提供了新方法；实际应用中，有助于改善自主代理在长视野任务中的性能。未来工作可扩展至其他领域或处理更复杂依赖关系，摘要未明确说明局限性，但潜在方向包括泛化性测试。",
      "tags": [
        "Large Language Model",
        "Knowledge Correction",
        "Adaptive Dependency Graph",
        "Failure-aware Action Memory",
        "Experience Learning"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:11.154362Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.22081",
    "title": "Can Test-time Computation Mitigate Reproduction Bias in Neural Symbolic Regression?",
    "authors": [
      "Shun Sato",
      "Issei Sato"
    ],
    "abstract": "Mathematical expressions play a central role in scientific discovery. Symbolic regression aims to automatically discover such expressions from given numerical data. Recently, Neural symbolic regression (NSR) methods that involve Transformers pre-trained on synthetic datasets have gained attention for their fast inference, but they often perform poorly, especially with many input variables. In this study, we analyze NSR from both theoretical and empirical perspectives and show that (1) ordinary token-by-token generation is ill-suited for NSR, as Transformers cannot compositionally generate tokens while validating numerical consistency, and (2) the search space of NSR methods is greatly restricted due to reproduction bias, where the majority of generated expressions are merely copied from the training data. We further examine whether tailored test-time strategies can reduce reproduction bias and show that providing additional information at test time effectively mitigates it. These findings contribute to a deeper understanding of the limitation of NSR approaches and provide guidance for designing more robust and generalizable methods. Code is available at https://github.com/Shun-0922/Mem-Bias-NSR .",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.22081.pdf",
    "abs_url": "https://arxiv.org/abs/2505.22081",
    "published": "2025-05-28T08:01:25Z",
    "updated": "2026-02-02T05:59:06Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.20137",
    "title": "ePC: Fast and Deep Predictive Coding for Digital Hardware",
    "authors": [
      "Cédric Goemaere",
      "Gaspard Oliviers",
      "Rafal Bogacz",
      "Thomas Demeester"
    ],
    "abstract": "Predictive Coding (PC) offers a brain-inspired alternative to backpropagation for neural network training, described as a physical system minimizing its internal energy. However, in practice, PC is predominantly digitally simulated, requiring excessive amounts of compute while struggling to scale to deeper architectures. This paper reformulates PC to overcome this hardware-algorithm mismatch. First, we uncover how the canonical state-based formulation of PC (sPC) is, by design, deeply inefficient in digital simulation, inevitably resulting in exponential signal decay that stalls the entire minimization process. Then, to overcome this fundamental limitation, we introduce error-based PC (ePC), a novel reparameterization of PC which does not suffer from signal decay. Though no longer biologically plausible, ePC numerically computes exact PC weights gradients and runs orders of magnitude faster than sPC. Experiments across multiple architectures and datasets demonstrate that ePC matches backpropagation's performance even for deeper models where sPC struggles. Besides practical improvements, our work provides theoretical insight into PC dynamics and establishes a foundation for scaling PC-based learning to deeper architectures on digital hardware and beyond.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.20137.pdf",
    "abs_url": "https://arxiv.org/abs/2505.20137",
    "published": "2025-05-26T15:39:16Z",
    "updated": "2026-02-02T10:42:02Z",
    "comment": "Title & intro change to emphasize PC's hardware-algorithm mismatch, which ePC solves for digital hardware. All code available at https://github.com/cgoemaere/error_based_PC",
    "light_analysis": {
      "overview": "本研究提出了误差预测编码（ePC），解决了传统预测编码在数字硬件上的低效问题，实现了快速且可扩展的深层网络训练。",
      "motivation": "预测编码作为脑启发的神经网络训练方法，是反向传播的替代方案，但在数字硬件上模拟时面临计算量大和可扩展性差的挑战。现有基于状态的预测编码（sPC）存在指数信号衰减问题，导致优化过程停滞，这限制了PC在实际应用中的效率和深层架构的部署，凸显了硬件-算法不匹配的迫切需要解决。",
      "method": "论文通过重新参数化预测编码，提出了基于误差的PC（ePC）。该方法放弃生物学合理性，专注于优化数字模拟效率，避免了信号衰减问题。核心创新是误差基础的设计，使得ePC能够精确计算PC权重梯度，并实现高效计算。研究涉及多架构和数据集的应用，但未指定具体模型细节，重点在于算法层面的改进和数字硬件的适应性。",
      "result": "实验在多种架构和数据集上进行，结果表明ePC与反向传播的性能匹配，即使在深层模型中也能有效工作，而sPC则表现不佳。ePC的运行速度比sPC快几个数量级，具体性能指标摘要未明确说明，但展示了效率和可扩展性的显著提升，为数字硬件上的应用提供了实证支持。",
      "conclusion": "本研究的主要贡献是提出ePC，克服了传统PC在数字硬件上的低效性，并为深层架构的扩展奠定基础。它提供了PC动态的理论见解，具有学术价值；在实际应用中，ePC为高效训练方法开发提供了新途径。局限性在于ePC不再具有生物学合理性，未来工作可探索其在更大规模模型和硬件中的优化应用。",
      "tags": [
        "Predictive Coding",
        "Backpropagation",
        "Digital Hardware",
        "Error-based Reparameterization",
        "Gradient Computation"
      ]
    },
    "analyzed_at": "2026-02-03T04:03:26.310741Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "2505.19653",
    "title": "Token-Importance Guided Direct Preference Optimization",
    "authors": [
      "Ning Yang",
      "Hai Lin",
      "Yibo Liu",
      "Baoliang Tian",
      "Guoqing Liu",
      "Haijun Zhang"
    ],
    "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial for safe and effective AI interactions. While popular methods like Direct Preference Optimization (DPO) have simplified alignment, they remain sensitive to data noise and overlook the differential importance of individual tokens. Existing token-level approaches often rely on probability prediction or simplistic weighting schemes to obtain token importance, which still cannot fully address these issues. To solve this problem, we propose the Token-Importance Guided Direct Preference Optimization (TI-DPO), a framework that achieves fine-grained semantic control through two synergistic innovations. First, we propose a novel hybrid weighting mechanism that combines gradient attribution with a Gaussian prior, ensuring both the accuracy and robustness of token importance scores. Second, we employ a triplet loss to provide structured guidance for the optimization, explicitly guiding model outputs to approach preferred responses and diverge from non-preferred ones. Experimental results show that TI-DPO achieves higher accuracy and stronger generative diversity, providing more stable and computationally efficient solutions compared with DPO and other RLHF methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2505.19653.pdf",
    "abs_url": "https://arxiv.org/abs/2505.19653",
    "published": "2025-05-26T08:11:24Z",
    "updated": "2026-02-02T07:09:20Z",
    "comment": "Accepted in ICLR 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.17779",
    "title": "U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding",
    "authors": [
      "Anjie Le",
      "Henan Liu",
      "Yue Wang",
      "Zhenyu Liu",
      "Rongkun Zhu",
      "Taohan Weng",
      "Jinze Yu",
      "Boyang Wang",
      "Yalun Wu",
      "Kaiwen Yan",
      "Quanlin Sun",
      "Meirui Jiang",
      "Jialun Pei",
      "Siya Liu",
      "Haoyun Zheng",
      "Zhoujun Li",
      "Alison Noble",
      "Jacques Souquet",
      "Xiaoqing Guo",
      "Manxi Lin",
      "Hongcheng Guo"
    ],
    "abstract": "Ultrasound is a widely-used imaging modality critical to global healthcare, yet its interpretation remains challenging due to its varying image quality on operators, noises, and anatomical structures. Although large vision-language models (LVLMs) have demonstrated impressive multimodal capabilities across natural and medical domains, their performance on ultrasound remains largely unexplored. We introduce U2-BENCH, the first comprehensive benchmark to evaluate LVLMs on ultrasound understanding across classification, detection, regression, and text generation tasks. U2-BENCH aggregates 7,241 cases spanning 15 anatomical regions and defines 8 clinically inspired tasks, such as diagnosis, view recognition, lesion localization, clinical value estimation, and report generation, across 50 ultrasound application scenarios. We evaluate 23 state-of-the-art LVLMs, both open- and closed-source, general-purpose and medical-specific. Our results reveal strong performance on image-level classification, but persistent challenges in spatial reasoning and clinical language generation. U2-BENCH establishes a rigorous and unified testbed to assess and accelerate LVLM research in the uniquely multimodal domain of medical ultrasound imaging.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2505.17779.pdf",
    "abs_url": "https://arxiv.org/abs/2505.17779",
    "published": "2025-05-23T11:48:48Z",
    "updated": "2026-02-02T13:10:09Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.16664",
    "title": "HyBattNet: Hybrid Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries",
    "authors": [
      "Khoa Tran",
      "Tri Le",
      "Bao Huynh",
      "Hung-Cuong Trinh",
      "Vy-Rin Nguyen",
      "T. Nguyen-Thoi",
      "Vin Nguyen-Thai"
    ],
    "abstract": "Accurate prediction of the Remaining Useful Life (RUL) is essential for enabling timely maintenance of lithium-ion batteries, impacting the operational efficiency of electric applications that rely on them. This paper proposes a RUL prediction approach that leverages data from recent charge-discharge cycles to estimate the number of remaining usable cycles. The approach introduces both a novel signal preprocessing pipeline and a deep learning prediction model. In the signal preprocessing pipeline, a derived capacity feature is computed using interpolated current and capacity signals. Alongside original capacity, voltage and current, these features are denoised and enhanced using statistical metrics and a delta-based method to capture differences between the current and previous cycles. In the prediction model, the processed features are then fed into a hybrid deep learning architecture composed of 1D Convolutional Neural Networks (CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential Equation-based LSTM (ODE-LSTM) blocks. The ODE-LSTM architecture employs ordinary differential equations to integrate continuous dynamics into sequence-to-sequence modeling, thereby combining continuous and discrete temporal representations, while the A-LSTM incorporates an attention mechanism to capture local temporal dependencies. The model is further evaluated using transfer learning across different learning strategies and target data partitioning scenarios. Results indicate that the model maintains robust performance, even when fine-tuned on limited target data. Experimental results on two publicly available LFP/graphite lithium-ion battery datasets demonstrate that the proposed method outperforms a baseline deep learning approach and machine learning techniques, achieving an RMSE of 101.59, highlighting its potential for real-world RUL prediction applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.16664.pdf",
    "abs_url": "https://arxiv.org/abs/2505.16664",
    "published": "2025-05-22T13:28:18Z",
    "updated": "2026-02-02T07:02:23Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.15386",
    "title": "RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection",
    "authors": [
      "Yiming Huang",
      "Junyan Zhang",
      "Zihao Wang",
      "Biquan Bie",
      "Yunzhong Qiu",
      "Xuming Hu",
      "Yi R. Fung",
      "Xinlei He"
    ],
    "abstract": "Large Language Models (LLMs) have become powerful, but hallucinations remain a vital obstacle to their trustworthy use. Previous works improved the capability of hallucination detection by measuring uncertainty. But they can not explain the provenance behind why hallucinations occur, particularly in identifying which part of the inputs tends to trigger hallucinations. Recent works on the prompt attack indicate that uncertainty exists in semantic propagation, where attention mechanisms gradually fuse local token information into high-level semantics across layers. Meanwhile, uncertainty also emerges in language generation, due to its probability-based selection of high-level semantics for sampled generations. Based on that, we propose RePPL to recalibrate uncertainty measurement by these two aspects, which dispatches explainable uncertainty scores to each token and aggregates in Perplexity-style Log-Average form as a total score. Experiments show that it achieves the best comprehensive detection performance across various QA datasets on advanced models (average AUC of 0.833), and it is capable of producing token-level uncertainty scores as explanations of hallucination.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.15386.pdf",
    "abs_url": "https://arxiv.org/abs/2505.15386",
    "published": "2025-05-21T11:23:05Z",
    "updated": "2026-02-02T07:47:17Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.14226",
    "title": "Code-Mixed Phonetic Perturbations for Red-Teaming LLMs",
    "authors": [
      "Darpan Aswal",
      "Siddharth D Jaiswal"
    ],
    "abstract": "Large language models (LLMs) continue to be demonstrably unsafe despite sophisticated safety alignment techniques and multilingual red-teaming. However, recent red-teaming work has focused on incremental gains in attack success over identifying underlying architectural vulnerabilities in models. In this work, we present \\textbf{CMP-RT}, a novel red-teaming probe that combines code-mixing with phonetic perturbations (CMP), exposing a tokenizer-level safety vulnerability in transformers. Combining realistic elements from digital communication such as code-mixing and textese, CMP-RT preserves phonetics while perturbing safety-critical tokens, allowing harmful prompts to bypass alignment mechanisms while maintaining high prompt interpretability, exposing a gap between pre-training and safety alignment. Our results demonstrate robustness against standard defenses, attack scalability, and generalization of the vulnerability across modalities and to SOTA models like Gemini-3-Pro, establishing CMP-RT as a major threat model and highlighting tokenization as an under-examined vulnerability in current safety pipelines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.14226.pdf",
    "abs_url": "https://arxiv.org/abs/2505.14226",
    "published": "2025-05-20T11:35:25Z",
    "updated": "2026-02-02T11:56:18Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2506.08018",
    "title": "KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache",
    "authors": [
      "Fei Li",
      "Song Liu",
      "Weiguo Wu",
      "Shiqiang Nie",
      "Jinyu Wang"
    ],
    "abstract": "The high memory demands of the Key-Value (KV) Cache during the inference of Large Language Models (LLMs) severely restrict their deployment in resource-constrained platforms. Quantization can effectively alleviate the memory pressure caused by KV Cache. However, existing methods either rely on static one-size-fits-all precision allocation or fail to dynamically prioritize critical KV in long-context tasks, forcing memory-accuracy-throughput tradeoffs. In this work, we propose a novel mixed-precision quantization method for KV Cache named KVmix. KVmix leverages gradient-based importance analysis to evaluate how individual Key and Value projection matrices affect the model loss, enabling layer-specific bit-width allocation for mix-precision quantization. It dynamically prioritizes higher precision for important layers while aggressively quantizing less influential ones, achieving a tunable balance between accuracy and efficiency. KVmix also introduces a dynamic long-context optimization strategy that adaptively keeps full-precision KV pairs for recent pivotal tokens and compresses older ones, achieving high-quality sequence generation with low memory usage. Additionally, KVmix provides efficient low-bit quantization and CUDA kernels to optimize computational overhead. On LLMs such as Llama and Mistral, KVmix achieves near-lossless inference performance with extremely low quantization configuration (Key 2.19bit Value 2.38bit), while delivering a remarkable 4.9x memory compression and a 5.3x speedup in inference throughput.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2506.08018.pdf",
    "abs_url": "https://arxiv.org/abs/2506.08018",
    "published": "2025-05-18T07:04:53Z",
    "updated": "2026-02-02T09:35:31Z",
    "comment": "AAAI 2026 Oral",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.11891",
    "title": "Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents",
    "authors": [
      "Weikai Xu",
      "Zhizheng Jiang",
      "Yuxuan Liu",
      "Pengzhi Gao",
      "Wei Liu",
      "Jian Luan",
      "Yuanchun Li",
      "Yunxin Liu",
      "Bin Wang",
      "Bo An"
    ],
    "abstract": "VLM-based mobile agents are increasingly popular due to their capabilities to interact with smartphone GUIs and XML-structured texts and to complete daily tasks. However, existing online benchmarks struggle with obtaining stable reward signals due to dynamic environmental changes. Offline benchmarks evaluate the agents through single-path trajectories, which stands in contrast to the inherently multi-solution characteristics of GUI tasks. Additionally, both types of benchmarks fail to assess whether mobile agents can handle noise or engage in proactive interactions due to a lack of noisy apps or overly full instructions during the evaluation process. To address these limitations, we use a slot-based instruction generation method to construct a more realistic and comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a common task split, with offline multi-path evaluation to assess the agent's ability to obtain step rewards during task execution. It contains a noisy split based on pop-ups and ads apps, and a contaminated split named AITZ-Noise to formulate a real noisy environment. Furthermore, an ambiguous instruction split with preset Q\\&A interactions is released to evaluate the agent's proactive interaction capabilities. We conduct evaluations on these splits using the single-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2, as well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are available at https://huggingface.co/datasets/xwk123/MobileBench-v2.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2505.11891.pdf",
    "abs_url": "https://arxiv.org/abs/2505.11891",
    "published": "2025-05-17T07:58:34Z",
    "updated": "2026-02-02T06:55:10Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.09134",
    "title": "Scaling Gaussian Process Regression with Full Derivative Observations",
    "authors": [
      "Daniel Huang"
    ],
    "abstract": "We present a scalable Gaussian Process (GP) method called DSoftKI that can fit and predict full derivative observations. It extends SoftKI, a method that approximates a kernel via softmax interpolation, to the setting with derivatives. DSoftKI enhances SoftKI's interpolation scheme by replacing its global temperature vector with local temperature vectors associated with each interpolation point. This modification allows the model to encode local directional sensitivity, enabling the construction of a scalable approximate kernel, including its first and second-order derivatives, through interpolation. Moreover, the interpolation scheme eliminates the need for kernel derivatives, facilitating extensions such as Deep Kernel Learning (DKL). We evaluate DSoftKI on synthetic benchmarks, a toy n-body physics simulation, standard regression datasets with synthetic gradients, and high-dimensional molecular force field prediction (100-1000 dimensions). Our results demonstrate that DSoftKI is accurate and scales to larger datasets with full derivative observations than previously possible.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.09134.pdf",
    "abs_url": "https://arxiv.org/abs/2505.09134",
    "published": "2025-05-14T04:35:26Z",
    "updated": "2026-02-02T04:01:34Z",
    "comment": "13 pages, Published in TMLR",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2505.05064",
    "title": "WaterDrum: Watermarking for Data-centric Unlearning Metric",
    "authors": [
      "Xinyang Lu",
      "Xinyuan Niu",
      "Gregory Kang Ruey Lau",
      "Bui Thi Cam Nhung",
      "Rachael Hwee Ling Sim",
      "John Russell Himawan",
      "Fanyu Wen",
      "Chuan-Sheng Foo",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Large language model (LLM) unlearning is critical in real-world applications where it is necessary to efficiently remove the influence of private, copyrighted, or harmful data from some users. Existing utility-centric unlearning metrics (based on model utility) may fail to accurately evaluate the extent of unlearning in realistic settings such as when the forget and retain sets have semantically similar content and/or retraining the model from scratch on the retain set is impractical. This paper presents the first data-centric unlearning metric for LLMs called WaterDrum that exploits robust text watermarking to overcome these limitations. We introduce new benchmark datasets (with different levels of data similarity) for LLM unlearning that can be used to rigorously evaluate unlearning algorithms via WaterDrum. Our code is available at https://github.com/lululu008/WaterDrum and our new benchmark datasets are released at https://huggingface.co/datasets/Glow-AI/WaterDrum-Ax.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2505.05064.pdf",
    "abs_url": "https://arxiv.org/abs/2505.05064",
    "published": "2025-05-08T08:56:46Z",
    "updated": "2026-02-02T07:45:25Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2504.19110",
    "title": "APE-Bench: Evaluating Automated Proof Engineering for Formal Math Libraries",
    "authors": [
      "Huajian Xin",
      "Luming Li",
      "Xiaoran Jin",
      "Jacques Fleuriot",
      "Wenda Li"
    ],
    "abstract": "While frontier formal mathematics systems now routinely develop repository-scale proof engineering artifacts requiring multi-file coordination and semantic correctness beyond compilation, existing evaluation benchmarks remain focused on isolated theorem proving. We introduce Automated Proof Engineering (APE), the first systematic framework for evaluating repository-scale proof engineering through dual verification that validates both syntactic compilation and semantic requirement satisfaction in pinned library environments. We present a complete infrastructure comprising APE-Bench, which automatically extracts proof engineering tasks from real library commit histories, and APE-Harness, a unified execution framework based on task contract abstraction. This contract-based design enables standardized evaluation across diverse formal mathematics tasks and fair systematic comparison of different agent implementations (including our APE-Agent reference scaffold alongside Claude Code and Codex CLI) on identical task specifications. We demonstrate the framework's effectiveness through comprehensive evaluation. All code and benchmark dataset are released as open-source at https://github.com/xinhjBrant/APE-Bench.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2504.19110.pdf",
    "abs_url": "https://arxiv.org/abs/2504.19110",
    "published": "2025-04-27T05:04:02Z",
    "updated": "2026-02-02T05:16:28Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2504.18881",
    "title": "TSCAN: Context-Aware Uplift Modeling via Two-Stage Training for Online Merchant Business Diagnosis",
    "authors": [
      "Hangtao Zhang",
      "Zhe Li",
      "Kairui Zhang"
    ],
    "abstract": "A primary challenge in ITE estimation is sample selection bias. Traditional approaches utilize treatment regularization techniques such as the Integral Probability Metrics (IPM), re-weighting, and propensity score modeling to mitigate this bias. However, these regularizations may introduce undesirable information loss and limit the performance of the model. Furthermore, treatment effects vary across different external contexts, and the existing methods are insufficient in fully interacting with and utilizing these contextual features. To address these issues, we propose a Context-Aware uplift model based on the Two-Stage training approach (TSCAN), comprising CAN-U and CAN-D sub-models. In the first stage, we train an uplift model, called CAN-U, which includes the treatment regularizations of IPM and propensity score prediction, to generate a complete dataset with counterfactual uplift labels. In the second stage, we train a model named CAN-D, which utilizes an isotonic output layer to directly model uplift effects, thereby eliminating the reliance on the regularization components. CAN-D adaptively corrects the errors estimated by CAN-U through reinforcing the factual samples, while avoiding the negative impacts associated with the aforementioned regularizations. Additionally, we introduce a Context-Aware Attention Layer throughout the two-stage process to manage the interactions between treatment, merchant, and contextual features, thereby modeling the varying treatment effect in different contexts. We conduct extensive experiments on two real-world datasets to validate the effectiveness of TSCAN. Ultimately, the deployment of our model for real-world merchant diagnosis on one of China's largest online food ordering platforms validates its practical utility and impact.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2504.18881.pdf",
    "abs_url": "https://arxiv.org/abs/2504.18881",
    "published": "2025-04-26T10:00:16Z",
    "updated": "2026-02-02T08:36:11Z",
    "comment": "15 pages,7 figures",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2504.16063",
    "title": "Free Access to World News: Reconstructing Full-Text Articles from GDELT",
    "authors": [
      "A. Fronzetti Colladon",
      "R. Vestrelli"
    ],
    "abstract": "News data have become essential resources across various disciplines. Still, access to full-text news corpora remains challenging due to high costs and the limited availability of free alternatives. This paper presents a novel Python package (gdeltnews) that reconstructs full-text newspaper articles at near-zero cost by leveraging the Global Database of Events, Language, and Tone (GDELT) Web News NGrams 3.0 dataset. Our method merges overlapping n-grams extracted from global online news to rebuild complete articles. We validate the approach on a benchmark set of 2211 articles from major U.S. news outlets, achieving up to 95% text similarity against original articles based on Levenshtein and SequenceMatcher metrics. Our tool facilitates economic forecasting, computational social science, information science, and natural language processing applications by enabling free and large-scale access to full-text news data.",
    "categories": [
      "cs.CL",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2504.16063.pdf",
    "abs_url": "https://arxiv.org/abs/2504.16063",
    "published": "2025-04-22T17:40:42Z",
    "updated": "2026-02-02T12:45:11Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2504.05711",
    "title": "Automated Archival Descriptions with Federated Intelligence of LLMs",
    "authors": [
      "Jinghua Groppe",
      "Andreas Marquet",
      "Annabel Walz",
      "Sven Groppe"
    ],
    "abstract": "Enforcing archival standards requires specialized expertise, and manually creating metadata descriptions for archival materials is a tedious and error-prone task. This work aims at exploring the potential of agentic AI and large language models (LLMs) in addressing the challenges of implementing a standardized archival description process. To this end, we introduce an agentic AI-driven system for automated generation of high-quality metadata descriptions of archival materials. We develop a federated optimization approach that unites the intelligence of multiple LLMs to construct optimal archival metadata. We also suggest methods to overcome the challenges associated with using LLMs for consistent metadata generation. To evaluate the feasibility and effectiveness of our techniques, we conducted extensive experiments using a real-world dataset of archival materials, which covers a variety of document types and formats. The evaluation results demonstrate the feasibility of our techniques and highlight the superior performance of the federated optimization approach compared to single-model solutions in metadata quality and reliability.",
    "categories": [
      "cs.AI",
      "cs.DL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2504.05711.pdf",
    "abs_url": "https://arxiv.org/abs/2504.05711",
    "published": "2025-04-08T06:11:05Z",
    "updated": "2026-02-02T09:43:35Z",
    "comment": "16 pages",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2504.05520",
    "title": "Efficient Reinforcement Finetuning via Adaptive Curriculum Learning",
    "authors": [
      "Taiwei Shi",
      "Yiyang Wu",
      "Linxin Song",
      "Tianyi Zhou",
      "Jieyu Zhao"
    ],
    "abstract": "Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a method that significantly improves both the efficiency and final accuracy of RFT through adaptive curriculum learning. AdaRFT dynamically adjusts the difficulty of training problems based on the model's recent reward signals, ensuring that the model consistently trains on tasks that are challenging but solvable. This adaptive sampling strategy accelerates learning by maintaining an optimal difficulty range, avoiding wasted computation on problems that are too easy or too hard. AdaRFT requires only a lightweight extension to standard RFT algorithms like Proximal Policy Optimization (PPO), without modifying the reward function or model architecture. Experiments on competition-level math datasets demonstrate that AdaRFT significantly improves both training efficiency and reasoning performance. We evaluate AdaRFT across multiple data distributions and model sizes, showing that it reduces training time by up to 2x and improves accuracy by a considerable margin, offering a more scalable and effective RFT framework.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2504.05520.pdf",
    "abs_url": "https://arxiv.org/abs/2504.05520",
    "published": "2025-04-07T21:31:31Z",
    "updated": "2026-02-02T04:04:08Z",
    "comment": "23 pages, 8 figures, 7 tables",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2504.01842",
    "title": "shapr: Explaining Machine Learning Models with Conditional Shapley Values in R and Python",
    "authors": [
      "Martin Jullum",
      "Lars Henry Berge Olsen",
      "Jon Lachmann",
      "Annabelle Redelmeier"
    ],
    "abstract": "This paper introduces the shapr R package, a versatile tool for generating Shapley value-based prediction explanations for machine learning and statistical regression models. Moreover, the shaprpy Python library brings the core capabilities of shapr to the Python ecosystem. Shapley values originate from cooperative game theory in the 1950s, but have over the past few years become a widely used method for quantifying how a model's features/covariates contribute to specific prediction outcomes. The shapr package emphasizes conditional Shapley value estimates, providing a comprehensive range of approaches for accurately capturing feature dependencies -- a crucial aspect for correct model explanation, typically lacking in similar software. In addition to regular tabular data, the shapr R package includes specialized functionality for explaining time series forecasts. The package offers a minimal set of user functions with sensible default values for most use cases while providing extensive flexibility for advanced users to fine-tune computations. Additional features include parallelized computations, iterative estimation with convergence detection, and rich visualization tools. shapr also extends its functionality to compute causal and asymmetric Shapley values when causal information is available. Overall, the shapr and shaprpy packages aim to enhance the interpretability of predictive models within a powerful and user-friendly framework.",
    "categories": [
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2504.01842.pdf",
    "abs_url": "https://arxiv.org/abs/2504.01842",
    "published": "2025-04-02T15:47:30Z",
    "updated": "2026-02-02T08:31:40Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2503.24047",
    "title": "Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents",
    "authors": [
      "Shuo Ren",
      "Can Xie",
      "Pu Jian",
      "Zhenjiang Ren",
      "Chunlin Leng",
      "Jiajun Zhang"
    ],
    "abstract": "As scientific research becomes increasingly complex, innovative tools are needed to manage vast data, facilitate interdisciplinary collaboration, and accelerate discovery. Large language models (LLMs) are now evolving into LLM-based scientific agents that automate critical tasks ranging from hypothesis generation and experiment design to data analysis and simulation. Unlike general-purpose LLMs, these specialized agents integrate domain-specific knowledge, advanced tool sets, and robust validation mechanisms, enabling them to handle complex data types, ensure reproducibility, and drive scientific breakthroughs. This survey provides a focused review of the architectures, design, benchmarks, applications, and ethical considerations surrounding LLM-based scientific agents. We highlight why they differ from general agents and the ways in which they advance research across various scientific fields. By examining their development and challenges, this survey offers a comprehensive roadmap for researchers and practitioners to harness these agents for more efficient, reliable, and ethically sound scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2503.24047.pdf",
    "abs_url": "https://arxiv.org/abs/2503.24047",
    "published": "2025-03-31T13:11:28Z",
    "updated": "2026-02-02T06:26:53Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2503.17279",
    "title": "CASE -- Condition-Aware Sentence Embeddings for Conditional Semantic Textual Similarity Measurement",
    "authors": [
      "Gaifan Zhang",
      "Yi Zhou",
      "Danushka Bollegala"
    ],
    "abstract": "The meaning conveyed by a sentence often depends on the context in which it appears. Despite the progress of sentence embedding methods, it remains unclear as how to best modify a sentence embedding conditioned on its context. To address this problem, we propose Condition-Aware Sentence Embeddings (CASE), an efficient and accurate method to create an embedding for a sentence under a given condition. First, CASE creates an embedding for the condition using a Large Language Model (LLM) encoder, where the sentence influences the attention scores computed for the tokens in the condition during pooling. Next, a supervised method is learnt to align the LLM-based text embeddings with the Conditional Semantic Textual Similarity (C-STS) task. We find that subtracting the condition embedding consistently improves the C-STS performance of LLM-based text embeddings by improving the isotropy of the embedding space. Moreover, our supervised projection method significantly improves the performance of LLM-based embeddings despite requiring a small number of embedding dimensions.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2503.17279.pdf",
    "abs_url": "https://arxiv.org/abs/2503.17279",
    "published": "2025-03-21T16:27:12Z",
    "updated": "2026-02-02T09:51:47Z",
    "comment": "Accepted to EACL2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2503.16553",
    "title": "A Foundational individual Mobility Prediction Model based on Open-Source Large Language Models",
    "authors": [
      "Zhenlin Qin",
      "Leizhen Wang",
      "Francisco Camara Pereira",
      "Zhenliang Ma"
    ],
    "abstract": "Large Language Models (LLMs) are widely applied to domain-specific tasks due to their massive general knowledge and remarkable inference capacities. Current studies on LLMs have shown immense potential in applying LLMs to model individual mobility prediction problems. However, most LLM-based mobility prediction models only train on specific datasets or use single well-designed prompts, leading to difficulty in adapting to different cities and users with diverse contexts. To fill these gaps, this paper proposes a unified fine-tuning framework to train a foundational open source LLM-based mobility prediction model. We conducted extensive experiments on six real-world mobility datasets to validate the proposed model. The results showed that the proposed model achieved the best performance in prediction accuracy and transferability over state-of-the-art models based on deep learning and LLMs.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2503.16553.pdf",
    "abs_url": "https://arxiv.org/abs/2503.16553",
    "published": "2025-03-19T15:08:37Z",
    "updated": "2026-02-02T09:08:26Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2503.10304",
    "title": "Large-Scale Auto-bidding with Nash Equilibrium Constraints",
    "authors": [
      "Zhiyu Mou",
      "Miao Xu",
      "Rongquan Bai",
      "Zhuoran Yang",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "abstract": "Auto-bidding has become a cornerstone of modern online advertising platforms, enabling many advertisers to automate bidding at scale and optimize campaign performance. However, prevailing industrial systems rely on single-agent auto-bidding methods that are scalable but overlook the strategic interdependence among advertisers' bids, leading to unstable or suboptimal outcomes. While recent works recognize the game-theoretic nature of auto-bidding, existing approaches remain either computationally intractable at scale or lack a principled equilibrium-selection that aligns with platform-wide objectives. In this paper, we bridge this gap by introducing Nash Equilibrium-Constrained Bidding (NCB), a principled and scalable auto-bidding framework that recasts auto-bidding as a platform-wide optimization problem subject to Nash equilibrium constraints. This approach accounts for fine-grained strategic interdependencies among advertisers, ensuring both agent-level stability and ecosystem-level optimality. Notably, we develop a theoretically sound penalty-based primal-dual gradient method with rigorous convergence guarantees, supported by an efficient algorithm suitable for industrial deployment. Extensive experiments validate the effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2503.10304.pdf",
    "abs_url": "https://arxiv.org/abs/2503.10304",
    "published": "2025-03-13T12:25:36Z",
    "updated": "2026-02-02T03:19:54Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2503.09701",
    "title": "Reassessing Active Learning Adoption in Contemporary NLP: A Community Survey",
    "authors": [
      "Julia Romberg",
      "Christopher Schröder",
      "Julius Gonsior",
      "Katrin Tomanek",
      "Fredrik Olsson"
    ],
    "abstract": "Supervised learning relies on data annotation which usually is time-consuming and therefore expensive. A longstanding strategy to reduce annotation costs is active learning, an iterative process, in which a human annotates only data instances deemed informative by a model. Research in active learning has made considerable progress, especially with the rise of large language models (LLMs). However, we still know little about how these remarkable advances have translated into real-world applications, or contributed to removing key barriers to active learning adoption. To fill in this gap, we conduct an online survey in the NLP community to collect previously intangible insights on current implementation practices, common obstacles in application, and future prospects in active learning. We also reassess the perceived relevance of data annotation and active learning as fundamental assumptions. Our findings show that data annotation is expected to remain important and active learning to stay relevant while benefiting from LLMs. Consistent with a community survey from over 15 years ago, three key challenges yet persist -- setup complexity, uncertain cost reduction, and tooling -- for which we propose alleviation strategies. We publish an anonymized version of the dataset.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2503.09701.pdf",
    "abs_url": "https://arxiv.org/abs/2503.09701",
    "published": "2025-03-12T18:00:04Z",
    "updated": "2026-02-02T09:14:57Z",
    "comment": "EACL 2026 Main Conference",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2502.12769",
    "title": "How Much Do LLMs Hallucinate across Languages? On Realistic Multilingual Estimation of LLM Hallucination",
    "authors": [
      "Saad Obaid ul Islam",
      "Anne Lauscher",
      "Goran Glavaš"
    ],
    "abstract": "In the age of misinformation, hallucination - the tendency of Large Language Models (LLMs) to generate non-factual or unfaithful responses - represents the main risk for their global utility. Despite LLMs becoming increasingly multilingual, the vast majority of research on detecting and quantifying LLM hallucination are (a) English-centric and (b) focus on machine translation (MT) and summarization, tasks that are less common in realistic settings than open information seeking. In contrast, we aim to quantify the extent of LLM hallucination across languages in knowledge-intensive long-form question answering (LFQA). To this end, we train a multilingual hallucination detection model and conduct a large-scale study across 30 languages and 6 open-source LLM families. We start from an English hallucination detection dataset and rely on MT to translate-train a detection model. We also manually annotate gold data for five high-resource languages; we then demonstrate, for these languages, that the estimates of hallucination rates are similar between silver (LLM-generated) and gold test sets, validating the use of silver data for estimating hallucination rates for other languages. For the final rates estimation, we build open-domain QA dataset for 30 languages with LLM-generated prompts and Wikipedia articles as references. Our analysis shows that LLMs, in absolute terms, hallucinate more tokens in high-resource languages due to longer responses, but that the actual hallucination rates (i.e., normalized for length) seems uncorrelated with the sizes of languages' digital footprints. We also find that smaller LLMs hallucinate more, and significantly, LLMs with broader language support display higher hallucination rates.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2502.12769.pdf",
    "abs_url": "https://arxiv.org/abs/2502.12769",
    "published": "2025-02-18T11:32:43Z",
    "updated": "2026-02-02T10:18:10Z",
    "comment": "EMNLP 2025",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2502.11367",
    "title": "Sparse Autoencoder Features for Classifications and Transferability",
    "authors": [
      "Jack Gallifant",
      "Shan Chen",
      "Kuleen Sasse",
      "Hugo Aerts",
      "Thomas Hartvigsen",
      "Danielle S. Bitterman"
    ],
    "abstract": "Sparse Autoencoders (SAEs) provide potentials for uncovering structured, human-interpretable representations in Large Language Models (LLMs), making them a crucial tool for transparent and controllable AI systems. We systematically analyze SAE for interpretable feature extraction from LLMs in safety-critical classification tasks. Our framework evaluates (1) model-layer selection and scaling properties, (2) SAE architectural configurations, including width and pooling strategies, and (3) the effect of binarizing continuous SAE activations. SAE-derived features achieve macro F1 > 0.8, outperforming hidden-state and BoW baselines while demonstrating cross-model transfer from Gemma 2 2B to 9B-IT models. These features generalize in a zero-shot manner to cross-lingual toxicity detection and visual classification tasks. Our analysis highlights the significant impact of pooling strategies and binarization thresholds, showing that binarization offers an efficient alternative to traditional feature selection while maintaining or improving performance. These findings establish new best practices for SAE-based interpretability and enable scalable, transparent deployment of LLMs in real-world applications. Full repo: https://github.com/shan23chen/MOSAIC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2502.11367.pdf",
    "abs_url": "https://arxiv.org/abs/2502.11367",
    "published": "2025-02-17T02:30:45Z",
    "updated": "2026-02-02T08:18:48Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2502.10028",
    "title": "3D Dynamics-Aware Manipulation: Endowing Manipulation Policies with 3D Foresight",
    "authors": [
      "Yuxin He",
      "Ruihao Zhang",
      "Xianzu Wu",
      "Zhiyuan Zhang",
      "Cheng Ding",
      "Qiang Nie"
    ],
    "abstract": "The incorporation of world modeling into manipulation policy learning has pushed the boundary of manipulation performance. However, existing efforts simply model the 2D visual dynamics, which is insufficient for robust manipulation when target tasks involve prominent depth-wise movement. To address this, we present a 3D dynamics-aware manipulation framework that seamlessly integrates 3D world modeling and policy learning. Three self-supervised learning tasks (current depth estimation, future RGB-D prediction, 3D flow prediction) are introduced within our framework, which complement each other and endow the policy model with 3D foresight. Extensive experiments on simulation and the real world show that 3D foresight can greatly boost the performance of manipulation policies without sacrificing inference speed. Code is available at https://github.com/Stardust-hyx/3D-Foresight.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2502.10028.pdf",
    "abs_url": "https://arxiv.org/abs/2502.10028",
    "published": "2025-02-14T09:13:57Z",
    "updated": "2026-02-02T10:52:49Z",
    "comment": "ICRA 2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2502.04528",
    "title": "Group-Adaptive Threshold Optimization for Robust AI-Generated Text Detection",
    "authors": [
      "Minseok Jung",
      "Cynthia Fuertes Panizo",
      "Liam Dugan",
      "Yi R.",
      "Fung",
      "Pin-Yu Chen",
      "Paul Pu Liang"
    ],
    "abstract": "The advancement of large language models (LLMs) has made it difficult to differentiate human-written text from AI-generated text. Several AI-text detectors have been developed in response, which typically utilize a fixed global threshold (e.g., $θ= 0.5$) to classify machine-generated text. However, one universal threshold could fail to account for distributional variations by subgroups. For example, when using a fixed threshold, detectors make more false positive errors on shorter human-written text, and more positive classifications of neurotic writing styles among long texts. These discrepancies can lead to misclassifications that disproportionately affect certain groups. We address this critical limitation by introducing FairOPT, an algorithm for group-specific threshold optimization for probabilistic AI-text detectors. We partitioned data into subgroups based on attributes (e.g., text length and writing style) and implemented FairOPT to learn decision thresholds for each group to reduce discrepancy. FairOPT showed notable discrepancy mitigation across nine detectors and three heterogeneous datasets, and the remarkable mitigation of the minimax problem by decreasing overall discrepancy 27.4% across five metrics while minimally sacrificing accuracy by 0.005%. Our framework paves the way for more robust classification in AI-generated content detection via post-processing. We release our data, code, and project information at URL.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "pdf_url": "https://arxiv.org/pdf/2502.04528.pdf",
    "abs_url": "https://arxiv.org/abs/2502.04528",
    "published": "2025-02-06T21:58:48Z",
    "updated": "2026-02-02T03:22:35Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2501.07809",
    "title": "Conformal mapping based Physics-informed neural networks for designing neutral inclusions",
    "authors": [
      "Daehee Cho",
      "Hyeonmin Yun",
      "Jaeyong Lee",
      "Mikyoung Lim"
    ],
    "abstract": "We address the neutral inclusion problem with imperfect boundary conditions, focusing on designing interface functions for inclusions of arbitrary shapes. Traditional Physics-Informed Neural Networks (PINNs) struggle with this inverse problem, leading to the development of Conformal Mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs), which integrate geometric function theory with PINNs. CoCo-PINNs effectively solve forward-inverse problems by modeling the interface function through neural network training, which yields a neutral inclusion effect. This approach enhances the performance of PINNs in terms of credibility, consistency, and stability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2501.07809.pdf",
    "abs_url": "https://arxiv.org/abs/2501.07809",
    "published": "2025-01-14T03:20:17Z",
    "updated": "2026-02-02T10:01:54Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2501.07114",
    "title": "Semantically Guided Dynamic Visual Prototype Refinement for Compositional Zero-Shot Learning",
    "authors": [
      "Zhong Peng",
      "Yishi Xu",
      "Gerong Wang",
      "Wenchao Chen",
      "Bo Chen",
      "Jing Zhang",
      "Hongwei Liu"
    ],
    "abstract": "Compositional Zero-Shot Learning (CZSL) seeks to recognize unseen state-object pairs by recombining primitives learned from seen compositions. Despite recent progress with vision-language models (VLMs), two limitations remain: (i) text-driven semantic prototypes are weakly discriminative in the visual feature space; and (ii) unseen pairs are optimized passively, thereby inducing seen bias. To address these limitations, we present Duplex, a framework that couples dual-prototype learning with dynamic local-graph refinement of visual prototypes. For each composition, Duplex maintains a semantic prototype via prompt learning and a visual prototype for unseen pairs constructed by recombining disentangled state and object primitives from seen images. The visual prototypes are updated dynamically through lightweight aggregation on mini-batch local graphs, which incorporates unseen compositions during training without labels. This design introduces fine-grained visual evidence while preserving semantic structure. It enriches class prototypes, better disambiguates semantically similar yet visually distinct pairs, and mitigates seen bias. Experiments on MIT-States, UT-Zappos, and CGQA in closed-world and open-world settings achieve competitive performance and consistent compositional generalization. Our source code is available at https://github.com/ISPZ/Duplex-CZSL.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2501.07114.pdf",
    "abs_url": "https://arxiv.org/abs/2501.07114",
    "published": "2025-01-13T08:04:32Z",
    "updated": "2026-02-02T03:09:49Z",
    "comment": "Accepted for publication in Neurocomputing",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2412.13526",
    "title": "MOMA: Masked Orthogonal Matrix Alignment for Zero-Additional-Parameter Model Merging",
    "authors": [
      "Fanshuang Kong",
      "Richong Zhang",
      "Zhijie Nie",
      "Hang Zhou",
      "Ziqiao Wang",
      "Qiang Sun",
      "Chunming Hu"
    ],
    "abstract": "Model merging offers a scalable alternative to multi-task learning but often yields suboptimal performance on classification tasks. We attribute this degradation to a geometric misalignment between the merged encoder and static task-specific classifier heads. Existing methods typically rely on auxiliary parameters to enforce strict representation alignment. We challenge this approach by revealing that the misalignment is predominantly an orthogonal transformation, rendering such strict alignment unnecessary. Leveraging this insight, we propose MOMA (Masked Orthogonal Matrix Alignment), which rectifies the misalignment by jointly optimizing a global multi-task vector mask and task-specific orthogonal transformations. Crucially, MOMA absorbs corresponding new parameters directly into the existing model weights, achieving performance comparable to state-of-the-art baselines with zero additional parameters and zero added inference cost.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2412.13526.pdf",
    "abs_url": "https://arxiv.org/abs/2412.13526",
    "published": "2024-12-18T05:53:15Z",
    "updated": "2026-02-02T10:03:31Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2412.09606",
    "title": "Feat2GS: Probing Visual Foundation Models with Gaussian Splatting",
    "authors": [
      "Yue Chen",
      "Xingyu Chen",
      "Anpei Chen",
      "Gerard Pons-Moll",
      "Yuliang Xiu"
    ],
    "abstract": "Given that visual foundation models (VFMs) are trained on extensive datasets but often limited to 2D images, a natural question arises: how well do they understand the 3D world? With the differences in architecture and training protocols (i.e., objectives, proxy tasks), a unified framework to fairly and comprehensively probe their 3D awareness is urgently needed. Existing works on 3D probing suggest single-view 2.5D estimation (e.g., depth and normal) or two-view sparse 2D correspondence (e.g., matching and tracking). Unfortunately, these tasks ignore texture awareness, and require 3D data as ground-truth, which limits the scale and diversity of their evaluation set. To address these issues, we introduce Feat2GS, which readout 3D Gaussians attributes from VFM features extracted from unposed images. This allows us to probe 3D awareness for geometry and texture via novel view synthesis, without requiring 3D data. Additionally, the disentanglement of 3DGS parameters - geometry ($\\boldsymbol{x}$, $α$, $Σ$) and texture ($\\boldsymbol{c}$) - enables separate analysis of texture and geometry awareness. Under Feat2GS, we conduct extensive experiments to probe the 3D awareness of several VFMs, and investigate the ingredients that lead to a 3D aware VFM. Building on these findings, we develop several variants that achieve state-of-the-art across diverse datasets. This makes Feat2GS useful for probing VFMs, and as a simple-yet-effective baseline for novel-view synthesis. Code and data are available at https://fanegg.github.io/Feat2GS/.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2412.09606.pdf",
    "abs_url": "https://arxiv.org/abs/2412.09606",
    "published": "2024-12-12T18:59:28Z",
    "updated": "2026-02-02T09:20:50Z",
    "comment": "Project Page: https://fanegg.github.io/Feat2GS/",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2411.10701",
    "title": "Diffusion-based Layer-wise Semantic Reconstruction for Unsupervised Out-of-Distribution Detection",
    "authors": [
      "Ying Yang",
      "De Cheng",
      "Chaowei Fang",
      "Yubiao Wang",
      "Changzhe Jiao",
      "Lechao Cheng",
      "Nannan Wang"
    ],
    "abstract": "Unsupervised out-of-distribution (OOD) detection aims to identify out-of-domain data by learning only from unlabeled In-Distribution (ID) training samples, which is crucial for developing a safe real-world machine learning system. Current reconstruction-based methods provide a good alternative approach by measuring the reconstruction error between the input and its corresponding generative counterpart in the pixel/feature space. However, such generative methods face a key dilemma: improving the reconstruction power of the generative model while keeping a compact representation of the ID data. To address this issue, we propose the diffusion-based layer-wise semantic reconstruction approach for unsupervised OOD detection. The innovation of our approach is that we leverage the diffusion model's intrinsic data reconstruction ability to distinguish ID samples from OOD samples in the latent feature space. Moreover, to set up a comprehensive and discriminative feature representation, we devise a multi-layer semantic feature extraction strategy. By distorting the extracted features with Gaussian noise and applying the diffusion model for feature reconstruction, the separation of ID and OOD samples is implemented according to the reconstruction errors. Extensive experimental results on multiple benchmarks built upon various datasets demonstrate that our method achieves state-of-the-art performance in terms of detection accuracy and speed. Code is available at <https://github.com/xbyym/DLSR>.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.10701.pdf",
    "abs_url": "https://arxiv.org/abs/2411.10701",
    "published": "2024-11-16T04:54:07Z",
    "updated": "2026-02-02T09:43:02Z",
    "comment": "26 pages, 23 figures, published to Neurlps2024",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2411.06501",
    "title": "Individual Regret in Cooperative Stochastic Multi-Armed Bandits",
    "authors": [
      "Idan Barnea",
      "Tal Lancewicki",
      "Yishay Mansour"
    ],
    "abstract": "We study the regret in stochastic Multi-Armed Bandits (MAB) with multiple agents that communicate over an arbitrary connected communication graph. We analyzed a variant of Cooperative Successive Elimination algorithm, $\\coopse$, and show an individual regret bound of ${O}(\\mathcal{R} / m + A^2 + A \\sqrt{\\log T})$ and a nearly matching lower bound. Here $A$ is the number of actions, $T$ the time horizon, $m$ the number of agents, and $\\mathcal{R} = \\sum_{Δ_i > 0}\\log(T)/Δ_i$ is the optimal single agent regret, where $Δ_i$ is the sub-optimality gap of action $i$. Our work is the first to show an individual regret bound in cooperative stochastic MAB that is independent of the graph's diameter.   When considering communication networks there are additional considerations beyond regret, such as message size and number of communication rounds. First, we show that our regret bound holds even if we restrict the messages to be of logarithmic size. Second, for logarithmic number of communication rounds, we obtain a regret bound of ${O}(\\mathcal{R} / m+A \\log T)$.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2411.06501.pdf",
    "abs_url": "https://arxiv.org/abs/2411.06501",
    "published": "2024-11-10T15:54:23Z",
    "updated": "2026-02-02T12:12:12Z",
    "comment": "55 pages, 1 figure",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2411.02843",
    "title": "Advances in Photoacoustic Imaging Reconstruction and Quantitative Analysis for Biomedical Applications",
    "authors": [
      "Lei Wang",
      "Weiming Zeng",
      "Kai Long",
      "Hongyu Chen",
      "Rongfeng Lan",
      "Li Liu",
      "Wai Ting Siok",
      "Nizhuan Wang"
    ],
    "abstract": "Photoacoustic imaging (PAI) represents an innovative biomedical imaging modality that harnesses the advantages of optical resolution and acoustic penetration depth while ensuring enhanced safety. Despite its promising potential across a diverse array of preclinical and clinical applications, the clinical implementation of PAI faces significant challenges, including the trade-off between penetration depth and spatial resolution, as well as the demand for faster imaging speeds. This paper explores the fundamental principles underlying PAI, with a particular emphasis on three primary implementations: photoacoustic computed tomography (PACT), photoacoustic microscopy (PAM), and photoacoustic endoscopy (PAE). We undertake a critical assessment of their respective strengths and practical limitations. Furthermore, recent developments in utilizing conventional or deep learning (DL) methodologies for image reconstruction and artefact mitigation across PACT, PAM, and PAE are outlined, demonstrating considerable potential to enhance image quality and accelerate imaging processes. Furthermore, this paper examines the recent developments in quantitative analysis within PAI, including the quantification of haemoglobin concentration, oxygen saturation, and other physiological parameters within tissues. Finally, our discussion encompasses current trends and future directions in PAI research while emphasizing the transformative impact of deep learning on advancing PAI.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2411.02843.pdf",
    "abs_url": "https://arxiv.org/abs/2411.02843",
    "published": "2024-11-05T06:31:48Z",
    "updated": "2026-02-02T03:07:35Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2409.13363",
    "title": "FPBoost: Fully Parametric Gradient Boosting for Survival Analysis",
    "authors": [
      "Alberto Archetti",
      "Eugenio Lomurno",
      "Diego Piccinotti",
      "Matteo Matteucci"
    ],
    "abstract": "Survival analysis is a statistical framework for modeling time-to-event data. It plays a pivotal role in medicine, reliability engineering, and social science research, where understanding event dynamics even with few data samples is critical. Recent advancements in machine learning, particularly those employing neural networks and decision trees, have introduced sophisticated algorithms for survival modeling. However, many of these methods rely on restrictive assumptions about the underlying event-time distribution, such as proportional hazard, time discretization, or accelerated failure time. In this study, we propose FPBoost, a survival model that combines a weighted sum of fully parametric hazard functions with gradient boosting. Distribution parameters are estimated with decision trees trained by maximizing the full survival likelihood. We show how FPBoost is a universal approximator of hazard functions, offering full event-time modeling flexibility while maintaining interpretability through the use of well-established parametric distributions. We evaluate concordance and calibration of FPBoost across multiple benchmark datasets, showcasing its robustness and versatility as a new tool for survival estimation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2409.13363.pdf",
    "abs_url": "https://arxiv.org/abs/2409.13363",
    "published": "2024-09-20T09:57:17Z",
    "updated": "2026-02-02T11:17:40Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2409.09777",
    "title": "EgoFSD: Ego-Centric Fully Sparse Paradigm with Uncertainty Denoising and Iterative Refinement for Efficient End-to-End Self-Driving",
    "authors": [
      "Haisheng Su",
      "Wei Wu",
      "Zhenjie Yang",
      "Isabel Guan"
    ],
    "abstract": "Current End-to-End Autonomous Driving (E2E-AD) methods resort to unifying modular designs for various tasks (e.g. perception, prediction and planning). Although optimized with a fully differentiable framework in a planning-oriented manner, existing end-to-end driving systems lacking ego-centric designs still suffer from unsatisfactory performance and inferior efficiency, due to rasterized scene representation learning and redundant information transmission. In this paper, we propose an ego-centric fully sparse paradigm, named EgoFSD, for end-to-end self-driving. Specifically, EgoFSD consists of sparse perception, hierarchical interaction and iterative motion planner. The sparse perception module performs detection and online mapping based on sparse representation of the driving scene. The hierarchical interaction module aims to select the Closest In-Path Vehicle / Stationary (CIPV / CIPS) from coarse to fine, benefiting from an additional geometric prior. As for the iterative motion planner, both selected interactive agents and ego-vehicle are considered for joint motion prediction, where the output multi-modal ego-trajectories are optimized in an iterative fashion. In addition, position-level motion diffusion and trajectory-level planning denoising are introduced for uncertainty modeling, thereby enhancing the training stability and convergence speed. Extensive experiments are conducted on nuScenes and Bench2Drive datasets, which significantly reduces the average L2 error by 59% and collision rate by 92% than UniAD while achieves 6.9x faster running efficiency.",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2409.09777.pdf",
    "abs_url": "https://arxiv.org/abs/2409.09777",
    "published": "2024-09-15T15:55:24Z",
    "updated": "2026-02-02T08:17:02Z",
    "comment": "Accepted to ICRA2026",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2406.09260",
    "title": "Deep Transformer Network for Monocular Pose Estimation of Shipborne Unmanned Aerial Vehicle",
    "authors": [
      "Maneesha Wickramasuriya",
      "Taeyoung Lee",
      "Murray Snyder"
    ],
    "abstract": "This paper introduces a deep transformer network for estimating the relative 6D pose of a Unmanned Aerial Vehicle (UAV) with respect to a ship using monocular images. A synthetic dataset of ship images is created and annotated with 2D keypoints of multiple ship parts. A Transformer Neural Network model is trained to detect these keypoints and estimate the 6D pose of each part. The estimates are integrated using Bayesian fusion. The model is tested on synthetic data and in-situ flight experiments, demonstrating robustness and accuracy in various lighting conditions. The position estimation error is approximately 0.8\\% and 1.0\\% of the distance to the ship for the synthetic data and the flight experiments, respectively. The method has potential applications for ship-based autonomous UAV landing and navigation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2406.09260.pdf",
    "abs_url": "https://arxiv.org/abs/2406.09260",
    "published": "2024-06-13T16:01:22Z",
    "updated": "2026-02-02T03:09:37Z",
    "comment": "23 pages, 25 figures, 3 tables",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2311.18547",
    "title": "Real-Time Vibration-Based Bearing Fault Diagnosis Under Time-Varying Speed Conditions",
    "authors": [
      "Tuomas Jalonen",
      "Mohammad Al-Sa'd",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "abstract": "Detection of rolling-element bearing faults is crucial for implementing proactive maintenance strategies and for minimizing the economic and operational consequences of unexpected failures. However, many existing techniques are developed and tested under strictly controlled conditions, limiting their adaptability to the diverse and dynamic settings encountered in practical applications. This paper presents an efficient real-time convolutional neural network (CNN) for diagnosing multiple bearing faults under various noise levels and time-varying rotational speeds. Additionally, we propose a novel Fisher-based spectral separability analysis (SSA) method to elucidate the effectiveness of the designed CNN model. We conducted experiments on both healthy bearings and bearings afflicted with inner race, outer race, and roller ball faults. The experimental results show the superiority of our model over the current state-of-the-art approach in three folds: it achieves substantial accuracy gains of up to 15.8%, it is robust to noise with high performance across various signal-to-noise ratios, and it runs in real-time with processing durations five times less than acquisition. Additionally, by using the proposed SSA technique, we offer insights into the model's performance and underscore its effectiveness in tackling real-world challenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2311.18547.pdf",
    "abs_url": "https://arxiv.org/abs/2311.18547",
    "published": "2023-11-30T13:30:00Z",
    "updated": "2026-02-02T12:39:06Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "2309.16146",
    "title": "T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems",
    "authors": [
      "Ming Wang",
      "Daling Wang",
      "Wenfang Wu",
      "Shi Feng",
      "Yifei Zhang"
    ],
    "abstract": "To address the interpretability challenge in machine learning (ML) systems, counterfactual explanations (CEs) have emerged as a promising solution. CEs are unique as they provide workable suggestions to users, instead of explaining why a certain outcome was predicted. The application of CEs encounters two main challenges: general user preferences and variable ML systems. On one hand, user preferences for specific values can vary depending on the task and scenario. On the other hand, the ML systems for verification may change while the CEs are performed. Thus, user preferences tend to be general rather than specific, and CEs need to be adaptable to variable ML models while maintaining robustness even as these models change. Facing these challenges, we propose general user preferences based on insights from psychology and behavioral science, and add the challenge of non-static ML systems as one preference. Moreover, we introduce a novel method, \\uline{T}ree-based \\uline{C}onditions \\uline{O}ptional \\uline{L}inks (T-COL) for generating CEs adaptable to general user preferences. Moreover, we employ T-COL to enhance the robustness of CEs with specific conditions, making CEs robust even when the ML models are replaced. To assess subjectivity preferences, we define LLM-based autonomous agents to simulate users and align them with real users. Experiments show that T-COL outperforms all baselines in adapting to general user preferences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2309.16146.pdf",
    "abs_url": "https://arxiv.org/abs/2309.16146",
    "published": "2023-09-28T03:51:49Z",
    "updated": "2026-02-02T07:44:17Z",
    "comment": null,
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  }
]