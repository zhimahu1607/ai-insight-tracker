[
  {
    "id": "e7f5cf39d4b4711c",
    "title": "Democratizing business intelligence: BGL’s journey with Claude Agent SDK and Amazon Bedrock AgentCore",
    "url": "https://aws.amazon.com/blogs/machine-learning/democratizing-business-intelligence-bgls-journey-with-claude-agent-sdk-and-amazon-bedrock-agentcore/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-03T20:28:29Z",
    "summary": "BGL is a leading provider of self-managed superannuation fund (SMSF) administration solutions that help individuals manage the complex compliance and reporting of their own or a client’s retirement savings, serving over 12,700 businesses across 15 countries. In this blog post, we explore how BGL built its production-ready AI agent using Claude Agent SDK and Amazon Bedrock AgentCore.",
    "content": "This post is cowritten with James Luo from BGL.\nData analysis is emerging as a high-impact use case for AI agents. According to Anthropic’s 2026 State of AI Agents Report , 60% of organizations rank data analysis and report generation as their most impactful agentic AI applications. 65% of enterprises cite it as a top priority. In practice, businesses face two common challenges:\n\nBusiness users without technical knowledge rely on data teams for queries, which is time-consuming and creates a bottleneck.\nTraditional text-to-SQL solutions don’t provide consistent and accurate results.\n\nLike many other businesses, BGL faced similar challenges with its data analysis and reporting use cases.  BGL is a leading provider of self-managed superannuation fund (SMSF) administration solutions that help individuals manage the complex compliance and reporting of their own or a client’s retirement savings, serving over 12,700 businesses across 15 countries. BGL’s solution processes complex compliance and financial data through over 400 analytics tables, each representing a specific business domain, such as aggregated customer feedback, investment performance, compliance tracking, and financial reporting. BGL’s customers and employees need to find insights from the data. For example, Which products had the most negative feedback last quarter?  or Show me investment trends for high-net-worth accounts . Working with Amazon Web Services (AWS) , BGL built an AI agent using Claude Agent SDK hosted on Amazon Bedrock AgentCore . By using the AI agent business users can retrieve analytic insights through natural language while aligning with the security and compliance requirements of financial services, including session isolation and identity-based access controls.\nIn this blog post, we explore how BGL built its production-ready AI agent using Claude Agent SDK and Amazon Bedrock AgentCore. We cover three key aspects of BGL’s implementation:\n\nWhy building a strong data foundation is essential for reliable AI agent-based text-to-SQL solutions\nHow BGL designed its AI agent using Claude Agent SDK for code execution, context management, and domain-specific expertise\nHow BGL used AgentCore to provide the ideal stateful execution sessions in production for a more secure, scalable AI agent.\n\nSetting up strong data foundations for an AI agent-based text-to-SQL solution\nWhen engineering teams implement an AI agent for analytics use cases, a common anti-pattern is to have the agent handle everything including understanding database schemas, transforming complex datasets, sorting out business logic for analyses and interpreting results. The AI agent is likely to produce inconsistent results and fail by joining tables incorrectly, missing edge cases, or producing incorrect aggregations.\nBGL used its existing mature big data solution powered by Amazon Athena  and dbt Labs , to process and transform terabytes of raw data across various business data sources. The extract, transform, and load (ETL) process builds analytic tables and each table answers a specific category of business questions. Those tables are aggregated, denormalized datasets (with metrics and, summaries) that serve as a business-ready single source of truth for business intelligence (BI) tools, AI agents, and applications. For details on how to build a serverless data transformation architecture with Athena and dbt, see How BMW Group built a serverless terabyte-scale data transformation architecture with dbt and Amazon Athena .\nThe AI agent’s role is to handle complex data transformation within the data system by focusing on interpreting the user’s natural language questions, translating it, and generating SQL SELECT queries against well-structured analytic tables. When needed, the AI agent writes Python scripts to further process results and generate visualizations. This separation of concerns significantly reduces the risk of hallucination and offers several key benefits:\n\nConsistency : The data system handles complex business logic in a more deterministic way: joins, aggregations, and business rules are validated by the data team ahead of time. The AI agent’s task becomes straightforward: interpret questions and generate basic SELECT queries against those tables.\nPerformance : Analytic tables are pre-aggregated and optimized with proper indexes. The agent performs basic queries rather than complex joins across raw tables, resulting in a faster response time even for large datasets.\nMaintainability and governance : Business logic resides in the data system, not in the AI’s context window. This helps ensure that the AI agent relies on the same single source of truth as other consumers, such as BI tools. If a business rule changes, the data team updates the data transformation logic in dbt, and the AI agent automatically consumes the updated analytic tables that reflect those changes.\n\n“Many people think the AI agent is so powerful that they can skip building the data platform; they want the agent to do everything. But you can’t achieve consistent and accurate results that way. Each layer should solve complexity at the appropriate level” \n– James Luo, BGL Head of Data and AI\n\nHow BGL builds AI agents using Claude Agent SDK with Amazon Bedrock\nBGL’s development team has been using Claude Code powered by Amazon Bedrock as its AI coding assistant. This integration uses temporary, session-based access to mitigate credential exposure, and integrates with existing identity providers to align with financial services compliance requirements. For details of integration, see  Guidance for Claude Code with Amazon Bedrock\nThrough its daily use of the Claude Code, BGL recognized that its core capabilities extend beyond coding. BGL used its ability to reason through complex problems, write and execute code, and interact with files and systems autonomously.  Claude Agent SDK packages the same agentic capabilities into a Python and TypeScript SDK, so that developers can build custom AI agents on top of Claude Code. For BGL, this meant they could build an analytics AI agent with:\n\nCode execution : The agent writes and runs Python code to process datasets returned from analytic tables and generate visualizations\nAutomatic context management : Long-running sessions don’t overwhelm token limits\nSandboxed execution : Production-grade isolation and permission controls\nModular memory and knowledge : A CLAUDE.md file for project context and Agent Skills for product line domain-specific expertise\n\nWhy code execution matters for data analytics\nAnalytics queries often return thousands of rows and sometimes beyond megabytes of data. Standard tool-use, function calling, and Model Context Protocol (MCP) patterns often pass retrieved data directly into the context window, which quickly reaches model context window limits. BGL implemented a different approach: the agent writes SQL to query Athena, then writes Python code to process the CSV file results directly in its file system. This enables the agent to handle large result sets, perform complex aggregations, and generate charts without reaching context window limits. You can learn more about the code execution patterns in Code execution with MCP: Building more efficient agents .\nModular knowledge architecture\nTo handle BGL’s diverse product lines and complex domain knowledge, the implementation uses a modular approach with two key configuration types that work together seamlessly.\nCLAUDE.md (project context)\nThe CLAUDE.md file provides the agent with global context—the project structure, environment configuration (test, production, and so on), and critically, how to execute SQL queries. It defines which folders store intermediate results and final outputs, making sure files land in a defined file path that users can access. The following diagram shows the structure of a CLAUDE.md file:\n\nSKILL.md (Product domain expertise)\nBGL organizes their agent domain knowledge by product lines using the SKILL.md configuration files. Each skill acts as a specialized data analyst for a specific product. For example, the BGL CAS 360 product has a skill called CAS360 Data Analyst agent , which   handles company and trust management with ASIC compliance alignment; while BGL’s Simple Fund 360 product   has a skill called Simple Fund 360 Data Analyst agent , which is equipped with SMSF administration and compliance-related domain skills. A SKILL.md file defines three things:\n\nWhen to trigger : What types of questions should activate this skill\nWhich tables to use or map : References to the relevant analytic tables in the data folder (as shown in the preceding figure)\nHow to handle complex scenarios : Step-by-step guidance for multi-table queries or specific business questions if required\n\nBy using SKILL.md files, the agent can dynamically discover and load the right skill to gain domain-specific expertise for corresponding tasks.\n\nUnified context : When a skill is triggered, Claude Agent SDK dynamically merges its specialized instructions with the global CLAUDE.md  file into a single prompt. This allows the agent to simultaneously apply project-wide standards (for example, always save to disk ) while using domain-specific knowledge (such as mapping user questions to a group of tables).\nProgressive discovery : Not all skills need to be loaded into the context window at once. The agent first reads the query to determine which skill needs to be triggered. It loads the skill body and references to understand which analytic table’s metadata is required. It then further explores corresponding data folders. This keeps context usage efficient while providing comprehensive coverage.\nIterative refinement : If the AI agent is unable to handle some business knowledge because of a lack of new domain knowledge, the team will gather feedback from users, identify the gaps, and add new knowledge to existing skills using a human-in-the-loop process so skills are updated and refined iteratively.\n\nAs shown in the preceding figure, agent skills are organized per product line. Each product folder contains a SKILL.md definition file and a references directory with more domain knowledge and support materials that the agent loads on demand.\nFor details about Anthropic Agent Skills, see the Anthropic blog post,  agents for the real world with Agent Skills\nHigh-level solution architecture\nTo deliver a more secure and scalable text-to-SQL experience, BGL uses Amazon Bedrock AgentCore to host Claude Agent SDK while keeping data transformation in the existing big data solution.\n\nThe preceding figure illustrates a high-level architecture and workflow. The analytic tables are pre-built daily using Athena and dbt, and serve as the single source of truth . A typical user interaction flows through the following stages:\n\nUser request : A user asks a business question using Slack (for example, Which products had the most negative feedback last quarter? ).\nSchema discovery and SQL generation : The agent identifies relevant tables using skills and writes SQL queries.\nSQL security validation : To help prevent unintended data modification, a security layer allows only SELECT queries and blocks DELETE, UPDATE, and DROP operations.\nQuery execution : Athena executes the query and stores results into Amazon Simple Storage Service (Amazon S3) .\nResult Download : The agent downloads the resulting CSV file to the file system on AgentCore, completely bypassing the context window to avoid token limits.\nAnalysis and visualization : The agent writes Python code to analyze the CSV file and generate visualizations or refined datasets depending on the business question.\nResponse delivery : Final insights and visualizations are formatted and returned to the user in Slack.\n\nWhy use Amazon Bedrock AgentCore to host Claude Agent SDK\nDeploying an AI agent that executes arbitrary Python code requires significant infrastructure considerations. For instance, you need isolation to help ensure that there’s no cross-session access to data or credentials. Amazon Bedrock AgentCore provides fully-managed, stateful execution sessions, each session has its own isolated microVM with a separate CPU, memory, and file system. When a session ends, the microVM terminates fully and sanitizes memory, helping to ensure no remnants persist for future sessions. BGL found this service especially valuable:\n\nStateful execution session : AgentCore maintains session state for up to 8 hours. Users can have ongoing conversations with the agent, referring back to previous queries without losing context.\nFramework flexibility: It’s framework-agnostic. It supports deployment of AI agents such as Strands Agents SDK , Claude Agent SDK, LangGraph , and CrewAI  with a few lines of code.\nAligned with security best practices : It provides session isolation, VPC support, AWS Identity and Access Management (IAM) or OAuth based identity to facilitate governed, compliance-aligned agent operations at scale.\nSystem integration : This is a forward-looking consideration.\n\n“There’s Gateway, Memory, Browser tools, a whole ecosystem built around it. I know AWS is investing in this direction, so everything we build now can integrate with these services in the future.”\n– James Luo, BGL Head of Data and AI. \n\nBGL is already planning to integrate AgentCore Memory for storing user preferences and query patterns.\nResults and impact\nFor BGL’s more than 200 employees, this represents a significant shift in how they extract business intelligence. Product managers can now validate hypotheses instantly without waiting for the data team. Compliance teams can spot risk trends without learning SQL. Customer success managers can pull account-specific analytics in real-time during client calls. This democratization of data access helps transform analytics from a bottleneck into a competitive advantage, enabling faster decision-making across the organization while freeing the data team to focus on strategic initiatives rather than one-time query requests.\nConclusion and key takeaways\nBGL’s journey demonstrates how combining a strong data foundation with agentic AI can democratize business intelligence. By using Amazon Bedrock AgentCore and the Claude Agent SDK, BGL built a more secure and scalable AI agent that empowers employees to tap into their data to answer business questions. Here are some key takeaways:\n\nInvest in a strong data foundation : Accuracy starts with a strong data foundation. By using the data system and data pipeline to handle complex business logic (joins and aggregations), the agent can focus on basic, reliable logic.\nOrganize knowledge by domain : Use Agent Skills to encapsulate domain-specific expertise (for example, Tax Law or Investment Performance ). This keeps the context window clean and manageable. Furthermore, establish a feedback loop: continuously monitor user queries to identify gaps and iteratively update these skills.\nUse code execution for data processing : Avoid using an agent to process large datasets using a large language model (LLM) context. Instead, instruct the agent to write and execute code to filter, aggregate, and visualize data.\nChoose stateful, session-based infrastructure to host the agent : Conversational analytics requires persistent context. Amazon Bedrock AgentCore simplifies this by providing built-in state persistence (up to 8-hour sessions), alleviating the need to build custom state handling layers on top of stateless compute.\n\nIf you’re ready to build similar capabilities for your organization, get started by exploring the Claude Agent SDK  and a short demo of Deploying Claude Agent SDK on Amazon Bedrock AgentCore Runtime . If you have a similar use case or need support designing your architecture, reach out to your AWS account team.\nReferences:\n\nAmazon Bedrock AgentCore\nClaude Agent SDK\nAmazon Bedrock\nAmazon Athena \nDeploying Claude Agent SDK on Amazon Bedrock AgentCore Runtime\n\nAbout the authors\nDustin Liu is a solutions architect at AWS, focused on supporting financial services and insurance (FSI) startups and SaaS companies. He has a diverse background spanning data engineering, data science, and machine learning, and he is passionate about leveraging AI/ML to drive innovation and business transformation.\nMelanie Li, PhD, is a Senior Generative AI Specialist Solutions Architect at AWS based in Sydney, Australia, where her focus is on working with customers to build solutions leveraging state-of-the-art AI and machine learning tools. She has been actively involved in multiple Generative AI initiatives across APJ, harnessing the power of Large Language Models (LLMs). Prior to joining AWS, Dr. Li held data science roles in the financial and retail industries.\nFrank Tan is a Senior Solutions Architect at AWS with a special interest in Applied AI. Coming from a product development background, he is driven to bridge technology and business success.\nJames Luo  is Head of Data & AI at BGL Corporate Solutions, a world-leading provider of compliance software for accountants and financial professionals. Since joining BGL in 2008, James has progressed from developer to architect to his current leadership role, spearheading the Data Platform and Roni AI Agent initiatives. In 2015, he formed BGL’s BigData team, implementing the first deep learning model in the SMSF industry (2017), which now processes 200+ million transactions annually. He has spoken at Big Data & AI World and AWS Summit, and BGL’s AI work has been featured in multiple AWS case studies.\nDr. James Bland is a Technology Leader with 30+ years driving AI transformation at scale. He holds a PhD in Computer Science with a machine learning focus and leads strategic AI initiatives at AWS, enabling enterprises to adopt AI-powered development lifecycles and agentic capabilities. Dr. Bland spearheaded the AI-SDLC initiative, authored comprehensive guides on Generative AI in the SDLC, and helps enterprises architect production-scale AI solutions that fundamentally transform how organizations operate in an AI-first world.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "5486b44fe813215c",
    "title": "Use Amazon Quick Suite custom action connectors to upload text files to Google Drive using OpenAPI specification",
    "url": "https://aws.amazon.com/blogs/machine-learning/use-amazon-quick-suite-custom-action-connectors-to-upload-text-files-to-google-drive-using-openapi-specification/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-03T19:14:30Z",
    "summary": "In this post, we demonstrate how to build a secure file upload solution by integrating Google Drive with Amazon Quick Suite custom connectors using Amazon API Gateway and AWS Lambda.",
    "content": "Many organizations need to manage file uploads across different cloud storage systems while maintaining security and compliance. Although Google Drive provides APIs for integration, organizations often don’t have the technical experts to interact with these APIs directly. Organizations need an intuitive way to handle file uploads using natural language, without requiring specialized knowledge of the underlying systems or APIs.\nAmazon Quick Suite is an enterprise AI platform that provides generative AI-powered capabilities for workplace productivity and business intelligence. It brings AI-powered research, business intelligence, and automation capabilities into a single workspace and can tackle a wide range of tasks—from answering questions and generating content, to analyzing data and providing strategic insights. To extend its capabilities beyond basic data searching, Amazon Quick Suite offers action connectors , powerful components that allow interaction with external enterprise systems. With these action connectors, users can perform actions and access information from various business tools while staying within the Amazon Quick Suite interface.\nAmazon Quick Suite supports external service connectors, AWS service connectors, and custom connectors. External service connectors provide ready-to-use integrations with common enterprise applications, helping organizations quickly implement standard functionalities. However, for specialized needs like integrating with Google Drive or building custom workflows like uploading a file to a drive, Amazon Quick Suite offers custom connectors that helps organizations to execute complex tasks through simple conversational commands and create a unified workspace by connecting various tools through OpenAPI specifications, alleviating the need to constantly switch between different interfaces.\nThis approach significantly reduces the technical barrier to entry for organizations while making sure they maintain control over security and access permissions. By using Amazon Quick Suite custom connectors, organizations can transform file management operations into simple, conversation-based interactions that authorized user can perform.\nIn this post, we demonstrate how to build a secure file upload solution by integrating Google Drive with Amazon Quick Suite custom connectors using Amazon API Gate way and AWS Lambda .\nSolution overview\nThis solution addresses common challenges organizations face when managing file operations across cloud storage systems, such as maintaining security compliance, managing user permissions, and reducing the technical barriers for users. With the natural language understanding capabilities and custom connectors available in Amazon Quick Suite, organizations can transform Google Drive operations into simple, conversation-based interactions while supporting secure file uploads to the folders the user has access to. The solution demonstrates the power of combining agentic AI capabilities of Amazon Quick Suite with enterprise storage systems to create a more efficient and user-friendly file management experience. Although this post covers the use case of uploading a file to Google Drive, you can use a similar approach to upload files to other enterprise storage systems like Amazon Simple Storage Service (Amazon S3), Box, Dropbox, SharePoint, and more.\nThe following example demonstrates how manufacturers can use an Amazon Quick Suite to upload text files to shared drive in Google Drive.\n\nThe following diagram illustrates the solution architecture that uses AWS services and integrations to provide a seamless and user experience. It illustrates the key components and the flow of the solution.\n\nThe architecture consists of the following key components:\n\nThe UI for the chatbot is built using the Amazon Quick Suite chat agent .\nThe user authentication is handled by AWS IAM Identity Center , and authorization is handled by Amazon Quick Suite and Amazon Cognito .\nRelevant actions are identified based on natural language queries from the users using Amazon Quick Suite action connectors . Amazon Quick Suite uses the configured third-party OpenAPI specifications to dynamically determine which API operations to perform to fulfill an end user request. Additionally, the API calls are authorized using an Amazon Cognito authorizer, which uses Google federated identity for authorization.\nThe APIs are implemented using API Gateway and Lambda functions.\nThe Lambda function has the logic to check if the authorized user has the necessary permissions to upload a file to the folder mentioned in the query, and calls the Google service by using the service account credentials stored in AWS Secrets Manager to upload the file to Google Drive.\n\nIn the following sections, we explore the technical approach for building an Amazon Quick Suite custom connectors to upload files to Google Drive. For step-by-step guidance, refer to the GitHub repository .\nPrerequisites\nVerify you have the following prerequisites:\n\nAWS account – Create an AWS account if you don’t already have one.\nIAM Identity Center enabled – For instructions, see Enable IAM Identity Center .\nAmazon Quick Suite Enterprise subscription – This subscription level is required to configure and setup actions. For pricing information, visit the Amazon Quick Suite pricing page .\n\nConfigure Google environment\nIn this section, you configure and set up the Google Workspace and Google Drive.\nSet up the Google Workspace account\nBefore you can integrate the Google Drive functionality into the Amazon Quick Suite solution, you must first set up the necessary configurations within the Google Workspace environment. Complete the following steps:\n\nEnable Google Drive and Admin SDK APIs.\nCreate a service account and a JSON private key to access the service account from Amazon Quick Suite. Save this key to complete the configuration in next steps.\nAdd a domain-wide delegation. This involves associating the service account’s client ID with the following OAuth scopes to allow the service account to access organization data in Google Drive:\n\nhttps://www.googleapis.com/auth/drive.readonly\nhttps://www.googleapis.com/auth/drive.metadata.readonly\nhttps://www.googleapis.com/auth/admin.directory.group.readonly\nhttps://www.googleapis.com/auth/admin.directory.user.readonly\nhttps://www.googleapis.com/auth/cloud-platform\n\nCreate users in Google Workspace\nTo demonstrate the access control functionality, create two test users in the Google Workspace admin console, called test user1 and test user2 .\nConfigure shared drive in Google Drive\nTo configure the shared drive access permissions in Google Drive:\n\nCreate a new shared drive in Google Drive and make note of the folder ID to use later when testing this solution.\nSet up access permissions:\n\nGrant test user1 the Content Manager role to allow full file management capabilities.\nLeave test user2 without any access permissions to the shared drive.\n\nThis setup makes it possible to validate that the solution correctly enforces access controls based on Google Drive permissions.\nConfigure AWS environment\nIn this section, we walk through the steps to configure AWS settings and resources.\nConfigure users and permissions on AWS\nCreate corresponding users in IAM Identity Center that match the test users created in Google Workspace:\n\nCreate a user for test user1 .\nCreate a user for test user2 .\n\nAlternatively, for enterprise deployments, manage users through your enterprise identity provider (IdP). Configure System for Cross-domain Identity Management (SCIM) for automated user provisioning and lifecycle management. For more information, see How to connect to an external identity provider .\n\nComplete the email verification and password reset process.\nCreate a group within IAM Identity Center with the above two users added.\n\nCreate a secret for Google service account credentials\nTo store the Google service account credentials securely:\n\nCreate a new secret in Secrets Manager:\n\nStore the JSON private key generated for the Google service account.\nUse appropriate secret naming conventions for quick identification.\n\nConfigure access controls:\n\nRestrict access to the secret using AWS Identity and Access Management (IAM) policies and grant access only to the Lambda function that performs file uploads.\n\nThis secure credential management approach offers the following capabilities:\n\nProtects sensitive Google service account credentials\nEnables the Lambda function to authenticate with Google Drive APIs\nSupports secure file uploads on behalf of authorized users\nFollows AWS security best practices for managing application secrets\n\nCreate the Amazon Quick Suite account\nTo create and configure the Amazon Quick Suite account:\n\nSearch for Amazon Quick Suite in AWS management console and sign up for a new Amazon Quick Suite account.\nProvide the account name and email address to which the notifications related to the account should be delivered.\nSelect the authentication method as IAM Identity Center . This authentication method can be configured only using Enterprise edition of Quick Suite.\nAdd the group created in IAM Identity Center with two test users as Admin Pro group.\nKeep all other setting as-is and create the account.\nVerify user access. Confirm both users can successfully log in to the account.\n\nConfigure Amazon Cognito for authentication and authorization\nTo configure Amazon Cognito, complete the following steps:\n\nIn the Amazon Cognito console, create an Amazon Cognito user pool:\n\nSet up a new user pool to manage user identities.\nConfigure basic user pool settings.\n\nConfigure an application client:\n\nCreate an application client in the user pool.\nSet Application type to Machine-to-machine application .\n\nCreate an Amazon Cognito domain:\n\nConfigure the domain with Hosted UI (classic) branding version.\nMake note of the Amazon Cognito domain name for subsequent steps.\n\nConfigure Google OAuth credentials:\n\nIn Google Workspace, create OAuth credentials, and provide the authorized redirect URI as <cognito-domain-name>/oauth2/idpresponse .\n\nSet up Google as a federated IdP:\n\nUse the client ID and client secret from the Google OAuth credentials from the previous step.\nConfigure authorized scopes as profile email openid (authorized scopes are separated with spaces).\nMap the Amazon Cognito user pool attributes for email, name, and user name to the corresponding Google attributes.\n\nConfigure login page settings:\n\nSet Allowed callback URLs to https://<your-region>.quicksight.aws.amazon.com/sn/oauthcallback .\nChoose Google as the IdP.\n\nConfigure OAuth 2.0:\n\nSet Grant type to Authorization code grant .\nSet the OpenID connect scopes as Email , OpenID , and Profile .\n\nEnsure all URIs and callback URLs are correctly formatted and match your application’s configuration.\nConfigure the Lambda function\nIn this section, we walk through the steps to configure the Lambda function which contains the logic for validating user permissions, interacting with the Google Drive API and uploading the files to the designated folder.\n\nDeploy the Lambda function:\nUse the code provided in the lambda_function.py file.\nInclude all necessary dependencies listed in the requirements.txt file.\nConfigure environment variables:\n\nCOGNITO_USER_POOL_ID – The user pool ID from your Amazon Cognito configuration.\nREGION_NAME – Your AWS Region.\nSECRET_NAME – The Amazon Resource Name (ARN) of the secret for Google service account credentials stored in Secrets Manager.\n\nSet up Lambda execution IAM role permissions for the Lambda function to access Secrets Manager and Amazon Cognito. The steps to define the IAM policy can be found in the GitHub repository .\n\nConfigure API Gateway\nComplete the following steps to configure an API resource:\n\nCreate a REST API:\n\nUse the OpenAPI schema defined in the api-gateway-spec.yaml file, which can be found in the GitHub repository .\nIn the schema, provide your Region and Lambda function ARN.\n\nCreate a new stage for the API and configure stage settings appropriate for your environment.\nConfigure the Amazon Cognito authorizer:\n\nLink to the previously created Amazon Cognito user pool.\nSet the authorization scopes: openid , email , profile , and aws.cognito.signin.user.admin .\n\nAllow API Gateway to invoke the Lambda function from the function’s resource-based policy :\n\nOn the Lambda console, modify the resource-based policy and grant invoke permission to the API Gateway source ARN for the POST method.\n\nDeploy the API:\n\nDeploy to your created stage.\nMake note of the API endpoint URL for use in the Amazon Quick Suite configuration.\n\nCreate the Amazon Quick Suite custom action connector\nIn this step, we create the custom action connector within Amazon Quick Suite:\n\nLocate the openapischema.json file in the GitHub repository and replace the following placeholder values:\n\n<your-api-gateway-url-with-stage>\n<your-cognito-domain-name>\n<your-region>\n<your-user-pool-id>\n<your-cognito-app-client-id>\n\nSign in to the Quick Suite account created earlier as test user1 .\nNavigate to the integrations section in your Amazon Quick Suite account and create a new action using OpenAPI specification custom connector type.\n\nUpload the modified OpenAPI schema file named openapischema.json .\n\nCreate the integration with authentication method as User authentication and complete the other fields:\n\nBase URL – Use your API Gateway Endpoint. Make sure to include the stage name as well at the end.\nClient ID – Use your Cognito App client Client ID.\nClient secret – Use your Cognito App client Client Secret.\nToken URL – <your-cognito-domain-name>/oauth2/token\nAuthorization URL – <your-cognito-domain-name>/oauth2/authorize\nRedirect URL – https://<your-region>.quicksight.aws.amazon.com/sn/oauthcallback\n\nShare the integration – Share the integration created with the group in IAM Identity Center that has two test users added.\n\nUsers can now upload files to Google Drive through natural language interactions.\nCreate the Amazon Quick Suite chat agent to upload file to Google Drive:\nThere are two ways to interact with the chat agent\n\nQuick Suite has a default chat agent called My Assistant which can be used to add the action which is configured as part of the previous steps.\nCreate a custom chat agent\n\nChoose Chat agents from the left navigation pane.\nCreate a new chat agent by providing a Name and Agent identity .\nUnder Actions , link the action connector created in the above step and launch the agent.\nOnce the agent is launched successfully, share the agent with test user2 by searching the user’s email address and provide viewer permissions to the chat agent.\n\nTest the solution\nNow you’re ready to test the file upload capabilities with appropriate permissions.\nScenario 1: Test as Content Manager or Contributor to the shared drive\n\nLog in to the Quick Suite account as test user1 .\nChoose the chat agent from the left navigation pane. Select the agent created as part of the previous step.\nEnter the following prompt within the chat window: “Upload a file with filename as ‘testfile1.txt’ and file content as ‘This is a sample text file I am uploading to shared drive’ and folder id as <the shared drive folder id that you made note of while creating the shared drive in Google Drive>”.\n\nWhen prompted to authorize, log in to the Google account.\n\nAfter you are successfully authorized, verify the fields you entered and modify them if necessary.\n\nOnce the action is completed, you’ll see a success message with the link to the file uploaded to Google Drive.\n\nCopy and paste the link in a new browser tab to see the file uploaded.\n\nScenario 2: Test with no permissions to the shared drive\nAccess the chat agent using Amazon Quick Suite account as test user2 , then try to run the same prompt to upload the file to the shared drive. Because test user2 doesn’t have access to the shared drive, you’ll get an error message similar to that shown in the following screenshot.\n\nClean up\nIf you no longer require the resources deployed as part of this solution, and you want to avoid incurring ongoing costs associated with those resources, complete the following steps to clean up and delete the relevant components:\n\nDelete Amazon Quick Suite related resources, including your Amazon Quick Suite account.\nDelete the secrets created for this application from Secrets Manager.\nDelete the Lambda function.\nDelete the API deployed in API Gateway.\nDelete the user pool in Amazon Cognito and other configurations made.\n\nConclusion\nThis post demonstrated how organizations can use Amazon Quick Suite action connectors to build a secure and intuitive file upload solution that integrates with Google Drive. By using AWS services like API Gateway, AWS Lambda, Amazon Cognito, and Secrets Manager, along with the natural language capabilities of Amazon Quick Suite, businesses can transform file management tasks into simple, conversation-based interactions. With this secure file upload solution using Amazon Quick Suite, users can manage their Google Drive content through natural language interactions.\nThe key benefits of this approach include:\n\nImproved user experience – Users can upload files to Google Drive using natural language prompts, without needing specialized technical knowledge of the underlying APIs and systems.\nEnhanced security and compliance – The solution enforces access controls by allowing only users with necessary permissions to upload files to the shared drive with file access permissions managed through Google Drive and an Amazon Cognito user pool.\nReduced operational complexity – The custom action connectors approach abstracts away the technical complexities of integrating with third-party cloud storage services, so organizations can focus on delivering valuable capabilities to their users.\n\nFor step-by-step guidance, refer to the GitHub repository . Try out the solution for yourself and share your feedback and questions in the comments.\n\nAbout the authors\nNaimisha Pinna is a Solutions Architect at AWS, responsible for helping Enterprise customers on their journey in the cloud. She graduated with a Master’s degree in Computer Science from Old Dominion University. Her area of specialization is in AI and ML. She enjoys painting and gardening.\nJosh Demuth is a GenAI Solutions Architect with 20 years in the tech industry, with several years specializing in systems integration. He thrives on creating solutions that make disparate systems work together and discovering innovative approaches to business problems. The rapid evolution of AI and automation has him excited about the transformative solutions on the horizon.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "b8a3308500e3f5a0",
    "title": "AI agents in enterprises: Best practices with Amazon Bedrock AgentCore",
    "url": "https://aws.amazon.com/blogs/machine-learning/ai-agents-in-enterprises-best-practices-with-amazon-bedrock-agentcore/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-03T18:44:43Z",
    "summary": "This post explores nine essential best practices for building enterprise AI agents using Amazon Bedrock AgentCore. Amazon Bedrock AgentCore is an agentic platform that provides the services you need to create, deploy, and manage AI agents at scale. In this post, we cover everything from initial scoping to organizational scaling, with practical guidance that you can apply immediately.",
    "content": "Building production-ready AI agents requires careful planning and execution across the entire development lifecycle. The difference between a prototype that impresses in a demo and an agent that delivers value in production is achieved through disciplined engineering practices, robust architecture, and continuous improvement.\nThis post explores nine essential best practices for building enterprise AI agents using Amazon Bedrock AgentCore . Amazon Bedrock AgentCore is an agentic platform that provides the services you need to create, deploy, and manage AI agents at scale. In this post, we cover everything from initial scoping to organizational scaling, with practical guidance that you can apply immediately.\nStart small and define success clearly\nThe first question you need to answer isn’t “what can this agent do?” but rather “what problem are we solving?” Too many teams start by building an agent that tries to handle every possible scenario. This leads to complexity, slow iteration cycles, and agents that don’t excel at anything.\nInstead, work backwards from a specific use case. If you’re building a financial assistant, start with the three most common analyst tasks. If you’re building an HR helper, focus on the top five employee questions. Get those working reliably before expanding scope.\nYour initial planning should produce four concrete deliverables:\n\n  Clear definition of what the agent should and should not do. Write this down. Share it with stakeholders. Use it to say no to feature creep.\nThe agent’s tone and personality . Decide if it will be formal or conversation, how it will greet users, and what will happen when it encounters questions outside its scope.\nUnambiguous definitions for every tool, parameter, and knowledge source . Vague descriptions cause the agent to make incorrect choices.\nA ground truth dataset of expected interactions covering both common queries and edge cases.\n\nAgent definition \nAgent tone and personality\nTools definition\nGround truth dataset\n\nFinancial analytics agent : Helps analysts retrieve quarterly revenue data, calculate growth metrics, and generate executive summaries for specific Regions (EMEA, APAC, AMER). Should not provide investment advice, execute trades, or access employee compensation data.\n\nProfessional but conversational. Addresses users by first name.\nAcknowledges data limitations transparently.\nWhen uncertain about data quality, states confidence level explicitly.\nDoesn’t use financial jargon without explanation.\n\ngetQuarterlyRevenue(Region: EMEA|APAC|AMER, quarter: YYYY-QN) – Returns revenue in millions USD. calculateGrowth(currentValue: number, previousValue: number) – Returns percentage change. getMarketData(Region: string, dataType: revenue|sales|customers) – Retrieves latest industry indicators.\n50 queries including:\n\n“What’s our Q3 revenue in EMEA?”\n“Show me growth compared to last quarter”\n“How did we perform in Asia?”\n“What’s the CEO’s bonus?” (should decline)\n“Compare all Regions for 2024”\n\nHR policy assistant : Answers employee questions about vacation policies, leave requests, benefits enrollment, and company policies. Should not access confidential personnel files, provide legal advice, or discuss individual compensation or performance reviews.\n\nFriendly and supportive.\nUses employee’s preferred name.\nMaintains professionalism while being approachable.\nWhen policies are complex, breaks them down into clear steps.\nOffers to connect employees with HR representatives for sensitive matters.\n\ncheckVacationBalance(employeeId: string) – Returns available days by type. getPolicy(policyName: string) – Retrieves policy documents from knowledge base. createHRTicket(employeeId: string, category: string, description: string) – Escalates complex issues.getUpcomingHolidays(year: number, region: string) – Returns company holiday calendar.\n45 queries including:\n\n“How many vacation days do I have?”\n“What’s the parental leave policy?”\n“Can I take time off next week?”\n“Why was my bonus lower than expected?” (should escalate)\n“How do I enroll in health insurance?”\n\nIT support agent : Assists employees with password resets, software access requests, VPN troubleshooting, and common technical issues. Should not access production systems, modify security permissions directly, or handle infrastructure changes.\n\nPatient and clear.\nAvoids technical jargon.\nProvides step-by-step instructions.\nConfirms understanding before moving to next step.\nCelebrates small wins (“Great, that worked!”).\nEscalates to IT team when issues require system access.\n\nresetPassword(userId: string, system: string) – Initiates password reset workflow.checkVPNStatus(userId: string) – Verifies VPN configuration and connectivity. requestSoftwareAccess(userId: string, software: string, justification: string) – Creates access request ticket. searchKnowledgeBase(query: string) – Retrieves troubleshooting articles.\n40 queries including:\n\n“I can’t log into my email”\n“VPN keeps disconnecting”\n“I need access to Salesforce”\n“Can you give me admin rights?” (should decline), “Laptop won’t connect to Wi-Fi”, “How do I install Slack?”\n\nBuild a proof of concept with this limited scope. Test it with real users. They will immediately find issues you didn’t anticipate. For example, the agent might struggle with date parsing. It might not handle abbreviations, not handle abbreviations well, or invoke the wrong tool when questions are phrased unexpectedly. Learning this in a proof of concept can cost you a couple of weeks while learning it in production can cost your credibility and user trust.\nInstrument everything from day one\nOne of the most significant mistakes teams can make with observability is treating it as something to add later. By the time you realize you need it, you’ve already shipped an agent, which can make it harder to debug effectively.\nFrom your first test query, you need visibility into what your agent is doing. AgentCore services emit OpenTelemetry traces automatically. Model invocations, tool calls, and reasoning steps get captured. When a query takes twelve seconds, you can see whether the delay came from the language model, a database query, or an external API call.\nThe observability strategy should include three layers:\n\nEnable trace-level debugging during development so you can see the steps of each conversation. When users report incorrect behavior, pull up the specific trace and see exactly what the agent did.\nSet up dashboards for production monitoring using the Amazon CloudWatch Generative AI observability dashboards that come with AgentCore Observability .\nTrack token usage, latency percentiles, error rates, and tool invocation patterns. Export the data to your existing observability system if your organization uses  Datadog , Dynatrace , LangSmith , or Langfuse . The figure below shows how AgentCore Observability allows you to deep dive into your agent’s trace and meta data information inside a session invocation:\n\nObservability serves different needs for different roles. Developers need it for debugging to answer questions such as why the agent hallucinated, which prompt version performs better, and where latency is coming from. Platform teams need it for governance; they need to know how much each team is spending, which agents are driving cost increases and what happened in any particular incident. The principle is straightforward: you can’t improve what you can’t measure. Set up your measurement infrastructure before you need it.\nBuild a deliberate tooling strategy\nTools are how your agent accesses the real world. They fetch data from databases, call external APIs, search documentation, and execute business logic. The quality of your tool definitions directly impacts agent performance.\nWhen you define a tool, clarity matters more than brevity. Consider these two descriptions for the same function:\n\nBad: “Gets revenue data”\nGood: \"Retrieves quarterly revenue data for a specified region and time period. Returns values in millions of USD. Requires region code (EMEA, APAC, AMER) and quarter in YYYY-QN format (e.g., 2024-Q3).\"\n\nThe first description forces the agent to guess what inputs are valid and how to interpret outputs. The second helps remove ambiguity. When you multiply this across twenty tools, the difference becomes dramatic. Your tooling strategy should address four areas:\n\nError handling and resilience. Tools fail. APIs return errors. Timeouts happen. Define the expected behavior for each failure mode, if the agent should retry, fallback to cached data, or tell the user the service is unavailable. Document this alongside the tool definition.\nReuse through Model Context Protocol (MCP). Many service providers already provide MCP servers for tools such as Slack, Google Drive, Salesforce, and GitHub. Use them instead of building custom integrations. For internal APIs, wrap them as MCP tools through AgentCore Gateway. This gives you one protocol across the tools and makes them discoverable by different agents.\nCentralized tool catalog. Teams shouldn’t build the same database connector five times. Maintain an approved catalog of tools that have been reviewed by security and tested in production. When a new team needs a capability, they start by checking the catalog.\nCode examples with every tool. Documentation alone isn’t enough. Show developers how to integrate each tool with working code samples that they can copy and adapt.\n\nThe following table shows what effective tool documentation includes:\n\nElement\nPurpose\nExample\n\nClear name\nDescribes what the tool does\ngetQuarterlyRevenue  not getData\n\nExplicit parameters\nRemoves ambiguity about inputs\nregion : string (EMEA|APAC|AMER), quarter : string (YYYY-QN)\n\nReturn format\nSpecifies output structure\nReturns: { revenue : number , currency : “USD”, period: string}\n\nError conditions\nDocuments failure modes\nReturns 404 if quarter not found, 503 if service unavailable\n\nUsage guidance\nExplains when to use this tool\nUse when user asks about revenue, sales, or financial performance\n\nThese documentation standards become even more valuable when you’re managing tools across multiple sources and types. The following diagram illustrates how  AgentCore Gateway   provides a unified interface for tools from different origins: whether they’re exposed through additional Gateway instances (for data retrieval and analysis functions), AWS Lambda (for reporting capabilities), or Amazon API Gateway (for internal services like project management). While this example shows a single gateway for simplicity, many teams deploy multiple Gateway instances (one per agent or per set of related agents) to maintain clear boundaries and ownership. Because of this modular approach, teams can manage their own tool collections while still benefiting from consistent authentication, discovery, and integration patterns across the organization.\n\nAgentCore Gateway helps solves the practical problem of tool proliferation. As you build more agents across your organization, you can quickly accumulate dozens of tools, some exposed through MCP servers, others through Amazon API Gateway, still others as Lambda functions. Without AgentCore Gateway, each agent team reimplements authentication, manages separate endpoints, and loads every tool definition into their prompts even when only a few are relevant. AgentCore Gateway provides a unified entry point for your tools regardless of where they live. Direct it to your existing MCP servers and API Gateways, and agents can discover them through one interface. The semantic search capability becomes critical when your number of tools increase to twenty or thirty tools: agents can find the right tool based on what they’re trying to accomplish rather than loading everything into context. You also get comprehensive authentication handling in both directions: verifying which agents can access which tools, and managing credentials for third-party services. This is the infrastructure that makes the centralized tool catalog practical at scale.\nAutomate evaluation from the start\nYou need to know whether your agent is getting better or worse with each change you make. Automated evaluation gives you this feedback loop. Start by defining what “good” means for your specific use case. The metrics will vary depending on the industry and task:\n\nA customer service agent might be measured on resolution rate and customer satisfaction.\nA financial analyst agent might be measured on calculation accuracy and citation quality.\nAn HR assistant might be measured on policy accuracy and response completeness.\n\nBalance technical metrics with business metrics. Response latency matters, but only if the answers are correct. Token cost matters, but only if users find the agent valuable. Define both types of metrics and track them together. Build your evaluation dataset carefully. Include data such as:\n\nMultiple phrasings of the same question because users don’t speak like API documentation.\nEdge cases where the agent should decline to answer or escalate to a human.\nAmbiguous queries that could have multiple valid interpretations.\n\nConsider the financial analytics agent from our earlier example. Your evaluation dataset should include queries like “What’s our Q3 revenue in EMEA?” with an expected answer and the correct tool invocation. But it should also include variations: “ How much did we make in Europe last quarter?”, “EMEA Q3 numbers?” , and “Show me European revenue for July through September.” Each phrasing should result in the same tool call with the same parameters. Your evaluation metrics might include:\n\nTool selection accuracy : Did the agent choose getQuarterlyRevenue instead of getMarketData ? Target: 95%\nParameter extraction accuracy : Did it correctly map EMEA and Q3 2024 to the right format? Target: 98%\nRefusal accuracy : Did the agent decline to answer What's the CEO's bonus? Target: 100%\nResponse quality : Did the agent explain the data clearly without financial jargon? Evaluated via LLM-as-Judge\nLatency : P50 under 2 seconds, P95 under 5 seconds\nCost per query : Average token usage under 5,000 tokens\n\nRun this evaluation suite against your ground truth dataset. Before your first change, your baseline might show 92% tool selection accuracy and 3.2 second P50 latency. After switching from Amazon Claude 4.5 Sonnet to Claude 4.5 Haiku on Amazon Bedrock , you could rerun the evaluation and discover tool selection dropped to 87% but latency improved to 1.8 seconds. This quantifies the tradeoff and helps you decide whether the speed gain justifies the accuracy loss.\nThe evaluation workflow should become part of your development process. Change a prompt? Run the evaluation. Add a new tool? Run the evaluation. Switch to a different model? Run the evaluation. The feedback loop needs to be fast enough that you catch problems immediately, not three commits later.\nDecompose complexity with multi-agent systems\nWhen a single agent tries to handle too many responsibilities, it becomes difficult to maintain. The prompts grow complex. Tool selection logic struggles. Performance degrades. The solution is to decompose the problem into multiple specialized agents that collaborate. Think of it like organizing a team. You don’t hire one person to handle sales, engineering, support, and finance. You hire specialists who coordinate their work. The same principle applies to agents. Instead of one agent handling thirty different tasks, build three agents that each handle ten related tasks, as shown in the following figure. Each agent has clearer instructions, simpler tool sets, and more focused logic. When complexity is isolated, problems become straightforward to debug and fix.\n\nChoosing the right orchestration pattern matters. Sequential patterns work when tasks have a natural order. The first agent retrieves data, the second analyzes it, the third generates a report. Hierarchical patterns work when you need intelligent routing. A supervisor agent determines user intent and delegates to specialist agents. Peer-to-peer patterns work when agents need to collaborate dynamically without a central coordinator.\nThe key challenge in multi-agent systems is maintaining context across handoffs. When one agent passes work to another, the second agent needs to know what has already happened. If a user provided their account number to the first agent, the second agent shouldn’t ask again. AgentCore Memory provides shared context that multiple agents can access within a session.\nMonitor the handoffs between agents carefully. That’s where most failures occur. Which agent handled which part of the request? Where did delays happen? Where did context get lost? AgentCore Observability traces the entire workflow end-to-end so you can diagnose these issues.\nOne common point of confusion deserves clarification. Protocols and patterns are not the same thing. Protocols define how agents communicate. They’re the infrastructure layer, the wire format, the API contract. Agent2Agent (A2A) protocol , MCP, and HTTP are protocols. Patterns define how agents organize work. They’re the architecture layer, the workflow design, the coordination strategy. Sequential, hierarchical, and peer-to-peer are patterns.\nYou can use the same protocol with different patterns. You might use A2A when you’re building a sequential pipeline or a hierarchical supervisor. You can use the same pattern with different protocols. Sequential handoffs work over MCP, A2A, or HTTP. Keep these concerns separate so you don’t tightly couple your infrastructure to your business logic.\nThe following table describes the differences in layer, examples, and concerns between multi-agent collaboration protocols and patterns.\n\nProtocols – How agents talk\nPatterns – How agents organize\n\nLayer\nCommunication and infrastructure\nArchitecture and organization\n\nConcerns\nMessage format, APIS, and standards\nWorkflow, role, and coordination\n\nExamples\nA2A, MCP, HTTP, and so on\nSequential, hierarchical, peer-to-peer, and so on\n\nScale securely with personalization\nMoving from a prototype that works for one developer to a production system serving thousands of users introduces new requirements around isolation, security, and personalization.\nSession isolation comes first. User A’s conversation cannot leak into User B’s session under any circumstances. When two users simultaneously ask questions about different projects, different Regions, or different accounts, those sessions must be completely independent. AgentCore Runtime handles this by running each session in its own isolated micro virtual machine (microVM) with dedicated compute and memory. When the session ends, the microVM terminates. No shared state exists between users.\nPersonalization requires memory that persists across sessions. Users have preferences about how they like information presented. They work on specific projects that provide context for their questions. They use terminology and abbreviations specific to their role. AgentCore Memory provides both short-term memory for conversation history and long-term memory for facts, preferences, and past interactions. Memory is namespaced by user so each person’s context remains private. Security and access control must be enforced before tools execute. Users should only access data they have permission to see. The following diagram below shows how AgentCore components work together to help enforce security at multiple layers.\n\nWhen a user interacts with your agent, they first authenticate through your identity provider (IdP), whether that’s Amazon Cognito , Microsoft Entra ID , or  Okta .  AgentCore Identity receives the authentication token and extracts custom OAuth claims that define the user’s permissions and attributes. These claims flow through AgentCore Runtime to the agent and are made available throughout the session.\nAs the agent determines which tools to invoke, AgentCore Gateway acts as the enforcement point. Before a tool executes, Gateway intercepts the request and evaluates it against two policy layers. AgentCore Policy  validates whether this specific user has permission to invoke this specific tool with these specific parameters, checking resource policies that define who can access what. Simultaneously, AgentCore Gateway checks credential providers (such as Google Drive, Dropbox, or Outlook) to retrieve and inject the necessary credentials for third-party services. Gateway interceptors provide an additional hook where you can implement custom authorization logic, rate limiting, or audit logging before the tool call proceeds.\nOnly after passing these checks do the tool execute. If a junior analyst tries to access executive compensation data, the request is denied at the AgentCore Gateway before it ever reaches your database. If a user hasn’t granted OAuth consent for their Google Drive, the agent receives a clear error it can communicate back to the user. The user consent flow is handled transparently; when an agent needs access to a credential provider for the first time, the system prompts for authorization and stores the token for subsequent requests.\nThis defense-in-depth approach helps ensure that security is enforced consistently across the agents and the tools, regardless of which team built them or where the tools are hosted.\nMonitoring becomes more complex at scale. With thousands of concurrent sessions, you need dashboards that show aggregate patterns and that you can use to examine individual interactions. AgentCore Observability provides real-time metrics across the users showing token usage, latency distributions, error rates, and tool invocation patterns, as shown in the figures below. When something breaks for one user, you can trace exactly what happened in that specific session, as shown in the following figures.\n\nAgentCore Runtime also hosts tools as MCP servers. This helps keep your architecture modular. Agents discover and call tools through AgentCore Gateway without tight coupling. When you update a tool’s implementation, agents automatically use the new version without code changes.\nCombine agents with deterministic code\nOne of the most important architectural decisions you’ll make is when to rely on agentic behavior and when to use traditional code. Agents are powerful but they may not be appropriate for every task. Reserve agents for tasks that require reasoning over ambiguous inputs. Understanding natural language queries, determining which tools to invoke, and interpreting results in context all can benefit from the reasoning capabilities of foundation models. These are tasks where deterministic code would require enumerating thousands of possible cases. Use traditional code for calculations, validations, and rule-based logic. Revenue growth is a formula. Date validation follows patterns. Business rules are conditional statements. You don’t need a language model to compute “subtract Q2 from Q3 and divide by Q2.” Write a Python function. It can run in milliseconds at no additional cost and produce the same answer every time.\nThe right architecture has agents orchestrating code functions. When a user asks, “What’s our growth in EMEA this quarter?” , the agent uses reasoning to understand the intent and determine which data to fetch. It calls a deterministic function to perform the calculation. Then it uses reasoning again to explain the result in natural language.\nLet’s compare the number of large language model (LLM) invocations, token count and latency of two queries to “Create the spendings report for next month”. In the first one,  get_current_date() is exposed as an agentic tool and in the second one, the current date is passed as attribute to the agent:\n\nget_current_date() as a tool\nCurrent date passed as attribute\n\nQuery\n“Create the spendings report for next month”\n“Create the spendings report for next month”\n\nAgent behavior\nCreates plan to invoke get_current_date() Calculates next month based on the value of current date Invokes create_report() with next month as parameter and creates final response\nUses code to get the current date Invokes agent with today as attribute Invokes create_booking() with next month (inferred via LLM reasoning) as the parameter and creates final response\n\nLatency\n12 seconds\n9 seconds\n\nNumber of LLM invocations\nFour invocations\nThree invocations\n\nTotal tokens (input + output)\nApproximately 8,500 tokens\nApproximately 6,200 tokens\n\nThe current date is something you can seamlessly get using code. You can then pass it to your agent context at invocation time, as attribute. The second approach is faster, less expensive, and more accurate. Multiply this across thousands of queries and the difference becomes substantial. Measure cost compared to value continuously. If deterministic code solves the problem reliably, use it. If you need reasoning or natural language understanding, use an agent. The common mistake is assuming everything must be agentic. The right answer is agents plus code working together.\nEstablish continuous testing practices\nDeploying to production isn’t the finish line. It’s the starting line. Agents operate in a constantly changing environment. User behavior evolves. Business logic changes. Model behavior can drift. You need continuous testing to catch these changes before they impact users. Build a continuous testing pipeline that runs on every update. Maintain a test suite with representative queries covering common cases and edge cases. When you change a prompt, add a tool, or switch models, the pipeline runs your test suite and scores the results. If accuracy drops below your threshold, the deployment fails automatically. This helps prevent regressions. Use A/B testing to validate changes in production. When you want to try a new model or a different prompting strategy, don’t switch all users at once. For example, route 10% of traffic to the new version. Compare performance over a week. Measure accuracy, latency, cost, and user satisfaction. If the new version performs better, gradually roll it out. If not, revert. AgentCore Runtime provides built-in support for versioning and traffic splitting. Monitor for drift in production. User patterns shift over time. Questions that were rare become common. New products launch. Terminology changes. Sample live interactions continuously and score them against your quality metrics. When you detect drift, such as accuracy dropping from 92% to 84% over two weeks, investigate and address the root cause.\nAgentCore Evaluations simplifies the mechanics of running these assessments. It provides two evaluation modes to fit different stages of your development lifecycle. On-demand evaluations let you assess agent performance against a predefined test dataset, run your test suite before deployment, compare two prompt versions side-by-side, or validate a model change against your ground truth examples. Online evaluations monitor live production traffic continuously, sampling and scoring real user interactions to detect quality degradation as it happens. Both modes work with popular frameworks including Strands and LangGraph through OpenTelemetry and OpenInference instrumentation. When your agent executes, traces are automatically captured, converted to a unified format, and scored using LLM-as-Judge techniques. You can use built-in evaluators for common quality dimensions like helpfulness, harmfulness, and accuracy. For domain-specific requirements, create custom evaluators with your own scoring logic. The figures below show an example metric evaluation being displayed on AgentCore Evaluations.\n\nEstablish automated rollback mechanisms. If critical metrics breach thresholds, automatically revert to the previous known-good version. For example, if the hallucination rate spikes above 5%, roll back and alert the team. Don’t wait for users to report problems.\nYour testing strategy should include these elements:\n\nAutomated regression testing on every change\nA/B testing for major updates\nContinuous sampling and evaluation in production\nDrift detection with automated alerts\nAutomated rollbacks when quality degrades\n\nWith agents, testing does not stop because the environment does not stop changing.\nBuild organizational capability\nYour first agent in production is an achievement. But enterprise value comes from scaling this capability across the organization. That requires platform thinking, not just project thinking.\nCollect user feedback and interaction patterns continuously. Watch your observability dashboards to identify which queries succeed, which fail and what edge cases appear in production that weren’t in your test set. Use this data to expand your ground truth dataset. What started as fifty test cases grows to hundreds based on real production interactions.\nSet up a platform team to establish standards and provide shared infrastructure. The platform team:\n\nMaintains a catalog of approved tools that have been vetted by security teams.\nProvides guidance on observability, evaluation, and deployment practices.\nRuns centralized dashboards showing performance across the agents. When a new team wants to build an agent.\n\nWhen a new team wants to build an agent, they start with the platform toolkit. When teams complete the deployment from their tools and/or agents to production, they can contribute back to the platform . At scale, the platform team provides reusable assets and standards to the organization and teams create their own assets while contributing to back to the platform with validated assets.\n\nImplement centralized monitoring across the agents in the organization. One dashboard shows the agents, the sessions, and the costs. When token usage spikes unexpectedly, platform leaders can see it immediately. They can review by team, by agent, or by time period to understand what changed.\nFoster cross-team collaboration so teams can learn from each other. Three teams shouldn’t build three versions of a database connector. Instead, they should share tools through AgentCore Gateway, share evaluation strategies and host regular sessions where teams demonstrate their agents and discuss challenges. By doing this, common problems surface and shared solutions emerge.\nThe organizational scaling pattern is a crawl, walk, run process:\n\nCrawl phase. Deploy the first agent internally for a small pilot group. Focus on learning and iteration. Failures are cheap.\nWalk phase. Deploy the agent to a controlled external user group. More users, more feedback, more edge cases discovered. Investment in observability and evaluation pays off.\nRun phase. Scale the agent to external users with confidence. Platform capabilities enable other teams to build their own agents faster. Organizational capability compounds.\n\nThis is how you can go from one developer building one agent to dozens of teams building dozens of agents with consistent quality, shared infrastructure, and accelerating velocity.\nConclusion\nBuilding production-ready AI agents requires more than connecting a foundation model to your APIs. It requires disciplined engineering practices across the entire lifecycle, include:\n\nStart small with a clearly defined problem\nInstrument everything from day one\nBuild a deliberate tooling strategy\nAutomate your evaluation\nDecompose complexity with multi-agent architectures\nScale securely with personalization\nCombine agents with deterministic code\nTest continuously\nBuild organizational capability with platform thinking\n\nAmazon Bedrock AgentCore provides the services you need to implement these practices:\n\nAgentCore Runtime hosts agents and tools in isolated environments\nAgentCore Memory enables personalized interactions\nAgentCore Identity and AgentCore Policy help enforce security\nAgentCore Observability provides visibility\nAgentCore Evaluations enables continuous quality assessment\nAgentCore Gateway unifies communication across agents and tools using standard protocols\nAgentCore Browser provides a secure, cloud-based browser that enables AI agents to interact with websites and AgentCore Code Interpreter enables AI agents to write and execute code more securely in sandbox environments.\n\nThese best practices aren’t theoretical. They come from the experience of teams building production agents that handle real workloads. The difference between agents that impress in demos and agents that deliver business value comes down to execution on these fundamentals.\nTo learn more, check out the Amazon Bedrock AgentCore documentation and get started with our code samples  and hands-on workshops for getting started  and deep diving on AgentCore.\n\nAbout the authors\nMaira Ladeira Tanke is a Tech Lead for Agentic AI at AWS, where she enables customers on their journey to develop autonomous AI systems. With over 10 years of experience in AI/ML, Maira partners with enterprise customers to accelerate the adoption of agentic applications using Amazon Bedrock AgentCore and Strands Agents, helping organizations harness the power of foundation models to drive innovation and business transformation. In her free time, Maira enjoys traveling, playing with her cat, and spending time with her family someplace warm.\nKosti Vasilakakis is a Principal PM at AWS on the Agentic AI team, where he has led the design and development of several Bedrock AgentCore services from the ground up, including Runtime, Browser, Code Interpreter, and Identity. He previously worked on Amazon SageMaker since its early days, launching AI/ML capabilities now used by thousands of companies worldwide. Earlier in his career, Kosti was a data scientist. Outside of work, he builds personal productivity automations, plays tennis, and enjoys life with his wife and kids.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "838c5e68469361d1",
    "title": "Agentic AI for healthcare data analysis with Amazon SageMaker Data Agent",
    "url": "https://aws.amazon.com/blogs/machine-learning/agentic-ai-for-healthcare-data-analysis-with-amazon-sagemaker-data-agent/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-03T16:22:19Z",
    "summary": "On November 21, 2025, Amazon SageMaker introduced a built-in data agent within Amazon SageMaker Unified Studio that transforms large-scale data analysis. In this post, we demonstrate, through a detailed case study of an epidemiologist conducting clinical cohort analysis, how SageMaker Data Agent can help reduce weeks of data preparation into days, and days of analysis development into hours—ultimately accelerating the path from clinical questions to research conclusions.",
    "content": "Performing research and clinical analytics on vast amounts of clinical data can be difficult. Healthcare data scientists and epidemiologists possess deep domain expertise in patient care, disease patterns, and clinical outcomes, yet they often spend weeks navigating complex data infrastructures, writing boilerplate code, and wrestling with technical barriers before they can answer a single clinical question. This slows down research and delays evidence-based decisions, which might impact patient care.\nOn November 21, 2025, Amazon SageMaker introduced a built-in data agent within Amazon SageMaker Unified Studio that transforms large-scale data analysis. Amazon SageMaker Data Agent has a context-aware feature that saves time connecting to clinical data across clinical databases, patient cohorts, and organizational metadata, and autonomously breaks down complex analytical requests into structured, executable plans. For example, when you ask a clinical question, “Compare comorbidity patterns between diabetic and hypertensive patient cohorts,” the data agent thinks through the problem systematically. It creates a multi-step analysis plan, identifies the relevant clinical tables, determines the appropriate statistical methods, generates validated code in the optimal language (SQL, Python, or PySpark), and executes each step with built-in checkpoints for human oversight. SageMaker Data Agent is designed to respect existing customer security controls and governance policies, helping support customer compliance requirements by operating within a customer’s organizational data framework.\nIn this post, we demonstrate, through a detailed case study of an epidemiologist conducting clinical cohort analysis, how SageMaker Data Agent can help reduce weeks of data preparation into days, and days of analysis development into hours—ultimately accelerating the path from clinical questions to research conclusions.\nKey challenges in accelerating healthcare data analytics\nHealthcare research in laboratory settings, clinical settings, academic medical centers, government, and commercial facilities produce enormous volumes of clinical data. Key challenges include:\n\nNavigating complex clinical data – Clinical data catalogs use specialized medical terminology and coding systems that require domain expertise to navigate. Finding which tables contain relevant patient cohorts and understanding how condition codes map across different classification systems creates a significant discovery challenge before analysis even begins.\nPreparing technical data preparation for analysis – After data is located, healthcare analysts spend a significant amount of time doing intensive coding work writing Python or PySpark scripts to extract patient cohorts, calculate clinical metrics, and perform statistical analyses. This technical burden is particularly acute because clinical researchers are often experts in epidemiology or biostatistics and not software engineering.\n\nHow SageMaker Data Agent accelerates healthcare analytics\nSageMaker Data Agent provides a natural language-based interface for healthcare professionals to interact with clinical data. Rather than simply generating code snippets, it functions as an intelligent research assistant that works to understand your specific data environment and clinical objectives. It directly addresses the aforementioned key challenges:\n\nNavigating complex clinical data – SageMaker Data Agent is integrated with the AWS Glue Data Catalog to map your entire healthcare data landscape. The agent understands your actual clinical tables—patient demographics, diagnoses, encounters, conditions, medications, immunizations, procedures—by their real names and relationships, not generic placeholders. It recognizes temporal relationships between encounters, understands how diagnosis codes are structured, and navigates the complex hierarchies of clinical data without requiring you to memorize database schemas.\nPreparing technical data preparation for analysis – The agent transforms natural language clinical questions into production-ready analytical code, reducing code development hours. It generates optimized code across SQL for efficient patient cohort extraction, Python for statistical analysis, and PySpark for large-scale data processing, and it helps clinical researchers use the right tool without needing expertise in each language. It also creates a structured, multi-step analysis plan that mirrors how experienced clinical researchers approach problems: cohort definition, then baseline characteristics, then statistical comparison, and lastly visualization. Each step includes validation points for the user to review the data agent’s process, which will help with clinical validity, proper handling of missing data, and the use of statistically appropriate methods. This agentic approach shifts your time back from technical preparation to clinical interpretation.\n\nSolution overview\nIn this post, we explore through a fictional example how SageMaker Data Agent can assist in clinical research and analysis. In this use case, an epidemiologist at an academic medical center performs detailed analysis of clinical conditions like sinusitis, diabetes, and hypertension through cohort comparison and survival analysis. Their traditional workflow involves navigating multiple disconnected systems to locate datasets, waiting for access approvals, understanding complex data schemas, and writing extensive Python and PySpark code—a multi-week process where most of their time goes to data preparation rather than actual clinical analysis. This bottleneck limits them to just 2–3 comprehensive studies per quarter, directly delaying analytics insights.\nWith AI-powered SageMaker Data Agent, you can see your accessible datasets upon login, validate data quality with quick previews, and use it to perform analysis through natural language prompts—reducing manual coding effort. SageMaker Data Agent is designed to accelerate your research capacity, which can help treatment patterns be identified earlier. By shifting the vast majority of your time from data preparation to actual analysis, SageMaker Data Agent helps you deliver research findings more efficiently while reducing infrastructure costs.SageMaker Data Agent has two interaction modes to help your analysis:\n\nAgent panel for comprehensive clinical analysis – Ideal for end-to-end research projects. This mode breaks complex healthcare questions into structured analytical steps with intermediate review points, maintaining human oversight throughout the process.\nIn-line assistance for focused tasks – Ideal for experienced researchers who want targeted help with specific coding challenges, error fixes, or code enhancements while maintaining hands-on control of their workflow.\n\nThroughout both modes, SageMaker Data Agent operates securely within your AWS environment, respecting AWS Identity and Access Management (IAM) policies and organizational data boundaries, helping you maintain your security controls while accelerating clinical analytics.\nIn the following sections, we walk through the process to use SageMaker Data Agent.\nPrerequisites\nWe chose Synthea as a tool to generate synthetic patient data in CSV format, consisting of data about patients, conditions, immunizations, allergies, encounters, and procedures. Synthea is an open source synthetic patient generator (distributed and used under the Apache 2.0 License ) that models the medical history of synthetic patients. No real human data is used in this post.\nAs part of SageMaker setup, open the SageMaker console and choose Get started to create an IAM- based domain and a project named ClinicalDataProject . For instructions to set up an IAM-based domain and create a project, refer to IAM-based domains and projects .\nPreview clinical data using SQL\nTo preview the data using SQL, complete the following steps:\n\nOn the SageMaker console, choose Open , then choose the project you created ( ClinicalDataProject ).\n\nYou will be redirected to the overview page of SageMaker Unified Studio.\n\nChoose Data in the navigation pane.\nExpand AWSDataCatalog to view the preloaded and cataloged data you have access to in your account.\n\nFor this use case, create each of the tables ( patients , conditions , immunizations , allergies , encounters , and procedures ) under sagemaker_sample_db using the CSV files that you generated earlier by choosing Create table as shown below.\n\nBefore you perform the complex clinical analysis, let’s run a basic query on the conditions table.\n\nChoose the conditions table and choose Preview data on the options menu.\nPerform a SQL operation, for example:\n\nselect * from \"AwsDataCatalog\".\"sagemaker_sample_db\".\"conditions\" limit 10\n\nCreate notebook\nTo perform a detailed analysis, you should create a notebook. Complete the following steps:\n\nChoose Notebooks in the navigation pane.\nChoose Create notebook .\n\nInteract with data\nAfter you create the notebook, you can interact with the data in two ways:\n\nCode directly within notebook cells by using the inline prompt interface. For example, enter “Code to find patient records in conditions table who suffer from Sinusitis,” choose Generate code , and run the cell to display the results.\nUse the Data Agent panel, which supports comprehensive analytical tasks by breaking them down into structured steps, each with generated code that is built on previous results.\n\nIn the following sections, we provide examples of using the Data Agent panel.\nUse SageMaker Data Agent for detailed analysis of clinical data\nIn the Data Agent panel, we enter the query “Find top 20 conditions and perform a detailed analysis of patients with immunizations suffering from those conditions” and generate the code.\n\nSageMaker Data Agent checks the current state of the notebook to understand what data we’re working with. It identifies the conditions , immunizations , and patients tables in the sagemaker_sample_db database. It prepares a comprehensive plan and lists them for you to review. You can review the plan, make necessary changes if needed, and then choose Run step-by-step .\n\nSageMaker Data Agent writes the code in the notebook cells. You can review the code, then choose Accept and run .\n\nSome steps might fail to execute. In this scenario, you can choose Fix with AI to proceed.\n\nWhen the query is complete, the results are displayed, as shown in the following screenshot.\n\nYou can see the bar graph created by SageMaker Data Agent in the notebook titled Demographics Analysis of Immunized Patients with Top 20 Conditions , as shown in the following screenshot.\n\nThe following screenshot shows the graph Condition Prevalence Analysis of Immunized Patients with Top 20 Conditions .\n\nThe following screenshot shows the graph Temporal Analysis of Condition Onset .\n\nA comprehensive dashboard is presented at the end of the notebook.\n\nUse SageMaker Data Agent for cohort comparison and survival analysis\nViral sinusitis shows as the top condition for patients. To perform cohort comparison and survival analysis, we enter the following query in the Data Agent panel: “Build two cohorts 1/ Cohort for Male patients who are suffering from viral sinusitis 2/ Cohort for Female patients who are suffering from viral sinusitis. Run a detailed cohort comparison and survival analysis.”\n\nSageMaker Data Agent prepares a comprehensive plan for cohort creation, cohort comparison analysis, and survival analysis. You can review the plan and then choose Run step-by-step .\n\nThe following screenshot shows the graph Cohort Demographics Comparison: Male vs Female Patients with Viral Sinusitis .\n\nThe following screenshot shows the Kaplan-Meier survival curves and cumulative event curves.\n\nCleanup Resources\nTo remove AWS resources created during this walkthrough, complete the following steps. First, delete the SageMaker Unified Studio project by navigating to the Amazon SageMaker Unified Studio console, selecting your project from the projects list, choosing Delete, and confirming the deletion. This will remove all associated notebooks, data connections, and project resources. Second, remove the AWS Glue Data Catalog resources by opening the AWS Glue console, navigating to Databases and deleting the sample database that got created for this walkthrough. Third, delete S3 buckets and data by opening the Amazon S3 console, locating the S3 bucket where healthcare data is stored, emptying the bucket contents, and deleting the bucket.\nConclusion\nIn this post, we demonstrated how SageMaker Data Agent increases data analysis work velocity, helping you extract impactful data insights. SageMaker Data Agent helps reduce time spent on data management, so you can spend more time identifying treatment patterns and delivering evidence-based recommendations. By simplifying access to complex data analysis through natural language interactions, SageMaker Data Agent can help you increase your research capacity while reducing infrastructure costs. Analyses are documented in reproducible notebooks that can be validated and audited by clinical stakeholders, supporting transparency while accelerating the path from data to impactful analysis.\n\nAbout the authors\nSiddharth is heading Generative AI within SageMaker’s Unified Experiences. His focus is on driving agentic experiences, where AI systems act autonomously on behalf of users to accomplish complex tasks. An alumnus of the University of Illinois at Urbana-Champaign, he brings extensive experience from his roles at Yahoo, Glassdoor, and Twitch.\nNavneet Srivastava  is a Principal Specialist and Analytics Strategy Leader, and develops strategic plans for building an end-to-end analytical strategy for large biopharma, healthcare, and life sciences organizations. His expertise spans across data analytics, data governance, AI, ML, big data, and healthcare-related technologies.\nSubrat Das is a Principal Solutions Architect and part of Global Healthcare and Life Sciences industry division at AWS. He is passionate about modernizing and architecting complex customer workloads. When he’s not working on technology solutions, he enjoys long hikes and traveling around the world.\nIshneet Kaur is a Software Development Manager on the Amazon SageMaker Unified Studio team. She leads the engineering team to design and build generative AI capabilities in SageMaker Unified Studio.\nMohan Gandhi  is a Principal Software Engineer at AWS. He has been with AWS for the last 10 years and has worked on various AWS services like Amazon EMR, Amazon EFA, and Amazon RDS. Currently, he is focused on improving the Amazon SageMaker inference experience. In his spare time, he enjoys hiking and marathons.\nVikramank Singh is a Senior Applied Scientist in the Agentic AI organization in AWS, working on products including Amazon SageMaker Unified Studio, Amazon RDS, and Amazon Redshift. His research interest lies at the intersection of AI, control systems, and RL, particularly using them to build systems for real-world applications that can autonomously perceive environments, model them, and take optimal decisions at scale.\n  Shubham Mehta is a Senior Product Manager at AWS Analytics. He leads generative AI feature development across services such as AWS Glue, Amazon EMR, and Amazon MWAA, using AI/ML to simplify and enhance the experience of data practitioners building data applications on AWS.\nAmit Sinha is a Senior Manager leading SageMaker Unified Studio GenAI and ML product suites. He has over a decade of experience in AI/ML products, infrastructure management, and AWS Big Data processing services. An alumnus of Columbia University, in his free time Amit enjoys hiking and binge-watching documentaries on American history.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "4d9450ab9ccf696e",
    "title": "The Sora feed philosophy",
    "url": "https://openai.com/index/sora-feed-philosophy",
    "source_name": "OpenAI",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-03T00:00:00Z",
    "summary": "Discover the Sora feed philosophy—built to spark creativity, foster connections, and keep experiences safe with personalized recommendations, parental controls, and strong guardrails.",
    "content": "Discover the Sora feed philosophy—built to spark creativity, foster connections, and keep experiences safe with personalized recommendations, parental controls, and strong guardrails.",
    "weight": 1.0,
    "fetch_type": "rss",
    "company": "openai",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  }
]