[
  {
    "id": "e125cb1140ff9c58",
    "title": "How Amazon uses Amazon Nova models to automate operational readiness testing for new fulfillment centers",
    "url": "https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-amazon-nova-models-to-automate-operational-readiness-testing-for-new-fulfillment-centers/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-10T18:34:09Z",
    "summary": "In this post, we discuss how Amazon Nova in Amazon Bedrock can be used to implement an AI-powered image recognition solution that automates the detection and validation of module components, significantly reducing manual verification efforts and improving accuracy.",
    "content": "Amazon is a global ecommerce and technology company that operates a vast network of fulfillment centers to store, process, and ship products to customers worldwide. The Amazon Global Engineering Services (GES) team is responsible for facilitating operational readiness across the company’s rapidly expanding network of fulfillment centers. When launching new fulfillment centers, Amazon must verify that each facility is properly equipped and ready for operations. This process is called operational readiness testing (ORT) and typically requires 2,000 hours of manual effort per facility to verify over 200,000 components across 10,500 workstations. Using Amazon Nova models, we’ve developed an automated solution that significantly reduces verification time while improving accuracy.\nIn this post, we discuss how  Amazon Nova  in  Amazon Bedrock  can be used to implement an AI-powered image recognition solution that automates the detection and validation of module components, significantly reducing manual verification efforts and improving accuracy.\nUnderstanding the ORT Process\nORT is a comprehensive verification process that makes sure the components are properly installed before our fulfillment center is ready for launch. The bill of materials (BOM) serves as the master checklist, detailing every component that should be present in each module of the facility. Each component or item in the fulfillment center is assigned a unique identification number (UIN) that serves as its distinct identifier. These components are essential for accurate tracking, verification, and inventory management throughout the ORT process and beyond. In this post we will refer to UINs and components interchangeably.\nThe ORT workflow has five components:\n\nTesting plan:  Testers receive a testing plan, which includes a BOM that details the exact components and quantities required\nWalk through:  Testers walk through the fulfillment center and stop at each module to review the setup against the BOM. A module is a physical workstation or operational area\nVerify:  They verify proper installation and configuration of each UIN\nTest:  They perform functional testing (i.e. power, connectivity, etc.) on each component\nDocument: They document results for each UIN and move to next module\n\nFinding the Right Approach\nWe evaluated multiple approaches to address the ORT automation challenge, with a focus on using image recognition capabilities from foundation models (FMs). Key factors in the decision-making process include:\nImage Detection Capability:  We selected Amazon Nova Pro for image detection after testing multiple AI models including  Anthropic Claude Sonnet ,  Amazon Nova Pro , Amazon Nova Lite and Meta AI Segment Anything Model (SAM) . Nova Pro met the criteria for production implementation.\nAmazon Nova Pro Features:\nObject Detection Capabilities\n\nPurpose-built for object detection\nProvides precise bounding box coordinates\nConsistent detection results with bounding boxes\n\nImage Processing\n\nBuilt-in image resizing to a fixed aspect ratio\nNo manual resizing needed\n\nPerformance\n\nHigher Request per Minute (RPM) quota on Amazon Bedrock\nHigher Tokens per Minute (TPM) throughput\nCost-effective for large-scale detection\n\nServerless Architecture: We used AWS Lambda and Amazon Bedrock to maintain a cost-effective, scalable solution that didn’t require complex infrastructure management or model hosting.\nAdditional contextual understanding: To improve detection and reduce false positives, we used Anthropic Claude Sonnet 4.0 to generate text descriptions for each UIN and create detection parameters.\nSolution Overview\nThe Intelligent Operational Readiness (IORA) solution includes several key services and is depicted in the architecture diagram that follows:\n\nAPI Gateway: Amazon API Gateway handles user requests and routes to the appropriate Lambda functions\nSynchronous Image Processing: Amazon Bedrock Nova Pro analyzes images with 2-5 second response times\nProgress Tracking: The system tracks UIN detection progress (% UINs detected per module)\nData Storage: Amazon Simple Storage Service (S3) is used to store module images, UIN reference pictures, and results. Amazon DynamoDB is used for storing structured verification data\nCompute: AWS Lambda is used for image analysis and data operations\nModel inference: Amazon Bedrock is used for real-time inference for object detection as well as batch inference for description generation\n\nDescription Generation Pipeline\nThe description generation pipeline is one of the key systems that work together to automate the ORT process. The first is the description generation pipeline, which creates a standardized knowledge base for component identification and is run as a batch process when new modules are introduced. Images taken at the fulfillment center have different lighting conditions and camera angles, which can impact the ability of the model to consistently detect the right component. By using high-quality reference images, we can generate standardized descriptions for each UIN. We then generate detection rules using the BOM, which lists out the required UINs in each module, their associated quantities and specifications. This process makes sure that each UIN has a standardized description and appropriate detection rules, creating a robust foundation for the subsequent detection and evaluation processes.\nThe workflow is as follows:\n\nAdmin uploads UIN images and BOM data\nLambda function triggers two parallel processes:\n\nPath A: UIN description generation\n\nProcess each UIN’s reference images through Claude Sonnet 4.0\nGenerate detailed UIN descriptions\nConsolidate multiple descriptions into one description per UIN\nStore consolidated descriptions in DynamoDB\n\nPath B: Detection rule creation\n\nCombine UIN descriptions with BOM data\nGenerate module-specific detection rules\nCreate false positive detection patterns\nStore rules in DynamoDB\n\n# UIN Description Generation Process\ndef generate_uin_descriptions(uin_images, bedrock_client):\n\"\"\"\nGenerate enhanced UIN descriptions using Claude Sonnet\n\"\"\"\nfor uin_id, image_set in uin_images.items():\n# First pass: Generate initial descriptions from multiple angles\ninitial_descriptions = []\nfor image in image_set:\nresponse = bedrock_client.invoke_model(\nmodelId='anthropic.claude-4-sonnet-20240229-v1:0',\nbody=json.dumps({\n'messages': [\n{\n'role': 'user',\n'content': [\n{'type': 'image', 'source': {'type': 'base64', 'data': image}},\n{'type': 'text', 'text': 'Describe this UIN component in detail, including physical characteristics, typical installation context, and identifying features.'}\n]\n}\n]\n})\n)\ninitial_descriptions.append(response['content'][0]['text'])\n\n# Second pass: Consolidate and enrich descriptions\nconsolidated_description = consolidate_descriptions(initial_descriptions, bedrock_client)\n\n# Store in DynamoDB for quick retrieval\nstore_uin_description(uin_id, consolidated_description)\n\nFalse positive detection patterns\nTo improve output consistency, we optimized the prompt by adding additional rules for common false positives. This helps filter out objects that are not relevant for detection. For instance, triangle signs should have a gate number and arrow and generic signs should not be detected.\n\n3:\ngeneric_object: \"Any triangular sign or warning marker\"\nconfused_with: \"SIGN.GATE.TRIANGLE\"\n▼ distinguishing_features:\n0: \"Gate number text in black at top (e.g., 'GATE 2350')\"\n1: \"Red downward-pointing arrow at bottom\"\n2: \"Red border with white background\"\n3: \"Black mounting system with suspension hardware\"\n\ntrap_description: \"Generic triangle sign ≠ SIGN.GATE.TRIANGLE without gate number and red arrow\"\n\nUIN Detection Evaluation Pipeline\nThis pipeline handles real-time component verification. We input the images taken by the tester, module-specific detection rules, and the UIN descriptions to Nova Pro using Amazon Bedrock. The outputs are the detected UINs with bounding boxes, along with installation status, defect identification, and confidence scores.\n\n# UIN Detection Configuration\ndetection_config = {\n'model_selection': 'nova-pro', # or 'claude-sonnet'\n'module_config': module_id,\n'prompt_engineering': {\n'system_prompt': system_prompt_template,\n'agent_prompt': agent_prompt_template\n},\n'data_sources': {\n's3_images_path': f's3://amzn-s3-demo-bucket/images/{module_id}/',\n'descriptions_table': 'uin-descriptions',\n'ground_truth_path': f's3://amzn-s3-demo-bucket/ground-truth/{module_id}/'\n}\n}\n\nThe Lambda function processes each module image using the selected configuration:\n\ndef detect_uins_in_module(image_data, module_bom, uin_descriptions):\n\"\"\"\nDetect UINs in module images using Nova Pro\n\"\"\"\n# Retrieve relevant UIN descriptions for the module\nrelevant_descriptions = get_descriptions_for_module(module_bom, uin_descriptions)\n\n# Construct detection prompt with descriptions\ndetection_prompt = f\"\"\"\nAnalyze this module image to detect the following components:\n{format_uin_descriptions(relevant_descriptions)}\nFor each UIN, provide:\n- Detection status (True/False)\n- Bounding box coordinates if detected\n- Confidence score\n- Installation status verification\n- Any visible defects\n\"\"\"\n\n# Process with Amazon Bedrock Nova Pro\nresponse = bedrock_client.invoke_model(\nmodelId='amazon.nova-pro-v1:0',\nbody=json.dumps({\n'messages': [\n{\n'role': 'user',\n'content': [\n{'type': 'image', 'source': {'type': 'base64', 'data': image_data}},\n{'type': 'text', 'text': detection_prompt}\n]\n}\n]\n})\n)\nreturn parse_detection_results(response)\n\nEnd-to-End Application Pipeline\nThe application brings everything together and provides testers in the fulfillment center with a production-ready user interface. It also provides comprehensive analysis including precise UIN identification, bounding box coordinates, installation status verification, and defect detection with confidence scoring.\nThe workflow, which is reflected in the UI, is as follows:\n\nA tester securely uploads the images to Amazon S3 from the frontend—either by taking a photo or uploading it manually. Images are automatically encrypted at rest in S3 using AWS Key Management Service (AWS KMS) .\nThis triggers the verification, which calls the API endpoint for UIN verification. API calls between services use AWS Identity and Access Management (IAM) role-based authentication.\nA Lambda function retrieves the images from S3.\nAmazon Nova Pro detects required UINs from each image.\nThe results of the UIN detection are stored in DynamoDB with encryption enabled.\n\nThe following figure shows the UI after an image has been uploaded and processed. The information includes the UIN name, a description, when it was last updated, and so on.\n\nThe following image is of a dashboard in the UI that the user can use to review the results and manually override any inputs if necessary.\nResults & Learnings\nAfter building the prototype, we tested the solution in multiple fulfillment centers using Amazon Kindle tablets. We achieved 92% precision on a representative set of test modules with 2–5 seconds latency per image. Compared to manual operational readiness testing, IORA reduces the total testing time by 60%. Amazon Nova Pro was also able to identify missing labels from the ground truth data, which gave us an opportunity to improve the quality of the dataset.\n\n“The precision results directly translate to time savings – 40% coverage equals 40% time reduction for our field teams. When the solution detects a UIN, our fulfillment center teams can confidently focus only on finding missing components.”\n– Wayne Jones, Sr Program Manager, Amazon General Engineering Services\n\nKey learnings:\n\nAmazon Nova Pro excels at visual recognition tasks when provided with rich contextual descriptions, and outperforms accuracy using standalone image comparison.\nGround truth data quality significantly impacts model performance. The solution identified missing labels in the original dataset and helps improve human labelled data.\nModules with less than 20 UINs performed best, and we saw performance degradation for modules with 40 or more UINs. Hierarchical processing is needed for modules with over 40 components.\nThe serverless architecture using Lambda and Amazon Bedrock provides cost-effective scalability without infrastructure complexity.\n\nConclusion\nThis post demonstrates how to use Amazon Nova and Anthropic Claude Sonnet in Amazon Bedrock to build an automated image recognition solution for operational readiness testing. We showed you how to:\n\nProcess and analyze images at scale using Amazon Nova models\nGenerate and enrich component descriptions to improve detection accuracy\nBuild a reliable pipeline for real-time component verification\nStore and manage results efficiently using managed storage services\n\nThis approach can be adapted for similar use cases that require automated visual inspection and verification across various industries including manufacturing, logistics, and quality assurance. Moving forward, we plan to enhance the system’s capabilities, conduct pilot implementations, and explore broader applications across Amazon operations.\nFor more information about Amazon Nova and other foundation models in Amazon Bedrock, visit the Amazon Bedrock documentation page.\n\nAbout the Authors\nBishesh Adhikari  is a Senior ML Prototyping Architect at AWS with over a decade of experience in software engineering and AI/ML. Specializing in generative AI, LLMs, NLP, CV, and GeoSpatial ML, he collaborates with AWS customers to build solutions for challenging problems through co-development. His expertise accelerates customers’ journey from concept to production, tackling complex use cases across various industries. In his free time, he enjoys hiking, traveling, and spending time with family and friends.\nHin Yee Liu is a Senior GenAI Engagement Manager at AWS. She leads AI prototyping engagements on complex technical challenges, working closely with customers to deliver production-ready solutions leveraging Generative AI, AI/ML, Big Data, and Serverless technologies through agile methodologies. Outside of work, she enjoys pottery, travelling, and trying out new restaurants around London.\nAkhil Anand is a Program Manager at Amazon, passionate about using technology and data to solve critical business problems and drive innovation. He focuses on using data as a core foundation and AI as a powerful layer to accelerate business growth. Akhil collaborates closely with tech and business teams at Amazon to translate ideas into scalable solutions, facilitating a strong user-first approach and rapid product development. Outside of work, Akhil enjoys continuous learning, collaborating with friends to build new solutions, and watching Formula 1.\nZakaria Fanna is a Senior AI Prototyping Engineer at Amazon with over 15 years of experience across diverse IT domains, including Networking, DevOps, Automation, and AI/ML. He specializes in rapidly developing Minimum Viable Products (MVPs) for internal users. Zakaria enjoys tackling challenging technical problems and helping customers scale their solutions by leveraging cutting-edge technologies. In his free time, Zakaria enjoys continuous learning, sports, and cherishes time spent with his children and family.\nElad Dwek is a Senior AI Business Developer at Amazon, working within Global Engineering, Maintenance, and Sustainability. He partners with stakeholders from business and tech side to identify opportunities where AI can enhance business challenges or completely transform processes, driving innovation from prototyping to production. With a background in construction and physical engineering, he focuses on change management, technology adoption, and building scalable, transferable solutions that deliver continuous improvement across industries. Outside of work, he enjoys traveling around the world with his family.\nPalash Choudhury  is a Software Development Engineer at AWS Corporate FP&A with over 10 years of experience across frontend, backend, and DevOps technologies. He specializes in developing scalable solutions for corporate financial allocation challenges and actively leverages AI/ML technologies to automate workflows and solve complex business problems. Passionate about innovation, Palash enjoys experimenting with emerging technologies to transform traditional business processes.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "177e6cdec73a9dc2",
    "title": "Iberdrola enhances IT operations using Amazon Bedrock AgentCore",
    "url": "https://aws.amazon.com/blogs/machine-learning/iberdrola-enhances-it-operations-using-amazon-bedrock-agentcore/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-10T18:31:57Z",
    "summary": "Iberdrola, one of the world’s largest utility companies, has embraced cutting-edge AI technology to revolutionize its IT operations in ServiceNow. Through its partnership with AWS, Iberdrola implemented different agentic architectures using Amazon Bedrock AgentCore, targeting three key areas: optimizing change request validation in the draft phase, enriching incident management with contextual intelligence, and simplifying change model selection using conversational AI. These innovations reduce ...",
    "content": "Iberdrola , one of the world’s largest utility companies, has embraced cutting-edge AI technology to revolutionize its IT operations in ServiceNow . By using different agentic architectures, Iberdrola has transformed the way thousands of change requests and incident tickets are managed, streamlining processes and enhancing productivity across departments.\nThrough its partnership with AWS, Iberdrola implemented those agents in a groundbreaking solution using Amazon Bedrock AgentCore , targeting three key areas: optimizing change request validation in the draft phase, enriching incident management with contextual intelligence, and simplifying change model selection using conversational AI. These innovations reduce bottlenecks, help teams accelerate ticket resolution, and deliver consistent and high-quality data handling throughout the organization.\nAmazon Bedrock AgentCore helps Iberdrola deploy production-ready AI agents seamlessly. With serverless compute capabilities, robust security, and integrated observability, the platform helps Iberdrola scale solutions across departments while adhering to enterprise-grade reliability and compliance standards.\nChallenges with change and incident management\nIberdrola has simplified the multi-phase process of change management using AI-powered validation. A group of orchestrated agents make sure requests align with intended modifications while formatting and verifying mandatory fields in real time. This optimized approach avoids manual resubmissions and drastically reduces processing times, helping teams focus on driving impactful outcomes.\nUsing a swarm of agents to perform contextual enrichment, Iberdrola’s networking department now processes incidents faster and with greater precision. This enrichment lets technicians access configuration item details, review related historical incidents, and categorize tickets by environment and alert types, enhancing response times and enabling teams to swiftly address critical issues.\nSolution overview\nIberdrola establishes its agentic AI practice through a layered architecture that separates operational concerns while enabling seamless integration across IT workflows. ServiceNow serves as the primary input source, and a MicroGateway provides intelligent routing to direct requests to relevant agents. A dedicated data layer maintains enterprise information, processing raw ServiceNow data through extract, transform, and load (ETL) pipelines for agent consumption.\n\nThe architecture comprises three layers:\n\nAgentic AI resources – This layer encompasses all agent deployments, Model Context Protocol (MCP) servers for standardized data access, authentication mechanisms, and memory objects that maintain contextual information. The design enables domain-specific agent development while sharing common infrastructure services.\nInference layer – A streamlined abstraction provides large language model (LLM) inference capabilities from the organization’s portfolio of integrated models. This layer provides consistent model access patterns while supporting experimentation without requiring agent modifications.\nData layer – A comprehensive information foundation contains operational data, analytical datasets, and transactional records. This layer enriches agent capabilities by providing access to historical patterns, real-time operational status, and contextual information necessary for intelligent decision-making.\n\nThis design enables three distinct use cases that address different operational challenges:\n\nEnhanced change management validation – The first implementation supports the draft phase of Iberdrola’s change management process through a deterministic agentic workflow. Multiple specialized agents work in sequence to validate change model appropriateness and verify that mandatory fields contain correctly formatted information. When validation errors are detected, the system provides clear feedback to requesters before allowing progression to subsequent phases.\nIntelligent incident enrichment – The incident management solution demonstrates multi-agent orchestration for Iberdrola’s Networking department. A master agent receives each incident and selectively engages specialized agents for tagging, contextual enrichment, similarity detection, and change impact analysis. This adaptive approach assists technicians by categorizing incidents, identifying related historical cases, and extracting configuration item details.\nConversational change model assistant – The third use case addresses the complexity of selecting appropriate change models through a conversational AI assistant. The agent collects information about technology families, change objectives, and deployment environments to recommend suitable change models. The system provides clickable recommendations that open pre-filled change forms, streamlining the change request process.\n\nThe conceptual architecture translates into a production-ready implementation through Amazon Bedrock AgentCore, which provides managed primitives for building and deploying enterprise AI agents. The serverless approach of Amazon Bedrock AgentCore enables Iberdrola to focus on agent logic rather than infrastructure management while providing scalability and operational reliability.\n\nAmazon Bedrock AgentCore components\nAgentCore Runtime serves as the foundation for agent deployment, accepting containerized agents built with any framework—in Iberdrola’s case, LangGraph —and deploying them through Amazon Elastic Container Registry (Amazon ECR) repositories. AgentCore Runtime maintains serverless characteristics, scaling based on request volume while providing session isolation. Each agent session can run up to 8 hours for complex workflows. Logs and metrics generated by AgentCore Runtime are automatically captured by AgentCore Observability. In addition, Iberdrola has configured explicit logging to their self-hosted Langfuse instance for centralized monitoring.\nAgentCore Memory provides contextual continuity across agent interactions by maintaining memory objects per agent session. Using the memory object, agents can store and retrieve session state, conversation history, and intermediate processing results. This capability is essential for Iberdrola’s multi-step workflows where agents must maintain context across validation phases or incident enrichment processes.\nAgentCore Gateway simplifies tool integration by acting as an MCP server that “MCPifies” external tools and services. Rather than requiring custom integration code for each data source, AgentCore Gateway provides standardized interfaces that agents can consume consistently. This approach is particularly valuable for Iberdrola’s ServiceNow endpoint connections.\nAgentCore Identity manages both inbound and outbound authentication flows, integrating with Entra ID through OAuth 2.0 protocols. For inbound requests, AgentCore Identity validates bearer tokens and authorizes access to underlying resources. For outbound operations, it handles token acquisition and manages secure communication with downstream tools.\nAgentCore Observability captures telemetry data from agents using OpenTelemetry standards and surfaces this information through Amazon CloudWatch . This integration provides comprehensive monitoring of operational metrics without requiring additional instrumentation.\nTechnical implementation\nThe implementation uses LiteLLM as a proxy layer for consistent access to Amazon Nova and Anthropic Claude models through Amazon Bedrock and various other models. This abstraction enables agents to interact with different model variants using standardized API calls while Amazon Bedrock Guardrails provides safety controls for model outputs.\nThe architecture addresses Iberdrola’s enterprise security requirements through a virtual private cloud (VPC) configuration within AgentCore Runtime , so agents can securely access internal resources while maintaining network isolation. VPC endpoints provide secure communication with internal data sources without exposing traffic to the public internet.\nUsers initiate requests through ServiceNow, which communicates through a REST API to the MicroGateway that routes requests to appropriate use case agents. The data architecture implements a hybrid approach combining real-time operational access with enriched analytical datasets. Raw ServiceNow data flows through ETL processes into Amazon Simple Storage Service (Amazon S3) storage, then into Amazon Relational Database Service (Amazon RDS) databases enhanced with pgvector extensions for semantic search.\nThe logs and metrics generated by the agents deployed in AgentCore Runtime can be monitored using AgentCore Observability. In addition, Iberdrola uses self-hosted Langfuse on Amazon Elastic Kubernetes Service (Amazon EKS) for a holistic view of spans and traces generated by the LLMs and the agents.\nUse case details\nIn this section, we discuss the implementation of two use cases mentioned earlier: enhanced change management and intelligent incident management.\nEnhanced change management\nThe first use case demonstrates an agentic workflow that supports the draft phase of Iberdrola’s change management process through sequential agent execution within a single AgentCore Runtime. The workflow processes change requests through four specialized agents—Rule Extractor, Content Validator, AIM Model Analyst, and Phase Transition—with each agent receiving context from the previous step.\nThe implementation consists of the following key components:\n\nSingle runtime context flow – Agents operate within one AgentCore Runtime instance, maintaining seamless context and session state across the entire validation pipeline\nLangGraph orchestration – Agents are defined as a graph structure, enabling visual workflow representation, conditional branching based on validation results, and comprehensive audit trails\nVector-enhanced validation – Pgvector-enabled PostgreSQL supports semantic similarity searches, enabling the AIM Model Analyst agent to match change models based on technical descriptions rather than keyword matching\nConsistent processing – Change requests follow identical validation steps, meeting compliance requirements and quality standards\n\nIntelligent incident management\nThe second use case demonstrates intelligent multi-agent orchestration for incident management, where a Smart Solver Agent analyzes incoming incidents and selectively engages specialized agents based on contextual needs. This implementation adapts processing steps to each incident’s unique characteristics, optimizing resource utilization while providing comprehensive enrichment when needed.\nThe implementation consists of the following key components:\n\nIntelligent orchestration – The Smart Solver Agent analyzes incident content and determines which specialized agents to invoke based on missing context and potential value-add\nSpecialized agent engagement – Five specialized agents (Tag Classifier, Incident Similarity, Incident Associator, Change Associator, Context Retriever) are available to provide enrichment based on the detail and complexity of the incident\nAdaptive processing – The system adjusts enrichment activities based on incident complexity—simple incidents might only require tagging, whereas complex issues receive full contextual analysis\n\nLessons learned\nThe implementation of AI agents at Iberdrola demonstrates how the managed primitives of Amazon Bedrock AgentCore significantly accelerate enterprise AI deployment. Amazon Bedrock AgentCore minimized the infrastructure complexity typically required for agentic AI, helping teams focus on agent logic while achieving scalable and secured cloud resources.“At Iberdrola, we’re extending our production AI platform with a new agentic capability powered by Amazon Bedrock AgentCore,” says Iñigo Gutierrez, AI Global Expert Engineer at Iberdrola. “By using a managed serverless runtime with built-in identity, memory, and observability, we can ship LangGraph-based agents that plan, call tools through MCP-style gateways, and operate securely inside our VPC. This feature moves us from point automations to reusable, production-grade agents—reducing engineering cognitive load and accelerating safe delivery across IT operations.”\nKey success factors\nThe solution offers the following key benefits:\n\nPurpose-built runtime – AgentCore Runtime provides a fully-managed quick start environments to host AI agents with complete session isolation. Additionally, out-of-the-box streaming and MCP and A2A support from AgentCore Runtime alleviate the need to develop custom solutions and build support for these protocols.\nManaged infrastructure – The serverless compute runtimes, identity, and memory services of Amazon Bedrock AgentCore minimize custom development overhead for enterprise-grade capabilities.\nEnterprise security – VPC support and comprehensive tagging aligns with stringent IT requirements, accelerating development without compromising security standards.\nOpen and framework-agnostic – Amazon Bedrock AgentCore fits well with development guidelines because you can choose the development framework, such as LangGraph, by adding a simple decorator. Furthermore, it has no restrictions on using third-party or open-source solutions like Langfuse.\nScalable tool discovery – AgentCore Gateway automatically indexes tools and provides serverless semantic search, scaling from tens to hundreds of targets, totally managed.\n\nFuture roadmap\nIberdrola is considering the following future enhancements to the solution:\n\nAgent catalog – Improve governance and discovery of agents seamlessly integrated into the Amazon Bedrock AgentCore ecosystem\nNew supported protocols and standards – Evolve Iberdrola’s agent development to use new protocols supported (such as A2A) by AgentCore Runtime and other managed services\nManaged orchestration and real-time flow monitoring – Build platform-provided dashboards that automatically manage and monitor complex interactions between multiple AI agents, tools, or workflows\n\nConclusion\nIberdrola’s innovative implementation showcases its leadership and vision in using advanced AI technologies to transform its operational workflows. By adopting Amazon Bedrock AgentCore, Iberdrola has demonstrated how organizations can deploy production-ready AI agents with remarkable efficiency while meeting robust enterprise security and scalability standards. Through its strategic use of Amazon Bedrock AgentCore managed primitives, Iberdrola has realized substantial productivity gains and unparalleled improvements in data quality across its change and incident management processes. This successful transformation underscores Iberdrola’s commitment to excellence in using intelligent solutions to solve complex operational challenges. It also highlights the unique value proposition of Amazon Bedrock AgentCore: industry-first serverless compute for AI agents, integrated enterprise-grade security, and adaptable deployment patterns that accommodate diverse processing requirements. The platform’s ability to streamline infrastructure complexity while supporting specialized workflows makes it an ideal foundation for enterprise AI initiatives.\nOrganizations looking to implement AI agents in production environments can draw inspiration from Iberdrola’s architectural patterns and its effective execution of AI-driven solutions. Iberdrola’s success serves as a blueprint for accelerating deployments and achieving operational excellence with an Amazon Bedrock AgentCore managed approach, which reduces time-to-value and supports the scale and reliability demanded by enterprise AI systems.\n\nAbout the authors\nTalha Chattha is a Sr. Agentic AI Specialist SA at AWS, based in Stockholm. With 10+ years of experience working with AI, Talha now helps establish practices to ease the path to production for Agentic AI workloads. Talha is an expert in AgentCore and supports customers across entire EMEA. He holds passion about meta-agents, async patterns, advanced hierarchical solutions and optimized context engineering for agents. When not shaping the future of AI, he explores the scenic European landscapes and delicious cuisines. Connect with Talha at LinkedIn.\nUnai Bermejo is a Global Expert AI Engineer at Iberdrola. With 10 years of experience in applied AI, AI research, and software engineering, Unai now helps Iberdrola establish best practices and frameworks in AI and agentic initiatives, aligned with corporate platforms and business needs. He acts as a technical bridge between AI technology, Cloud engineering teams, and business developers, driving the adoption of scalable, responsible, and high‑impact AI solutions across the organization.\nXabier Muruaga is the Global Head of AI and Data at Iberdrola. With over 15 years of experience in AI/ML and data‑driven architectures, he leads the company’s strategy and governance for secure, cloud‑native, and production‑ready AI platforms. His background across architecture, digital transformation, and energy technologies enables him to drive responsible, high‑impact AI and agentic initiatives across the organization.\nIñigo Gutierrez is a Global Cloud AI Engineer at Iberdrola with five years of experience in Cloud architecture, platform engineering, and AI enablement. Based in Bilbao, he is responsible for the design, evolution, and governance of the company’s corporate Cloud platforms, ensuring they provide a secure and scalable foundation for AI and digital transformation initiatives. Iñigo acts as a technical enabler between Cloud engineering teams, AI projects, and business units, promoting standardized practices, operational excellence, and the adoption of responsible, high‑impact AI solutions across the organization.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  },
  {
    "id": "f0cc9530f5e800cc",
    "title": "Building real-time voice assistants with Amazon Nova Sonic compared to cascading architectures",
    "url": "https://aws.amazon.com/blogs/machine-learning/building-real-time-voice-assistants-with-amazon-nova-sonic-compared-to-cascading-architectures/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-02-10T18:29:05Z",
    "summary": "Amazon Nova Sonic delivers real-time, human-like voice conversations through the bidirectional streaming interface. In this post, you learn how Amazon Nova Sonic can solve some of the challenges faced by cascaded approaches, simplify building voice AI agents, and provide natural conversational capabilities. We also provide guidance on when to choose each approach to help you make informed decisions for your voice AI projects.",
    "content": "Voice AI agents are reshaping how we interact with technology. From customer service and healthcare assistance to home automation and personal productivity, these intelligent virtual assistants are rapidly gaining popularity across industries. Their natural language capabilities, constant availability, and increasing sophistication make them valuable tools for businesses seeking efficiency and individuals desiring seamless digital experiences.\nAmazon Nova Sonic  delivers real-time, human-like voice conversations through the bidirectional streaming interface. It understands different speaking styles and generates expressive responses that adapt to both the words spoken and the way they are spoken. The model supports multiple languages and offers both masculine and feminine voices, making it ideal for customer support, marketing calls, voice assistants, and educational applications.\nWhen compared with newer architectures such as Amazon Nova Sonic—which combines speech understanding and generation into a single end-to-end model—classic AI voice chat systems use cascading architectures with sequential processing. These systems process a user’s speech through a distinct pipeline: The cascaded models approach breaks down voice AI processing into separate components:\n\nVoice activity detection (VAD) : A pre-processing VAD is required to detect when the user pauses or stops speaking.\nSpeech-to-text (STT) : The user’s spoken words are converted into a written text format by an automatic speech recognition (ASR) model.\nLarge language model (LLM) processing : The transcribed text is then fed to a LLM or dialogue manager, which analyzes the input and generates a relevant textual response based on the conversation’s context.\nText-to-speech (TTS) : The AI’s text-based reply is then converted back into natural-sounding spoken audio by a TTS model, which is then played to the user.\n\nThe following diagram illustrates the conceptual flow of how users interact with Nova Sonic for real-time voice conversations compared to a cascading voice assistant solution.\n\nThe core challenges of cascading architecture\nWhile a cascading architecture offers benefits such as modular design, specialized components, and debuggability, cumulative latency and reduced interactivity are its drawbacks.\nThe cascade effect\nConsider a voice assistant handling a simple weather query. In cascading pipelines, each processing step introduces latency and potential errors. Customer implementations showed how initial misinterpretations can compound through the pipeline, often resulting in irrelevant responses. This cascading effect complicated troubleshooting and negatively impacted overall user experience.\nTime is everything\nReal conversations require natural timing. Sequential processing can create noticeable delays in response times. These interruptions in conversational flow can lead to user friction.\nThe integration challenge\nVoice AI demands more than just speech processing—it requires natural interaction patterns. Customer feedback highlighted how orchestrating multiple components made it difficult to handle dynamic conversation elements like interruptions or rapid exchanges. Engineering resources often focused more on pipeline management.\nResource reality\nCascading architectures require independent computing resources, monitoring, and maintenance for each component. This architectural complexity impacts both development velocity and operational efficiency. Scaling challenges intensify as conversation volumes increase, affecting system reliability and cost optimization.\nImpact on voice assistant development\nThese insights drove key architectural decisions in Nova Sonic development, addressing the fundamental need for unified speech-to-speech processing that enables natural, responsive voice experiences without the complexity of multi-component management.\nComparing the two approaches\nTo compare the speech-to-speech and cascaded approach to building voice AI agents, consider the following:\n\nConsideration\nSpeech-to-speech (Nova Sonic)\nCascaded models\n\nLatency\nOptimized latency performance and TTFA  We evaluate the latency performance of Nova Sonic model using the Time to First Audio (TTFA 1.09) metric. TTFA measures the elapsed time from the completion of a user’s spoken query until the first byte of response audio is received. See technical report and model card .\nPotential added latency and errors Cascaded models can use multiple models across speech recognition, language understanding, and voice generation, but are challenged by added latency and potential error propagation between stages. By using modern asynchronous orchestration frameworks like Pipecat and LiveKit, you can minimize latency. Streaming components and using text-to-speech fillers help maintain natural conversational flow and reduce delays\n\nArchitecture and development complexity\nSimplified architecture Nova Sonic combines speech-to-text, natural language understanding, and text-to-speech in the one model with built-in tool use and barge-in detection, providing an event-driven architecture for key input and output events , and a bidirectional streaming API for a simplified developer experience.\nPotential complexity in architecture Developers need to select best-in-class models for each stage of the pipeline, while orchestrating additional components such as asynchronous pipelines for delegated agents and tool use, TTS fillers and (VAD).\n\nModel selection and customization\nLess control over individual components Amazon Nova Sonic allows customization of voices , built-in tool use and integrations to Amazon Bedrock Knowledge Bases and Amazon Bedrock AgentCore . However, it offers less granular control over individual model components compared to fully modular cascaded systems.\nPotential granular control over each step Cascaded models provide more control over each step by allowing individual tuning, replacement, and optimization of each model components such as STT, language understanding, and TTS independently. This includes models from Amazon Bedrock Marketplace , Amazon SageMaker AI and fine–tuned models. This modularity enables selection and flexibility of models, making it ideal for complex or specialized capabilities requiring tailored performance.\n\nCost structure\nSimplified cost structure through an integrated approach Amazon Nova Sonic is priced on a token-based consumption model.\nPotential complexity in costs associated with multiple components Cascaded models consist of multiple components whose costs need to be estimated. This is especially important at scale and high volumes.\n\nLanguage and accent support\nLanguages supported by Nova Sonic\nPotential broader language support through specialized models including the ability to switch languages mid-conversation\n\nRegion availability\nRegions supported by Nova Sonic\nPotential broader region support because of the broad selection of models and ability to self-host models on Amazon Elastic Kubernetes Service (Amazon EKS) or Amazon SageMaker .\n\nThe two approaches also have some shared traits.\n\nTelephony and transport options\nBoth cascaded and speech-to-speech approaches support a variety of telephony and transport protocols such as WebRTC and WebSocket, enabling real-time, low-latency audio streaming over the web and phone networks. These protocols facilitate seamless, bidirectional audio exchange crucial for natural conversational experiences, allowing voice AI systems to integrate easily with existing communication infrastructures while maintaining responsiveness and audio quality.\n\nEvaluations, observability, and testing\nBoth cascaded and speech-to-speech voice AI approaches can be systematically evaluated, observed, and tested for reliable comparison. Investing in a voice AI evaluation and observability system is recommended to gain confidence in production accuracy and performance. Such a system should be capable of tracing the entire input-to-output pipeline, capturing metrics and conversation data end-to-end to comprehensively assess quality, latency, and conversational robustness over time.\n\nDeveloper frameworks\nBoth cascaded and speech-to-speech approaches are well supported by leading open-source voice AI frameworks like Pipecat and LiveKit. These frameworks provide modular, flexible pipelines and real-time processing capabilities that developers can use to build, customize, and orchestrate voice AI models efficiently across different components and interaction styles.\n\nWhen to use each approach\nThe following diagram shows a practical framework to guide your architecture decision:\n\nUse speech-to-speech when:\n\nSimplicity of implementation is important\nThe use case fits within Nova Sonic’s capabilities\nYou’re looking for a real-time chat experience that feels human-like and delivers low latency\n\nUse cascaded models when:\n\nCustomization of individual components is required\nYou need to use specialized models from the Amazon Bedrock Marketplace , Amazon SageMaker AI, or fine-tuned models for your specific domain\nYou need support for languages or accents not covered by Nova Sonic\nThe use case requires specialized processing at specific stages\n\nConclusion\nIn this post, you learned how Amazon Nova Sonic is designed to solve some of the challenges faced by cascaded approaches, simplify building voice AI agents, and provide natural conversational capabilities. We also provided guidance on when to choose each approach to help you make informed decisions for your voice AI projects. If you’re looking to enhance your cascaded voice system, you know have the basics of how to migrate to Nova Sonic so you can offer seamless, real-time conversational experiences with a simplified architecture.\nTo learn more, see Amazon Nova Sonic and contact your account team to explore how you can accelerate your voice AI initiatives.\nResources\n\nAmazon Nova Sonic Technical Report and Model Card\nAmazon Nova Sonic User Guide\nAmazon Nova Sonic and Amazon Bedrock AgentCore\nAmazon Nova Sonic Telephony Integration Guide\nAmazon Nova Sonic and Pipecat\nAmazon Nova Sonic and LiveKit\n\nAbout the authors\nDaniel Wirjo is a Solutions Architect at AWS, focused on AI and SaaS startups. As a former startup CTO, he enjoys collaborating with founders and engineering leaders to drive growth and innovation on AWS. Outside of work, Daniel enjoys taking walks with a coffee in hand, appreciating nature, and learning new ideas.\nRavi Thakur is a Sr Solutions Architect at AWS based in Charlotte, NC. He has cross‑industry experience across retail, financial services, healthcare, and energy & utilities, and specializes in solving complex business challenges using well‑architected cloud patterns. His expertise spans microservices, cloud‑native architectures, and generative AI. Outside of work, Ravi enjoys motorcycle rides and family getaways.\nLana Zhang is a Senior Specialist Solutions Architect for Generative AI at AWS within the Worldwide Specialist Organization. She specializes in AI/ML, with a focus on use cases such as AI voice assistants and multimodal understanding. She works closely with customers across diverse industries, including media and entertainment, gaming, sports, advertising, financial services, and healthcare, to help them transform their business solutions through AI.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": null,
    "analyzed_at": null,
    "analysis_status": "failed",
    "analysis_error": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
  }
]