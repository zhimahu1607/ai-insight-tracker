[
  {
    "id": "ff7f93e3363eac95",
    "title": "Build AI agents with Amazon Bedrock AgentCore using AWS CloudFormation",
    "url": "https://aws.amazon.com/blogs/machine-learning/build-ai-agents-with-amazon-bedrock-agentcore-using-aws-cloudformation/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-01-23T17:54:02Z",
    "summary": "Amazon Bedrock AgentCore services are now being supported by various IaC frameworks such as AWS Cloud Development Kit (AWS CDK), Terraform and AWS CloudFormation Templates. This integration brings the power of IaC directly to AgentCore so developers can provision, configure, and manage their AI agent infrastructure. In this post, we use CloudFormation templates to build an end-to-end application for a weather activity planner.",
    "content": "Agentic-AI has become essential for deploying production-ready AI applications, yet many developers struggle with the complexity of manually configuring agent infrastructure across multiple environments. Infrastructure as code (IaC) facilitates consistent, secure, and scalable infrastructure that autonomous AI systems require. It minimizes manual configuration errors through automated resource management and declarative templates, reducing deployment time from hours to minutes while facilitating infrastructure consistency across the environments to help prevent unpredictable agent behavior. It provides version control and rollback capabilities for quick recovery from issues, essential for maintaining agentic system availability, and enables automated scaling and resource optimization through parameterized templates that adapt from lightweight development to production-grade deployments. For agentic applications operating with minimal human intervention, the reliability of IaC, automated validation of security standards, and seamless integration into DevOps workflows are essential for robust autonomous operations.\nIn order to streamline the resource deployment and management, Amazon Bedrock AgentCore services are now being supported by various IaC frameworks such as AWS Cloud Development Kit (AWS CDK), Terraform and AWS CloudFormation Templates . This integration brings the power of IaC directly to AgentCore so developers can provision, configure, and manage their AI agent infrastructure. In this post, we use CloudFormation templates to build an end-to-end application for a weather activity planner. Examples of using CDK and Terraform can be found at GitHub Sample Library .\nBuilding an activity planner agent based on weather\nThe sample creates a weather activity planner, demonstrating a practical application that processes real-time weather data to provide personalized activity recommendations based on a location of interest. The application consists of multiple integrated components:\n\nReal-time weather data collection – The application retrieves current weather conditions from authoritative meteorological sources such as weather.gov, gathering essential data points including temperature readings, precipitation probability forecasts, wind speed measurements, and other relevant atmospheric conditions that influence outdoor activity suitability.\nWeather analysis engine – The application processes raw meteorological data through customized logic to evaluate suitability of a day for an outdoor activity based on multiple weather factors:\n\nTemperature comfort scoring – Activities receive reduced suitability scores when temperatures drop below 50°F\nPrecipitation risk assessment – Rain probabilities exceeding 30% trigger adjustments to outdoor activity recommendations\nWind condition impact evaluation – Wind speeds above 15 mph affect overall comfort and safety ratings for various activities\n\nPersonalized recommendation system – The application processes weather analysis results with user preferences and location-based awareness to generate tailored activity suggestions.\n\nThe following diagram shows this flow.\n\nNow let’s look at how this can be implemented using AgentCore services:\n\nAgentCore Browser – For automated browsing of weather data from sources such as weather.gov\nAgentCore Code Interpreter – For executing Python code that processes weather data, performs calculations, and implements the scoring algorithms\nAgentCore Runtime – For hosting an agent that orchestrates the application flow, managing data processing pipelines, and coordinating between different components\nAgentCore Memory – For storing the user preferences as long term memory\n\nThe following diagram shows this architecture.\n\nDeploying the CloudFormation template\n\nDownload the CloudFormation template from github for End-to-End-Weather-Agent.yaml on your local machine\nOpen CloudFormation from AWS Console\nClick  Create stack  →  With new resources (standard)\nChoose template source (upload file) and select your template\nEnter stack name and change any required parameters if needed\nReview configuration and acknowledge IAM capabilities\nClick  Submit  and monitor deployment progress on the Events tab\n\nHere is the visual steps for CloudFomation template deployment\n\nRunning and testing the application\n\nAdding observability and monitoring\nAgentCore Observability provides key advantages. It offers quality and trust through detailed workflow visualizations and real-time performance monitoring. You can gain accelerated time-to-market by using Amazon CloudWatch powered dashboards that reduce manual data integration from multiple sources, making it possible to take corrective actions based on actionable insights. Integration flexibility with OpenTelemetry-compatible format supports existing tools such as CloudWatch ,  DataDog ,  Arize  Phoenix ,  LangSmith , and  LangFuse .\nThe service provides end-to-end traceability across frameworks and foundation models (FMs), captures critical metrics such as token usage and tool selection patterns, and supports both automatic instrumentation for AgentCore Runtime hosted agents and configurable monitoring for agents deployed on other services. This comprehensive observability approach helps organizations achieve faster development cycles, more reliable agent behavior, and improved operational visibility while building trustworthy AI agents at scale.\nThe following screenshot shows metrics in the AgentCore Runtime UI.\n\nCustomizing for your use case\nThe weather activity planner AWS CloudFormation template is designed with modular components that can be seamlessly adapted for various applications. For instance, you can customize the AgentCore Browser tool to collect information from different web applications (such as financial websites for investment guidance, social media feeds for sentiment monitoring, or ecommerce sites for price tracking), modify the AgentCore Code Interpreter algorithms to process your specific business logic (such as predictive modeling for sales forecasting, risk assessment for insurance, or quality control for manufacturing), adjust the AgentCore Memory component to store relevant user preferences or business context (such as customer profiles, inventory levels, or project requirements), and reconfigure the Strands Agents tasks to orchestrate workflows specific to your domain (such as supply chain optimization, customer service automation, or compliance monitoring).\nBest practices for deployments\nWe recommend the following practices for your deployments:\n\nModular component architecture – Design AWS CloudFormation templates with separate sections for each AWS Services.\nParameterized template design – Use AWS CloudFormation parameters for the configurable elements to facilitate reusable templates across environments. For example, this can help associate the same base container with multiple agent deployments, help point to two different build configurations, or parameterize the LLM of choice for powering your agents.\nAWS Identity and Access Management (IAM) security and least privilege – Implement fine-grained IAM roles for each AgentCore component with specific resource Amazon Resource Names (ARNs). Refer to our documentation on AgentCore security considerations .\nComprehensive monitoring and observability – Enable CloudWatch logging, custom metrics, AWS X-Ray distributed tracing, and alerts across the components.\nVersion control and continuous integration and continuous delivery (CI/CD) integration – Maintain templates in GitHub with automated validation, comprehensive testing, and AWS CloudFormation StackSets for consistent multi-Region deployments.\n\nYou can find a more comprehensive set of best practices at CloudFormation best practices\nClean up resources\nTo avoid incurring future charges, delete the resources used in this solution:\n\nOn the Amazon S3 console , manually delete the contents inside the bucket you created for template deployment and then delete the bucket.\nOn the CloudFormation console , choose Stacks in the navigation pane, select the main stack, and choose Delete .\n\nConclusion\nIn this post, we introduced an automated solution for deploying AgentCore services using AWS CloudFormation. These preconfigured templates enable rapid deployment of powerful agentic AI systems without the complexity of manual component setup. This automated approach helps save time and facilitates consistent and reproducible deployments so you can focus on building agentic AI workflows that drive business growth.\nTry out some more examples from our Infrastructure as Code sample repositories :\n\nTerraform\nCloudFormation\nCDK\n\nAbout the authors\nChintan Patel is a Senior Solution Architect at AWS with extensive experience in solution design and development. He helps organizations across diverse industries to modernize their infrastructure, demystify Generative AI technologies, and optimize their cloud investments. Outside of work, he enjoys spending time with his kids, playing pickleball, and experimenting with AI tools.\nShreyas Subramanian  is a Principal Data Scientist and helps customers by using Generative AI and deep learning to solve their business challenges using AWS services like Amazon Bedrock and AgentCore. Dr. Subramanian contributes to cutting-edge research in deep learning, Agentic AI, foundation models and optimization techniques with several books, papers and patents to his name. In his current role at Amazon, Dr. Subramanian works with various science leaders and research teams within and outside Amazon, helping to guide customers to best leverage state-of-the-art algorithms and techniques to solve business critical problems. Outside AWS, Dr. Subramanian is a expert reviewer for AI papers and funding via organizations like Neurips, ICML, ICLR, NASA and NSF.\nKosti Vasilakakis is a Principal PM at AWS on the Agentic AI team, where he has led the design and development of several Bedrock AgentCore services from the ground up, including Runtime. He previously worked on Amazon SageMaker since its early days, launching AI/ML capabilities now used by thousands of companies worldwide. Earlier in his career, Kosti was a data scientist. Outside of work, he builds personal productivity automations, plays tennis, and explores the wilderness with his family.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": {
      "summary": "Amazon AWS宣布其Amazon Bedrock AgentCore服务现在支持通过AWS CloudFormation等基础设施即代码（IaC）框架进行部署，使开发者能快速配置和管理AI代理基础设施。这一集成利用IaC技术减少人工配置错误，缩短部署时间，并确保环境一致性，对于构建生产就绪的AI应用程序至关重要。新闻通过一个天气活动规划器的示例应用，详细展示了如何使用AgentCore组件（如AgentCore Browser、Code Interpreter、Runtime和Memory）处理实时天气数据并提供个性化建议。此举提升了AI代理的开发效率，支持自动化监控和可扩展部署，帮助企业更轻松地构建可靠的AI系统以驱动业务增长。",
      "category": "产品",
      "sentiment": "positive",
      "keywords": [
        "Amazon AWS",
        "Amazon Bedrock AgentCore",
        "AWS CloudFormation",
        "Infrastructure as Code",
        "Agentic AI"
      ]
    },
    "analyzed_at": "2026-01-24T03:11:34.206216Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "df040834e32264a6",
    "title": "How the Amazon.com Catalog Team built self-learning generative AI at scale with Amazon Bedrock",
    "url": "https://aws.amazon.com/blogs/machine-learning/how-the-amazon-com-catalog-team-built-self-learning-generative-ai-at-scale-with-amazon-bedrock/",
    "source_name": "Amazon AWS ML",
    "source_category": "ai",
    "language": "en",
    "published": "2026-01-23T17:49:37Z",
    "summary": "In this post, we demonstrate how the Amazon Catalog Team built a self-learning system that continuously improves accuracy while reducing costs at scale using Amazon Bedrock.",
    "content": "The Amazon.com Catalog is the foundation of every customer’s shopping experience—the definitive source of product information with attributes that power search, recommendations, and discovery. When a seller lists a new product, the catalog system must extract structured attributes—dimensions, materials, compatibility, and technical specifications—while generating content such as titles that match how customers search. A title isn’t a simple enumeration like color or size; it must balance seller intent, customer search behavior, and discoverability. This complexity, multiplied by millions of daily submissions, makes catalog enrichment an ideal proving ground for self-learning AI.\nIn this post, we demonstrate how the Amazon Catalog Team built a self-learning system that continuously improves accuracy while reducing costs at scale using Amazon Bedrock .\nThe challenge\nIn generative AI deployment environments, improving model performance calls for constant attention. Because models process millions of products, they inevitably encounter edge cases, evolving terminology, and domain-specific patterns where accuracy may degrade. The traditional approach—applied scientists analyzing failures, updating prompts, testing changes, and redeploying—works but is resource-intensive and struggles to keep pace with real-world volume and variety. The challenge isn’t whether we can improve these systems, but how to make improvement scalable and automatic rather than dependent on manual intervention. At Amazon Catalog, we faced this challenge head-on. The tradeoffs seemed impossible: large models would deliver accuracy but wouldn’t scale efficiently to our volume, while smaller models struggled with the complex, ambiguous cases where sellers needed the most help.\nSolution overview\nOur breakthrough came from an unconventional experiment. Instead of choosing a single model, we deployed multiple smaller models to process the same products. When these models agreed on an attribute extraction, we could trust the result. But when they disagreed—whether from genuine ambiguity, missing context, or one model making an error—we discovered something profound. These disagreements weren’t always errors, but they were almost always indicators of complexity. This led us to design a self-learning system that reimagines how generative AI scales. Multiple smaller models process routine cases through consensus, invoking larger models only when disagreements occur. The larger model is implemented as a supervisor agent with access to specialized tools for deeper investigation and analysis. But the supervisor doesn’t just resolve disputes; it generates reusable learnings stored in a dynamic knowledge base that helps prevent entire classes of future disagreements. We invoke more powerful models only when the system detects high learning value at inference time, while correcting the output. The result is a self-learning system where costs decrease and quality increases—because the system learns to handle edge cases that previously triggered supervisor calls. Error rates fell continuously, not through retraining but through accumulated learnings from resolved disagreements injected into smaller model prompts. The following figure shows the architecture of this self-learning system.\n\nIn the self-learning architecture, product data flows through generator-evaluator workers, with disagreements routed to a supervisor for investigation. Post-inference, the system also captures feedback signals from sellers (such as listing updates and appeals) and customers (such as returns and negative reviews). Learnings from the sources are stored in a hierarchical knowledge base and injected back into worker prompts, creating a continuous improvement loop.\nThe following describes a simplified reference architecture that demonstrates how this self-learning pattern can be implemented using AWS services. While our production system has additional complexity, this example illustrates the core components and data flows.\nThis system can be built with Amazon Bedrock, which provides the essential infrastructure for multi-model architectures. The ability of Amazon Bedrock to access diverse foundation models enables teams to deploy smaller, efficient models like Amazon Nova Lite as workers and more capable models like Anthropic Claude Sonnet as supervisors—optimizing both cost and performance. For even greater cost efficiency at scale, teams can also deploy open source small models on Amazon Elastic Compute Cloud (Amazon EC2) GPU instances, providing full control over worker model selection and batch throughput optimization. For productionizing a supervisor agent with its specialized tools and dynamic knowledge base, Bedrock AgentCore provides the runtime scalability, memory management, and observability needed to deploy self-learning systems reliably at scale.\n\nOur supervisor agent integrates with Amazon’s extensive Selection and Catalog Systems. The above diagram is a simplified view showing the key features of the agent and some of the AWS services that make it possible. Product data flows through generator-evaluator workers (Amazon EC2 and Amazon Bedrock Runtime ), with agreements stored directly and disagreements routed to a supervisor agent (Bedrock AgentCore). The learning aggregator and memory manager utilize Amazon DynamoDB for the knowledge base, with learnings injected back into worker prompts. Human review ( Amazon Simple Queue Service (Amazon SQS) ) and observability ( Amazon CloudWatch ) complete the architecture. Production implementations will likely require additional components for scale, reliability, and integration with existing systems.\nBut how did we arrive at this architecture? The key insight came from an unexpected place.\nThe insight: Turning disagreements into opportunities\nOur perspective shifted during a debugging session. When multiple smaller models (such as Nova Lite) disagreed on product attributes—interpreting the same specification differently based on how they understood technical terminology—we initially saw this as a failure. But the data told a different story: products where our smaller models disagreed correlated with cases requiring more manual review and clarification. When models disagreed, those were precisely the products that needed additional investigation. The disagreements were surfacing learning opportunities, but we couldn’t have engineers and scientists deep-dive on every case. The supervisor agent does this automatically at scale. And crucially, the goal isn’t just to determine which model was right—it’s to extract learnings that help prevent similar disagreements in the future. This is the key to efficient scaling. Disagreements don’t just come from AI workers at inference time. Post-inference, sellers express disagreement through listing updates and appeals—signals that our original extraction might have missed important context. Customers disagree through returns and negative reviews, often indicating that product information didn’t match expectations. These post-inference human signals feed into the same learning pipeline, with the supervisor investigating patterns and generating learnings that help prevent similar issues across future products. We found a sweet spot: attributes with moderate AI worker disagreement rates yielded the richest learnings—high enough to surface meaningful patterns, low enough to indicate solvable ambiguity. When disagreement rates are too low, they typically reflect noise or fundamental model limitations rather than learnable patterns—for those, we consider using more capable workers. When disagreement rates are too high, it signals that worker models or prompts aren’t yet mature enough, triggering excessive supervisor calls that undermine the efficiency gains of the architecture. These thresholds will vary by task and domain; the key is identifying your own sweet spot where disagreements represent genuine complexity worth investigating, rather than fundamental gaps in worker capability or random noise.\nDeep dive: How it works\nAt the heart of our system are multiple lightweight worker models operating in parallel—some as generators extracting attributes, others as evaluators assessing those extractions. These workers can be implemented in a non-agentic way with fixed inputs, making them batch-friendly and scalable. The generator-evaluator pattern creates productive tension, conceptually similar to the productive tension in generative adversarial networks (GANs), though our approach operates at inference time through prompting rather than training. We explicitly prompt evaluators to be critical, instructing them to scrutinize extractions for ambiguities, missing context, or potential misinterpretations. This adversarial dynamic surfaces disagreements that represent genuine complexity rather than letting ambiguous cases pass through undetected. When the generator and evaluator agree, we have high confidence in the result and process it at minimal computational cost. This consensus path handles most product attributes. When they disagree, we’ve identified a case worth investigating—triggering the supervisor to resolve the dispute and extract reusable learnings.\nOur architecture treats disagreement as a universal learning signal. At inference time, worker-to-worker disagreements catch ambiguity. Post-inference, seller feedback catches misalignments with intent and customer feedback catches misalignments with expectations. The three channels feed the supervisor, which extracts learnings that improve accuracy across the board. When workers disagree, we invoke a supervisor agent—a more capable model that resolves the dispute and investigates why it occurred. The supervisor determines what context or reasoning the workers lacked, and these insights become reusable learnings for future cases. For example, when workers disagreed about usage classification for a product based on certain technical terms, the supervisor investigated and clarified that those terms alone were insufficient—visual context and other indicators needed to be considered together. The supervisor generated a learning about how to properly weight different signals for that product category. This learning immediately updated our knowledge base, and when injected into worker prompts for similar products, helped prevent future disagreements across thousands of items. While the workers could theoretically be the same model as the supervisor, using smaller models is crucial for efficiency at scale. The architectural advantage emerges from this asymmetry: lightweight workers handle routine cases through consensus, while the more capable supervisor is invoked only when disagreements surface high-value learning opportunities. As the system accumulates learnings and disagreement rates drop, supervisor calls naturally decline—efficiency gains are baked directly into the architecture. This worker-supervisor heterogeneity also enables richer investigation. Because supervisors are invoked selectively, they can afford to pull in additional signals—customer reviews, return reasons, seller history—that would be impractical to retrieve for every product but provide crucial context when resolving complex disagreements. When these signals yield generalizable insights about how customers want product information presented—which attributes to highlight, what terminology resonates, how to frame specifications—the resulting learnings benefit future inferences across similar products without retrieving those resource-intensive signals again. Over time, this creates a feedback loop: better product information leads to fewer returns and negative reviews, which in turn reflects improved customer satisfaction.\nThe knowledge base: Making learnings scalable\nThe supervisor investigates disagreements at the individual product level. With millions of items to process, we need a scalable way to transform these product-specific insights into reusable learnings. Our aggregation strategy adapts to context: high-volume patterns get synthesized into broader learnings, while unique or critical cases are preserved individually. We use a hierarchical structure where a large language model (LLM)-based memory manager navigates the knowledge tree to place each learning. Starting from the root, it traverses categories and subcategories, deciding at each level whether to continue down an existing path, create a new branch, merge with existing knowledge, or replace outdated information. This dynamic organization allows the knowledge base to evolve with emerging patterns while maintaining logical structure. During inference, workers receive relevant learnings in their prompts based on product category, automatically incorporating domain knowledge from past disagreements. The knowledge base also introduces traceability—when an extraction seems incorrect, we can pinpoint exactly which learning influenced it. This shifts auditing from an unscalable task to a practical one: instead of reviewing a sample of millions of outputs—where human effort grows proportionally with scale—teams can audit the knowledge base itself, which remains relatively fixed in size regardless of inference volume. Domain experts can directly contribute by adding or refining entries, no retraining required. A single well-crafted learning can immediately improve accuracy across thousands of products. The knowledge base bridges human expertise and AI capability, where automated learnings and human insights work together.\nLessons learned and best practices\nWhen this self-learning architecture works best:\n\nHigh-volume inference  where input diversity drives compounded learning\nQuality-critical applications  where consensus provides natural quality assurance\nEvolving domains  with new patterns and terminology constantly emerging\n\nIt’s less suitable for low-volume scenarios (insufficient disagreements for learning) or use cases with fixed, unchanging rules.\nCritical success factors:\n\nDefining disagreements:  With a generator-evaluator pair, disagreement occurs when the evaluator flags the extraction as needing improvement. With multiple workers, scale thresholds accordingly. The key is maintaining productive tension between workers. If disagreement rates fall outside the productive range (too low or too high), consider more capable workers or refined prompts.\nTracking learning effectiveness:  Disagreement rates must decrease over time—this is your primary health metric. If rates stay flat, check knowledge retrieval, prompt injection, or evaluator criticality.\nKnowledge organization:  Structure learnings hierarchically and keep them actionable. Abstract guidance doesn’t help; specific, concrete learnings directly improve future inferences.\n\nCommon pitfalls\n\nFocusing on cost over intelligence:  Cost reduction is a byproduct, not the goal\nRubber-stamp evaluators: Evaluators that simply approve generator outputs won’t surface meaningful disagreements—prompt them to actively challenge and critique extractions\nPoor learning extraction:  Supervisors must identify generalizable patterns, not just fix individual cases\nKnowledge rot:  Without organization, learnings become unsearchable and unusable\n\nThe key insight: treat declining disagreement rates as your north star metric—they show the system is truly learning.\nDeployment strategies: Two approaches\n\nLearn-then-deploy: Start with basic prompts and let the system learn aggressively in a pre-production environment. Domain experts then audit the knowledge base—not individual outputs—to make sure learned patterns align with desired outcomes. When approved, deploy with validated learnings. This is ideal for new use cases where you don’t yet know what good looks like—disagreements help discover the right patterns, and knowledge base auditing lets you shape them before production.\nDeploy-and-learn: Start with refined prompts and good initial quality, then continuously improve through ongoing learning in production. This works best for well-understood use cases where you can define quality upfront but still want to capture domain-specific nuances over time.\n\nBoth approaches use the same architecture—the choice depends on whether you’re exploring new territory or optimizing familiar ground.\nConclusion\nWhat started as an experiment in catalog enrichment revealed a fundamental truth: AI systems don’t have to be frozen in time. By embracing disagreements as learning signals rather than failures, we’ve built an architecture that accumulates domain knowledge through actual usage. We watched the system evolve from generic understanding to domain-specific expertise. It learned industry-specific terminology. It discovered contextual rules that vary across categories. It adapted to requirements no pre-trained model would encounter—all without retraining, through learnings stored in a knowledge base and injected back into worker prompts. For teams operationalizing similar architectures, Amazon Bedrock AgentCore offers purpose-built capabilities:\n\nAgentCore Runtime  handles quick consensus decisions for routine cases while supporting extended reasoning when supervisors investigate complex disagreements\nAgentCore Observability provides visibility into which learnings drive impact, helping teams refine knowledge propagation and maintain reliability at scale\n\nThe implications extend beyond catalog management. High-volume AI applications could benefit from this process—and the ability of Amazon Bedrock to access diverse models makes this architecture straightforward to implement. The key insight is this: we’ve shifted from asking “which model should we use?” to “how can we build systems that learn our specific patterns? “Whether you learn-then-deploy for new use cases or deploy-and-learn for established ones, the implementation is straightforward: start with workers suited to your task, choose a supervisor, and let disagreements drive learning. With the right architecture, every inference can become an opportunity to capture domain knowledge. That’s not just scaling—that’s building institutional knowledge into your AI systems.\nAcknowledgement This work wouldn’t have been possible without the contributions and support from  Ankur Datta (Senior Principal Applied Scientist – leader of science in Everyday Essentials Stores), Zhu Cheng (Applied Scientist), Xuan Tang (Software Engineer), Mohammad Ghasemi (Applied Scientist). We sincerely appreciate the contributions in designs, implementations, numerous fruitful brain-storming sessions, and all the insightful ideas and suggestions.\n\nAbout the authors\nTar ik Arici is a Principal Scientist at Amazon Selection and Catalog Systems (ASCS), where he pioneers self-learning generative AI systems design for catalog quality enhancement at scale. His work focuses on building AI systems that automatically accumulate domain knowledge through production usage—learning from customer reviews and returns, seller feedback, and model disagreements to improve quality while reducing costs. Tarik holds a PhD in Electrical and Computer Engineering from Georgia Institute of Technology.\nSameer Thombare is a Senior Product Manager at Amazon with over a decade of experience in Product Management, Category/P&L Management across diverse industries, including heavy engineering, telecommunications, finance, and eCommerce. Sameer is passionate about developing continuously improving closed-loop systems and leads strategic initiatives within Amazon Selection and Catalog Systems (ASCS) to build a sophisticated self-learning closed-loop system that synthesize signals from customers, sellers, and supply chain operations to optimize outcomes. Sameer holds an MBA from the Indian Institute of Management Bangalore and an engineering degree from Mumbai University.\nAmin Banitalebi received his PhD in the Digital Media at the University of British Columbia (UBC), Canada, in 2014. Since then, he has taken various applied science roles spanning over areas in computer vision, natural language processing, recommendation systems, classical machine learning, and generative AI. Amin has co-authored over 90 publications and patents. He is currently an Applied Science Manager in Amazon Everyday Essentials.\nPuneet Sahni is a Senior Principal Engineer at Amazon Selection and Catalog Systems (ASCS), where he has spent over 8 years improving the completeness, consistency, and correctness of catalog data. He specializes in catalog data modeling and its application to enhancing Selling Partner and customer experiences, while using ML/DL and LLM-based enrichment to drive improvements in catalog data quality.\nErdinc Basci joined Amazon in 2015 and brings over 23 years of technology industry experience. At Amazon, he has led the evolution of Catalog system architectures—including ingestion pipelines, prioritized processing, and traffic shaping—as well as catalog data architecture improvements such as segmented offers, product specifications for manufacture-on-demand products, and catalog data experimentation. Erdinc has championed a hands-on performance engineering culture across Amazon services unlocking $1B+ annualized cost savings and 20%+ latency wins across core Stores services. He is currently focused on improving generative AI application performance and GPU efficiency across Amazon. Erdinc holds a BS in Computer Science from Bilkent University, Turkey, and an MBA from Seattle University, US.\nMey Meenakshisundaram  is a Director in Amazon Selection and Catalog Systems, where he leads innovative GenAI solutions to establish Amazon’s worldwide catalog as the best-in-class source for product information. His team pioneers advanced machine learning techniques, including multi-agent systems and large language models, to automatically enrich product attributes and improve catalog quality at scale. High-quality product information in the catalog is critical for delighting customers in finding the right products, empowering selling partners to list their products effectively, and enabling Amazon operations to reduce manual effort.",
    "weight": 0.85,
    "fetch_type": "rss",
    "company": "amazon",
    "light_analysis": {
      "summary": "亚马逊目录团队利用 Amazon Bedrock 构建了一个自学习生成式 AI 系统，用于大规模处理产品目录的富化。系统部署多个小模型（如 Amazon Nova Lite）作为工作者，通过生成器-评估器模式处理常规情况，以共识机制降低成本。当模型出现分歧时，调用更强大的监督者代理（如 Anthropic Claude Sonnet）解决并提取可重用学习，存储到动态知识库中。这使系统能持续从分歧中学习，提高准确性，无需重新训练模型，显著降低错误率和运营成本。该架构解决了大规模 AI 部署中性能与成本的平衡问题，为高容量 AI 应用提供了参考。",
      "category": "AI",
      "sentiment": "positive",
      "keywords": [
        "Amazon Bedrock",
        "自学习系统",
        "多模型架构",
        "监督者代理",
        "动态知识库"
      ]
    },
    "analyzed_at": "2026-01-24T03:11:35.569332Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "4d2f2d9410429793",
    "title": "Unrolling the Codex agent loop",
    "url": "https://openai.com/index/unrolling-the-codex-agent-loop",
    "source_name": "OpenAI",
    "source_category": "ai",
    "language": "en",
    "published": "2026-01-23T12:00:00Z",
    "summary": "A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API.",
    "content": "A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API.",
    "weight": 1.0,
    "fetch_type": "rss",
    "company": "openai",
    "light_analysis": {
      "summary": "OpenAI发布了一篇技术深潜文章，标题为'Unrolling the Codex agent loop'，详细解析了Codex代理循环的工作机制。文章重点介绍了Codex CLI如何利用Responses API来协调AI模型、工具、提示和性能优化，通过精心设计的循环结构提升AI代理的响应速度和准确性。这一技术讲解帮助开发者理解如何构建和优化基于Codex的智能代理系统，特别是在代码生成和自动化任务中。这不仅展示了OpenAI在AI工具开发方面的技术细节，还为开发社区提供了宝贵参考，有望促进更多创新应用的诞生，推动AI技术在编程和自动化领域的实际应用。",
      "category": "LLM",
      "sentiment": "neutral",
      "keywords": [
        "OpenAI",
        "Codex",
        "Codex CLI",
        "Responses API",
        "agent loop"
      ]
    },
    "analyzed_at": "2026-01-24T03:11:39.822562Z",
    "analysis_status": "success",
    "analysis_error": null
  },
  {
    "id": "806619e99a4c4e56",
    "title": "Inside GPT-5 for Work: How Businesses Use GPT-5",
    "url": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work",
    "source_name": "OpenAI",
    "source_category": "ai",
    "language": "en",
    "published": "2026-01-22T00:00:00Z",
    "summary": "A data-driven report on how workers across industries use ChatGPT—covering adoption trends, top tasks, departmental patterns, and the future of AI at work.",
    "content": "A data-driven report on how workers across industries use ChatGPT—covering adoption trends, top tasks, departmental patterns, and the future of AI at work.",
    "weight": 1.0,
    "fetch_type": "rss",
    "company": "openai",
    "light_analysis": {
      "summary": "OpenAI发布了一份数据驱动报告，标题为“Inside GPT-5 for Work: How Businesses Use GPT-5”，但报告内容聚焦于ChatGPT在工作场所的实际使用情况。报告详细分析了各行业员工如何利用ChatGPT进行日常任务，包括采用率的增长趋势、主要应用如内容生成、代码编写和客户支持，以及不同部门如营销、研发和行政中的使用模式。此外，报告还探讨了AI在工作中的未来前景，讨论了潜在的发展方向和挑战。这份报告为企业提供了基于实证数据的洞察，帮助理解AI工具的实用价值，并可能指导未来的AI集成策略，以提升工作效率和创新。",
      "category": "LLM",
      "sentiment": "neutral",
      "keywords": [
        "OpenAI",
        "ChatGPT",
        "报告",
        "AI",
        "工作场所"
      ]
    },
    "analyzed_at": "2026-01-24T03:12:01.157793Z",
    "analysis_status": "success",
    "analysis_error": null
  }
]